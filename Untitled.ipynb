{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from neupy import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import pyrenn as prn\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant \n",
    "path = '2016_spring/2016_spring{}.csv'\n",
    "yield_path = '2016_spring/2016_spring.csv'\n",
    "parameters = ['CC', 'CV', 'CH', 'ExG']\n",
    "data_type = \"CC\"\n",
    "limit_day = 80\n",
    "interval_day = 10\n",
    "x_pred = range(interval_day, limit_day+1, interval_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id    CC160323    CC160328    CC160329    CC160331    CC160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    1.779190    4.260457    5.343076    5.519863   16.668472   \n",
      "std     70.292247    2.702540    5.568591    6.607118    6.401390   10.776966   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.022717   \n",
      "25%     61.500000    0.000000    0.000000    0.000000    0.077062    5.043572   \n",
      "50%    122.000000    0.000000    1.006531    1.703657    2.849220   18.146174   \n",
      "75%    182.500000    3.539496    8.860301   11.834021   11.154441   24.911321   \n",
      "max    243.000000   10.094508   18.670866   22.237157   21.618151   46.901408   \n",
      "\n",
      "         CC160419    CC160421    CC160425    CC160504    CC160510    CC160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean    19.428900   22.604212   24.042545   25.209774   31.745804   35.118721   \n",
      "std     10.698871   10.495013    9.047723    9.244777   10.168303    9.193573   \n",
      "min      1.370548    2.348012    4.478416    1.124346    3.753984    9.872068   \n",
      "25%      7.091002   11.761658   15.771608   18.444575   25.246675   28.907828   \n",
      "50%     22.985194   25.513733   24.698005   25.490427   31.354081   35.029461   \n",
      "75%     27.815988   30.735162   30.749257   31.510117   37.680059   41.482717   \n",
      "max     40.299648   43.896321   45.503766   46.619828   68.101868   63.510101   \n",
      "\n",
      "         CC160516    CC160523    CC160524    CC160525    CC160609    CC160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean    35.458836   33.087046   35.329070   35.005474   31.574042   33.209143   \n",
      "std      8.931532    9.351277    9.539150    9.669084    8.983270   10.696622   \n",
      "min      7.653061    6.359917    7.650765    8.963321    7.236125    7.098944   \n",
      "25%     29.057810   27.323628   28.902265   28.885636   25.075075   25.219030   \n",
      "50%     34.964923   32.403659   34.929118   35.320062   31.673776   32.690701   \n",
      "75%     41.618178   39.581977   41.076032   42.053084   37.487278   40.549022   \n",
      "max     64.986500   68.607416   66.424389   64.055425   55.018662   62.065420   \n",
      "\n",
      "         CC160622  \n",
      "count  243.000000  \n",
      "mean    29.855072  \n",
      "std     13.559514  \n",
      "min      3.122053  \n",
      "25%     21.090568  \n",
      "50%     28.897902  \n",
      "75%     36.906560  \n",
      "max     70.738119  \n",
      "               id    CV160323    CV160328    CV160329    CV160331    CV160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.025504    0.162589   -0.120347   -1.275453    0.455756   \n",
      "std     70.292247    0.054609    0.121064    0.095629    0.526068    0.405926   \n",
      "min      1.000000   -0.241641   -0.134953   -0.372370   -1.988806   -0.351105   \n",
      "25%     61.500000   -0.000407    0.079524   -0.187198   -1.669335    0.184268   \n",
      "50%    122.000000    0.018088    0.154566   -0.124536   -1.421133    0.422573   \n",
      "75%    182.500000    0.048915    0.250237   -0.062527   -0.979031    0.742030   \n",
      "max    243.000000    0.339361    0.528110    0.268199    0.251432    2.023506   \n",
      "\n",
      "         CV160419    CV160421    CV160425    CV160504    CV160510    CV160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.537714    0.708608    0.733255    1.184895    1.106869    1.360369   \n",
      "std      0.336711    0.377674    0.379954    0.489754    0.442903    0.411224   \n",
      "min     -0.099054    0.056110    0.050718    0.225353    0.194038    0.374577   \n",
      "25%      0.257365    0.370449    0.380842    0.801605    0.784589    1.083015   \n",
      "50%      0.534366    0.746013    0.757832    1.087891    1.020255    1.310624   \n",
      "75%      0.755954    0.971196    0.992019    1.502699    1.378449    1.651033   \n",
      "max      1.383204    1.573283    1.613604    2.881781    2.784953    2.683436   \n",
      "\n",
      "         CV160516    CV160523    CV160524    CV160525    CV160609    CV160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     1.245839    1.345457    1.282874    1.486181    1.225371    0.947739   \n",
      "std      0.402119    0.470097    0.449471    0.496881    0.444273    0.351954   \n",
      "min      0.390300    0.339928    0.328364    0.423053    0.135786    0.133531   \n",
      "25%      0.959590    1.034972    0.930971    1.121043    0.882057    0.691438   \n",
      "50%      1.200863    1.309832    1.272195    1.456835    1.260330    0.929283   \n",
      "75%      1.493418    1.625070    1.541857    1.783188    1.526492    1.201803   \n",
      "max      2.515981    2.793169    2.619310    3.033122    2.981787    1.797718   \n",
      "\n",
      "         CV160622  \n",
      "count  243.000000  \n",
      "mean     1.208259  \n",
      "std      0.323304  \n",
      "min      0.514999  \n",
      "25%      0.948969  \n",
      "50%      1.198723  \n",
      "75%      1.445859  \n",
      "max      2.179391  \n",
      "               id    CH160323    CH160328    CH160329    CH160331    CH160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.076246    0.106770    0.110527    0.110976    0.238481   \n",
      "std     70.292247    0.051069    0.048342    0.079658    0.132101    0.152020   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     61.500000    0.057907    0.065751    0.070746    0.000000    0.104721   \n",
      "50%    122.000000    0.068730    0.090834    0.089447    0.093469    0.207002   \n",
      "75%    182.500000    0.082941    0.150629    0.153059    0.184821    0.331964   \n",
      "max    243.000000    0.760147    0.254143    0.969861    1.076819    0.763881   \n",
      "\n",
      "         CH160419    CH160421    CH160425    CH160504    CH160510    CH160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.326765    0.380316    0.434813    0.555992    0.581738    0.553074   \n",
      "std      0.159808    0.172381    0.175906    0.159174    0.128924    0.135876   \n",
      "min      0.062200    0.089616    0.099268    0.195958    0.250065    0.230499   \n",
      "25%      0.159139    0.201092    0.242200    0.421301    0.474530    0.452727   \n",
      "50%      0.346280    0.415334    0.472981    0.541967    0.569039    0.533580   \n",
      "75%      0.455055    0.496061    0.567771    0.665200    0.679777    0.639246   \n",
      "max      0.700948    0.773985    0.866399    1.016903    0.874122    0.955869   \n",
      "\n",
      "         CH160516    CH160523    CH160524    CH160525    CH160609    CH160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.562553    0.622173    0.643549    0.648695    0.547599    0.476690   \n",
      "std      0.133658    0.135163    0.140558    0.146192    0.106029    0.110016   \n",
      "min      0.222351    0.264048    0.323193    0.259544    0.272005    0.201900   \n",
      "25%      0.466641    0.518361    0.539487    0.534388    0.477356    0.401076   \n",
      "50%      0.542644    0.607084    0.645303    0.632763    0.542530    0.467899   \n",
      "75%      0.655245    0.711207    0.743766    0.746891    0.619767    0.548069   \n",
      "max      0.892660    0.923697    0.969956    0.990879    0.811504    0.779979   \n",
      "\n",
      "         CH160622  \n",
      "count  243.000000  \n",
      "mean     0.336080  \n",
      "std      0.087689  \n",
      "min      0.157737  \n",
      "25%      0.275544  \n",
      "50%      0.324984  \n",
      "75%      0.394074  \n",
      "max      0.596945  \n",
      "               id   ExG160317   ExG160323   ExG160328   ExG160329   ExG160331  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.065331    0.096702    0.135541    0.144645    0.211936   \n",
      "std     70.292247    0.071743    0.079134    0.098548    0.097907    0.080964   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.104701   \n",
      "25%     61.500000    0.000000    0.000000    0.000000    0.093325    0.156305   \n",
      "50%    122.000000    0.000000    0.114337    0.161547    0.158173    0.204603   \n",
      "75%    182.500000    0.128573    0.167559    0.217595    0.237995    0.251572   \n",
      "max    243.000000    0.208723    0.250075    0.319363    0.319114    1.050000   \n",
      "\n",
      "        ExG160414   ExG160419   ExG160421   ExG160425   ExG160504   ExG160510  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.223494    0.252478    0.223410    0.266880    0.272247    0.234704   \n",
      "std      0.060474    0.053447    0.034973    0.034144    0.033235    0.031493   \n",
      "min      0.106751    0.132074    0.148127    0.182493    0.177950    0.143914   \n",
      "25%      0.160492    0.208172    0.198456    0.242295    0.255126    0.213842   \n",
      "50%      0.241370    0.262620    0.226973    0.269579    0.273329    0.238325   \n",
      "75%      0.272044    0.295827    0.247310    0.291451    0.293501    0.256113   \n",
      "max      0.337627    0.345226    0.311434    0.360905    0.374617    0.312947   \n",
      "\n",
      "        ExG160512   ExG160516   ExG160523   ExG160524   ExG160525   ExG160609  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.264808    0.258221    0.239454    0.237113    0.263938    0.264946   \n",
      "std      0.037053    0.040075    0.037964    0.040119    0.041691    0.054771   \n",
      "min      0.166548    0.155537    0.138684    0.129689    0.165107    0.157211   \n",
      "25%      0.238292    0.231425    0.214118    0.206064    0.234373    0.220702   \n",
      "50%      0.264688    0.260281    0.242203    0.242705    0.270033    0.265563   \n",
      "75%      0.292520    0.286816    0.264560    0.267872    0.294405    0.311555   \n",
      "max      0.361511    0.366541    0.319069    0.328575    0.351662    0.384207   \n",
      "\n",
      "        ExG160616   ExG160622  \n",
      "count  243.000000  243.000000  \n",
      "mean     0.213018    0.202651  \n",
      "std      0.043176    0.035695  \n",
      "min      0.127558    0.130875  \n",
      "25%      0.178086    0.176415  \n",
      "50%      0.209619    0.200414  \n",
      "75%      0.243025    0.223618  \n",
      "max      0.349283    0.355599  \n"
     ]
    }
   ],
   "source": [
    "#read files\n",
    "data = []\n",
    "yield_data = pd.read_csv(path.format(''))\n",
    "for i in range(len(parameters)):\n",
    "    temp = pd.read_csv(path.format('_'+parameters[i]))\n",
    "#     print(column_name for column_name in temp.columns if parameter[i] in column_name)\n",
    "    temp = temp[['id']+[x for x in temp.columns if parameters[i] in x and len(x) == len(parameters[i]) + 6]]\n",
    "    data.append(temp)\n",
    "    print(temp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count date function\n",
    "def count_days(date_planting, date_key):\n",
    "#     print(date_planting, date_key)\n",
    "    f_date_array = date_planting.split('-')\n",
    "    f_date = date(int(f_date_array[2]), int(f_date_array[0]), int(f_date_array[1]))\n",
    "    l_date = ''.join(s for s in date_key if s.isdigit())\n",
    "    #print(int('20'+l_date[:2]), int(l_date[2:4]), int(l_date[4:6]))\n",
    "    l_date = date(int('20'+l_date[:2]), int(l_date[2:4]), int(l_date[4:6]))\n",
    "    return(abs((l_date-f_date).days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process function\n",
    "def convert_day_after_planting(data, yield_data, parameter_type, normalization, std):\n",
    "    x_pred = range(interval_day, limit_day+1, interval_day)\n",
    "    my_list = np.empty((0, len(x_pred)))\n",
    "    for i in range(len(data)):\n",
    "        date_plant = yield_data['plantDate'].iloc[i]\n",
    "        data_extract = data.iloc[i]\n",
    "        grnn = algorithms.GRNN(std = std)\n",
    "        x = np.array([count_days(date_plant, i) for i in data.columns])\n",
    "        mask = (x<=limit_day) & (data_extract >=0) &(x>=0)\n",
    "        x = x[mask]\n",
    "        x = np.append([0], x)\n",
    "        data_extract = np.append([0],data_extract[mask].values)\n",
    "        grnn.train(x, data_extract)\n",
    "        pred = np.transpose(grnn.predict(x_pred))\n",
    "        my_list = np.append(my_list, pred, axis=0)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(normalization, std):\n",
    "    preprocessed_data = []\n",
    "    for i in range(len(parameters)):\n",
    "        passed_data = data[i].copy()\n",
    "        print(normalization)\n",
    "        if normalization:\n",
    "            passed_data = passed_data/np.linalg.norm(passed_data)\n",
    "        preprocessed_data.append(convert_day_after_planting(passed_data[passed_data.columns[1:]], yield_data, parameters[i], normalization, std))\n",
    "    preprocessed_data = np.array(preprocessed_data)\n",
    "    preprocessed_data = preprocessed_data.swapaxes(0,1)\n",
    "\n",
    "    #train data has shape (number_of_observes, number_of_day_observed * number_of_parameter)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_GRNN_example(observation, std, normalization):\n",
    "    plant_date = yield_data['plantDate'][observation]\n",
    "    grnn = algorithms.GRNN(std = std)\n",
    "    x_test= np.array(range(1, limit_day + 1))\n",
    "    x_preprocessed = np.array(range(10, limit_day+1, 10))\n",
    "    fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(8, 6))\n",
    "    fig.suptitle('Observation id:{}, Yield:{}\\n'.format(yield_data['id'][observation], yield_data['Yield'][observation])+'reps: {} variety: {} plantDate: {} Mulching: {}'.format(yield_data['reps'][observation], yield_data['variety'][observation], yield_data['plantDate'][observation], yield_data['Mulching'][observation]), fontsize=16)\n",
    "#     fig.suptitle('Observation id:{} reps: {} variety: {} plantDate: {} Mulching: {}'.format(yield_data['id'][observation], yield_data['reps'][observation], yield_data['variety'][observation], yield_data['plantDate'][observation], yield_data['Mulching'][observation]), fontsize=16)\n",
    "    for i, parameter in enumerate(parameters):\n",
    "        plant_date = yield_data['plantDate'][observation]\n",
    "        value_data = data[i].copy()\n",
    "\n",
    "        value_data = value_data[[column for column in value_data.columns if parameter in column]][observation:observation+1]\n",
    "        x_original = np.array([count_days(plant_date, column) for column in value_data.columns])\n",
    "        \n",
    "        \n",
    "#         value_data = value_data[value_data.columns[mask]]\n",
    "        y_original = np.array(value_data.values)\n",
    "        y_original = y_original[0]\n",
    "        mask = (x_original<=limit_day) & (x_original>=0) & (y_original>=0)\n",
    "#         print (len(mask))\n",
    "        x_original = x_original[mask]\n",
    "        \n",
    "        y_original = y_original[mask]\n",
    "        print(len(y_original))\n",
    "        x_original = np.append([0], x_original)\n",
    "        y_original = np.append([0], y_original)\n",
    "#         if normalization:\n",
    "#              y_original = y_original / np.linalg.norm(y_original)\n",
    "        grnn.train(x_original, y_original)\n",
    "        y_test = np.transpose(grnn.predict(x_test))\n",
    "        y_test = y_test[0]\n",
    "        y_preprocessed = x_train[observation:observation+1]\n",
    "        y_preprocessed = y_preprocessed[0]\n",
    "        y_preprocessed = y_preprocessed[i:i+1,:]\n",
    "       \n",
    "        axs[i//2, i%2].plot(x_test, y_test)\n",
    "        axs[i//2, i%2].scatter(x_original, y_original, color='red', label ='original')\n",
    "        axs[i//2, i%2].scatter(x_preprocessed, y_preprocessed, color='blue', label='predicted')\n",
    "        axs[i//2, i%2].legend()\n",
    "        axs[i//2, i%2].set_ylabel(parameter+' values')\n",
    "        axs[i//2, i%2].set_xlabel('Days after planting')\n",
    "        axs[i//2, i%2].set_title(parameter)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAG4CAYAAAC+ZBgrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3xUVfbAv4caegdpSRRUQAREUARRcC0o2DtYsLG23VV3FZW1rMrqqj9118biqqAglrUjKhZQYUEFQaUXCSHUJEAIhISU8/vjvoHJY5LMpM0kOd/PZz4zc98t57Xzzjv33HtFVTEMwzAMwzAOUCvaAhiGYRiGYcQaZiAZhmEYhmH4MAPJMAzDMAzDhxlIhmEYhmEYPsxAMgzDMAzD8GEGkmEYhmEYhg8zkIxqgYicLiKfiki6iGSLyCoR+YeItAiRV0XkkWjIWZGIyHkickeI9CHePg+pZHkmiUhSGPlGe/IllpCvk4g8KyLzRCSruDLetlCfPhHuQ0cR2SkibxSx/VUR2SUinUUk0WtjdCRtePXMFpHZYeR7UERKnJtFRHqKyL9FZKGI7CuqjHeOijpWK8Jop5aI3CMiSd5997OIXFhSOcOoCpiBZFR5RORe4HMgG7geOAOYAIwGfhSRztGTrlI5DzjIQAJ+Ak7wviuTh4Hzy7G+rsAlwA7guzDyT8Ltd/BnVSQNqupG4C/A5SIyPHibiJyKu8buVNUNwGavjU8iaaOCOBY4C0gGFhST72EOPkaXe9s+CqOdh4EHgeeAM4H5wDsiclappDaMGKJOtAUwjLIgIkOBR4BnVPX2oE3fiMj7wELgNWBoNOQrChGpr6o5ldGWqu7CPbgqFVVdW85Vfquq7QBE5Hrg9BLyb1TVMu+3qv5HRC4FJohID1XNFJGGwERglveNdz4r/TgXweuqOhnA85aeECqTd44KnScROc37Obm4BkSkLc54fExVn/SSZ4lIV+AxYEbpxTeM6GMeJKOqcxewHbjHv0FV1+EU9RAROd63WURknIikiMheEfnW3/0iImeIyFwRyRCR3SKyUkTu9+XpLSIficgOr565IjLYl2eS184JIvI/EdkLPC4iM0RkoV9uEWkvInkicpv3v43XXbLK61raICJviEjH4DaAq4GOQV0kSd62g7rYxHG7t0/7RGSziDwnIk19sqiIPCIifxSRdSKSKSLfiMhRRZwP/34n+dIOE5FPvP1IFZF/AvVLqgtAVQvCyVdB3AA0B/7h/R8PtAOuV285gqK62ETkZBH5yjt2e0TkcxHpWVKDInKMiHzndV1tFJH7AAlH2DIeq6uAhaq6tIR8ZwD1gCm+9CnA0SJyaBlkMIyoYwaSUWURkTrAycAXqppdRLZAN8EpvvSrcF0Qt+K6SdoBX4lIS6/uw7yyScClwDnAU0CjoPb7Av8DWuIeoBcC6cCXInKsr71mwJvANFxXxBs4z1ZfEenhyzvS+57mfbfEdR/eAwwD7gQOB+aKSJyX52HcG3sqB7pKiuveGu/tzxfA2cDj3nH4RET8euEKYDjwJ+AaIB740Dv+YSMi9bz2jgFu8do7FPhriLwPShhxSSVwk4jkeMbY137DNRJUNQl3/G8UkT8DfwTuVdXfiivndct9BezGHceRQBPgu+K6fkWkNfA10Bpn+N6CO/fXhsg7ScKISwoHERmE68os1nvkcRSQA6zxpQcMK/91bRhVC1W1j32q5Adn1CjwaDF54rw8LwSlKZAGNApKSwRygYe9/xd5+ZoWU/dXwHKgXlBabS/tg6C0SV5d5/rKNwAy/PIDi4EZxbRbG+js1Xm+r52UEPmHeHmHeP8DBtckX74rvHzn+I7VaqBuUFrg2Aws4fxMApKC/t/glRsQlFYL90BVIDEo/X4gD0goou7r/WV821/HGbaDvf362Tu/Q8pwvQnwrdfuXKCWb3uit210UNoa4Ctfvqbe9fdMUNpsYHbQ//HAPiA+KK2RV0599b0M5BUj9yP+MsXk/bfXbusw8k4EtoRI7+odhytLe6ztY59Y+JgHyajKhNXdUAQzVHVP4I86D8F8DsRqLMY9UN8UkYu8eIsDDYs0wHmv3gEKRKSO51ER4EvgJF97ecD04ARV3Qu8C4wSEfHqPRrojfMuBbd3k7gRQru9upK9TUeWYt8H4Lq1/F0jb3p1n+xL/0JVc4P+/+p9x0fY7gnABg2KC1LXFfS2P6OqPqSqdVR1fYRtBMpfqapvqep3qjoFOBHYhDMWSoWqalD58VpCN5aIHA50AaYGrg/vGskC5nHwNRLMCcB8VQ2cZ7zr9eMQcl2nqmWOJxWR+rgg+OmqmhZOEZwhFCrdMKo8ZiAZVZk0YC/uzb0oAts2+NK3hsi7FegIoKprcDEWtXDeiC0i8r2IBIyHljhPzn04Qyr4cyvQwtdVtU1V80O0+RrOGzTE+38lkAl8GMggIn8AXsAZXhcAx+GMHHAeskhp6X1vDk5U1TxcF2FLX/7tvv+B4PJI225P0ce9QlHVTNzosv5lrGqf77s4Akb1yxx8jYwAWhVTNhrH6lxcnFU43WvgrosWAeM+iBZB2w2jymKj2Iwqi6rmici3wGkiEqeh45DO8b6/9qW3C5G3HbAxqP5ZuFE59YFBwEO4GJ1EYCdQADyPz9sTVD7Yw1BUjMg3OG/QFSLyDW6I9X8971KAy3DdNH8OJJQxADbw4DqEA/EigZiuVjgjqSLYjItb8RPqXFQERXk8KorAcbwHZ9z6Kc7I2kzR12hFcTXupSPc0WdLcZ7ILhSOQwrEHi0rP9EMo/IxD5JR1XkC91D/u3+DZ0SMxQ0P/963+SwRCQ64TsR5Zeb561HVHFX9GhfI3Ag41Ovu+A7XHfaTqi7wf8IR3uu2mYqL6zkL6MTBBldDnNchmGtCVJeDi2sqifle3st86ZfiXpq+CaOO0jAP6CwiAe8Xnpftkgpqbz/e6LzhgP86qEhW4oL8jwp1fajqL8WUnQcMCA7k9q7XsytCUBFph5s24Q1fd2pxfIYz8kb50q8AlqgbRWoYVRbzIBlVGlX9StzQ+4c8I+c13ESCfYG7cUHQV4YouheYKSJP4N6C/wbsAp4GEJEbcTEiM3Ddc61xnoBNwBKvjjtwQbufi8jLuLf+1l7btVX17jB34zWv7gleW34D5TNgrLgJMX/Ajci7KEQ9y4CWInITbnLAbFX91Z9JVbeLyFPAPSKyx9vH7rj4mjlU3ESHk3Hn5D1vX7YBN+KClgvhndP7gS7BcUgiEtjvwCjBM0UkFUhV1W+8PH/BxWbNwp2vBNx8PYfge5iLm706UVUTy2cXD6CqKiK34Eb81cPFWqXhvEADgWRVfaqI4k8DN+Ou0QdxBu2duOu2EN61d3VwHJK4eZoCkzV289ICxy4phAE/Cvc8KLJ7TUTygMmqep23f9tE5GncdZSJm4j0Utz1eW5R9RhGVcEMJKPKo6oPi8iPwO3AqziPSzLO8HhUVUPFQrwG7MHNANwa+BG4LCjvz7jh+I/iYkm244yHUYHuL1X9SUT6Aw8A/8IN5U/FPSgmRCD/ChFZAPTz5PV3Az2Eiw25HRf38w0uPso/xPw/OC/Y37386yk6PmucJ+uNuAdxundM7ikp+Li0qOo+cZMQPoeLqdqDm+7gEw4+XrVwMV7++JZ3fP9f8L6/4UAc10rcFAfn487JLtyos+tU9Qdf+UbAllLsTlio6gwROQl3vP+D8/BtwXnx3iqmXJqI/A74J85oSccdozo4wzGY2t4nmLYcfKwC/yfjplgI5mqc16e42dZDtTMON4XBn3AG6ErgElU9KJjcMKoacrAuNgzDqP54XVY7gCtU9aCRdIZh1GwsBskwjJrKQNwyG/+NtiCGYcQe5kEyDMMwDMPwYR4kwzAMwzAMH2YgGYZhGIZh+DADyTAMwzAMw4cZSGVERB4TkV9EZKe3avgKEbnPm4ckJvBW+04qRbk+3qrq/qUnyh0RSfFWb1cRyReRZBF5W0RKs9ZYtUFETvWOyYkV2Ma1IjK6mLYDn73eefrEK1OvlO0d5l1XiWUUPZy2LhGR90RkfdD9OV5EGodZ/kYR+VRENorIHhFZIiJ/FpG6IfIOFpEvRCRVRHaJyMJQx7WscopISxF5RUTSRWS3iMwUkaN8eURE/u5tS/fO3xXFtN9SRP4lIhtEJMc7zy+HIfcUr+4kkYOWHEFEHglcP+EchyLqX1NyzkJlrvfaTCwhX9eSjktlEnysvE+ud1xfEpH20ZavIgg6V52C0lJE5D/RlCuAGUhlpylu7p2RuFlup+LmBpkWTaF8PIybEyZS+uDm+KlwA8ljBm6RzsHAg97vb0WkdSW1X1O5loPnxQnmFty5OB034eIW4EVgvogUt55YURyGu64SS1E2Uu7EzfZ8D25eq3/j1sr7TAqvlVcU9+OWn/kjbv20d3DzTPkXEz4G+AKnU6/DTeS5CHhVRG4oLzm9358Ap+LOy8W4uZVm+x6itYE/4ObNKnbpEO8FaC5uHql7cef5Ttz8RuGwB7dwcaHFdz2D6Qrc2oKxyAbcdf1ZtAXxcYL3OQV4DDfp5vRQBmg14EPcvm6LtiChiOmJIkWkvqrmlJwzeqjqzb6krzzv0d0i0jrMVbErhMDxU9W10ZIhQlKDVnr/n4isx61hNRI3EeNBVIVrpBqwLOi8ALwpIq8CX+EmPyyN8V1ZnKWqqUH/vxGRDNwCsifiZkIvjt6+8rNEpDZwn4iMVdVkL/1y3DpvZ6tqlpc2U0R6A1cBL5WTnOfjJgM9SVW/AxCR+cA6nFFzB+xfp7CZqhaISDecoVIUj+MMqeO8RX0DhPuSl4ZbUuVKCs8CfzJuIeYpuGMQU3h6Y36JGSsZ3732nWcXvQh0BVaXtf5Y0pneNZ9aYsYoETMeJM/lriLSU0Q+F5HduKn5A9svEJH5nvt5p4i8IyLxvjqSPJfsDSKyRkSyReQnERnqy9ffc4Wne/X9JiIvUH4EFqksck0jEXlBRLaKWyA0OL2+iOwQkWe8/3Ei8rQ41/5uEdkiIh97Si+43Gjv+J3kHZudeOtOSYguNhFpKCL/EJF1IrLP+x4XeFsV1zXwqpd9dZDbN1FEfhWR90Ps0xAvzxmRHKxi+NH77urVH3DHDhKRd70HyFxv2xwROWhBUL+7NqiO/iIyTVxXyCYReUbcorSBfCG7topwCV8pIovFdcFkiOtyvb64HZMD7vSjRGS2dx1u8u6DYu9LERkmrttnsxzo9rnNe3D7932SiIwS12WzR0R+FJGBQXnm4BbiPTnoHIdaWLUQqjoHmAicK0FdGSLyJ+8+3e7dp/8TkWFB20/FeVrAGRuBNk8MynOjdwyzxXVXvSQizUuSqQg5QynfwHXVsRzL18Pd7/4FkzMIQ89G0M45uCVKvgsquwPnVSq0vEc4M6KLW6PuCmCizziKlNeAi0QkLijtKmA2zlMT3GYd75z/1ZceVpeXiDQWkcdFZK247sAtIvJfEWnjy9qmhHv8oPbEPT+SRORYT6dkicgqCeEFFJHTvfs+W0RWi8g1UoouwTDY5X3v79YVkeM9HZgirut7padTgo9/QC/OFpHzPFlzgDHetjridP5K7zhuFJEngo9RUYhIBxF53TuuOd73xxLkURaRjt7xSPOO0c8iMtJXz0H6NJaIGQMpiA9xbyHnUHhdrHdxa01dBPwe6Il7y2riK38y7i1qHG4xzhzgU/FiWcT16X8O5OO6Fc7CLeXgN1RURCaFK7R3sTX2HgB3AK+oakYxRV7DLQdwui99BG6ZiNe9//WBJrh1soYDN+He9uaLyCEh6p2Ke5u8CLfuVUhZccfgetxSBmfiPAH34RZ/BadwH/F+X8wBt+9m3NvMCBHp4Kv6917bM712Agror5SOwIr1O33p03BvUhfiznNpmIpbFuECXHfGH4G7Iq1ERE7GLd3wNe6avRh4BWgRZhUf4c7FebilJx7AdXMUx2G4Y3wt7np5DXeu/hYi71DcvgXuh3o4d31g/bMxwC+47qDAOf5DmLLPwC0FMjAoLQFnOF3stfcz7v47zdv+gycPHOi6O8HLh4g8CTyLOybn4BYbHgHMkMJdTVPErQ1WGk72vpeXoXw+hd/mX8XpkGdEpL2ItPD01sl4eqyc5DyKA2sBBrMUOFREwlmsOJh+OB2TKi4Gaq+4F7H3RCQhgnrewV1b5wB4clzEwQsvlwnv4f0V7tp5FacTb8UZon4jurT3eHOc12syzuhcBEwUkcFBchwNTPfavRT4K677+SR/ZZ6RErbR5D1L6ohIAxHph+t2/QVYEZQtAbek0Y04/f0v4AacHvfTHXgKeAa3RNFsL32aV/fruOP4OE4fhHPOpgL9cft8Gm6pmc14i2V7z+VvcM+3e3Cez2XAVBG5Noz6YwNVjYkPLuZEgT/50hvjLsJXfOmJuD7724LSkry0+KC0Jrh1tF73/vfz2ulVgjx5wMthyt7TqzPwmYxbrLSkcquAab60D3BdGkWVqY1baywTuD0ofbTX9tMhykzCLVAZ+H+ll/ckX75x3vFr66uzqy9fE9xbzX1Baa1xxujdQWldvON4bxjHIsU7bnVwirYXzv2dh+vmAGfQKfBEiPJzgC+LqPc/Qf8Dddzny/dZ8HHHxXgocKIvX6B8J+//3cC2Ulzvj3j1/MWX/qp3vTctTo6g/OIdswdwXR3i2/d0oFlQ2gCvvkt8x252iLoDbQ8pou2jvO1/LmJ7LU+2r4F3S6rXu17y/dcLzlBQYERQ2mTcYryRHvfO3nH6NNKyXvljcF6iF0NsG4CLVwrogRxgdCnbCSknbv29KSHy3+i12T7Etm7etitCbLvC27YLty7eaV7aBq+txiXIOQVPt3jlp3u/R+JimBoHrvWgMnW8Nv/qq6urX06v/jVB/8d4ec4qRqZw7/Gi2lNgcFBaHG5JmheC0t4GtgINgtI64fTnGl+7s4EVYZzzgE7wf5YBhxZTLqADRnv3T/OgbXOAAuBoX5mhXt0jfelXe+lHlyDrXuDmYrbfRmj9ORtnSNXynatOQXkK6exofmLRg+TvujkBFwg9NciyroM7iCs42GKfrwfiAlDnNv7EqwfcW99O4N8icoWIdA4lhKrWUW/V6jBYg7Omh+De/s8nPCt8Cq6LognsD5Y8019W3AiX78V1m+XhgiIb41Ys93NQ11cIhuEWMv2f75jOxLlxBxRX2DumU4Drg97qr8HdqK8G5VvrHce/hyETOJd8Lu7B8jPOw3ahqv7syxfOPpaEf8X6X3GBppHyI86V/5qIDBeRZhGW968B9ibueu9RVAHPvf2SiCTjjlcu7gWjlfcJZq4W9mT+6n2XZl8PEsX71iDZ+osb5bYVp6xzcco4nNGIp+OMKv+9PhfIIuheV9WrVTWuiHpCC+u8Zh/iDJxrfdvq+NoMVb4j7gVmJS7eJ3jbkTgvys+4wRqn4t7mXxKRSyNsp0g5ccdcDyp08KK+4RK4f1fjFmL+QlWn4Lx/h+Jiq8LlNeAMEWmLu5ffV9VwA73D5XRgo6oWG3juUdp7PFMLd2Fm43R8cNkBOGNwb1C+FELENKnqEFXt5k8vhv7e53icdyobF8+2vwtRRJp73WG/4fRlLk731sILSQhijar+6ksb5tX7fohnALiBMohIbd81G7jOFgBjReQPItIzxD6cBKxX1xUfzBTcosZVYnRyLBpIm33/23rfX3LgYRD4HM3BD4StIerciteP7z0shgKbcCuBJ4uL4biwtAKraraqLlDVb1T1UZwrd6SIFGto4FybcThXNDilVBfnvgRARM7Gdb0sx72VHY+7eVK9sn78xy8UbXEuWv/xDKx0Hs7IpBdwCuMs76YZg1OIoY5/uEzH7Vtf4BBVPUxVPwyRL5x9LIntvv85hD6exaKqX+GUWCLu4Zkmbmh1KKURCv/xCvwPGR8jLs5oOk7BPYQzyvvjRrvAwfsQaj9D5SsNgZeLzZ5sCbj7tCmu2+MET7YvwmwvcK8ncfC12ZDwrsuQiBs48THuuj9dVTcHbevqb88fE+E9nL7AGX3DQjz4H8O9VZ+jqtNV9StVvQV4D3hWHHVCtOOPcStSTo/thB5V2gJnOPm7o0siEC/5pXqv7wCqOhf3InZMBHV9gdNLd+AMxHLtXvNohXs5DofS3uP+cqHKtif0yKuy6D8AvGfJAlX9Qd0iyiNwRs9tQdkm47rUnsF5/fpzoOvav4+h9GVbL18Wha/JTd72wL223rd9lJd+Ec4AvQf4VVz80v4YVtw1GqrdLUHbY55YHMXmfzsK3MCjcf3sfvyBhe1C5GmHc327BlQXAxd6CivQx/u2iPRW1VD9+5GywPvuSjGjJFR1nYjMxbm0X/W+Z6tqcFDjZbg3gNGBBHFzsBR1gYV6u/STjosVuqSI7UklVaCqS0TkO1zcUTZuX38fRtvFyqWqC0rOFnIfs3Fdc/vxDLdwY4FC1Ye/TkI8pD0l9rYX33YK8A9c3E188EOnCNoByb7/EHS9+jgC99C6XFXfDCSKSDRGkg3HnYu53v+zcMbRxaoaUISISKMw6wvc67/jQGBqMKUaESpuvqb3ccftd6q6zJdlA+4BE8z+B524APGZuNiUE0MYLeBe1n5SVX9c1A+4+6yVqqaJiL+d/XElYcgJTgceFOeC8ziuC/ZohElA3xXllSox0DuAquaLyBs479pmXKxQKAKexRLvrRCkUYKHu5LYzAGDPphQz58yoaqbRGQHLuwgYESPAMap6v7RveKmmghZRYi0dJxxdHIRZQKG0lkUPk+/eTJtBW4GbhY3YOgaXBfhNtyIze2ENq4DcbPpIbbFHLFoIPn5H84I6qqqk8PIP0BEOgeMDK/7ajgHu1vxlNl8EbkPF1zYndABkJESuOjCGV7/OvCiiAzBvXFf49veENetFsyVuFik0vIZLsB5t6quKCZfwNtQVODnCziXaQtglap+XQaZysp6XOB4naCH1FDc8SttfeDiy4L366yiCnhehY88j8T/4Y5LqLfRYC4Bngz6fxnOOAj1MgAH9mf/CEnvwToydPawyMF12YaN5/m4ARdbFDDwQsnWHef1TPK1BwdfVzNxyrxzmPd6OHLWxnVbDsbFrfzoz6NuyHNIw9wz7mbgvGUnq+pvRTS1BThGROqqavDo1eNxnpidXltFtVOinB4fAVeKyCDPyxMw4EYQ1L0dLqq6XkQW47rG7gkY9F5AckMOjKQLl5dxL0ufaRGj6FRVRWQD7t4KZngY9c/EjZY7U1U/jVC28mQ+Tt80CBilntdxAIVfeMqMV28LDgyHj8P1/gTfZ0Lxc5n5+Qz4M9BIVb8pKpOq/lJSRd4zZKyI3MSBc/oNcL6IDNDC0xaMxN0rqyKQNWrEvIGkqrtE5E7gec/N/SkuiLUjzhCZrapvBBXZiuuvfRCniMcCjXCTJSIiI3DdQR/gvCiNcK7JTGBeoBJxI2QmFxeHJCK9cA+3d3CWdX3c292fcMGV84oqG8TbuBEIU3Au+nd92z8DzhORp3FdK8d68kbqSg9mKs4Q+0pE/g8XN1EPFyR7DnCeurlcAm+wt4jIZNwN+Yuq7vPS38W5eAfhbrZCiEgXXLzG/RHEIZWWN3HxGq+IyGu4fbmNUk5Sp6obPO/eOO/tLQ1nmCYE5xOR8bg331m4t8p4XPfSAlUtyTgCuNHzZP6Eiz8bjQteLUrupbguhsfEzU5cgOvSyI9sDwuxDBdPdjHuntilqsEKrIeIZOO6f9vj4kCuxMV0BHsNA11QU7zrtQNuZJ3/gbHSy3ediOzC3acrVHWVuFFsL3qG1bfets5emy/qgbl/JgOXhhGHNAEXE/gQkO3r9t6gqkV56gK8jzNy/gg08ZVfowfmOXsWdw1+JCITcPfyebjRfE+E8CyVVs73cF6pN0TkLpwuvBf3EhVsaOO9dLXGnQeA/t55LFDV94KyjsXp1bdE5BWcF+TvuGvtrRLkLoSqLsftd0m8iXuo3oMzwk7CvRyUxGRcYO/bIvIobiqTprh753FVLe8h9kURmHz3M0+HNsBNKroVn9dNRGbjQgbCikMKOve1cF33d+F07wQAVd0uIguAu8TF+u3AHZOwvVeq+qWIvIOLQXqKA+EVibiXwD9rEfPniRvK/ynuObICd+1dgBu8E5jC4xXcaNj3xY1i3oTrIRkKXFeU8RxzaBQiw0N9ODCKrU4R28/CPYR24ZTPGtxJ6BGUJwkveBjnvcnBDdE8JSjPkbibfh2uGyUV94Z4vK89BSaVIHM73MiNdZ5M6bib/RagfgT7/o7X3hshttXCuS434Vyi3+Bcl0nB8lHEiDNv2ySCRrF5aXHeMV/hHaftnuwPBp8D3OiojbgHmgKJvnr+7R3HViHaDYwS+WsYxyAljON9fSgZgrbf7F0Xe3GjN46h6FFs/v14BMjzpcXjPI8ZuLeeR3AGwf5RFziDcibOOMrBdde8hFOIxe1LYMRKD9zIjr1eHQ/ijfDw8h00ig0XoxUIXN7glSkkV1HHlBAjiHAP0M9wxqTijQYMajvwyfauhRk4A7tuiP26HGcAZeO8sZfgG4kUdK7W4ZSrf/+uxj34sjyZluEMkA5Beab4z1cx11WokUElXpdBx6qozxW+/MNx92caTk8two0uC2dEa9hy4oyeSbh7dg/uodQzRJ1ziqjvoOPmyb7AO29pXv1tw5B7/yi2kq51X1oD4DncNb8LN+Q8MMKyyFFsXloTnId2PW7U2Gbci2brSO5xih7FdtD+EGKULG7I/M+4+36t1+7HwI8hyq4JdWyK0AmBTwHufvsQ6OfLexgH7tltuJfsczj4Xgo5QtXbVhu4HTeFQDbupXsxLkSgaTFyNsBN5bEUN1IxA2dgXebL19E7nukcGHjjHzUX06PYxBOoWiBuMsQ5qhoTa+tUdzzPxxrgO1W9MtryVCVE5BFcDEF1XD7AMGoc4kYfrsENVilrPKYRA8R8F5sRe3iKoCeuP7kz7m3OMAyjxiAiz+E8NJtx3pLbcN19z0ZTLqP8MAPJKA19cd2d23ATey6OsjyGYRiVTUPcygNtcV1IP+DCOcpjoI8RA1SrLjbDMAzDMIzyIBYnijQMwzAMw4gqZiAZhmEYhmH4MAPJMJRxrjoAACAASURBVAzDMAzDhxlIhmEYhmEYPsxAMgzDMAzD8GEGkmEYhmEYhg8zkAzDMAzDMHyYgWQYhmEYhuHDDCTDMAzDMAwfZiAZhmEYhmH4MAPJMAzDMAzDhxlIhmEYhmEYPsxAMqKGiIwUkQUisltENovIpyJyorftCBF5R0TSRCRDRH4RkTtEpHa05TYMo3pRhC66T0SSRER8eeuIyDYRGREteY3KwQwkIyqIyB3AM8DfgXZAPPACcK6IdAG+BzYAR6tqM+BioB/QJDoSG4ZRHSlGFzUFmgMn+4oMAxT4rBLFNKKAqGq0ZTBqGCLSDNgIXKOq74TYPgVooarDK104wzBqDGHooolAHVW9NijtbSBFVe+oPEmNaGAeJCManADEAe8Xsf1U4L+VJ45hGDWUknTRZOAiEWkA+w2qs4HXKkc8I5qYgWREg1ZAmqrmFbN9cyXKYxhGzaRYXaSqc4GtwPle0iXAKlVdXEnyGVHEDCQjGqQDrUWkTjHb21eiPIZh1ExK0kXgvEVXeb+vxHmVjBqAGUhGNJgHZAPnFbH9S+DCyhPHMIwaSkm6CJyB9DsROQEYALxRGYIZ0ccMJKPSUdUM4H7geRE5T0QaikhdETlTRB4HHgAGisgTInIIgIh0FZEpItI8mrIbhlF9CEMXoarrgTnANOALVd0SRZGNSsQMJCMqqOpTwB3AX4FU3JD+W4EPVHUtLngyEVgqIhnAu8ACIDMqAhuGUS0pThcFZZsMJGDB2TUKG+ZvGIZhGIbhwzxIhmEYhmEYPsxAMgzDMAzD8GEGkmEYhmEYhg8zkAzDMAzDMHwUNzlWTNK6dWtNTEyMthiGYZSBhQsXpqlqm2jLURZMFxlG1ac4XVTlDKTExEQWLFgQbTEMwygDIrI+2jKUFdNFhlH1KU4XWRebYRiGYRiGDzOQDMMwDMMwfJiBZBiGYRiG4aPKxSCFIjc3l5SUFLKzs6MtSpUnLi6OTp06Ubdu3WiLYhhVDtNF5YfpIiPaVAsDKSUlhSZNmpCYmIiIRFucKouqkp6eTkpKCoceemi0xTEqkqlTYdw4SE6G+HgYPx5GjYq2VFUe00Xlg+miGkQM66Jq0cWWnZ1Nq1atTCGVERGhVatW9vZb3Zk6FcaMgfXrQdV9jxnj0o0yYbqofDBdVEOIcV1ULQwkwBRSOWHHsQYwbhxkZRVOy8py6UaZsXuofLDjWAOIcV1UbQwkwzDCJDk5snTDMIyKIMZ1kRlIlcxZZ53Fzp07i81z//338+WXX5aq/tmzZzNixIhSlTVqCPHxkaUb1RLTRUbUiXFdVC2CtKsCqoqqMmPGjBLzPvTQQ5UgkVFjGT/e9fMHu7YbNnTpRrXHdJERM8S4LqpUD5KI1BaRRSIy3ft/qIh8LyKrReQtEalXKYJMnQqJiVCrlvsup4Cwp556ip49e9KzZ0+eeeYZkpKS6N69OzfffDN9+/Zlw4YNJCYmkpaWBsDDDz9Mt27dOO2007j88st58sknARg9ejT//e9/AbecwQMPPEDfvn05+uijWbFiBQA//PADAwcO5JhjjmHgwIGsXLmyXPbBqAGMGgUTJ0JCAoi474kTY2bkSI3CdJFRk4lxXVTZXWx/ApYH/f8H8LSqHg7sAK6rcAkqKGp+4cKFvPrqq3z//ffMnz+fl156iR07drBy5UquuuoqFi1aREJCwv78CxYs4N1332XRokW89957xa7p1Lp1a3766Sduuumm/YqrW7dufPvttyxatIiHHnqIe++9t0zyGzWMUaMgKQkKCtx3jCikGoXpIsOIaV1UaV1sItIJGA6MB+4QN0ThFGCkl2Uy8CDwYoUKUlzUfBlOzJw5czj//PNp1KgRABdccAHfffcdCQkJDBgwIGT+c889lwYNGgBw9tlnF1n3BRdcAMCxxx7Le++9B0BGRgZXX301q1evRkTIzc0tteyGYUQB00WGEdNUpgfpGeAuoMD73wrYqap53v8UoGOFS1FBUfOqGjI9oKTCzR+K+vXrA1C7dm3y8tzhuu+++xg6dChLlizh448/tvlCDKOqYbrIMGKaSjGQRGQEsE1VFwYnh8ga8k4VkTEiskBEFqSmppZNmAqKmj/ppJP44IMPyMrKYs+ePbz//vsMHjy4yPwnnnjifmWye/duPvnkk4jay8jIoGNHZ09OmjSpLKIbhhENTBcZRkxTWR6kQcA5IpIEvInrWnsGaC4igW6+TsCmUIVVdaKq9lPVfm3atCmbJOPHuyj5YMohar5v376MHj2a4447juOPP57rr7+eFi1aFJm/f//+nHPOOfTu3ZsLLriAfv360axZs7Dbu+uuu7jnnnsYNGgQ+fn5ZZLdMIwoYLrIMGKbwJDPyvoAQ4Dp3u93gMu83xOAm0sqf+yxx6qfZcuWHZRWLFOmqCYkqIq47ylTIitfTmRmZqqq6p49e/TYY4/VhQsXRkUOPxEfT8OIEGCBVrLuKe+P6aKKx3SRUdEUp4uiPVHkWFzA9hpcTNLLldJqjETNjxkzhj59+tC3b18uvPBC+vbtGxU5DMOIEqaLDKNMVNBMGUAUJopU1dnAbO/3b8BxlS1DrPDGG29EWwTDMAzTRUbJTJ3qRlgmJ7s4ufHjoz4kPzBTRmAwaGCmDCgf0WwmbcMwDMMwiqaiLZEiyC9QMvbmsjNrH7s+mM6ulyexe+dudrfvzO7zLuChz/tQ79h86tfLJ2tle3JSWpbHTBn7MQPJMIyIicGXScMwKooI5+wqST+oKtv37CN5exYbd+5l0869bMnIYWtmNqmZOaTvziF9zz4y9uZyYBaKJjDkDwcq2Qz0WkXTAkFza5Ob1oSclJZA+a11awaSYRhFE0LTTWVUNF4mDcOIFhHM2eV3NiVvzuWWhzKYm7aLRh0yWbU1k9/S9pCZnVeoXMN6tTmkaRytm9Sn2yFNadW4Hs0b1qNFw7o0GzeWZilJNM3eQ+N9WTTOyaLxvr0cU7CE5H2d8c8aVF5r3ZqBZBhGaII0nQKbt+9hzcPPMa5tP+oPyKdR8z3sWdaRrBUdytWtbRhGjBEf796EQqX7GPdgLtopjZYJadTvvIO6rTMRgRmboXVmfY48pDHn9elIYutGJLRsSMcWDejYogFN4+oW3f63/yXIlbSf8dzDmIZTK2ytWzOQYpTGjRuze/duNm3axB//+Mf9C0aG4plnnmHMmDE09M+pUgyzZ8/mySefZPr06eUhrlGNyC9QVm/LZPHLn7B00FUsa3sYK9sksrt+4PpaQ+N9tcnb2RCpc2Dem/Jya5c3IvIKEJistmeI7UOAD4F1XtJ7qmrL2HuYLjIYP76wWwgKWSJbd2Xz2ZItzPh1M3r+dtrWgoKc2uRsbEnWykPI2dSc3G3NSNpdv3TtF2GgjUqYC+MrrrvfDKRKJD8/n9q1a0dUpkOHDsUqJHBK6YorrohIKRlGgH15BSzesJP5v6Xz/bp0FifvZM++fDhuFI1zsuix7TcuXPIVXdOS6ZqewuXb32XDnq5UlFu7ApgEPAe8Vkye71R1ROWIE31MFxkREbA4giyR3EfG83Wf3/Hmqz/wzapUChQOb9sYWd6VLYvakLO5ORQcmEkoaH3kyCnGQBs1quI81zXSQKqIANOkpCSGDRvG8ccfz6JFizjiiCN47bXX6NGjB9deey0zZ87k1ltvpX///txyyy2kpqbSsGFDXnrpJbp168a6desYOXIkeXl5DBs2rFC9I0aMYMmSJeTn5zN27Fg+//xzRIQbbrgBVWXTpk0MHTqU1q1bM2vWLGbOnMkDDzxATk4OXbp04dVXX6Vx48Z89tln3HbbbbRu3drmOanhbMnI5svlW5m9MpV5a9OcQQR0O6QJF/TtRN+E5vS58nwSli6klm8FoPGtnmWM/qvC3Nrljap+KyKJ0ZYjFKaLTBdVGTxLJGtfHm/9uIH/fLeOjUsW0q5pfW4e0pXzjulA17ZNmNoOxnzNgVVXKQf9EMJAq5SRIUXNIBmrn7LOXjtlimrDhqquQ9N9GjYs+wS269atU0DnzJmjqqrXXHONPvHEE5qQkKD/+Mc/9uc75ZRTdNWqVaqqOn/+fB06dKiqqp599tk6efJkVVV97rnntFGjRvvrPeqoo1RV9YUXXtALLrhAc3NzVVU1PT1dVVUTEhI0NTVVVVVTU1N18ODBunv3blVVfeyxx/Rvf/ub7t27Vzt16qSrVq3SgoICvfjii3X48OEh98Vmr62epOzI0gmz1+i5z83RhLHTNWHsdB302Fd6z3u/6Ke/btLtu3MKFyjmZinrBNBU8kzaQCKwpIhtQ4B04GfgU+CocOo0XWS6qCaxd1+eTpi9Rvv87XNNGDtdL57wP/18yWbNzcs/KG+MTBAfFsXpoqgbPJF+yqqUEhIKK6TAJyEh7CpCsm7dOu3cufP+/1999ZWee+65mpCQoElJSarqpvOPi4vT3r177/9069ZNVVVbtmyp+/btU1XVjIyMkErpggsu0JkzZ4bYpwNK6eOPP9ZWrVrtr7979+567bXX6qJFi3Tw4MH7y3z44YemlKoZoZTSrr37dNr36/WiF+fuN4rOfvY7fe7r1bpyyy4tKCiIvNJyIMYMpKZAY+/3WcDqYuoZAywAFsTHxx+0X6aLTBdVN/LzC/SdBRv0hL9/qQljp+tVL3+vC5LSoy1WuVGcLqpxXWwRjFaMGBEJ+b9Ro0YAFBQU0Lx5cxYvXhxWeT+qGlae0047jWnTphVKX7x4cYlljapL4aG1yuZ9Gfz5rfU8uGQzuZrP4W0bc+cZR3J2rw7Et4ogPqQiO/hjBFXdFfR7hoi8ICKtVTUtRN6JwESAfv36HTysJgJMFxmxzvLNu/jrB0tYuH4HvTs148lLejOwS+toi1VpRHsttkqnqEDS8ggwTU5OZt68eQBMmzaNE088sdD2pk2bcuihh/LOO+8AToH8/PPPAAwaNIg333wTgKlFLCZz+umnM2HCBPLy3PwR27dvB6BJkyZkZmYCMGDAAObOncuaNWsAyMrKYtWqVftjC9auXbtfPqP6MG4cZOXk06hnCodcNZf2V82lXpct5K7uyAe3DGLm7Sdxy9CukRlHNQQROUS8J7aIHIfTi+kV3a7pItNFsUp2bj6PfrqcEc/OYV3aHp64qBfv3zyoRhlHUAMNpPHjXcBYMOUVYNq9e3cmT55Mr1692L59OzfddNNBeaZOncrLL79M7969Oeqoo/jwww8B+Oc//8nzzz9P//79ycjICFn/9ddfT3x8PL169aJ37977108aM2YMZ555JkOHDqVNmzZMmjSJyy+/nF69ejFgwABWrFhBXFwcEydOZPjw4Zx44okklGlIgRFL7Mzax84Oq+l44yxaD/8ZqZNP+uc9SXnhdyS/dzR9Ojev0W/sIjINmAccKSIpInKdiNwoIjd6WS4ClojIz8C/gMs813uFYrrIdFEs8lPyDob/6zv+/c1vXNS3E1/dcTIX9+tMrVo1UIcU1fcWq5+yxiCpVkxYRXD/fFXH+v2rBlsy9uoj05dqj/s+1YSx07Xtxd9rXOI2hYJyi2epKKjkGKSK+JguqnhMF1Ue+/Ly9YnPVuihd0/XE/7+pX67alv5NhCjkdvF6aIaF4MENSKswqjGpOzIYsI3a3n7xxTyVTm7V3s67+nC/c82JbuKDL03HKaLjFjgt9Td3PbWYn5JyeDiYztx/9k9aFLczNaREqXFbstKjTSQKoLExESWLFkSbTGMasyG7Vk8P2sN/12YgghcdGxnbjq5y/64okPiQkwTwlRItFVlaxKmi4xwUVXeXrCBBz9aRv26tZhwRV+G9Wxf/g1FuNhtrFBtDCQNY1SFUTJa8aEXVYMYWq4+Od0ZRu/+lEItES4/Lp6bhnShQ/MGhfId5I2oom9tVR3TReWD6aKKJSMrl3ve/4UZv25hUNdW/N/FfTikWVzFNFaRQzYrkGphIMXFxZGenk6rVq1MMZUBVSU9PZ24uAq6SaoKMWJYrEvbw/Oz1vD+oo3UriWMOj6eG4d0oX2zBiUXhir71laVMV1UPpguKn8KvfMdm06zYYvZk5/D3Wd2Y8zgwyo2CDuCxW5jiWphIHXq1ImUlBRSU1OjLUqVJy4ujk6dOkVbjOgSZcNi6aYMXpy9lhm/bqZu7VpcdUICN57chXZNI3xYVNG3tqqM6aLyw3RR+bH/nS+7gOYnrkZPWEN6akP+cOxAbjy5ecULUMJit7FKtTCQ6taty6GHHhptMYzqQhQMC1Xl29VpvDxnHd+uSqVx/TrccNJhXHfiobRtUsq36Cr61laVMV1kxCLjxsG+uN0cctFi6rfPYPcvndj+5VG8+Fkdxt5QCQJEay21MlItDCTDKFcq0bDI2JvLB4s2MmX+elZv202bJvX5y+lHcOUJiTRrUMZRJFX0rc0wjPKjoEDZ0SaJ9heuQHNrk/p+X7JWuUDsSnUmV8Ehm5UyUaSIxInIDyLys4gsFZG/eemHisj3IrJaRN4SkXqVIY9hFEs5zuA3dSokJkKtWu576lTIyy/g21Wp3PHWYo7/+5c88NFS4urW5qlLejNn7FBuPeXwshtH4JTRxImQkAAi7nvixCqnpAyjRhNKiYSZb23qbi6dOI8Wv1tG9vrWbHrlpP3GEZgzuSQqy4OUA5yiqrtFpC4wR0Q+Be4AnlbVN0VkAnAd8GIlyWQYoYnEHVzMaLdCsd6189laK507pm7j0eVb2J2XQ5P6dTj/mE6MPC6eozs1q7h9MYPIMKom4Q4Y8eXbt2EjL/17Bv9c0oy4+nW5sFNvJjzbkYKsA4HY5kwuGansoZQi0hCYA9wEfAIcoqp5InIC8KCqnlFc+X79+umCBQsqQVLDKAG/8gKndSZOJP/ykXTpm8n2umnEJaQT1zmdWvXzKdhXm1pb2zDhng4MObItcXVrR0/+KCIiC1W1X7TlKAumi4wKJzExdHd/QgIkJYXMN6/z0dx3+k2saR3PsA2LeOjFv9C2aVwszVwSUxSniyrNQBKR2sBCoCvwPPAEMF9Vu3rbOwOfqmrPEGXHAGMA4uPjj10f6oIxjMomSCmlNmzOL+0P55dDDuenLn1YnNiLzBy3kGfu9kZkr29F1pp2ZK9vhRTUpqAginLHAGYgGUYY1KrlVg3yI0IhJVKrFilNWvPYkGuY3v0kOu3cwkNfTOCUdQup8cqmBIrTRZUWpK2q+UAfEWkOvA90D5WtiLITgYnglFKFCWkYJaCqbNi+l2WbM1gaP5il/a5mSbsubGvSCoBaBfkckZbMOX06MPWfLUj5qRX5mYXnLYq3tTkNwwiHMAaM7MrO5d/Db+GlI0+hlhbwx7lvcNP8d2mQl+M8TUapqfRRbKq6U0RmAwOA5iJSR1XzgE7ApsqWxzCKQlVJ2bGXxRt28vOGnSzZlMHSTbvIzHaeodoDLqZLegqD1v/MUdt+o9fm1Ry1dS2NOrSDV26lR5bXAxdUZ8T9/uYXN4yaSzEjUbNz85kyfz3Pz1rDjqOGce7K7xj71ct0yEwrlM8oPREZSCLyOPAIsBf4DOgN3KaqU0oo1wbI9YyjBsCpwD+AWcBFwJvA1cCHEe+BYZSCUHbHyJHKss27mLc2nR+TtrMgaQfpe/YBUL9OLbq3b8q5fTrQo30zjurQlCNnf0LcjXcWOYy+zFN/xMiM3rFCafWPYVRZQiiR7IfH8/Zhg3jhidls2ZXN4MNbM3ZYN3rO3gmLGsHudHuZKiciikESkcWq2kdEzgfOA24HZqlq7xLK9QImA7VxUwu8raoPichhOOOoJbAIuEJVc4qry/r9jbISbHdInXziDttG08M30vqwZHY3rA9A55YN6J/Ykr7xLejTuTlHHtKEurVDzIpRkR6ecAM0qyCliUEqrf6pKEwXGZXJ3n35vPljMv/+5je27Mqmf2ILbj/1CAZ2bR1t0ao05RmDFJic5SxgmqpuD2e9IVX9BTgmRPpvwHERymAYZWLcOKWgTTqte22gQdet1KqXT35WXXYnteXJjX9n0B+uoP3o4eFVVpHD6G2pED+l0j+GUSUo4mUrIyuX1+cn8crcJLbv2cdxiS35v0t6M7CLrfdX0URqIH0sIitwLu6bva6z7PIXyzDKn+zcfN78IZncM5Jo1yKL/L112bO0I1kr25Od3BJRuIhP4cFlMHpktMW1pUIOxvSPUT0J0Z2+6Y57eHlTHNMyG5G1L58hR7bhlqFd6Z/YMrqy1iAiMpBU9W4R+QewS1XzRSQLOLdiRDOM8mFfXgHTfkjmhdlr2Lorh7r5zUn7+HD2rGwP+QfmIYonyf2IFQ+NLRVSCNM/RnVk6lQYd/XJJOdnEk8yt7R9go3HNWB6t8FoqnDOsYdww+DD6NGhabRFrXFEGqTdELgFiMfNS9QBOBKYXv6iGUbZ+Sl5B/e8+ysrt2ZyXGJLnr60D7/Na8XvpwnkH8jXkD2M5173J1Y8NFV0gceKwvSPUd3Y7zjK70jcYans7b+F5xPPol5OLlf/NJ1rF3xEx4yt0RazxhJpF9uruMkeB3r/U4B3MAVlxBg5efk8OmMFk+clcUjTOF66qh+ndm+LiDCwi5tnbdyfdpOc3pB4khnPvYxiWux5aGypkGBM/xjVinH3FSCHbaL9cWup12Y3eZn12TG7Gy0Ww30559s8RlEmUgOpi6peKiKXA6jqXrEoMSPG2LYrmxunLOSn5J1cfUICdw7rRuP6hS91Z3c09gVGJtRoD00VwPSPUS3Yk5PHtB+SyTtzHa2bZLNvWxPSpvdmz/IOUFCLTApi72WtBhKpgbTPm8dIAUSkC24hWsOICX7esJMbXltAZnYeL4zqy1lHty++gHloqhKmf4wqTcbeXCbNTeLV/61jZ1YudbJasvXTo8le1wY4YOvH194EEyeabooykRpID+AmaOssIlOBQcDo8hbKMErD4g07ufI/39OsYV3eu3kg3dtbUGM1w/SPUSXZlZ3LK3PW8fKcdWRm53Fq97bcPLQry79rwZi3C+dt2BDGT+xkxlEMEOkoti9E5CfcMiEC/ElV0ypEMsOIgF9TMrjyxTm02JXGW0/fSfsXG1l3WTXD9I9R1cjJy+f1eet59us1ZOzN5fQe7fjTqYdzVIdmAPS1cRgxTaSj2E7yfmZ63z1EBFX9tnzFMozwWb01kyte/JamO9N4Y+pY2memQWZajV6Wozpi+seoKqgqM37dwqOfLidlx15OOqINd51xJD07Njsor/Xyxy6RdrHdGfQ7DjcL9kLglHKTyDAiYFd2Lr9/fSF1d+/mzTfuodOu1AMbs7Lcq5lpn+pCqfSPiLwCjAC2qWrPENsF+Cduhu4sYLSq/lReQhs1i6S0Pdz34RK+W51G9/ZNef26oxl8eJtoi2WUgki72M4O/i8inYHHy1UiwwiTggLljrd+Jnl7Fm+8P57OoeYLiZVJH40yUwb9Mwl4DnitiO1nAod7n+OBF71vwwibggLlP3N+48mZq6hXuxYPnt2DK09IpHYtG2hZVYnUg+QnBTjojcwwKoPnZ63hy+VbeeDsHhz3xu7QmWJl0kejIghL/6jqtyKSWEyWc4HX1K3cPV9EmotIe1XdXD5iGtWdTTv38ue3f2beb+mc3qMdD5/Xk3ZN46ItllFGIo1BehZviC1QC+gD/FzeQhlGSSzesJOnv1zFuX06MHpgoi3LUQOoQP3TEdgQ9D/FSzMDySiRuWvSuHnqT+TmF/D4hb24uF8nW0S2mhCpB2lB0O883Irac8tRHsMokZy8fO7678+0bRLHw+f1dMrIluWoCVSU/gn1NNMQaYjIGNwyJ8Sbd7LG89q8JP728TK6tGnExCv7kdi6UbRFMsqRSGOQJleUIIYRLs/PWsuqrbt5ZXQ/msbVPbDBhoNUaypQ/6QAnYP+dwI2FSHDRGAiQL9+/UIaUUb1R1V5ePpyXpm7jt91a8szl/WhSbAuMqoFYRlIIvIrod+oBFBV7VWuUhlGESzbtIsXZq3h/GM6ckq3dtEWx6gEKkH/fATcKiJv4oKzMyz+yCgKVeWBj5by2rz1XDMokb8O72GB2NWUcD1IIypUCsMIA1Xlvg+X0KxBXe4f0SPa4hiVR5n0j4hMA4YArUUkBTcjd10AVZ0AzMAN8V+DG+Z/TVnaM6ovqsr9Hy7l9fnr+f1Jh3H3md0s3qgaE5aBpKrrK1oQwyiJT37dzML1O/jHhUfTolG9aItjVBJl1T+qenkJ2xW4pSxtGDWDJ2eudMbRyYdx9zAzjqo7tSLJLCIDRORHEdktIvtEJF9EdlWUcIYRIDs3n8c+XUH39k256NjOJRcwqh2mf4xo8sGijTw/ay2X9e9sxlENISIDCTfZ2uXAaqABcD3wbEmFRKSziMwSkeUislRE/uSltxSRL0RktffdItIdMGoGr85NImXHXv46vLv199dcSqV/DKOs/JS8g7ve/YXjD23JQ+f2NOOohhCpgYSqrgFqq2q+qr4KDA2jWB7wZ1Xtjlto8hYR6QHcDXylqocDX3n/DaMQabtzeH7WGk7t3pZBXVtHWxwjipRS/xhGqUnbncPvX19I+2ZxTLjiWOrVifixaVRRIp0HKUtE6gGLReRx3ERqJU784I0I2ez9zhSR5biJ2M7FBU8CTAZmA2MjlMmo5rwway1Z+/K4+8zu0RbFiC6l0j+GUVpUlbvf/YWMvbm8ft1xFvtYw4jUFL7SK3MrsAc3d8iFkVTgTfl/DPA90C4wnNb7bhuhPEY1Z0tGNlO+X88FfTvRtW3jaItjRJcy6x/DCIepUyExEZoes4Evl2/j1Dbd6HZI02iLZVQykRpIfXGDPnap6t9U9Q7P5R0WItIYeBe4TVXDDq4UkTEiskBEFqSmppZcwKg2PD9rDQUFyp9+d3i0RTGiT5n0j2GEw9SpbtWijRl7aHHKMvYmtWLyvYlMnRphJYmJUKuW+46osBErRGognQOsEpHXRWS4iITd+ifv/wAAIABJREFURScidXHG0VRVfc9L3ioi7b3t7YFtocqq6kRV7aeq/dq0aROhyEZVZePOvbz5YzIX9+tM55YNoy2OEX1KrX8MI1zGjYOsLKXVWb+gBUL6jN5kZQnjxoVZQcDCWr8eVN33mDFmJFVBIjKQVPUaoCvwDjASWCsi/ympnLiQ/5eB5ar6VNCmj4Crvd9XAx9GIo9RvXnu69UIwh9O6RptUYwYoLT6xzAiITkZGh21kbjO29k5qzv5mQ32p4eFs7AKp2VlEb6FZcQKEb+BqWquiHyKm/q/AS7Q+voSig3CxQ/8KiKLvbR7gceAt0XkOiAZuDhSeYzqyYbtWbyzIIWRx8fToXmDaItjxAil1D+GETbxXXLJH7qcnI3N2f3LgTnXwl6buChLKmwLy4gVIjKQRGQYcBluaO1s4D/AJSWVU9U5hF4xG+B3kchg1AxemL2WWiLcNKRLtEUxYoTS6h/DiIQBY1YyL3Uf2985jsBjq2FDGD8+zAri4123Wqh0o0oRaQzSaOAD4AhVvVpVZ6hqXvmLZdRkNu7cy38XbuCS/p1o38y8R8Z+RmP6x6hAlm7K4Ift6xnQOoH2cc0QgYQEmDgRRo0Ks5Lx451FFUxEFpYRK0TkQVLVyypKEMOYOtV102cesZYmvaH9Dos9Mg5g+seoSFSVv89YTrMGdZl465E0u6uUFQUsqXHjXLdafLwzjsK2sIxYwUaBGDFBYOBHTq1sOvbaQOavnbjrhQY0r2d6xTCMiufb1WnMXZPO/SN60Kxh3bJVNmqUKa5qgM2ZbsQEgYEfTY9fC7WUXfO72sAPwzAqhfwC5dEZy4lv2ZArBiREWxwjRgjLQBKRNt7aaf70o0TEJiYyykxyMtRunE2TPsnsWdKRvIyG+9ONmo2I/EVEOpec0zBKx/uLNrJiSyZ3nnGkrbVm7CfcK+FZIJQh1An4Z/mJY9RU4uOh6YA1IErG/w4vlG7UeDoC/xORb0XkJhGxFYuNciM7N5//m7mS3p2aMfzo9tEWx4ghwjWQjlbVb/yJqvo50Kt8RTJqInc9uJcmfTawe0mn/d4jG/hhAKjq7UA8cB9O3/wiIp+KyFUi0iS60hlVnSnz17M5I5uxw7pRq1ZRs9EYNZFwDaTiItbKGM1mGLC5+Vpq11aaJHct3dBao1qjjm9U9SbcIrXPALcDW6MrmVGVyczO5flZazixa2sGdjXHpFGYcEexrRaRs1R1RnCiiJwJ/Fb+Yhk1iU079/LWjxu49LjOPPqYrblmFI2IHI2bLPJSIB03I79hlIqX56xjR1Yud55xZLRFMWKQcA2k24HpInIJsNBL6wecAIyoCMGMmsNTX6wC4JahNmu2cTAicjhwOc4wygfeBE5XVXs5M0rN9j37+M936zjjqHb07tw82uIYMUhYBpKqrvLe3EYCPb3kb4Dfq2p2RQlnVH+Wb97Fuz+lcMPgw+jUwrxHRkg+B6YBl6rqr9EWxqgevDh7DXv25fGX0817ZIQmLANJRLoC7VT1VV/6YBHZpKprK0Q6o9rz2KcraBpXl1uG2KzZRpGcgdM/hYwjERkMmP4xImbjzr1MnreeC47pxOHtLM7fCE24QdrPAJkh0vd62wwjYuasTuObVancOrRr2WeuNaozTwO7QqSb/jFKxVMzXbf+HacfEWVJjFgmXAMpUVV/8Seq6gIgsVwlMmoE+QXKo58up2PzBlx5gs1caxSL6R+j3FixZRfvLUph9MBEOja3xbCNognXQIorZptdYUbEvDYviaWbdnH3md2Iq1s72uIYsY3pH6PcePyzlTSpX4ebh9igEKN4wjWQfhSRG/yJInIdB0a1GUZYbNq5lyc/X8nJR7RhRC+budYokTLrHxEZJiIrRWSNiNwdYvtoEUkVkcXe5/pykNuIMeatTefrFdu4eWhXmjesF21xjBgn3GH+twHvi8goCg/zrwecXxGCGdWXBz5aSr4qj5zXExGbudYokTLpHxGpDTwPnAak4Ayuj1R1mS/rW6p6a/mJbcQSefkF/O3jpXRs3oDRAxOjLY5RBQh3mP9WYKCIDOXAMP9PVPXrCpPMqJZ8tmQLXyzbyj1ndqNzSxvWb5RMOeif44A1gXmTRORN4FzAbyAZ1Zgp89ezYksmE6441rr1jbAI14MEgKrOgv9n777DoyqzB45/T3onpNFCCh2kiYgIsoJlZe3LT2zg2ll3Lavb1MW1Lru667rWXRddy2psWFZUbCgWxEJVeg8QWkIgvWfO7487wRCTMCGZzExyPs8zz8zcuTNzbmbm5Nz3vvd9WeClWEwHt6ugnFtf/44hPeK44oRMX4djAkwr8k8vYEe9+znAcY2s938i8iNgA3CTqu5ouIKIzABmAKTZTMoBY19JJX//cAMT+idx2lHdfB2OCRCe9kEyplWqa11c98IyqmpcPHrx0YQG21fPtJvGjuNqg/tv4ZwtNxyYDzzb2Aup6mxVHa2qo5OTk9s4TOMtf31vHRXVtdx59lF2WN94rN3+S4nIUyKSKyKr6i1LEJEPRWSj+7pre8Vj2tff3l/Psu0F/OX/htMnOcbX4ZjOJQdngts6qcCu+iuoar6qVrrvPgEc006xGS/7YtM+XlmSwxXjM+lruce0QHvuxj8DTG6w7BbgI1XtD3zkvm86mDdX7GT2Z1uYPjaNs0f09HU4pvNZDPQXkUwRCcOZ021u/RVEpP7plGcDa9sxPuMlheXV/HbOt/RJjubGU2xQSNMy7VYgqepnwP4Gi8/h+6bsZ4Fz2yse0z4+XreX37zyLWMyE7jtjCG+Dsd0QqpaA1yHM6fbWuAVVV0tIneLyNnu1W4QkdUi8i1wA3CZb6I1bemut1aTW1zJP84fSWSYdcw2LePrjiDdVHU3gPs6xcfxmDb09ZZ8fvH8Mgb3iOM/l462M0eMz6jqPFUdoKp9VXWWe9ntqjrXfftWVT1KVUeo6iRVXefbiM1BWVmQkQFBQc51VpZHT3tv1W5eX7aT6yb1Y0TveK+GaDomXxdIHhGRGSKyRESW5OXl+TqczuUIk9P8NXu5/JnFpHaN5NkrxhAbYXOtGWNaKCsLZsyAbdtA1bmeMeOweWjD3mJ+O+c7hqd24bqTbCJsc2R8XSDtrTv2777ObWwlO3PER5pLTk0UTqrKk59v4ernltAvJYYXrx5LQrSNWGuMOQIzZ0JZ2aHLysqc5U3YX1rFlc8uJjIsmMenH2NnzJoj1qJxkLxgLnApcK/7+k3fhmMO0VRy+tWvoLz8+8fchdOBGuGOsMHM/XYXpw/rzt+n2nF/Y0wrbN/eouVVNS6ueW4puUWVvPzz4+lpk9GaVmi3AklEXgQmAkkikgPcgVMYveKeU2k7MLW94jEeaCo55ecfcleB91NHcNsyoSB6N78+dQDXTepHUJCNN2KMaYW0NGcHrLHlDVRU13Jt1jK+yd7PwxcdzUjrd2Raqd0KJFW9qImHTm6vGEwLNZWc6lncawh/nzCdr9KHM3TPJv578xkM6RnXTgEaYzq0WbOcw/r1W7Kjopzl9ZRV1TDjv0tZuGkf95w71IYTMW3CDs6aps2aRVboZWSwlSBqyWArWaGXUZOUzAf9jmP6Bfcwdfpf2ZyYyp0fPs4bnz5kxZExpu1MmwazZ0N6Oog417NnO8vd8oor+dl/vmHR5n3cP3UEl4xN92HApiPxdR8k48eymMYMuYAyQgBld7eu3DTkd9w3eipFQUr34n3cuuApfrbsHaev0ezZvg7ZGNPRTJt2SEFU3zdb93PdC8soLK/m4YuO5szh1nJk2o4VSKZJM++oRtP20zUjj8i+uYTGl6MuoWhPEv8em83Jf7uLkG3ZzqG4WbOaTGLGGNNaWVnOeSPbt0NahotTrt/MgryN9O4ayTOXj7HWa9PmrEAygHN6fs6Bcr7NKWDptgMszt6PTikiJQhcVcFUbE+kcFF/yjd2QyvDOO2/Y+CX5/s6bGNMJ1A34khZGYSn7aP65FXM31vKsC49yLp+GHE2zprxAiuQOiGXS9m2v4y1u4tYvauQVTuLWLWzkPzSKgAiQoMYGVaJfN2LPVv7ULkrHmq/P10/3Q7xG2Pa0cyZUBNXQPJPNhLVL5fqA1HsnXMs1KYQd6uvozMdlRVIAeqQ5uZmjnAVlFWxbk8x6/cUs25P0cHbZVW1AIQECf27xTJpUAojesczMjWegQveJuyaGWSVncMMngC+L44aOYHEGGO8wuVSPtuYR/mx2fTom0dteSgHPh1I8ZJMtCaY7TaSiPEiK5ACUP3mZnCP03hNLbvLS+kzyimCnEKoiL1FlQefFx8VyqDusZw/ujdDesQxuEcc/bvF/HCOtD86A0RO40UAZvJntpNGWvAuZs1Ota5Gxhiv2l1Yzv+W7+LlxdvJzi8jsme4UxgtS0ervj+c1shwSMa0GSuQAtDMO6upTSwi9qhCwlKKCEspIjSxhEc3KWyCsJAg+iXHML5vEgO7xzKweyyDusfRLS4cEQ92ueoNEDmNFw8WSrgEprm8tFXGmM4st7iCD1bv5Z3vdvPV1nxU4diMrtx06gAKVvbgl08GoVXfr2+t2cbbrEDyc6rKxtwSvt66n+XbD7BiRwH8Xynd3Y/XFIdTlRtH+eYUqvPiWPFJLBmJ0YS0Zv6hFoxea4wxR0JVWbu7mAXrc/l4XS7Lth9AFfokRXPjyQM49+iepCdGOyuPhJAgz7oVGNNWrEDyQ/tKKvlkfR4L1uXy5ZZ89rs7TyfFhDGyd1e2fNSLveu6ULW3C66y8IPPS0+HfiltEICHo9caY0xL5BVXsmjzPj7fuI/PN+Yd7AIwtFccN548gJ8M607/lJhGW7qbGQ7JGK+wAslPFFdU8+7KPby2LIdvsvejCimx4UwcmMzYPomMzUykd0IkIkJWiFO/uLxVv9RlIdtdM8YcRnMnjBworeLrrfv5aks+izbvY8PeEsDpDzm+XxI/6p/EpIEppMRF+HALjGmcFUg+tiWvhP8s3Mpry3KoqHaRmRTNDSf159Qh3TiqZ1yTe1Lg5frFdteMMYfR8ISRnH0VXP/X/czduZ/CsP2s21MMOEOHHJuRwE+PTmVc30SG9upCsE1mbfycFUg+sim3mPvf38D7a/YQGhzET0f24sIxvRnZO96jjtQe1y+ejgdgjDEtoKrM/HM50iefxN77CU/dT2iCUyl9vTeYCUO6cubwHhzfN5FhveIJC7GpP01gsQKpneUWV/CPDzfw8uIdRIeFcN2kfvzs+AySY8MP/+SWanQ8gBnObSuSjDEttD2/jEWb9/HVlny+2rIfzqogCagtD6UyJ4HiFelU5iRQnRvHczVWEJnAZgVSO6l1Kc99mc3fP9hARU0tl47L4PqT+pMQHea9N50589CO1uDcnznTCiRjzGEVVVTzxcZ9fLohj4Wb9pFzoByApJhwjuuTwDtPJbDr20Sq98UA37d822j7piOwAqkdrMwp5NY3vmPVziIm9E/i7nOGkpkU7f03rjeekUfLjTGdXs6BMj5cs5cPVu9lcfZ+alxKbHgIx/dNZMaP+jCubyJ9k50zzcap0yhdXe/5dsKr6SisQGpDDbv73H53DTldN/DMoq0kxoTz6MVHc8awHp4N1tgWbDwjY4wHcosqePu73bz57S6+3VEAwIBuMVz9oz5MGpjC0WnxhDYytpqd8Go6MiuQ2sih3X2UvKhd3PH1OkJiK5g2No3fTx7U/jNO23hGxpgmVFTX8uGavby2LIfPNuThUhjSI46bJw9i8tDuHrdy2wmvpqOyAqmN1HX3Ce+1n/iJ64hIPUDlnjiCvzqaP92b4JugbPfOmE6pqZNXVZWVOwuZsySHN1fspKiihh5dIvjlxH6ce3RP+qXE+jp0Y/yGFUhtoNal5Ibk0e3izUT03k9taRj75g2ndGVq+x1Oa4rt3hnTqTR28uo1vy1lQe4utrp2sjmvlLCQICYf1Z2po1MZ1zepfcYksiFHTIDx+XmYIjJZRNaLyCYRucUrb5KVBRkZEBTkXGdltfolq2tdLN22n3veXsO4ez8i5bzFhHQpY//8Iez89yRKV/YGxLr7GOMHDpdnRCRcRF52P/61iGS0eRBeyEONmTkTyqtriEjfR/yJ6+hx5ackXvoJ8/duIDE6nFk/Hcrimafw8EVHM6F/cvsVRzNmONWa6vdDjnjpb2BMW/BpC5KIBAOPAacCOcBiEZmrqmva7E1aORZQRXUtecWV7CmqYEteCZvzSlm1s5Bl2w9QUe0iNFg4cUAKE7v05NFbulNW8n3Nad19jPE9D/PMlcABVe0nIhcC9wEXtFkQXhiTrKrGxf7SKvYUVbCnsJwt+0rZlFtC1aRieicXIUGgtULFjgT2f5tG+cZuvFIQ1UYb1EI25IgJQL4+xDYG2KSqWwBE5CXgHKDtCqQGP8w3B5/IFxkjqJ27jtrg5dS4lOpaF9W1SkV1LeXVtZRV1lJcUU1RRQ0llTWHvFxYSBADusVw4bFpjMlMYHzfJLpEOZ2vh8dbC7IxfsiTPHMOcKf79qvAoyIiqqptEkEjBUJW/x+x5K0NaPByXAoKuFyKS5Ual+JyKdUupbrGRXWti/J6+amwvJry6tofvE23uHDCNJaCL/tRuTOByp3xaJWTn3w6NpENOWICkK8LpF7Ajnr3c4DjGq4kIjOAGQBpLT1m1eAHuCEpjc8yRxHsqiV4ewEhwUJYcBAhwUJESDAx4SEkx4QTFxlKbEQIidFhpMRGkBIXTp+kGHp1jWyySdq6+xjjlzzJMwfXUdUaESkEEoF99Vc64lzUSCGwJTGVJfFpBO0oQIAgEUSc6+AgISRYCA4KIjw4iPDQIOKjQokIDSYyNJi4yFDiI0PpGh1G97gIuneJIC0xiriIUKexag5U+NPJqzbkiAlAvi6QGqs0frDHpqqzgdkAo0ePbtkeXYMf5u8+f47fff6cszuVnd2ilzLGBCRP8ox3c1EjBcIfP36SP27+sM3zkF+evGpDjpgA5OtO2jlA73r3U4FdbfoOs2Y5P8T67IdpTGfiSZ45uI6IhABdgP1tFkE756Fp05y6y+Vyrn3esj1tGsye7eyYijjXs2f7QWDGNM3XBdJioL+IZIpIGHAhMLdN38F+mMZ0dp7kmbnApe7b5wEft1n/I7A8BH5YtRnTPJ8eYnMf678OeB8IBp5S1dVt/kbWOciYTqupPCMidwNLVHUu8B/gORHZhNNydGGbB2J5yJiA4us+SKjqPGCer+MwxnRcjeUZVb293u0KYGp7x2WM8V++PsRmjDHGGON3rEAyxhhjjGnACiRjjDHGmAakLU/UaA8ikgc0MuKYR5JoMPBbB2DbFBg64jbBkW9Xuqomt3Uw7akVuci+C4HDtilwtHkuCrgCqTVEZImqjvZ1HG3JtikwdMRtgo67Xd7UUf9mHXG7bJsChze2yw6xGWOMMcY0YAWSMcYYY0wDna1Amu3rALzAtikwdMRtgo67Xd7UUf9mHXG7bJsCR5tvV6fqg2SMMcYY44nO1oJkjDHGGHNYnaJAEpHJIrJeRDaJyC2+judIiEhvEVkgImtFZLWI/Mq9PEFEPhSRje7rrr6OtaVEJFhElovI2+77mSLytXubXnZPMBpQRCReRF4VkXXuz+z4QP+sROQm93dvlYi8KCIRHeGzak+Wi/yb5aLA0F65qMMXSCISDDwG/AQYAlwkIkN8G9URqQF+o6qDgbHAte7tuAX4SFX7Ax+57weaXwFr692/D/iHe5sOAFf6JKrWeQh4T1UHASNwti9gPysR6QXcAIxW1aE4k75eSMf4rNqF5aKAYLnIz7VnLurwBRIwBtikqltUtQp4CTjHxzG1mKruVtVl7tvFOF/yXjjb8qx7tWeBc30T4ZERkVTgDOBJ930BTgJeda8SiNsUB/wIZ4Z4VLVKVQsI8M8KZ3LrSBEJAaKA3QT4Z9XOLBf5MctFAaVdclFnKJB6ATvq3c9xLwtYIpIBHA18DXRT1d3gJC4gxXeRHZEHgd8DLvf9RKBAVWvc9wPx8+oD5AFPu5vrnxSRaAL4s1LVncD9wHacZFQILCXwP6v2ZLnIv1kuCgDtmYs6Q4EkjSwL2FP3RCQGeA24UVWLfB1Pa4jImUCuqi6tv7iRVQPt8woBRgH/UtWjgVICqAm7Me4+CucAmUBPIBrnUFFDgfZZtaeO8N0+yHJRQLBc1AqdoUDKAXrXu58K7PJRLK0iIqE4CSlLVV93L94rIj3cj/cAcn0V3xEYD5wtItk4hxtOwtmLi3c3nUJgfl45QI6qfu2+/ypOkgrkz+oUYKuq5qlqNfA6MI7A/6zak+Ui/2W5KHC0Wy7qDAXSYqC/u4d7GE5nrrk+jqnF3MfD/wOsVdUH6j00F7jUfftS4M32ju1Iqeqtqpqqqhk4n8vHqjoNWACc514toLYJQFX3ADtEZKB70cnAGgL4s8Jpzh4rIlHu72LdNgX0Z9XOLBf5KctFAbVd7ZaLOsVAkSJyOs7eQDDwlKrO8nFILSYiJwCfAyv5/hj5H3CO/b8CpOF8caaq6n6fBNkKIjIR+K2qnikifXD24hKA5cB0Va30ZXwtJSIjcTp7hgFbgMtxdkgC9rMSkbuAC3DOYloOXIVznD+gP6v2ZLnI/1ku8n/tlYs6RYFkjDHGGNMSneEQmzHGGGNMi1iBZIwxxhjTgBVIxhhjjDENWIFkjDHGGNOAFUjGGGOMMQ1YgdRBiUitiKxwz3j8rYj8WkTa/fMWkQnuGFaIyGARudiL7/WMiJx3+DUbfe5I9ynYdffPlgCdbd0Yf2K5qMXPtVzkJ6xA6rjKVXWkqh4FnAqcDtzhgzimAfer6kigG9CipOSeAb09jMT5GwGgqnNV9d52em9jOjLLRS1juchPWIHUCahqLjADuE4cGSLyuYgsc1/GAYjIcyJycHZxEcly770cJSLfuPe8vhOR/g3fQ0T+JSJL3Htod7mXXQWcD9wuIlnAvcAE9+vcJCLBIvI3EVnsft2fu583UUQWiMgLOIPRNXyvEhH5uzv2j0QkuZF1bne/7ioRme0ecRUR+URE7nNvzwb3XmUYcDdwgTu2C0TkMhF51P2cZ0TkYRFZJCJb6vYMRSRIRP7p3ua3RWTeke41GtMZWC6yXBRQVNUuHfAClDSy7ADOnlMUEOFe1h9Y4r59IvA/9+0uwFacyQ4fAaa5l4cBkY28doL7Ohj4BBjuvv8McJ779kTg7XrPmQHc5r4dDizBmYBwIs6kiplNbJvWi+d24NFG3iuh3vrPAWe5b38C/N19+3Rgvvv2ZXWv0/C++3Xn4OxQDAE2uZefB8xzL+/u/vue5+vP3i528aeL5SLLRYF6sRakzqVudupQ4AkRWYnzYxsCoKqfAv1EJAW4CHhNVWuAL4E/iMjNQLqqljfy2ueLyDKcId6PqnvNw/gx8DMRWYEzTUEiTpIE+EZVtzbxPBfwsvv288AJjawzSUS+dm/jSe6Y6tRNrrkUyPAgTnCStUtV1+AkdtzvO8e9fA/OXEDGmMOzXOSwXOTHrEDqJMSZU6gWZ9bmm4C9wAhgNM6eWJ3ncI7VXw48DaCqLwBnA+XA+yJyUoPXzgR+C5ysqsOBd4AIT8ICrlenf8JIVc1U1Q/cj5W2YPMOmS9HRCKAf+LsQQ0DnmgQT938PLU4e6WeqD+njzS4NsZ4yHKR5aJAYQVSJ+A+Lv44TjOt4jRZ71ZVF3AJTlN0nWeAGwFUdbX7+X2ALar6MM4s0MMbvEUcThIpFJFuwE+aCKUYiK13/33gFyIS6n6fASIS7cEmBfH9rM0XAwsbPF6XgPaJSEy9dZvTMDZPLAT+z338vxtOc7wxpgmWiywXBRJPK1YTeCLdzcWhODMePwc84H7sn8BrIjIVpyn24B6Squ4VkbXA/+q91gXAdBGpBvbgdCKk3nO+FZHlwGqc2aK/aCKm74AaEfkWJ/k9hNOsvMzdcTEPONeDbSsFjhKRpUChO7768RSIyBM4nSqzgcUevOYC4Bb33+wvHqwP8BpwMrAK2IDTNF/o4XON6SwsF1kuCkjiFPHGOEQkCufHPEpV/fIHJiIlqhrj6zgARCRGVUtEJBH4Bhjv7gNgjGkFy0UtY7mo7VkLkjlIRE4BngIe8NeE5IfeFpF4nL4T91hCMqb1LBcdEctFbcxakIwxxhhjGrBO2sYYY4wxDViBZIwxxhjTgBVIxhhjjDENWIFkjDHGGNOAFUjGGGOMMQ1YgWSMMcYY04AVSMYYY4wxDViBZIwxxhjTgBVIxhhjjDENWIFkjDHGGNOAFUjGGGOMMQ1YgWR8RkQuFpElIlIiIrtF5F0ROUFE7hSR5xtZX0Wkny9iNcZ0DCKSLSLl7rxTd3nUg+fFisgD7ueXish2EXlVRMa0R9ym/YX4OgDTOYnIr4FbgGuA94EqYDJwDlDqw9CMMR3fWao639OVRSQc+BgoAM4E1gIRwE+A04FvvBGk8S1rQTLtTkS6AHcD16rq66paqqrVqvqWqv7O1/EZYzofEfmXiLxa7/59IvKRiAhwCZAKnKuqq1S11p23XlXVO30Vs/Eua0EyvnA8zt7XG74OxBhj3H4DrBCRy4DNwJXASFVVETkFeF9VrXW7E7EWJOMLicA+Va1pZp3zRaSg/qW9gjPGdHj/a5BfrlbVMmA68ADwPHC9qua4108C9tQ9WURGup9XJCLr2z980x6sQDK+kA8kiUhzLZivqGp8/Ut7BWeM6fDObZBfngBQ1W+ALYAAr9RbPx/oUXdHVVe4c9IUILwd4zbtyAok4wtfAhXAub4OxBhj6ojItTgFzy7g9/Ue+gj4sYhE+yQw4xNWIJl2p6qFwO3AYyJyrohEiUioiPxERP7q6/iMMZ2PiAwA/oRzmO0S4PciMtL98H+B3cAbIjJURIJFJAIY7ZtoTXuwTtrGJ1T1ARHZC9wGZAHFwFJgFvBjX8ZmjOnw3hKR2nroJHArAAAgAElEQVT3PwR6Afep6rcAIvIH4DkRGa2qFSIyCbgLeAenT9I+YAlwfvuGbtqLqKqvYzDGGGOM8St2iM0YY4wxpgErkIwxxhhjGrACyRhjjDGmASuQjDHGGGMaCLiz2JKSkjQjI8PXYRhjWmHp0qX7VDXZ13G0huUiYwJfc7ko4AqkjIwMlixZ4uswjDGtICLbfB1Da1kuMibwNZeL7BCbMcYYY0wDViAZY4wxxjRgBZIxpsMTkckisl5ENonILY08fo2IrBSRFSKyUESG+CJOY4z/CLg+SI2prq4mJyeHiooKX4cS8CIiIkhNTSU0NNTXoRjTJkQkGHgMOBXIARaLyFxVXVNvtRdU9XH3+mcDDwCTW/pelovajuUi42teLZBEZDLwEBAMPKmq9zZ4PA14Foh3r3OLqs5r6fvk5OQQGxtLRkYGItIGkXdOqkp+fj45OTlkZmb6OhzTFrKyYOZM2L4d0tJg1iyYNs3XUbW3McAmVd0CICIvAecABwskVS2qt340cERzMFkuahudMhfZb9XveO0QW729tp8AQ4CLGmm2vg14RVWPBi4E/nkk71VRUUFiYqIlpFYSERITE23vt6PIyoIZM2DbNlB1rmfMcJZ3Lr2AHfXu57iXHUJErhWRzcBfgRsaeyERmSEiS0RkSV5e3g8et1zUNjpdLrLfql/yZh+kg3ttqloF1O211adAnPt2F2DXkb6ZJaS2YX/HDmTmTCgrO3RZWZmzvHNp7Ev9gxYiVX1MVfsCN+PsvP3wSaqzVXW0qo5OTm58GCf7DbWNTvV3tN+qX/JmgeTJXtudwHQRyQHmAdd7MR5j2l5WFmRkQFCQc+1Pe3zbt7dseceVA/Sudz+V5nfGXgLO9WpExtRnv1W/5M0CyZO9touAZ1Q1FTgdeE5EfhDT4Zq1A8npp59OQUFBs+vcfvvtzJ8//4he/5NPPuHMM888oueaFvL3ZvG0tJYt77gWA/1FJFNEwnAO58+tv4KI9K939wxgYzvG5xOWi/yI/Vb9kjcLJE/22q4EXgFQ1S+BCCCp4Qt50qzt71QVl8vFvHnziI+Pb3bdu+++m1NOOaWdIjNHzN+bxWfNgqioQ5dFRTnLOxFVrQGuA94H1uL0e1wtIne7z1gDuE5EVovICuDXwKU+CtfrLBf5Ifut+iVvFkiH3WsDtgMnA4jIYJwCyftNRF46LPLAAw8wdOhQhg4dyoMPPkh2djaDBw/ml7/8JaNGjWLHjh1kZGSwb98+AO655x4GDRrEqaeeykUXXcT9998PwGWXXcarr74KONMZ3HHHHYwaNYphw4axbt06AL755hvGjRvH0Ucfzbhx41i/fn2bbINpAX9vFp82DWbPhvR0EHGuZ8/ulGfGqOo8VR2gqn1VdZZ72e2qOtd9+1eqepSqjlTVSaq6ul0Cs1xkoG1+q/58uD9QqarXLjiHzTYAm4GZ7mV3A2e7bw8BvgC+BVYAPz7cax5zzDHa0Jo1a36wrEnPP68aFaXqHBRxLlFRzvJWWLJkiQ4dOlRLSkq0uLhYhwwZosuWLVMR0S+//PLgeunp6ZqXl6eLFy/WESNGaFlZmRYVFWm/fv30b3/7m6qqXnrppTpnzpyD6z/88MOqqvrYY4/plVdeqaqqhYWFWl1draqqH374oU6ZMkVVVRcsWKBnnHFGq7alRX/Pziw9/dDvUd0lPd3Xkfk9YIl6Mfe0x8VykeUiv+Gl71Jn0Fwu8upI2nr4vbY1qjpeVUeos+f2gTfjAbx2WGThwoX89Kc/JTo6mpiYGKZMmcLnn39Oeno6Y8eObXT9c845h8jISGJjYznrrLOafO0pU6YAcMwxx5CdnQ1AYWEhU6dOZejQodx0002sXt0+O7ymHmsWN61huajjau/WHH8/3B+gOt9UI146LOIUoj8UHR3dovUbEx4eDkBwcDA1NTUA/PGPf2TSpEmsWrWKt956q/OMF+JP7BCWaQ3LRR2TL07e8PfD/QGq8xVIXjpb4Ec/+hH/+9//KCsro7S0lDfeeIMJEyY0uf4JJ5xwMJmUlJTwzjvvtOj9CgsL6dXLGTXhmWeeaU3opjWmTYPsbHC5nGsrjoynLBd1TL5ozWmPs+A6YR+nzlcgeemwyKhRo7jssssYM2YMxx13HFdddRVdu3Ztcv1jjz2Ws88+mxEjRjBlyhRGjx5Nly5dPH6/3//+99x6662MHz+e2traVsVujPEBy0UdUwtbc9qk7vD24X5/H9LEW5rqnOSvl1Z3jFR1Oq6lp6uKONc+6shWXFysqqqlpaV6zDHH6NKlS30SR0PWMdJ4G9ZJ22G5qFkBmYtacPJGm/at9uZ3qQOfkNJcLvLqZLV+a9o0vzgUMmPGDNasWUNFRQWXXnopo0aN8nVIxt/YBJYdm+WijmfWLKd1pd5hNldUNHl3/pndOwrYW1RBUXk1RRU13JNVQ+goJT7IdcjQyjNfEnJThNBgISwkiLDgIMJDg4kIDSIiJJjIsGCiwkKICgsmJjyEmIgQ4i64iLBmvkutSiWdtI9T5yyQ/MQLL7zg6xCMP6tr1q5LtHXN2uAX/1RNx2G5qA1Nm8aeauGzZ99iaWQKa3sNZH1SGpXrBNZ9cei6wyEe0FoB/b5C0iDloY887zxfJzI0mPioUBJjwkiMDiclNpweXSLYtj6SZx+LouRAFEok27ZJy1JJWpqTfxpb3lp+vBNoBZIxXtTUb19V2VNUQfa+MnYcKGN3QQVFFdUUV1RTWeNCAHlrA1EnXEaXihLiK4rpUbSPnkV59L7nPpIvvvgHk3n6cZ4xpsPLLa7g1aU5zF2xi3V7usBx0+kaFcqQnnFc0j2O9KRoenaJoFtcBF0iQ4mLCGXE0GC2bRUazsyVng5btyrVtUpVrYuqGheVNbVUVLuoqK6lrKqW8qpaSqtqKK2soaSyhqLyagrKqjlQVs3+0kryS6tYv6eY3OIKXArx57qLsZogqvbFUJ0Xx8xn4xg8IZ4hPeKICA1ueuMaaRVrkz5Ofr4TaAWSMV5S/7cvIbXs5QA3/iefp7YWsN9VyIGy6kPWjw4LJjYilPDQIFTBFZ9OWcpACiNiqA06NHnF3fUBfVNiGNQ9liE9u5CzMo4//SaOsmJnPT/LM8Z0WBv2FvPQRxt5f9UealzKsRld+cPpgzhxQAoDusX8YEemvln3NF13iAhhIc4hNsKPPL6aWheRCZUEx5cS2rWM0IQSQpOLiczMg5gcpvwTQoOF4anxjO2TwNg+iRybkXBowVSXRNp6D6y5M/78IHFZgWRMY9qgOWbmn8sIHryXlH65RPTOR4IVdQmbt8dy4WndOapnHH2SY0jtGkmPLpFOIqwv43LYtg0FisKj2RObxK64ZLb1GcKma3/LptwS5q3cw4vf7AAg6edCVW4clTu7OpecBGbOjPCHPGNMh7OzoJwHPtjA68tziAkL4bJxGVw4Jo1+KTEev4a36o76QoKD6NU1km3bIqls0GUofVAFj885wPLtBXy9dT+Pf7qFxxZsJjwkiDGZCZw4IJmJA1PomxyNeKO/nJ/3bbICyZiGWtHsu7OgnLe+3cU73+2GswpJAKr2xVC0JJOKbYlU7kyA6hDune1BHO5mbSkro0tlKV0qSxlYlgd33wjnDgOcQ3U7C8oZOLaQsB6FhPc8QMzwHcSNzgag+kAUv5vj7BUe3zeRnvGRR/Y3McYA4HIpWd9s5955a6l2KVdP6MMvTuxL1+iwI3q99uin3+QRstsimDy0B5OH9gCgtLKGb7L38/mGfXy2MY8/vbOWP72zlrSEKE4alMJJg1I4rk8C4SHNHI5rCW/2bWoDViD5qZiYGEpKSti1axc33HDDwQkjG/Pggw8yY8YMohqOg9GMTz75hPvvv5+33367LcLtWFrY7FtSWcO8lbt5fVkOX23ZD8CI3vGwfBA7v+lOTcGhIxinp3sYhwe7lyJCatcokiuj2Papk+QIchGWUkR46n4SBu7nw7V7mbM0x3nvxCiO75PI+H5JjOubSGJMK9ruTadgueh7uwrK+c0r3/LllnxO6JfEX6YMo3eC59vqK562VEWHhzBpYAqTBqYAsGN/GZ9syGPBulxe/GY7zyzKJjosmPH9kjhpUAoTB6bQvUvEkQfmrb5NbcQKpHZUW1tLcHDLKu+ePXs2m5DASUrTp09vUVIyzfCg2VdVWbrtAC8v3sE7K3dTVlVLZlI0vzl1AOeM7EVaYhRZ8TBjIdTUe4kW//Y93L08JM+4gqjaE09IUTyzbuzDRRcp6/cW8+XmfBZtzuedlbt5abFzWG5Q91hO6JfE+H5JjMlMIDrcUkJnYLmo5T7fmMcNLy6nqsbFvVOGccGxvZvtX+RvjqSlqndCFJeMTeeSsemUV9Xy5ZZ9fLQ2lwXrcvlgzV4ABnaL5UcDkjihfzLHZnQlKizE8x4K7XGMsRU6ZTb0xtk+2dnZTJ48meOOO47ly5czYMAA/vvf/zJkyBCuuOIKPvjgA6677jqOPfZYrr32WvLy8oiKiuKJJ55g0KBBbN26lYsvvpiamhomT558yOueeeaZrFq1itraWm6++Wbef/99RISrr74aVWXXrl1MmjSJpKQkFixYwAcffMAdd9xBZWUlffv25emnnyYmJob33nuPG2+8kaSkJBvnpDnNNPsWllfz+rIcXvxmOxv2lhAdFszZI3oydXRvRqXFH5Iw2/O33/x7CYN7xDG4RxxXnJBJTa2LVbuK+GLTPr7YtI//frmNJxduJTRYODqt68GCaURqF0KCO99g++3JcpH/5yJV5bEFm/j7hxsYkBLLv6aPok+y5/2MOorIsGBOGtSNkwZ1Q9XZ6fp0fR6fbczj2UXbeOLzrYQECb0i4ln7WQIlwV2R8K5s2xbWfA8FPxkLrFFNjSDpr5fWjl7bpiOX1rN161YFdOHChaqqevnll+vf/vY3TU9P1/vuu+/geieddJJu2LBBVVW/+uornTRpkqqqnnXWWfrss8+qquqjjz6q0dHRB1/3qKOOUlXVf/7znzplyhStrq5WVdX8/HxVVU1PT9e8vDxVVc3Ly9MJEyZoSUmJqqree++9etddd2l5ebmmpqbqhg0b1OVy6dSpU/WMM85odFsCcvTattTIl2Rl2hC9+d7XdOBt8zT95rf17Ec+15e+2aYlFdW+jrbVyqtq9LMNufqXeWv1jIc/04xb3tb0m9/Wobe/p1c+s1ifXrhFN+wpUpfLdfA5rR20FxtJ23KRH+eig9/vkBpNv3CZpt/8tt7w4jItrQz837s3lFU6OeTed9dq+pULNe2372j6zU4e6Xn1x5p05jJN//FmXbgxT/NLKn0d7iGay0WdrgXJm2cV9u7dm/HjxwMwffp0Hn74YQAuuOACAEpKSli0aBFTp049+JzKykoAvvjiC1577TUALrnkEm6++eYfvP78+fO55pprCAlxPraEhIQfrPPVV1+xZs2ag3FUVVVx/PHHs27dOjIzM+nfv//B+GbP9qSncCfk/iJU3/ZH3o9I5elx57E0uS8RJUGcO7IX08emM7SX53NV+buI0GAm9E9mQv9kYBD7S6v4cnM+Czfl8cWmfOavdZrSU2LDGdc3kaC8JJ6YlUjJXucwig0pcGQsF/lnLqo7R6OCSlIuXAK9CihZNJBjh/YlKixwDqm1p8iw73PIracDwbWE9SggvOcBwnsUEJ62H2J3Me1JZ/3E6DD6pcTQNyWGzMRo0hOjSEuMold8JLERoS16b2+O/9bpCiRvnlXY8Hh03f3oaKeTrsvlIj4+nhUrVnj0/IZU1aN1Tj31VF588cVDlq9YsSKgjpf7UmF5NS+ljuWZGU+wu7CCtIQobjs+namje9MlsmU/3kCUEB3GGcN7cMZwp9P3jv1lzuG4zfks3LSPfSW7SLwM4g5EUbioH6WrevvT0CUBw3KRf5o5E6oiSug+9RuCoyvJe2MUZRt6cNt2mD7d19H5P6eHQjCVOxKp3JF4cHn6gEqef7uYdXuK2Li3hA25xcxbuZuCBuPBdYkMpUeXCHq4B9VMiQ0nOTacpJhwEmPCSYgOo2tUKPFRYbz0onh1nMlOVyB586zC7du38+WXX3L88cfz4osvcsIJJ7B8+fKDj8fFxZGZmcmcOXOYOnUqqsp3333HiBEjGD9+PC+99BLTp08nq4kZkn/84x/z+OOPM3HiREJCQti/fz8JCQnExsZSXFxMUlISY8eO5dprr2XTpk3069ePsrIycnJyDvYt2Lx5M3379v1B0jKwt6iCJz/fwgtfb6e0qpZxfRO555yhTBqUQnCQ/yb0I9KC3a7eCVFcOCaNC8ekoapEdCshPG0fEWn5aNX3KcRPhi4JGJaL/DMX7dV8uk9fCi5h74vHU7U7HrDvt6eaPDHt9nBO6B/OCf2TDlm/oKyK7Pwycg6UkXOgnJwDZewprGR3YTkrdxaRX1qJNjXrSlUI8ZeEElcRStHXfSlb17Ntd9aaOvbmrxd/Pu4/ePBg/fnPf67Dhg3TKVOmaGlp6SHH5FVVt2zZoqeddpoOHz5cBw8erHfdddfB5WPHjtXRo0frX/7yl0aP+1dXV+tNN92kgwcP1uHDh+sjjzyiqqoPP/ywDhw4UCdOnKiqqh999JGOHj1ahw0bpsOGDdM333xTVVXfffddHThwoI4fP15vvvlmvzvu354O6UMzuEzPu+877f+Hedrn1nf0hheX6cqcAl+H6D2t/BG0xcTeWB8ky0V+mIteW7pD0387T3tetUBDupR2tInr201r+yjWV11Tq3sKy3X1zkL9fEOe/m95jj69cIs+8MF6TThllSaeuUyTz/taI/vuOfhZiXj++s3lIp8nmZZeWpuUVNv2w6tTP3kEuo5eINX9YwqKqtCuJ6/StN/M07TfztPz7vtOt+0r9XV43tfKCqct/rFbgeSwXNS89spFtbUup4PxzW/rpLu/1OiuVW1euJpWauTH4u2dtU55Du+0aZCdDS6Xc239JjqXmX+sJWTYZnrNWEDsqG2UrO7Fzn9PZPE/h5GW2PHGb/mBVnZ+mTYNZs92BrwUca5nz7bf0ZGwXNQGsrIgIwOCgpzrJg4LNqWoopqfP7+Uf32ymYuPS+P9P4zh34+E+s/3u5Xb1yHU9Zzfts2pgdydjWadvpCGQ2615TiTna4PkrdkZGSwatUqX4dhDuOzDXlUn7qKrl3LKNvQjQOfDKLmgDOmyfYSHwfXXtqg84s/D13S2XWqXNTK2eBX7yrk2qxl7DhQzh1nDeGycRmIiP98v/18tvt208Qpn9PmTYfZ2V47i82rLUgiMllE1ovIJhG5pYl1zheRNSKyWkReONL3clrKTGt11L9jSWUNt76+kp899Q2hwcLeV8aQ98bog8UR+M30P943axZe3e3q5Drqb6i9efR3bG6shMO89vNfbeOn/1xERbWLl2eM5fLxmf53dt0Rbl+H00yrtzdbYb3WgiQiwcBjwKlADrBYROaq6pp66/QHbgXGq+oBEUk5kveKiIggPz+fxMRE//uCBxBVJT8/n4iIVsyt44e+3VHAtS8sY2dBOT//UR965A/g2mcPnWahU9UHfj68fyCzXNQ2PM5FR3C4OOdAGbe8tpKFm/YxoX8S/7hgJEn+Oiehn8923258NKmtNw+xjQE2qeoWABF5CTgHWFNvnauBx1T1AICq5h7JG6WmppKTk0NeXl4rQzYRERGkpqb6Oow28+rSHP7wxkqSY8KZ8/PjGZ3hDGgXGtTJ6wO/OYbQsVguajse5aIW/OOsrKnl2UXZPDR/IwCzfjqUi8ek+Xch6+ez3bdIa0Z09NGktt4skHoBO+rdzwGOa7DOAAAR+QIIBu5U1fda+kahoaFkZmYeaZymA3K5lD+9s5anvtjKuL6JPHrxKBKiww4+bvWBh7w5TG0HZLmonXnwj1NVeX/1Hv7y7jq25ZcxaWAyd58zlN4JAXBChp/Pdu+x1val8lGrtzcLpMbK8oYHlUOA/sBEIBX4XESGqmrBIS8kMgOYAZAWiJWzaVe1LuWW175jztIcLhuXwW1nDLZJV4+EdRA1/q6Zf5y1LuW9VXt45OONrNtTTL+UGJ65/FgmDjyinhy+0VEOh7fFvDo+2Kv15n+NHKB3vfupwK5G1nlTVatVdSuwHqdgOoSqzlbV0ao6Ojk52WsBm8BX61J+N+db5izN4Vcn9+eOs4Y0XxzZKbRNsw6ixp809Vtt0Et3/7lT+fenm5l0/ydc+8Iyqmpd3D91BO/+akJgFUd1OsJYEAHal8qbLUiLgf4ikgnsBC4ELm6wzv+Ai4BnRCQJ55DbFi/GZDowfT6LW+au5fU+x/Ob797i+mETQAY0/QRrIWlegCY10wFlZZF1+XxmVn/CdtJI27adWZffxTSAadOoqnHxyfpc/rdiJ/PX5lJV42JMZgK3/GQQpx3VveNNFRRoArQvldcKJFWtEZHrgPdx+hc9paqrReRunJEr57of+7GIrAFqgd+par63YjIdWFYWsx9/izknXML1i17i+s+fh0+fcx5rqtjx5nTqHYEfJzURCQJiVLXI17EYL8vKIuuSd5mh/6YMZ7LdbWQwQx9izd8fojx0BfPX7KWooobE6DAuHpPGxcelMaBbrI8DNwcFaF8qCbQxO0aPHq1LlizxdRjGz8wfdyZXT/g5p6//gkfe/CtBdd3d0tOdZunGBAU5o7I2JOI0Z3d2DVvYwElqbTCssIgsVdXRLXzOC8A1ODtTS4EuwAOq+rdWBXOELBe1A/d3MKNsNdvIIDi2nMg+eUT23UtExj6CQl10iQzl5MEpnDWiJyf0SyLU+hv6Jz894aO5XGQjaZuAtym3mF+NvZShezZz/zsPfl8cQfOHg/y4hcQv+F8H0SGqWiQi04B5wM04hdJhCyQRmQw8hNOa/aSq3tvg8V8DVwE1QB5whao28uUw7anqj7ezJKkfRX3K6NHnM8KSiwGoKYik5Ns0KjYns3GTFUUBIQBPHT5sgSQi44EVqloqItOBUcBDljyMP6iudXHjyysId9XyxOt/IrKm8tAVmit2ArTZt135V1ILFZFQ4FzgUVWtFpHDNoF7MmgtsBwYraplIvIL4K/ABW2/CeZwcg6U8cn6PD5Zn8eic++jLCySuNpsynckcGDVIMq3pFC9LwYQ0hNLrDgyXuNJC9K/gBEiMgL4PfAf4L/Aid4MzBhPPPLxJlbtLOJfA4Lo7io/9MHDFTv+10JimvdvIBv4FvhMRNIBT/ogHXbQWlVdUG/9r4DpbRSzOYyaWhdLth1gwbpcPl6Xy8ZcZ1LE1K6R/HTbEiZ+t4Ad2wZyffW/DvZBAogKq2HWQzFNvawxreZJgVSjqioi5+C0HP1HRC71dmDGHM63Owp4bMEmfnp0L35ywUjoUt3yYse/WkhMM1T1YeDheou2icgkD57qyaC19V0JvNvYAzYmW9soqazhk/W5zF+zlwXr8ygsryY0WBiTmcAFx/Zm4sAU+iZHIy/shvcegepvCKeGmfzZOYstsYxZD8XYT9d4lScFUrGI3ApcAkxwN1eHejcsY5pXVePi16+sIDkmnDvPPspZaMVOhyYi3YA/Az1V9SciMgQ4HqdVu9mnNrKs0UNz7m4Eo2mihVxVZwOzwemk7WHoBigoq+KDNXt5b9UeFm7aR1WNi4ToME4Z3I1TBqcwYUAyMeEN/iXVa+Wdtv0lpqUtslZe0248KZAuwBm/6ApV3SMiaXjQKdIYb3p2UTab80p56rLRdIm0er2TeAZ4GqgbqXID8DKHL5A8GbQWETnF/donqmplw8dNyxWWV/P+6j28/d1uFm3aR41LSe0aySVj0zntqO4ck9718GMU2Y6P8ZHDFkjuoug1vh/heh/whlejMqYZ+0oqefijjUwcmMxJg7r5OhzTfpJU9RV3i3bdWGu1HjzvsIPWisjROH2cJh/ppNmdVcOzt++8p5ZuI3N5fflOPl2fR1Wti94JkVw1oQ9nDOvB0F5x/j1BrDFunpzFdjXOMfcEoC/O8fzHgZO9G5oxjfv7B+spr67ltjOG+DoU075KRSQR9+ExERkLFB7uSR4OWvs3IAaY4/7nvV1Vz/bSdnQY3w+VpYR1L6R4wA5uX7qLoNU1JMeGc8nx6Zw9oifDU7tYUWQCjieH2K7FOQvkawBV3SgiATihjekIVu8q5KXFO7hifCb9UuwMlk7m18BcoK+IfAEkA+d58kRVnYczdlL9ZbfXu31KG8bZacy8o4ag/jvpcfR2wroV4aoOonxDd6LzUvlqUdKhh8/8dKBAY5riSYFUqapVddW/iITQRAdHY7zt3nfX0TUqjBtO/sGcxqaDU9VlInIiMBCn4/V6Va32cVid0q6Ccp5auBXXWTtIDK+ham8c+e8PpXRtT7QylHyBQ4YnsnkPTQDypED6VET+AESKyKnAL4G3vBuWMT+0JHs/n2/cx8zTB1vH7E5IRH7WYNEoEUFV/+uTgDqh7H2lPPLxJt5csRMFgnb3YPfnGVTtiqf+yYI/GAHB5j00AciTAukWnHFBVgI/x2mmftKbQRnTmAfnbyQpJoxpY238mU7q2Hq3I3D6QS7DGbjWeFFucQWPfLSJF7/ZTkiwMH1sOldNyOTTeVHMeAuq6q3b6PisTU3509xUQMb4mCdnsbmAJ9wXY3xicfZ+Fm5yWo+iwmwKwc5IVa+vf19EugDP+SicTsHlUrK+3sZ9762norqWC8f05oaT+pMSFwG0YDB6m/fQBCBPzmLbSiN9jlS1j1ciMqYRD87fYK1HpqEyvh9+xLSxzXkl3PzqdyzZdoAJ/ZO4+5yhZCZF/2A9j4YpsnkPTQDyZFd8dL3bEcBUnFP+jWkXS7L388WmfG47w1qPOjMReYvvd9aCgCHAK76LqON6b9UefvPKCkKCg7h/6gj+b1Qv5IUXjvwsNJv30AQgTw6x5TdY9KCILARub2x9Y9ra459upmtUKBiVyDkAAB9MSURBVBcfZ61Hndz99W7XANtUNcdXwXRELpfyj/kbeOTjTYxI7cLjlxxDjy6RbXMWmo2IbQKMJ4fYRtW7G4TTohTrtYiMqWdTbjHz1+Zyw8n9rfWok1PVT30dQ0fmcik3v/Ydc5bmcP7oVO4+ZygRocHOg3YWmumEPPmP8/d6t2uAbOB8r0RjTANPfLaV8JAgLj0+3dehGB8RkWIaH3tNAFXVuHYOqcNxuZRbX1/JnKU53HByf246pf+hI1/bWWimE/LkENuk9gjEmIZyiyp4Y/lOzj82lcSYcF+HY3xEVa3F2otUldveXMXLS3Zw/Un9flgcgZ2FZjqlJgskEfl1c09U1QfaPhxjvvfMomyqXS6uOsFOmDTfc091FFF3X1WtGaMVnl2UzQtfb+eaE/vy61MHND5nmp2FZjqhoGYeiz3MxRivKa2s4fmvtjH5qO5kNHJqsel8RORsEdkIbAU+xTnc/65PgwpwS7ft50/vrOWUwSn8/rSBTU8oO20azJ4N6ekg4lzPnm39j0yH1mQLkqre1doXF5HJwEM4M2g/qar3NrHeecAc4FhVXdLa9zWB79WlORRV1HDVBGs9MgfdA4wF5qvq0SIyCbjIxzEFrLziSn6ZtYye8ZH8/fyRBAU1URzVsbPQTCfjyVlsEThTjRzFoc3aVxzmecHAY8CpQA6wWETmquqaBuvFAjcAX7c4etMhuVzK019sZWTveI5J7+rrcIz/qFbVfBEJEpEgVV0gIvf5OqhApOqcsVZQVs0bvxxjcxsa04jmDrHVeQ7oDpyG06ydChR78LwxwCZV3aKqVcBLwDmNrHcP8FegwqOITYf30bpcsvPLuPKETF+HYvxLgYjEAJ8BWSLyEM6ZtaaF3l+9h4/X5fK70wYypKedBGhMYzwpkPqp6h+BUlV9FjgDGObB83oBO+rdz3EvO0hEjgZ6q+rbHsZrOrCsLMjIgEv+tAVKIzmwsruvQzL+5Ryc6UVuAt4DNgNn+TSiAFRSWcOdc9cwuEccl43L8HU4xvgtT8ZBqnZfF4jIUGAPkOHB8xo7oH1wLBMRCQL+AVx22BcSmQHMAEiz00o7pLqBeqtjCumZtp8DCwbxi6eCCBbr9mAOmgHMcY+e/ayvgwlU//hwA3uLK/jn9FGEBHuyj2xM5+TJr2O2iHQF/gjMBdYAnhz3zwF617ufCuyqdz8WGAp8IiLZOJ0v54pI/bnfAFDV2ao6WlVHJycne/DWJtDUDdQbN3orrqpgir9NOzhQrzFuccD7IvK5iFwrIt18HVCgWbu7iKe/2MpFY9IYlWb9+4xpjictSE+rai1O/6OWnFK0GOgvIpnATuBC4OK6B1W1EEiquy8inwC/tbPYOqft2yE4tpzoIbsoXp6OVoYeXG4MHDyz9i4RGQ5cAHwqIjmqeoqPQwsYD3y4gejwEH5/2kBfh2KM3/OkBWmriMwWkZOlyUEyfkhVa4DrgPeBtcArqrpaRO4WkbOPMF7TQaWlQeyobBClaHHmIcuNaSAX51B/PpDi41gCxqqdhXy4Zi9XnpBJfFSYr8Mxxu95UiANBOYD1wLZIvKoiJzgyYur6jxVHaCqfVV1lnvZ7ao6t5F1J1rrUef1x7uriT16O2Xre1BbFAXYQL3mUCLyC3dL80c4rc9Xq+pw30YVOB6cv4G4iBCusLNDjfHIYQskVS1X1VdUdQowEqcfgM2qbdqUZu4gKLyG6O19bKBe05R04EZVPUpV72g4pppp2nc5Bcxfm8tVE/oQF2FjHhnjCU/6ICEiJ+Ic8/8JTt+i870ZlOlcqmtdPP1FNsdlJvDy8nhfh2P8lKre4usYAtVD8zfSJTKUy8dn+DoUYwKGJyNpbwVWAK8Av1PVUq9HZTqVt7/bxc6Ccu46+yhfh2JMh7NxbzEfrcvl16cOINZaj4zxmCctSCNUtcjrkZhOqdalPPLxJgZ1j+WkQdbf1pi29vSibMJCgpg+Nt3XoRgTUDzpg2TFkfGat7/bxZa8Um44uf/hJ8s0xrRIYVk1ry/L4dyRPUmItjPXjGkJG0bV+IzL3Xo0oFsMk4+yaUVM40TkShH5Xb37O0WkSESKReQXvozNX9VN25M2aTsV1S5SCuzMNWNaygok4zPzVu1mU24J159krUemWdcAT9W7n6uqcUAycJFvQvJfddP2bNuuxI7aRsX2BO74VRxZWb6OzJjA0mQfJBH5dXNPVNUH2j4c01nUupRHPtpE3+RoTh/Ww9fhGP8WpKr59e7PAVDVChGJ9FFMfqtu2p7I/nsJ6VLO/o8HU+6etseGzTDGc821IMXWu/y2wf1Y74dmOrJXl+5g/d5ibjxlAMHWemSa16X+HVX9Mxyc8DrRJxH5sbrpeWJHbaOmMJLyjd0OWW6M8UyTLUjueY8AEJFz6983pjVKKmu4/4MNjEqL58zh1npkDusDEfmTqt7WYPndwAe+CMifpaXBzoIyIjP2UfD5ANCg/2/vzuOrKq/9j39WQgYCylRABpkEGVRAGsE6VBGt6I+qt8ok9qdWi7+2XqsdbCutt/ZXbLV1arXXYrGoN06IVq711lbF1qmYCAgiIAghBGQMYxLItO4fewfDaQhJyJlyvu/X67xy9j77nLM2O1ms/exnP8/B9SLSeI3tg+RRjUJSysNvfMK2vQf4yYRhNGF6P0ld3wdOMLM1ZjYvfKwBBoavSR0zZ0LHURvwGti3rDegaXtEmkOdtCWmNu4q55E313LpyJ6c2qdTvMORJODupe4+FfgSMCd8XOjuU9x9b2M+w8zGm9mqsMj6lxG5zeyLZrbIzKrM7IqWjD/WJk+poccZxdjmrtTsa6tpe0SaqaFO2sv4rOVooJktrX0JcE0SKU3l7vz8pWD6rFvHD4lzNJKExrr77NoFM0sHfnyky//hdg8BFwDFQL6ZzY+Yy60IuIagv2VS+8fqbeyp2s/Dt57E+MfjHY1I8mpoJO0JMYtCUsL8DzbxPx9u5tbxg+nVUTcfSZONM7PLgesIOmf/kcZNnD0aWOPuawHM7GngUuBggeTuheFrNS0cc8w99d4GPtc+k3FDNTK9yNFoqEDKALq7+9t1V5rZ2cCmqEYlrc6WPfu5/cXlnNqnIzd88YR4hyNJyN2vNLPJwDKgDJgamZ8Ooxewoc5yMTCmOTGY2XRgOkCfBOz1vHXPfl5fuZXrz+5PRrp6UIgcjYb+gu4H6ru+Xx6+JtIo7s6Pnl/G/spqfj1xhG7rl2Yxs0HAt4F5QCHwVTPLacxb61nXrBtP3H2Wu+e6e27Xrl2b8xFRNW/RRqprnMm5x8c7FJGk11CB1M/dl0audPcCoF/UIpJWZ/Zb63h95VZ+MH4IJ3RtH+9wJHn9N/ATd78BOAdYDeQ34n3FQN2KoTetsBXc3Zn7/gZy+3ZigP7ORI5aQwVSdgOvqQOJNMrrK7dw58sruPCk7lxzRr94hyPJbbS7vwbBXSLufg9wWSPelw8MMrP+ZpYJTAHmRzHOuFhUtIu120qZpNYjkRbRUIGUb2Zfj1xpZtcB70cvJGktVm3ey01PLWFoj2O5b/JIzbcmzWJmtwK4+x4zmxjx8rVHer+7VwE3Aq8AK4Bn3X25mf3MzC4Jv+M0MysGJgK/N7PlLboTMTC3YANtM9K5WIOvirSIhjpp3wy8YGbT+KwgygUygX+LdmCS3Aq3l/K1OfnkZKYz++rTyMls6FdNpEFTgLvD5z8inIstNB647Ugf4O4vAy9HrLu9zvN8gktvSamsooqXln7Kxaf0oH2W/tZEWkJDU41sAc4ws7HAyeHqP7v76zGJTJLWqs17uWr2Qqqqa3jiujEc16Ghq7UiR2SHeV7fckr6y4eb2Xegikm5SVvjiSScI94H6u4L3P234aNJxVEjRq/9jpl9ZGZLzew1M+vblM+XGMjLg379IC0t+JmX1+Dmi4p2MnnWu6QZPHvDFzi5V4cGtxdpBD/M8/qWU9LcgmL6dslhdP/O8Q5FpNWIWltsI0evXQzkunuZmX2DoBl9crRikibKy4Pp06GsLFhevz5Yhn+Zt8Ddmf3WOu76y0p6dGhL3vVjOL5zY+7AFjmiEWa2h6C1qG34nHA55Zsn1+8o5d21O/juBSdqbkORFhTNi9WNGb12QZ3t/wlcFcV4pKlmzPisOKpVVhasr329qIgtJ57CbV+9g9f2ZvClYd25+4rhdMzJjH280iq5e3q8Y0hkT+dvID3NmKi710RaVDQLpKaOXnsd8D9RjEeaqqio/vVhS9KBAxXMHn05D54xmaqdzk+PL+Pqr35eZ7EiMVJRVcPcgg2MHdxNff1EWlg0x6Jv9Oi1ZnYVwR1yvzrM69PNrMDMCrZt29aCIcph5eVBWhp5TKUf60ijmn6sI4+plGe15fHBYxl3/cPcfe41nFW4hFf/8A2uue/7Ko5EYui1FVvYvq+CK8eo9UikpUWzBalRo9ea2fnADOAcdz9Q3we5+yxgFkBubq46ZUZb2Pcor3oS03mEMtoBsLFDN24efht3jric0nbZnLpxJb945UHOLlwSvG+PiiORWHoqfwM9OmRzzomamFakpUWzQDo4ei2wkWAskyvrbmBmpwK/B8a7+9YoxiJNEfY9msGd7M9pQ/sT19NuyCay+5bgDqVru/LMP7/J6OLlhzYTJuDknSKt1YaSMt5cvY2bzhuk+Q1FoiBqBZK7V5lZ7ei16cCjtaPXAgXuPp/gklp7YG54aabI3S+JVkxyZO7OivI0Fpw+kf0DNtG793LMoLKkHTv/cSKlH/amZm82Y3LWHfrGnByYOTM+QYukoGfyN2DApNN0eU0kGqI65GojRq89P5rfL0fm7qzfUcbCdTt4e80O3vlkB9uv/S0A2ZvL2fX2IMpWHUfl9mOo7VbWty8wc9bBu9jo0ycojiJu/ReR6NhfWc2T7xVx3pBu9OqoqTFFokFj0qeYmhpn9dZ9vFdYQv66Ehau28GWPUHXr67HZHHWwC6cuX0N59xxM3/bfg7TeYTKsA8S1GkomjZNBZFInLyweCMlpRVcd9aAeIci0mqpQGrl9ldWs2zjbvILSygo3ElBYQl79lcB0O2YLMYM6MKY/p0Z078zA7u1D+9COxU6VTBtxgxYP50Z6XdRVN2LPn1NDUUicVY7KOuwHsdy+gCNnC0SLSqQklReXv1XuPbsr+T9wp28V1hCQWEJH2zYTUV1DQAndG3Hxaf0ILdfZ0b368zxndse/rb8sIVoGqB6SCRx/P3jbazZuo97J43QsBoiUaQCKQnVnQHEMivZ2qaEWx7fwUOrd7D5wB5qHNqkGSf36sA1Z/Yjt28nPt+3E13aZ8U7dBE5SrPfWke3Y7KYMLxnvEMRadVUICWZquoaZty3i4xR2ziu/3Yyj9uFpYFXpbGpqCM3TR3E6f07M7JPR3IydXhFWpOVm/fw5urtfP/CwWS2ieY4vyKi/0GTQFlFFa+v3MqrH21hwaptcH4lHWqg4tOO7PnnQMrXd+HAxk5YTTrfeTTe0YpItNz7149pn9WGK0drzDGRaFOBlKCqa5w3Vm3lhcUbeW3FVsorq+mUk8H5Q7sz7zfdKC74HDUHMg55T5++cQpWRKJucdFO/vrRFm45/0Q6tdNk0CLRpgIpwZSUVvDUe0U8ubCIjbvK6ZSTwVdG9WLC8J6M7t+Z9DRjVGXYB6nO+zROo0jr9qtXVtGlXSbXnd0/3qGIpAQVSAmipLSCWf9Yy+PvFlJWUc2ZA7vwkwlDGTe0Oxnph/Y1qL3NXuM0iqSGt1Zv551PdvCTCcNon6W0LRIL+kuLs8rqGua8Xcj9r35MWWU1Xx7ek38/byCDuh/T4Ps0TqNIaqiuce5+ZSU9O2QzbYz6HonEigqkOFpctJMfPb+MlZv3Mm5IN3540ZAjFkYikloee6eQpcW7uW/yCLIz0uMdjkjKUIEUB9U1zu8WrOG+Vz+m2zHZPHzV57nwpO4a9E1EDrF+Ryl3v7KSsYO7ctnIXvEORySlqECKsa1793Pz00t455MdXDqyJz+/7GSOyc448htFJKXU1Di3PreUjLQ07vzKKTqBEokxjTQWQ8uKd3PJb99mUdFO7r58OPdPHhn94igvD/r1g7S04GdeXnS/T0RaxGPvFrJwXQk/njCUHh3axjsckZSjFqQYeWnpJr439wO6tMvi+W+cybCex0b/S+vOSQKwfn2wDOrhLZLA3ly9jZ//eQXnDenGpNzj4x2OSEpSC1KUuTsPvLqaG59czMk9O/DijTEqjiAYB6Cs7NB1ZWXBehFJSKs27+Wb/7WIQd3a88CUkbq0JhInakGKov2V1fxg3lJeXLKJr4zqxS++cgpZbWJ4F0pRUdPWi0hcbdxVztfm5JOTlc6j15ym/okicaQWpBZ0SHefoeVccOc/eXHJJr5/4WDumTgitsURBCNINmW9iMTNsuLdXPbQ2+wpr2T21afRs6P6HYnEkwqkFlLb3Wf9esjqs53qC95i/e69TO0zim+NHRifZvKZM4M5SOrSnCQiCedvH21h0u/fJTM9jXnfPIOTe3WId0giKU8FUguZMQPKK6rp+MWVdJu8kOrSTD597CyeurtH/IKaNg1mzYK+fcEs+DlrljpoiySIktIKvvvsB3z98QIGdW/PC986gxM1WKxIQlAfpBayNW0bPb72IRmdyti3tDclr56EV7ahaGecA9OcJCIJ6U+LN3LHfy9n7/4qvnnuCdw0bpBGyhZJIFEtkMxsPPAAkA78wd1/GfF6FvA48HlgBzDZ3QujGVNLcnfeWLWNh//+Cd0mlVC5ox1bnhrD/qLPHdxG3X1EpD4ffbqHAV3bc+e/ncLg49RqJJJoonaJzczSgYeAi4BhwFQzGxax2XXATncfCNwH3BWVYFpwsMSaGueDDbu4+y8rGXfP37l2Tj5FJWVcdNxQdj1z9iHFkbr7iCQGMxtvZqvMbI2Z/bCe17PM7Jnw9YVm1q/Fg4jIQ9/dsYi5N3xBxZFIgopmC9JoYI27rwUws6eBS4GP6mxzKfDT8PlzwINmZu7uLRZFMwZLrK5xdpdXUlJ6gE279lO8s5zCHaV8uHE3yzbuZu/+KtLTjDH9O/OtsQP58oieZLZJ46yuQV+koqKg5WjmTF3dEom3OidrFwDFQL6ZzXf3urno4MmamU0hOFmb3GJB1JOHsv7f9OAUVUlCJCFFs0DqBWyos1wMjDncNu5eZWa7gS7A9haLImKwxMdGTeBvg8ZQ9epWqve+Q0VVDQfCR1lFFWUHqtlXUUVkiZaZnsaQHsdw6ciejOrTibGDu9GpXeYh26i7j0hCiv/JWkODtippiCSkaBZI9d3XHplsGrMNZjYdmA7Qp6mdeiIGRaxIz6C8TRbpFRVkpKfRLqsNmelpZLZJo11mG9pltaF9dhs652TQqV0mxx2bzfGdc+h+bDbpaRrRViQJtdjJWrNzkQZtFUk60SyQioG6kwj1BjYdZptiM2sDdABKIj/I3WcBswByc3ObdkbXp09wWS309fwX+Hr+C8Et73k/aNJHiUhSarGTtWbnoog8dMh6EUlI0RwHKR8YZGb9zSwTmALMj9hmPnB1+PwK4PUW7X8EGixRRJpyskZDJ2vNpjwkknSiViC5exVwI/AKsAJ41t2Xm9nPzOyScLPZQBczWwN8B/iXu0uOmgZLFEl18T9ZUx4SSTrW0g020Zabm+sFBQXxDkNEjoKZve/uuTH8vouB+wnGZHvU3Wea2c+AAnefb2bZwBPAqQQtR1NqO3UfjnKRSPJrKBdpJG0RafXc/WXg5Yh1t9d5vh+YGOu4RCRxaS42ERERkQgqkEREREQiqEASERERiZB0nbTNbBtQz4AijfI5WnKU7sSgfUoOrXGfoPn71dfdu7Z0MLF0FLlIvwvJQ/uUPFo8FyVdgXQ0zKwglnfOxIL2KTm0xn2C1rtf0dRa/81a435pn5JHNPZLl9hEREREIqhAEhEREYmQagXSrHgHEAXap+TQGvcJWu9+RVNr/TdrjfulfUoeLb5fKdUHSURERKQxUq0FSUREROSIUqJAMrPxZrbKzNaYWctPiBsDZna8mS0wsxVmttzMvh2u72xmfzOz1eHPTvGOtanMLN3MFpvZS+FyfzNbGO7TM+EEo0nFzDqa2XNmtjI8Zl9I9mNlZreEv3sfmtlTZpbdGo5VLCkXJTblouQQq1zU6gskM0sHHgIuAoYBU81sWHyjapYq4LvuPhQ4HfhWuB8/BF5z90HAa+Fysvk2sKLO8l3AfeE+7QSui0tUR+cB4C/uPgQYQbB/SXuszKwXcBOQ6+4nE0z6OoXWcaxiQrkoKSgXJbhY5qJWXyABo4E17r7W3SuAp4FL4xxTk7n7p+6+KHy+l+CXvBfBvjwWbvYYcFl8ImweM+sN/B/gD+GyAecBz4WbJOM+HQt8EZgN4O4V7r6LJD9WBJNbtzWzNkAO8ClJfqxiTLkogSkXJZWY5KJUKJB6ARvqLBeH65KWmfUDTgUWAt3d/VMIEhfQLX6RNcv9wK1ATbjcBdjl7lXhcjIerwHANuCPYXP9H8ysHUl8rNx9I/BroIggGe0G3if5j1UsKRclNuWiJBDLXJQKBZLVsy5pb90zs/bAPOBmd98T73iOhplNALa6+/t1V9ezabIdrzbAKOA/3f1UoJQkasKuT9hH4VKgP9ATaEdwqShSsh2rWGoNv9sHKRclBeWio5AKBVIxcHyd5d7ApjjFclTMLIMgIeW5+/Ph6i1m1iN8vQewNV7xNcOZwCVmVkhwueE8grO4jmHTKSTn8SoGit19Ybj8HEGSSuZjdT6wzt23uXsl8DxwBsl/rGJJuShxKRclj5jlolQokPKBQWEP90yCzlzz4xxTk4XXw2cDK9z93jovzQeuDp9fDbwY69iay91/5O693b0fwXF53d2nAQuAK8LNkmqfANx9M7DBzAaHq8YBH5HEx4qgOft0M8sJfxdr9ympj1WMKRclKOWipNqvmOWilBgo0swuJjgbSAcedfeZcQ6pyczsLOBNYBmfXSO/jeDa/7NAH4JfnInuXhKXII+CmZ0LfM/dJ5jZAIKzuM7AYuAqdz8Qz/iaysxGEnT2zATWAtcSnJAk7bEyszuAyQR3MS0Grie4zp/UxyqWlIsSn3JR4otVLkqJAklERESkKVLhEpuIiIhIk6hAEhEREYmgAklEREQkggokERERkQgqkEREREQiqEBqpcys2syWhDMef2Bm3zGzmB9vMzs7jGGJmQ01syuj+F1zzOyKI29Z73tHhrdg1y5fYkk627pIIlEuavJ7lYsShAqk1qvc3Ue6+0nABcDFwH/EIY5pwK/dfSTQHWhSUgpnQI+FkQT/RgC4+3x3/2WMvlukNVMuahrlogShAikFuPtWYDpwowX6mdmbZrYofJwBYGZPmNnB2cXNLC88eznJzN4Lz7yWmtmgyO8ws/80s4LwDO2OcN31wCTgdjPLA34JnB1+zi1mlm5mvzKz/PBzbwjfd66ZLTCzJwkGo4v8rn1mdk8Y+2tm1rWebW4PP/dDM5sVjriKmb1hZneF+/NxeFaZCfwMmBzGNtnMrjGzB8P3zDGz35jZO2a2tvbM0MzSzOx34T6/ZGYvN/esUSQVKBcpFyUVd9ejFT6AffWs20lw5pQDZIfrBgEF4fNzgD+FzzsA6wgmO/wtMC1cnwm0reezO4c/04E3gOHh8hzgivD5ucBLdd4zHfhx+DwLKCCYgPBcgkkV+x9m37xOPLcDD9bzXZ3rbP8E8OXw+RvAPeHzi4FXw+fX1H5O5HL4uXMJTiiGAWvC9VcAL4frjwv/fa+I97HXQ49EeigXKRcl60MtSKmldnbqDOARM1tG8Mc2DMDd/w4MNLNuwFRgnrtXAe8Ct5nZD4C+7l5ez2dPMrNFBEO8n1T7mUfwJeD/mtkSgmkKuhAkSYD33H3dYd5XAzwTPv8v4Kx6thlrZgvDfTwvjKlW7eSa7wP9GhEnBMm6xt0/IkjshN87N1y/mWAuIBE5MuWigHJRAlOBlCIsmFOommDW5luALcAIIJfgTKzWEwTX6q8F/gjg7k8ClwDlwCtmdl7EZ/cHvgeMc/fhwJ+B7MaEBfy7B/0TRrp7f3f/a/haaRN275D5cswsG/gdwRnUKcAjEfHUzs9TTXBW2hh15/SxiJ8i0kjKRcpFyUIFUgoIr4s/TNBM6wRN1p+6ew3wVYKm6FpzgJsB3H15+P4BwFp3/w3BLNDDI77iWIIkstvMugMXHSaUvcAxdZZfAb5hZhnh95xoZu0asUtpfDZr85XAWxGv1yag7WbWvs62DYmMrTHeAi4Pr/93J2iOF5HDUC5SLkomja1YJfm0DZuLMwhmPH4CuDd87XfAPDObSNAUe/AMyd23mNkK4E91PmsycJWZVQKbCToRUuc9H5jZYmA5wWzRbx8mpqVAlZl9QJD8HiBoVl4UdlzcBlzWiH0rBU4ys/eB3WF8dePZZWaPEHSqLATyG/GZC4Afhv9mv2jE9gDzgHHAh8DHBE3zuxv5XpFUoVykXJSULCjiRQJmlkPwxzzK3RPyD8zM9rl7+3jHAWBm7d19n5l1Ad4Dzgz7AIjIUVAuahrlopanFiQ5yMzOBx4F7k3UhJSAXjKzjgR9J/6/EpLI0VMuahblohamFiQRERGRCOqkLSIiIhJBBZKIiIhIBBVIIiIiIhFUIImIiIhEUIEkIiIiEkEFkoiIiEiE/wXQmttBsEuClQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "\n",
    "std = 10\n",
    "observation = 15\n",
    "normalization = False\n",
    "# x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "# print(x_train[observation:observation+1])\n",
    "y_train = yield_data['Yield'].values\n",
    "show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "std = 10\n",
    "observation = 4\n",
    "normalization = True\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "# y_original = y_original / np.linalg.norm(y_original)\n",
    "y_train = y_train/np.linalg.norm(y_train)\n",
    "# show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "11\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "9\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_GRNN_example(5, std, normalization)\n",
    "show_GRNN_example(6, std, normalization)\n",
    "show_GRNN_example(7, std, normalization)\n",
    "show_GRNN_example(8, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "\n",
    "std = 3\n",
    "observation = 13\n",
    "normalization = True\n",
    "# x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_medium_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_default_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    \n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(10, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "#     model.add(keras.layers.Dense(4, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_small_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(16, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(16, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(1, activation ='relu'))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_tiny_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(10, activation='relu', input_shape=[input_shape],kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(1, activation ='relu'))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 6,537\n",
      "Trainable params: 6,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_medium_regression_model(len(parameters) * len(x_pred))\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "optimizer = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "# model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and train model\n",
    "\n",
    "std = 10\n",
    "observation = 4\n",
    "normalization = True\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "y_train = y_train / np.linalg.norm(y_train)\n",
    "x_train = x_train.reshape(len(yield_data), len(x_pred) * len(parameters))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 34 samples\n",
      "Epoch 1/10000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0373 - mse: 0.0021 - val_loss: 9.2062e-04 - val_mae: 0.0249 - val_mse: 9.2062e-04\n",
      "Epoch 2/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 9.1963e-04 - mae: 0.0240 - mse: 9.1963e-04 - val_loss: 8.1035e-04 - val_mae: 0.0243 - val_mse: 8.1035e-04\n",
      "Epoch 3/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.5892e-04 - mae: 0.0235 - mse: 8.5892e-04 - val_loss: 8.1775e-04 - val_mae: 0.0243 - val_mse: 8.1775e-04\n",
      "Epoch 4/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.3583e-04 - mae: 0.0226 - mse: 8.3583e-04 - val_loss: 0.0011 - val_mae: 0.0265 - val_mse: 0.0011\n",
      "Epoch 5/10000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 9.2969e-04 - mae: 0.0239 - mse: 9.2969e-04 - val_loss: 7.5789e-04 - val_mae: 0.0240 - val_mse: 7.5789e-04\n",
      "Epoch 6/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 9.1771e-04 - mae: 0.0233 - mse: 9.1771e-04 - val_loss: 9.0952e-04 - val_mae: 0.0248 - val_mse: 9.0952e-04\n",
      "Epoch 7/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.7684e-04 - mae: 0.0233 - mse: 8.7684e-04 - val_loss: 8.0131e-04 - val_mae: 0.0242 - val_mse: 8.0131e-04\n",
      "Epoch 8/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.6320e-04 - mae: 0.0233 - mse: 8.6320e-04 - val_loss: 9.8954e-04 - val_mae: 0.0256 - val_mse: 9.8954e-04\n",
      "Epoch 9/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.6529e-04 - mae: 0.0235 - mse: 8.6529e-04 - val_loss: 7.4537e-04 - val_mae: 0.0238 - val_mse: 7.4537e-04\n",
      "Epoch 10/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 9.0987e-04 - mae: 0.0238 - mse: 9.0987e-04 - val_loss: 7.5583e-04 - val_mae: 0.0239 - val_mse: 7.5583e-04\n",
      "Epoch 11/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.9692e-04 - mae: 0.0239 - mse: 8.9692e-04 - val_loss: 8.7098e-04 - val_mae: 0.0245 - val_mse: 8.7098e-04\n",
      "Epoch 12/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.7881e-04 - mae: 0.0238 - mse: 8.7881e-04 - val_loss: 7.4657e-04 - val_mae: 0.0238 - val_mse: 7.4657e-04\n",
      "Epoch 13/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.9856e-04 - mae: 0.0238 - mse: 8.9856e-04 - val_loss: 9.6709e-04 - val_mae: 0.0254 - val_mse: 9.6709e-04\n",
      "Epoch 14/10000\n",
      "136/136 [==============================] - 0s 74us/step - loss: 8.9623e-04 - mae: 0.0242 - mse: 8.9623e-04 - val_loss: 8.3793e-04 - val_mae: 0.0243 - val_mse: 8.3793e-04\n",
      "Epoch 15/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.2984e-04 - mae: 0.0227 - mse: 8.2984e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0011\n",
      "Epoch 16/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 9.4092e-04 - mae: 0.0246 - mse: 9.4092e-04 - val_loss: 7.7770e-04 - val_mae: 0.0239 - val_mse: 7.7770e-04\n",
      "Epoch 17/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 8.3854e-04 - mae: 0.0229 - mse: 8.3854e-04 - val_loss: 8.4462e-04 - val_mae: 0.0244 - val_mse: 8.4462e-04\n",
      "Epoch 18/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 9.0041e-04 - mae: 0.0234 - mse: 9.0041e-04 - val_loss: 0.0010 - val_mae: 0.0257 - val_mse: 0.0010\n",
      "Epoch 19/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.8301e-04 - mae: 0.0239 - mse: 8.8301e-04 - val_loss: 0.0013 - val_mae: 0.0299 - val_mse: 0.0013\n",
      "Epoch 20/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 9.3765e-04 - mae: 0.0237 - mse: 9.3765e-04 - val_loss: 0.0011 - val_mae: 0.0265 - val_mse: 0.0011\n",
      "Epoch 21/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.5173e-04 - mae: 0.0233 - mse: 8.5173e-04 - val_loss: 7.4703e-04 - val_mae: 0.0238 - val_mse: 7.4703e-04\n",
      "Epoch 22/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.2387e-04 - mae: 0.0226 - mse: 8.2387e-04 - val_loss: 9.0914e-04 - val_mae: 0.0248 - val_mse: 9.0914e-04\n",
      "Epoch 23/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.3834e-04 - mae: 0.0232 - mse: 8.3834e-04 - val_loss: 7.8710e-04 - val_mae: 0.0240 - val_mse: 7.8710e-04\n",
      "Epoch 24/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.1910e-04 - mae: 0.0226 - mse: 8.1910e-04 - val_loss: 7.6028e-04 - val_mae: 0.0239 - val_mse: 7.6028e-04\n",
      "Epoch 25/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.2354e-04 - mae: 0.0227 - mse: 8.2354e-04 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012\n",
      "Epoch 26/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.5587e-04 - mae: 0.0232 - mse: 8.5587e-04 - val_loss: 0.0011 - val_mae: 0.0262 - val_mse: 0.0011\n",
      "Epoch 27/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.4377e-04 - mae: 0.0232 - mse: 8.4377e-04 - val_loss: 7.3053e-04 - val_mae: 0.0235 - val_mse: 7.3053e-04\n",
      "Epoch 28/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.4226e-04 - mae: 0.0226 - mse: 8.4226e-04 - val_loss: 7.3149e-04 - val_mae: 0.0234 - val_mse: 7.3149e-04\n",
      "Epoch 29/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.6141e-04 - mae: 0.0234 - mse: 8.6141e-04 - val_loss: 7.7774e-04 - val_mae: 0.0235 - val_mse: 7.7774e-04\n",
      "Epoch 30/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.4608e-04 - mae: 0.0229 - mse: 8.4608e-04 - val_loss: 8.4095e-04 - val_mae: 0.0242 - val_mse: 8.4095e-04\n",
      "Epoch 31/10000\n",
      "136/136 [==============================] - 0s 99us/step - loss: 8.4208e-04 - mae: 0.0230 - mse: 8.4208e-04 - val_loss: 7.2376e-04 - val_mae: 0.0233 - val_mse: 7.2376e-04\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=30, mode=\"min\", verbose=1)\n",
    "history = model.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])\n",
    "# history = model.fit(x_train, y_train, epochs= 10000, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 68us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007446734115085883, 0.022263439372181892, 0.0007446734234690666]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mae', 'val_mse', 'loss', 'mae', 'mse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['mse'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['val_mse'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using default network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrenn as prn\n",
    "net = prn.CreateNN([32, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  6.574105877473802 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  3.92758178419609 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  2.842927263696396 \tscale factor:  0.02\n",
      "Iteration:  3 \t\tError:  2.6579319932618244 \tscale factor:  0.1458\n",
      "Iteration:  4 \t\tError:  2.5283194976270194 \tscale factor:  0.054\n",
      "Iteration:  5 \t\tError:  2.4595635923532795 \tscale factor:  0.019999999999999997\n",
      "Iteration:  6 \t\tError:  2.384437987231993 \tscale factor:  0.007407407407407406\n",
      "Iteration:  7 \t\tError:  1.6970042068163227 \tscale factor:  0.007407407407407406\n",
      "Iteration:  8 \t\tError:  1.3518058576324674 \tscale factor:  0.019999999999999997\n",
      "Iteration:  9 \t\tError:  1.0821591659533865 \tscale factor:  0.007407407407407406\n",
      "Iteration:  10 \t\tError:  0.9396936505418847 \tscale factor:  0.007407407407407406\n",
      "Iteration:  11 \t\tError:  0.7782720390782079 \tscale factor:  0.002743484224965706\n",
      "Iteration:  12 \t\tError:  0.6608469459210028 \tscale factor:  0.007407407407407406\n",
      "Iteration:  13 \t\tError:  0.5716945735925149 \tscale factor:  0.007407407407407406\n",
      "Iteration:  14 \t\tError:  0.5146104326880458 \tscale factor:  0.007407407407407406\n",
      "Iteration:  15 \t\tError:  0.4932748182012767 \tscale factor:  0.002743484224965706\n",
      "Iteration:  16 \t\tError:  0.3941332785992945 \tscale factor:  0.007407407407407406\n",
      "Iteration:  17 \t\tError:  0.3781555266617259 \tscale factor:  0.007407407407407406\n",
      "Iteration:  18 \t\tError:  0.3299007164510469 \tscale factor:  0.007407407407407406\n",
      "Iteration:  19 \t\tError:  0.2762793355310798 \tscale factor:  0.007407407407407406\n",
      "Iteration:  20 \t\tError:  0.2393301974602186 \tscale factor:  0.007407407407407406\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=20, E_stop=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prn.NNOut(x_train, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_train_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>57.441457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.392380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26.8</td>\n",
       "      <td>24.081672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.983642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>35.587038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_train  y_train_pred\n",
       "0     59.2     57.441457\n",
       "1     24.6     25.392380\n",
       "2     26.8     24.081672\n",
       "3     23.4     23.983642\n",
       "4     36.4     35.587038"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': y.flatten()})\n",
    "acc_sc_chk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.9611871773202583 / 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score_1 = r2_score(acc_sc_chk.y_train, acc_sc_chk.y_train_pred)\n",
    "print('r2 score = ', r2_score_1, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction test data\n",
    "y_pred = prn.NNOut(x_test, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>25.507260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>22.314717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>29.390475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>46.2</td>\n",
       "      <td>30.507028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>14.127041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_test_pred\n",
       "0     9.4    25.507260\n",
       "1     1.4    22.314717\n",
       "2     1.4    29.390475\n",
       "3    46.2    30.507028\n",
       "4    17.4    14.127041"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk_2 = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': y_pred.flatten()})\n",
    "acc_sc_chk_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-4efaa3864a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr2_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_sc_chk_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_sc_chk_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r2 score = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/ 1.0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "r2_score = r2_score(acc_sc_chk_2.y_test, acc_sc_chk_2.y_test_pred)\n",
    "print('r2 score = ', r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"normalizationWeight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 32)\n",
      "(129,)\n"
     ]
    }
   ],
   "source": [
    "#compile and train model\n",
    "\n",
    "std = 2\n",
    "observation = 4\n",
    "normalization = False\n",
    "x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "x_train = x_train.reshape(len(yield_data), len(x_pred) * len(parameters))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-d853d70ac43a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = build_model(len(parameters) * len(x_pred))\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 34 samples\n",
      "Epoch 1/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 22.0235 - accuracy: 0.0294 - val_loss: 330.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 22.0566 - accuracy: 0.0294 - val_loss: 304.6982 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "136/136 [==============================] - 0s 125us/step - loss: 16.2596 - accuracy: 0.0441 - val_loss: 302.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 20.9351 - accuracy: 0.0221 - val_loss: 297.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 20.3262 - accuracy: 0.0294 - val_loss: 292.8714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 19.4125 - accuracy: 0.0147 - val_loss: 318.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 16.2981 - accuracy: 0.0074 - val_loss: 277.9302 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 26.9520 - accuracy: 0.0000e+00 - val_loss: 277.6325 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 17.2630 - accuracy: 0.0147 - val_loss: 331.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 24.1353 - accuracy: 0.0294 - val_loss: 289.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 27.6881 - accuracy: 0.0147 - val_loss: 225.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 31.5064 - accuracy: 0.0000e+00 - val_loss: 245.7843 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 27.9803 - accuracy: 0.0074 - val_loss: 277.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "136/136 [==============================] - 0s 154us/step - loss: 23.5792 - accuracy: 0.0294 - val_loss: 295.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 21.3009 - accuracy: 0.0294 - val_loss: 297.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 22.5863 - accuracy: 0.0294 - val_loss: 287.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 24.0893 - accuracy: 0.0221 - val_loss: 293.1207 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 19.0059 - accuracy: 0.0074 - val_loss: 304.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 14.6915 - accuracy: 0.0441 - val_loss: 296.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 19.9271 - accuracy: 0.0074 - val_loss: 309.7323 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 23.0918 - accuracy: 0.0074 - val_loss: 312.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 20.0033 - accuracy: 0.0147 - val_loss: 304.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 20.5833 - accuracy: 0.0294 - val_loss: 294.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 20.4638 - accuracy: 0.0294 - val_loss: 305.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 15.8400 - accuracy: 0.0221 - val_loss: 328.9878 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 21.7599 - accuracy: 0.0074 - val_loss: 309.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 16.2800 - accuracy: 0.0147 - val_loss: 318.8981 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "136/136 [==============================] - 0s 154us/step - loss: 20.0312 - accuracy: 0.0147 - val_loss: 314.4065 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "136/136 [==============================] - 0s 125us/step - loss: 22.1290 - accuracy: 0.0000e+00 - val_loss: 283.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 22.1368 - accuracy: 0.0221 - val_loss: 300.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 20.5637 - accuracy: 0.0221 - val_loss: 319.8900 - val_accuracy: 0.0000e+00\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = model.fit(x_train, y_train, epochs=10000, validation_data=(x_valid, y_valid), callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 62us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[152.62903189953462, 0.012345679104328156]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"UnnormalizationWeight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test connection of input and output\n",
    "# Output using: plants planted on 2/28/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "test = data\n",
    "print(type(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 12)\n",
      "(81, 9)\n",
      "(81, 12)\n",
      "(81, 12)\n",
      "(81, 45)\n"
     ]
    }
   ],
   "source": [
    "plantDate = '2-28-2016'\n",
    "mask_yield = yield_data['plantDate'] == plantDate\n",
    "test_data = np.empty((81, 0))\n",
    "for i in range(len(data)):\n",
    "    test = data[i].copy()\n",
    "    test = test[mask_yield]\n",
    "    for column in test.columns:\n",
    "        temp_mask = test[column].values<=0\n",
    "        if sum(temp_mask) != 0:\n",
    "            test = test.drop(column, axis = 1)\n",
    "#     print(test.columns)\n",
    "    test = test[test.columns[test.columns != 'id' ]]\n",
    "    day_after_planting = np.array([count_days(plantDate, x) for x in test.columns])\n",
    "    \n",
    "    mask = (day_after_planting>20) & (day_after_planting <=limit_day)\n",
    "#     print(day_after_planting[mask])\n",
    "    value = test[test.columns[mask]].values\n",
    "    print(value.shape)\n",
    "    value = value/np.linalg.norm(value)\n",
    "    test_data = np.append(test_data, value, axis = 1)\n",
    "    \n",
    "# test_data=np.array(test_data)\n",
    "# test_data = test_data.swapaxes(0,1)\n",
    "print(test_data.shape)\n",
    "#     print(type(test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= test_data.reshape(81, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 45)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "test_data_x = test_data\n",
    "test_data_y = yield_data['Yield'][mask_yield].values\n",
    "test_data_y /= np.linalg.norm(test_data_y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(test_data_x, test_data_y, test_size = 0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.076548</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>0.064414</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>0.077544</td>\n",
       "      <td>0.122361</td>\n",
       "      <td>0.185421</td>\n",
       "      <td>0.246436</td>\n",
       "      <td>0.325305</td>\n",
       "      <td>0.450840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383785</td>\n",
       "      <td>0.512663</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.605675</td>\n",
       "      <td>0.596939</td>\n",
       "      <td>0.662752</td>\n",
       "      <td>0.730180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.040188</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.054816</td>\n",
       "      <td>0.088630</td>\n",
       "      <td>0.170701</td>\n",
       "      <td>0.287965</td>\n",
       "      <td>0.397261</td>\n",
       "      <td>0.510692</td>\n",
       "      <td>0.642437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474338</td>\n",
       "      <td>0.631576</td>\n",
       "      <td>0.724246</td>\n",
       "      <td>0.760365</td>\n",
       "      <td>0.762104</td>\n",
       "      <td>0.555369</td>\n",
       "      <td>0.322262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0.057990</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.053455</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.086824</td>\n",
       "      <td>0.156805</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>0.351107</td>\n",
       "      <td>0.458857</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639595</td>\n",
       "      <td>0.760024</td>\n",
       "      <td>0.822052</td>\n",
       "      <td>0.839582</td>\n",
       "      <td>0.816573</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.636550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.648787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.072349</td>\n",
       "      <td>0.067886</td>\n",
       "      <td>0.064455</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>0.100332</td>\n",
       "      <td>0.175779</td>\n",
       "      <td>0.274623</td>\n",
       "      <td>0.360292</td>\n",
       "      <td>0.453749</td>\n",
       "      <td>0.582514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599032</td>\n",
       "      <td>0.735785</td>\n",
       "      <td>0.798537</td>\n",
       "      <td>0.812896</td>\n",
       "      <td>0.789501</td>\n",
       "      <td>0.815436</td>\n",
       "      <td>0.924938</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.086425</td>\n",
       "      <td>0.139599</td>\n",
       "      <td>0.197102</td>\n",
       "      <td>0.257314</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.455256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393861</td>\n",
       "      <td>0.549271</td>\n",
       "      <td>0.650403</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.709303</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.594256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "612  0.076548  0.070373  0.064414  0.062494  0.077544  0.122361  0.185421   \n",
       "27   0.036692  0.040188  0.044507  0.054816  0.088630  0.170701  0.287965   \n",
       "568  0.057990  0.055000  0.053455  0.059006  0.086824  0.156805  0.257027   \n",
       "609  0.072349  0.067886  0.064455  0.068856  0.100332  0.175779  0.274623   \n",
       "238  0.031597  0.032631  0.036055  0.050084  0.086425  0.139599  0.197102   \n",
       "\n",
       "           f8        f9       f10  ...       f56       f57       f58  \\\n",
       "612  0.246436  0.325305  0.450840  ...  0.383785  0.512663  0.580496   \n",
       "27   0.397261  0.510692  0.642437  ...  0.474338  0.631576  0.724246   \n",
       "568  0.351107  0.458857  0.604437  ...  0.639595  0.760024  0.822052   \n",
       "609  0.360292  0.453749  0.582514  ...  0.599032  0.735785  0.798537   \n",
       "238  0.257314  0.337184  0.455256  ...  0.393861  0.549271  0.650403   \n",
       "\n",
       "          f59       f60       f61       f62  f63  f64    target  \n",
       "612  0.605675  0.596939  0.662752  0.730180    1    0  0.609836  \n",
       "27   0.760365  0.762104  0.555369  0.322262    0    1  0.152262  \n",
       "568  0.839582  0.816573  0.607383  0.636550    1    0  0.648787  \n",
       "609  0.812896  0.789501  0.815436  0.924938    1    0  0.706230  \n",
       "238  0.698242  0.709303  0.622483  0.594256    0    1  0.364590  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy_dataframe = pd.read_excel('X.xlsx')\n",
    "canopy_dataframe = canopy_dataframe.reindex(np.random.permutation(canopy_dataframe.index))\n",
    "canopy_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805, 64)\n"
     ]
    }
   ],
   "source": [
    "X = canopy_dataframe.loc[:, canopy_dataframe.columns != 'target' ].values\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805,)\n"
     ]
    }
   ],
   "source": [
    "y = canopy_dataframe['target'].values\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "history ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,385\n",
      "Trainable params: 8,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.9375 - mae: 0.3789 - mse: 0.2098 - val_loss: 0.7624 - val_mae: 0.2977 - val_mse: 0.1229\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.8203 - mae: 0.3049 - mse: 0.1440 - val_loss: 0.6674 - val_mae: 0.2114 - val_mse: 0.0708\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.7315 - mae: 0.2543 - mse: 0.0986 - val_loss: 0.6028 - val_mae: 0.1682 - val_mse: 0.0466\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.6716 - mae: 0.2294 - mse: 0.0818 - val_loss: 0.5522 - val_mae: 0.1460 - val_mse: 0.0355\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.6221 - mae: 0.2182 - mse: 0.0745 - val_loss: 0.5086 - val_mae: 0.1383 - val_mse: 0.0315\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.5671 - mae: 0.1990 - mse: 0.0621 - val_loss: 0.4692 - val_mae: 0.1264 - val_mse: 0.0261\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.5259 - mae: 0.1854 - mse: 0.0563 - val_loss: 0.4359 - val_mae: 0.1228 - val_mse: 0.0245\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.4896 - mae: 0.1797 - mse: 0.0529 - val_loss: 0.4077 - val_mae: 0.1276 - val_mse: 0.0256\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.4544 - mae: 0.1746 - mse: 0.0492 - val_loss: 0.3811 - val_mae: 0.1299 - val_mse: 0.0259\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.4210 - mae: 0.1639 - mse: 0.0443 - val_loss: 0.3574 - val_mae: 0.1361 - val_mse: 0.0279\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.3896 - mae: 0.1657 - mse: 0.0416 - val_loss: 0.3362 - val_mae: 0.1391 - val_mse: 0.0291\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.3666 - mae: 0.1625 - mse: 0.0434 - val_loss: 0.3166 - val_mae: 0.1477 - val_mse: 0.0325\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.3410 - mae: 0.1638 - mse: 0.0433 - val_loss: 0.2969 - val_mae: 0.1438 - val_mse: 0.0313\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.3196 - mae: 0.1647 - mse: 0.0429 - val_loss: 0.2787 - val_mae: 0.1452 - val_mse: 0.0320\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2932 - mae: 0.1540 - mse: 0.0368 - val_loss: 0.2621 - val_mae: 0.1511 - val_mse: 0.0343\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2735 - mae: 0.1536 - mse: 0.0376 - val_loss: 0.2463 - val_mae: 0.1493 - val_mse: 0.0335\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.2562 - mae: 0.1550 - mse: 0.0382 - val_loss: 0.2319 - val_mae: 0.1512 - val_mse: 0.0341\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2415 - mae: 0.1611 - mse: 0.0390 - val_loss: 0.2201 - val_mae: 0.1545 - val_mse: 0.0353\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.2287 - mae: 0.1626 - mse: 0.0403 - val_loss: 0.2083 - val_mae: 0.1538 - val_mse: 0.0349\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.2163 - mae: 0.1603 - mse: 0.0409 - val_loss: 0.1974 - val_mae: 0.1523 - val_mse: 0.0342\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2051 - mae: 0.1578 - mse: 0.0390 - val_loss: 0.1904 - val_mae: 0.1593 - val_mse: 0.0367\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1974 - mae: 0.1647 - mse: 0.0415 - val_loss: 0.1831 - val_mae: 0.1559 - val_mse: 0.0353\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1896 - mae: 0.1624 - mse: 0.0398 - val_loss: 0.1758 - val_mae: 0.1470 - val_mse: 0.0318\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1855 - mae: 0.1627 - mse: 0.0412 - val_loss: 0.1704 - val_mae: 0.1466 - val_mse: 0.0317\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1779 - mae: 0.1577 - mse: 0.0384 - val_loss: 0.1649 - val_mae: 0.1394 - val_mse: 0.0290\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1723 - mae: 0.1548 - mse: 0.0360 - val_loss: 0.1603 - val_mae: 0.1388 - val_mse: 0.0288\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1697 - mae: 0.1573 - mse: 0.0390 - val_loss: 0.1560 - val_mae: 0.1364 - val_mse: 0.0280\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1610 - mae: 0.1445 - mse: 0.0323 - val_loss: 0.1515 - val_mae: 0.1306 - val_mse: 0.0260\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1590 - mae: 0.1453 - mse: 0.0331 - val_loss: 0.1485 - val_mae: 0.1369 - val_mse: 0.0280\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1544 - mae: 0.1472 - mse: 0.0328 - val_loss: 0.1444 - val_mae: 0.1287 - val_mse: 0.0252\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1516 - mae: 0.1452 - mse: 0.0327 - val_loss: 0.1406 - val_mae: 0.1196 - val_mse: 0.0223\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1475 - mae: 0.1380 - mse: 0.0299 - val_loss: 0.1378 - val_mae: 0.1220 - val_mse: 0.0230\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.1449 - mae: 0.1394 - mse: 0.0302 - val_loss: 0.1350 - val_mae: 0.1219 - val_mse: 0.0229\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.1417 - mae: 0.1425 - mse: 0.0307 - val_loss: 0.1315 - val_mae: 0.1138 - val_mse: 0.0204\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.1386 - mae: 0.1363 - mse: 0.0285 - val_loss: 0.1288 - val_mae: 0.1160 - val_mse: 0.0210\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1349 - mae: 0.1331 - mse: 0.0277 - val_loss: 0.1260 - val_mae: 0.1132 - val_mse: 0.0202\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1308 - mae: 0.1261 - mse: 0.0252 - val_loss: 0.1231 - val_mae: 0.1109 - val_mse: 0.0194\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1284 - mae: 0.1258 - mse: 0.0252 - val_loss: 0.1203 - val_mae: 0.1086 - val_mse: 0.0187\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.1253 - mae: 0.1242 - mse: 0.0240 - val_loss: 0.1177 - val_mae: 0.1056 - val_mse: 0.0178\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1229 - mae: 0.1243 - mse: 0.0243 - val_loss: 0.1153 - val_mae: 0.1052 - val_mse: 0.0178\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1201 - mae: 0.1202 - mse: 0.0231 - val_loss: 0.1129 - val_mae: 0.1046 - val_mse: 0.0177\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.1189 - mae: 0.1224 - mse: 0.0244 - val_loss: 0.1108 - val_mae: 0.1052 - val_mse: 0.0178\n",
      "Epoch 43/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.1146 - mae: 0.1159 - mse: 0.0216 - val_loss: 0.1082 - val_mae: 0.0978 - val_mse: 0.0156\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1134 - mae: 0.1170 - mse: 0.0218 - val_loss: 0.1063 - val_mae: 0.1005 - val_mse: 0.0164\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1103 - mae: 0.1132 - mse: 0.0203 - val_loss: 0.1041 - val_mae: 0.0982 - val_mse: 0.0156\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1092 - mae: 0.1154 - mse: 0.0213 - val_loss: 0.1022 - val_mae: 0.0976 - val_mse: 0.0155\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1078 - mae: 0.1172 - mse: 0.0220 - val_loss: 0.1004 - val_mae: 0.0983 - val_mse: 0.0157\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1052 - mae: 0.1134 - mse: 0.0204 - val_loss: 0.0986 - val_mae: 0.0989 - val_mse: 0.0158\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1028 - mae: 0.1135 - mse: 0.0201 - val_loss: 0.0967 - val_mae: 0.0948 - val_mse: 0.0146\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1009 - mae: 0.1094 - mse: 0.0188 - val_loss: 0.0950 - val_mae: 0.0963 - val_mse: 0.0150\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0988 - mae: 0.1072 - mse: 0.0187 - val_loss: 0.0932 - val_mae: 0.0958 - val_mse: 0.0149\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0973 - mae: 0.1079 - mse: 0.0187 - val_loss: 0.0915 - val_mae: 0.0931 - val_mse: 0.0141\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0963 - mae: 0.1073 - mse: 0.0187 - val_loss: 0.0899 - val_mae: 0.0947 - val_mse: 0.0146\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0945 - mae: 0.1094 - mse: 0.0190 - val_loss: 0.0881 - val_mae: 0.0896 - val_mse: 0.0131\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0940 - mae: 0.1095 - mse: 0.0196 - val_loss: 0.0866 - val_mae: 0.0903 - val_mse: 0.0133\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0912 - mae: 0.1064 - mse: 0.0180 - val_loss: 0.0850 - val_mae: 0.0885 - val_mse: 0.0128\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0901 - mae: 0.1059 - mse: 0.0184 - val_loss: 0.0835 - val_mae: 0.0857 - val_mse: 0.0121\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0875 - mae: 0.1028 - mse: 0.0167 - val_loss: 0.0823 - val_mae: 0.0905 - val_mse: 0.0136\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0872 - mae: 0.1059 - mse: 0.0184 - val_loss: 0.0808 - val_mae: 0.0897 - val_mse: 0.0134\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0855 - mae: 0.1047 - mse: 0.0179 - val_loss: 0.0794 - val_mae: 0.0884 - val_mse: 0.0130\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0841 - mae: 0.1029 - mse: 0.0177 - val_loss: 0.0778 - val_mae: 0.0856 - val_mse: 0.0122\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0828 - mae: 0.1041 - mse: 0.0172 - val_loss: 0.0764 - val_mae: 0.0840 - val_mse: 0.0117\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 209us/step - loss: 0.0812 - mae: 0.1003 - mse: 0.0164 - val_loss: 0.0753 - val_mae: 0.0871 - val_mse: 0.0127\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0804 - mae: 0.1050 - mse: 0.0178 - val_loss: 0.0740 - val_mae: 0.0865 - val_mse: 0.0125\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0790 - mae: 0.1028 - mse: 0.0174 - val_loss: 0.0726 - val_mae: 0.0837 - val_mse: 0.0117\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0766 - mae: 0.0996 - mse: 0.0158 - val_loss: 0.0712 - val_mae: 0.0829 - val_mse: 0.0114\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0753 - mae: 0.0980 - mse: 0.0154 - val_loss: 0.0702 - val_mae: 0.0844 - val_mse: 0.0119\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0752 - mae: 0.1008 - mse: 0.0169 - val_loss: 0.0690 - val_mae: 0.0825 - val_mse: 0.0114\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0741 - mae: 0.0990 - mse: 0.0161 - val_loss: 0.0680 - val_mae: 0.0821 - val_mse: 0.0113\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0728 - mae: 0.0993 - mse: 0.0165 - val_loss: 0.0668 - val_mae: 0.0795 - val_mse: 0.0106\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0716 - mae: 0.0961 - mse: 0.0154 - val_loss: 0.0658 - val_mae: 0.0808 - val_mse: 0.0110\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0709 - mae: 0.0988 - mse: 0.0160 - val_loss: 0.0649 - val_mae: 0.0837 - val_mse: 0.0119\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0697 - mae: 0.1003 - mse: 0.0167 - val_loss: 0.0638 - val_mae: 0.0829 - val_mse: 0.0117\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0669 - mae: 0.0926 - mse: 0.0147 - val_loss: 0.0626 - val_mae: 0.0806 - val_mse: 0.0111\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0662 - mae: 0.0932 - mse: 0.0146 - val_loss: 0.0616 - val_mae: 0.0808 - val_mse: 0.0112\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0661 - mae: 0.0954 - mse: 0.0156 - val_loss: 0.0607 - val_mae: 0.0821 - val_mse: 0.0116\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 185us/step - loss: 0.0652 - mae: 0.0963 - mse: 0.0156 - val_loss: 0.0599 - val_mae: 0.0842 - val_mse: 0.0122\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0643 - mae: 0.0979 - mse: 0.0159 - val_loss: 0.0585 - val_mae: 0.0800 - val_mse: 0.0109\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0629 - mae: 0.0954 - mse: 0.0152 - val_loss: 0.0576 - val_mae: 0.0799 - val_mse: 0.0110\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0622 - mae: 0.0952 - mse: 0.0157 - val_loss: 0.0568 - val_mae: 0.0807 - val_mse: 0.0113\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0604 - mae: 0.0910 - mse: 0.0142 - val_loss: 0.0561 - val_mae: 0.0819 - val_mse: 0.0117\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0588 - mae: 0.0903 - mse: 0.0136 - val_loss: 0.0546 - val_mae: 0.0747 - val_mse: 0.0097\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0589 - mae: 0.0908 - mse: 0.0140 - val_loss: 0.0543 - val_mae: 0.0804 - val_mse: 0.0113\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0581 - mae: 0.0926 - mse: 0.0144 - val_loss: 0.0532 - val_mae: 0.0755 - val_mse: 0.0100\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0578 - mae: 0.0911 - mse: 0.0144 - val_loss: 0.0524 - val_mae: 0.0756 - val_mse: 0.0100\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0575 - mae: 0.0924 - mse: 0.0147 - val_loss: 0.0517 - val_mae: 0.0752 - val_mse: 0.0100\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0562 - mae: 0.0927 - mse: 0.0143 - val_loss: 0.0510 - val_mae: 0.0760 - val_mse: 0.0102\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0539 - mae: 0.0880 - mse: 0.0128 - val_loss: 0.0501 - val_mae: 0.0732 - val_mse: 0.0094\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0540 - mae: 0.0885 - mse: 0.0131 - val_loss: 0.0496 - val_mae: 0.0761 - val_mse: 0.0101\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0535 - mae: 0.0906 - mse: 0.0143 - val_loss: 0.0488 - val_mae: 0.0729 - val_mse: 0.0093\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0529 - mae: 0.0890 - mse: 0.0137 - val_loss: 0.0482 - val_mae: 0.0761 - val_mse: 0.0102\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0530 - mae: 0.0919 - mse: 0.0144 - val_loss: 0.0476 - val_mae: 0.0756 - val_mse: 0.0101\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0515 - mae: 0.0888 - mse: 0.0135 - val_loss: 0.0466 - val_mae: 0.0716 - val_mse: 0.0089\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0490 - mae: 0.0820 - mse: 0.0111 - val_loss: 0.0461 - val_mae: 0.0738 - val_mse: 0.0096\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0500 - mae: 0.0870 - mse: 0.0132 - val_loss: 0.0455 - val_mae: 0.0714 - val_mse: 0.0092\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0494 - mae: 0.0868 - mse: 0.0130 - val_loss: 0.0453 - val_mae: 0.0762 - val_mse: 0.0104\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0490 - mae: 0.0906 - mse: 0.0138 - val_loss: 0.0443 - val_mae: 0.0709 - val_mse: 0.0089\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0492 - mae: 0.0892 - mse: 0.0138 - val_loss: 0.0438 - val_mae: 0.0729 - val_mse: 0.0094\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 127us/step - loss: 0.0468 - mae: 0.0837 - mse: 0.0123 - val_loss: 0.0432 - val_mae: 0.0724 - val_mse: 0.0093\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0472 - mae: 0.0867 - mse: 0.0128 - val_loss: 0.0425 - val_mae: 0.0700 - val_mse: 0.0088\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0465 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0421 - val_mae: 0.0719 - val_mse: 0.0093\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0467 - mae: 0.0889 - mse: 0.0136 - val_loss: 0.0416 - val_mae: 0.0708 - val_mse: 0.0090\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0459 - mae: 0.0883 - mse: 0.0133 - val_loss: 0.0413 - val_mae: 0.0736 - val_mse: 0.0098\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0444 - mae: 0.0852 - mse: 0.0125 - val_loss: 0.0406 - val_mae: 0.0688 - val_mse: 0.0083\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0445 - mae: 0.0861 - mse: 0.0122 - val_loss: 0.0401 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0437 - mae: 0.0843 - mse: 0.0121 - val_loss: 0.0397 - val_mae: 0.0707 - val_mse: 0.0091\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0435 - mae: 0.0869 - mse: 0.0125 - val_loss: 0.0392 - val_mae: 0.0678 - val_mse: 0.0081\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0431 - mae: 0.0851 - mse: 0.0122 - val_loss: 0.0389 - val_mae: 0.0702 - val_mse: 0.0089\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0437 - mae: 0.0890 - mse: 0.0136 - val_loss: 0.0385 - val_mae: 0.0713 - val_mse: 0.0091\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0428 - mae: 0.0852 - mse: 0.0131 - val_loss: 0.0382 - val_mae: 0.0722 - val_mse: 0.0092\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0448 - mae: 0.0924 - mse: 0.0154 - val_loss: 0.0379 - val_mae: 0.0726 - val_mse: 0.0093\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0420 - mae: 0.0845 - mse: 0.0128 - val_loss: 0.0373 - val_mae: 0.0701 - val_mse: 0.0089\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0415 - mae: 0.0879 - mse: 0.0128 - val_loss: 0.0371 - val_mae: 0.0704 - val_mse: 0.0086\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mae: 0.0853 - mse: 0.0126 - val_loss: 0.0368 - val_mae: 0.0725 - val_mse: 0.0095\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0406 - mae: 0.0858 - mse: 0.0127 - val_loss: 0.0363 - val_mae: 0.0674 - val_mse: 0.0081\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0406 - mae: 0.0841 - mse: 0.0124 - val_loss: 0.0359 - val_mae: 0.0689 - val_mse: 0.0087\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0399 - mae: 0.0841 - mse: 0.0123 - val_loss: 0.0356 - val_mae: 0.0691 - val_mse: 0.0087\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0398 - mae: 0.0870 - mse: 0.0128 - val_loss: 0.0354 - val_mae: 0.0663 - val_mse: 0.0078\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0401 - mae: 0.0836 - mse: 0.0124 - val_loss: 0.0350 - val_mae: 0.0674 - val_mse: 0.0079\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0388 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0346 - val_mae: 0.0696 - val_mse: 0.0087\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0385 - mae: 0.0842 - mse: 0.0121 - val_loss: 0.0346 - val_mae: 0.0719 - val_mse: 0.0093\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0380 - mae: 0.0819 - mse: 0.0121 - val_loss: 0.0342 - val_mae: 0.0694 - val_mse: 0.0086\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0382 - mae: 0.0850 - mse: 0.0123 - val_loss: 0.0339 - val_mae: 0.0696 - val_mse: 0.0084\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0380 - mae: 0.0857 - mse: 0.0123 - val_loss: 0.0335 - val_mae: 0.0690 - val_mse: 0.0085\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0371 - mae: 0.0817 - mse: 0.0119 - val_loss: 0.0333 - val_mae: 0.0691 - val_mse: 0.0084\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0379 - mae: 0.0869 - mse: 0.0129 - val_loss: 0.0332 - val_mae: 0.0703 - val_mse: 0.0089\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0364 - mae: 0.0831 - mse: 0.0118 - val_loss: 0.0332 - val_mae: 0.0720 - val_mse: 0.0093\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0368 - mae: 0.0847 - mse: 0.0125 - val_loss: 0.0329 - val_mae: 0.0713 - val_mse: 0.0093\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0366 - mae: 0.0849 - mse: 0.0123 - val_loss: 0.0324 - val_mae: 0.0691 - val_mse: 0.0087\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0366 - mae: 0.0843 - mse: 0.0124 - val_loss: 0.0324 - val_mae: 0.0700 - val_mse: 0.0086\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0363 - mae: 0.0842 - mse: 0.0122 - val_loss: 0.0321 - val_mae: 0.0695 - val_mse: 0.0087\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0359 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0318 - val_mae: 0.0705 - val_mse: 0.0091\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0346 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0318 - val_mae: 0.0723 - val_mse: 0.0095\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0363 - mae: 0.0900 - mse: 0.0135 - val_loss: 0.0314 - val_mae: 0.0685 - val_mse: 0.0084\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0350 - mae: 0.0825 - mse: 0.0115 - val_loss: 0.0314 - val_mae: 0.0716 - val_mse: 0.0093\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0335 - mae: 0.0785 - mse: 0.0106 - val_loss: 0.0312 - val_mae: 0.0706 - val_mse: 0.0090\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0338 - mae: 0.0805 - mse: 0.0109 - val_loss: 0.0310 - val_mae: 0.0709 - val_mse: 0.0090\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0344 - mae: 0.0819 - mse: 0.0117 - val_loss: 0.0304 - val_mae: 0.0666 - val_mse: 0.0080\n",
      "Epoch 139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.0334 - mae: 0.0792 - mse: 0.0107 - val_loss: 0.0302 - val_mae: 0.0660 - val_mse: 0.0077\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0341 - mae: 0.0825 - mse: 0.0114 - val_loss: 0.0303 - val_mae: 0.0697 - val_mse: 0.0084\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0338 - mae: 0.0815 - mse: 0.0118 - val_loss: 0.0302 - val_mae: 0.0703 - val_mse: 0.0085\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0333 - mae: 0.0802 - mse: 0.0110 - val_loss: 0.0297 - val_mae: 0.0677 - val_mse: 0.0082\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0331 - mae: 0.0812 - mse: 0.0111 - val_loss: 0.0296 - val_mae: 0.0676 - val_mse: 0.0080\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0331 - mae: 0.0817 - mse: 0.0114 - val_loss: 0.0293 - val_mae: 0.0661 - val_mse: 0.0077\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0339 - mae: 0.0823 - mse: 0.0122 - val_loss: 0.0292 - val_mae: 0.0673 - val_mse: 0.0080\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0332 - mae: 0.0823 - mse: 0.0116 - val_loss: 0.0290 - val_mae: 0.0668 - val_mse: 0.0079\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0323 - mae: 0.0789 - mse: 0.0108 - val_loss: 0.0288 - val_mae: 0.0669 - val_mse: 0.0079\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0329 - mae: 0.0823 - mse: 0.0117 - val_loss: 0.0288 - val_mae: 0.0692 - val_mse: 0.0085\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0326 - mae: 0.0833 - mse: 0.0117 - val_loss: 0.0286 - val_mae: 0.0679 - val_mse: 0.0081\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0325 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0284 - val_mae: 0.0678 - val_mse: 0.0081\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0325 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0286 - val_mae: 0.0704 - val_mse: 0.0088\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0318 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0283 - val_mae: 0.0690 - val_mse: 0.0085\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0315 - mae: 0.0805 - mse: 0.0113 - val_loss: 0.0282 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0311 - mae: 0.0815 - mse: 0.0111 - val_loss: 0.0277 - val_mae: 0.0656 - val_mse: 0.0076\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0306 - mae: 0.0774 - mse: 0.0101 - val_loss: 0.0276 - val_mae: 0.0680 - val_mse: 0.0079\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0313 - mae: 0.0805 - mse: 0.0111 - val_loss: 0.0277 - val_mae: 0.0700 - val_mse: 0.0085\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0316 - mae: 0.0840 - mse: 0.0118 - val_loss: 0.0277 - val_mae: 0.0693 - val_mse: 0.0081\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0312 - mae: 0.0798 - mse: 0.0115 - val_loss: 0.0273 - val_mae: 0.0674 - val_mse: 0.0078\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0312 - mae: 0.0789 - mse: 0.0114 - val_loss: 0.0275 - val_mae: 0.0714 - val_mse: 0.0087\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0311 - mae: 0.0826 - mse: 0.0119 - val_loss: 0.0275 - val_mae: 0.0722 - val_mse: 0.0091\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0306 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0271 - val_mae: 0.0691 - val_mse: 0.0083\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0306 - mae: 0.0819 - mse: 0.0116 - val_loss: 0.0270 - val_mae: 0.0708 - val_mse: 0.0089\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0299 - mae: 0.0792 - mse: 0.0110 - val_loss: 0.0268 - val_mae: 0.0692 - val_mse: 0.0085\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0309 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0266 - val_mae: 0.0694 - val_mse: 0.0086\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0301 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0264 - val_mae: 0.0673 - val_mse: 0.0080\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0297 - mae: 0.0782 - mse: 0.0109 - val_loss: 0.0263 - val_mae: 0.0665 - val_mse: 0.0078\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0292 - mae: 0.0770 - mse: 0.0101 - val_loss: 0.0262 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0293 - mae: 0.0803 - mse: 0.0110 - val_loss: 0.0261 - val_mae: 0.0667 - val_mse: 0.0077\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0302 - mae: 0.0812 - mse: 0.0118 - val_loss: 0.0260 - val_mae: 0.0701 - val_mse: 0.0087\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0295 - mae: 0.0817 - mse: 0.0116 - val_loss: 0.0257 - val_mae: 0.0661 - val_mse: 0.0077\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0284 - mae: 0.0753 - mse: 0.0098 - val_loss: 0.0255 - val_mae: 0.0649 - val_mse: 0.0074\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0291 - mae: 0.0792 - mse: 0.0107 - val_loss: 0.0254 - val_mae: 0.0669 - val_mse: 0.0078\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0282 - mae: 0.0776 - mse: 0.0103 - val_loss: 0.0254 - val_mae: 0.0690 - val_mse: 0.0083\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0288 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0252 - val_mae: 0.0671 - val_mse: 0.0077\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0280 - mae: 0.0771 - mse: 0.0103 - val_loss: 0.0250 - val_mae: 0.0676 - val_mse: 0.0078\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0287 - mae: 0.0814 - mse: 0.0111 - val_loss: 0.0248 - val_mae: 0.0676 - val_mse: 0.0078\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0290 - mae: 0.0803 - mse: 0.0117 - val_loss: 0.0250 - val_mae: 0.0700 - val_mse: 0.0084\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0274 - mae: 0.0777 - mse: 0.0103 - val_loss: 0.0246 - val_mae: 0.0671 - val_mse: 0.0079\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0275 - mae: 0.0782 - mse: 0.0101 - val_loss: 0.0245 - val_mae: 0.0679 - val_mse: 0.0081\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0279 - mae: 0.0789 - mse: 0.0107 - val_loss: 0.0244 - val_mae: 0.0675 - val_mse: 0.0079\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0294 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0245 - val_mae: 0.0688 - val_mse: 0.0083\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0276 - mae: 0.0777 - mse: 0.0108 - val_loss: 0.0243 - val_mae: 0.0692 - val_mse: 0.0083\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0274 - mae: 0.0794 - mse: 0.0110 - val_loss: 0.0241 - val_mae: 0.0689 - val_mse: 0.0081\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0281 - mae: 0.0832 - mse: 0.0118 - val_loss: 0.0240 - val_mae: 0.0676 - val_mse: 0.0080\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0270 - mae: 0.0783 - mse: 0.0104 - val_loss: 0.0237 - val_mae: 0.0661 - val_mse: 0.0075\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0276 - mae: 0.0799 - mse: 0.0109 - val_loss: 0.0238 - val_mae: 0.0676 - val_mse: 0.0079\n",
      "Epoch 187/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0271 - mae: 0.0793 - mse: 0.0106 - val_loss: 0.0238 - val_mae: 0.0689 - val_mse: 0.0080\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0272 - mae: 0.0803 - mse: 0.0113 - val_loss: 0.0237 - val_mae: 0.0687 - val_mse: 0.0079\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0270 - mae: 0.0802 - mse: 0.0109 - val_loss: 0.0236 - val_mae: 0.0693 - val_mse: 0.0080\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0273 - mae: 0.0805 - mse: 0.0110 - val_loss: 0.0234 - val_mae: 0.0688 - val_mse: 0.0081\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0270 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0232 - val_mae: 0.0642 - val_mse: 0.0071\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0275 - mae: 0.0820 - mse: 0.0111 - val_loss: 0.0229 - val_mae: 0.0655 - val_mse: 0.0074\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0268 - mae: 0.0802 - mse: 0.0109 - val_loss: 0.0230 - val_mae: 0.0652 - val_mse: 0.0072\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0268 - mae: 0.0784 - mse: 0.0107 - val_loss: 0.0229 - val_mae: 0.0683 - val_mse: 0.0079\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0271 - mae: 0.0841 - mse: 0.0116 - val_loss: 0.0231 - val_mae: 0.0718 - val_mse: 0.0088\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0271 - mae: 0.0839 - mse: 0.0120 - val_loss: 0.0228 - val_mae: 0.0676 - val_mse: 0.0075\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0783 - mse: 0.0106 - val_loss: 0.0228 - val_mae: 0.0691 - val_mse: 0.0079\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0801 - mse: 0.0111 - val_loss: 0.0226 - val_mae: 0.0683 - val_mse: 0.0077\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0266 - mae: 0.0815 - mse: 0.0113 - val_loss: 0.0224 - val_mae: 0.0667 - val_mse: 0.0074\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0259 - mae: 0.0786 - mse: 0.0105 - val_loss: 0.0225 - val_mae: 0.0675 - val_mse: 0.0077\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0268 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0223 - val_mae: 0.0686 - val_mse: 0.0079\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0259 - mae: 0.0791 - mse: 0.0109 - val_loss: 0.0222 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0253 - mae: 0.0773 - mse: 0.0103 - val_loss: 0.0221 - val_mae: 0.0642 - val_mse: 0.0069\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0256 - mae: 0.0792 - mse: 0.0103 - val_loss: 0.0221 - val_mae: 0.0685 - val_mse: 0.0078\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0264 - mae: 0.0830 - mse: 0.0117 - val_loss: 0.0219 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0258 - mae: 0.0786 - mse: 0.0110 - val_loss: 0.0218 - val_mae: 0.0659 - val_mse: 0.0072\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0259 - mae: 0.0811 - mse: 0.0113 - val_loss: 0.0218 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0261 - mae: 0.0829 - mse: 0.0116 - val_loss: 0.0218 - val_mae: 0.0682 - val_mse: 0.0076\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0260 - mae: 0.0827 - mse: 0.0116 - val_loss: 0.0216 - val_mae: 0.0669 - val_mse: 0.0073\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0254 - mae: 0.0794 - mse: 0.0108 - val_loss: 0.0215 - val_mae: 0.0669 - val_mse: 0.0074\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0257 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0214 - val_mae: 0.0684 - val_mse: 0.0078\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0250 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0214 - val_mae: 0.0688 - val_mse: 0.0080\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0257 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0210 - val_mae: 0.0647 - val_mse: 0.0071\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0253 - mae: 0.0784 - mse: 0.0113 - val_loss: 0.0211 - val_mae: 0.0676 - val_mse: 0.0077\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0255 - mae: 0.0810 - mse: 0.0116 - val_loss: 0.0215 - val_mae: 0.0721 - val_mse: 0.0089\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0247 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0210 - val_mae: 0.0692 - val_mse: 0.0080\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0252 - mae: 0.0804 - mse: 0.0114 - val_loss: 0.0210 - val_mae: 0.0688 - val_mse: 0.0080\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0250 - mae: 0.0805 - mse: 0.0113 - val_loss: 0.0208 - val_mae: 0.0671 - val_mse: 0.0075\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0240 - mae: 0.0774 - mse: 0.0100 - val_loss: 0.0208 - val_mae: 0.0681 - val_mse: 0.0076\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0250 - mae: 0.0809 - mse: 0.0113 - val_loss: 0.0207 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0242 - mae: 0.0766 - mse: 0.0104 - val_loss: 0.0209 - val_mae: 0.0695 - val_mse: 0.0081\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0239 - mae: 0.0782 - mse: 0.0105 - val_loss: 0.0207 - val_mae: 0.0693 - val_mse: 0.0079\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0249 - mae: 0.0817 - mse: 0.0116 - val_loss: 0.0204 - val_mae: 0.0679 - val_mse: 0.0076\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0246 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0204 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0247 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0204 - val_mae: 0.0687 - val_mse: 0.0078\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0242 - mae: 0.0808 - mse: 0.0112 - val_loss: 0.0203 - val_mae: 0.0670 - val_mse: 0.0074\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0238 - mae: 0.0783 - mse: 0.0105 - val_loss: 0.0203 - val_mae: 0.0695 - val_mse: 0.0080\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0242 - mae: 0.0812 - mse: 0.0111 - val_loss: 0.0199 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0240 - mae: 0.0802 - mse: 0.0108 - val_loss: 0.0200 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0239 - mae: 0.0783 - mse: 0.0110 - val_loss: 0.0200 - val_mae: 0.0676 - val_mse: 0.0075\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0236 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0201 - val_mae: 0.0704 - val_mse: 0.0083\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0237 - mae: 0.0803 - mse: 0.0112 - val_loss: 0.0197 - val_mae: 0.0668 - val_mse: 0.0074\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0240 - mae: 0.0819 - mse: 0.0114 - val_loss: 0.0197 - val_mae: 0.0685 - val_mse: 0.0077\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0241 - mae: 0.0822 - mse: 0.0114 - val_loss: 0.0198 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 124us/step - loss: 0.0235 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0194 - val_mae: 0.0659 - val_mse: 0.0072\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0238 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0195 - val_mae: 0.0667 - val_mse: 0.0073\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0235 - mae: 0.0783 - mse: 0.0109 - val_loss: 0.0193 - val_mae: 0.0662 - val_mse: 0.0073\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0244 - mae: 0.0824 - mse: 0.0121 - val_loss: 0.0196 - val_mae: 0.0693 - val_mse: 0.0078\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0231 - mae: 0.0785 - mse: 0.0107 - val_loss: 0.0193 - val_mae: 0.0682 - val_mse: 0.0077\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0232 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0192 - val_mae: 0.0673 - val_mse: 0.0076\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0240 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0195 - val_mae: 0.0704 - val_mse: 0.0082\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0236 - mae: 0.0835 - mse: 0.0115 - val_loss: 0.0193 - val_mae: 0.0671 - val_mse: 0.0073\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0236 - mae: 0.0821 - mse: 0.0113 - val_loss: 0.0195 - val_mae: 0.0711 - val_mse: 0.0083\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0227 - mae: 0.0796 - mse: 0.0107 - val_loss: 0.0192 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0227 - mae: 0.0797 - mse: 0.0107 - val_loss: 0.0190 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0222 - mae: 0.0758 - mse: 0.0101 - val_loss: 0.0190 - val_mae: 0.0675 - val_mse: 0.0076\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0233 - mae: 0.0820 - mse: 0.0115 - val_loss: 0.0189 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0231 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0189 - val_mae: 0.0695 - val_mse: 0.0080\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 132us/step - loss: 0.0230 - mae: 0.0811 - mse: 0.0114 - val_loss: 0.0190 - val_mae: 0.0705 - val_mse: 0.0082\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0230 - mae: 0.0830 - mse: 0.0115 - val_loss: 0.0187 - val_mae: 0.0660 - val_mse: 0.0071\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0233 - mae: 0.0819 - mse: 0.0116 - val_loss: 0.0192 - val_mae: 0.0731 - val_mse: 0.0088\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0234 - mae: 0.0845 - mse: 0.0124 - val_loss: 0.0188 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0230 - mae: 0.0813 - mse: 0.0114 - val_loss: 0.0187 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0227 - mae: 0.0811 - mse: 0.0111 - val_loss: 0.0188 - val_mae: 0.0692 - val_mse: 0.0076\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0230 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0188 - val_mae: 0.0711 - val_mse: 0.0081\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0236 - mae: 0.0839 - mse: 0.0123 - val_loss: 0.0186 - val_mae: 0.0703 - val_mse: 0.0081\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0222 - mae: 0.0804 - mse: 0.0111 - val_loss: 0.0187 - val_mae: 0.0715 - val_mse: 0.0085\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0233 - mae: 0.0835 - mse: 0.0123 - val_loss: 0.0185 - val_mae: 0.0706 - val_mse: 0.0083\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0223 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0184 - val_mae: 0.0685 - val_mse: 0.0077\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0222 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0184 - val_mae: 0.0684 - val_mse: 0.0077\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0225 - mae: 0.0798 - mse: 0.0114 - val_loss: 0.0186 - val_mae: 0.0716 - val_mse: 0.0084\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0218 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0183 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0229 - mae: 0.0818 - mse: 0.0117 - val_loss: 0.0183 - val_mae: 0.0684 - val_mse: 0.0077\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0224 - mae: 0.0819 - mse: 0.0115 - val_loss: 0.0185 - val_mae: 0.0717 - val_mse: 0.0084\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0225 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0184 - val_mae: 0.0703 - val_mse: 0.0080\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0229 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0187 - val_mae: 0.0735 - val_mse: 0.0088\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0225 - mae: 0.0832 - mse: 0.0119 - val_loss: 0.0181 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0222 - mae: 0.0796 - mse: 0.0111 - val_loss: 0.0183 - val_mae: 0.0702 - val_mse: 0.0080\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0224 - mae: 0.0798 - mse: 0.0116 - val_loss: 0.0181 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0217 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0180 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0224 - mae: 0.0806 - mse: 0.0117 - val_loss: 0.0181 - val_mae: 0.0698 - val_mse: 0.0080\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0225 - mae: 0.0828 - mse: 0.0119 - val_loss: 0.0178 - val_mae: 0.0680 - val_mse: 0.0077\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0228 - mae: 0.0838 - mse: 0.0122 - val_loss: 0.0180 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0225 - mae: 0.0822 - mse: 0.0119 - val_loss: 0.0179 - val_mae: 0.0686 - val_mse: 0.0077\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0220 - mae: 0.0813 - mse: 0.0114 - val_loss: 0.0177 - val_mae: 0.0676 - val_mse: 0.0076\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0219 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0180 - val_mae: 0.0704 - val_mse: 0.0082\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0223 - mae: 0.0818 - mse: 0.0120 - val_loss: 0.0179 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0229 - mae: 0.0848 - mse: 0.0123 - val_loss: 0.0179 - val_mae: 0.0702 - val_mse: 0.0082\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0225 - mae: 0.0839 - mse: 0.0124 - val_loss: 0.0180 - val_mae: 0.0711 - val_mse: 0.0082\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0222 - mae: 0.0830 - mse: 0.0119 - val_loss: 0.0176 - val_mae: 0.0690 - val_mse: 0.0079\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0218 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0175 - val_mae: 0.0661 - val_mse: 0.0072\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0219 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0174 - val_mae: 0.0674 - val_mse: 0.0075\n",
      "Epoch 283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.0224 - mae: 0.0831 - mse: 0.0119 - val_loss: 0.0178 - val_mae: 0.0706 - val_mse: 0.0080\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0220 - mae: 0.0820 - mse: 0.0116 - val_loss: 0.0176 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0218 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0175 - val_mae: 0.0674 - val_mse: 0.0074\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0222 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0175 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0217 - mae: 0.0797 - mse: 0.0111 - val_loss: 0.0177 - val_mae: 0.0709 - val_mse: 0.0082\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0176 - val_mae: 0.0702 - val_mse: 0.0080\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0223 - mae: 0.0829 - mse: 0.0121 - val_loss: 0.0175 - val_mae: 0.0709 - val_mse: 0.0083\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0223 - mae: 0.0834 - mse: 0.0123 - val_loss: 0.0178 - val_mae: 0.0727 - val_mse: 0.0084\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0222 - mae: 0.0835 - mse: 0.0122 - val_loss: 0.0175 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0213 - mae: 0.0799 - mse: 0.0110 - val_loss: 0.0175 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0818 - mse: 0.0113 - val_loss: 0.0174 - val_mae: 0.0698 - val_mse: 0.0078\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0223 - mae: 0.0856 - mse: 0.0124 - val_loss: 0.0173 - val_mae: 0.0694 - val_mse: 0.0078\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0216 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0174 - val_mae: 0.0705 - val_mse: 0.0081\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0225 - mae: 0.0854 - mse: 0.0127 - val_loss: 0.0174 - val_mae: 0.0695 - val_mse: 0.0077\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0223 - mae: 0.0836 - mse: 0.0123 - val_loss: 0.0175 - val_mae: 0.0725 - val_mse: 0.0086\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0811 - mse: 0.0113 - val_loss: 0.0173 - val_mae: 0.0686 - val_mse: 0.0075\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0220 - mae: 0.0823 - mse: 0.0119 - val_loss: 0.0175 - val_mae: 0.0720 - val_mse: 0.0085\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0171 - val_mae: 0.0671 - val_mse: 0.0074\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0226 - mae: 0.0852 - mse: 0.0128 - val_loss: 0.0172 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0220 - mae: 0.0840 - mse: 0.0121 - val_loss: 0.0172 - val_mae: 0.0697 - val_mse: 0.0078\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0216 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0172 - val_mae: 0.0712 - val_mse: 0.0082\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0210 - mae: 0.0806 - mse: 0.0112 - val_loss: 0.0169 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0214 - mae: 0.0818 - mse: 0.0118 - val_loss: 0.0171 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0219 - mae: 0.0832 - mse: 0.0122 - val_loss: 0.0169 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0225 - mae: 0.0852 - mse: 0.0128 - val_loss: 0.0172 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0825 - mse: 0.0119 - val_loss: 0.0170 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0213 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0169 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0218 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0167 - val_mae: 0.0666 - val_mse: 0.0072\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0220 - mae: 0.0847 - mse: 0.0124 - val_loss: 0.0171 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0214 - mae: 0.0826 - mse: 0.0117 - val_loss: 0.0168 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0217 - mae: 0.0835 - mse: 0.0120 - val_loss: 0.0170 - val_mae: 0.0709 - val_mse: 0.0081\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0218 - mae: 0.0838 - mse: 0.0125 - val_loss: 0.0173 - val_mae: 0.0732 - val_mse: 0.0087\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0829 - mse: 0.0118 - val_loss: 0.0170 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0216 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0169 - val_mae: 0.0714 - val_mse: 0.0083\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0210 - mae: 0.0817 - mse: 0.0117 - val_loss: 0.0172 - val_mae: 0.0730 - val_mse: 0.0086\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0211 - mae: 0.0811 - mse: 0.0117 - val_loss: 0.0170 - val_mae: 0.0721 - val_mse: 0.0083\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0215 - mae: 0.0839 - mse: 0.0123 - val_loss: 0.0170 - val_mae: 0.0725 - val_mse: 0.0085\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0213 - mae: 0.0847 - mse: 0.0123 - val_loss: 0.0168 - val_mae: 0.0699 - val_mse: 0.0079\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0220 - mae: 0.0858 - mse: 0.0126 - val_loss: 0.0166 - val_mae: 0.0681 - val_mse: 0.0075\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0219 - mae: 0.0852 - mse: 0.0125 - val_loss: 0.0171 - val_mae: 0.0725 - val_mse: 0.0083\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0824 - mse: 0.0117 - val_loss: 0.0167 - val_mae: 0.0710 - val_mse: 0.0080\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0808 - mse: 0.0112 - val_loss: 0.0166 - val_mae: 0.0697 - val_mse: 0.0077\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0219 - mae: 0.0863 - mse: 0.0129 - val_loss: 0.0167 - val_mae: 0.0715 - val_mse: 0.0082\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0210 - mae: 0.0826 - mse: 0.0118 - val_loss: 0.0167 - val_mae: 0.0702 - val_mse: 0.0079\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0207 - mae: 0.0817 - mse: 0.0114 - val_loss: 0.0164 - val_mae: 0.0652 - val_mse: 0.0070\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0166 - val_mae: 0.0704 - val_mse: 0.0080\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0220 - mae: 0.0857 - mse: 0.0130 - val_loss: 0.0167 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0842 - mse: 0.0123 - val_loss: 0.0166 - val_mae: 0.0713 - val_mse: 0.0082\n",
      "Epoch 331/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 110us/step - loss: 0.0229 - mae: 0.0894 - mse: 0.0140 - val_loss: 0.0170 - val_mae: 0.0744 - val_mse: 0.0090\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0865 - mse: 0.0129 - val_loss: 0.0167 - val_mae: 0.0714 - val_mse: 0.0083\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0841 - mse: 0.0120 - val_loss: 0.0166 - val_mae: 0.0717 - val_mse: 0.0082\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0207 - mae: 0.0820 - mse: 0.0116 - val_loss: 0.0165 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0166 - val_mae: 0.0715 - val_mse: 0.0081\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0212 - mae: 0.0841 - mse: 0.0122 - val_loss: 0.0170 - val_mae: 0.0744 - val_mse: 0.0090\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0221 - mae: 0.0867 - mse: 0.0134 - val_loss: 0.0167 - val_mae: 0.0718 - val_mse: 0.0082\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0211 - mae: 0.0839 - mse: 0.0121 - val_loss: 0.0164 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mae: 0.0821 - mse: 0.0115 - val_loss: 0.0165 - val_mae: 0.0705 - val_mse: 0.0080\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0217 - mae: 0.0858 - mse: 0.0128 - val_loss: 0.0162 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0214 - mae: 0.0834 - mse: 0.0121 - val_loss: 0.0162 - val_mae: 0.0681 - val_mse: 0.0077\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0208 - mae: 0.0822 - mse: 0.0118 - val_loss: 0.0162 - val_mae: 0.0689 - val_mse: 0.0078\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0214 - mae: 0.0849 - mse: 0.0126 - val_loss: 0.0162 - val_mae: 0.0663 - val_mse: 0.0071\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0215 - mae: 0.0838 - mse: 0.0123 - val_loss: 0.0164 - val_mae: 0.0701 - val_mse: 0.0080\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0210 - mae: 0.0850 - mse: 0.0124 - val_loss: 0.0163 - val_mae: 0.0691 - val_mse: 0.0078\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0212 - mae: 0.0846 - mse: 0.0123 - val_loss: 0.0167 - val_mae: 0.0735 - val_mse: 0.0086\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0211 - mae: 0.0831 - mse: 0.0123 - val_loss: 0.0164 - val_mae: 0.0716 - val_mse: 0.0082\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0164 - val_mae: 0.0708 - val_mse: 0.0081\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0835 - mse: 0.0121 - val_loss: 0.0164 - val_mae: 0.0713 - val_mse: 0.0081\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0217 - mae: 0.0857 - mse: 0.0129 - val_loss: 0.0164 - val_mae: 0.0709 - val_mse: 0.0081\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0210 - mae: 0.0841 - mse: 0.0122 - val_loss: 0.0162 - val_mae: 0.0699 - val_mse: 0.0078\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0210 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0651 - val_mse: 0.0068\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0207 - mae: 0.0808 - mse: 0.0114 - val_loss: 0.0160 - val_mae: 0.0681 - val_mse: 0.0074\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0220 - mae: 0.0864 - mse: 0.0133 - val_loss: 0.0164 - val_mae: 0.0711 - val_mse: 0.0080\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0207 - mae: 0.0829 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0689 - val_mse: 0.0075\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0211 - mae: 0.0833 - mse: 0.0120 - val_loss: 0.0164 - val_mae: 0.0721 - val_mse: 0.0084\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0214 - mae: 0.0866 - mse: 0.0129 - val_loss: 0.0161 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0209 - mae: 0.0827 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0831 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0666 - val_mse: 0.0072\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0212 - mae: 0.0852 - mse: 0.0122 - val_loss: 0.0159 - val_mae: 0.0662 - val_mse: 0.0071\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0210 - mae: 0.0830 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0206 - mae: 0.0810 - mse: 0.0115 - val_loss: 0.0159 - val_mae: 0.0675 - val_mse: 0.0073\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0207 - mae: 0.0832 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0835 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0852 - mse: 0.0126 - val_loss: 0.0162 - val_mae: 0.0715 - val_mse: 0.0083\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0826 - mse: 0.0115 - val_loss: 0.0161 - val_mae: 0.0683 - val_mse: 0.0075\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0201 - mae: 0.0807 - mse: 0.0112 - val_loss: 0.0159 - val_mae: 0.0687 - val_mse: 0.0076\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0159 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0833 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0199 - mae: 0.0801 - mse: 0.0110 - val_loss: 0.0160 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0200 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0162 - val_mae: 0.0726 - val_mse: 0.0085\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0204 - mae: 0.0850 - mse: 0.0121 - val_loss: 0.0159 - val_mae: 0.0696 - val_mse: 0.0078\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0840 - mse: 0.0120 - val_loss: 0.0157 - val_mae: 0.0674 - val_mse: 0.0074\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0807 - mse: 0.0117 - val_loss: 0.0158 - val_mae: 0.0681 - val_mse: 0.0075\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0206 - mae: 0.0834 - mse: 0.0120 - val_loss: 0.0159 - val_mae: 0.0696 - val_mse: 0.0078\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0838 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0709 - val_mse: 0.0080\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0203 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0160 - val_mae: 0.0714 - val_mse: 0.0081\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0206 - mae: 0.0827 - mse: 0.0120 - val_loss: 0.0156 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0834 - mse: 0.0119 - val_loss: 0.0159 - val_mae: 0.0700 - val_mse: 0.0077\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0216 - mae: 0.0863 - mse: 0.0131 - val_loss: 0.0159 - val_mae: 0.0693 - val_mse: 0.0076\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0207 - mae: 0.0834 - mse: 0.0120 - val_loss: 0.0155 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0801 - mse: 0.0115 - val_loss: 0.0158 - val_mae: 0.0699 - val_mse: 0.0079\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0827 - mse: 0.0117 - val_loss: 0.0155 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0816 - mse: 0.0116 - val_loss: 0.0156 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0201 - mae: 0.0817 - mse: 0.0115 - val_loss: 0.0156 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0214 - mae: 0.0859 - mse: 0.0129 - val_loss: 0.0157 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0206 - mae: 0.0825 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0822 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0648 - val_mse: 0.0069\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0207 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0155 - val_mae: 0.0664 - val_mse: 0.0072\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0805 - mse: 0.0114 - val_loss: 0.0156 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0208 - mae: 0.0849 - mse: 0.0124 - val_loss: 0.0155 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0205 - mae: 0.0823 - mse: 0.0119 - val_loss: 0.0159 - val_mae: 0.0706 - val_mse: 0.0078\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0203 - mae: 0.0830 - mse: 0.0120 - val_loss: 0.0156 - val_mae: 0.0683 - val_mse: 0.0075\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0211 - mae: 0.0849 - mse: 0.0128 - val_loss: 0.0158 - val_mae: 0.0715 - val_mse: 0.0082\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0202 - mae: 0.0825 - mse: 0.0119 - val_loss: 0.0154 - val_mae: 0.0662 - val_mse: 0.0071\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0204 - mae: 0.0821 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0708 - val_mse: 0.0081\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0833 - mse: 0.0118 - val_loss: 0.0156 - val_mae: 0.0697 - val_mse: 0.0078\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0830 - mse: 0.0117 - val_loss: 0.0157 - val_mae: 0.0707 - val_mse: 0.0081\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0200 - mae: 0.0837 - mse: 0.0117 - val_loss: 0.0155 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0825 - mse: 0.0122 - val_loss: 0.0153 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0709 - val_mse: 0.0080\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0848 - mse: 0.0124 - val_loss: 0.0156 - val_mae: 0.0697 - val_mse: 0.0077\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0206 - mae: 0.0850 - mse: 0.0124 - val_loss: 0.0154 - val_mae: 0.0676 - val_mse: 0.0074\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0207 - mae: 0.0836 - mse: 0.0124 - val_loss: 0.0155 - val_mae: 0.0679 - val_mse: 0.0074\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0201 - mae: 0.0812 - mse: 0.0117 - val_loss: 0.0158 - val_mae: 0.0708 - val_mse: 0.0079\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0198 - mae: 0.0819 - mse: 0.0114 - val_loss: 0.0156 - val_mae: 0.0701 - val_mse: 0.0078\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0812 - mse: 0.0113 - val_loss: 0.0155 - val_mae: 0.0701 - val_mse: 0.0079\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0797 - mse: 0.0107 - val_loss: 0.0155 - val_mae: 0.0689 - val_mse: 0.0076\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0200 - mae: 0.0807 - mse: 0.0117 - val_loss: 0.0153 - val_mae: 0.0667 - val_mse: 0.0071\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0196 - mae: 0.0814 - mse: 0.0111 - val_loss: 0.0153 - val_mae: 0.0664 - val_mse: 0.0071\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0810 - mse: 0.0115 - val_loss: 0.0153 - val_mae: 0.0678 - val_mse: 0.0074\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0202 - mae: 0.0823 - mse: 0.0120 - val_loss: 0.0155 - val_mae: 0.0700 - val_mse: 0.0080\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0198 - mae: 0.0813 - mse: 0.0116 - val_loss: 0.0154 - val_mae: 0.0695 - val_mse: 0.0078\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0204 - mae: 0.0848 - mse: 0.0123 - val_loss: 0.0158 - val_mae: 0.0724 - val_mse: 0.0083\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0201 - mae: 0.0841 - mse: 0.0121 - val_loss: 0.0153 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0806 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0811 - mse: 0.0112 - val_loss: 0.0150 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0199 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0152 - val_mae: 0.0665 - val_mse: 0.0072\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0205 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0152 - val_mae: 0.0655 - val_mse: 0.0070\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0196 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0153 - val_mae: 0.0688 - val_mse: 0.0076\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0206 - mae: 0.0855 - mse: 0.0126 - val_loss: 0.0159 - val_mae: 0.0740 - val_mse: 0.0086\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0210 - mae: 0.0870 - mse: 0.0134 - val_loss: 0.0157 - val_mae: 0.0722 - val_mse: 0.0083\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0849 - mse: 0.0127 - val_loss: 0.0154 - val_mae: 0.0691 - val_mse: 0.0076\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0835 - mse: 0.0122 - val_loss: 0.0155 - val_mae: 0.0699 - val_mse: 0.0077\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0838 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0676 - val_mse: 0.0073\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0201 - mae: 0.0815 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0735 - val_mse: 0.0085\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0198 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0152 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0204 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0153 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0803 - mse: 0.0115 - val_loss: 0.0152 - val_mae: 0.0679 - val_mse: 0.0073\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0826 - mse: 0.0117 - val_loss: 0.0156 - val_mae: 0.0721 - val_mse: 0.0084\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0199 - mae: 0.0834 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0691 - val_mse: 0.0077\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0198 - mae: 0.0808 - mse: 0.0116 - val_loss: 0.0154 - val_mae: 0.0706 - val_mse: 0.0079\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0837 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0211 - mae: 0.0871 - mse: 0.0131 - val_loss: 0.0152 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0785 - mse: 0.0104 - val_loss: 0.0153 - val_mae: 0.0691 - val_mse: 0.0077\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0198 - mae: 0.0832 - mse: 0.0117 - val_loss: 0.0153 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0200 - mae: 0.0829 - mse: 0.0120 - val_loss: 0.0152 - val_mae: 0.0688 - val_mse: 0.0076\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0201 - mae: 0.0828 - mse: 0.0119 - val_loss: 0.0152 - val_mae: 0.0689 - val_mse: 0.0076\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0819 - mse: 0.0118 - val_loss: 0.0151 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0195 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0639 - val_mse: 0.0067\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0826 - mse: 0.0119 - val_loss: 0.0151 - val_mae: 0.0653 - val_mse: 0.0067\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0818 - mse: 0.0117 - val_loss: 0.0152 - val_mae: 0.0687 - val_mse: 0.0075\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0196 - mae: 0.0823 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0198 - mae: 0.0809 - mse: 0.0116 - val_loss: 0.0150 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0151 - val_mae: 0.0686 - val_mse: 0.0075\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0207 - mae: 0.0854 - mse: 0.0127 - val_loss: 0.0150 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0203 - mae: 0.0829 - mse: 0.0120 - val_loss: 0.0153 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0849 - mse: 0.0124 - val_loss: 0.0151 - val_mae: 0.0686 - val_mse: 0.0076\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0203 - mae: 0.0853 - mse: 0.0123 - val_loss: 0.0151 - val_mae: 0.0683 - val_mse: 0.0074\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0202 - mae: 0.0833 - mse: 0.0121 - val_loss: 0.0149 - val_mae: 0.0668 - val_mse: 0.0072\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0195 - mae: 0.0804 - mse: 0.0114 - val_loss: 0.0148 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0203 - mae: 0.0837 - mse: 0.0122 - val_loss: 0.0151 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0810 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0673 - val_mse: 0.0073\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0199 - mae: 0.0827 - mse: 0.0119 - val_loss: 0.0149 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0853 - mse: 0.0132 - val_loss: 0.0151 - val_mae: 0.0682 - val_mse: 0.0074\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0195 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0673 - val_mse: 0.0072\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0200 - mae: 0.0820 - mse: 0.0119 - val_loss: 0.0147 - val_mae: 0.0657 - val_mse: 0.0069\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0646 - val_mse: 0.0068\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0193 - mae: 0.0799 - mse: 0.0110 - val_loss: 0.0149 - val_mae: 0.0670 - val_mse: 0.0074\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0655 - val_mse: 0.0070\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0835 - mse: 0.0123 - val_loss: 0.0150 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0814 - mse: 0.0118 - val_loss: 0.0148 - val_mae: 0.0649 - val_mse: 0.0068\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0812 - mse: 0.0113 - val_loss: 0.0150 - val_mae: 0.0685 - val_mse: 0.0074\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0202 - mae: 0.0848 - mse: 0.0124 - val_loss: 0.0149 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0830 - mse: 0.0118 - val_loss: 0.0151 - val_mae: 0.0685 - val_mse: 0.0076\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0195 - mae: 0.0812 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0674 - val_mse: 0.0072\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0203 - mae: 0.0853 - mse: 0.0124 - val_loss: 0.0149 - val_mae: 0.0659 - val_mse: 0.0069\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0826 - mse: 0.0115 - val_loss: 0.0148 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0197 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0149 - val_mae: 0.0648 - val_mse: 0.0066\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0808 - mse: 0.0110 - val_loss: 0.0147 - val_mae: 0.0654 - val_mse: 0.0069\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0192 - mae: 0.0799 - mse: 0.0111 - val_loss: 0.0148 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0837 - mse: 0.0120 - val_loss: 0.0150 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0195 - mae: 0.0820 - mse: 0.0117 - val_loss: 0.0148 - val_mae: 0.0660 - val_mse: 0.0070\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0191 - mae: 0.0802 - mse: 0.0110 - val_loss: 0.0148 - val_mae: 0.0670 - val_mse: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0206 - mae: 0.0847 - mse: 0.0128 - val_loss: 0.0149 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0202 - mae: 0.0834 - mse: 0.0124 - val_loss: 0.0148 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0799 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0680 - val_mse: 0.0073\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0194 - mae: 0.0831 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0629 - val_mse: 0.0065\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0816 - mse: 0.0112 - val_loss: 0.0148 - val_mae: 0.0685 - val_mse: 0.0076\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0815 - mse: 0.0114 - val_loss: 0.0146 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0802 - mse: 0.0116 - val_loss: 0.0145 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0198 - mae: 0.0838 - mse: 0.0120 - val_loss: 0.0148 - val_mae: 0.0655 - val_mse: 0.0067\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0146 - val_mae: 0.0649 - val_mse: 0.0067\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0819 - mse: 0.0118 - val_loss: 0.0147 - val_mae: 0.0674 - val_mse: 0.0072\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0193 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0147 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0823 - mse: 0.0115 - val_loss: 0.0146 - val_mae: 0.0658 - val_mse: 0.0069\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0151 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0198 - mae: 0.0825 - mse: 0.0120 - val_loss: 0.0145 - val_mae: 0.0649 - val_mse: 0.0068\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0146 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0832 - mse: 0.0121 - val_loss: 0.0146 - val_mae: 0.0650 - val_mse: 0.0070\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0188 - mae: 0.0777 - mse: 0.0107 - val_loss: 0.0146 - val_mae: 0.0661 - val_mse: 0.0071\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0824 - mse: 0.0115 - val_loss: 0.0146 - val_mae: 0.0660 - val_mse: 0.0071\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0145 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0812 - mse: 0.0115 - val_loss: 0.0145 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0190 - mae: 0.0784 - mse: 0.0109 - val_loss: 0.0150 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0188 - mae: 0.0802 - mse: 0.0111 - val_loss: 0.0144 - val_mae: 0.0642 - val_mse: 0.0067\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0197 - mae: 0.0819 - mse: 0.0117 - val_loss: 0.0144 - val_mae: 0.0647 - val_mse: 0.0068\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0188 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0146 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0774 - mse: 0.0102 - val_loss: 0.0144 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0199 - mae: 0.0818 - mse: 0.0120 - val_loss: 0.0149 - val_mae: 0.0687 - val_mse: 0.0075\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0192 - mae: 0.0800 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0648 - val_mse: 0.0069\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0805 - mse: 0.0117 - val_loss: 0.0146 - val_mae: 0.0667 - val_mse: 0.0073\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0190 - mae: 0.0801 - mse: 0.0112 - val_loss: 0.0144 - val_mae: 0.0634 - val_mse: 0.0066\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0786 - mse: 0.0109 - val_loss: 0.0145 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0204 - mae: 0.0855 - mse: 0.0127 - val_loss: 0.0146 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0790 - mse: 0.0108 - val_loss: 0.0146 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0798 - mse: 0.0113 - val_loss: 0.0146 - val_mae: 0.0670 - val_mse: 0.0072\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0144 - val_mae: 0.0640 - val_mse: 0.0067\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0802 - mse: 0.0113 - val_loss: 0.0145 - val_mae: 0.0657 - val_mse: 0.0070\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0192 - mae: 0.0815 - mse: 0.0113 - val_loss: 0.0145 - val_mae: 0.0652 - val_mse: 0.0068\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0792 - mse: 0.0106 - val_loss: 0.0142 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0144 - val_mae: 0.0632 - val_mse: 0.0066\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0144 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0801 - mse: 0.0117 - val_loss: 0.0145 - val_mae: 0.0662 - val_mse: 0.0070\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0801 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0654 - val_mse: 0.0070\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0782 - mse: 0.0106 - val_loss: 0.0149 - val_mae: 0.0701 - val_mse: 0.0080\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0191 - mae: 0.0808 - mse: 0.0116 - val_loss: 0.0145 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0183 - mae: 0.0780 - mse: 0.0104 - val_loss: 0.0142 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0801 - mse: 0.0112 - val_loss: 0.0146 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0793 - mse: 0.0109 - val_loss: 0.0142 - val_mae: 0.0627 - val_mse: 0.0065\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0190 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0634 - val_mse: 0.0065\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0192 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0684 - val_mse: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0193 - mae: 0.0825 - mse: 0.0116 - val_loss: 0.0142 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0792 - mse: 0.0109 - val_loss: 0.0144 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0796 - mse: 0.0111 - val_loss: 0.0140 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0184 - mae: 0.0775 - mse: 0.0105 - val_loss: 0.0143 - val_mae: 0.0658 - val_mse: 0.0071\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0197 - mae: 0.0817 - mse: 0.0119 - val_loss: 0.0148 - val_mae: 0.0706 - val_mse: 0.0079\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0200 - mae: 0.0843 - mse: 0.0125 - val_loss: 0.0146 - val_mae: 0.0679 - val_mse: 0.0073\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0800 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0804 - mse: 0.0113 - val_loss: 0.0141 - val_mae: 0.0614 - val_mse: 0.0062\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0640 - val_mse: 0.0068\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0846 - mse: 0.0126 - val_loss: 0.0142 - val_mae: 0.0651 - val_mse: 0.0070\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0191 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0142 - val_mae: 0.0642 - val_mse: 0.0067\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0142 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0115 - val_loss: 0.0141 - val_mae: 0.0627 - val_mse: 0.0065\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0144 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0809 - mse: 0.0113 - val_loss: 0.0143 - val_mae: 0.0650 - val_mse: 0.0066\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0808 - mse: 0.0114 - val_loss: 0.0142 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0190 - mae: 0.0807 - mse: 0.0113 - val_loss: 0.0142 - val_mae: 0.0639 - val_mse: 0.0065\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0191 - mae: 0.0799 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0688 - val_mse: 0.0078\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0843 - mse: 0.0122 - val_loss: 0.0143 - val_mae: 0.0652 - val_mse: 0.0067\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0144 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0195 - mae: 0.0814 - mse: 0.0119 - val_loss: 0.0141 - val_mae: 0.0639 - val_mse: 0.0066\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0189 - mae: 0.0795 - mse: 0.0111 - val_loss: 0.0143 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0141 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0795 - mse: 0.0113 - val_loss: 0.0140 - val_mae: 0.0639 - val_mse: 0.0065\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0192 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0636 - val_mse: 0.0065\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0801 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0197 - mae: 0.0817 - mse: 0.0120 - val_loss: 0.0143 - val_mae: 0.0673 - val_mse: 0.0072\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0140 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0807 - mse: 0.0115 - val_loss: 0.0143 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0788 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0636 - val_mse: 0.0065\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0843 - mse: 0.0124 - val_loss: 0.0142 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mae: 0.0799 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0643 - val_mse: 0.0065\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0198 - mae: 0.0825 - mse: 0.0121 - val_loss: 0.0142 - val_mae: 0.0657 - val_mse: 0.0071\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0786 - mse: 0.0111 - val_loss: 0.0139 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0187 - mae: 0.0803 - mse: 0.0110 - val_loss: 0.0144 - val_mae: 0.0676 - val_mse: 0.0074\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0773 - mse: 0.0104 - val_loss: 0.0139 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0790 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0183 - mae: 0.0791 - mse: 0.0107 - val_loss: 0.0143 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0794 - mse: 0.0107 - val_loss: 0.0139 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0139 - val_mae: 0.0636 - val_mse: 0.0066\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0194 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0141 - val_mae: 0.0656 - val_mse: 0.0069\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0794 - mse: 0.0109 - val_loss: 0.0140 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0193 - mae: 0.0824 - mse: 0.0116 - val_loss: 0.0143 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0791 - mse: 0.0110 - val_loss: 0.0138 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0187 - mae: 0.0780 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0644 - val_mse: 0.0068\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0190 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0783 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0785 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0184 - mae: 0.0789 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0110 - val_loss: 0.0140 - val_mae: 0.0630 - val_mse: 0.0062\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0783 - mse: 0.0107 - val_loss: 0.0139 - val_mae: 0.0640 - val_mse: 0.0066\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mae: 0.0790 - mse: 0.0113 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0792 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0626 - val_mse: 0.0064\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0796 - mse: 0.0109 - val_loss: 0.0137 - val_mae: 0.0600 - val_mse: 0.0060\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0784 - mse: 0.0107 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0809 - mse: 0.0116 - val_loss: 0.0138 - val_mae: 0.0620 - val_mse: 0.0063\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0771 - mse: 0.0104 - val_loss: 0.0140 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0782 - mse: 0.0103 - val_loss: 0.0139 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0194 - mae: 0.0813 - mse: 0.0118 - val_loss: 0.0143 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0768 - mse: 0.0105 - val_loss: 0.0141 - val_mae: 0.0658 - val_mse: 0.0069\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0188 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0139 - val_mae: 0.0638 - val_mse: 0.0067\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0790 - mse: 0.0112 - val_loss: 0.0141 - val_mae: 0.0658 - val_mse: 0.0068\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0183 - mae: 0.0777 - mse: 0.0106 - val_loss: 0.0139 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0785 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0637 - val_mse: 0.0067\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0790 - mse: 0.0107 - val_loss: 0.0142 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0761 - mse: 0.0101 - val_loss: 0.0139 - val_mae: 0.0638 - val_mse: 0.0067\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0189 - mae: 0.0800 - mse: 0.0114 - val_loss: 0.0140 - val_mae: 0.0651 - val_mse: 0.0069\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0807 - mse: 0.0111 - val_loss: 0.0139 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0810 - mse: 0.0117 - val_loss: 0.0141 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0792 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0611 - val_mse: 0.0062\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0780 - mse: 0.0108 - val_loss: 0.0138 - val_mae: 0.0626 - val_mse: 0.0063\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0786 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0782 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0644 - val_mse: 0.0065\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0187 - mae: 0.0802 - mse: 0.0111 - val_loss: 0.0140 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0188 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0621 - val_mse: 0.0061\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0817 - mse: 0.0118 - val_loss: 0.0137 - val_mae: 0.0604 - val_mse: 0.0059\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0783 - mse: 0.0109 - val_loss: 0.0141 - val_mae: 0.0654 - val_mse: 0.0070\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0112 - val_loss: 0.0139 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0764 - mse: 0.0103 - val_loss: 0.0137 - val_mae: 0.0624 - val_mse: 0.0064\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0757 - mse: 0.0096 - val_loss: 0.0135 - val_mae: 0.0595 - val_mse: 0.0058\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0189 - mae: 0.0794 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0182 - mae: 0.0765 - mse: 0.0105 - val_loss: 0.0138 - val_mae: 0.0638 - val_mse: 0.0066\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0109 - val_loss: 0.0136 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0188 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0134 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0759 - mse: 0.0103 - val_loss: 0.0136 - val_mae: 0.0616 - val_mse: 0.0063\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0176 - mae: 0.0754 - mse: 0.0100 - val_loss: 0.0134 - val_mae: 0.0591 - val_mse: 0.0058\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0762 - mse: 0.0103 - val_loss: 0.0136 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0746 - mse: 0.0100 - val_loss: 0.0135 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0782 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0780 - mse: 0.0110 - val_loss: 0.0137 - val_mae: 0.0629 - val_mse: 0.0066\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0592 - val_mse: 0.0057\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0767 - mse: 0.0101 - val_loss: 0.0138 - val_mae: 0.0648 - val_mse: 0.0067\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0764 - mse: 0.0103 - val_loss: 0.0139 - val_mae: 0.0632 - val_mse: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0793 - mse: 0.0109 - val_loss: 0.0134 - val_mae: 0.0602 - val_mse: 0.0060\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0175 - mae: 0.0738 - mse: 0.0098 - val_loss: 0.0136 - val_mae: 0.0632 - val_mse: 0.0065\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0190 - mae: 0.0798 - mse: 0.0114 - val_loss: 0.0136 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0186 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0137 - val_mae: 0.0645 - val_mse: 0.0068\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0188 - mae: 0.0795 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0180 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0135 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0135 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0769 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0621 - val_mse: 0.0061\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0137 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0786 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0180 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0134 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0136 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0788 - mse: 0.0109 - val_loss: 0.0135 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0607 - val_mse: 0.0059\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0103 - val_loss: 0.0135 - val_mae: 0.0623 - val_mse: 0.0063\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0751 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0781 - mse: 0.0111 - val_loss: 0.0136 - val_mae: 0.0616 - val_mse: 0.0060\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0771 - mse: 0.0104 - val_loss: 0.0134 - val_mae: 0.0606 - val_mse: 0.0059\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0752 - mse: 0.0097 - val_loss: 0.0138 - val_mae: 0.0652 - val_mse: 0.0070\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0781 - mse: 0.0104 - val_loss: 0.0134 - val_mae: 0.0602 - val_mse: 0.0058\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0754 - mse: 0.0098 - val_loss: 0.0133 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0183 - mae: 0.0776 - mse: 0.0108 - val_loss: 0.0137 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0772 - mse: 0.0109 - val_loss: 0.0135 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0753 - mse: 0.0098 - val_loss: 0.0137 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0181 - mae: 0.0774 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0628 - val_mse: 0.0062\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0138 - val_mae: 0.0637 - val_mse: 0.0064\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0771 - mse: 0.0102 - val_loss: 0.0133 - val_mae: 0.0601 - val_mse: 0.0059\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0750 - mse: 0.0098 - val_loss: 0.0138 - val_mae: 0.0661 - val_mse: 0.0071\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0819 - mse: 0.0119 - val_loss: 0.0135 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0137 - val_mae: 0.0639 - val_mse: 0.0064\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0777 - mse: 0.0103 - val_loss: 0.0137 - val_mae: 0.0646 - val_mse: 0.0068\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0184 - mae: 0.0784 - mse: 0.0109 - val_loss: 0.0133 - val_mae: 0.0596 - val_mse: 0.0058\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0753 - mse: 0.0102 - val_loss: 0.0134 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0174 - mae: 0.0756 - mse: 0.0099 - val_loss: 0.0137 - val_mae: 0.0646 - val_mse: 0.0067\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0772 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0757 - mse: 0.0105 - val_loss: 0.0134 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0189 - mae: 0.0797 - mse: 0.0114 - val_loss: 0.0135 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0790 - mse: 0.0107 - val_loss: 0.0136 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0181 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0783 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0759 - mse: 0.0100 - val_loss: 0.0133 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0780 - mse: 0.0107 - val_loss: 0.0134 - val_mae: 0.0608 - val_mse: 0.0060\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0770 - mse: 0.0103 - val_loss: 0.0135 - val_mae: 0.0611 - val_mse: 0.0060\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0179 - mae: 0.0764 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0639 - val_mse: 0.0068\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0137 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0746 - mse: 0.0094 - val_loss: 0.0135 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0772 - mse: 0.0105 - val_loss: 0.0131 - val_mae: 0.0579 - val_mse: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0182 - mae: 0.0765 - mse: 0.0105 - val_loss: 0.0133 - val_mae: 0.0621 - val_mse: 0.0063\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0761 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0131 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0176 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0640 - val_mse: 0.0064\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0793 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0175 - mae: 0.0767 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0614 - val_mse: 0.0059\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0787 - mse: 0.0104 - val_loss: 0.0133 - val_mae: 0.0627 - val_mse: 0.0064\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0756 - mse: 0.0100 - val_loss: 0.0139 - val_mae: 0.0677 - val_mse: 0.0073\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0188 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0132 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0774 - mse: 0.0106 - val_loss: 0.0134 - val_mae: 0.0628 - val_mse: 0.0064\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0767 - mse: 0.0104 - val_loss: 0.0131 - val_mae: 0.0595 - val_mse: 0.0057\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0762 - mse: 0.0101 - val_loss: 0.0134 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0762 - mse: 0.0102 - val_loss: 0.0130 - val_mae: 0.0596 - val_mse: 0.0059\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0130 - val_mae: 0.0592 - val_mse: 0.0057\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0769 - mse: 0.0105 - val_loss: 0.0131 - val_mae: 0.0598 - val_mse: 0.0058\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0792 - mse: 0.0113 - val_loss: 0.0132 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0781 - mse: 0.0107 - val_loss: 0.0136 - val_mae: 0.0646 - val_mse: 0.0067\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0787 - mse: 0.0110 - val_loss: 0.0135 - val_mae: 0.0635 - val_mse: 0.0066\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0765 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0608 - val_mse: 0.0061\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0133 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0790 - mse: 0.0110 - val_loss: 0.0131 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0168 - mae: 0.0730 - mse: 0.0093 - val_loss: 0.0132 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0801 - mse: 0.0111 - val_loss: 0.0131 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0178 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0616 - val_mse: 0.0061\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0136 - val_mae: 0.0658 - val_mse: 0.0068\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0133 - val_mae: 0.0624 - val_mse: 0.0062\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0657 - val_mse: 0.0070\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0178 - mae: 0.0785 - mse: 0.0105 - val_loss: 0.0132 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0132 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0787 - mse: 0.0111 - val_loss: 0.0134 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0172 - mae: 0.0764 - mse: 0.0100 - val_loss: 0.0135 - val_mae: 0.0627 - val_mse: 0.0061\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0748 - mse: 0.0098 - val_loss: 0.0130 - val_mae: 0.0605 - val_mse: 0.0060\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0111 - val_loss: 0.0132 - val_mae: 0.0627 - val_mse: 0.0064\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0773 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0764 - mse: 0.0101 - val_loss: 0.0132 - val_mae: 0.0618 - val_mse: 0.0063\n",
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0130 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0172 - mae: 0.0742 - mse: 0.0097 - val_loss: 0.0133 - val_mae: 0.0641 - val_mse: 0.0067\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0177 - mae: 0.0763 - mse: 0.0104 - val_loss: 0.0133 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0750 - mse: 0.0102 - val_loss: 0.0135 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0176 - mae: 0.0781 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0575 - val_mse: 0.0055\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0174 - mae: 0.0765 - mse: 0.0098 - val_loss: 0.0131 - val_mae: 0.0623 - val_mse: 0.0063\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0133 - val_mae: 0.0634 - val_mse: 0.0066\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0765 - mse: 0.0102 - val_loss: 0.0130 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0176 - mae: 0.0780 - mse: 0.0103 - val_loss: 0.0131 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0788 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0617 - val_mse: 0.0060\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0810 - mse: 0.0118 - val_loss: 0.0131 - val_mae: 0.0626 - val_mse: 0.0063\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0182 - mae: 0.0779 - mse: 0.0109 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0175 - mae: 0.0771 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0625 - val_mse: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0131 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0185 - mae: 0.0798 - mse: 0.0113 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0177 - mae: 0.0778 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0571 - val_mse: 0.0054\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0180 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0132 - val_mae: 0.0609 - val_mse: 0.0059\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0767 - mse: 0.0104 - val_loss: 0.0130 - val_mae: 0.0600 - val_mse: 0.0057\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0179 - mae: 0.0762 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0626 - val_mse: 0.0064\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0749 - mse: 0.0099 - val_loss: 0.0134 - val_mae: 0.0641 - val_mse: 0.0067\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0783 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0568 - val_mse: 0.0053\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0756 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0584 - val_mse: 0.0056\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0102 - val_loss: 0.0132 - val_mae: 0.0635 - val_mse: 0.0063\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0174 - mae: 0.0776 - mse: 0.0101 - val_loss: 0.0127 - val_mae: 0.0595 - val_mse: 0.0058\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0180 - mae: 0.0775 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0660 - val_mse: 0.0072\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0167 - mae: 0.0755 - mse: 0.0096 - val_loss: 0.0131 - val_mae: 0.0629 - val_mse: 0.0064\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0128 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0171 - mae: 0.0755 - mse: 0.0097 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0065\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0782 - mse: 0.0107 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0064\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0129 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0172 - mae: 0.0754 - mse: 0.0100 - val_loss: 0.0130 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0168 - mae: 0.0735 - mse: 0.0096 - val_loss: 0.0129 - val_mae: 0.0612 - val_mse: 0.0061\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0783 - mse: 0.0110 - val_loss: 0.0128 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0182 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0130 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mae: 0.0759 - mse: 0.0097 - val_loss: 0.0126 - val_mae: 0.0578 - val_mse: 0.0054\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0179 - mae: 0.0782 - mse: 0.0107 - val_loss: 0.0130 - val_mae: 0.0621 - val_mse: 0.0063\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0182 - mae: 0.0780 - mse: 0.0110 - val_loss: 0.0128 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0787 - mse: 0.0110 - val_loss: 0.0130 - val_mae: 0.0624 - val_mse: 0.0063\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0757 - mse: 0.0101 - val_loss: 0.0132 - val_mae: 0.0637 - val_mse: 0.0065\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0183 - mae: 0.0795 - mse: 0.0112 - val_loss: 0.0129 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0099 - val_loss: 0.0135 - val_mae: 0.0654 - val_mse: 0.0069\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0751 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0601 - val_mse: 0.0060\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0768 - mse: 0.0102 - val_loss: 0.0128 - val_mae: 0.0603 - val_mse: 0.0060\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0167 - mae: 0.0745 - mse: 0.0094 - val_loss: 0.0129 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0184 - mae: 0.0772 - mse: 0.0109 - val_loss: 0.0127 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 121us/step - loss: 0.0177 - mae: 0.0784 - mse: 0.0104 - val_loss: 0.0131 - val_mae: 0.0609 - val_mse: 0.0058\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0171 - mae: 0.0747 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0054\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0169 - mae: 0.0752 - mse: 0.0095 - val_loss: 0.0128 - val_mae: 0.0609 - val_mse: 0.0061\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0762 - mse: 0.0100 - val_loss: 0.0130 - val_mae: 0.0628 - val_mse: 0.0065\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0177 - mae: 0.0776 - mse: 0.0106 - val_loss: 0.0128 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0759 - mse: 0.0100 - val_loss: 0.0128 - val_mae: 0.0612 - val_mse: 0.0061\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0167 - mae: 0.0730 - mse: 0.0096 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0054\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0173 - mae: 0.0750 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0623 - val_mse: 0.0061\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0787 - mse: 0.0108 - val_loss: 0.0129 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0126 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0757 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0790 - mse: 0.0108 - val_loss: 0.0126 - val_mae: 0.0594 - val_mse: 0.0058\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0061\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0778 - mse: 0.0105 - val_loss: 0.0126 - val_mae: 0.0576 - val_mse: 0.0054\n",
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.0741 - mse: 0.0098 - val_loss: 0.0126 - val_mae: 0.0596 - val_mse: 0.0057\n",
      "Epoch 762/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0184 - mae: 0.0796 - mse: 0.0113 - val_loss: 0.0127 - val_mae: 0.0604 - val_mse: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0184 - mae: 0.0806 - mse: 0.0113 - val_loss: 0.0132 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0180 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0126 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0780 - mse: 0.0105 - val_loss: 0.0129 - val_mae: 0.0616 - val_mse: 0.0062\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0170 - mae: 0.0755 - mse: 0.0099 - val_loss: 0.0126 - val_mae: 0.0600 - val_mse: 0.0059\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0773 - mse: 0.0105 - val_loss: 0.0124 - val_mae: 0.0560 - val_mse: 0.0052\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0127 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0173 - mae: 0.0775 - mse: 0.0101 - val_loss: 0.0125 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0742 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0598 - val_mse: 0.0059\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0098 - val_loss: 0.0133 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0166 - mae: 0.0738 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0601 - val_mse: 0.0058\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0760 - mse: 0.0101 - val_loss: 0.0130 - val_mae: 0.0621 - val_mse: 0.0060\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0126 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0172 - mae: 0.0765 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0766 - mse: 0.0102 - val_loss: 0.0128 - val_mae: 0.0614 - val_mse: 0.0059\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0750 - mse: 0.0098 - val_loss: 0.0126 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0774 - mse: 0.0103 - val_loss: 0.0126 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0160 - mae: 0.0713 - mse: 0.0088 - val_loss: 0.0126 - val_mae: 0.0605 - val_mse: 0.0060\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0175 - mae: 0.0759 - mse: 0.0104 - val_loss: 0.0126 - val_mae: 0.0601 - val_mse: 0.0059\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0759 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0613 - val_mse: 0.0058\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0766 - mse: 0.0102 - val_loss: 0.0126 - val_mae: 0.0594 - val_mse: 0.0058\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0733 - mse: 0.0094 - val_loss: 0.0127 - val_mae: 0.0605 - val_mse: 0.0058\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0179 - mae: 0.0774 - mse: 0.0109 - val_loss: 0.0127 - val_mae: 0.0600 - val_mse: 0.0058\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0166 - mae: 0.0742 - mse: 0.0094 - val_loss: 0.0128 - val_mae: 0.0621 - val_mse: 0.0062\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0762 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0768 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0641 - val_mse: 0.0065\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0794 - mse: 0.0112 - val_loss: 0.0130 - val_mae: 0.0623 - val_mse: 0.0060\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0768 - mse: 0.0105 - val_loss: 0.0128 - val_mae: 0.0604 - val_mse: 0.0058\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.0762 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0058\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0741 - mse: 0.0094 - val_loss: 0.0125 - val_mae: 0.0595 - val_mse: 0.0056\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0774 - mse: 0.0103 - val_loss: 0.0128 - val_mae: 0.0617 - val_mse: 0.0062\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.0758 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0169 - mae: 0.0739 - mse: 0.0095 - val_loss: 0.0126 - val_mae: 0.0609 - val_mse: 0.0060\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0127 - val_mae: 0.0594 - val_mse: 0.0056\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0167 - mae: 0.0743 - mse: 0.0094 - val_loss: 0.0126 - val_mae: 0.0593 - val_mse: 0.0057\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.0758 - mse: 0.0102 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0055\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0163 - mae: 0.0737 - mse: 0.0093 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0762 - mse: 0.0101 - val_loss: 0.0128 - val_mae: 0.0620 - val_mse: 0.0061\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0165 - mae: 0.0747 - mse: 0.0096 - val_loss: 0.0127 - val_mae: 0.0621 - val_mse: 0.0062\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.0742 - mse: 0.009 - 0s 104us/step - loss: 0.0168 - mae: 0.0756 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0175 - mae: 0.0768 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0633 - val_mse: 0.0065\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0173 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0130 - val_mae: 0.0634 - val_mse: 0.0064\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.0755 - mse: 0.0105 - val_loss: 0.0126 - val_mae: 0.0608 - val_mse: 0.0061\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0760 - mse: 0.0105 - val_loss: 0.0125 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0748 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0168 - mae: 0.0745 - mse: 0.0097 - val_loss: 0.0129 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0128 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0751 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 810/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.0742 - mse: 0.0098 - val_loss: 0.0124 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0173 - mae: 0.0765 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0776 - mse: 0.0106 - val_loss: 0.0127 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0166 - mae: 0.0743 - mse: 0.0095 - val_loss: 0.0125 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0753 - mse: 0.0096 - val_loss: 0.0127 - val_mae: 0.0617 - val_mse: 0.0059\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0177 - mae: 0.0772 - mse: 0.0106 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0758 - mse: 0.0101 - val_loss: 0.0124 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0164 - mae: 0.0723 - mse: 0.0093 - val_loss: 0.0124 - val_mae: 0.0596 - val_mse: 0.0058\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.0772 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0167 - mae: 0.0739 - mse: 0.0095 - val_loss: 0.0126 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0767 - mse: 0.0103 - val_loss: 0.0120 - val_mae: 0.0558 - val_mse: 0.0051\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0757 - mse: 0.0098 - val_loss: 0.0120 - val_mae: 0.0558 - val_mse: 0.0050\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0779 - mse: 0.0102 - val_loss: 0.0122 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0770 - mse: 0.0108 - val_loss: 0.0123 - val_mae: 0.0584 - val_mse: 0.0056\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0163 - mae: 0.0723 - mse: 0.0093 - val_loss: 0.0127 - val_mae: 0.0614 - val_mse: 0.0061\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0122 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0123 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0161 - mae: 0.0726 - mse: 0.0091 - val_loss: 0.0123 - val_mae: 0.0574 - val_mse: 0.0053\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0773 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0600 - val_mse: 0.0057\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0780 - mse: 0.0105 - val_loss: 0.0125 - val_mae: 0.0600 - val_mse: 0.0059\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0174 - mae: 0.0770 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0637 - val_mse: 0.0065\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0167 - mae: 0.0749 - mse: 0.0096 - val_loss: 0.0122 - val_mae: 0.0576 - val_mse: 0.0054\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0763 - mse: 0.0100 - val_loss: 0.0124 - val_mae: 0.0596 - val_mse: 0.0056\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0171 - mae: 0.0766 - mse: 0.0101 - val_loss: 0.0123 - val_mae: 0.0592 - val_mse: 0.0056\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0161 - mae: 0.0732 - mse: 0.0091 - val_loss: 0.0125 - val_mae: 0.0592 - val_mse: 0.0055\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0766 - mse: 0.0103 - val_loss: 0.0122 - val_mae: 0.0583 - val_mse: 0.0055\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0770 - mse: 0.0102 - val_loss: 0.0122 - val_mae: 0.0589 - val_mse: 0.0055\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0166 - mae: 0.0755 - mse: 0.0096 - val_loss: 0.0128 - val_mae: 0.0638 - val_mse: 0.0065\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0165 - mae: 0.0735 - mse: 0.0096 - val_loss: 0.0124 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0126 - val_mae: 0.0613 - val_mse: 0.0060\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0747 - mse: 0.0099 - val_loss: 0.0122 - val_mae: 0.0584 - val_mse: 0.0054\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0164 - mae: 0.0732 - mse: 0.0092 - val_loss: 0.0122 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0169 - mae: 0.0761 - mse: 0.0098 - val_loss: 0.0124 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0168 - mae: 0.0742 - mse: 0.0096 - val_loss: 0.0128 - val_mae: 0.0629 - val_mse: 0.0063\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0168 - mae: 0.0744 - mse: 0.0101 - val_loss: 0.0126 - val_mae: 0.0608 - val_mse: 0.0059\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0170 - mae: 0.0758 - mse: 0.0100 - val_loss: 0.0124 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0167 - mae: 0.0749 - mse: 0.0097 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0124 - val_mae: 0.0593 - val_mse: 0.0054\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0167 - mae: 0.0742 - mse: 0.0094 - val_loss: 0.0123 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0166 - mae: 0.0729 - mse: 0.0093 - val_loss: 0.0126 - val_mae: 0.0611 - val_mse: 0.0058\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00850: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_medium = build_medium_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_medium.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "model_medium.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['medium'] = model_medium.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_201 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,821\n",
      "Trainable params: 4,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.6086 - mae: 0.1588 - mse: 0.0349 - val_loss: 0.5534 - val_mae: 0.1180 - val_mse: 0.0200\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.5555 - mae: 0.1306 - mse: 0.0242 - val_loss: 0.5133 - val_mae: 0.1022 - val_mse: 0.0154\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.5185 - mae: 0.1223 - mse: 0.0214 - val_loss: 0.4805 - val_mae: 0.1026 - val_mse: 0.0156\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.4834 - mae: 0.1224 - mse: 0.0213 - val_loss: 0.4478 - val_mae: 0.1022 - val_mse: 0.0155\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.4500 - mae: 0.1219 - mse: 0.0211 - val_loss: 0.4168 - val_mae: 0.1020 - val_mse: 0.0154\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.4186 - mae: 0.1195 - mse: 0.0204 - val_loss: 0.3884 - val_mae: 0.1000 - val_mse: 0.0149\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.3902 - mae: 0.1169 - mse: 0.0197 - val_loss: 0.3625 - val_mae: 0.1006 - val_mse: 0.0152\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.3641 - mae: 0.1158 - mse: 0.0195 - val_loss: 0.3391 - val_mae: 0.0988 - val_mse: 0.0149\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.3404 - mae: 0.1135 - mse: 0.0190 - val_loss: 0.3174 - val_mae: 0.0982 - val_mse: 0.0149\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.3189 - mae: 0.1124 - mse: 0.0189 - val_loss: 0.2977 - val_mae: 0.0961 - val_mse: 0.0145\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2993 - mae: 0.1109 - mse: 0.0186 - val_loss: 0.2800 - val_mae: 0.0969 - val_mse: 0.0149\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.2818 - mae: 0.1109 - mse: 0.0188 - val_loss: 0.2641 - val_mae: 0.0979 - val_mse: 0.0153\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.2662 - mae: 0.1113 - mse: 0.0191 - val_loss: 0.2501 - val_mae: 0.1010 - val_mse: 0.0162\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.2520 - mae: 0.1148 - mse: 0.0203 - val_loss: 0.2369 - val_mae: 0.1055 - val_mse: 0.0175\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.2389 - mae: 0.1184 - mse: 0.0214 - val_loss: 0.2253 - val_mae: 0.1087 - val_mse: 0.0183\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.2278 - mae: 0.1217 - mse: 0.0224 - val_loss: 0.2153 - val_mae: 0.1088 - val_mse: 0.0182\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2180 - mae: 0.1220 - mse: 0.0225 - val_loss: 0.2065 - val_mae: 0.1136 - val_mse: 0.0197\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2093 - mae: 0.1242 - mse: 0.0232 - val_loss: 0.1988 - val_mae: 0.1248 - val_mse: 0.0230\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.2016 - mae: 0.1287 - mse: 0.0248 - val_loss: 0.1917 - val_mae: 0.1175 - val_mse: 0.0208\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1947 - mae: 0.1261 - mse: 0.0238 - val_loss: 0.1850 - val_mae: 0.1093 - val_mse: 0.0184\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.1883 - mae: 0.1212 - mse: 0.0221 - val_loss: 0.1794 - val_mae: 0.1061 - val_mse: 0.0175\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1826 - mae: 0.1195 - mse: 0.0215 - val_loss: 0.1738 - val_mae: 0.1059 - val_mse: 0.0174\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1770 - mae: 0.1197 - mse: 0.0215 - val_loss: 0.1684 - val_mae: 0.1071 - val_mse: 0.0178\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1714 - mae: 0.1198 - mse: 0.0215 - val_loss: 0.1631 - val_mae: 0.1062 - val_mse: 0.0175\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1665 - mae: 0.1184 - mse: 0.0210 - val_loss: 0.1586 - val_mae: 0.1064 - val_mse: 0.0175\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1617 - mae: 0.1183 - mse: 0.0209 - val_loss: 0.1538 - val_mae: 0.1086 - val_mse: 0.0181\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.1616 - mae: 0.1216 - mse: 0.024 - 0s 97us/step - loss: 0.1567 - mae: 0.1207 - mse: 0.0217 - val_loss: 0.1491 - val_mae: 0.1052 - val_mse: 0.0172\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1522 - mae: 0.1178 - mse: 0.0207 - val_loss: 0.1450 - val_mae: 0.1050 - val_mse: 0.0171\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1478 - mae: 0.1193 - mse: 0.0212 - val_loss: 0.1407 - val_mae: 0.1034 - val_mse: 0.0166\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1434 - mae: 0.1183 - mse: 0.0209 - val_loss: 0.1366 - val_mae: 0.1024 - val_mse: 0.0163\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1392 - mae: 0.1177 - mse: 0.0206 - val_loss: 0.1327 - val_mae: 0.1010 - val_mse: 0.0158\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1356 - mae: 0.1160 - mse: 0.0200 - val_loss: 0.1296 - val_mae: 0.1125 - val_mse: 0.0190\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1324 - mae: 0.1243 - mse: 0.0226 - val_loss: 0.1266 - val_mae: 0.1040 - val_mse: 0.0165\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1295 - mae: 0.1186 - mse: 0.0207 - val_loss: 0.1237 - val_mae: 0.1066 - val_mse: 0.0172\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 160us/step - loss: 0.1266 - mae: 0.1202 - mse: 0.0211 - val_loss: 0.1208 - val_mae: 0.1135 - val_mse: 0.0191\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1235 - mae: 0.1243 - mse: 0.0223 - val_loss: 0.1178 - val_mae: 0.1094 - val_mse: 0.0179\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1206 - mae: 0.1237 - mse: 0.0221 - val_loss: 0.1149 - val_mae: 0.1045 - val_mse: 0.0164\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1177 - mae: 0.1188 - mse: 0.0205 - val_loss: 0.1121 - val_mae: 0.1029 - val_mse: 0.0160\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1150 - mae: 0.1188 - mse: 0.0204 - val_loss: 0.1094 - val_mae: 0.1016 - val_mse: 0.0156\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.1122 - mae: 0.1160 - mse: 0.0195 - val_loss: 0.1068 - val_mae: 0.1085 - val_mse: 0.0175\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1091 - mae: 0.1216 - mse: 0.0212 - val_loss: 0.1031 - val_mae: 0.1078 - val_mse: 0.0171\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1050 - mae: 0.1182 - mse: 0.0201 - val_loss: 0.0991 - val_mae: 0.1095 - val_mse: 0.0175\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1013 - mae: 0.1182 - mse: 0.0201 - val_loss: 0.0959 - val_mae: 0.1022 - val_mse: 0.0155\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0985 - mae: 0.1137 - mse: 0.0188 - val_loss: 0.0931 - val_mae: 0.0972 - val_mse: 0.0143\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0957 - mae: 0.1098 - mse: 0.0177 - val_loss: 0.0907 - val_mae: 0.1012 - val_mse: 0.0153\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0933 - mae: 0.1124 - mse: 0.0185 - val_loss: 0.0882 - val_mae: 0.0948 - val_mse: 0.0137\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0910 - mae: 0.1080 - mse: 0.0173 - val_loss: 0.0861 - val_mae: 0.0944 - val_mse: 0.0136\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0886 - mae: 0.1073 - mse: 0.0171 - val_loss: 0.0837 - val_mae: 0.0929 - val_mse: 0.0132\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0865 - mae: 0.1070 - mse: 0.0169 - val_loss: 0.0815 - val_mae: 0.0930 - val_mse: 0.0132\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0842 - mae: 0.1060 - mse: 0.0167 - val_loss: 0.0793 - val_mae: 0.0901 - val_mse: 0.0125\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0822 - mae: 0.1046 - mse: 0.0163 - val_loss: 0.0776 - val_mae: 0.0889 - val_mse: 0.0122\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0805 - mae: 0.1028 - mse: 0.0158 - val_loss: 0.0759 - val_mae: 0.0888 - val_mse: 0.0122\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0787 - mae: 0.1021 - mse: 0.0157 - val_loss: 0.0742 - val_mae: 0.0885 - val_mse: 0.0122\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0770 - mae: 0.1015 - mse: 0.0155 - val_loss: 0.0726 - val_mae: 0.0895 - val_mse: 0.0125\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0754 - mae: 0.1016 - mse: 0.0156 - val_loss: 0.0712 - val_mae: 0.0891 - val_mse: 0.0124\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0740 - mae: 0.1013 - mse: 0.0155 - val_loss: 0.0697 - val_mae: 0.0846 - val_mse: 0.0113\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0727 - mae: 0.0973 - mse: 0.0145 - val_loss: 0.0685 - val_mae: 0.0844 - val_mse: 0.0113\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0714 - mae: 0.0974 - mse: 0.0146 - val_loss: 0.0673 - val_mae: 0.0830 - val_mse: 0.0109\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0702 - mae: 0.0957 - mse: 0.0141 - val_loss: 0.0661 - val_mae: 0.0824 - val_mse: 0.0108\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0689 - mae: 0.0956 - mse: 0.0141 - val_loss: 0.0649 - val_mae: 0.0805 - val_mse: 0.0103\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0678 - mae: 0.0935 - mse: 0.0137 - val_loss: 0.0637 - val_mae: 0.0815 - val_mse: 0.0106\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0665 - mae: 0.0940 - mse: 0.0138 - val_loss: 0.0626 - val_mae: 0.0841 - val_mse: 0.0113\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0653 - mae: 0.0963 - mse: 0.0144 - val_loss: 0.0613 - val_mae: 0.0802 - val_mse: 0.0103\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0642 - mae: 0.0925 - mse: 0.0134 - val_loss: 0.0603 - val_mae: 0.0810 - val_mse: 0.0106\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0631 - mae: 0.0930 - mse: 0.0136 - val_loss: 0.0592 - val_mae: 0.0796 - val_mse: 0.0102\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0620 - mae: 0.0922 - mse: 0.0133 - val_loss: 0.0582 - val_mae: 0.0782 - val_mse: 0.0099\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0610 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0572 - val_mae: 0.0776 - val_mse: 0.0098\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0601 - mae: 0.0908 - mse: 0.0130 - val_loss: 0.0562 - val_mae: 0.0785 - val_mse: 0.0099\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0590 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0552 - val_mae: 0.0783 - val_mse: 0.0099\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0580 - mae: 0.0912 - mse: 0.0131 - val_loss: 0.0542 - val_mae: 0.0791 - val_mse: 0.0101\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0570 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0532 - val_mae: 0.0796 - val_mse: 0.0102\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0559 - mae: 0.0917 - mse: 0.0131 - val_loss: 0.0521 - val_mae: 0.0775 - val_mse: 0.0097\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0550 - mae: 0.0898 - mse: 0.0127 - val_loss: 0.0513 - val_mae: 0.0774 - val_mse: 0.0097\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0541 - mae: 0.0904 - mse: 0.0128 - val_loss: 0.0505 - val_mae: 0.0753 - val_mse: 0.0092\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 98us/step - loss: 0.0533 - mae: 0.0883 - mse: 0.0122 - val_loss: 0.0497 - val_mae: 0.0762 - val_mse: 0.0094\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0524 - mae: 0.0890 - mse: 0.0124 - val_loss: 0.0489 - val_mae: 0.0797 - val_mse: 0.0102\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0516 - mae: 0.0915 - mse: 0.0130 - val_loss: 0.0480 - val_mae: 0.0770 - val_mse: 0.0095\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0508 - mae: 0.0895 - mse: 0.0125 - val_loss: 0.0472 - val_mae: 0.0757 - val_mse: 0.0092\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0500 - mae: 0.0884 - mse: 0.0122 - val_loss: 0.0464 - val_mae: 0.0754 - val_mse: 0.0092\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0491 - mae: 0.0882 - mse: 0.0122 - val_loss: 0.0457 - val_mae: 0.0747 - val_mse: 0.0090\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0483 - mae: 0.0880 - mse: 0.0121 - val_loss: 0.0448 - val_mae: 0.0750 - val_mse: 0.0090\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0476 - mae: 0.0880 - mse: 0.0121 - val_loss: 0.0441 - val_mae: 0.0758 - val_mse: 0.0092\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0467 - mae: 0.0883 - mse: 0.0121 - val_loss: 0.0433 - val_mae: 0.0777 - val_mse: 0.0096\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 191us/step - loss: 0.0460 - mae: 0.0891 - mse: 0.0123 - val_loss: 0.0427 - val_mae: 0.0788 - val_mse: 0.0098\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0453 - mae: 0.0897 - mse: 0.0124 - val_loss: 0.0420 - val_mae: 0.0779 - val_mse: 0.0096\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0446 - mae: 0.0889 - mse: 0.0122 - val_loss: 0.0412 - val_mae: 0.0756 - val_mse: 0.0091\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 203us/step - loss: 0.0438 - mae: 0.0882 - mse: 0.0121 - val_loss: 0.0405 - val_mae: 0.0734 - val_mse: 0.0086\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0432 - mae: 0.0868 - mse: 0.0117 - val_loss: 0.0399 - val_mae: 0.0757 - val_mse: 0.0091\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0426 - mae: 0.0880 - mse: 0.0120 - val_loss: 0.0392 - val_mae: 0.0749 - val_mse: 0.0089\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0419 - mae: 0.0876 - mse: 0.0119 - val_loss: 0.0386 - val_mae: 0.0730 - val_mse: 0.0084\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0413 - mae: 0.0859 - mse: 0.0115 - val_loss: 0.0380 - val_mae: 0.0738 - val_mse: 0.0086\n",
      "Epoch 92/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 164us/step - loss: 0.0406 - mae: 0.0862 - mse: 0.0115 - val_loss: 0.0374 - val_mae: 0.0731 - val_mse: 0.0085\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0401 - mae: 0.0855 - mse: 0.0114 - val_loss: 0.0368 - val_mae: 0.0753 - val_mse: 0.0089\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0395 - mae: 0.0872 - mse: 0.0117 - val_loss: 0.0362 - val_mae: 0.0718 - val_mse: 0.0082\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0390 - mae: 0.0852 - mse: 0.0113 - val_loss: 0.0357 - val_mae: 0.0715 - val_mse: 0.0081\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 199us/step - loss: 0.0383 - mae: 0.0846 - mse: 0.0111 - val_loss: 0.0352 - val_mae: 0.0705 - val_mse: 0.0079\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0378 - mae: 0.0838 - mse: 0.0109 - val_loss: 0.0347 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0373 - mae: 0.0839 - mse: 0.0110 - val_loss: 0.0342 - val_mae: 0.0741 - val_mse: 0.0087\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0368 - mae: 0.0855 - mse: 0.0113 - val_loss: 0.0337 - val_mae: 0.0717 - val_mse: 0.0082\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0363 - mae: 0.0840 - mse: 0.0110 - val_loss: 0.0332 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0359 - mae: 0.0833 - mse: 0.0108 - val_loss: 0.0327 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0355 - mae: 0.0829 - mse: 0.0107 - val_loss: 0.0324 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0351 - mae: 0.0822 - mse: 0.0106 - val_loss: 0.0320 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0347 - mae: 0.0822 - mse: 0.0106 - val_loss: 0.0316 - val_mae: 0.0684 - val_mse: 0.0075\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0342 - mae: 0.0814 - mse: 0.0104 - val_loss: 0.0311 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0339 - mae: 0.0834 - mse: 0.0109 - val_loss: 0.0308 - val_mae: 0.0710 - val_mse: 0.0080\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0334 - mae: 0.0828 - mse: 0.0108 - val_loss: 0.0304 - val_mae: 0.0682 - val_mse: 0.0075\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0331 - mae: 0.0805 - mse: 0.0103 - val_loss: 0.0301 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0328 - mae: 0.0808 - mse: 0.0103 - val_loss: 0.0297 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0324 - mae: 0.0803 - mse: 0.0102 - val_loss: 0.0294 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0321 - mae: 0.0821 - mse: 0.0106 - val_loss: 0.0291 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0319 - mae: 0.0797 - mse: 0.0101 - val_loss: 0.0288 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0315 - mae: 0.0809 - mse: 0.0104 - val_loss: 0.0284 - val_mae: 0.0681 - val_mse: 0.0074\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0312 - mae: 0.0797 - mse: 0.0101 - val_loss: 0.0282 - val_mae: 0.0693 - val_mse: 0.0077\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0309 - mae: 0.0808 - mse: 0.0103 - val_loss: 0.0280 - val_mae: 0.0670 - val_mse: 0.0072\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0307 - mae: 0.0788 - mse: 0.0099 - val_loss: 0.0276 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0303 - mae: 0.0802 - mse: 0.0102 - val_loss: 0.0273 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0300 - mae: 0.0792 - mse: 0.0100 - val_loss: 0.0270 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0298 - mae: 0.0784 - mse: 0.0099 - val_loss: 0.0268 - val_mae: 0.0677 - val_mse: 0.0073\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0295 - mae: 0.0791 - mse: 0.0100 - val_loss: 0.0264 - val_mae: 0.0684 - val_mse: 0.0075\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0293 - mae: 0.0794 - mse: 0.0101 - val_loss: 0.0263 - val_mae: 0.0668 - val_mse: 0.0072\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0290 - mae: 0.0783 - mse: 0.0099 - val_loss: 0.0261 - val_mae: 0.0676 - val_mse: 0.0073\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0288 - mae: 0.0782 - mse: 0.0098 - val_loss: 0.0258 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0285 - mae: 0.0783 - mse: 0.0098 - val_loss: 0.0256 - val_mae: 0.0657 - val_mse: 0.0069\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0283 - mae: 0.0770 - mse: 0.0096 - val_loss: 0.0253 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0281 - mae: 0.0775 - mse: 0.0097 - val_loss: 0.0250 - val_mae: 0.0698 - val_mse: 0.0077\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0279 - mae: 0.0796 - mse: 0.0101 - val_loss: 0.0249 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0277 - mae: 0.0770 - mse: 0.0096 - val_loss: 0.0248 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0275 - mae: 0.0760 - mse: 0.0093 - val_loss: 0.0247 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0274 - mae: 0.0756 - mse: 0.0093 - val_loss: 0.0245 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0271 - mae: 0.0762 - mse: 0.0094 - val_loss: 0.0244 - val_mae: 0.0642 - val_mse: 0.0066\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 162us/step - loss: 0.0269 - mae: 0.0756 - mse: 0.0092 - val_loss: 0.0242 - val_mae: 0.0638 - val_mse: 0.0065\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0268 - mae: 0.0747 - mse: 0.0090 - val_loss: 0.0239 - val_mae: 0.0662 - val_mse: 0.0070\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 153us/step - loss: 0.0266 - mae: 0.0765 - mse: 0.0094 - val_loss: 0.0238 - val_mae: 0.0651 - val_mse: 0.0068\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0265 - mae: 0.0757 - mse: 0.0093 - val_loss: 0.0237 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 185us/step - loss: 0.0263 - mae: 0.0761 - mse: 0.0093 - val_loss: 0.0235 - val_mae: 0.0655 - val_mse: 0.0068\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0262 - mae: 0.0752 - mse: 0.0092 - val_loss: 0.0233 - val_mae: 0.0652 - val_mse: 0.0068\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0260 - mae: 0.0752 - mse: 0.0091 - val_loss: 0.0233 - val_mae: 0.0641 - val_mse: 0.0065\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0258 - mae: 0.0739 - mse: 0.0089 - val_loss: 0.0231 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0257 - mae: 0.0744 - mse: 0.0090 - val_loss: 0.0230 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0256 - mae: 0.0737 - mse: 0.0088 - val_loss: 0.0228 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0254 - mae: 0.0743 - mse: 0.0089 - val_loss: 0.0228 - val_mae: 0.0623 - val_mse: 0.0062\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 193us/step - loss: 0.0253 - mae: 0.0723 - mse: 0.0085 - val_loss: 0.0227 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0251 - mae: 0.0724 - mse: 0.0085 - val_loss: 0.0224 - val_mae: 0.0640 - val_mse: 0.0065\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0249 - mae: 0.0732 - mse: 0.0087 - val_loss: 0.0224 - val_mae: 0.0627 - val_mse: 0.0063\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0248 - mae: 0.0728 - mse: 0.0086 - val_loss: 0.0224 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0247 - mae: 0.0711 - mse: 0.0082 - val_loss: 0.0221 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 153us/step - loss: 0.0245 - mae: 0.0718 - mse: 0.0084 - val_loss: 0.0219 - val_mae: 0.0635 - val_mse: 0.0064\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0244 - mae: 0.0725 - mse: 0.0085 - val_loss: 0.0220 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0242 - mae: 0.0705 - mse: 0.0081 - val_loss: 0.0218 - val_mae: 0.0613 - val_mse: 0.0060\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0241 - mae: 0.0703 - mse: 0.0080 - val_loss: 0.0216 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0240 - mae: 0.0706 - mse: 0.0081 - val_loss: 0.0217 - val_mae: 0.0630 - val_mse: 0.0063\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0239 - mae: 0.0713 - mse: 0.0082 - val_loss: 0.0214 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0237 - mae: 0.0699 - mse: 0.0080 - val_loss: 0.0213 - val_mae: 0.0622 - val_mse: 0.0062\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0236 - mae: 0.0704 - mse: 0.0081 - val_loss: 0.0211 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 218us/step - loss: 0.0235 - mae: 0.0712 - mse: 0.0082 - val_loss: 0.0211 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 285us/step - loss: 0.0234 - mae: 0.0705 - mse: 0.0081 - val_loss: 0.0209 - val_mae: 0.0627 - val_mse: 0.0063\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 183us/step - loss: 0.0233 - mae: 0.0702 - mse: 0.0081 - val_loss: 0.0209 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0231 - mae: 0.0708 - mse: 0.0082 - val_loss: 0.0208 - val_mae: 0.0603 - val_mse: 0.0058\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0230 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0208 - val_mae: 0.0604 - val_mse: 0.0058\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0230 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0206 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0229 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0205 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0228 - mae: 0.0689 - mse: 0.0077 - val_loss: 0.0205 - val_mae: 0.0620 - val_mse: 0.0061\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0227 - mae: 0.0695 - mse: 0.0078 - val_loss: 0.0204 - val_mae: 0.0600 - val_mse: 0.0058\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0226 - mae: 0.0683 - mse: 0.0076 - val_loss: 0.0203 - val_mae: 0.0611 - val_mse: 0.0060\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0225 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0203 - val_mae: 0.0599 - val_mse: 0.0057\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0677 - mse: 0.0075 - val_loss: 0.0202 - val_mae: 0.0597 - val_mse: 0.0057\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0223 - mae: 0.0673 - mse: 0.0074 - val_loss: 0.0202 - val_mae: 0.0590 - val_mse: 0.0056\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0223 - mae: 0.0674 - mse: 0.0074 - val_loss: 0.0201 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0222 - mae: 0.0677 - mse: 0.0075 - val_loss: 0.0199 - val_mae: 0.0602 - val_mse: 0.0058\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0221 - mae: 0.0683 - mse: 0.0076 - val_loss: 0.0199 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0220 - mae: 0.0671 - mse: 0.0074 - val_loss: 0.0198 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0219 - mae: 0.0682 - mse: 0.0076 - val_loss: 0.0198 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0218 - mae: 0.0671 - mse: 0.0074 - val_loss: 0.0197 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0217 - mae: 0.0659 - mse: 0.0071 - val_loss: 0.0195 - val_mae: 0.0598 - val_mse: 0.0057\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0216 - mae: 0.0673 - mse: 0.0074 - val_loss: 0.0196 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0216 - mae: 0.0660 - mse: 0.0071 - val_loss: 0.0195 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0214 - mae: 0.0670 - mse: 0.0074 - val_loss: 0.0194 - val_mae: 0.0596 - val_mse: 0.0057\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0672 - mse: 0.0074 - val_loss: 0.0193 - val_mae: 0.0587 - val_mse: 0.0055\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0213 - mae: 0.0665 - mse: 0.0073 - val_loss: 0.0193 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0657 - mse: 0.0071 - val_loss: 0.0192 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0211 - mae: 0.0662 - mse: 0.0072 - val_loss: 0.0192 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0211 - mae: 0.0650 - mse: 0.0069 - val_loss: 0.0192 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0211 - mae: 0.0651 - mse: 0.0070 - val_loss: 0.0190 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0210 - mae: 0.0656 - mse: 0.0071 - val_loss: 0.0189 - val_mae: 0.0587 - val_mse: 0.0056\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0659 - mse: 0.0072 - val_loss: 0.0188 - val_mae: 0.0590 - val_mse: 0.0056\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0208 - mae: 0.0663 - mse: 0.0073 - val_loss: 0.0189 - val_mae: 0.0575 - val_mse: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0207 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0188 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0656 - mse: 0.0070 - val_loss: 0.0188 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 236us/step - loss: 0.0206 - mae: 0.0649 - mse: 0.0069 - val_loss: 0.0187 - val_mae: 0.0574 - val_mse: 0.0054\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 203us/step - loss: 0.0206 - mae: 0.0651 - mse: 0.0070 - val_loss: 0.0186 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0205 - mae: 0.0654 - mse: 0.0071 - val_loss: 0.0186 - val_mae: 0.0579 - val_mse: 0.0055\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 162us/step - loss: 0.0205 - mae: 0.0653 - mse: 0.0070 - val_loss: 0.0185 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0204 - mae: 0.0656 - mse: 0.0071 - val_loss: 0.0185 - val_mae: 0.0582 - val_mse: 0.0055\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0185 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0203 - mae: 0.0649 - mse: 0.0070 - val_loss: 0.0183 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0184 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0184 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0201 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0182 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0201 - mae: 0.0648 - mse: 0.0069 - val_loss: 0.0182 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0182 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0200 - mae: 0.0642 - mse: 0.0068 - val_loss: 0.0181 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0199 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0180 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0648 - mse: 0.0070 - val_loss: 0.0180 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0198 - mae: 0.0647 - mse: 0.0069 - val_loss: 0.0180 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0198 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0646 - mse: 0.0069 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0179 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0179 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0196 - mae: 0.0636 - mse: 0.0067 - val_loss: 0.0177 - val_mae: 0.0574 - val_mse: 0.0053\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0196 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0178 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0642 - mse: 0.0068 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0177 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0194 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0176 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0176 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0175 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0174 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0647 - mse: 0.0069 - val_loss: 0.0175 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0175 - val_mae: 0.0589 - val_mse: 0.0055\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0643 - mse: 0.0068 - val_loss: 0.0174 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0634 - mse: 0.0066 - val_loss: 0.0174 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0639 - mse: 0.0067 - val_loss: 0.0174 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0191 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0173 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0191 - mae: 0.0636 - mse: 0.0067 - val_loss: 0.0172 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0173 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0171 - val_mae: 0.0567 - val_mse: 0.0053\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0643 - mse: 0.0069 - val_loss: 0.0172 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0189 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0171 - val_mae: 0.0564 - val_mse: 0.0051\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0189 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0170 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0188 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0170 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0646 - mse: 0.0070 - val_loss: 0.0171 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0188 - mae: 0.0633 - mse: 0.0066 - val_loss: 0.0170 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0187 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0169 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0187 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0169 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0187 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0169 - val_mae: 0.0571 - val_mse: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0187 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0168 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0186 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0168 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0167 - val_mae: 0.0576 - val_mse: 0.0055\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0186 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0578 - val_mse: 0.0055\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0185 - mae: 0.0650 - mse: 0.0070 - val_loss: 0.0167 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0167 - val_mae: 0.0559 - val_mse: 0.0050\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0165 - val_mae: 0.0566 - val_mse: 0.0053\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0184 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0165 - val_mae: 0.0583 - val_mse: 0.0055\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0184 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0166 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0184 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0183 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0164 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0183 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0164 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0165 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0163 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0182 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0182 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0051\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0163 - val_mae: 0.0556 - val_mse: 0.0050\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0162 - val_mae: 0.0561 - val_mse: 0.0051\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0181 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0181 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0162 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0568 - val_mse: 0.0052\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0161 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0180 - mae: 0.0649 - mse: 0.0070 - val_loss: 0.0162 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0162 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0161 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0179 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0160 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0178 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0161 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0052\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0052\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0158 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0160 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0158 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0157 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0176 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0157 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0158 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0156 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0158 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0158 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0624 - mse: 0.0065 - val_loss: 0.0156 - val_mae: 0.0574 - val_mse: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0157 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0175 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0157 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0175 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0156 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0174 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0156 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0174 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0174 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0154 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0155 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0173 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0173 - mae: 0.0625 - mse: 0.0065 - val_loss: 0.0154 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0154 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0173 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0153 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0153 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0153 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0172 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0154 - val_mae: 0.0584 - val_mse: 0.0054\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0172 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0153 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0154 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0153 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0154 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0171 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0171 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0152 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0152 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0170 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0170 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0170 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0170 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0170 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0151 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0151 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0150 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0151 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0150 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0152 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0151 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0150 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0150 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0168 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0150 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0177 - mae: 0.0580 - mse: 0.007 - 0s 116us/step - loss: 0.0168 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0582 - val_mse: 0.0052\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0168 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0167 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0149 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0167 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0167 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0149 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0167 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0147 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0166 - mae: 0.0645 - mse: 0.0070 - val_loss: 0.0147 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0166 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0149 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0166 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0149 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0166 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0147 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0147 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0165 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0148 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0165 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0147 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0147 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0148 - val_mae: 0.0578 - val_mse: 0.0051\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0165 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0146 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0146 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0164 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0643 - mse: 0.0069 - val_loss: 0.0146 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0144 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0163 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0144 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0144 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0162 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0580 - val_mse: 0.0051\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0162 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0162 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0161 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0142 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0161 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0161 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0161 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0142 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0161 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0161 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0160 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0569 - val_mse: 0.0049\n",
      "Epoch 379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0160 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0160 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0160 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0160 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0160 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0160 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0159 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0142 - val_mae: 0.0580 - val_mse: 0.0051\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0159 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0159 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0159 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0158 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0587 - val_mse: 0.0055\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0158 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0157 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0139 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0157 - mae: 0.0643 - mse: 0.0070 - val_loss: 0.0140 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0157 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0157 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0157 - mae: 0.0644 - mse: 0.0070 - val_loss: 0.0139 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0157 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0157 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0156 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0156 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0156 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0156 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0156 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0156 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0138 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0155 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0155 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mae: 0.0646 - mse: 0.0070 - val_loss: 0.0137 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0155 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0155 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0589 - val_mse: 0.0053\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0155 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0155 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0138 - val_mae: 0.0584 - val_mse: 0.0053\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0154 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0154 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0136 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0154 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0154 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0154 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0154 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0138 - val_mae: 0.0583 - val_mse: 0.0052\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0154 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 184us/step - loss: 0.0154 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0153 - mae: 0.0638 - mse: 0.0069 - val_loss: 0.0137 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0153 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 427/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 68us/step - loss: 0.0153 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0135 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.0153 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0153 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0588 - val_mse: 0.0055\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 47us/step - loss: 0.0153 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 65us/step - loss: 0.0153 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 78us/step - loss: 0.0153 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 161us/step - loss: 0.0152 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0135 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0152 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0152 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0152 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0152 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0151 - mae: 0.0632 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0151 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0586 - val_mse: 0.0054\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0150 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0150 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0150 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0133 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0150 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0150 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0149 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0133 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0593 - val_mse: 0.0054\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0149 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0149 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0149 - mae: 0.0637 - mse: 0.0069 - val_loss: 0.0132 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0149 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0149 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0133 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0148 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 133us/step - loss: 0.0148 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0148 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0148 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0147 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0133 - val_mae: 0.0579 - val_mse: 0.0051\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0147 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mae: 0.0627 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0147 - mae: 0.0626 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0130 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0146 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0129 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0146 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0590 - val_mse: 0.0054\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0146 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0146 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0145 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0128 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0145 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0584 - val_mse: 0.0052\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0578 - val_mse: 0.0051\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0144 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0128 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 116us/step - loss: 0.0144 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0144 - mae: 0.0627 - mse: 0.0067 - val_loss: 0.0128 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0144 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0144 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0143 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0126 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mae: 0.0617 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0142 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0142 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0142 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0126 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0611 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0141 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0141 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0125 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0125 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0140 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0140 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0612 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0124 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0139 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0124 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0127 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0139 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0139 - mae: 0.0607 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0139 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0125 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0138 - mae: 0.0614 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0138 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0138 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0123 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0138 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0138 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0579 - val_mse: 0.0051\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mae: 0.0612 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0617 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mae: 0.0607 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0122 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0137 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0137 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mae: 0.0606 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0064 - val_loss: 0.0121 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0613 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0136 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0136 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0136 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mae: 0.0601 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0135 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0565 - val_mse: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0136 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0613 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0145 - mae: 0.0664 - mse: 0.007 - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0120 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0135 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0608 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0134 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0609 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0598 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0134 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0134 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0134 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mae: 0.0601 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0134 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0134 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0134 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0134 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0133 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0134 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0134 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0133 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 148us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0133 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0133 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mae: 0.0608 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0133 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0133 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0123 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0133 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 136us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 140us/step - loss: 0.0133 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 134us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0132 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0132 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0133 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0122 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0132 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0131 - mae: 0.0598 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0131 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0132 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0131 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 762/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 119us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0131 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0131 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0050\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0117 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0131 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0117 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0562 - val_mse: 0.0048\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0131 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0565 - val_mse: 0.0051\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0130 - mae: 0.0593 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0129 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0130 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0130 - mae: 0.0599 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0130 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0130 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0129 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0129 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0130 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0129 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0129 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0129 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0556 - val_mse: 0.0049\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0118 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0128 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0127 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 851/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 852/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0050\n",
      "Epoch 853/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mae: 0.0598 - mse: 0.0060 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 854/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 855/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 856/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 857/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 859/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 860/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 861/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 862/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 863/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 864/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 865/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0127 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 866/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 867/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 868/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 869/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 870/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0579 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 871/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 872/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 873/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 874/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 875/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 876/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 877/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 878/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 879/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 880/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 881/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 882/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0126 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 883/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 884/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 885/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 886/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mae: 0.0594 - mse: 0.0059 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 887/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 888/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0126 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 889/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 890/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 891/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 892/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 893/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 894/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 895/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 896/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 897/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0125 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 898/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 899/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 900/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 901/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 902/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 903/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 904/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 905/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 906/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 122us/step - loss: 0.0125 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 907/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 908/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 909/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 910/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 911/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 912/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 913/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 914/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 915/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0125 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 916/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 917/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0116 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 918/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0125 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 919/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 920/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 921/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 922/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 923/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 924/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0058 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 925/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 926/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 927/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 928/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 929/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 930/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 931/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 932/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0577 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 933/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0574 - mse: 0.0055 - val_loss: 0.0115 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 934/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 935/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0568 - val_mse: 0.0049\n",
      "Epoch 936/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 937/10000\n",
      "482/482 [==============================] - 0s 182us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 938/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 939/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 940/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 941/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 942/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 943/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 944/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 945/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0574 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 946/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 947/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0048\n",
      "Epoch 948/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 949/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 950/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 951/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 952/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 953/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 954/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 131us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 955/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0115 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 956/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0124 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0048\n",
      "Epoch 957/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0556 - val_mse: 0.0049\n",
      "Epoch 958/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 959/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 960/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 961/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 962/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 963/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 964/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 965/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 966/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 967/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 968/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 969/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 970/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0123 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 971/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0571 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 972/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 973/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 974/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0056 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 975/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 976/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 977/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0123 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0560 - val_mse: 0.0050\n",
      "Epoch 978/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 979/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 980/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 981/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 982/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0584 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 983/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 984/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 985/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 986/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 987/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 988/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 989/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 990/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0571 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 991/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0555 - val_mse: 0.0049\n",
      "Epoch 992/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 993/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 994/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0122 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 995/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 996/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0122 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 997/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0122 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 999/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1000/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1001/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0546 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1002/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1003/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 1004/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1005/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1006/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1007/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1008/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1009/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1010/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0564 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1011/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1012/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1013/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1014/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 1015/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1016/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1017/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1018/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1019/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1020/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 1021/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1022/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0579 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 1023/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1024/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1025/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1026/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0121 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1027/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 1028/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0584 - mse: 0.0057 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1029/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1030/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1031/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0121 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1032/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1033/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1034/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1035/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1036/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1037/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1038/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1039/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1040/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1041/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1042/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1043/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1044/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0121 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1045/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1046/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1047/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0120 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1048/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1049/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1050/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1051/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0121 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0113 - val_mae: 0.0558 - val_mse: 0.0047\n",
      "Epoch 1052/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0121 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1053/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1054/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 1055/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1056/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1057/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1058/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0574 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1059/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1060/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1061/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1062/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1063/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 1064/10000\n",
      "482/482 [==============================] - 0s 127us/step - loss: 0.0120 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1065/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1066/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1067/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1068/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1069/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1070/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1071/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1072/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 1073/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1074/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1075/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1076/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1077/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1078/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1079/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1080/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1081/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1082/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1083/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1084/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1085/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1086/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1087/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1088/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1089/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1090/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1091/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1092/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1093/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1094/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1095/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1096/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1097/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1098/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1099/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1100/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1101/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0119 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1102/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1103/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0047\n",
      "Epoch 1104/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 1105/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1107/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1108/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1109/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1110/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1111/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1112/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1113/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1114/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1115/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 1116/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1117/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0047\n",
      "Epoch 1118/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1119/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1120/10000\n",
      "482/482 [==============================] - 0s 128us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1121/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1122/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1123/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1124/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1125/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1126/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1127/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1128/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1129/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1130/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1131/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1132/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1133/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1134/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1135/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1136/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1137/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1138/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1139/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1140/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1141/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1142/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1143/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1144/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1145/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0554 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1146/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1147/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1148/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1149/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1150/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1151/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1152/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1153/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0045\n",
      "Epoch 1154/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1155/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1156/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1157/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1159/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1160/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1161/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1163/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1164/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1165/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1166/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1168/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1169/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1170/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1171/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1172/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1173/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1174/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1175/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1176/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1177/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1178/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1179/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1180/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1181/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1182/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1183/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1184/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1185/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1186/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1187/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1188/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1189/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0545 - val_mse: 0.0047\n",
      "Epoch 1191/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1192/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1193/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1194/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1195/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 1196/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1197/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1198/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1199/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1200/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1201/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1202/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1203/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1204/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1205/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1206/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1207/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1208/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1209/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1210/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1211/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0547 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1212/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1213/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1214/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1215/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1216/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1217/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1218/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1219/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0560 - val_mse: 0.0047\n",
      "Epoch 1220/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1221/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1222/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1223/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1224/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 1225/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1226/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1227/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1228/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1229/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1230/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1231/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1232/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0549 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1233/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1234/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1235/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1236/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1237/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1238/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1239/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1240/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1241/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0563 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1242/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1243/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0116 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1244/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1245/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0115 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1246/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1247/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1248/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1249/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1250/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1251/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1252/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1253/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0115 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1254/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1255/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1256/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1257/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1258/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1259/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1260/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1261/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1262/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1263/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1264/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1265/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0528 - val_mse: 0.0044\n",
      "Epoch 1266/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0107 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1267/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1269/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1270/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1271/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1272/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1273/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1274/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1275/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1278/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1279/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1280/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1281/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1282/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1283/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1284/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1285/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1286/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1287/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 1288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0552 - val_mse: 0.0046\n",
      "Epoch 1289/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1290/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1291/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1292/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1293/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0544 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1294/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1295/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1296/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1297/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1298/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1299/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1300/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1301/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0552 - val_mse: 0.0046\n",
      "Epoch 1302/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1303/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1304/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1305/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1306/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1307/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1308/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1309/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1310/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1311/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1312/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1313/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1314/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1316/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 1317/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1318/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1319/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1320/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1322/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1323/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1324/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1325/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0114 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1328/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1329/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0544 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1330/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1331/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1332/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1333/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1334/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1335/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1336/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1337/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1338/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1339/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1340/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1341/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1342/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1343/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1344/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1345/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1346/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1348/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1349/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1350/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1351/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1352/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1353/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1354/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1355/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1356/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1357/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1358/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1359/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1360/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1361/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1362/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1363/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0112 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1364/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1365/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1366/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1367/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1368/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1369/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1370/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1371/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1372/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1373/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1374/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1375/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1376/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1377/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1378/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1379/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1380/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1381/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1383/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1384/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1385/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1386/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1387/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1388/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1389/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1390/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0539 - val_mse: 0.0046\n",
      "Epoch 1391/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1392/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1393/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1394/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1395/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1396/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1397/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1398/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1399/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1400/10000\n",
      "482/482 [==============================] - 0s 167us/step - loss: 0.0112 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1401/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1402/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1403/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1404/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1405/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1406/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1408/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1409/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1410/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1411/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1412/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1413/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1414/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1415/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1416/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1417/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1418/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0045\n",
      "Epoch 1419/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0109 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1420/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0543 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1421/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1422/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1423/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1424/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1425/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1426/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1427/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1428/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1429/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0045\n",
      "Epoch 1430/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1431/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1432/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1433/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1434/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0102 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1435/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0043\n",
      "Epoch 1436/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1437/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1438/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1439/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1440/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1441/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1442/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1443/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1445/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1446/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1447/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1448/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1449/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1450/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1451/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1452/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0124 - mae: 0.0587 - mse: 0.006 - 0s 112us/step - loss: 0.0111 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1454/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1456/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1457/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1458/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1459/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1460/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1461/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1462/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1463/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1464/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1465/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1466/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0043\n",
      "Epoch 1467/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1468/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1469/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1470/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1471/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1472/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1473/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1474/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1475/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1476/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1477/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1478/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1479/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1480/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1481/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1482/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1483/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1484/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1485/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1486/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1487/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1488/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1489/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1490/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1491/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1492/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1493/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1494/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1495/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1496/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1497/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1498/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1499/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1500/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0553 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1501/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1502/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1503/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1504/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1505/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1506/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1508/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1509/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1510/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1511/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1513/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1514/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1515/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1516/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0100 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1517/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1518/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0538 - val_mse: 0.0046\n",
      "Epoch 1519/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1520/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0105 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1521/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1522/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1523/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0527 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1524/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1525/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1526/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1528/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1529/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1530/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0104 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1531/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1532/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1533/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1534/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1535/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1536/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1537/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1538/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1539/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1540/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1541/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1542/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1543/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1544/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1545/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1546/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1547/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1548/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1549/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1550/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1551/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1552/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1553/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1554/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1555/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1556/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0109 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1557/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1558/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1559/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1560/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1561/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1562/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1563/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1564/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1565/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1566/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0520 - val_mse: 0.0043\n",
      "Epoch 1567/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1568/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1569/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1570/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1571/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0108 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1572/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1573/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1574/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1576/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1577/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1578/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1579/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1580/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0553 - val_mse: 0.0046\n",
      "Epoch 1581/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1582/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1583/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1584/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1585/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1586/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1587/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1588/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1589/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1590/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1591/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1592/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1593/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1594/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1595/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1596/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1597/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1598/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1599/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0108 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1600/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1601/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0107 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1602/10000\n",
      "482/482 [==============================] - 0s 152us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1603/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0108 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1604/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1605/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1606/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1607/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1608/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1609/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1610/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1611/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1612/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1613/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1614/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1615/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1616/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1617/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1618/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1619/10000\n",
      "482/482 [==============================] - 0s 150us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1620/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0107 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1621/10000\n",
      "482/482 [==============================] - 0s 134us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1622/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1623/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1624/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1625/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1626/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0107 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1627/10000\n",
      "482/482 [==============================] - 0s 146us/step - loss: 0.0107 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0099 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1628/10000\n",
      "482/482 [==============================] - 0s 138us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1629/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1630/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1631/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1632/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0042\n",
      "Epoch 1633/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1634/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1635/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1636/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1637/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1638/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1639/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1640/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1641/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1642/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1643/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1644/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1645/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1646/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1647/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1648/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1649/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1650/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1651/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1652/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1653/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1654/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1655/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1656/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1657/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1658/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1659/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1660/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0042\n",
      "Epoch 1661/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 1662/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1663/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1664/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1665/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1666/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1667/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1668/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1669/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1670/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1672/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1673/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1674/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1675/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1676/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1677/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1678/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1679/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1680/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1681/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1682/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1684/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1685/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1686/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1687/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1688/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1689/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1690/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1691/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1692/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1693/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0106 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1694/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1695/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1696/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1697/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1698/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1699/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1700/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1702/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1703/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0106 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1704/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1705/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1706/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1707/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1708/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1709/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0046\n",
      "Epoch 1710/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1711/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1712/10000\n",
      "482/482 [==============================] - 0s 109us/step - loss: 0.0106 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1713/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1714/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1715/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1716/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1717/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1718/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0555 - val_mse: 0.0047\n",
      "Epoch 1719/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1720/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1721/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1722/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1723/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1724/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1725/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1726/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1727/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1728/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1729/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1730/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1731/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1732/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1733/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1734/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1736/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1737/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1738/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1739/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1740/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1741/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1742/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1743/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1744/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1745/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1746/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1747/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1748/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1749/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1750/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1751/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1752/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1753/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1754/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1755/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0105 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1756/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1757/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1758/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1759/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1760/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1761/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1762/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1763/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1764/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0044\n",
      "Epoch 1765/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1766/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1767/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1768/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1769/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1770/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1771/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1772/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1773/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1774/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1775/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1776/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1777/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1778/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1779/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1780/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1781/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1782/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1783/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1784/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1785/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1786/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1787/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1788/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1789/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1790/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1791/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1792/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1793/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1794/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1795/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1796/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1797/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0514 - val_mse: 0.0042\n",
      "Epoch 1798/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1799/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0042\n",
      "Epoch 1800/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1801/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1802/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1803/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0513 - val_mse: 0.0042\n",
      "Epoch 1804/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1805/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1806/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1807/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1808/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1809/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1810/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1811/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1812/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1813/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1814/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1815/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1816/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1817/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1818/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1819/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1820/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1821/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1822/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1823/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1824/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1825/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1826/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1827/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1828/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1829/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1830/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1831/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 1832/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1833/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1834/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1835/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1836/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1838/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1839/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1840/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1841/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0532 - val_mse: 0.0043\n",
      "Epoch 1842/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1843/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1844/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1845/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1846/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1847/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1848/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1849/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1850/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1851/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1852/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1853/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1854/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1855/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1856/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1857/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1858/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1859/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1860/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1861/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1862/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1863/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1864/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1865/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1866/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1867/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1868/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1869/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1870/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1871/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1872/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1873/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0081 - mae: 0.0410 - mse: 0.002 - 0s 108us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1874/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1875/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1876/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1877/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1878/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1879/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1880/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1881/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1882/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1883/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1884/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1885/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1886/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1887/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1888/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1889/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1890/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1891/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1892/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1893/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1894/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1895/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1896/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1897/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1898/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1899/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1900/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0536 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1901/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1902/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0096 - val_mae: 0.0509 - val_mse: 0.0041\n",
      "Epoch 1903/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1904/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1905/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1906/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1907/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1908/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1909/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1910/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1911/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1912/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1913/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1914/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1915/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1916/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1917/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1918/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1919/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1920/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1921/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0105 - mae: 0.0562 - mse: 0.005 - 0s 120us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1922/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1923/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1924/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1925/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1926/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1927/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1928/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1929/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1930/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1931/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1932/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0508 - val_mse: 0.0041\n",
      "Epoch 1933/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1934/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1935/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1936/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1937/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1938/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1939/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1940/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1941/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0043\n",
      "Epoch 1942/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1943/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1944/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1945/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 1946/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1947/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1948/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0539 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1949/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1950/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1951/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0520 - val_mse: 0.0041\n",
      "Epoch 1952/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1953/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1954/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1955/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 1956/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0042\n",
      "Epoch 1957/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1958/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1959/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1960/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0523 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1961/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1962/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1963/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1964/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1965/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0101 - mae: 0.0550 - mse: 0.004 - 0s 104us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1966/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0040\n",
      "Epoch 1967/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1968/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1969/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1970/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1971/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0106 - val_mae: 0.0546 - val_mse: 0.0048\n",
      "Epoch 1972/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 1973/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1974/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1975/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1976/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1977/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1978/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1979/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0508 - val_mse: 0.0041\n",
      "Epoch 1980/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0523 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1981/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0042\n",
      "Epoch 1982/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1983/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1984/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1985/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1986/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1987/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1988/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1989/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1990/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1991/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1992/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1993/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1994/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1995/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1996/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1997/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1999/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 2000/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2001/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 2002/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 2003/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 2004/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2005/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2006/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2007/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 2008/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 2009/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2010/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2011/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2012/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2013/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 2014/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0518 - mse: 0.0046 - val_loss: 0.0097 - val_mae: 0.0546 - val_mse: 0.0045\n",
      "Epoch 2015/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2016/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 2017/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2018/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2019/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0523 - mse: 0.0046 - val_loss: 0.0093 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 2020/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2021/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 2022/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2023/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2024/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 2025/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2026/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2027/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 2028/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0510 - val_mse: 0.0040\n",
      "Epoch 2029/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 2030/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2031/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 2032/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 2033/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 2034/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2035/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2036/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2037/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2038/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 2039/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0046 - val_loss: 0.0095 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 2040/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2041/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 2042/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2043/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 2044/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0520 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2045/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 2046/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 2047/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2048/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0523 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 2049/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2050/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 2051/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2052/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2053/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 2054/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 2055/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0506 - val_mse: 0.0040\n",
      "Epoch 2056/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0042\n",
      "Epoch 2057/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2058/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0046 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2059/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 2060/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 2061/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2062/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 2063/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2064/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 2065/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 2066/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 2067/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2068/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 2069/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 2070/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 2071/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0099 - mae: 0.0522 - mse: 0.0046 - val_loss: 0.0092 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2072/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0099 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2073/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0533 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2074/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 2075/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 2076/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0505 - val_mse: 0.0040\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 02076: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_default = build_default_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_default.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "model_default.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['default'] = model_default.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.3553 - mae: 0.3076 - val_loss: 0.3525 - val_mae: 0.3612\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.3351 - mae: 0.2935 - val_loss: 0.3118 - val_mae: 0.3185\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.3002 - mae: 0.2552 - val_loss: 0.2708 - val_mae: 0.2673\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.2893 - mae: 0.2512 - val_loss: 0.2398 - val_mae: 0.2254\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2711 - mae: 0.2379 - val_loss: 0.2223 - val_mae: 0.2036\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2504 - mae: 0.2172 - val_loss: 0.2046 - val_mae: 0.1781\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.2403 - mae: 0.2127 - val_loss: 0.1921 - val_mae: 0.1657\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.2246 - mae: 0.2013 - val_loss: 0.1841 - val_mae: 0.1675\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2177 - mae: 0.2000 - val_loss: 0.1714 - val_mae: 0.1498\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.2071 - mae: 0.1986 - val_loss: 0.1615 - val_mae: 0.1385\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1975 - mae: 0.1913 - val_loss: 0.1559 - val_mae: 0.1438\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1861 - mae: 0.1794 - val_loss: 0.1512 - val_mae: 0.1474\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1756 - mae: 0.1735 - val_loss: 0.1446 - val_mae: 0.1420\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1719 - mae: 0.1764 - val_loss: 0.1420 - val_mae: 0.1510\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1639 - mae: 0.1705 - val_loss: 0.1373 - val_mae: 0.1479\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1601 - mae: 0.1728 - val_loss: 0.1315 - val_mae: 0.1390\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.1538 - mae: 0.1693 - val_loss: 0.1279 - val_mae: 0.1422\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1448 - mae: 0.1621 - val_loss: 0.1244 - val_mae: 0.1443\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1435 - mae: 0.1678 - val_loss: 0.1201 - val_mae: 0.1402\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1355 - mae: 0.1592 - val_loss: 0.1166 - val_mae: 0.1381\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1300 - mae: 0.1567 - val_loss: 0.1128 - val_mae: 0.1336\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1244 - mae: 0.1481 - val_loss: 0.1098 - val_mae: 0.1355\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1232 - mae: 0.1547 - val_loss: 0.1077 - val_mae: 0.1403\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1179 - mae: 0.1498 - val_loss: 0.1030 - val_mae: 0.1286\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1147 - mae: 0.1476 - val_loss: 0.1005 - val_mae: 0.1250\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1140 - mae: 0.1529 - val_loss: 0.0991 - val_mae: 0.1283\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1153 - mae: 0.1565 - val_loss: 0.0977 - val_mae: 0.1274\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1098 - mae: 0.1475 - val_loss: 0.0966 - val_mae: 0.1266\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1105 - mae: 0.1544 - val_loss: 0.0958 - val_mae: 0.1266\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1079 - mae: 0.1490 - val_loss: 0.0944 - val_mae: 0.1244\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1062 - mae: 0.1466 - val_loss: 0.0934 - val_mae: 0.1258\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.1042 - mae: 0.1475 - val_loss: 0.0911 - val_mae: 0.1138\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1015 - mae: 0.1386 - val_loss: 0.0905 - val_mae: 0.1189\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0999 - mae: 0.1372 - val_loss: 0.0893 - val_mae: 0.1205\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0981 - mae: 0.1337 - val_loss: 0.0881 - val_mae: 0.1196\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0985 - mae: 0.1409 - val_loss: 0.0862 - val_mae: 0.1141\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0962 - mae: 0.1351 - val_loss: 0.0858 - val_mae: 0.1176\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0957 - mae: 0.1378 - val_loss: 0.0845 - val_mae: 0.1156\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0944 - mae: 0.1361 - val_loss: 0.0830 - val_mae: 0.1103\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0926 - mae: 0.1366 - val_loss: 0.0820 - val_mae: 0.1144\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0926 - mae: 0.1365 - val_loss: 0.0810 - val_mae: 0.1150\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0908 - mae: 0.1362 - val_loss: 0.0793 - val_mae: 0.1063\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0897 - mae: 0.1309 - val_loss: 0.0792 - val_mae: 0.1150\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0876 - mae: 0.1343 - val_loss: 0.0782 - val_mae: 0.1161\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0879 - mae: 0.1385 - val_loss: 0.0766 - val_mae: 0.1104\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0866 - mae: 0.1359 - val_loss: 0.0755 - val_mae: 0.1087\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0838 - mae: 0.1272 - val_loss: 0.0753 - val_mae: 0.1147\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0822 - mae: 0.1233 - val_loss: 0.0737 - val_mae: 0.1108\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0798 - mae: 0.1263 - val_loss: 0.0724 - val_mae: 0.1081\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0816 - mae: 0.1283 - val_loss: 0.0716 - val_mae: 0.1086\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0792 - mae: 0.1271 - val_loss: 0.0696 - val_mae: 0.0986\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0814 - mae: 0.1306 - val_loss: 0.0687 - val_mae: 0.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0779 - mae: 0.1200 - val_loss: 0.0685 - val_mae: 0.1039\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0778 - mae: 0.1298 - val_loss: 0.0671 - val_mae: 0.0986\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0768 - mae: 0.1288 - val_loss: 0.0666 - val_mae: 0.1016\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0729 - mae: 0.1202 - val_loss: 0.0659 - val_mae: 0.1012\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0724 - mae: 0.1180 - val_loss: 0.0660 - val_mae: 0.1075\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0736 - mae: 0.1245 - val_loss: 0.0642 - val_mae: 0.0974\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0727 - mae: 0.1198 - val_loss: 0.0635 - val_mae: 0.0971\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0729 - mae: 0.1241 - val_loss: 0.0629 - val_mae: 0.0975\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0708 - mae: 0.1184 - val_loss: 0.0627 - val_mae: 0.1014\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0685 - mae: 0.1152 - val_loss: 0.0609 - val_mae: 0.0902\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0667 - mae: 0.1105 - val_loss: 0.0601 - val_mae: 0.0885\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0689 - mae: 0.1179 - val_loss: 0.0605 - val_mae: 0.0980\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0665 - mae: 0.1169 - val_loss: 0.0596 - val_mae: 0.0948\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0649 - mae: 0.1104 - val_loss: 0.0583 - val_mae: 0.0863\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0655 - mae: 0.1137 - val_loss: 0.0582 - val_mae: 0.0927\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0651 - mae: 0.1144 - val_loss: 0.0579 - val_mae: 0.0950\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0653 - mae: 0.1166 - val_loss: 0.0571 - val_mae: 0.0920\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0647 - mae: 0.1167 - val_loss: 0.0568 - val_mae: 0.0938\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0650 - mae: 0.1166 - val_loss: 0.0558 - val_mae: 0.0896\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0630 - mae: 0.1131 - val_loss: 0.0554 - val_mae: 0.0912\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0613 - mae: 0.1128 - val_loss: 0.0546 - val_mae: 0.0879\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0609 - mae: 0.1103 - val_loss: 0.0544 - val_mae: 0.0907\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0613 - mae: 0.1117 - val_loss: 0.0539 - val_mae: 0.0908\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0625 - mae: 0.1174 - val_loss: 0.0530 - val_mae: 0.0874\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0611 - mae: 0.1152 - val_loss: 0.0528 - val_mae: 0.0894\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0585 - mae: 0.1105 - val_loss: 0.0521 - val_mae: 0.0862\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0606 - mae: 0.1140 - val_loss: 0.0515 - val_mae: 0.0864\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0580 - mae: 0.1093 - val_loss: 0.0512 - val_mae: 0.0883\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0585 - mae: 0.1115 - val_loss: 0.0505 - val_mae: 0.0846\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0574 - mae: 0.1087 - val_loss: 0.0503 - val_mae: 0.0870\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0572 - mae: 0.1114 - val_loss: 0.0503 - val_mae: 0.0932\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0562 - mae: 0.1101 - val_loss: 0.0495 - val_mae: 0.0896\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0563 - mae: 0.1111 - val_loss: 0.0494 - val_mae: 0.0926\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0570 - mae: 0.1140 - val_loss: 0.0486 - val_mae: 0.0890\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0568 - mae: 0.1119 - val_loss: 0.0486 - val_mae: 0.0929\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0550 - mae: 0.1111 - val_loss: 0.0481 - val_mae: 0.0915\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0559 - mae: 0.1126 - val_loss: 0.0474 - val_mae: 0.0884\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0553 - mae: 0.1130 - val_loss: 0.0469 - val_mae: 0.0868\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0547 - mae: 0.1112 - val_loss: 0.0468 - val_mae: 0.0894\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mae: 0.1061 - val_loss: 0.0461 - val_mae: 0.0854\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0554 - mae: 0.1140 - val_loss: 0.0455 - val_mae: 0.0838\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0539 - mae: 0.1119 - val_loss: 0.0454 - val_mae: 0.0867\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0517 - mae: 0.1071 - val_loss: 0.0454 - val_mae: 0.0898\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0522 - mae: 0.1069 - val_loss: 0.0446 - val_mae: 0.0854\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0513 - mae: 0.1057 - val_loss: 0.0442 - val_mae: 0.0841\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0530 - mae: 0.1114 - val_loss: 0.0438 - val_mae: 0.0843\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0514 - mae: 0.1100 - val_loss: 0.0437 - val_mae: 0.0873\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0498 - mae: 0.1065 - val_loss: 0.0435 - val_mae: 0.0887\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0519 - mae: 0.1140 - val_loss: 0.0434 - val_mae: 0.0907\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0517 - mae: 0.1143 - val_loss: 0.0424 - val_mae: 0.0846\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mae: 0.1136 - val_loss: 0.0423 - val_mae: 0.0864\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0489 - mae: 0.1029 - val_loss: 0.0419 - val_mae: 0.0859\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0482 - mae: 0.1065 - val_loss: 0.0414 - val_mae: 0.0844\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0488 - mae: 0.1055 - val_loss: 0.0412 - val_mae: 0.0851\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0500 - mae: 0.1110 - val_loss: 0.0413 - val_mae: 0.0879\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0475 - mae: 0.1065 - val_loss: 0.0410 - val_mae: 0.0879\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0489 - mae: 0.1103 - val_loss: 0.0405 - val_mae: 0.0866\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0475 - mae: 0.1063 - val_loss: 0.0398 - val_mae: 0.0829\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0487 - mae: 0.1095 - val_loss: 0.0397 - val_mae: 0.0847\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0474 - mae: 0.1063 - val_loss: 0.0394 - val_mae: 0.0841\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0451 - mae: 0.1032 - val_loss: 0.0387 - val_mae: 0.0793\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0462 - mae: 0.093 - 0s 112us/step - loss: 0.0461 - mae: 0.1037 - val_loss: 0.0385 - val_mae: 0.0819\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0468 - mae: 0.1072 - val_loss: 0.0381 - val_mae: 0.0802\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0461 - mae: 0.1048 - val_loss: 0.0380 - val_mae: 0.0822\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0441 - mae: 0.1013 - val_loss: 0.0381 - val_mae: 0.0852\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0464 - mae: 0.1106 - val_loss: 0.0380 - val_mae: 0.0863\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0440 - mae: 0.1030 - val_loss: 0.0373 - val_mae: 0.0831\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0450 - mae: 0.1046 - val_loss: 0.0374 - val_mae: 0.0857\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0443 - mae: 0.1040 - val_loss: 0.0369 - val_mae: 0.0837\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0438 - mae: 0.1035 - val_loss: 0.0365 - val_mae: 0.0825\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0431 - mae: 0.1025 - val_loss: 0.0363 - val_mae: 0.0831\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0439 - mae: 0.1058 - val_loss: 0.0362 - val_mae: 0.0837\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0425 - mae: 0.1026 - val_loss: 0.0356 - val_mae: 0.0807\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0429 - mae: 0.1030 - val_loss: 0.0355 - val_mae: 0.0822\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0428 - mae: 0.1051 - val_loss: 0.0351 - val_mae: 0.0803\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0422 - mae: 0.1021 - val_loss: 0.0347 - val_mae: 0.0784\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0398 - mae: 0.0950 - val_loss: 0.0347 - val_mae: 0.0820\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0419 - mae: 0.1060 - val_loss: 0.0346 - val_mae: 0.0827\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0417 - mae: 0.1030 - val_loss: 0.0342 - val_mae: 0.0817\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0409 - mae: 0.1016 - val_loss: 0.0341 - val_mae: 0.0828\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0401 - mae: 0.0997 - val_loss: 0.0338 - val_mae: 0.0819\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 70us/step - loss: 0.0411 - mae: 0.1040 - val_loss: 0.0335 - val_mae: 0.0813\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0387 - mae: 0.0955 - val_loss: 0.0334 - val_mae: 0.0820\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 64us/step - loss: 0.0394 - mae: 0.0997 - val_loss: 0.0332 - val_mae: 0.0824\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0398 - mae: 0.1022 - val_loss: 0.0329 - val_mae: 0.0809\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 60us/step - loss: 0.0388 - mae: 0.1004 - val_loss: 0.0328 - val_mae: 0.0823\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0384 - mae: 0.0984 - val_loss: 0.0325 - val_mae: 0.0815\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 78us/step - loss: 0.0390 - mae: 0.1014 - val_loss: 0.0326 - val_mae: 0.0839\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 65us/step - loss: 0.0383 - mae: 0.0987 - val_loss: 0.0320 - val_mae: 0.0810\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0381 - mae: 0.1000 - val_loss: 0.0316 - val_mae: 0.0800\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0374 - mae: 0.0988 - val_loss: 0.0311 - val_mae: 0.0767\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0392 - mae: 0.1024 - val_loss: 0.0311 - val_mae: 0.0787\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0371 - mae: 0.0985 - val_loss: 0.0313 - val_mae: 0.0816\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0370 - mae: 0.0988 - val_loss: 0.0308 - val_mae: 0.0798\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0369 - mae: 0.1002 - val_loss: 0.0305 - val_mae: 0.0783\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0374 - mae: 0.0998 - val_loss: 0.0309 - val_mae: 0.0828\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0363 - mae: 0.1003 - val_loss: 0.0300 - val_mae: 0.0771\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0359 - mae: 0.0946 - val_loss: 0.0299 - val_mae: 0.0781\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0373 - mae: 0.0996 - val_loss: 0.0299 - val_mae: 0.0795\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0363 - mae: 0.0992 - val_loss: 0.0294 - val_mae: 0.0768\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0361 - mae: 0.0985 - val_loss: 0.0292 - val_mae: 0.0769\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0365 - mae: 0.1013 - val_loss: 0.0294 - val_mae: 0.0796\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0359 - mae: 0.1013 - val_loss: 0.0295 - val_mae: 0.0818\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0345 - mae: 0.0962 - val_loss: 0.0289 - val_mae: 0.0788\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0345 - mae: 0.0977 - val_loss: 0.0289 - val_mae: 0.0794\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0336 - mae: 0.0935 - val_loss: 0.0283 - val_mae: 0.0766\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0343 - mae: 0.0962 - val_loss: 0.0281 - val_mae: 0.0762\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0347 - mae: 0.0977 - val_loss: 0.0288 - val_mae: 0.0829\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0330 - mae: 0.0946 - val_loss: 0.0279 - val_mae: 0.0768\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0351 - mae: 0.0995 - val_loss: 0.0279 - val_mae: 0.0779\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0341 - mae: 0.0970 - val_loss: 0.0279 - val_mae: 0.0791\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0336 - mae: 0.0963 - val_loss: 0.0275 - val_mae: 0.0774\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0336 - mae: 0.0949 - val_loss: 0.0272 - val_mae: 0.0761\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0342 - mae: 0.0976 - val_loss: 0.0273 - val_mae: 0.0780\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0336 - mae: 0.0958 - val_loss: 0.0269 - val_mae: 0.0756\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0320 - mae: 0.0921 - val_loss: 0.0266 - val_mae: 0.0741\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0314 - mae: 0.0890 - val_loss: 0.0264 - val_mae: 0.0739\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0323 - mae: 0.0925 - val_loss: 0.0263 - val_mae: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0321 - mae: 0.0952 - val_loss: 0.0264 - val_mae: 0.0764\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0317 - mae: 0.0936 - val_loss: 0.0261 - val_mae: 0.0757\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0322 - mae: 0.0953 - val_loss: 0.0263 - val_mae: 0.0783\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0322 - mae: 0.0955 - val_loss: 0.0270 - val_mae: 0.0830\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0311 - mae: 0.0962 - val_loss: 0.0261 - val_mae: 0.0788\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0317 - mae: 0.0950 - val_loss: 0.0259 - val_mae: 0.0775\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0324 - mae: 0.0996 - val_loss: 0.0258 - val_mae: 0.0785\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0305 - mae: 0.0906 - val_loss: 0.0255 - val_mae: 0.0775\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0316 - mae: 0.0957 - val_loss: 0.0252 - val_mae: 0.0756\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0294 - mae: 0.0894 - val_loss: 0.0251 - val_mae: 0.0760\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0318 - mae: 0.0973 - val_loss: 0.0247 - val_mae: 0.0730\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0300 - mae: 0.0912 - val_loss: 0.0246 - val_mae: 0.0729\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0312 - mae: 0.0931 - val_loss: 0.0248 - val_mae: 0.0768\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0289 - mae: 0.0903 - val_loss: 0.0244 - val_mae: 0.0742\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0297 - mae: 0.0918 - val_loss: 0.0243 - val_mae: 0.0743\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0312 - mae: 0.0951 - val_loss: 0.0249 - val_mae: 0.0791\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0292 - mae: 0.0900 - val_loss: 0.0243 - val_mae: 0.0757\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0298 - mae: 0.0935 - val_loss: 0.0239 - val_mae: 0.0735\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0293 - mae: 0.0921 - val_loss: 0.0241 - val_mae: 0.0764\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0300 - mae: 0.0943 - val_loss: 0.0236 - val_mae: 0.0722\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0288 - mae: 0.0889 - val_loss: 0.0241 - val_mae: 0.0774\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0292 - mae: 0.0922 - val_loss: 0.0238 - val_mae: 0.0764\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0303 - mae: 0.0935 - val_loss: 0.0236 - val_mae: 0.0753\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0278 - mae: 0.0888 - val_loss: 0.0232 - val_mae: 0.0723\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0306 - mae: 0.102 - 0s 116us/step - loss: 0.0293 - mae: 0.0909 - val_loss: 0.0233 - val_mae: 0.0751\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0287 - mae: 0.0912 - val_loss: 0.0233 - val_mae: 0.0759\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0278 - mae: 0.0891 - val_loss: 0.0229 - val_mae: 0.0735\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0279 - mae: 0.0886 - val_loss: 0.0228 - val_mae: 0.0731\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0272 - mae: 0.0875 - val_loss: 0.0229 - val_mae: 0.0749\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0229 - val_mae: 0.0760\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0280 - mae: 0.0915 - val_loss: 0.0224 - val_mae: 0.0720\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0272 - mae: 0.0868 - val_loss: 0.0225 - val_mae: 0.0736\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0284 - mae: 0.0927 - val_loss: 0.0227 - val_mae: 0.0763\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0278 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.0749\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0276 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.0765\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0269 - mae: 0.0883 - val_loss: 0.0218 - val_mae: 0.0706\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0270 - mae: 0.0878 - val_loss: 0.0217 - val_mae: 0.0709\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0272 - mae: 0.0872 - val_loss: 0.0219 - val_mae: 0.0730\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0272 - mae: 0.0883 - val_loss: 0.0216 - val_mae: 0.0713\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0267 - mae: 0.0867 - val_loss: 0.0216 - val_mae: 0.0724\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0269 - mae: 0.0904 - val_loss: 0.0217 - val_mae: 0.0741\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.0773\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0262 - mae: 0.0886 - val_loss: 0.0213 - val_mae: 0.0716\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0267 - mae: 0.0905 - val_loss: 0.0221 - val_mae: 0.0783\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0264 - mae: 0.0893 - val_loss: 0.0216 - val_mae: 0.0753\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0261 - mae: 0.0881 - val_loss: 0.0212 - val_mae: 0.0726\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0266 - mae: 0.0892 - val_loss: 0.0213 - val_mae: 0.0748\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0271 - mae: 0.0927 - val_loss: 0.0209 - val_mae: 0.0714\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0265 - mae: 0.0894 - val_loss: 0.0209 - val_mae: 0.0728\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0253 - mae: 0.0875 - val_loss: 0.0208 - val_mae: 0.0720\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0267 - mae: 0.0908 - val_loss: 0.0211 - val_mae: 0.0751\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0257 - mae: 0.0881 - val_loss: 0.0209 - val_mae: 0.0746\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0251 - mae: 0.0866 - val_loss: 0.0208 - val_mae: 0.0739\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0914 - val_loss: 0.0208 - val_mae: 0.0750\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0258 - mae: 0.0899 - val_loss: 0.0205 - val_mae: 0.0727\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0247 - mae: 0.0859 - val_loss: 0.0205 - val_mae: 0.0731\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0248 - mae: 0.0857 - val_loss: 0.0206 - val_mae: 0.0750\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0248 - mae: 0.0855 - val_loss: 0.0204 - val_mae: 0.0739\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0259 - mae: 0.0905 - val_loss: 0.0210 - val_mae: 0.0785\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0257 - mae: 0.0903 - val_loss: 0.0205 - val_mae: 0.0752\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0251 - mae: 0.0890 - val_loss: 0.0201 - val_mae: 0.0722\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0246 - mae: 0.0852 - val_loss: 0.0200 - val_mae: 0.0729\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0248 - mae: 0.0873 - val_loss: 0.0202 - val_mae: 0.0746\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0246 - mae: 0.0864 - val_loss: 0.0196 - val_mae: 0.0704\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0239 - mae: 0.0842 - val_loss: 0.0195 - val_mae: 0.0698\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0247 - mae: 0.0883 - val_loss: 0.0199 - val_mae: 0.0739\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0253 - mae: 0.0905 - val_loss: 0.0195 - val_mae: 0.0709\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0245 - mae: 0.0865 - val_loss: 0.0194 - val_mae: 0.0706\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0246 - mae: 0.0881 - val_loss: 0.0196 - val_mae: 0.0732\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0253 - mae: 0.0899 - val_loss: 0.0197 - val_mae: 0.0737\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0244 - mae: 0.0882 - val_loss: 0.0199 - val_mae: 0.0761\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0253 - mae: 0.0916 - val_loss: 0.0193 - val_mae: 0.0713\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0238 - mae: 0.0850 - val_loss: 0.0195 - val_mae: 0.0737\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0246 - mae: 0.0897 - val_loss: 0.0191 - val_mae: 0.0710\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0248 - mae: 0.0899 - val_loss: 0.0192 - val_mae: 0.0719\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0240 - mae: 0.0865 - val_loss: 0.0190 - val_mae: 0.0706\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0238 - mae: 0.0871 - val_loss: 0.0192 - val_mae: 0.0731\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0258 - mae: 0.0933 - val_loss: 0.0194 - val_mae: 0.0751\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0241 - mae: 0.0874 - val_loss: 0.0193 - val_mae: 0.0748\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0235 - mae: 0.0868 - val_loss: 0.0191 - val_mae: 0.0733\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0237 - mae: 0.0884 - val_loss: 0.0192 - val_mae: 0.0747\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0235 - mae: 0.0865 - val_loss: 0.0188 - val_mae: 0.0712\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0244 - mae: 0.0881 - val_loss: 0.0188 - val_mae: 0.0716\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0243 - mae: 0.0886 - val_loss: 0.0188 - val_mae: 0.0722\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0242 - mae: 0.0891 - val_loss: 0.0188 - val_mae: 0.0733\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0236 - mae: 0.0874 - val_loss: 0.0187 - val_mae: 0.0719\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0227 - mae: 0.0826 - val_loss: 0.0187 - val_mae: 0.0723\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0228 - mae: 0.0852 - val_loss: 0.0184 - val_mae: 0.0704\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0233 - mae: 0.0850 - val_loss: 0.0186 - val_mae: 0.0727\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0236 - mae: 0.0881 - val_loss: 0.0183 - val_mae: 0.0698\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0229 - mae: 0.0837 - val_loss: 0.0185 - val_mae: 0.0721\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0236 - mae: 0.0861 - val_loss: 0.0185 - val_mae: 0.0726\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0231 - mae: 0.0855 - val_loss: 0.0185 - val_mae: 0.0729\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0231 - mae: 0.0863 - val_loss: 0.0184 - val_mae: 0.0724\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0229 - mae: 0.0856 - val_loss: 0.0183 - val_mae: 0.0718\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0232 - mae: 0.0890 - val_loss: 0.0180 - val_mae: 0.0696\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0223 - mae: 0.0831 - val_loss: 0.0185 - val_mae: 0.0745\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0238 - mae: 0.0899 - val_loss: 0.0184 - val_mae: 0.0735\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0239 - mae: 0.0893 - val_loss: 0.0181 - val_mae: 0.0722\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0233 - mae: 0.0888 - val_loss: 0.0180 - val_mae: 0.0710\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0848 - val_loss: 0.0181 - val_mae: 0.0725\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0190 - mae: 0.068 - 0s 118us/step - loss: 0.0222 - mae: 0.0863 - val_loss: 0.0180 - val_mae: 0.0723\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0235 - mae: 0.0903 - val_loss: 0.0181 - val_mae: 0.0725\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0223 - mae: 0.0851 - val_loss: 0.0180 - val_mae: 0.0722\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0224 - mae: 0.0854 - val_loss: 0.0179 - val_mae: 0.0717\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0231 - mae: 0.0887 - val_loss: 0.0180 - val_mae: 0.0725\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0229 - mae: 0.0877 - val_loss: 0.0180 - val_mae: 0.0733\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0224 - mae: 0.0864 - val_loss: 0.0181 - val_mae: 0.0740\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0280 - mae: 0.117 - 0s 112us/step - loss: 0.0230 - mae: 0.0879 - val_loss: 0.0179 - val_mae: 0.0728\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0213 - mae: 0.0831 - val_loss: 0.0177 - val_mae: 0.0719\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0222 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0228 - mae: 0.0889 - val_loss: 0.0178 - val_mae: 0.0729\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0227 - mae: 0.0862 - val_loss: 0.0177 - val_mae: 0.0729\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0232 - mae: 0.0886 - val_loss: 0.0178 - val_mae: 0.0737\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0865 - val_loss: 0.0178 - val_mae: 0.0739\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0227 - mae: 0.0887 - val_loss: 0.0177 - val_mae: 0.0732\n",
      "Epoch 287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0227 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0717\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0218 - mae: 0.0833 - val_loss: 0.0180 - val_mae: 0.0758\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0231 - mae: 0.0909 - val_loss: 0.0175 - val_mae: 0.0720\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0230 - mae: 0.0890 - val_loss: 0.0175 - val_mae: 0.0720\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0220 - mae: 0.0845 - val_loss: 0.0176 - val_mae: 0.0733\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0229 - mae: 0.0904 - val_loss: 0.0173 - val_mae: 0.0716\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0224 - mae: 0.0875 - val_loss: 0.0174 - val_mae: 0.0719\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0225 - mae: 0.0872 - val_loss: 0.0174 - val_mae: 0.0730\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0219 - mae: 0.0849 - val_loss: 0.0177 - val_mae: 0.0747\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0219 - mae: 0.0864 - val_loss: 0.0174 - val_mae: 0.0728\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0223 - mae: 0.0887 - val_loss: 0.0178 - val_mae: 0.0760\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0228 - mae: 0.0885 - val_loss: 0.0176 - val_mae: 0.0752\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 109us/step - loss: 0.0221 - mae: 0.0875 - val_loss: 0.0175 - val_mae: 0.0745\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0218 - mae: 0.0850 - val_loss: 0.0171 - val_mae: 0.0709\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0228 - mae: 0.0884 - val_loss: 0.0174 - val_mae: 0.0740\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0219 - mae: 0.0876 - val_loss: 0.0174 - val_mae: 0.0746\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0215 - mae: 0.0864 - val_loss: 0.0174 - val_mae: 0.0742\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0215 - mae: 0.0860 - val_loss: 0.0175 - val_mae: 0.0757\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0219 - mae: 0.0884 - val_loss: 0.0174 - val_mae: 0.0751\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0218 - mae: 0.0875 - val_loss: 0.0169 - val_mae: 0.0709\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0834 - val_loss: 0.0169 - val_mae: 0.0710\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0223 - mae: 0.0888 - val_loss: 0.0171 - val_mae: 0.0726\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0863 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0222 - mae: 0.0892 - val_loss: 0.0171 - val_mae: 0.0735\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0216 - mae: 0.0865 - val_loss: 0.0171 - val_mae: 0.0741\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0217 - mae: 0.0862 - val_loss: 0.0169 - val_mae: 0.0726\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0213 - mae: 0.0857 - val_loss: 0.0171 - val_mae: 0.0741\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0215 - mae: 0.0871 - val_loss: 0.0173 - val_mae: 0.0755\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0214 - mae: 0.0875 - val_loss: 0.0168 - val_mae: 0.0718\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0212 - mae: 0.0846 - val_loss: 0.0166 - val_mae: 0.0706\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0225 - mae: 0.0885 - val_loss: 0.0167 - val_mae: 0.0717\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0209 - mae: 0.0824 - val_loss: 0.0166 - val_mae: 0.0707\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0218 - mae: 0.0870 - val_loss: 0.0167 - val_mae: 0.0718\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0207 - mae: 0.0846 - val_loss: 0.0166 - val_mae: 0.0715\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0228 - mae: 0.0911 - val_loss: 0.0169 - val_mae: 0.0744\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0867 - val_loss: 0.0166 - val_mae: 0.0716\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0868 - val_loss: 0.0167 - val_mae: 0.0728\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0224 - mae: 0.0897 - val_loss: 0.0166 - val_mae: 0.0720\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0216 - mae: 0.0878 - val_loss: 0.0166 - val_mae: 0.0721\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0211 - mae: 0.0847 - val_loss: 0.0167 - val_mae: 0.0731\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0851 - val_loss: 0.0168 - val_mae: 0.0741\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0874 - val_loss: 0.0164 - val_mae: 0.0704\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0853 - val_loss: 0.0169 - val_mae: 0.0751\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0830 - val_loss: 0.0165 - val_mae: 0.0715\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0205 - mae: 0.0845 - val_loss: 0.0167 - val_mae: 0.0737\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0214 - mae: 0.0869 - val_loss: 0.0166 - val_mae: 0.0732\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0213 - mae: 0.0848 - val_loss: 0.0166 - val_mae: 0.0728\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0862 - val_loss: 0.0164 - val_mae: 0.0714\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0218 - mae: 0.0897 - val_loss: 0.0165 - val_mae: 0.0728\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0869 - val_loss: 0.0165 - val_mae: 0.0728\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mae: 0.0853 - val_loss: 0.0163 - val_mae: 0.0715\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0836 - val_loss: 0.0162 - val_mae: 0.0707\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0208 - mae: 0.0833 - val_loss: 0.0164 - val_mae: 0.0720\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0862 - val_loss: 0.0165 - val_mae: 0.0736\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0846 - val_loss: 0.0163 - val_mae: 0.0722\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0897 - val_loss: 0.0164 - val_mae: 0.0721\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0208 - mae: 0.0846 - val_loss: 0.0164 - val_mae: 0.0722\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0208 - mae: 0.0847 - val_loss: 0.0164 - val_mae: 0.0728\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0865 - val_loss: 0.0163 - val_mae: 0.0723\n",
      "Epoch 346/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 124us/step - loss: 0.0210 - mae: 0.0859 - val_loss: 0.0165 - val_mae: 0.0741\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0207 - mae: 0.0850 - val_loss: 0.0165 - val_mae: 0.0742\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0207 - mae: 0.0855 - val_loss: 0.0163 - val_mae: 0.0734\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0205 - mae: 0.0858 - val_loss: 0.0162 - val_mae: 0.0723\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0861 - val_loss: 0.0161 - val_mae: 0.0718\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0202 - mae: 0.0847 - val_loss: 0.0163 - val_mae: 0.0727\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0208 - mae: 0.0863 - val_loss: 0.0161 - val_mae: 0.0713\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0213 - mae: 0.0868 - val_loss: 0.0165 - val_mae: 0.0749\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0213 - mae: 0.0871 - val_loss: 0.0165 - val_mae: 0.0744\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0858 - val_loss: 0.0162 - val_mae: 0.0733\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0209 - mae: 0.0845 - val_loss: 0.0161 - val_mae: 0.0724\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0209 - mae: 0.0860 - val_loss: 0.0164 - val_mae: 0.0747\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0204 - mae: 0.0850 - val_loss: 0.0164 - val_mae: 0.0750\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0210 - mae: 0.0872 - val_loss: 0.0160 - val_mae: 0.0723\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0205 - mae: 0.0850 - val_loss: 0.0160 - val_mae: 0.0720\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0209 - mae: 0.0844 - val_loss: 0.0160 - val_mae: 0.0728\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0900 - val_loss: 0.0162 - val_mae: 0.0735\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0206 - mae: 0.0842 - val_loss: 0.0161 - val_mae: 0.0737\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mae: 0.0871 - val_loss: 0.0159 - val_mae: 0.0718\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0864 - val_loss: 0.0159 - val_mae: 0.0723\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0210 - mae: 0.0869 - val_loss: 0.0157 - val_mae: 0.0701\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0850 - val_loss: 0.0161 - val_mae: 0.0738\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0897 - val_loss: 0.0162 - val_mae: 0.0752\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0205 - mae: 0.0854 - val_loss: 0.0158 - val_mae: 0.0722\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0846 - val_loss: 0.0159 - val_mae: 0.0729\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0852 - val_loss: 0.0159 - val_mae: 0.0723\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0202 - mae: 0.0844 - val_loss: 0.0158 - val_mae: 0.0717\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0841 - val_loss: 0.0158 - val_mae: 0.0714\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0849 - val_loss: 0.0155 - val_mae: 0.0692\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0206 - mae: 0.0856 - val_loss: 0.0156 - val_mae: 0.0706\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0859 - val_loss: 0.0161 - val_mae: 0.0745\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0158 - val_mae: 0.0727\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0201 - mae: 0.0858 - val_loss: 0.0154 - val_mae: 0.0690\n",
      "Epoch 379/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0204 - mae: 0.0854 - val_loss: 0.0155 - val_mae: 0.0699\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0864 - val_loss: 0.0161 - val_mae: 0.0746\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mae: 0.0893 - val_loss: 0.0155 - val_mae: 0.0710\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0873 - val_loss: 0.0159 - val_mae: 0.0743\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0202 - mae: 0.0862 - val_loss: 0.0157 - val_mae: 0.0729\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0208 - mae: 0.0882 - val_loss: 0.0158 - val_mae: 0.0736\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0878 - val_loss: 0.0156 - val_mae: 0.0720\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0208 - mae: 0.0867 - val_loss: 0.0157 - val_mae: 0.0733\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0859 - val_loss: 0.0160 - val_mae: 0.0745\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0205 - mae: 0.0867 - val_loss: 0.0154 - val_mae: 0.0709\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0841 - val_loss: 0.0156 - val_mae: 0.0719\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0851 - val_loss: 0.0155 - val_mae: 0.0719\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0206 - mae: 0.0877 - val_loss: 0.0155 - val_mae: 0.0720\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mae: 0.0889 - val_loss: 0.0156 - val_mae: 0.0729\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0205 - mae: 0.0859 - val_loss: 0.0157 - val_mae: 0.0737\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0863 - val_loss: 0.0156 - val_mae: 0.0727\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0204 - mae: 0.0861 - val_loss: 0.0158 - val_mae: 0.0744\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0828 - val_loss: 0.0156 - val_mae: 0.0734\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0866 - val_loss: 0.0159 - val_mae: 0.0750\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0198 - mae: 0.0857 - val_loss: 0.0155 - val_mae: 0.0721\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mae: 0.0869 - val_loss: 0.0154 - val_mae: 0.0712\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0199 - mae: 0.0848 - val_loss: 0.0152 - val_mae: 0.0695\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0841 - val_loss: 0.0155 - val_mae: 0.0729\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0202 - mae: 0.0860 - val_loss: 0.0160 - val_mae: 0.0763\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0200 - mae: 0.0851 - val_loss: 0.0155 - val_mae: 0.0723\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0707\n",
      "Epoch 405/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mae: 0.0849 - val_loss: 0.0151 - val_mae: 0.0700\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0832 - val_loss: 0.0154 - val_mae: 0.0726\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0203 - mae: 0.0856 - val_loss: 0.0158 - val_mae: 0.0755\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0200 - mae: 0.0861 - val_loss: 0.0158 - val_mae: 0.0754\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0706\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0830 - val_loss: 0.0153 - val_mae: 0.0713\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0199 - mae: 0.0845 - val_loss: 0.0157 - val_mae: 0.0746\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0844 - val_loss: 0.0155 - val_mae: 0.0732\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0861 - val_loss: 0.0153 - val_mae: 0.0722\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0831 - val_loss: 0.0152 - val_mae: 0.0707\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0197 - mae: 0.0838 - val_loss: 0.0155 - val_mae: 0.0730\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0202 - mae: 0.0859 - val_loss: 0.0151 - val_mae: 0.0703\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0828 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0151 - val_mae: 0.0707\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0200 - mae: 0.0846 - val_loss: 0.0151 - val_mae: 0.0709\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0846 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0862 - val_loss: 0.0154 - val_mae: 0.0732\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0190 - mae: 0.0835 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0853 - val_loss: 0.0152 - val_mae: 0.0719\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0846 - val_loss: 0.0150 - val_mae: 0.0708\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0831 - val_loss: 0.0148 - val_mae: 0.0681\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0190 - mae: 0.0835 - val_loss: 0.0153 - val_mae: 0.0730\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0208 - mae: 0.0876 - val_loss: 0.0154 - val_mae: 0.0744\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mae: 0.0878 - val_loss: 0.0151 - val_mae: 0.0724\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0199 - mae: 0.0855 - val_loss: 0.0149 - val_mae: 0.0697\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0203 - mae: 0.0856 - val_loss: 0.0151 - val_mae: 0.0718\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0842 - val_loss: 0.0150 - val_mae: 0.0712\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mae: 0.0823 - val_loss: 0.0148 - val_mae: 0.0687\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0198 - mae: 0.0838 - val_loss: 0.0152 - val_mae: 0.0721\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0836 - val_loss: 0.0149 - val_mae: 0.0704\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0205 - mae: 0.0881 - val_loss: 0.0149 - val_mae: 0.0706\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0194 - mae: 0.0837 - val_loss: 0.0150 - val_mae: 0.0714\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0841 - val_loss: 0.0151 - val_mae: 0.0721\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0195 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0729\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mae: 0.0888 - val_loss: 0.0152 - val_mae: 0.0733\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0191 - mae: 0.0833 - val_loss: 0.0152 - val_mae: 0.0731\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0194 - mae: 0.0858 - val_loss: 0.0147 - val_mae: 0.0678\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0192 - mae: 0.0831 - val_loss: 0.0151 - val_mae: 0.0719\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0197 - mae: 0.0846 - val_loss: 0.0147 - val_mae: 0.0699\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0844 - val_loss: 0.0148 - val_mae: 0.0709\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0150 - val_mae: 0.0721\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0202 - mae: 0.0889 - val_loss: 0.0148 - val_mae: 0.0706\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0886 - val_loss: 0.0148 - val_mae: 0.0711\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0831 - val_loss: 0.0150 - val_mae: 0.0726\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0801 - val_loss: 0.0150 - val_mae: 0.0722\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0193 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0729\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0845 - val_loss: 0.0148 - val_mae: 0.0699\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0199 - mae: 0.0850 - val_loss: 0.0149 - val_mae: 0.0718\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0811 - val_loss: 0.0150 - val_mae: 0.0724\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0195 - mae: 0.0859 - val_loss: 0.0149 - val_mae: 0.0717\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0186 - mae: 0.0813 - val_loss: 0.0150 - val_mae: 0.0721\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0807 - val_loss: 0.0145 - val_mae: 0.0680\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0197 - mae: 0.0856 - val_loss: 0.0148 - val_mae: 0.0706\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0204 - mae: 0.0884 - val_loss: 0.0146 - val_mae: 0.0694\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0191 - mae: 0.0838 - val_loss: 0.0150 - val_mae: 0.0736\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0149 - val_mae: 0.0724\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0193 - mae: 0.0842 - val_loss: 0.0149 - val_mae: 0.0719\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0839 - val_loss: 0.0147 - val_mae: 0.0704\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0204 - mae: 0.0870 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 464/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 108us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0145 - val_mae: 0.0677\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0789 - val_loss: 0.0144 - val_mae: 0.0666\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0190 - mae: 0.0826 - val_loss: 0.0146 - val_mae: 0.0696\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0828 - val_loss: 0.0146 - val_mae: 0.0706\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0192 - mae: 0.0840 - val_loss: 0.0145 - val_mae: 0.0701\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0183 - mae: 0.0793 - val_loss: 0.0146 - val_mae: 0.0706\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0798 - val_loss: 0.0150 - val_mae: 0.0733\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0815 - val_loss: 0.0145 - val_mae: 0.0709\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0188 - mae: 0.0832 - val_loss: 0.0150 - val_mae: 0.0739\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0844 - val_loss: 0.0146 - val_mae: 0.0709\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0849 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0185 - mae: 0.0807 - val_loss: 0.0143 - val_mae: 0.0672\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0196 - mae: 0.0836 - val_loss: 0.0144 - val_mae: 0.0696\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0192 - mae: 0.0842 - val_loss: 0.0149 - val_mae: 0.0732\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0840 - val_loss: 0.0146 - val_mae: 0.0708\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0834 - val_loss: 0.0150 - val_mae: 0.0738\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0872 - val_loss: 0.0145 - val_mae: 0.0702\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0840 - val_loss: 0.0148 - val_mae: 0.0730\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0853 - val_loss: 0.0145 - val_mae: 0.0717\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0185 - mae: 0.0831 - val_loss: 0.0144 - val_mae: 0.0695\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0828 - val_loss: 0.0146 - val_mae: 0.0715\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0184 - mae: 0.0824 - val_loss: 0.0143 - val_mae: 0.0667\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0826 - val_loss: 0.0143 - val_mae: 0.0674\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0195 - mae: 0.0844 - val_loss: 0.0143 - val_mae: 0.0681\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0190 - mae: 0.0826 - val_loss: 0.0144 - val_mae: 0.0699\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0848 - val_loss: 0.0144 - val_mae: 0.0706\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0184 - mae: 0.0821 - val_loss: 0.0144 - val_mae: 0.0694\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0842 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0794 - val_loss: 0.0144 - val_mae: 0.0688\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0803 - val_loss: 0.0144 - val_mae: 0.0690\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0184 - mae: 0.0805 - val_loss: 0.0146 - val_mae: 0.0716\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0843 - val_loss: 0.0146 - val_mae: 0.0712\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0189 - mae: 0.0836 - val_loss: 0.0143 - val_mae: 0.0688\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0826 - val_loss: 0.0144 - val_mae: 0.0696\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0805 - val_loss: 0.0142 - val_mae: 0.0660\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0788 - val_loss: 0.0143 - val_mae: 0.0694\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0183 - mae: 0.0808 - val_loss: 0.0141 - val_mae: 0.0674\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0799 - val_loss: 0.0142 - val_mae: 0.0688\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mae: 0.0781 - val_loss: 0.0141 - val_mae: 0.0672\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0191 - mae: 0.0821 - val_loss: 0.0144 - val_mae: 0.0702\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0188 - mae: 0.0834 - val_loss: 0.0142 - val_mae: 0.0683\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0812 - val_loss: 0.0145 - val_mae: 0.0716\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0844 - val_loss: 0.0145 - val_mae: 0.0713\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0181 - mae: 0.0805 - val_loss: 0.0148 - val_mae: 0.0737\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mae: 0.0841 - val_loss: 0.0142 - val_mae: 0.0692\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0821 - val_loss: 0.0145 - val_mae: 0.0720\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0806 - val_loss: 0.0143 - val_mae: 0.0712\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0827 - val_loss: 0.0143 - val_mae: 0.0712\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0811 - val_loss: 0.0140 - val_mae: 0.0684\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0807 - val_loss: 0.0143 - val_mae: 0.0706\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0832 - val_loss: 0.0141 - val_mae: 0.0686\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0817 - val_loss: 0.0143 - val_mae: 0.0711\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0864 - val_loss: 0.0143 - val_mae: 0.0708\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mae: 0.0827 - val_loss: 0.0143 - val_mae: 0.0713\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0825 - val_loss: 0.0145 - val_mae: 0.0720\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0141 - val_mae: 0.0699\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0186 - mae: 0.0806 - val_loss: 0.0142 - val_mae: 0.0708\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0838 - val_loss: 0.0141 - val_mae: 0.0690\n",
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0837 - val_loss: 0.0140 - val_mae: 0.0683\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mae: 0.0841 - val_loss: 0.0142 - val_mae: 0.0704\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0179 - mae: 0.0797 - val_loss: 0.0141 - val_mae: 0.0695\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0777 - val_loss: 0.0140 - val_mae: 0.0677\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0192 - mae: 0.0835 - val_loss: 0.0142 - val_mae: 0.0699\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0810 - val_loss: 0.0141 - val_mae: 0.0690\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.0839 - val_loss: 0.0140 - val_mae: 0.0701\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0141 - val_mae: 0.0700\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0792 - val_loss: 0.0139 - val_mae: 0.0684\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0174 - mae: 0.0767 - val_loss: 0.0138 - val_mae: 0.0674\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0802 - val_loss: 0.0139 - val_mae: 0.0686\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0187 - mae: 0.0817 - val_loss: 0.0138 - val_mae: 0.0680\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0186 - mae: 0.0818 - val_loss: 0.0140 - val_mae: 0.0699\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0815 - val_loss: 0.0137 - val_mae: 0.0661\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0190 - mae: 0.0839 - val_loss: 0.0137 - val_mae: 0.0670\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0775 - val_loss: 0.0137 - val_mae: 0.0673\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0179 - mae: 0.0801 - val_loss: 0.0144 - val_mae: 0.0733\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0817 - val_loss: 0.0140 - val_mae: 0.0697\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0188 - mae: 0.0823 - val_loss: 0.0141 - val_mae: 0.0702\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0823 - val_loss: 0.0140 - val_mae: 0.0698\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0139 - val_mae: 0.0695\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0176 - mae: 0.0781 - val_loss: 0.0143 - val_mae: 0.0724\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0187 - mae: 0.0839 - val_loss: 0.0144 - val_mae: 0.0730\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0822 - val_loss: 0.0136 - val_mae: 0.0660\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0171 - mae: 0.0764 - val_loss: 0.0137 - val_mae: 0.0671\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0782 - val_loss: 0.0139 - val_mae: 0.0698\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.0841 - val_loss: 0.0139 - val_mae: 0.0693\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0808 - val_loss: 0.0139 - val_mae: 0.0696\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0805 - val_loss: 0.0141 - val_mae: 0.0711\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0808 - val_loss: 0.0140 - val_mae: 0.0700\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0189 - mae: 0.0830 - val_loss: 0.0141 - val_mae: 0.0709\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0805 - val_loss: 0.0141 - val_mae: 0.0711\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0187 - mae: 0.0822 - val_loss: 0.0139 - val_mae: 0.0698\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0827 - val_loss: 0.0139 - val_mae: 0.0700\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0826 - val_loss: 0.0139 - val_mae: 0.0700\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0173 - mae: 0.0780 - val_loss: 0.0138 - val_mae: 0.0691\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0171 - mae: 0.081 - 0s 108us/step - loss: 0.0181 - mae: 0.0809 - val_loss: 0.0139 - val_mae: 0.0702\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0191 - mae: 0.0839 - val_loss: 0.0141 - val_mae: 0.0719\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0806 - val_loss: 0.0137 - val_mae: 0.0663\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0188 - mae: 0.0829 - val_loss: 0.0138 - val_mae: 0.0694\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0786 - val_loss: 0.0137 - val_mae: 0.0686\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0777 - val_loss: 0.0136 - val_mae: 0.0675\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0800 - val_loss: 0.0136 - val_mae: 0.0682\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0179 - mae: 0.0797 - val_loss: 0.0138 - val_mae: 0.0700\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0816 - val_loss: 0.0139 - val_mae: 0.0709\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0856 - val_loss: 0.0138 - val_mae: 0.0703\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0820 - val_loss: 0.0135 - val_mae: 0.0672\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0855 - val_loss: 0.0136 - val_mae: 0.0686\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0812 - val_loss: 0.0136 - val_mae: 0.0694\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0185 - mae: 0.0837 - val_loss: 0.0140 - val_mae: 0.0714\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0833 - val_loss: 0.0137 - val_mae: 0.0699\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0830 - val_loss: 0.0137 - val_mae: 0.0697\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0814 - val_loss: 0.0136 - val_mae: 0.0688\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0821 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0811 - val_loss: 0.0134 - val_mae: 0.0670\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0797 - val_loss: 0.0135 - val_mae: 0.0682\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0805 - val_loss: 0.0137 - val_mae: 0.0700\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0170 - mae: 0.0775 - val_loss: 0.0142 - val_mae: 0.0726\n",
      "Epoch 581/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0802 - val_loss: 0.0135 - val_mae: 0.0676\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0182 - mae: 0.0811 - val_loss: 0.0134 - val_mae: 0.0659\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0809 - val_loss: 0.0136 - val_mae: 0.0668\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0806 - val_loss: 0.0139 - val_mae: 0.0710\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0178 - mae: 0.0804 - val_loss: 0.0137 - val_mae: 0.0697\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0174 - mae: 0.0805 - val_loss: 0.0135 - val_mae: 0.0674\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0789 - val_loss: 0.0134 - val_mae: 0.0663\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0179 - mae: 0.0798 - val_loss: 0.0135 - val_mae: 0.0679\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0806 - val_loss: 0.0136 - val_mae: 0.0691\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0178 - mae: 0.0799 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0787 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0802 - val_loss: 0.0136 - val_mae: 0.0690\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0180 - mae: 0.0809 - val_loss: 0.0139 - val_mae: 0.0716\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mae: 0.0750 - val_loss: 0.0135 - val_mae: 0.0684\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0811 - val_loss: 0.0136 - val_mae: 0.0706\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0180 - mae: 0.0835 - val_loss: 0.0135 - val_mae: 0.0694\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0819 - val_loss: 0.0133 - val_mae: 0.0659\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0788 - val_loss: 0.0134 - val_mae: 0.0677\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0176 - mae: 0.0794 - val_loss: 0.0134 - val_mae: 0.0682\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0175 - mae: 0.0795 - val_loss: 0.0135 - val_mae: 0.0695\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0796 - val_loss: 0.0135 - val_mae: 0.0688\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0777 - val_loss: 0.0140 - val_mae: 0.0728\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0174 - mae: 0.0798 - val_loss: 0.0136 - val_mae: 0.0697\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0173 - mae: 0.0806 - val_loss: 0.0135 - val_mae: 0.0689\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0177 - mae: 0.0807 - val_loss: 0.0134 - val_mae: 0.0680\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0185 - mae: 0.0827 - val_loss: 0.0136 - val_mae: 0.0698\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0797 - val_loss: 0.0135 - val_mae: 0.0696\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0782 - val_loss: 0.0134 - val_mae: 0.0686\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0793 - val_loss: 0.0132 - val_mae: 0.0671\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0828 - val_loss: 0.0134 - val_mae: 0.0686\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0175 - mae: 0.0806 - val_loss: 0.0134 - val_mae: 0.0683\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0180 - mae: 0.0803 - val_loss: 0.0136 - val_mae: 0.0703\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0827 - val_loss: 0.0140 - val_mae: 0.0727\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0163 - mae: 0.0755 - val_loss: 0.0132 - val_mae: 0.0665\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0173 - mae: 0.0783 - val_loss: 0.0137 - val_mae: 0.0706\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0798 - val_loss: 0.0133 - val_mae: 0.0678\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0796 - val_loss: 0.0134 - val_mae: 0.0688\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0789 - val_loss: 0.0132 - val_mae: 0.0669\n",
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.0657\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0178 - mae: 0.0797 - val_loss: 0.0131 - val_mae: 0.0668\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0179 - mae: 0.0814 - val_loss: 0.0130 - val_mae: 0.0656\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0801 - val_loss: 0.0131 - val_mae: 0.0661\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0136 - val_mae: 0.0703\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0817 - val_loss: 0.0133 - val_mae: 0.0681\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0814 - val_loss: 0.0132 - val_mae: 0.0672\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0764 - val_loss: 0.0134 - val_mae: 0.0694\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.0670\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0186 - mae: 0.0829 - val_loss: 0.0133 - val_mae: 0.0687\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0802 - val_loss: 0.0132 - val_mae: 0.0673\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0829 - val_loss: 0.0130 - val_mae: 0.0647\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0802 - val_loss: 0.0132 - val_mae: 0.0674\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0775 - val_loss: 0.0131 - val_mae: 0.0664\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0177 - mae: 0.0803 - val_loss: 0.0134 - val_mae: 0.0685\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0174 - mae: 0.0776 - val_loss: 0.0131 - val_mae: 0.0652\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0782 - val_loss: 0.0131 - val_mae: 0.0664\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0770 - val_loss: 0.0132 - val_mae: 0.0675\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0787 - val_loss: 0.0130 - val_mae: 0.0661\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0176 - mae: 0.0815 - val_loss: 0.0136 - val_mae: 0.0710\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0180 - mae: 0.0822 - val_loss: 0.0129 - val_mae: 0.0642\n",
      "Epoch 640/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0770 - val_loss: 0.0130 - val_mae: 0.0659\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0129 - val_mae: 0.0653\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0801 - val_loss: 0.0133 - val_mae: 0.0686\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0837 - val_loss: 0.0132 - val_mae: 0.0686\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0170 - mae: 0.0795 - val_loss: 0.0131 - val_mae: 0.0679\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0817 - val_loss: 0.0130 - val_mae: 0.0656\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0136 - val_mae: 0.0712\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0175 - mae: 0.0808 - val_loss: 0.0134 - val_mae: 0.0693\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0177 - mae: 0.0812 - val_loss: 0.0135 - val_mae: 0.0696\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0175 - mae: 0.0790 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0165 - mae: 0.0760 - val_loss: 0.0133 - val_mae: 0.0688\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0787 - val_loss: 0.0132 - val_mae: 0.0681\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0175 - mae: 0.0807 - val_loss: 0.0134 - val_mae: 0.0692\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0178 - mae: 0.0804 - val_loss: 0.0133 - val_mae: 0.0694\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0168 - mae: 0.0790 - val_loss: 0.0130 - val_mae: 0.0669\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0781 - val_loss: 0.0132 - val_mae: 0.0686\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0799 - val_loss: 0.0131 - val_mae: 0.0677\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0162 - mae: 0.078 - 0s 114us/step - loss: 0.0172 - mae: 0.0790 - val_loss: 0.0131 - val_mae: 0.0681\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0169 - mae: 0.0797 - val_loss: 0.0131 - val_mae: 0.0682\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0168 - mae: 0.0783 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0181 - mae: 0.0822 - val_loss: 0.0134 - val_mae: 0.0696\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0825 - val_loss: 0.0135 - val_mae: 0.0710\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0175 - mae: 0.0817 - val_loss: 0.0131 - val_mae: 0.0657\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0182 - mae: 0.0806 - val_loss: 0.0131 - val_mae: 0.0681\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0803 - val_loss: 0.0132 - val_mae: 0.0683\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mae: 0.0755 - val_loss: 0.0129 - val_mae: 0.0667\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0823 - val_loss: 0.0130 - val_mae: 0.0674\n",
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mae: 0.0769 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0819 - val_loss: 0.0133 - val_mae: 0.0696\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0165 - mae: 0.0761 - val_loss: 0.0133 - val_mae: 0.0693\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00669: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_small = build_small_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_small.compile(optimizer = optimizer, loss='mse', metrics=['mae'])\n",
    "model_small.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['small'] = model_small.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 661\n",
      "Trainable params: 661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.2259 - mse: 0.1734 - val_loss: 0.2455 - val_mse: 0.1950\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2225 - mse: 0.1717 - val_loss: 0.2438 - val_mse: 0.1950\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2219 - mse: 0.1726 - val_loss: 0.2425 - val_mse: 0.1950\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.2149 - mse: 0.1668 - val_loss: 0.2419 - val_mse: 0.1950\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2070 - mse: 0.1595 - val_loss: 0.2409 - val_mse: 0.1947\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2057 - mse: 0.1590 - val_loss: 0.2384 - val_mse: 0.1934\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.1960 - mse: 0.1496 - val_loss: 0.1891 - val_mse: 0.1426\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1679 - mse: 0.1201 - val_loss: 0.1417 - val_mse: 0.0942\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.1431 - mse: 0.0945 - val_loss: 0.1139 - val_mse: 0.0659\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1356 - mse: 0.0868 - val_loss: 0.0960 - val_mse: 0.0481\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1143 - mse: 0.0655 - val_loss: 0.0802 - val_mse: 0.0323\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1154 - mse: 0.0669 - val_loss: 0.0728 - val_mse: 0.0259\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.1078 - mse: 0.0606 - val_loss: 0.0687 - val_mse: 0.0229\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1012 - mse: 0.0552 - val_loss: 0.0665 - val_mse: 0.0219\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.1000 - mse: 0.0553 - val_loss: 0.0659 - val_mse: 0.0230\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0950 - mse: 0.0519 - val_loss: 0.0642 - val_mse: 0.0220\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0894 - mse: 0.0469 - val_loss: 0.0642 - val_mse: 0.0229\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 81us/step - loss: 0.0876 - mse: 0.0460 - val_loss: 0.0649 - val_mse: 0.0248\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0897 - mse: 0.0495 - val_loss: 0.0661 - val_mse: 0.0273\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0889 - mse: 0.0497 - val_loss: 0.0656 - val_mse: 0.0276\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0870 - mse: 0.0486 - val_loss: 0.0659 - val_mse: 0.0288\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0841 - mse: 0.0466 - val_loss: 0.0651 - val_mse: 0.0286\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.0865 - mse: 0.0497 - val_loss: 0.0637 - val_mse: 0.0274\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0843 - mse: 0.0479 - val_loss: 0.0644 - val_mse: 0.0292\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0840 - mse: 0.0482 - val_loss: 0.0629 - val_mse: 0.0278\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0804 - mse: 0.0452 - val_loss: 0.0635 - val_mse: 0.0295\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0797 - mse: 0.0454 - val_loss: 0.0628 - val_mse: 0.0294\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0853 - mse: 0.0513 - val_loss: 0.0620 - val_mse: 0.0287\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0796 - mse: 0.0458 - val_loss: 0.0608 - val_mse: 0.0276\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0765 - mse: 0.0430 - val_loss: 0.0609 - val_mse: 0.0284\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0811 - mse: 0.0484 - val_loss: 0.0600 - val_mse: 0.0278\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0788 - mse: 0.0463 - val_loss: 0.0589 - val_mse: 0.0265\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0809 - mse: 0.0481 - val_loss: 0.0588 - val_mse: 0.0269\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0800 - mse: 0.0480 - val_loss: 0.0587 - val_mse: 0.0275\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0764 - mse: 0.0448 - val_loss: 0.0580 - val_mse: 0.0271\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0783 - mse: 0.0471 - val_loss: 0.0569 - val_mse: 0.0260\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0767 - mse: 0.0455 - val_loss: 0.0568 - val_mse: 0.0263\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0732 - mse: 0.0427 - val_loss: 0.0573 - val_mse: 0.0277\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0717 - mse: 0.0418 - val_loss: 0.0559 - val_mse: 0.0265\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0734 - mse: 0.0437 - val_loss: 0.0563 - val_mse: 0.0276\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0714 - mse: 0.0423 - val_loss: 0.0545 - val_mse: 0.0255\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0734 - mse: 0.0439 - val_loss: 0.0535 - val_mse: 0.0241\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0651 - mse: 0.0355 - val_loss: 0.0531 - val_mse: 0.0243\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0704 - mse: 0.0415 - val_loss: 0.0522 - val_mse: 0.0235\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0692 - mse: 0.0402 - val_loss: 0.0522 - val_mse: 0.0238\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0693 - mse: 0.0406 - val_loss: 0.0515 - val_mse: 0.0237\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 81us/step - loss: 0.0693 - mse: 0.0412 - val_loss: 0.0513 - val_mse: 0.0236\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0659 - mse: 0.0380 - val_loss: 0.0513 - val_mse: 0.0241\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0674 - mse: 0.0400 - val_loss: 0.0504 - val_mse: 0.0232\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.0625 - mse: 0.0352 - val_loss: 0.0500 - val_mse: 0.0233\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0636 - mse: 0.0366 - val_loss: 0.0497 - val_mse: 0.0235\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0606 - mse: 0.0341 - val_loss: 0.0491 - val_mse: 0.0234\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0688 - mse: 0.0426 - val_loss: 0.0478 - val_mse: 0.0217\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0670 - mse: 0.0406 - val_loss: 0.0474 - val_mse: 0.0213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0613 - mse: 0.0352 - val_loss: 0.0463 - val_mse: 0.0203\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0612 - mse: 0.0352 - val_loss: 0.0466 - val_mse: 0.0214\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0677 - mse: 0.040 - 0s 110us/step - loss: 0.0588 - mse: 0.0336 - val_loss: 0.0453 - val_mse: 0.0202\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0616 - mse: 0.0364 - val_loss: 0.0445 - val_mse: 0.0193\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0573 - mse: 0.0321 - val_loss: 0.0437 - val_mse: 0.0186\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0636 - mse: 0.0386 - val_loss: 0.0438 - val_mse: 0.0189\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0561 - mse: 0.0312 - val_loss: 0.0433 - val_mse: 0.0186\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0584 - mse: 0.0338 - val_loss: 0.0432 - val_mse: 0.0190\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0587 - mse: 0.0344 - val_loss: 0.0436 - val_mse: 0.0198\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0584 - mse: 0.0343 - val_loss: 0.0432 - val_mse: 0.0195\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0585 - mse: 0.0346 - val_loss: 0.0431 - val_mse: 0.0200\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0558 - mse: 0.0324 - val_loss: 0.0411 - val_mse: 0.0179\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0590 - mse: 0.0358 - val_loss: 0.0407 - val_mse: 0.0177\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0569 - mse: 0.0341 - val_loss: 0.0400 - val_mse: 0.0170\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0530 - mse: 0.0300 - val_loss: 0.0396 - val_mse: 0.0168\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0564 - mse: 0.0336 - val_loss: 0.0402 - val_mse: 0.0181\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0532 - mse: 0.0310 - val_loss: 0.0391 - val_mse: 0.0168\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0544 - mse: 0.0321 - val_loss: 0.0393 - val_mse: 0.0176\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0504 - mse: 0.0285 - val_loss: 0.0383 - val_mse: 0.0164\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0534 - mse: 0.0316 - val_loss: 0.0386 - val_mse: 0.0173\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0516 - mse: 0.0301 - val_loss: 0.0373 - val_mse: 0.0158\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0540 - mse: 0.0326 - val_loss: 0.0368 - val_mse: 0.0151\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0549 - mse: 0.0335 - val_loss: 0.0377 - val_mse: 0.0169\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mse: 0.0320 - val_loss: 0.0365 - val_mse: 0.0156\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0503 - mse: 0.0295 - val_loss: 0.0362 - val_mse: 0.0153\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0487 - mse: 0.0280 - val_loss: 0.0359 - val_mse: 0.0152\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0472 - mse: 0.0267 - val_loss: 0.0354 - val_mse: 0.0149\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0468 - mse: 0.0264 - val_loss: 0.0356 - val_mse: 0.0154\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0497 - mse: 0.0297 - val_loss: 0.0358 - val_mse: 0.0162\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0532 - mse: 0.0334 - val_loss: 0.0362 - val_mse: 0.0171\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0478 - mse: 0.0286 - val_loss: 0.0349 - val_mse: 0.0156\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0467 - mse: 0.0274 - val_loss: 0.0336 - val_mse: 0.0141\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0487 - mse: 0.0296 - val_loss: 0.0335 - val_mse: 0.0141\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0476 - mse: 0.0283 - val_loss: 0.0338 - val_mse: 0.0148\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0459 - mse: 0.0270 - val_loss: 0.0331 - val_mse: 0.0143\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0480 - mse: 0.0291 - val_loss: 0.0327 - val_mse: 0.0138\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0477 - mse: 0.0290 - val_loss: 0.0323 - val_mse: 0.0136\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0476 - mse: 0.0290 - val_loss: 0.0319 - val_mse: 0.0133\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0442 - mse: 0.0258 - val_loss: 0.0327 - val_mse: 0.0149\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0460 - mse: 0.0281 - val_loss: 0.0313 - val_mse: 0.0131\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0453 - mse: 0.0271 - val_loss: 0.0314 - val_mse: 0.0136\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0464 - mse: 0.0288 - val_loss: 0.0318 - val_mse: 0.0147\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0430 - mse: 0.0259 - val_loss: 0.0310 - val_mse: 0.0137\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0438 - mse: 0.0265 - val_loss: 0.0308 - val_mse: 0.0137\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0430 - mse: 0.0260 - val_loss: 0.0302 - val_mse: 0.0131\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0421 - mse: 0.0252 - val_loss: 0.0302 - val_mse: 0.0133\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0438 - mse: 0.0271 - val_loss: 0.0309 - val_mse: 0.0145\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0474 - mse: 0.0307 - val_loss: 0.0297 - val_mse: 0.0122\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0429 - mse: 0.0255 - val_loss: 0.0298 - val_mse: 0.0128\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0437 - mse: 0.0266 - val_loss: 0.0293 - val_mse: 0.0120\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0424 - mse: 0.0255 - val_loss: 0.0301 - val_mse: 0.0137\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0425 - mse: 0.0262 - val_loss: 0.0291 - val_mse: 0.0126\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0445 - mse: 0.0282 - val_loss: 0.0291 - val_mse: 0.0129\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0395 - mse: 0.0233 - val_loss: 0.0278 - val_mse: 0.0116\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0401 - mse: 0.0242 - val_loss: 0.0285 - val_mse: 0.0131\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0408 - mse: 0.0253 - val_loss: 0.0288 - val_mse: 0.0138\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mse: 0.0262 - val_loss: 0.0282 - val_mse: 0.0125\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0402 - mse: 0.0248 - val_loss: 0.0284 - val_mse: 0.0131\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0397 - mse: 0.0245 - val_loss: 0.0278 - val_mse: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0406 - mse: 0.0256 - val_loss: 0.0270 - val_mse: 0.0115\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0387 - mse: 0.0234 - val_loss: 0.0273 - val_mse: 0.0120\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0399 - mse: 0.0249 - val_loss: 0.0273 - val_mse: 0.0125\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mse: 0.0267 - val_loss: 0.0272 - val_mse: 0.0121\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0351 - mse: 0.0202 - val_loss: 0.0266 - val_mse: 0.0117\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0373 - mse: 0.0225 - val_loss: 0.0260 - val_mse: 0.0107\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0380 - mse: 0.0231 - val_loss: 0.0259 - val_mse: 0.0109\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0400 - mse: 0.0254 - val_loss: 0.0256 - val_mse: 0.0106\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0387 - mse: 0.0240 - val_loss: 0.0263 - val_mse: 0.0118\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0397 - mse: 0.0253 - val_loss: 0.0255 - val_mse: 0.0104\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0349 - mse: 0.0203 - val_loss: 0.0270 - val_mse: 0.0131\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0364 - mse: 0.0225 - val_loss: 0.0257 - val_mse: 0.0114\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0349 - mse: 0.0209 - val_loss: 0.0249 - val_mse: 0.0105\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0400 - mse: 0.0259 - val_loss: 0.0248 - val_mse: 0.0102\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0373 - mse: 0.0231 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0339 - mse: 0.0200 - val_loss: 0.0243 - val_mse: 0.0108\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0359 - mse: 0.0225 - val_loss: 0.0246 - val_mse: 0.0116\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0364 - mse: 0.0234 - val_loss: 0.0240 - val_mse: 0.0106\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0352 - mse: 0.0224 - val_loss: 0.0238 - val_mse: 0.0106\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0358 - mse: 0.0230 - val_loss: 0.0242 - val_mse: 0.0112\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0336 - mse: 0.0209 - val_loss: 0.0241 - val_mse: 0.0114\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0351 - mse: 0.0226 - val_loss: 0.0238 - val_mse: 0.0109\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0344 - mse: 0.0217 - val_loss: 0.0234 - val_mse: 0.0104\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 163us/step - loss: 0.0341 - mse: 0.0216 - val_loss: 0.0236 - val_mse: 0.0113\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0336 - mse: 0.0215 - val_loss: 0.0237 - val_mse: 0.0115\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0364 - mse: 0.0243 - val_loss: 0.0232 - val_mse: 0.0105\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0325 - mse: 0.0202 - val_loss: 0.0226 - val_mse: 0.0097\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0327 - mse: 0.0202 - val_loss: 0.0227 - val_mse: 0.0100\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0337 - mse: 0.0213 - val_loss: 0.0230 - val_mse: 0.0108\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0335 - mse: 0.0213 - val_loss: 0.0225 - val_mse: 0.0099\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0313 - mse: 0.0194 - val_loss: 0.0219 - val_mse: 0.0097\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0296 - mse: 0.0181 - val_loss: 0.0222 - val_mse: 0.0106\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0333 - mse: 0.0220 - val_loss: 0.0222 - val_mse: 0.0104\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0328 - mse: 0.0213 - val_loss: 0.0220 - val_mse: 0.0102\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 128us/step - loss: 0.0312 - mse: 0.0196 - val_loss: 0.0218 - val_mse: 0.0102\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0316 - mse: 0.0204 - val_loss: 0.0218 - val_mse: 0.0106\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0302 - mse: 0.0192 - val_loss: 0.0221 - val_mse: 0.0111\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0292 - mse: 0.0184 - val_loss: 0.0210 - val_mse: 0.0100\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0285 - mse: 0.0178 - val_loss: 0.0204 - val_mse: 0.0090\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0315 - mse: 0.0205 - val_loss: 0.0208 - val_mse: 0.0094\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0286 - mse: 0.0177 - val_loss: 0.0213 - val_mse: 0.0103\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0322 - mse: 0.0214 - val_loss: 0.0210 - val_mse: 0.0096\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0282 - mse: 0.0173 - val_loss: 0.0203 - val_mse: 0.0090\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0321 - mse: 0.0212 - val_loss: 0.0206 - val_mse: 0.0097\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0255 - mse: 0.0150 - val_loss: 0.0205 - val_mse: 0.0100\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0295 - mse: 0.0192 - val_loss: 0.0207 - val_mse: 0.0102\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0299 - mse: 0.0197 - val_loss: 0.0199 - val_mse: 0.0092\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0256 - mse: 0.0155 - val_loss: 0.0196 - val_mse: 0.0090\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0285 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0091\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0303 - mse: 0.0204 - val_loss: 0.0193 - val_mse: 0.0088\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0274 - mse: 0.0173 - val_loss: 0.0196 - val_mse: 0.0094\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0288 - mse: 0.0190 - val_loss: 0.0195 - val_mse: 0.0093\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0285 - mse: 0.0185 - val_loss: 0.0196 - val_mse: 0.0091\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0303 - mse: 0.0202 - val_loss: 0.0193 - val_mse: 0.0089\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0298 - mse: 0.0199 - val_loss: 0.0191 - val_mse: 0.0092\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0261 - mse: 0.0166 - val_loss: 0.0192 - val_mse: 0.0094\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0253 - mse: 0.0160 - val_loss: 0.0185 - val_mse: 0.0083\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0301 - mse: 0.0203 - val_loss: 0.0188 - val_mse: 0.0089\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0268 - mse: 0.0174 - val_loss: 0.0188 - val_mse: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0267 - mse: 0.0172 - val_loss: 0.0185 - val_mse: 0.0082\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0268 - mse: 0.0171 - val_loss: 0.0184 - val_mse: 0.0081\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0281 - mse: 0.0184 - val_loss: 0.0186 - val_mse: 0.0086\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0270 - mse: 0.0174 - val_loss: 0.0185 - val_mse: 0.0084\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0257 - mse: 0.0162 - val_loss: 0.0183 - val_mse: 0.0082\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0268 - mse: 0.0173 - val_loss: 0.0182 - val_mse: 0.0078\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0266 - mse: 0.0167 - val_loss: 0.0180 - val_mse: 0.0077\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0235 - mse: 0.0137 - val_loss: 0.0178 - val_mse: 0.0079\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0241 - mse: 0.0147 - val_loss: 0.0178 - val_mse: 0.0081\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0232 - mse: 0.0139 - val_loss: 0.0174 - val_mse: 0.0079\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0243 - mse: 0.0151 - val_loss: 0.0172 - val_mse: 0.0075\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0244 - mse: 0.0150 - val_loss: 0.0176 - val_mse: 0.0085\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0240 - mse: 0.0152 - val_loss: 0.0174 - val_mse: 0.0078\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0244 - mse: 0.0152 - val_loss: 0.0178 - val_mse: 0.0087\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0236 - mse: 0.0144 - val_loss: 0.0171 - val_mse: 0.0076\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0231 - mse: 0.0137 - val_loss: 0.0172 - val_mse: 0.0079\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0222 - mse: 0.0132 - val_loss: 0.0169 - val_mse: 0.0070\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0241 - mse: 0.0148 - val_loss: 0.0173 - val_mse: 0.0079\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0248 - mse: 0.0153 - val_loss: 0.0180 - val_mse: 0.0091\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0224 - mse: 0.0135 - val_loss: 0.0169 - val_mse: 0.0073\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0228 - mse: 0.0136 - val_loss: 0.0169 - val_mse: 0.0079\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0230 - mse: 0.0141 - val_loss: 0.0170 - val_mse: 0.0082\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0240 - mse: 0.0152 - val_loss: 0.0168 - val_mse: 0.0076\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0218 - mse: 0.0129 - val_loss: 0.0167 - val_mse: 0.0079\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0204 - mse: 0.0118 - val_loss: 0.0168 - val_mse: 0.0083\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0217 - mse: 0.0131 - val_loss: 0.0164 - val_mse: 0.0073\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0216 - mse: 0.0127 - val_loss: 0.0168 - val_mse: 0.0083\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0233 - mse: 0.0148 - val_loss: 0.0163 - val_mse: 0.0074\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0227 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0080\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mse: 0.0126 - val_loss: 0.0165 - val_mse: 0.0079\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0225 - mse: 0.0140 - val_loss: 0.0168 - val_mse: 0.0084\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0212 - mse: 0.0126 - val_loss: 0.0162 - val_mse: 0.0070\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0218 - mse: 0.0131 - val_loss: 0.0163 - val_mse: 0.0077\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0219 - mse: 0.0134 - val_loss: 0.0160 - val_mse: 0.0070\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0224 - mse: 0.0138 - val_loss: 0.0162 - val_mse: 0.0073\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0213 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0072\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0210 - mse: 0.0125 - val_loss: 0.0160 - val_mse: 0.0075\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0218 - mse: 0.0135 - val_loss: 0.0159 - val_mse: 0.0075\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0213 - mse: 0.0130 - val_loss: 0.0160 - val_mse: 0.0075\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0214 - mse: 0.0130 - val_loss: 0.0158 - val_mse: 0.0073\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0215 - mse: 0.0133 - val_loss: 0.0163 - val_mse: 0.0085\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 90us/step - loss: 0.0203 - mse: 0.0123 - val_loss: 0.0157 - val_mse: 0.0068\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mse: 0.0126 - val_loss: 0.0161 - val_mse: 0.0078\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mse: 0.0128 - val_loss: 0.0158 - val_mse: 0.0073\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0204 - mse: 0.0121 - val_loss: 0.0154 - val_mse: 0.0063\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mse: 0.0128 - val_loss: 0.0155 - val_mse: 0.0070\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mse: 0.0126 - val_loss: 0.0152 - val_mse: 0.0070\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mse: 0.0130 - val_loss: 0.0153 - val_mse: 0.0071\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mse: 0.0121 - val_loss: 0.0153 - val_mse: 0.0074\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mse: 0.0116 - val_loss: 0.0155 - val_mse: 0.0081\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0197 - mse: 0.0120 - val_loss: 0.0153 - val_mse: 0.0076\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mse: 0.0124 - val_loss: 0.0153 - val_mse: 0.0076\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0203 - mse: 0.0126 - val_loss: 0.0151 - val_mse: 0.0072\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0199 - mse: 0.0121 - val_loss: 0.0149 - val_mse: 0.0066\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mse: 0.0123 - val_loss: 0.0150 - val_mse: 0.0070\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0206 - mse: 0.0127 - val_loss: 0.0148 - val_mse: 0.0066\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0198 - mse: 0.0119 - val_loss: 0.0148 - val_mse: 0.0066\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0206 - mse: 0.0127 - val_loss: 0.0150 - val_mse: 0.0069\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mse: 0.0121 - val_loss: 0.0147 - val_mse: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0196 - mse: 0.0117 - val_loss: 0.0147 - val_mse: 0.0066\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mse: 0.0110 - val_loss: 0.0146 - val_mse: 0.0067\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0203 - mse: 0.0124 - val_loss: 0.0149 - val_mse: 0.0074\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0189 - mse: 0.0112 - val_loss: 0.0145 - val_mse: 0.0060\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mse: 0.0109 - val_loss: 0.0144 - val_mse: 0.0062\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mse: 0.0104 - val_loss: 0.0144 - val_mse: 0.0069\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0186 - mse: 0.0111 - val_loss: 0.0145 - val_mse: 0.0073\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mse: 0.0112 - val_loss: 0.0143 - val_mse: 0.0066\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0188 - mse: 0.0113 - val_loss: 0.0142 - val_mse: 0.0060\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0191 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0063\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0195 - mse: 0.0119 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0193 - mse: 0.0119 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0065\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0185 - mse: 0.0111 - val_loss: 0.0140 - val_mse: 0.0062\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mse: 0.0115 - val_loss: 0.0140 - val_mse: 0.0060\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0190 - mse: 0.0113 - val_loss: 0.0141 - val_mse: 0.0064\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0194 - mse: 0.0119 - val_loss: 0.0140 - val_mse: 0.0064\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0179 - mse: 0.0104 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0179 - mse: 0.0105 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0186 - mse: 0.0112 - val_loss: 0.0138 - val_mse: 0.0064\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0188 - mse: 0.0114 - val_loss: 0.0139 - val_mse: 0.0062\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mse: 0.0110 - val_loss: 0.0139 - val_mse: 0.0057\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 105us/step - loss: 0.0179 - mse: 0.0101 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0172 - mse: 0.0097 - val_loss: 0.0137 - val_mse: 0.0060\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0175 - mse: 0.0102 - val_loss: 0.0137 - val_mse: 0.0066\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0177 - mse: 0.0107 - val_loss: 0.0135 - val_mse: 0.0060\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0181 - mse: 0.0108 - val_loss: 0.0141 - val_mse: 0.0075\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0176 - mse: 0.0107 - val_loss: 0.0135 - val_mse: 0.0061\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0172 - mse: 0.0102 - val_loss: 0.0134 - val_mse: 0.0059\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mse: 0.0106 - val_loss: 0.0134 - val_mse: 0.0065\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0172 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0059\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0174 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0065\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0168 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0063\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0173 - mse: 0.0105 - val_loss: 0.0130 - val_mse: 0.0059\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0170 - mse: 0.0100 - val_loss: 0.0130 - val_mse: 0.0061\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mse: 0.0116 - val_loss: 0.0132 - val_mse: 0.0066\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mse: 0.0109 - val_loss: 0.0131 - val_mse: 0.0063\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mse: 0.0108 - val_loss: 0.0134 - val_mse: 0.0069\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0185 - mse: 0.0117 - val_loss: 0.0133 - val_mse: 0.0065\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0061\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0175 - mse: 0.0106 - val_loss: 0.0131 - val_mse: 0.0061\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0170 - mse: 0.0099 - val_loss: 0.0130 - val_mse: 0.0058\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0169 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0067\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0176 - mse: 0.0108 - val_loss: 0.0131 - val_mse: 0.0067\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0173 - mse: 0.0106 - val_loss: 0.0128 - val_mse: 0.0058\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mse: 0.0103 - val_loss: 0.0128 - val_mse: 0.0061\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0174 - mse: 0.011 - 0s 116us/step - loss: 0.0172 - mse: 0.0105 - val_loss: 0.0128 - val_mse: 0.0062\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mse: 0.0102 - val_loss: 0.0128 - val_mse: 0.0058\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mse: 0.0100 - val_loss: 0.0127 - val_mse: 0.0057\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0158 - mse: 0.0091 - val_loss: 0.0129 - val_mse: 0.0067\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0126 - val_mse: 0.0057\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0168 - mse: 0.0100 - val_loss: 0.0125 - val_mse: 0.0057\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mse: 0.0106 - val_loss: 0.0126 - val_mse: 0.0060\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0167 - mse: 0.0101 - val_loss: 0.0126 - val_mse: 0.0059\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0126 - val_mse: 0.0060\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0058\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0162 - mse: 0.0096 - val_loss: 0.0125 - val_mse: 0.0059\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0171 - mse: 0.0106 - val_loss: 0.0125 - val_mse: 0.0059\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0165 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0055\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0166 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0055\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0174 - mse: 0.0107 - val_loss: 0.0124 - val_mse: 0.0060\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0061\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0123 - val_mse: 0.0057\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0161 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0059\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0161 - mse: 0.0097 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0161 - mse: 0.0093 - val_loss: 0.0123 - val_mse: 0.0055\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0160 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0062\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mse: 0.0100 - val_loss: 0.0124 - val_mse: 0.0060\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0166 - mse: 0.0102 - val_loss: 0.0123 - val_mse: 0.0057\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mse: 0.0101 - val_loss: 0.0123 - val_mse: 0.0059\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0152 - mse: 0.0088 - val_loss: 0.0122 - val_mse: 0.0058\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0153 - mse: 0.0087 - val_loss: 0.0122 - val_mse: 0.0060\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0163 - mse: 0.0098 - val_loss: 0.0120 - val_mse: 0.0055\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0066\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0160 - mse: 0.0097 - val_loss: 0.0121 - val_mse: 0.0057\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0159 - mse: 0.0094 - val_loss: 0.0121 - val_mse: 0.0058\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0157 - mse: 0.0092 - val_loss: 0.0121 - val_mse: 0.0059\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mse: 0.0099 - val_loss: 0.0121 - val_mse: 0.0056\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0121 - val_mse: 0.0057\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0120 - val_mse: 0.0058\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0159 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0063\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0159 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0060\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mse: 0.0102 - val_loss: 0.0122 - val_mse: 0.0061\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0094 - val_loss: 0.0121 - val_mse: 0.0055\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0152 - mse: 0.0087 - val_loss: 0.0120 - val_mse: 0.0057\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0157 - mse: 0.0093 - val_loss: 0.0121 - val_mse: 0.0054\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0153 - mse: 0.0086 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0086 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0156 - mse: 0.0092 - val_loss: 0.0119 - val_mse: 0.0054\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0153 - mse: 0.0088 - val_loss: 0.0120 - val_mse: 0.0057\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0119 - val_mse: 0.0054\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0121 - val_mse: 0.0061\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0149 - mse: 0.0086 - val_loss: 0.0118 - val_mse: 0.0054\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mse: 0.0101 - val_loss: 0.0118 - val_mse: 0.0058\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0119 - val_mse: 0.0059\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0156 - mse: 0.0093 - val_loss: 0.0119 - val_mse: 0.0059\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0158 - mse: 0.0095 - val_loss: 0.0119 - val_mse: 0.0057\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0154 - mse: 0.0091 - val_loss: 0.0118 - val_mse: 0.0055\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0167 - mse: 0.0104 - val_loss: 0.0119 - val_mse: 0.0053\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mse: 0.0098 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mse: 0.0085 - val_loss: 0.0119 - val_mse: 0.0060\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0154 - mse: 0.0092 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0156 - mse: 0.0093 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0155 - mse: 0.0091 - val_loss: 0.0117 - val_mse: 0.0054\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0153 - mse: 0.0088 - val_loss: 0.0117 - val_mse: 0.0057\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0055\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mse: 0.0090 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0151 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0056\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0116 - val_mse: 0.0053\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0153 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mse: 0.0094 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mse: 0.0084 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mse: 0.0080 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mse: 0.0095 - val_loss: 0.0117 - val_mse: 0.0058\n",
      "Epoch 349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0154 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0052\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mse: 0.0082 - val_loss: 0.0115 - val_mse: 0.0053\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0154 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0151 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0056\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0117 - val_mse: 0.0061\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0156 - mse: 0.0097 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0052\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0151 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0150 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0150 - mse: 0.009 - 0s 114us/step - loss: 0.0146 - mse: 0.0083 - val_loss: 0.0115 - val_mse: 0.0056\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0059\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mse: 0.0086 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0153 - mse: 0.0092 - val_loss: 0.0114 - val_mse: 0.0054\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0148 - mse: 0.0087 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mse: 0.0088 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0148 - mse: 0.0086 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0115 - val_mse: 0.0058\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0089 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0145 - mse: 0.0083 - val_loss: 0.0115 - val_mse: 0.0057\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0117 - val_mse: 0.0059\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0139 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0060\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0151 - mse: 0.0092 - val_loss: 0.0117 - val_mse: 0.0053\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0150 - mse: 0.0087 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0148 - mse: 0.0086 - val_loss: 0.0115 - val_mse: 0.0058\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0149 - mse: 0.0088 - val_loss: 0.0114 - val_mse: 0.0056\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0121 - mse: 0.006 - 0s 135us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0153 - mse: 0.0093 - val_loss: 0.0113 - val_mse: 0.0052\n",
      "Epoch 379/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mse: 0.0092 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0051\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0148 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0148 - mse: 0.0087 - val_loss: 0.0114 - val_mse: 0.0052\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0160 - mse: 0.0097 - val_loss: 0.0113 - val_mse: 0.0053\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0156 - mse: 0.0095 - val_loss: 0.0114 - val_mse: 0.0057\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0089 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0147 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0052\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0056\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0144 - mse: 0.0083 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mse: 0.0084 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0137 - mse: 0.0076 - val_loss: 0.0112 - val_mse: 0.0056\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0080 - val_loss: 0.0112 - val_mse: 0.0055\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0077 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0115 - val_mse: 0.0062\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0145 - mse: 0.0085 - val_loss: 0.0114 - val_mse: 0.0051\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0144 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mse: 0.0089 - val_loss: 0.0113 - val_mse: 0.0056\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0147 - mse: 0.0088 - val_loss: 0.0111 - val_mse: 0.0052\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0056\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0110 - val_mse: 0.0052\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0057\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0150 - mse: 0.0091 - val_loss: 0.0112 - val_mse: 0.0057\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0142 - mse: 0.0084 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0078 - val_loss: 0.0112 - val_mse: 0.0055\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0143 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0060\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0079 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0069 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0146 - mse: 0.0089 - val_loss: 0.0111 - val_mse: 0.0056\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0061\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0054\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0148 - mse: 0.0089 - val_loss: 0.0111 - val_mse: 0.0057\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0145 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mse: 0.0082 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0143 - mse: 0.0082 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0052\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0075 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0075 - val_loss: 0.0110 - val_mse: 0.0056\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0070 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mse: 0.0073 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0153 - mse: 0.0096 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0144 - mse: 0.0086 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0148 - mse: 0.0090 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0079 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0052\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mse: 0.0078 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0059\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0059\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mse: 0.0081 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mse: 0.0086 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0051\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0122 - mse: 0.006 - 0s 114us/step - loss: 0.0148 - mse: 0.0089 - val_loss: 0.0109 - val_mse: 0.0055\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0139 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0146 - mse: 0.0089 - val_loss: 0.0109 - val_mse: 0.0050\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0061\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0056\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0082 - val_loss: 0.0108 - val_mse: 0.0052\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0109 - val_mse: 0.0056\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 132us/step - loss: 0.0136 - mse: 0.0078 - val_loss: 0.0108 - val_mse: 0.0055\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mse: 0.0071 - val_loss: 0.0109 - val_mse: 0.0058\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0147 - mse: 0.0090 - val_loss: 0.0109 - val_mse: 0.0051\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mse: 0.0077 - val_loss: 0.0108 - val_mse: 0.0051\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0143 - mse: 0.0085 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0108 - val_mse: 0.0053\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0107 - val_mse: 0.0051\n",
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0144 - mse: 0.0087 - val_loss: 0.0107 - val_mse: 0.0052\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0049\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0060\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0143 - mse: 0.0086 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0107 - val_mse: 0.0048\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0109 - val_mse: 0.0059\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mse: 0.0084 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0077 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0133 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mse: 0.0076 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0070 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0134 - mse: 0.0078 - val_loss: 0.0107 - val_mse: 0.0050\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0108 - val_mse: 0.0058\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0107 - val_mse: 0.0057\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0082 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0133 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0054\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 140us/step - loss: 0.0142 - mse: 0.0086 - val_loss: 0.0106 - val_mse: 0.0055\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0139 - mse: 0.0084 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0136 - mse: 0.0079 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0051\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0130 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0049\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0049\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0047\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0048\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0058\n",
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0105 - val_mse: 0.0049\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0105 - val_mse: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0059\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0145 - mse: 0.0090 - val_loss: 0.0103 - val_mse: 0.0047\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mse: 0.0087 - val_loss: 0.0105 - val_mse: 0.0055\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0132 - mse: 0.0077 - val_loss: 0.0105 - val_mse: 0.0048\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 136us/step - loss: 0.0141 - mse: 0.0084 - val_loss: 0.0105 - val_mse: 0.0055\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0104 - val_mse: 0.0053\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0105 - val_mse: 0.0054\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0104 - val_mse: 0.0054\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0050\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0145 - mse: 0.0090 - val_loss: 0.0105 - val_mse: 0.0056\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0131 - mse: 0.0077 - val_loss: 0.0104 - val_mse: 0.0048\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0058\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0050\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mse: 0.0089 - val_loss: 0.0104 - val_mse: 0.0056\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0141 - mse: 0.0085 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0070 - val_loss: 0.0102 - val_mse: 0.0050\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mse: 0.0074 - val_loss: 0.0103 - val_mse: 0.0049\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0135 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0058\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0053\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0079 - val_loss: 0.0102 - val_mse: 0.0053\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0084 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0047\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0078 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0101 - val_mse: 0.0050\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0140 - mse: 0.0086 - val_loss: 0.0106 - val_mse: 0.0059\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0136 - mse: 0.0084 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0083 - val_loss: 0.0100 - val_mse: 0.0048\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0135 - mse: 0.0078 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0102 - val_mse: 0.0053\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0050\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0100 - val_mse: 0.0047\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0051\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0100 - val_mse: 0.0047\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0123 - mse: 0.0068 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0046\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0052\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0100 - val_mse: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0079 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mse: 0.0071 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0047\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0048\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0045\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mse: 0.0069 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0099 - val_mse: 0.0047\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0069 - val_loss: 0.0100 - val_mse: 0.0051\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mse: 0.0079 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0082 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0082 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0134 - mse: 0.0081 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0046\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0056\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0130 - mse: 0.0077 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0078 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0046\n",
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0074 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mse: 0.0078 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0125 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0056\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0102 - val_mse: 0.0057\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mse: 0.0078 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0078 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0053\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0097 - val_mse: 0.0049\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0135 - mse: 0.0081 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0077 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0048\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0097 - val_mse: 0.0043\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0103 - val_mse: 0.0058\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0125 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0124 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0056\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0062 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mse: 0.0076 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0070 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0043\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0130 - mse: 0.0079 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0128 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0046\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0055\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0083 - val_loss: 0.0095 - val_mse: 0.0046\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0071 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0096 - val_mse: 0.0051\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0131 - mse: 0.0080 - val_loss: 0.0096 - val_mse: 0.0044\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0042\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0064 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0095 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0130 - mse: 0.0078 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0073 - val_loss: 0.0096 - val_mse: 0.0044\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0063 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0080 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0070 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0068 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0120 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0066 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0049\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0070 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0092 - val_mse: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 762/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0047\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0050\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mse: 0.0076 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0065 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0093 - val_mse: 0.0048\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mse: 0.0074 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0043\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0041\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0062 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0048\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0063 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0116 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0062 - val_loss: 0.0090 - val_mse: 0.0046\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0125 - mse: 0.0075 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 810/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0063 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0078 - val_loss: 0.0091 - val_mse: 0.0046\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0060 - val_loss: 0.0089 - val_mse: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mse: 0.0064 - val_loss: 0.0092 - val_mse: 0.0051\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0065 - val_loss: 0.0096 - val_mse: 0.0055\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0126 - mse: 0.0079 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0039\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0120 - mse: 0.0071 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0065 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 851/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 852/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 853/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0062 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 854/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0045\n",
      "Epoch 855/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 856/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 857/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 858/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 859/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 860/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 861/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 862/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 863/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 864/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 865/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0116 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 866/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 867/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 868/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0049\n",
      "Epoch 869/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 870/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0089 - val_mse: 0.0045\n",
      "Epoch 871/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0041\n",
      "Epoch 872/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 873/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 874/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 875/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 876/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 877/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 878/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0060 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 880/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 881/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 882/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0068 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 883/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 884/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 885/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0039\n",
      "Epoch 886/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 887/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 888/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 889/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 890/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 891/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 892/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 893/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0119 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 894/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 895/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 896/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 897/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 898/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 899/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 900/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0074 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 901/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0052\n",
      "Epoch 902/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 903/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0050\n",
      "Epoch 904/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 905/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0057\n",
      "Epoch 906/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 907/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0053\n",
      "Epoch 908/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 909/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0076 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 910/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 911/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 912/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 913/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 914/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0039\n",
      "Epoch 915/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0073 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 916/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 917/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 918/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 919/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 920/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0061 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 921/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 922/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0091 - val_mse: 0.0052\n",
      "Epoch 923/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 924/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0120 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0052\n",
      "Epoch 925/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 926/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 927/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 928/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0073 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 929/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0107 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 930/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 931/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 932/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0089 - val_mse: 0.0049\n",
      "Epoch 933/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0096 - mse: 0.005 - 0s 110us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 934/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 935/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 936/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 937/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0039\n",
      "Epoch 938/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 939/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 940/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 941/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 942/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 943/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 944/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 945/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 946/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 947/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0061 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 948/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 949/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 950/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 951/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0076 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 952/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 953/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 954/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0078 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 955/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mse: 0.0074 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 956/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0058 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 957/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 958/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0120 - mse: 0.0072 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 959/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 960/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 961/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 962/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 963/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0073 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 964/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 965/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 966/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 967/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 968/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0046\n",
      "Epoch 969/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 970/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 971/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 972/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 973/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 974/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 975/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 976/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 977/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 978/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 979/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 980/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 981/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 982/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 983/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 984/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 985/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 986/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 987/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 988/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 989/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 990/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 991/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 992/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 993/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 994/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 995/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 996/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 997/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 999/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1000/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0059 - val_loss: 0.0090 - val_mse: 0.0052\n",
      "Epoch 1001/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0050\n",
      "Epoch 1002/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 1003/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1004/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1005/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 1006/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0106 - mse: 0.0061 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1007/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1008/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 1009/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1010/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 1011/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1012/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1013/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1014/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 1015/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1016/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 1017/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1018/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0076 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1019/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1020/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1021/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 1022/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1023/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1024/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1025/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1026/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1027/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1028/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1029/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1030/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0105 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 1031/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 1032/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 1033/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1034/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1035/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1036/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1037/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1038/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1039/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1040/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1041/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1042/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0046\n",
      "Epoch 1043/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1044/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1045/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0044\n",
      "Epoch 1046/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 1047/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1048/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 1049/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0039\n",
      "Epoch 1050/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1051/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1052/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0084 - val_mse: 0.0044\n",
      "Epoch 1053/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0046\n",
      "Epoch 1054/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1055/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1056/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1057/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1058/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1059/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1060/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 1061/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0046\n",
      "Epoch 1062/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1063/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1064/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1065/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1066/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1067/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1068/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1069/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1070/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0116 - mse: 0.0072 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1071/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 1072/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1073/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1074/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1075/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1076/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1077/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1078/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1079/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1080/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1081/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1082/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1083/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0073 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1084/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1085/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1086/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1087/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0084 - val_mse: 0.0047\n",
      "Epoch 1088/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1089/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1090/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1091/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1092/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1093/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1094/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1095/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1096/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1097/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0072 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1098/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1099/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1100/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 1101/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1102/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1103/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1104/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1105/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mse: 0.0074 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1106/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1107/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1108/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1109/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1110/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1111/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0039\n",
      "Epoch 1113/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1114/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1115/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1116/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0110 - mse: 0.0068 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1117/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1118/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1119/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1120/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1121/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 1122/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1123/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1124/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1125/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1126/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1127/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1128/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0038\n",
      "Epoch 1129/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1130/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0084 - mse: 0.004 - 0s 112us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 1131/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 1132/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1133/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1134/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1135/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1136/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1137/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1138/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1139/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 1140/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1141/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1142/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1143/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1144/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1145/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1146/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0120 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1147/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1148/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0099 - mse: 0.0056 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1149/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1150/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1151/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1152/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1153/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0082 - val_mse: 0.0044\n",
      "Epoch 1154/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1155/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0082 - val_mse: 0.0044\n",
      "Epoch 1156/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1157/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1159/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1160/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1161/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1162/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0072 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1163/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0059 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1164/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1165/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1166/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mse: 0.0059 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 1167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0075 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1168/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1169/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1172/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 1173/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mse: 0.0055 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1174/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1175/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1176/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1177/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1178/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0108 - mse: 0.006 - 0s 108us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1179/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1180/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0043\n",
      "Epoch 1181/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1182/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1183/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0041\n",
      "Epoch 1184/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 1185/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1186/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1187/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1188/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0044\n",
      "Epoch 1189/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 1190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1191/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1192/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1193/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1194/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1195/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1196/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0112 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0044\n",
      "Epoch 1197/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1198/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1199/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0072 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1200/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0084 - val_mse: 0.0049\n",
      "Epoch 1201/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1202/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1203/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1204/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0043\n",
      "Epoch 1205/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 1206/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1207/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1208/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1209/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1210/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1211/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1212/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1213/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1214/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 1215/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1216/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 1217/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1218/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 1219/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 1220/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1221/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1222/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1223/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1224/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1225/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1226/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1227/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0051\n",
      "Epoch 1228/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1229/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mse: 0.0058 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1230/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1231/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1232/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1233/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1234/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1235/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1236/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1237/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1238/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 1239/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0069 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1241/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1242/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1243/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1244/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1245/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1246/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1247/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1248/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1249/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1250/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 1251/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1252/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1253/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1254/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1255/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1256/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1257/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1258/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1259/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1261/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1262/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1264/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1265/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1266/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1267/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 1270/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1271/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1272/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1273/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0037\n",
      "Epoch 1274/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0036\n",
      "Epoch 1275/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0047\n",
      "Epoch 1276/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0065 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1278/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1279/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1280/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1281/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0084 - val_mse: 0.0051\n",
      "Epoch 1282/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1283/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1284/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0072 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 1285/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1286/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0049\n",
      "Epoch 1288/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1289/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1290/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1291/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1292/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1293/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1294/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1295/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1296/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mse: 0.0061 - val_loss: 0.0082 - val_mse: 0.0048\n",
      "Epoch 1297/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1298/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0059 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1299/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1300/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1301/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1302/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1303/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1304/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0047\n",
      "Epoch 1305/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1306/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1307/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0070 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1308/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1309/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1310/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1311/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1312/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1313/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0066 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1314/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1316/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1317/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1318/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1319/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1320/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1322/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1323/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0095 - mse: 0.0055 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1324/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1325/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1329/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0048\n",
      "Epoch 1330/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0049\n",
      "Epoch 1331/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1332/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1333/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1334/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0099 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1335/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1336/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1337/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1338/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1339/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1340/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1341/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1342/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0097 - mse: 0.0058 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1343/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1344/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0103 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1345/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1346/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1347/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1348/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1349/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1350/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 1351/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1352/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1353/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1354/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1355/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1356/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0037\n",
      "Epoch 1357/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1358/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1359/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1360/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1361/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1362/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1363/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1364/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0076 - val_mse: 0.0037\n",
      "Epoch 1365/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0070 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1366/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0095 - mse: 0.0057 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1367/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1368/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1369/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1370/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1371/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1372/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0065 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1373/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mse: 0.0065 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1374/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 1375/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0043\n",
      "Epoch 1376/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0102 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1377/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1378/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1379/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1380/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1381/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 01381: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_tiny = build_tiny_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_tiny.compile(optimizer = optimizer, loss='mse', metrics=['mse'])\n",
    "model_tiny.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['tiny'] = model_tiny.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prn.CreateNN([64, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 603)\n",
      "(603,)\n",
      "(64, 202)\n",
      "(202,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  882.8162979844722 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  26.177556237542092 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  9.341793040836631 \tscale factor:  0.007407407407407407\n",
      "Iteration:  3 \t\tError:  6.71134769805921 \tscale factor:  0.3936600000000001\n",
      "Iteration:  4 \t\tError:  2.5254005292343162 \tscale factor:  0.14580000000000004\n",
      "Iteration:  5 \t\tError:  1.9236393623491903 \tscale factor:  0.14580000000000004\n",
      "Iteration:  6 \t\tError:  1.687300050809699 \tscale factor:  0.05400000000000001\n",
      "Iteration:  7 \t\tError:  1.6160548125720917 \tscale factor:  0.05400000000000001\n",
      "Iteration:  8 \t\tError:  1.5356668949939483 \tscale factor:  0.05400000000000001\n",
      "Iteration:  9 \t\tError:  1.4736452210781634 \tscale factor:  0.020000000000000004\n",
      "Iteration:  10 \t\tError:  1.4254625807512398 \tscale factor:  0.05400000000000001\n",
      "Iteration:  11 \t\tError:  1.4116778597370008 \tscale factor:  0.05400000000000001\n",
      "Iteration:  12 \t\tError:  1.365237846690635 \tscale factor:  0.05400000000000001\n",
      "Iteration:  13 \t\tError:  1.323235904443498 \tscale factor:  0.05400000000000001\n",
      "Iteration:  14 \t\tError:  1.2925159023223451 \tscale factor:  0.05400000000000001\n",
      "Iteration:  15 \t\tError:  1.2619840230417894 \tscale factor:  0.05400000000000001\n",
      "Iteration:  16 \t\tError:  1.2299898519913346 \tscale factor:  0.05400000000000001\n",
      "Iteration:  17 \t\tError:  1.1884255640132588 \tscale factor:  0.020000000000000004\n",
      "Iteration:  18 \t\tError:  1.186742445422218 \tscale factor:  0.0074074074074074086\n",
      "Iteration:  19 \t\tError:  1.0641568368274221 \tscale factor:  0.0074074074074074086\n",
      "Iteration:  20 \t\tError:  1.0288475822902372 \tscale factor:  0.0074074074074074086\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=20, E_stop=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = prn.NNOut(x_train, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = prn.NNOut(x_test, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_train  y_train_pred\n",
      "0  0.647607      0.660812\n",
      "1  0.527738      0.508704\n",
      "2  0.624918      0.571427\n",
      "3  0.158689      0.204018\n",
      "4  0.467016      0.431129\n",
      "train r2 score =  0.9225192374167468 / 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy on the training data\n",
    "train_compare = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': pred_train.flatten()})\n",
    "print(train_compare.head())\n",
    "train_r2_score = r2_score(train_compare.y_train, train_compare.y_train_pred)\n",
    "print('train r2 score = ', train_r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_test  y_test_pred\n",
      "0  0.094426     0.168700\n",
      "1  0.629770     0.598467\n",
      "2  0.498361     0.465771\n",
      "3  0.366033     0.250176\n",
      "4  0.414426     0.394646\n",
      "test r2 score =  0.8376478450635576 / 1.0\n"
     ]
    }
   ],
   "source": [
    "test_compare = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': pred_test.flatten()})\n",
    "print(test_compare.head())\n",
    "test_r2_score = r2_score(test_compare.y_test, test_compare.y_test_pred)\n",
    "print('test r2 score = ', test_r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linestyles = ['-', '--', '-.', ':']\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "sizes = ['tiny', 'small', 'medium', 'default']\n",
    "plt.figure()\n",
    "for y, linestyle in enumerate(sizes):\n",
    "    data_history = history[sizes[y]].history\n",
    "    loss = data_history['loss']\n",
    "    val_loss = data_history['val_loss']\n",
    "    plt.plot(val_loss, color=colors[y], linestyle = '--', label = sizes[y] + '_val_loss')\n",
    "    plt.plot(loss, color=colors[y], linestyle = ':', label = sizes[y] +'_loss')\n",
    "    \n",
    "plt.legend(loc = 'upper left' )\n",
    "plt.xlabel = 'epochs'\n",
    "plt.ylabel = 'loss'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['medium'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['small'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.title('small model')\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['tiny'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.title('tiny model')\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_default.predict(x_test)\n",
    "pred_train = model_default.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_train  y_train_pred\n",
      "0  0.647607      0.514552\n",
      "1  0.527738      0.498594\n",
      "2  0.624918      0.629943\n",
      "3  0.158689      0.218937\n",
      "4  0.467016      0.408544\n",
      "train r2 score =  0.7898080341059219 / 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy on the training data\n",
    "train_compare = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': pred_train.flatten()})\n",
    "print(train_compare.head())\n",
    "train_r2_score = r2_score(train_compare.y_train, train_compare.y_train_pred)\n",
    "print('train r2 score = ', train_r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_test  y_test_pred\n",
      "0  0.094426     0.218937\n",
      "1  0.629770     0.585916\n",
      "2  0.498361     0.533952\n",
      "3  0.366033     0.339156\n",
      "4  0.414426     0.407704\n",
      "test r2 score =  0.7518127377966217 / 1.0\n"
     ]
    }
   ],
   "source": [
    "test_compare = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': pred_test.flatten()})\n",
    "print(test_compare.head())\n",
    "test_r2_score = r2_score(test_compare.y_test, test_compare.y_test_pred)\n",
    "print('test r2 score = ', test_r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.330492</td>\n",
       "      <td>0.339449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663082</td>\n",
       "      <td>0.515690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.427934</td>\n",
       "      <td>0.275546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.346492</td>\n",
       "      <td>0.341245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.364590</td>\n",
       "      <td>0.327694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_test_pred\n",
       "0  0.330492     0.339449\n",
       "1  0.663082     0.515690\n",
       "2  0.427934     0.275546\n",
       "3  0.346492     0.341245\n",
       "4  0.364590     0.327694"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.8265397095743221 / 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with CH value only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = test_data[:,0,:]\n",
    "test_data_y = yield_data['Yield'][mask_yield].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5,257\n",
      "Trainable params: 5,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_regression_model(12)\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 12)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 17 samples\n",
      "Epoch 1/10000\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 919.0145 - accuracy: 0.0000e+00 - val_loss: 519.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 656.6866 - accuracy: 0.0000e+00 - val_loss: 371.0316 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 414.0786 - accuracy: 0.0000e+00 - val_loss: 266.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 265.6183 - accuracy: 0.0000e+00 - val_loss: 212.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "64/64 [==============================] - 0s 179us/step - loss: 273.8373 - accuracy: 0.0000e+00 - val_loss: 197.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 298.7087 - accuracy: 0.0000e+00 - val_loss: 200.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 310.8811 - accuracy: 0.0156 - val_loss: 203.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 234.9682 - accuracy: 0.0000e+00 - val_loss: 200.1054 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 283.4267 - accuracy: 0.0000e+00 - val_loss: 191.4078 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 271.8621 - accuracy: 0.0000e+00 - val_loss: 184.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "64/64 [==============================] - 0s 315us/step - loss: 267.7375 - accuracy: 0.0000e+00 - val_loss: 182.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 250.3867 - accuracy: 0.0000e+00 - val_loss: 188.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 251.0997 - accuracy: 0.0156 - val_loss: 197.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 252.6989 - accuracy: 0.0000e+00 - val_loss: 204.9701 - val_accuracy: 0.0588\n",
      "Epoch 15/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 233.4025 - accuracy: 0.0000e+00 - val_loss: 210.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 221.7016 - accuracy: 0.0000e+00 - val_loss: 210.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 213.7828 - accuracy: 0.0000e+00 - val_loss: 207.2567 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 268.9313 - accuracy: 0.0156 - val_loss: 199.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 259.7483 - accuracy: 0.0000e+00 - val_loss: 188.6309 - val_accuracy: 0.0588\n",
      "Epoch 20/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 205.6538 - accuracy: 0.0000e+00 - val_loss: 179.5594 - val_accuracy: 0.0588\n",
      "Epoch 21/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 195.3052 - accuracy: 0.0000e+00 - val_loss: 170.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 151.9656 - accuracy: 0.0000e+00 - val_loss: 164.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 201.0114 - accuracy: 0.0156 - val_loss: 160.4981 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 203.5452 - accuracy: 0.0000e+00 - val_loss: 160.3402 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 196.0561 - accuracy: 0.0000e+00 - val_loss: 163.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 178.2034 - accuracy: 0.0000e+00 - val_loss: 167.5468 - val_accuracy: 0.0588\n",
      "Epoch 27/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 221.9117 - accuracy: 0.0156 - val_loss: 173.8404 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 222.7455 - accuracy: 0.0000e+00 - val_loss: 175.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 155.0220 - accuracy: 0.0000e+00 - val_loss: 172.7637 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 174.5987 - accuracy: 0.0000e+00 - val_loss: 167.8829 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 184.5064 - accuracy: 0.0156 - val_loss: 161.8482 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 225.6445 - accuracy: 0.0000e+00 - val_loss: 156.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 230.4330 - accuracy: 0.0156 - val_loss: 151.7428 - val_accuracy: 0.0588\n",
      "Epoch 34/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 235.5918 - accuracy: 0.0000e+00 - val_loss: 146.1258 - val_accuracy: 0.0588\n",
      "Epoch 35/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.9772 - accuracy: 0.0000e+00 - val_loss: 142.8292 - val_accuracy: 0.0588\n",
      "Epoch 36/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 191.1345 - accuracy: 0.0156 - val_loss: 139.7425 - val_accuracy: 0.0588\n",
      "Epoch 37/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 219.8819 - accuracy: 0.0000e+00 - val_loss: 140.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 159.8179 - accuracy: 0.0000e+00 - val_loss: 144.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 149.3368 - accuracy: 0.0000e+00 - val_loss: 151.1553 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.4899 - accuracy: 0.0000e+00 - val_loss: 153.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 183.8045 - accuracy: 0.0000e+00 - val_loss: 151.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 158.0460 - accuracy: 0.0000e+00 - val_loss: 147.6312 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 192.7749 - accuracy: 0.0000e+00 - val_loss: 142.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 203.7605 - accuracy: 0.0000e+00 - val_loss: 132.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.5863 - accuracy: 0.0000e+00 - val_loss: 125.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 163.2003 - accuracy: 0.0000e+00 - val_loss: 121.6926 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 188.6192 - accuracy: 0.0000e+00 - val_loss: 122.1478 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 174.5193 - accuracy: 0.0000e+00 - val_loss: 131.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.4134 - accuracy: 0.0000e+00 - val_loss: 142.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.0945 - accuracy: 0.0156 - val_loss: 151.0955 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 194.2966 - accuracy: 0.0000e+00 - val_loss: 152.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.1273 - accuracy: 0.0000e+00 - val_loss: 147.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 169.1698 - accuracy: 0.0000e+00 - val_loss: 135.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 151.9541 - accuracy: 0.0000e+00 - val_loss: 122.7022 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 175.2093 - accuracy: 0.0000e+00 - val_loss: 115.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 163.7057 - accuracy: 0.0000e+ - 0s 125us/step - loss: 171.9912 - accuracy: 0.0156 - val_loss: 110.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 173.0939 - accuracy: 0.0000e+00 - val_loss: 107.5262 - val_accuracy: 0.0588\n",
      "Epoch 58/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.2368 - accuracy: 0.0000e+00 - val_loss: 109.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.6484 - accuracy: 0.0000e+00 - val_loss: 113.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 142.9353 - accuracy: 0.0000e+00 - val_loss: 119.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.1225 - accuracy: 0.0000e+00 - val_loss: 125.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.8518 - accuracy: 0.0000e+00 - val_loss: 136.3193 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 187.2827 - accuracy: 0.0000e+00 - val_loss: 138.3542 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 161.4770 - accuracy: 0.0000e+00 - val_loss: 132.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 142.3231 - accuracy: 0.0156 - val_loss: 126.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 154.8860 - accuracy: 0.0000e+00 - val_loss: 119.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 188.1061 - accuracy: 0.0156 - val_loss: 112.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 140.7591 - accuracy: 0.0000e+00 - val_loss: 110.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 134.2978 - accuracy: 0.0000e+00 - val_loss: 108.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 162.2009 - accuracy: 0.0000e+00 - val_loss: 108.7579 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 173.6074 - accuracy: 0.0000e+00 - val_loss: 113.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 162.2045 - accuracy: 0.0000e+00 - val_loss: 117.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.5753 - accuracy: 0.0000e+00 - val_loss: 123.6619 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.6151 - accuracy: 0.0000e+00 - val_loss: 126.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 167.5950 - accuracy: 0.0312 - val_loss: 126.5158 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 169.8740 - accuracy: 0.0156 - val_loss: 126.0813 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 163.6138 - accuracy: 0.0000e+00 - val_loss: 117.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 170.6783 - accuracy: 0.0000e+00 - val_loss: 113.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 157.0419 - accuracy: 0.0000e+00 - val_loss: 112.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 158.5028 - accuracy: 0.0000e+00 - val_loss: 115.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 137.4615 - accuracy: 0.0000e+00 - val_loss: 113.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.0983 - accuracy: 0.0312 - val_loss: 112.8232 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 122.8114 - accuracy: 0.0000e+00 - val_loss: 112.8495 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 119.7417 - accuracy: 0.0000e+00 - val_loss: 113.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.4022 - accuracy: 0.0000e+00 - val_loss: 112.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 147.7029 - accuracy: 0.0000e+00 - val_loss: 109.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.8216 - accuracy: 0.0000e+00 - val_loss: 108.8237 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 154.0785 - accuracy: 0.0156 - val_loss: 108.6925 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.5411 - accuracy: 0.0000e+00 - val_loss: 105.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.9461 - accuracy: 0.0000e+00 - val_loss: 102.5481 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 150.4585 - accuracy: 0.0000e+00 - val_loss: 106.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 138.8390 - accuracy: 0.0000e+00 - val_loss: 111.7747 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 133.2212 - accuracy: 0.0000e+00 - val_loss: 121.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 118.0976 - accuracy: 0.0156 - val_loss: 131.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 152.3251 - accuracy: 0.0156 - val_loss: 133.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 157.6668 - accuracy: 0.0156 - val_loss: 130.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.4156 - accuracy: 0.0000e+00 - val_loss: 123.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.6404 - accuracy: 0.0000e+00 - val_loss: 117.7926 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 136.1808 - accuracy: 0.0156 - val_loss: 114.3712 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.8008 - accuracy: 0.0000e+00 - val_loss: 113.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.0952 - accuracy: 0.0000e+00 - val_loss: 115.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.4529 - accuracy: 0.0156 - val_loss: 118.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.8029 - accuracy: 0.0000e+00 - val_loss: 118.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.8860 - accuracy: 0.0000e+00 - val_loss: 119.1265 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 145.9311 - accuracy: 0.0000e+00 - val_loss: 117.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 141.6039 - accuracy: 0.0000e+00 - val_loss: 116.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 111.7204 - accuracy: 0.0000e+00 - val_loss: 111.4548 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.7446 - accuracy: 0.0156 - val_loss: 103.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.2041 - accuracy: 0.0000e+00 - val_loss: 95.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 137.0257 - accuracy: 0.0156 - val_loss: 91.8084 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 166.7494 - accuracy: 0.0000e+00 - val_loss: 94.5509 - val_accuracy: 0.0588\n",
      "Epoch 112/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 156.8771 - accuracy: 0.0000e+00 - val_loss: 105.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.9853 - accuracy: 0.0000e+00 - val_loss: 119.4765 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 143.0402 - accuracy: 0.0000e+00 - val_loss: 130.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 113.2497 - accuracy: 0.0000e+00 - val_loss: 133.1805 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.2063 - accuracy: 0.0000e+00 - val_loss: 123.2787 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.4163 - accuracy: 0.0312 - val_loss: 107.3158 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.0141 - accuracy: 0.0156 - val_loss: 96.0545 - val_accuracy: 0.0588\n",
      "Epoch 119/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 128.2527 - accuracy: 0.0000e+00 - val_loss: 96.1778 - val_accuracy: 0.0588\n",
      "Epoch 120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 149.4209 - accuracy: 0.0000e+00 - val_loss: 100.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 126.9805 - accuracy: 0.0000e+00 - val_loss: 107.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.4711 - accuracy: 0.0156 - val_loss: 116.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 133.5065 - accuracy: 0.0000e+00 - val_loss: 125.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 149.3536 - accuracy: 0.0000e+00 - val_loss: 129.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 121.7429 - accuracy: 0.0000e+00 - val_loss: 126.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 141.7879 - accuracy: 0.0000e+00 - val_loss: 114.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.4128 - accuracy: 0.0000e+00 - val_loss: 103.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 158.2665 - accuracy: 0.0000e+00 - val_loss: 102.3653 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 116.6244 - accuracy: 0.0000e+00 - val_loss: 99.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 136.5044 - accuracy: 0.0000e+00 - val_loss: 101.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/10000\n",
      "64/64 [==============================] - 0s 167us/step - loss: 117.5791 - accuracy: 0.0000e+00 - val_loss: 107.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 138.3744 - accuracy: 0.0156 - val_loss: 116.6736 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.4452 - accuracy: 0.0000e+00 - val_loss: 119.4997 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.0111 - accuracy: 0.0156 - val_loss: 116.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 129.6651 - accuracy: 0.0000e+00 - val_loss: 115.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.2324 - accuracy: 0.0000e+00 - val_loss: 113.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.1081 - accuracy: 0.0000e+00 - val_loss: 105.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 115.4761 - accuracy: 0.0312 - val_loss: 97.1477 - val_accuracy: 0.0588\n",
      "Epoch 139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.7672 - accuracy: 0.0000e+00 - val_loss: 92.9759 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.6531 - accuracy: 0.0000e+00 - val_loss: 93.3417 - val_accuracy: 0.0588\n",
      "Epoch 141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 166.5128 - accuracy: 0.0000e+00 - val_loss: 103.4739 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.1838 - accuracy: 0.0000e+00 - val_loss: 109.5036 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.6452 - accuracy: 0.0000e+00 - val_loss: 112.2923 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 151.0158 - accuracy: 0.0156 - val_loss: 115.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.4967 - accuracy: 0.0156 - val_loss: 119.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 144.0561 - accuracy: 0.0000e+00 - val_loss: 123.7539 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.5438 - accuracy: 0.0000e+00 - val_loss: 120.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.3885 - accuracy: 0.0312 - val_loss: 109.6579 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 89.9623 - accuracy: 0.0156 - val_loss: 101.2648 - val_accuracy: 0.0588\n",
      "Epoch 150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 131.7073 - accuracy: 0.0000e+00 - val_loss: 98.7363 - val_accuracy: 0.0588\n",
      "Epoch 151/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 109.3032 - accuracy: 0.0312 - val_loss: 99.6822 - val_accuracy: 0.0588\n",
      "Epoch 152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.7682 - accuracy: 0.0000e+00 - val_loss: 108.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.0859 - accuracy: 0.0000e+00 - val_loss: 117.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.2467 - accuracy: 0.0156 - val_loss: 126.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 105.3410 - accuracy: 0.0000e+00 - val_loss: 123.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 107.7761 - accuracy: 0.0000e+00 - val_loss: 115.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.6404 - accuracy: 0.0156 - val_loss: 108.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 143.2380 - accuracy: 0.0000e+00 - val_loss: 100.2565 - val_accuracy: 0.0588\n",
      "Epoch 159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.9077 - accuracy: 0.0156 - val_loss: 97.8493 - val_accuracy: 0.0588\n",
      "Epoch 160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.6835 - accuracy: 0.0000e+00 - val_loss: 101.2257 - val_accuracy: 0.0588\n",
      "Epoch 161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 127.7558 - accuracy: 0.0156 - val_loss: 104.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.6880 - accuracy: 0.0000e+00 - val_loss: 111.7978 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 132.9052 - accuracy: 0.0156 - val_loss: 121.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.0965 - accuracy: 0.0000e+00 - val_loss: 122.9704 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.7255 - accuracy: 0.0000e+00 - val_loss: 113.0666 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.0673 - accuracy: 0.0000e+00 - val_loss: 103.4545 - val_accuracy: 0.0588\n",
      "Epoch 167/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 128.5817 - accuracy: 0.0000e+00 - val_loss: 97.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.1869 - accuracy: 0.0156 - val_loss: 96.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.5461 - accuracy: 0.0000e+00 - val_loss: 101.5615 - val_accuracy: 0.0588\n",
      "Epoch 170/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.6186 - accuracy: 0.0000e+00 - val_loss: 111.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.1388 - accuracy: 0.0000e+00 - val_loss: 115.5616 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 125.4294 - accuracy: 0.0000e+00 - val_loss: 110.1922 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 128.7043 - accuracy: 0.0000e+00 - val_loss: 103.3265 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8304 - accuracy: 0.0156 - val_loss: 101.2994 - val_accuracy: 0.0588\n",
      "Epoch 175/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.6713 - accuracy: 0.0000e+00 - val_loss: 94.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2976 - accuracy: 0.0000e+00 - val_loss: 89.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.7842 - accuracy: 0.0000e+00 - val_loss: 90.8683 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.8239 - accuracy: 0.0000e+00 - val_loss: 95.1817 - val_accuracy: 0.0588\n",
      "Epoch 179/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.5889 - accuracy: 0.0000e+00 - val_loss: 107.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.4848 - accuracy: 0.0000e+00 - val_loss: 121.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.6250 - accuracy: 0.0000e+00 - val_loss: 127.7294 - val_accuracy: 0.0588\n",
      "Epoch 182/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.1550 - accuracy: 0.0000e+00 - val_loss: 121.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.0697 - accuracy: 0.0156 - val_loss: 107.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 114.4849 - accuracy: 0.0156 - val_loss: 91.9452 - val_accuracy: 0.0588\n",
      "Epoch 185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.6717 - accuracy: 0.0000e+00 - val_loss: 84.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.7658 - accuracy: 0.0000e+00 - val_loss: 86.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 111.1621 - accuracy: 0.0000e+00 - val_loss: 92.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.3226 - accuracy: 0.0000e+00 - val_loss: 96.8399 - val_accuracy: 0.0588\n",
      "Epoch 189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 124.8146 - accuracy: 0.0156 - val_loss: 102.3237 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4722 - accuracy: 0.0000e+00 - val_loss: 108.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 119.2177 - accuracy: 0.0000e+00 - val_loss: 108.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.8709 - accuracy: 0.0000e+00 - val_loss: 106.7145 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.3099 - accuracy: 0.0000e+00 - val_loss: 106.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.3901 - accuracy: 0.0000e+00 - val_loss: 107.8556 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.2561 - accuracy: 0.0000e+00 - val_loss: 103.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.9955 - accuracy: 0.0156 - val_loss: 94.6895 - val_accuracy: 0.0588\n",
      "Epoch 197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 127.0519 - accuracy: 0.0000e+00 - val_loss: 97.0042 - val_accuracy: 0.0588\n",
      "Epoch 198/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.1124 - accuracy: 0.0156 - val_loss: 99.3207 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.4393 - accuracy: 0.0000e+00 - val_loss: 96.5420 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5349 - accuracy: 0.0000e+00 - val_loss: 94.3689 - val_accuracy: 0.0588\n",
      "Epoch 201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.8088 - accuracy: 0.0000e+00 - val_loss: 97.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.4753 - accuracy: 0.0000e+00 - val_loss: 104.0720 - val_accuracy: 0.0588\n",
      "Epoch 203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.0399 - accuracy: 0.0000e+00 - val_loss: 104.0496 - val_accuracy: 0.0588\n",
      "Epoch 204/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.9834 - accuracy: 0.0000e+00 - val_loss: 93.6528 - val_accuracy: 0.0588\n",
      "Epoch 205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.9764 - accuracy: 0.0000e+00 - val_loss: 88.4511 - val_accuracy: 0.1176\n",
      "Epoch 206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.1814 - accuracy: 0.0000e+00 - val_loss: 90.0319 - val_accuracy: 0.0588\n",
      "Epoch 207/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.6819 - accuracy: 0.0000e+00 - val_loss: 95.2764 - val_accuracy: 0.0588\n",
      "Epoch 208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.4941 - accuracy: 0.0156 - val_loss: 101.1636 - val_accuracy: 0.0588\n",
      "Epoch 209/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 111.8264 - accuracy: 0.0000e+00 - val_loss: 100.2464 - val_accuracy: 0.0588\n",
      "Epoch 210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.9181 - accuracy: 0.0000e+00 - val_loss: 90.9203 - val_accuracy: 0.0588\n",
      "Epoch 211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5659 - accuracy: 0.0000e+00 - val_loss: 82.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.3451 - accuracy: 0.0000e+00 - val_loss: 82.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.7654 - accuracy: 0.0156 - val_loss: 87.9866 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.2716 - accuracy: 0.0000e+00 - val_loss: 90.7559 - val_accuracy: 0.0588\n",
      "Epoch 215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2886 - accuracy: 0.0000e+00 - val_loss: 97.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.8506 - accuracy: 0.0156 - val_loss: 104.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.7234 - accuracy: 0.0000e+00 - val_loss: 110.3955 - val_accuracy: 0.0588\n",
      "Epoch 218/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 131.8628 - accuracy: 0.0000e+00 - val_loss: 110.8574 - val_accuracy: 0.0588\n",
      "Epoch 219/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 131.5726 - accuracy: 0.0000e+00 - val_loss: 105.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 105.7620 - accuracy: 0.0000e+00 - val_loss: 99.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.8223 - accuracy: 0.0000e+00 - val_loss: 92.8922 - val_accuracy: 0.0588\n",
      "Epoch 222/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 111.4602 - accuracy: 0.0000e+00 - val_loss: 91.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.5863 - accuracy: 0.0000e+00 - val_loss: 95.7270 - val_accuracy: 0.0588\n",
      "Epoch 224/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4913 - accuracy: 0.0156 - val_loss: 99.5599 - val_accuracy: 0.0588\n",
      "Epoch 225/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 106.4728 - accuracy: 0.0000e+00 - val_loss: 107.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.2317 - accuracy: 0.0000e+00 - val_loss: 108.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.0144 - accuracy: 0.0156 - val_loss: 108.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.3196 - accuracy: 0.0000e+00 - val_loss: 108.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.8445 - accuracy: 0.0000e+00 - val_loss: 100.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.8861 - accuracy: 0.0312 - val_loss: 94.7652 - val_accuracy: 0.0588\n",
      "Epoch 231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.6268 - accuracy: 0.0000e+00 - val_loss: 94.9179 - val_accuracy: 0.0588\n",
      "Epoch 232/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 113.4374 - accuracy: 0.0000e+00 - val_loss: 98.9667 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 130.8697 - accuracy: 0.0000e+00 - val_loss: 102.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.0747 - accuracy: 0.0000e+00 - val_loss: 106.8406 - val_accuracy: 0.0588\n",
      "Epoch 235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.3734 - accuracy: 0.0000e+00 - val_loss: 106.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.8739 - accuracy: 0.0156 - val_loss: 104.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.9640 - accuracy: 0.0000e+00 - val_loss: 97.9894 - val_accuracy: 0.0588\n",
      "Epoch 238/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.4768 - accuracy: 0.0000e+00 - val_loss: 94.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.7573 - accuracy: 0.0000e+00 - val_loss: 98.5964 - val_accuracy: 0.0588\n",
      "Epoch 240/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.5485 - accuracy: 0.0000e+00 - val_loss: 105.6901 - val_accuracy: 0.0588\n",
      "Epoch 241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 125.9917 - accuracy: 0.0000e+00 - val_loss: 109.6110 - val_accuracy: 0.0588\n",
      "Epoch 242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.3168 - accuracy: 0.0000e+00 - val_loss: 114.4814 - val_accuracy: 0.0588\n",
      "Epoch 243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.8329 - accuracy: 0.0000e+00 - val_loss: 108.6885 - val_accuracy: 0.0588\n",
      "Epoch 244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.9922 - accuracy: 0.0156 - val_loss: 96.8548 - val_accuracy: 0.0588\n",
      "Epoch 245/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.1671 - accuracy: 0.0000e+00 - val_loss: 91.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.6872 - accuracy: 0.0000e+00 - val_loss: 95.3283 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.3609 - accuracy: 0.0000e+00 - val_loss: 100.0944 - val_accuracy: 0.0588\n",
      "Epoch 248/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.9677 - accuracy: 0.0469 - val_loss: 107.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.7987 - accuracy: 0.0000e+00 - val_loss: 110.9006 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 119.9479 - accuracy: 0.0000e+00 - val_loss: 103.7780 - val_accuracy: 0.0588\n",
      "Epoch 251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.8595 - accuracy: 0.0000e+00 - val_loss: 101.3351 - val_accuracy: 0.0588\n",
      "Epoch 252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.0036 - accuracy: 0.0156 - val_loss: 97.2887 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.4315 - accuracy: 0.0000e+00 - val_loss: 91.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 134.1394 - accuracy: 0.0000e+00 - val_loss: 89.8328 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 99.6643 - accuracy: 0.0156 - val_loss: 96.8473 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.6935 - accuracy: 0.0000e+00 - val_loss: 102.5279 - val_accuracy: 0.0588\n",
      "Epoch 257/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.1677 - accuracy: 0.0000e+00 - val_loss: 104.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.7711 - accuracy: 0.0000e+00 - val_loss: 100.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.2402 - accuracy: 0.0156 - val_loss: 100.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.8149 - accuracy: 0.0000e+00 - val_loss: 100.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.8428 - accuracy: 0.0000e+00 - val_loss: 99.8558 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4534 - accuracy: 0.0000e+00 - val_loss: 106.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.3966 - accuracy: 0.0000e+00 - val_loss: 108.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.6927 - accuracy: 0.0156 - val_loss: 111.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 111.8311 - accuracy: 0.0156 - val_loss: 102.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.9629 - accuracy: 0.0156 - val_loss: 94.2159 - val_accuracy: 0.0588\n",
      "Epoch 267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.6645 - accuracy: 0.0000e+00 - val_loss: 88.9603 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 110.4884 - accuracy: 0.0312 - val_loss: 92.0392 - val_accuracy: 0.0588\n",
      "Epoch 269/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.4273 - accuracy: 0.0000e+00 - val_loss: 92.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.7567 - accuracy: 0.0000e+00 - val_loss: 94.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.8061 - accuracy: 0.0000e+00 - val_loss: 101.6894 - val_accuracy: 0.0588\n",
      "Epoch 272/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1069 - accuracy: 0.0000e+00 - val_loss: 114.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.8672 - accuracy: 0.0000e+00 - val_loss: 116.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 129.5299 - accuracy: 0.0000e+00 - val_loss: 99.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.3699 - accuracy: 0.0156 - val_loss: 90.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.4674 - accuracy: 0.0000e+00 - val_loss: 85.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.1128 - accuracy: 0.0000e+00 - val_loss: 86.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.5016 - accuracy: 0.0156 - val_loss: 93.4024 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.4966 - accuracy: 0.0156 - val_loss: 100.5123 - val_accuracy: 0.0588\n",
      "Epoch 280/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.9574 - accuracy: 0.0000e+00 - val_loss: 102.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 93.0762 - accuracy: 0.0000e+00 - val_loss: 99.7115 - val_accuracy: 0.0588\n",
      "Epoch 282/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 85.8949 - accuracy: 0.0156 - val_loss: 98.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.6751 - accuracy: 0.0000e+00 - val_loss: 103.5083 - val_accuracy: 0.0588\n",
      "Epoch 284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.8426 - accuracy: 0.0000e+00 - val_loss: 107.0803 - val_accuracy: 0.0588\n",
      "Epoch 285/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 118.8223 - accuracy: 0.0000e+00 - val_loss: 105.2366 - val_accuracy: 0.0588\n",
      "Epoch 286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.8358 - accuracy: 0.0000e+00 - val_loss: 103.8737 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.0888 - accuracy: 0.0156 - val_loss: 104.8745 - val_accuracy: 0.0588\n",
      "Epoch 288/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 106.3634 - accuracy: 0.0000e+00 - val_loss: 102.9231 - val_accuracy: 0.1176\n",
      "Epoch 289/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.7796 - accuracy: 0.0000e+00 - val_loss: 95.6854 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.4865 - accuracy: 0.0000e+00 - val_loss: 94.5033 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.3967 - accuracy: 0.0000e+00 - val_loss: 105.4209 - val_accuracy: 0.1176\n",
      "Epoch 292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.0377 - accuracy: 0.0000e+00 - val_loss: 113.1493 - val_accuracy: 0.0588\n",
      "Epoch 293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.7438 - accuracy: 0.0156 - val_loss: 111.0640 - val_accuracy: 0.0588\n",
      "Epoch 294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.6250 - accuracy: 0.0000e+00 - val_loss: 105.2549 - val_accuracy: 0.0588\n",
      "Epoch 295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.8411 - accuracy: 0.0156 - val_loss: 97.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.8214 - accuracy: 0.0000e+00 - val_loss: 96.7206 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6435 - accuracy: 0.0000e+00 - val_loss: 98.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.4060 - accuracy: 0.0000e+00 - val_loss: 100.3378 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.1560 - accuracy: 0.0000e+00 - val_loss: 107.1931 - val_accuracy: 0.0588\n",
      "Epoch 300/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.2129 - accuracy: 0.0000e+00 - val_loss: 116.3856 - val_accuracy: 0.0588\n",
      "Epoch 301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0376 - accuracy: 0.0469 - val_loss: 116.5196 - val_accuracy: 0.0588\n",
      "Epoch 302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.8815 - accuracy: 0.0156 - val_loss: 107.2790 - val_accuracy: 0.0588\n",
      "Epoch 303/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 85.1174 - accuracy: 0.0000e+00 - val_loss: 100.3736 - val_accuracy: 0.1176\n",
      "Epoch 304/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.4343 - accuracy: 0.0000e+00 - val_loss: 93.1719 - val_accuracy: 0.0588\n",
      "Epoch 305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.3857 - accuracy: 0.0000e+00 - val_loss: 87.4255 - val_accuracy: 0.0588\n",
      "Epoch 306/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.1350 - accuracy: 0.0312 - val_loss: 86.1900 - val_accuracy: 0.0588\n",
      "Epoch 307/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.2286 - accuracy: 0.0000e+00 - val_loss: 86.6234 - val_accuracy: 0.0588\n",
      "Epoch 308/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 66.9708 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 106.9388 - accuracy: 0.0000e+00 - val_loss: 89.2942 - val_accuracy: 0.0588\n",
      "Epoch 309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.1429 - accuracy: 0.0000e+00 - val_loss: 97.1006 - val_accuracy: 0.1176\n",
      "Epoch 310/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4550 - accuracy: 0.0312 - val_loss: 106.9123 - val_accuracy: 0.0588\n",
      "Epoch 311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.6462 - accuracy: 0.0000e+00 - val_loss: 104.7097 - val_accuracy: 0.0588\n",
      "Epoch 312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.0392 - accuracy: 0.0000e+00 - val_loss: 102.6634 - val_accuracy: 0.1176\n",
      "Epoch 313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.4925 - accuracy: 0.0000e+00 - val_loss: 97.9159 - val_accuracy: 0.0588\n",
      "Epoch 314/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.2809 - accuracy: 0.0000e+00 - val_loss: 93.0219 - val_accuracy: 0.0588\n",
      "Epoch 315/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.4473 - accuracy: 0.0000e+00 - val_loss: 89.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.5992 - accuracy: 0.0000e+00 - val_loss: 95.4519 - val_accuracy: 0.0588\n",
      "Epoch 317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4593 - accuracy: 0.0000e+00 - val_loss: 95.0179 - val_accuracy: 0.0588\n",
      "Epoch 318/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 121.9485 - accuracy: 0.0000e+00 - val_loss: 101.1753 - val_accuracy: 0.0588\n",
      "Epoch 319/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.9441 - accuracy: 0.0000e+00 - val_loss: 105.7359 - val_accuracy: 0.0588\n",
      "Epoch 320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1934 - accuracy: 0.0000e+00 - val_loss: 101.0880 - val_accuracy: 0.0588\n",
      "Epoch 321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 119.3930 - accuracy: 0.0000e+00 - val_loss: 92.5855 - val_accuracy: 0.0588\n",
      "Epoch 322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.9269 - accuracy: 0.0000e+00 - val_loss: 89.0226 - val_accuracy: 0.0588\n",
      "Epoch 323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.8394 - accuracy: 0.0000e+00 - val_loss: 93.7038 - val_accuracy: 0.0588\n",
      "Epoch 324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.9217 - accuracy: 0.0000e+00 - val_loss: 101.0674 - val_accuracy: 0.0588\n",
      "Epoch 325/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.4809 - accuracy: 0.0000e+00 - val_loss: 104.2927 - val_accuracy: 0.0588\n",
      "Epoch 326/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.7246 - accuracy: 0.0000e+00 - val_loss: 103.1698 - val_accuracy: 0.0588\n",
      "Epoch 327/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 107.5280 - accuracy: 0.0000e+00 - val_loss: 99.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.4291 - accuracy: 0.0000e+00 - val_loss: 97.1858 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5582 - accuracy: 0.0156 - val_loss: 98.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.3779 - accuracy: 0.0000e+00 - val_loss: 97.7955 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0440 - accuracy: 0.0000e+00 - val_loss: 97.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.0903 - accuracy: 0.0000e+00 - val_loss: 95.8167 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.3339 - accuracy: 0.0000e+00 - val_loss: 96.5624 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.6995 - accuracy: 0.0000e+00 - val_loss: 102.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.3850 - accuracy: 0.0000e+00 - val_loss: 113.5541 - val_accuracy: 0.0588\n",
      "Epoch 336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5649 - accuracy: 0.0000e+00 - val_loss: 119.0588 - val_accuracy: 0.0588\n",
      "Epoch 337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.2573 - accuracy: 0.0000e+00 - val_loss: 112.6940 - val_accuracy: 0.1176\n",
      "Epoch 338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.1340 - accuracy: 0.0000e+00 - val_loss: 101.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.9614 - accuracy: 0.0000e+00 - val_loss: 88.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.8688 - accuracy: 0.0000e+00 - val_loss: 83.9405 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7872 - accuracy: 0.0000e+00 - val_loss: 89.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.4395 - accuracy: 0.0000e+00 - val_loss: 102.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.9139 - accuracy: 0.0156 - val_loss: 115.2095 - val_accuracy: 0.0588\n",
      "Epoch 344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.9786 - accuracy: 0.0000e+00 - val_loss: 114.6668 - val_accuracy: 0.0588\n",
      "Epoch 345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 101.6278 - accuracy: 0.0156 - val_loss: 101.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.1412 - accuracy: 0.0000e+00 - val_loss: 90.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.1814 - accuracy: 0.0000e+00 - val_loss: 90.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.5473 - accuracy: 0.0156 - val_loss: 96.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 97.2911 - accuracy: 0.0000e+00 - val_loss: 102.2145 - val_accuracy: 0.0588\n",
      "Epoch 350/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.3358 - accuracy: 0.0312 - val_loss: 105.9345 - val_accuracy: 0.0588\n",
      "Epoch 351/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 87.2983 - accuracy: 0.0000e+00 - val_loss: 105.8435 - val_accuracy: 0.0588\n",
      "Epoch 352/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 101.9084 - accuracy: 0.0000e+00 - val_loss: 98.9948 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3965 - accuracy: 0.0156 - val_loss: 93.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0348 - accuracy: 0.0000e+00 - val_loss: 96.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.9720 - accuracy: 0.0000e+00 - val_loss: 104.1754 - val_accuracy: 0.0588\n",
      "Epoch 356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.8068 - accuracy: 0.0000e+00 - val_loss: 102.8825 - val_accuracy: 0.0588\n",
      "Epoch 357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.1081 - accuracy: 0.0000e+00 - val_loss: 93.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.4866 - accuracy: 0.0156 - val_loss: 96.1037 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.3273 - accuracy: 0.0000e+00 - val_loss: 100.3488 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.0097 - accuracy: 0.0000e+00 - val_loss: 103.3388 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1317 - accuracy: 0.0000e+00 - val_loss: 98.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.4489 - accuracy: 0.0000e+00 - val_loss: 94.7724 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.1170 - accuracy: 0.0000e+00 - val_loss: 94.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 118.4706 - accuracy: 0.0000e+00 - val_loss: 95.4854 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.9878 - accuracy: 0.0000e+00 - val_loss: 96.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.7897 - accuracy: 0.0000e+00 - val_loss: 97.8365 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.4964 - accuracy: 0.0000e+00 - val_loss: 95.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 121.0691 - accuracy: 0.0000e+00 - val_loss: 100.9794 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9542 - accuracy: 0.0156 - val_loss: 107.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9391 - accuracy: 0.0000e+00 - val_loss: 105.8027 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.1508 - accuracy: 0.0000e+00 - val_loss: 100.6825 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.6349 - accuracy: 0.0000e+00 - val_loss: 94.6353 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5249 - accuracy: 0.0156 - val_loss: 90.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.5905 - accuracy: 0.0156 - val_loss: 96.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.5214 - accuracy: 0.0000e+00 - val_loss: 101.4064 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.4019 - accuracy: 0.0000e+00 - val_loss: 107.7156 - val_accuracy: 0.0588\n",
      "Epoch 377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.0806 - accuracy: 0.0156 - val_loss: 110.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.7549 - accuracy: 0.0312 - val_loss: 105.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.0675 - accuracy: 0.0000e+00 - val_loss: 99.9443 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.9889 - accuracy: 0.0000e+00 - val_loss: 99.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.5414 - accuracy: 0.0000e+00 - val_loss: 102.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.4270 - accuracy: 0.0156 - val_loss: 108.0455 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.7176 - accuracy: 0.0000e+00 - val_loss: 114.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2157 - accuracy: 0.0000e+00 - val_loss: 118.9841 - val_accuracy: 0.0588\n",
      "Epoch 385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.2822 - accuracy: 0.0000e+00 - val_loss: 110.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.2827 - accuracy: 0.0156 - val_loss: 98.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.9357 - accuracy: 0.0000e+00 - val_loss: 91.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1381 - accuracy: 0.0000e+00 - val_loss: 92.7707 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.2133 - accuracy: 0.0000e+00 - val_loss: 102.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1913 - accuracy: 0.0156 - val_loss: 108.1537 - val_accuracy: 0.0588\n",
      "Epoch 391/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.1478 - accuracy: 0.0312 - val_loss: 106.4983 - val_accuracy: 0.0588\n",
      "Epoch 392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.8614 - accuracy: 0.0000e+00 - val_loss: 102.3817 - val_accuracy: 0.0588\n",
      "Epoch 393/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.1058 - accuracy: 0.0000e+00 - val_loss: 96.1927 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0531 - accuracy: 0.0312 - val_loss: 88.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.8293 - accuracy: 0.0000e+00 - val_loss: 88.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.1947 - accuracy: 0.0000e+00 - val_loss: 91.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.0539 - accuracy: 0.0000e+00 - val_loss: 99.5058 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.3972 - accuracy: 0.0312 - val_loss: 106.4376 - val_accuracy: 0.0588\n",
      "Epoch 399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.3148 - accuracy: 0.0000e+00 - val_loss: 109.5307 - val_accuracy: 0.0588\n",
      "Epoch 400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.8643 - accuracy: 0.0156 - val_loss: 108.6847 - val_accuracy: 0.0588\n",
      "Epoch 401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.5593 - accuracy: 0.0000e+00 - val_loss: 100.5564 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.6717 - accuracy: 0.0000e+00 - val_loss: 90.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0893 - accuracy: 0.0000e+00 - val_loss: 83.0851 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 149.3524 - accuracy: 0.0000e+00 - val_loss: 86.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.9447 - accuracy: 0.0000e+00 - val_loss: 96.3531 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.0076 - accuracy: 0.0000e+00 - val_loss: 105.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.6981 - accuracy: 0.0156 - val_loss: 104.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.8989 - accuracy: 0.0000e+00 - val_loss: 110.1064 - val_accuracy: 0.0588\n",
      "Epoch 409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.8239 - accuracy: 0.0000e+00 - val_loss: 102.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.3580 - accuracy: 0.0000e+00 - val_loss: 98.6050 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6419 - accuracy: 0.0000e+00 - val_loss: 94.7609 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.3177 - accuracy: 0.0000e+00 - val_loss: 88.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.1798 - accuracy: 0.0000e+00 - val_loss: 95.2638 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.8759 - accuracy: 0.0156 - val_loss: 110.6747 - val_accuracy: 0.0588\n",
      "Epoch 415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.8944 - accuracy: 0.0000e+00 - val_loss: 112.2980 - val_accuracy: 0.0588\n",
      "Epoch 416/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.3970 - accuracy: 0.0000e+00 - val_loss: 102.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.3350 - accuracy: 0.0000e+00 - val_loss: 90.3576 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.0271 - accuracy: 0.0000e+00 - val_loss: 89.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.5609 - accuracy: 0.0156 - val_loss: 90.6043 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7626 - accuracy: 0.0000e+00 - val_loss: 93.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.6778 - accuracy: 0.0000e+00 - val_loss: 88.6712 - val_accuracy: 0.0588\n",
      "Epoch 422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.6543 - accuracy: 0.0000e+00 - val_loss: 80.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.6116 - accuracy: 0.0000e+00 - val_loss: 82.6286 - val_accuracy: 0.0588\n",
      "Epoch 424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.7960 - accuracy: 0.0000e+00 - val_loss: 86.6037 - val_accuracy: 0.0588\n",
      "Epoch 425/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.9596 - accuracy: 0.0000e+00 - val_loss: 90.7660 - val_accuracy: 0.0588\n",
      "Epoch 426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.4355 - accuracy: 0.0000e+00 - val_loss: 103.9383 - val_accuracy: 0.0588\n",
      "Epoch 427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1594 - accuracy: 0.0000e+00 - val_loss: 107.7349 - val_accuracy: 0.0588\n",
      "Epoch 428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8230 - accuracy: 0.0000e+00 - val_loss: 108.9735 - val_accuracy: 0.0588\n",
      "Epoch 429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 85.9071 - accuracy: 0.0000e+00 - val_loss: 103.7849 - val_accuracy: 0.0588\n",
      "Epoch 430/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.7514 - accuracy: 0.0156 - val_loss: 94.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.8796 - accuracy: 0.0000e+00 - val_loss: 82.5222 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1242 - accuracy: 0.0000e+00 - val_loss: 82.8449 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2938 - accuracy: 0.0000e+00 - val_loss: 87.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.3492 - accuracy: 0.0000e+00 - val_loss: 98.3431 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4459 - accuracy: 0.0156 - val_loss: 105.4842 - val_accuracy: 0.0588\n",
      "Epoch 436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.0038 - accuracy: 0.0312 - val_loss: 107.4186 - val_accuracy: 0.0588\n",
      "Epoch 437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.8337 - accuracy: 0.0000e+00 - val_loss: 106.5220 - val_accuracy: 0.0588\n",
      "Epoch 438/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.4239 - accuracy: 0.0000e+00 - val_loss: 97.5426 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.2088 - accuracy: 0.0156 - val_loss: 87.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.5145 - accuracy: 0.0000e+00 - val_loss: 87.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.0136 - accuracy: 0.0000e+00 - val_loss: 93.2304 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.6534 - accuracy: 0.0156 - val_loss: 99.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.7219 - accuracy: 0.0000e+00 - val_loss: 103.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.3280 - accuracy: 0.0000e+00 - val_loss: 102.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.9420 - accuracy: 0.0000e+00 - val_loss: 97.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.4067 - accuracy: 0.0000e+00 - val_loss: 93.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.9980 - accuracy: 0.0000e+00 - val_loss: 87.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.4426 - accuracy: 0.0000e+00 - val_loss: 94.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.5976 - accuracy: 0.0000e+00 - val_loss: 114.7637 - val_accuracy: 0.0588\n",
      "Epoch 450/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.0602 - accuracy: 0.0156 - val_loss: 111.6577 - val_accuracy: 0.0588\n",
      "Epoch 451/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2468 - accuracy: 0.0000e+00 - val_loss: 99.9349 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.3709 - accuracy: 0.0000e+00 - val_loss: 85.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 102.7358 - accuracy: 0.0000e+00 - val_loss: 75.7740 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.1405 - accuracy: 0.0000e+00 - val_loss: 78.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3099 - accuracy: 0.0000e+00 - val_loss: 90.9544 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.7671 - accuracy: 0.0000e+00 - val_loss: 106.2811 - val_accuracy: 0.0588\n",
      "Epoch 457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.0391 - accuracy: 0.0000e+00 - val_loss: 115.6346 - val_accuracy: 0.0588\n",
      "Epoch 458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.2144 - accuracy: 0.0000e+00 - val_loss: 110.0830 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.4906 - accuracy: 0.0000e+00 - val_loss: 99.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.8363 - accuracy: 0.0156 - val_loss: 88.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.0819 - accuracy: 0.0000e+00 - val_loss: 85.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.0409 - accuracy: 0.0000e+00 - val_loss: 91.6070 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.2861 - accuracy: 0.0000e+00 - val_loss: 104.7698 - val_accuracy: 0.0588\n",
      "Epoch 464/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.5714 - accuracy: 0.0000e+00 - val_loss: 109.4923 - val_accuracy: 0.0588\n",
      "Epoch 465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.2240 - accuracy: 0.0000e+00 - val_loss: 103.5889 - val_accuracy: 0.0588\n",
      "Epoch 466/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 80.8674 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 103.3034 - accuracy: 0.0000e+00 - val_loss: 94.2656 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.9898 - accuracy: 0.0000e+00 - val_loss: 84.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1101 - accuracy: 0.0156 - val_loss: 83.3144 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 108.1273 - accuracy: 0.0000e+00 - val_loss: 85.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 87.0556 - accuracy: 0.0000e+00 - val_loss: 96.0717 - val_accuracy: 0.0588\n",
      "Epoch 471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 86.3035 - accuracy: 0.0000e+00 - val_loss: 106.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8652 - accuracy: 0.0000e+00 - val_loss: 111.4135 - val_accuracy: 0.0588\n",
      "Epoch 473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3188 - accuracy: 0.0156 - val_loss: 103.7553 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.8447 - accuracy: 0.0156 - val_loss: 92.6031 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.4036 - accuracy: 0.0000e+00 - val_loss: 89.3469 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.2942 - accuracy: 0.0000e+00 - val_loss: 85.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.2228 - accuracy: 0.0156 - val_loss: 86.8489 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 101.0983 - accuracy: 0.0000e+00 - val_loss: 92.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.1335 - accuracy: 0.0000e+00 - val_loss: 91.3299 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4157 - accuracy: 0.0312 - val_loss: 92.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.3203 - accuracy: 0.0000e+00 - val_loss: 99.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 76.6590 - accuracy: 0.0000e+00 - val_loss: 101.8712 - val_accuracy: 0.0588\n",
      "Epoch 483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.4034 - accuracy: 0.0000e+00 - val_loss: 101.6246 - val_accuracy: 0.0588\n",
      "Epoch 484/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.0542 - accuracy: 0.0000e+00 - val_loss: 98.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.9302 - accuracy: 0.0000e+00 - val_loss: 90.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.0947 - accuracy: 0.0000e+00 - val_loss: 84.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.6717 - accuracy: 0.0000e+00 - val_loss: 81.0594 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.8445 - accuracy: 0.0000e+00 - val_loss: 89.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.7464 - accuracy: 0.0000e+00 - val_loss: 107.6835 - val_accuracy: 0.0588\n",
      "Epoch 490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.0747 - accuracy: 0.0000e+00 - val_loss: 114.5082 - val_accuracy: 0.0588\n",
      "Epoch 491/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 92.8695 - accuracy: 0.0000e+00 - val_loss: 104.4609 - val_accuracy: 0.0588\n",
      "Epoch 492/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.6299 - accuracy: 0.0000e+00 - val_loss: 90.3733 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.8307 - accuracy: 0.0000e+00 - val_loss: 82.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1717 - accuracy: 0.0000e+00 - val_loss: 83.7354 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8930 - accuracy: 0.0000e+00 - val_loss: 90.2950 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5622 - accuracy: 0.0000e+00 - val_loss: 97.0154 - val_accuracy: 0.1176\n",
      "Epoch 497/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1225 - accuracy: 0.0000e+00 - val_loss: 98.5227 - val_accuracy: 0.1176\n",
      "Epoch 498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4968 - accuracy: 0.0312 - val_loss: 92.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.0571 - accuracy: 0.0000e+00 - val_loss: 93.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.3945 - accuracy: 0.0156 - val_loss: 93.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.5666 - accuracy: 0.0000e+00 - val_loss: 97.9770 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.5531 - accuracy: 0.0156 - val_loss: 98.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.2721 - accuracy: 0.0000e+00 - val_loss: 100.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 94.8595 - accuracy: 0.0000e+00 - val_loss: 97.2317 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.0490 - accuracy: 0.0000e+00 - val_loss: 100.6555 - val_accuracy: 0.0588\n",
      "Epoch 506/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.1607 - accuracy: 0.0156 - val_loss: 92.7270 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.1622 - accuracy: 0.0000e+00 - val_loss: 87.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 102.8480 - accuracy: 0.0156 - val_loss: 91.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.9334 - accuracy: 0.0000e+00 - val_loss: 92.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.7803 - accuracy: 0.0000e+00 - val_loss: 97.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5775 - accuracy: 0.0000e+00 - val_loss: 102.8419 - val_accuracy: 0.0588\n",
      "Epoch 512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.2442 - accuracy: 0.0156 - val_loss: 98.2354 - val_accuracy: 0.0588\n",
      "Epoch 513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3147 - accuracy: 0.0000e+00 - val_loss: 94.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 94.2236 - accuracy: 0.0312 - val_loss: 98.8048 - val_accuracy: 0.0588\n",
      "Epoch 515/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2980 - accuracy: 0.0156 - val_loss: 99.1891 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.2867 - accuracy: 0.0156 - val_loss: 94.0281 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9354 - accuracy: 0.0156 - val_loss: 87.6063 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.2452 - accuracy: 0.0000e+00 - val_loss: 80.4842 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2174 - accuracy: 0.0156 - val_loss: 80.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1960 - accuracy: 0.0000e+00 - val_loss: 87.9981 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.2042 - accuracy: 0.0156 - val_loss: 98.2087 - val_accuracy: 0.1176\n",
      "Epoch 522/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 74.5718 - accuracy: 0.0000e+00 - val_loss: 102.0065 - val_accuracy: 0.0588\n",
      "Epoch 523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.1666 - accuracy: 0.0000e+00 - val_loss: 102.4148 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 120.2487 - accuracy: 0.0156 - val_loss: 103.3898 - val_accuracy: 0.0588\n",
      "Epoch 525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.6894 - accuracy: 0.0000e+00 - val_loss: 102.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6578 - accuracy: 0.0000e+00 - val_loss: 92.3634 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.3423 - accuracy: 0.0000e+00 - val_loss: 86.1897 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.8764 - accuracy: 0.0000e+00 - val_loss: 81.8870 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.7408 - accuracy: 0.0000e+00 - val_loss: 92.7986 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.9982 - accuracy: 0.0000e+00 - val_loss: 113.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.0709 - accuracy: 0.0000e+00 - val_loss: 120.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5803 - accuracy: 0.0000e+00 - val_loss: 110.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 96.4958 - accuracy: 0.0000e+00 - val_loss: 99.7906 - val_accuracy: 0.0588\n",
      "Epoch 534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.7730 - accuracy: 0.0000e+00 - val_loss: 86.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.7437 - accuracy: 0.0000e+00 - val_loss: 78.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.1724 - accuracy: 0.0000e+00 - val_loss: 74.6493 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1907 - accuracy: 0.0000e+00 - val_loss: 81.7761 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2867 - accuracy: 0.0156 - val_loss: 101.8510 - val_accuracy: 0.0588\n",
      "Epoch 539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.9184 - accuracy: 0.0000e+00 - val_loss: 117.8388 - val_accuracy: 0.0588\n",
      "Epoch 540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7964 - accuracy: 0.0000e+00 - val_loss: 118.9003 - val_accuracy: 0.0588\n",
      "Epoch 541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.1350 - accuracy: 0.0000e+00 - val_loss: 104.4429 - val_accuracy: 0.0588\n",
      "Epoch 542/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 79.0658 - accuracy: 0.0000e+00 - val_loss: 89.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.6994 - accuracy: 0.0000e+00 - val_loss: 78.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.0951 - accuracy: 0.0000e+00 - val_loss: 80.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.6627 - accuracy: 0.0000e+00 - val_loss: 93.0401 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.0687 - accuracy: 0.0000e+00 - val_loss: 108.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.0341 - accuracy: 0.0000e+00 - val_loss: 117.9037 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.4128 - accuracy: 0.0156 - val_loss: 109.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.2821 - accuracy: 0.0156 - val_loss: 91.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9104 - accuracy: 0.0156 - val_loss: 77.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1529 - accuracy: 0.0156 - val_loss: 76.6552 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1767 - accuracy: 0.0000e+00 - val_loss: 86.5749 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 146.4702 - accuracy: 0.03 - 0s 125us/step - loss: 107.5238 - accuracy: 0.0156 - val_loss: 98.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.7736 - accuracy: 0.0156 - val_loss: 107.8889 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8367 - accuracy: 0.0156 - val_loss: 110.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7502 - accuracy: 0.0156 - val_loss: 99.2730 - val_accuracy: 0.0588\n",
      "Epoch 557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1432 - accuracy: 0.0000e+00 - val_loss: 84.9471 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.0087 - accuracy: 0.0000e+00 - val_loss: 78.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.6155 - accuracy: 0.0000e+00 - val_loss: 78.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.4474 - accuracy: 0.0000e+00 - val_loss: 79.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.0540 - accuracy: 0.0000e+00 - val_loss: 82.8537 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 130.6043 - accuracy: 0.0000e+00 - val_loss: 90.8324 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.1811 - accuracy: 0.0156 - val_loss: 90.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1942 - accuracy: 0.0156 - val_loss: 93.7903 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.0975 - accuracy: 0.0000e+00 - val_loss: 93.0263 - val_accuracy: 0.0588\n",
      "Epoch 566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5567 - accuracy: 0.0000e+00 - val_loss: 89.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.3668 - accuracy: 0.0156 - val_loss: 92.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7803 - accuracy: 0.0000e+00 - val_loss: 94.0660 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5521 - accuracy: 0.0000e+00 - val_loss: 89.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5313 - accuracy: 0.0000e+00 - val_loss: 87.6863 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.4861 - accuracy: 0.0156 - val_loss: 87.0284 - val_accuracy: 0.0588\n",
      "Epoch 572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.1995 - accuracy: 0.0000e+00 - val_loss: 96.2818 - val_accuracy: 0.1176\n",
      "Epoch 573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.6928 - accuracy: 0.0000e+00 - val_loss: 99.4517 - val_accuracy: 0.1176\n",
      "Epoch 574/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.6113 - accuracy: 0.0000e+00 - val_loss: 89.3144 - val_accuracy: 0.0588\n",
      "Epoch 575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.5279 - accuracy: 0.0000e+00 - val_loss: 75.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9480 - accuracy: 0.0000e+00 - val_loss: 74.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4657 - accuracy: 0.0000e+00 - val_loss: 79.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.9294 - accuracy: 0.0000e+00 - val_loss: 86.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.0321 - accuracy: 0.0000e+00 - val_loss: 94.9470 - val_accuracy: 0.0588\n",
      "Epoch 580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.2225 - accuracy: 0.0156 - val_loss: 105.1113 - val_accuracy: 0.0588\n",
      "Epoch 581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.7499 - accuracy: 0.0156 - val_loss: 107.7531 - val_accuracy: 0.0588\n",
      "Epoch 582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.8116 - accuracy: 0.0000e+00 - val_loss: 101.2485 - val_accuracy: 0.1176\n",
      "Epoch 583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6185 - accuracy: 0.0156 - val_loss: 97.3910 - val_accuracy: 0.0588\n",
      "Epoch 584/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 69.7025 - accuracy: 0.0000e+00 - val_loss: 90.8655 - val_accuracy: 0.0588\n",
      "Epoch 585/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.5880 - accuracy: 0.0000e+00 - val_loss: 91.7124 - val_accuracy: 0.0588\n",
      "Epoch 586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.7900 - accuracy: 0.0000e+00 - val_loss: 100.2474 - val_accuracy: 0.0588\n",
      "Epoch 587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1872 - accuracy: 0.0000e+00 - val_loss: 99.0997 - val_accuracy: 0.0588\n",
      "Epoch 588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8692 - accuracy: 0.0000e+00 - val_loss: 95.5681 - val_accuracy: 0.0588\n",
      "Epoch 589/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 83.2669 - accuracy: 0.0000e+00 - val_loss: 83.7981 - val_accuracy: 0.0588\n",
      "Epoch 590/10000\n",
      "64/64 [==============================] - 0s 562us/step - loss: 77.1190 - accuracy: 0.0000e+00 - val_loss: 76.2694 - val_accuracy: 0.0588\n",
      "Epoch 591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1762 - accuracy: 0.0000e+00 - val_loss: 76.7394 - val_accuracy: 0.0588\n",
      "Epoch 592/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.5170 - accuracy: 0.0000e+00 - val_loss: 77.8290 - val_accuracy: 0.0588\n",
      "Epoch 593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6601 - accuracy: 0.0000e+00 - val_loss: 91.7142 - val_accuracy: 0.0588\n",
      "Epoch 594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.0276 - accuracy: 0.0000e+00 - val_loss: 115.4722 - val_accuracy: 0.0588\n",
      "Epoch 595/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.7159 - accuracy: 0.0156 - val_loss: 122.5612 - val_accuracy: 0.1176\n",
      "Epoch 596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1852 - accuracy: 0.0000e+00 - val_loss: 111.4176 - val_accuracy: 0.0588\n",
      "Epoch 597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.1537 - accuracy: 0.0000e+00 - val_loss: 93.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.4957 - accuracy: 0.0000e+00 - val_loss: 85.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.9351 - accuracy: 0.031 - 0s 125us/step - loss: 65.2672 - accuracy: 0.0156 - val_loss: 80.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.2039 - accuracy: 0.0156 - val_loss: 79.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.1147 - accuracy: 0.0000e+00 - val_loss: 85.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.1198 - accuracy: 0.0156 - val_loss: 100.5730 - val_accuracy: 0.0588\n",
      "Epoch 603/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.0405 - accuracy: 0.0000e+00 - val_loss: 107.4209 - val_accuracy: 0.0588\n",
      "Epoch 604/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.3175 - accuracy: 0.0156 - val_loss: 103.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.0979 - accuracy: 0.0000e+00 - val_loss: 98.7084 - val_accuracy: 0.0588\n",
      "Epoch 606/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.9224 - accuracy: 0.0000e+00 - val_loss: 97.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.6311 - accuracy: 0.0000e+00 - val_loss: 90.4057 - val_accuracy: 0.0588\n",
      "Epoch 608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.8316 - accuracy: 0.0000e+00 - val_loss: 87.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.0016 - accuracy: 0.0000e+00 - val_loss: 83.9240 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5411 - accuracy: 0.0000e+00 - val_loss: 84.1563 - val_accuracy: 0.0588\n",
      "Epoch 611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7883 - accuracy: 0.0000e+00 - val_loss: 89.3763 - val_accuracy: 0.1176\n",
      "Epoch 612/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.5107 - accuracy: 0.0000e+00 - val_loss: 90.0771 - val_accuracy: 0.0588\n",
      "Epoch 613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8371 - accuracy: 0.0000e+00 - val_loss: 85.7784 - val_accuracy: 0.0588\n",
      "Epoch 614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2205 - accuracy: 0.0000e+00 - val_loss: 79.7275 - val_accuracy: 0.0588\n",
      "Epoch 615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0507 - accuracy: 0.0000e+00 - val_loss: 80.9971 - val_accuracy: 0.0588\n",
      "Epoch 616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3793 - accuracy: 0.0000e+00 - val_loss: 85.2482 - val_accuracy: 0.0588\n",
      "Epoch 617/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.4485 - accuracy: 0.0000e+00 - val_loss: 95.4915 - val_accuracy: 0.0588\n",
      "Epoch 618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0994 - accuracy: 0.0000e+00 - val_loss: 105.6877 - val_accuracy: 0.1176\n",
      "Epoch 619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5345 - accuracy: 0.0156 - val_loss: 109.9327 - val_accuracy: 0.1176\n",
      "Epoch 620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7995 - accuracy: 0.0000e+00 - val_loss: 96.8790 - val_accuracy: 0.0588\n",
      "Epoch 621/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.4215 - accuracy: 0.0156 - val_loss: 82.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.1895 - accuracy: 0.0000e+00 - val_loss: 75.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0877 - accuracy: 0.0000e+00 - val_loss: 75.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1272 - accuracy: 0.0000e+00 - val_loss: 85.7094 - val_accuracy: 0.0588\n",
      "Epoch 625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5511 - accuracy: 0.0000e+00 - val_loss: 102.2882 - val_accuracy: 0.0588\n",
      "Epoch 626/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 60.1573 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 74.8618 - accuracy: 0.0156 - val_loss: 113.4802 - val_accuracy: 0.0588\n",
      "Epoch 627/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.9480 - accuracy: 0.0000e+00 - val_loss: 103.0058 - val_accuracy: 0.0588\n",
      "Epoch 628/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.1458 - accuracy: 0.0000e+00 - val_loss: 89.3523 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.9817 - accuracy: 0.0156 - val_loss: 80.2573 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2091 - accuracy: 0.0000e+00 - val_loss: 82.8885 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.6840 - accuracy: 0.0156 - val_loss: 87.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.6886 - accuracy: 0.0000e+00 - val_loss: 93.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.5273 - accuracy: 0.0000e+00 - val_loss: 96.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1456 - accuracy: 0.0000e+00 - val_loss: 98.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.0475 - accuracy: 0.0000e+00 - val_loss: 99.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.9355 - accuracy: 0.0000e+00 - val_loss: 95.7678 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5861 - accuracy: 0.0156 - val_loss: 88.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5099 - accuracy: 0.0000e+00 - val_loss: 80.0504 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.6117 - accuracy: 0.0000e+00 - val_loss: 83.3240 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.3652 - accuracy: 0.0156 - val_loss: 93.9959 - val_accuracy: 0.0588\n",
      "Epoch 641/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.6379 - accuracy: 0.0312 - val_loss: 104.7596 - val_accuracy: 0.0588\n",
      "Epoch 642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.6462 - accuracy: 0.0000e+00 - val_loss: 98.8249 - val_accuracy: 0.0588\n",
      "Epoch 643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4493 - accuracy: 0.0000e+00 - val_loss: 90.2327 - val_accuracy: 0.0588\n",
      "Epoch 644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.2507 - accuracy: 0.0000e+00 - val_loss: 88.1547 - val_accuracy: 0.0588\n",
      "Epoch 645/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.5720 - accuracy: 0.0000e+00 - val_loss: 85.9480 - val_accuracy: 0.0588\n",
      "Epoch 646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.4569 - accuracy: 0.0000e+00 - val_loss: 80.5695 - val_accuracy: 0.0588\n",
      "Epoch 647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.1450 - accuracy: 0.0000e+00 - val_loss: 82.8173 - val_accuracy: 0.0588\n",
      "Epoch 648/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 72.2205 - accuracy: 0.0000e+00 - val_loss: 88.5950 - val_accuracy: 0.0588\n",
      "Epoch 649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.1158 - accuracy: 0.0000e+00 - val_loss: 93.8454 - val_accuracy: 0.0588\n",
      "Epoch 650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.8874 - accuracy: 0.0000e+00 - val_loss: 102.6689 - val_accuracy: 0.1176\n",
      "Epoch 651/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.5655 - accuracy: 0.0000e+00 - val_loss: 105.3781 - val_accuracy: 0.1176\n",
      "Epoch 652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.3866 - accuracy: 0.0156 - val_loss: 99.2595 - val_accuracy: 0.0588\n",
      "Epoch 653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1767 - accuracy: 0.0000e+00 - val_loss: 93.3945 - val_accuracy: 0.0588\n",
      "Epoch 654/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.1170 - accuracy: 0.0000e+00 - val_loss: 97.4342 - val_accuracy: 0.0588\n",
      "Epoch 655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5221 - accuracy: 0.0000e+00 - val_loss: 89.1843 - val_accuracy: 0.0588\n",
      "Epoch 656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.0846 - accuracy: 0.0000e+00 - val_loss: 88.0482 - val_accuracy: 0.0588\n",
      "Epoch 657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.7546 - accuracy: 0.0000e+00 - val_loss: 92.3418 - val_accuracy: 0.0588\n",
      "Epoch 658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.6275 - accuracy: 0.0000e+00 - val_loss: 103.3384 - val_accuracy: 0.1765\n",
      "Epoch 659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.6707 - accuracy: 0.0000e+00 - val_loss: 108.3470 - val_accuracy: 0.1765\n",
      "Epoch 660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.7158 - accuracy: 0.0156 - val_loss: 105.5793 - val_accuracy: 0.1765\n",
      "Epoch 661/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1873 - accuracy: 0.0000e+00 - val_loss: 92.3978 - val_accuracy: 0.0588\n",
      "Epoch 662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3111 - accuracy: 0.0156 - val_loss: 79.5756 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.8165 - accuracy: 0.0000e+00 - val_loss: 73.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.6252 - accuracy: 0.0000e+00 - val_loss: 75.8613 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.1831 - accuracy: 0.0000e+00 - val_loss: 90.2206 - val_accuracy: 0.0588\n",
      "Epoch 666/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3755 - accuracy: 0.0000e+00 - val_loss: 105.0446 - val_accuracy: 0.0588\n",
      "Epoch 667/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.0256 - accuracy: 0.0469 - val_loss: 112.0146 - val_accuracy: 0.0588\n",
      "Epoch 668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9531 - accuracy: 0.0000e+00 - val_loss: 104.8267 - val_accuracy: 0.0588\n",
      "Epoch 669/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.8435 - accuracy: 0.0000e+00 - val_loss: 91.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.2611 - accuracy: 0.0000e+00 - val_loss: 81.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3093 - accuracy: 0.0000e+00 - val_loss: 81.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.9247 - accuracy: 0.0000e+00 - val_loss: 96.4955 - val_accuracy: 0.0588\n",
      "Epoch 673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3429 - accuracy: 0.0156 - val_loss: 108.5267 - val_accuracy: 0.0588\n",
      "Epoch 674/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 106.0328 - accuracy: 0.0000e+00 - val_loss: 100.1075 - val_accuracy: 0.1176\n",
      "Epoch 675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6599 - accuracy: 0.0156 - val_loss: 93.0429 - val_accuracy: 0.0588\n",
      "Epoch 676/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.3564 - accuracy: 0.0000e+00 - val_loss: 83.8457 - val_accuracy: 0.0588\n",
      "Epoch 677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1358 - accuracy: 0.0000e+00 - val_loss: 78.2222 - val_accuracy: 0.0588\n",
      "Epoch 678/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.7810 - accuracy: 0.0000e+00 - val_loss: 88.8045 - val_accuracy: 0.1176\n",
      "Epoch 679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.4059 - accuracy: 0.0000e+00 - val_loss: 109.7601 - val_accuracy: 0.1176\n",
      "Epoch 680/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.2034 - accuracy: 0.0000e+00 - val_loss: 112.4618 - val_accuracy: 0.1176\n",
      "Epoch 681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.2127 - accuracy: 0.0000e+00 - val_loss: 97.9312 - val_accuracy: 0.0588\n",
      "Epoch 682/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.8469 - accuracy: 0.0000e+00 - val_loss: 89.7514 - val_accuracy: 0.0588\n",
      "Epoch 683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.2411 - accuracy: 0.0000e+00 - val_loss: 80.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.8719 - accuracy: 0.0000e+00 - val_loss: 81.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1048 - accuracy: 0.0000e+00 - val_loss: 90.7390 - val_accuracy: 0.0588\n",
      "Epoch 686/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 84.5313 - accuracy: 0.0000e+00 - val_loss: 109.8861 - val_accuracy: 0.1176\n",
      "Epoch 687/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1053 - accuracy: 0.0000e+00 - val_loss: 117.1830 - val_accuracy: 0.0588\n",
      "Epoch 688/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.2967 - accuracy: 0.0000e+00 - val_loss: 114.9679 - val_accuracy: 0.0588\n",
      "Epoch 689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5888 - accuracy: 0.0000e+00 - val_loss: 103.0563 - val_accuracy: 0.0588\n",
      "Epoch 690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.9350 - accuracy: 0.0000e+00 - val_loss: 89.0339 - val_accuracy: 0.1765\n",
      "Epoch 691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5447 - accuracy: 0.0000e+00 - val_loss: 80.8744 - val_accuracy: 0.0588\n",
      "Epoch 692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2350 - accuracy: 0.0000e+00 - val_loss: 89.5311 - val_accuracy: 0.1765\n",
      "Epoch 693/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.6953 - accuracy: 0.0000e+00 - val_loss: 97.8314 - val_accuracy: 0.1176\n",
      "Epoch 694/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.8447 - accuracy: 0.0000e+00 - val_loss: 95.5824 - val_accuracy: 0.0588\n",
      "Epoch 695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5097 - accuracy: 0.0000e+00 - val_loss: 98.7090 - val_accuracy: 0.0588\n",
      "Epoch 696/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.6058 - accuracy: 0.0000e+00 - val_loss: 96.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.8430 - accuracy: 0.0156 - val_loss: 96.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5432 - accuracy: 0.0156 - val_loss: 96.5758 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.0452 - accuracy: 0.0000e+00 - val_loss: 93.7319 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 78.7419 - accuracy: 0.0000e+00 - val_loss: 85.2588 - val_accuracy: 0.0000e+00\n",
      "Epoch 701/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.2192 - accuracy: 0.0000e+00 - val_loss: 82.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.8947 - accuracy: 0.0000e+00 - val_loss: 85.7786 - val_accuracy: 0.0588\n",
      "Epoch 703/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 81.1349 - accuracy: 0.0000e+00 - val_loss: 96.6078 - val_accuracy: 0.1176\n",
      "Epoch 704/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.0733 - accuracy: 0.0000e+00 - val_loss: 107.7002 - val_accuracy: 0.0588\n",
      "Epoch 705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.2129 - accuracy: 0.0000e+00 - val_loss: 107.6734 - val_accuracy: 0.0588\n",
      "Epoch 706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.2290 - accuracy: 0.0000e+00 - val_loss: 92.5213 - val_accuracy: 0.0588\n",
      "Epoch 707/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1856 - accuracy: 0.0000e+00 - val_loss: 88.4697 - val_accuracy: 0.0588\n",
      "Epoch 708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1386 - accuracy: 0.0000e+00 - val_loss: 91.2288 - val_accuracy: 0.0588\n",
      "Epoch 709/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.8229 - accuracy: 0.0000e+00 - val_loss: 99.0496 - val_accuracy: 0.1176\n",
      "Epoch 710/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.2555 - accuracy: 0.0000e+00 - val_loss: 97.9640 - val_accuracy: 0.1176\n",
      "Epoch 711/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.4121 - accuracy: 0.0156 - val_loss: 101.2422 - val_accuracy: 0.0588\n",
      "Epoch 712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0713 - accuracy: 0.0000e+00 - val_loss: 100.0707 - val_accuracy: 0.1176\n",
      "Epoch 713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.2113 - accuracy: 0.0000e+00 - val_loss: 88.6242 - val_accuracy: 0.1176\n",
      "Epoch 714/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.2465 - accuracy: 0.0000e+00 - val_loss: 79.9826 - val_accuracy: 0.0588\n",
      "Epoch 715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.2148 - accuracy: 0.0000e+00 - val_loss: 78.2845 - val_accuracy: 0.1176\n",
      "Epoch 716/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.1050 - accuracy: 0.0000e+00 - val_loss: 81.0131 - val_accuracy: 0.1176\n",
      "Epoch 717/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4067 - accuracy: 0.0000e+00 - val_loss: 94.4674 - val_accuracy: 0.1176\n",
      "Epoch 718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0755 - accuracy: 0.0000e+00 - val_loss: 97.9553 - val_accuracy: 0.1176\n",
      "Epoch 719/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.7183 - accuracy: 0.0000e+00 - val_loss: 91.5066 - val_accuracy: 0.0588\n",
      "Epoch 720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6597 - accuracy: 0.0000e+00 - val_loss: 88.6956 - val_accuracy: 0.0588\n",
      "Epoch 721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.8570 - accuracy: 0.0000e+00 - val_loss: 88.7368 - val_accuracy: 0.0588\n",
      "Epoch 722/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.3525 - accuracy: 0.0156 - val_loss: 94.9402 - val_accuracy: 0.0588\n",
      "Epoch 723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.4078 - accuracy: 0.0156 - val_loss: 98.1307 - val_accuracy: 0.1176\n",
      "Epoch 724/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.5718 - accuracy: 0.0000e+00 - val_loss: 94.6790 - val_accuracy: 0.0588\n",
      "Epoch 725/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.0275 - accuracy: 0.0000e+00 - val_loss: 95.2803 - val_accuracy: 0.1176\n",
      "Epoch 726/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1253 - accuracy: 0.0000e+00 - val_loss: 96.4418 - val_accuracy: 0.1176\n",
      "Epoch 727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.4650 - accuracy: 0.0156 - val_loss: 89.3331 - val_accuracy: 0.1176\n",
      "Epoch 728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4502 - accuracy: 0.0156 - val_loss: 91.7219 - val_accuracy: 0.1176\n",
      "Epoch 729/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.5593 - accuracy: 0.0000e+00 - val_loss: 97.1124 - val_accuracy: 0.0588\n",
      "Epoch 730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9031 - accuracy: 0.0000e+00 - val_loss: 93.4041 - val_accuracy: 0.1176\n",
      "Epoch 731/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.3041 - accuracy: 0.0000e+00 - val_loss: 90.0112 - val_accuracy: 0.1176\n",
      "Epoch 732/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.0086 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 56.8306 - accuracy: 0.0000e+00 - val_loss: 91.3547 - val_accuracy: 0.1176\n",
      "Epoch 733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.6749 - accuracy: 0.0000e+00 - val_loss: 90.6372 - val_accuracy: 0.1176\n",
      "Epoch 734/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 93.9741 - accuracy: 0.0000e+00 - val_loss: 89.9889 - val_accuracy: 0.1176\n",
      "Epoch 735/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 86.5903 - accuracy: 0.0000e+00 - val_loss: 87.8450 - val_accuracy: 0.0588\n",
      "Epoch 736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1852 - accuracy: 0.0000e+00 - val_loss: 87.3806 - val_accuracy: 0.0588\n",
      "Epoch 737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.3927 - accuracy: 0.0000e+00 - val_loss: 97.1952 - val_accuracy: 0.1176\n",
      "Epoch 738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7562 - accuracy: 0.0000e+00 - val_loss: 107.7456 - val_accuracy: 0.1176\n",
      "Epoch 739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.5586 - accuracy: 0.0312 - val_loss: 109.9493 - val_accuracy: 0.1176\n",
      "Epoch 740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5433 - accuracy: 0.0000e+00 - val_loss: 93.2845 - val_accuracy: 0.1176\n",
      "Epoch 741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5513 - accuracy: 0.0000e+00 - val_loss: 81.2238 - val_accuracy: 0.0588\n",
      "Epoch 742/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 61.7552 - accuracy: 0.0000e+00 - val_loss: 77.1579 - val_accuracy: 0.0588\n",
      "Epoch 743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3604 - accuracy: 0.0000e+00 - val_loss: 75.1561 - val_accuracy: 0.0588\n",
      "Epoch 744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4986 - accuracy: 0.0156 - val_loss: 81.5426 - val_accuracy: 0.0588\n",
      "Epoch 745/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.9509 - accuracy: 0.0156 - val_loss: 84.2354 - val_accuracy: 0.1176\n",
      "Epoch 746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.7383 - accuracy: 0.0000e+00 - val_loss: 88.3777 - val_accuracy: 0.1765\n",
      "Epoch 747/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.7412 - accuracy: 0.0000e+00 - val_loss: 87.8061 - val_accuracy: 0.1765\n",
      "Epoch 748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7768 - accuracy: 0.0156 - val_loss: 87.0032 - val_accuracy: 0.1176\n",
      "Epoch 749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1522 - accuracy: 0.0000e+00 - val_loss: 82.9623 - val_accuracy: 0.0588\n",
      "Epoch 750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2808 - accuracy: 0.0000e+00 - val_loss: 79.4138 - val_accuracy: 0.0588\n",
      "Epoch 751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5834 - accuracy: 0.0156 - val_loss: 80.2804 - val_accuracy: 0.0588\n",
      "Epoch 752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.7180 - accuracy: 0.0000e+00 - val_loss: 86.8056 - val_accuracy: 0.1176\n",
      "Epoch 753/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2417 - accuracy: 0.0156 - val_loss: 93.3687 - val_accuracy: 0.1176\n",
      "Epoch 754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6775 - accuracy: 0.0156 - val_loss: 97.7180 - val_accuracy: 0.1176\n",
      "Epoch 755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.3350 - accuracy: 0.0000e+00 - val_loss: 89.9036 - val_accuracy: 0.0588\n",
      "Epoch 756/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.2845 - accuracy: 0.0000e+00 - val_loss: 83.8054 - val_accuracy: 0.0588\n",
      "Epoch 757/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.3421 - accuracy: 0.0000e+00 - val_loss: 89.6279 - val_accuracy: 0.0588\n",
      "Epoch 758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0409 - accuracy: 0.0000e+00 - val_loss: 93.5340 - val_accuracy: 0.0588\n",
      "Epoch 759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4565 - accuracy: 0.0000e+00 - val_loss: 91.9497 - val_accuracy: 0.0588\n",
      "Epoch 760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.9123 - accuracy: 0.0000e+00 - val_loss: 88.0153 - val_accuracy: 0.0588\n",
      "Epoch 761/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.8936 - accuracy: 0.0000e+00 - val_loss: 82.0183 - val_accuracy: 0.0588\n",
      "Epoch 762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2901 - accuracy: 0.0312 - val_loss: 78.3799 - val_accuracy: 0.0588\n",
      "Epoch 763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.2969 - accuracy: 0.0312 - val_loss: 83.0871 - val_accuracy: 0.1176\n",
      "Epoch 764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6019 - accuracy: 0.0000e+00 - val_loss: 87.0599 - val_accuracy: 0.1765\n",
      "Epoch 765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5470 - accuracy: 0.0000e+00 - val_loss: 90.3805 - val_accuracy: 0.1765\n",
      "Epoch 766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9053 - accuracy: 0.0000e+00 - val_loss: 94.2696 - val_accuracy: 0.1765\n",
      "Epoch 767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.8690 - accuracy: 0.0000e+00 - val_loss: 91.3828 - val_accuracy: 0.1176\n",
      "Epoch 768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9813 - accuracy: 0.0000e+00 - val_loss: 89.5473 - val_accuracy: 0.0588\n",
      "Epoch 769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.5103 - accuracy: 0.0000e+00 - val_loss: 87.4034 - val_accuracy: 0.0588\n",
      "Epoch 770/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1102 - accuracy: 0.0156 - val_loss: 83.0198 - val_accuracy: 0.0588\n",
      "Epoch 771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.3549 - accuracy: 0.0000e+00 - val_loss: 84.0612 - val_accuracy: 0.0588\n",
      "Epoch 772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5182 - accuracy: 0.0000e+00 - val_loss: 92.4878 - val_accuracy: 0.0588\n",
      "Epoch 773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3805 - accuracy: 0.0000e+00 - val_loss: 111.2910 - val_accuracy: 0.0588\n",
      "Epoch 774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1139 - accuracy: 0.0156 - val_loss: 113.2538 - val_accuracy: 0.0588\n",
      "Epoch 775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.9840 - accuracy: 0.0000e+00 - val_loss: 105.7541 - val_accuracy: 0.0588\n",
      "Epoch 776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.5472 - accuracy: 0.0000e+00 - val_loss: 86.2621 - val_accuracy: 0.1176\n",
      "Epoch 777/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.6528 - accuracy: 0.0156 - val_loss: 71.0884 - val_accuracy: 0.1176\n",
      "Epoch 778/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.3699 - accuracy: 0.0000e+00 - val_loss: 70.6929 - val_accuracy: 0.1176\n",
      "Epoch 779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.1315 - accuracy: 0.0000e+00 - val_loss: 69.9477 - val_accuracy: 0.1176\n",
      "Epoch 780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.6767 - accuracy: 0.0000e+00 - val_loss: 75.7931 - val_accuracy: 0.1176\n",
      "Epoch 781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.8896 - accuracy: 0.0000e+00 - val_loss: 92.8507 - val_accuracy: 0.0588\n",
      "Epoch 782/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.8924 - accuracy: 0.0000e+00 - val_loss: 109.9400 - val_accuracy: 0.0588\n",
      "Epoch 783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.0059 - accuracy: 0.0000e+00 - val_loss: 110.2918 - val_accuracy: 0.0588\n",
      "Epoch 784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5662 - accuracy: 0.0000e+00 - val_loss: 94.9252 - val_accuracy: 0.1176\n",
      "Epoch 785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.2176 - accuracy: 0.0000e+00 - val_loss: 80.0991 - val_accuracy: 0.0588\n",
      "Epoch 786/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.8047 - accuracy: 0.0000e+00 - val_loss: 73.1667 - val_accuracy: 0.0588\n",
      "Epoch 787/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.0304 - accuracy: 0.0156 - val_loss: 76.0281 - val_accuracy: 0.0588\n",
      "Epoch 788/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.9337 - accuracy: 0.0000e+00 - val_loss: 91.3037 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.3351 - accuracy: 0.0000e+00 - val_loss: 106.5365 - val_accuracy: 0.0588\n",
      "Epoch 790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.2717 - accuracy: 0.0000e+00 - val_loss: 109.8862 - val_accuracy: 0.0588\n",
      "Epoch 791/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 72.9747 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 67.6064 - accuracy: 0.0000e+00 - val_loss: 97.2210 - val_accuracy: 0.0588\n",
      "Epoch 792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.9569 - accuracy: 0.0000e+00 - val_loss: 80.0823 - val_accuracy: 0.1176\n",
      "Epoch 793/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2804 - accuracy: 0.0000e+00 - val_loss: 73.9175 - val_accuracy: 0.0588\n",
      "Epoch 794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7209 - accuracy: 0.0000e+00 - val_loss: 73.8210 - val_accuracy: 0.0588\n",
      "Epoch 795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.1383 - accuracy: 0.0000e+00 - val_loss: 79.8796 - val_accuracy: 0.0588\n",
      "Epoch 796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6487 - accuracy: 0.0000e+00 - val_loss: 81.4757 - val_accuracy: 0.0588\n",
      "Epoch 797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5799 - accuracy: 0.0000e+00 - val_loss: 85.2486 - val_accuracy: 0.0588\n",
      "Epoch 798/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.7220 - accuracy: 0.0000e+00 - val_loss: 94.5747 - val_accuracy: 0.0588\n",
      "Epoch 799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5328 - accuracy: 0.0000e+00 - val_loss: 92.1499 - val_accuracy: 0.0588\n",
      "Epoch 800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2660 - accuracy: 0.0000e+00 - val_loss: 83.6101 - val_accuracy: 0.0588\n",
      "Epoch 801/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.0822 - accuracy: 0.0000e+00 - val_loss: 72.5766 - val_accuracy: 0.0588\n",
      "Epoch 802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6617 - accuracy: 0.0000e+00 - val_loss: 69.7917 - val_accuracy: 0.0588\n",
      "Epoch 803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.9886 - accuracy: 0.0156 - val_loss: 82.0686 - val_accuracy: 0.1176\n",
      "Epoch 804/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8419 - accuracy: 0.0000e+00 - val_loss: 99.3820 - val_accuracy: 0.1176\n",
      "Epoch 805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.7908 - accuracy: 0.0000e+00 - val_loss: 101.0068 - val_accuracy: 0.0588\n",
      "Epoch 806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6260 - accuracy: 0.0000e+00 - val_loss: 89.1970 - val_accuracy: 0.1765\n",
      "Epoch 807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9515 - accuracy: 0.0000e+00 - val_loss: 78.8486 - val_accuracy: 0.1176\n",
      "Epoch 808/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.7450 - accuracy: 0.0000e+00 - val_loss: 73.2369 - val_accuracy: 0.1176\n",
      "Epoch 809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8215 - accuracy: 0.0156 - val_loss: 82.3763 - val_accuracy: 0.1176\n",
      "Epoch 810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3637 - accuracy: 0.0156 - val_loss: 95.2009 - val_accuracy: 0.1176\n",
      "Epoch 811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8129 - accuracy: 0.0000e+00 - val_loss: 100.8215 - val_accuracy: 0.1176\n",
      "Epoch 812/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.5490 - accuracy: 0.0000e+00 - val_loss: 97.8464 - val_accuracy: 0.1176\n",
      "Epoch 813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1753 - accuracy: 0.0312 - val_loss: 84.7844 - val_accuracy: 0.1176\n",
      "Epoch 814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5475 - accuracy: 0.0000e+00 - val_loss: 86.7092 - val_accuracy: 0.1765\n",
      "Epoch 815/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6568 - accuracy: 0.0000e+00 - val_loss: 88.3042 - val_accuracy: 0.1765\n",
      "Epoch 816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.4332 - accuracy: 0.0000e+00 - val_loss: 85.3795 - val_accuracy: 0.1176\n",
      "Epoch 817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2466 - accuracy: 0.0000e+00 - val_loss: 84.8018 - val_accuracy: 0.1176\n",
      "Epoch 818/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.5619 - accuracy: 0.0000e+00 - val_loss: 89.0814 - val_accuracy: 0.1765\n",
      "Epoch 819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1732 - accuracy: 0.0000e+00 - val_loss: 91.4699 - val_accuracy: 0.1176\n",
      "Epoch 820/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.6870 - accuracy: 0.0156 - val_loss: 91.6378 - val_accuracy: 0.0588\n",
      "Epoch 821/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.8919 - accuracy: 0.0000e+00 - val_loss: 93.1513 - val_accuracy: 0.0588\n",
      "Epoch 822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0094 - accuracy: 0.0156 - val_loss: 93.3946 - val_accuracy: 0.0588\n",
      "Epoch 823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4051 - accuracy: 0.0000e+00 - val_loss: 83.2904 - val_accuracy: 0.0588\n",
      "Epoch 824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.6268 - accuracy: 0.0000e+00 - val_loss: 80.0274 - val_accuracy: 0.0588\n",
      "Epoch 825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.0817 - accuracy: 0.0000e+00 - val_loss: 86.7435 - val_accuracy: 0.0588\n",
      "Epoch 826/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4557 - accuracy: 0.0000e+00 - val_loss: 90.5825 - val_accuracy: 0.0588\n",
      "Epoch 827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.8710 - accuracy: 0.0000e+00 - val_loss: 90.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.6467 - accuracy: 0.0000e+00 - val_loss: 84.2341 - val_accuracy: 0.0000e+00\n",
      "Epoch 829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.8184 - accuracy: 0.0000e+00 - val_loss: 76.7980 - val_accuracy: 0.0000e+00\n",
      "Epoch 830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.1670 - accuracy: 0.0000e+00 - val_loss: 86.8648 - val_accuracy: 0.0588\n",
      "Epoch 831/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 73.4621 - accuracy: 0.0000e+00 - val_loss: 90.9164 - val_accuracy: 0.0588\n",
      "Epoch 832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0717 - accuracy: 0.0000e+00 - val_loss: 95.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.7205 - accuracy: 0.0000e+00 - val_loss: 91.8247 - val_accuracy: 0.1176\n",
      "Epoch 834/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.0587 - accuracy: 0.0000e+00 - val_loss: 88.9863 - val_accuracy: 0.0588\n",
      "Epoch 835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.0514 - accuracy: 0.0000e+00 - val_loss: 86.3305 - val_accuracy: 0.1176\n",
      "Epoch 836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.2940 - accuracy: 0.0156 - val_loss: 82.9861 - val_accuracy: 0.1176\n",
      "Epoch 837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.0861 - accuracy: 0.0000e+00 - val_loss: 79.9324 - val_accuracy: 0.1176\n",
      "Epoch 838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1655 - accuracy: 0.0000e+00 - val_loss: 85.5624 - val_accuracy: 0.1176\n",
      "Epoch 839/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.7568 - accuracy: 0.0000e+00 - val_loss: 83.7519 - val_accuracy: 0.1176\n",
      "Epoch 840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3978 - accuracy: 0.0000e+00 - val_loss: 85.1310 - val_accuracy: 0.0588\n",
      "Epoch 841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.3349 - accuracy: 0.0000e+00 - val_loss: 84.5499 - val_accuracy: 0.0588\n",
      "Epoch 842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1846 - accuracy: 0.0000e+00 - val_loss: 86.7856 - val_accuracy: 0.0588\n",
      "Epoch 843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.3543 - accuracy: 0.0000e+00 - val_loss: 89.5784 - val_accuracy: 0.0588\n",
      "Epoch 844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.5390 - accuracy: 0.0000e+00 - val_loss: 94.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 845/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.9468 - accuracy: 0.0000e+00 - val_loss: 92.0399 - val_accuracy: 0.0588\n",
      "Epoch 846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5617 - accuracy: 0.0000e+00 - val_loss: 91.8799 - val_accuracy: 0.0588\n",
      "Epoch 847/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.8054 - accuracy: 0.0000e+00 - val_loss: 80.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.5538 - accuracy: 0.0000e+00 - val_loss: 77.4521 - val_accuracy: 0.0588\n",
      "Epoch 849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.8181 - accuracy: 0.0156 - val_loss: 78.1883 - val_accuracy: 0.0588\n",
      "Epoch 850/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.1158 - accuracy: 0.0000e+00 - val_loss: 84.6025 - val_accuracy: 0.0588\n",
      "Epoch 851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.5221 - accuracy: 0.0156 - val_loss: 88.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.5074 - accuracy: 0.0000e+00 - val_loss: 81.4488 - val_accuracy: 0.0588\n",
      "Epoch 853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.5569 - accuracy: 0.0156 - val_loss: 79.4939 - val_accuracy: 0.0588\n",
      "Epoch 854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.3377 - accuracy: 0.0156 - val_loss: 83.9310 - val_accuracy: 0.0588\n",
      "Epoch 855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.4085 - accuracy: 0.0156 - val_loss: 94.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.0055 - accuracy: 0.0000e+00 - val_loss: 100.0572 - val_accuracy: 0.0000e+00\n",
      "Epoch 857/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.3406 - accuracy: 0.0000e+00 - val_loss: 88.5858 - val_accuracy: 0.0588\n",
      "Epoch 858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.6327 - accuracy: 0.0000e+00 - val_loss: 80.4594 - val_accuracy: 0.1176\n",
      "Epoch 859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8318 - accuracy: 0.0156 - val_loss: 87.2023 - val_accuracy: 0.1176\n",
      "Epoch 860/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 82.1227 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 89.3502 - accuracy: 0.0156 - val_loss: 87.5084 - val_accuracy: 0.1176\n",
      "Epoch 861/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.6373 - accuracy: 0.0000e+00 - val_loss: 92.7201 - val_accuracy: 0.0588\n",
      "Epoch 862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.3614 - accuracy: 0.0000e+00 - val_loss: 96.3895 - val_accuracy: 0.0588\n",
      "Epoch 863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6056 - accuracy: 0.0000e+00 - val_loss: 100.2838 - val_accuracy: 0.0588\n",
      "Epoch 864/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.8179 - accuracy: 0.0156 - val_loss: 95.6579 - val_accuracy: 0.0588\n",
      "Epoch 865/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 84.6090 - accuracy: 0.0156 - val_loss: 92.9063 - val_accuracy: 0.0588\n",
      "Epoch 866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.6285 - accuracy: 0.0000e+00 - val_loss: 94.9568 - val_accuracy: 0.0000e+00\n",
      "Epoch 867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1345 - accuracy: 0.0156 - val_loss: 87.5289 - val_accuracy: 0.0588\n",
      "Epoch 868/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 44.9557 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 47.2785 - accuracy: 0.0000e+00 - val_loss: 87.0650 - val_accuracy: 0.0588\n",
      "Epoch 869/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2256 - accuracy: 0.0000e+00 - val_loss: 88.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8442 - accuracy: 0.0312 - val_loss: 86.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 871/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 81.4284 - accuracy: 0.0000e+00 - val_loss: 85.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 872/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.0068 - accuracy: 0.0000e+00 - val_loss: 82.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.2571 - accuracy: 0.0000e+00 - val_loss: 83.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.5500 - accuracy: 0.0000e+00 - val_loss: 88.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.2110 - accuracy: 0.0000e+00 - val_loss: 95.0949 - val_accuracy: 0.0000e+00\n",
      "Epoch 876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.2929 - accuracy: 0.0000e+00 - val_loss: 96.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2454 - accuracy: 0.0000e+00 - val_loss: 85.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6613 - accuracy: 0.0000e+00 - val_loss: 80.6890 - val_accuracy: 0.0588\n",
      "Epoch 879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2780 - accuracy: 0.0000e+00 - val_loss: 82.3463 - val_accuracy: 0.0588\n",
      "Epoch 880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.2194 - accuracy: 0.0000e+00 - val_loss: 95.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.4523 - accuracy: 0.0000e+00 - val_loss: 104.3852 - val_accuracy: 0.0588\n",
      "Epoch 882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.4128 - accuracy: 0.0156 - val_loss: 100.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0775 - accuracy: 0.0000e+00 - val_loss: 87.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.2817 - accuracy: 0.0000e+00 - val_loss: 75.8984 - val_accuracy: 0.0588\n",
      "Epoch 885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.6020 - accuracy: 0.0156 - val_loss: 73.8895 - val_accuracy: 0.0588\n",
      "Epoch 886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0770 - accuracy: 0.0156 - val_loss: 86.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2483 - accuracy: 0.0000e+00 - val_loss: 99.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.1833 - accuracy: 0.0000e+00 - val_loss: 114.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 889/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.7496 - accuracy: 0.0156 - val_loss: 108.8455 - val_accuracy: 0.0000e+00\n",
      "Epoch 890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6605 - accuracy: 0.0000e+00 - val_loss: 92.9935 - val_accuracy: 0.0588\n",
      "Epoch 891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.9112 - accuracy: 0.0000e+00 - val_loss: 77.0519 - val_accuracy: 0.0588\n",
      "Epoch 892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9150 - accuracy: 0.0156 - val_loss: 72.5828 - val_accuracy: 0.0588\n",
      "Epoch 893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.5936 - accuracy: 0.0000e+00 - val_loss: 79.7125 - val_accuracy: 0.1176\n",
      "Epoch 894/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.3224 - accuracy: 0.0156 - val_loss: 97.3790 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4736 - accuracy: 0.0000e+00 - val_loss: 101.3205 - val_accuracy: 0.0588\n",
      "Epoch 896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6090 - accuracy: 0.0000e+00 - val_loss: 102.1066 - val_accuracy: 0.0588\n",
      "Epoch 897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.9414 - accuracy: 0.0000e+00 - val_loss: 96.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 898/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 63.8522 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 69.6823 - accuracy: 0.0156 - val_loss: 93.3850 - val_accuracy: 0.0588\n",
      "Epoch 899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.4828 - accuracy: 0.0156 - val_loss: 93.6793 - val_accuracy: 0.0588\n",
      "Epoch 900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.4256 - accuracy: 0.0156 - val_loss: 103.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3023 - accuracy: 0.0000e+00 - val_loss: 104.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 902/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 66.2685 - accuracy: 0.0000e+00 - val_loss: 94.1982 - val_accuracy: 0.0000e+00\n",
      "Epoch 903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7138 - accuracy: 0.0000e+00 - val_loss: 80.5755 - val_accuracy: 0.0588\n",
      "Epoch 904/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3592 - accuracy: 0.0000e+00 - val_loss: 82.1249 - val_accuracy: 0.0588\n",
      "Epoch 905/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.1127 - accuracy: 0.0312 - val_loss: 90.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 906/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 79.5332 - accuracy: 0.0000e+00 - val_loss: 96.6507 - val_accuracy: 0.0588\n",
      "Epoch 907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.3719 - accuracy: 0.0000e+00 - val_loss: 105.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 908/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2985 - accuracy: 0.0000e+00 - val_loss: 96.2249 - val_accuracy: 0.0588\n",
      "Epoch 909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4047 - accuracy: 0.0312 - val_loss: 83.9757 - val_accuracy: 0.0000e+00\n",
      "Epoch 910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1566 - accuracy: 0.0000e+00 - val_loss: 83.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 911/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.3866 - accuracy: 0.0156 - val_loss: 84.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6846 - accuracy: 0.0000e+00 - val_loss: 91.4477 - val_accuracy: 0.0588\n",
      "Epoch 913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.3639 - accuracy: 0.0000e+00 - val_loss: 98.2272 - val_accuracy: 0.0000e+00\n",
      "Epoch 914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.7291 - accuracy: 0.0156 - val_loss: 89.2545 - val_accuracy: 0.0588\n",
      "Epoch 915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.1226 - accuracy: 0.0000e+00 - val_loss: 81.4773 - val_accuracy: 0.0000e+00\n",
      "Epoch 916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9419 - accuracy: 0.0000e+00 - val_loss: 80.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 917/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.5814 - accuracy: 0.0156 - val_loss: 81.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.4346 - accuracy: 0.0000e+00 - val_loss: 81.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8254 - accuracy: 0.0000e+00 - val_loss: 79.3895 - val_accuracy: 0.0588\n",
      "Epoch 920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1363 - accuracy: 0.0000e+00 - val_loss: 91.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.4051 - accuracy: 0.0156 - val_loss: 114.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6102 - accuracy: 0.0000e+00 - val_loss: 105.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 923/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0832 - accuracy: 0.0156 - val_loss: 83.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 924/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 77.7987 - accuracy: 0.0000e+00 - val_loss: 67.5980 - val_accuracy: 0.0000e+00\n",
      "Epoch 925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.3503 - accuracy: 0.0000e+00 - val_loss: 68.5851 - val_accuracy: 0.0588\n",
      "Epoch 926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.0057 - accuracy: 0.0000e+00 - val_loss: 82.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5922 - accuracy: 0.0000e+00 - val_loss: 94.1409 - val_accuracy: 0.0588\n",
      "Epoch 928/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4203 - accuracy: 0.0000e+00 - val_loss: 101.1979 - val_accuracy: 0.0000e+00\n",
      "Epoch 929/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3386 - accuracy: 0.0000e+00 - val_loss: 93.4578 - val_accuracy: 0.0588\n",
      "Epoch 930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0175 - accuracy: 0.0000e+00 - val_loss: 79.2957 - val_accuracy: 0.0000e+00\n",
      "Epoch 931/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 67.8730 - accuracy: 0.0000e+00 - val_loss: 72.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 932/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.5883 - accuracy: 0.0000e+00 - val_loss: 81.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 933/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 67.8132 - accuracy: 0.0000e+00 - val_loss: 99.9030 - val_accuracy: 0.0588\n",
      "Epoch 934/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1214 - accuracy: 0.0000e+00 - val_loss: 112.2575 - val_accuracy: 0.0000e+00\n",
      "Epoch 935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9721 - accuracy: 0.0156 - val_loss: 105.7000 - val_accuracy: 0.0000e+00\n",
      "Epoch 936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.1123 - accuracy: 0.0156 - val_loss: 89.5496 - val_accuracy: 0.0588\n",
      "Epoch 937/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1643 - accuracy: 0.0000e+00 - val_loss: 78.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1097 - accuracy: 0.0156 - val_loss: 77.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1734 - accuracy: 0.0000e+00 - val_loss: 84.6068 - val_accuracy: 0.0588\n",
      "Epoch 940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.5788 - accuracy: 0.0000e+00 - val_loss: 104.9441 - val_accuracy: 0.0000e+00\n",
      "Epoch 941/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 71.9351 - accuracy: 0.0156 - val_loss: 122.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5520 - accuracy: 0.0156 - val_loss: 117.2512 - val_accuracy: 0.0000e+00\n",
      "Epoch 943/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 73.2604 - accuracy: 0.0000e+00 - val_loss: 93.4369 - val_accuracy: 0.0588\n",
      "Epoch 944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5391 - accuracy: 0.0312 - val_loss: 77.0645 - val_accuracy: 0.0588\n",
      "Epoch 945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6660 - accuracy: 0.0000e+00 - val_loss: 78.7231 - val_accuracy: 0.1176\n",
      "Epoch 946/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1650 - accuracy: 0.0000e+00 - val_loss: 83.8958 - val_accuracy: 0.0588\n",
      "Epoch 947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9674 - accuracy: 0.0156 - val_loss: 86.1006 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9111 - accuracy: 0.0156 - val_loss: 87.7073 - val_accuracy: 0.0000e+00\n",
      "Epoch 949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.5041 - accuracy: 0.0000e+00 - val_loss: 88.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.8038 - accuracy: 0.0000e+00 - val_loss: 82.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2303 - accuracy: 0.0156 - val_loss: 80.1552 - val_accuracy: 0.0000e+00\n",
      "Epoch 952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.3356 - accuracy: 0.0000e+00 - val_loss: 85.8737 - val_accuracy: 0.0000e+00\n",
      "Epoch 953/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.3994 - accuracy: 0.0000e+00 - val_loss: 93.2180 - val_accuracy: 0.0588\n",
      "Epoch 954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2366 - accuracy: 0.0000e+00 - val_loss: 105.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 955/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.3987 - accuracy: 0.0000e+00 - val_loss: 102.8030 - val_accuracy: 0.0588\n",
      "Epoch 956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4611 - accuracy: 0.0000e+00 - val_loss: 97.7804 - val_accuracy: 0.0000e+00\n",
      "Epoch 957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.7176 - accuracy: 0.0000e+00 - val_loss: 83.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1975 - accuracy: 0.0000e+00 - val_loss: 81.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1000 - accuracy: 0.0000e+00 - val_loss: 77.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 960/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 75.1823 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 76.5193 - accuracy: 0.0000e+00 - val_loss: 80.8827 - val_accuracy: 0.0588\n",
      "Epoch 961/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 78.6519 - accuracy: 0.0000e+00 - val_loss: 92.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1171 - accuracy: 0.0000e+00 - val_loss: 100.1735 - val_accuracy: 0.0000e+00\n",
      "Epoch 963/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.5042 - accuracy: 0.0156 - val_loss: 98.7376 - val_accuracy: 0.0000e+00\n",
      "Epoch 964/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 82.8804 - accuracy: 0.031 - 0s 125us/step - loss: 81.1840 - accuracy: 0.0156 - val_loss: 91.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3417 - accuracy: 0.0156 - val_loss: 84.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6045 - accuracy: 0.0000e+00 - val_loss: 89.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6234 - accuracy: 0.0000e+00 - val_loss: 92.9058 - val_accuracy: 0.0000e+00\n",
      "Epoch 968/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.0601 - accuracy: 0.0000e+00 - val_loss: 93.2249 - val_accuracy: 0.0588\n",
      "Epoch 969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4282 - accuracy: 0.0000e+00 - val_loss: 89.1497 - val_accuracy: 0.0588\n",
      "Epoch 970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.9088 - accuracy: 0.0000e+00 - val_loss: 85.8226 - val_accuracy: 0.0588\n",
      "Epoch 971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.6018 - accuracy: 0.0000e+00 - val_loss: 88.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.7495 - accuracy: 0.0156 - val_loss: 90.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.8882 - accuracy: 0.0000e+00 - val_loss: 95.3423 - val_accuracy: 0.0000e+00\n",
      "Epoch 974/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.2697 - accuracy: 0.0156 - val_loss: 89.8899 - val_accuracy: 0.0000e+00\n",
      "Epoch 975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.6938 - accuracy: 0.0156 - val_loss: 77.9684 - val_accuracy: 0.0000e+00\n",
      "Epoch 976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.0582 - accuracy: 0.0000e+00 - val_loss: 74.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.6538 - accuracy: 0.0000e+00 - val_loss: 77.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.8527 - accuracy: 0.0000e+00 - val_loss: 92.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.0206 - accuracy: 0.0000e+00 - val_loss: 105.9875 - val_accuracy: 0.0000e+00\n",
      "Epoch 980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.1946 - accuracy: 0.0000e+00 - val_loss: 101.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 981/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.7815 - accuracy: 0.0000e+00 - val_loss: 88.6355 - val_accuracy: 0.0588\n",
      "Epoch 982/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 71.4843 - accuracy: 0.031 - 0s 62us/step - loss: 77.8650 - accuracy: 0.0156 - val_loss: 82.5395 - val_accuracy: 0.0000e+00\n",
      "Epoch 983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0838 - accuracy: 0.0000e+00 - val_loss: 82.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0161 - accuracy: 0.0156 - val_loss: 78.9983 - val_accuracy: 0.0000e+00\n",
      "Epoch 985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.8333 - accuracy: 0.0000e+00 - val_loss: 83.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 986/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.9849 - accuracy: 0.0000e+00 - val_loss: 90.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.7329 - accuracy: 0.0156 - val_loss: 96.1451 - val_accuracy: 0.0588\n",
      "Epoch 988/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1080 - accuracy: 0.0156 - val_loss: 98.0006 - val_accuracy: 0.0000e+00\n",
      "Epoch 989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9474 - accuracy: 0.0000e+00 - val_loss: 85.4630 - val_accuracy: 0.0000e+00\n",
      "Epoch 990/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1385 - accuracy: 0.0312 - val_loss: 78.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9166 - accuracy: 0.0000e+00 - val_loss: 79.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.1978 - accuracy: 0.0000e+00 - val_loss: 87.0693 - val_accuracy: 0.0588\n",
      "Epoch 993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7439 - accuracy: 0.0000e+00 - val_loss: 95.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 994/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 57.0394 - accuracy: 0.0156 - val_loss: 92.8347 - val_accuracy: 0.0000e+00\n",
      "Epoch 995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.4622 - accuracy: 0.0312 - val_loss: 87.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 996/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 98.6950 - accuracy: 0.0000e+00 - val_loss: 83.7799 - val_accuracy: 0.0000e+00\n",
      "Epoch 997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5723 - accuracy: 0.0312 - val_loss: 82.3330 - val_accuracy: 0.0588\n",
      "Epoch 998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4080 - accuracy: 0.0156 - val_loss: 80.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.3337 - accuracy: 0.0000e+00 - val_loss: 87.9402 - val_accuracy: 0.0588\n",
      "Epoch 1000/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 65.6156 - accuracy: 0.0000e+00 - val_loss: 100.7752 - val_accuracy: 0.0000e+00\n",
      "Epoch 1001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5239 - accuracy: 0.0000e+00 - val_loss: 100.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 1002/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.4076 - accuracy: 0.0156 - val_loss: 93.5009 - val_accuracy: 0.0588\n",
      "Epoch 1003/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 66.8657 - accuracy: 0.0156 - val_loss: 85.8623 - val_accuracy: 0.1176\n",
      "Epoch 1004/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 74.0227 - accuracy: 0.0000e+00 - val_loss: 80.6392 - val_accuracy: 0.0588\n",
      "Epoch 1005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9887 - accuracy: 0.0000e+00 - val_loss: 82.9192 - val_accuracy: 0.0588\n",
      "Epoch 1006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.8243 - accuracy: 0.0000e+00 - val_loss: 85.8060 - val_accuracy: 0.0588\n",
      "Epoch 1007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.5013 - accuracy: 0.0156 - val_loss: 82.5570 - val_accuracy: 0.0588\n",
      "Epoch 1008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.9051 - accuracy: 0.0000e+00 - val_loss: 82.3891 - val_accuracy: 0.0588\n",
      "Epoch 1009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4062 - accuracy: 0.0000e+00 - val_loss: 87.1666 - val_accuracy: 0.0588\n",
      "Epoch 1010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8547 - accuracy: 0.0000e+00 - val_loss: 90.7114 - val_accuracy: 0.0588\n",
      "Epoch 1011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1179 - accuracy: 0.0000e+00 - val_loss: 99.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8362 - accuracy: 0.0312 - val_loss: 102.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 1013/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2542 - accuracy: 0.0000e+00 - val_loss: 90.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 1014/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1750 - accuracy: 0.0000e+00 - val_loss: 82.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 1015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.2919 - accuracy: 0.0000e+00 - val_loss: 82.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 1016/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 76.2924 - accuracy: 0.0000e+00 - val_loss: 86.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 1017/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.4001 - accuracy: 0.0156 - val_loss: 95.3649 - val_accuracy: 0.0000e+00\n",
      "Epoch 1018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6365 - accuracy: 0.0156 - val_loss: 100.6124 - val_accuracy: 0.0588\n",
      "Epoch 1019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2087 - accuracy: 0.0156 - val_loss: 94.3970 - val_accuracy: 0.0588\n",
      "Epoch 1020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2596 - accuracy: 0.0000e+00 - val_loss: 94.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 1021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8462 - accuracy: 0.0156 - val_loss: 107.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 1022/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 59.6731 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 65.3695 - accuracy: 0.0000e+00 - val_loss: 109.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 1023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.6312 - accuracy: 0.0000e+00 - val_loss: 89.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 1024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5436 - accuracy: 0.0000e+00 - val_loss: 70.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1025/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.1283 - accuracy: 0.0156 - val_loss: 63.8952 - val_accuracy: 0.0000e+00\n",
      "Epoch 1026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4710 - accuracy: 0.0000e+00 - val_loss: 74.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 1027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5183 - accuracy: 0.0000e+00 - val_loss: 83.5394 - val_accuracy: 0.0588\n",
      "Epoch 1028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0907 - accuracy: 0.0000e+00 - val_loss: 87.5618 - val_accuracy: 0.0588\n",
      "Epoch 1029/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.3355 - accuracy: 0.0156 - val_loss: 90.2681 - val_accuracy: 0.0588\n",
      "Epoch 1030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7685 - accuracy: 0.0156 - val_loss: 102.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 1031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3626 - accuracy: 0.0312 - val_loss: 100.8685 - val_accuracy: 0.0588\n",
      "Epoch 1032/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2588 - accuracy: 0.0000e+00 - val_loss: 87.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 1033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1427 - accuracy: 0.0000e+00 - val_loss: 80.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 1034/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2330 - accuracy: 0.0000e+00 - val_loss: 79.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.9345 - accuracy: 0.0000e+00 - val_loss: 86.3291 - val_accuracy: 0.0588\n",
      "Epoch 1036/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.8562 - accuracy: 0.0156 - val_loss: 101.2233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5946 - accuracy: 0.0000e+00 - val_loss: 112.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1038/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.5670 - accuracy: 0.0156 - val_loss: 96.7604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1039/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.9202 - accuracy: 0.0000e+00 - val_loss: 80.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.9818 - accuracy: 0.0156 - val_loss: 74.7255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1041/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3374 - accuracy: 0.0000e+00 - val_loss: 79.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1042/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 84.1559 - accuracy: 0.0000e+00 - val_loss: 91.9469 - val_accuracy: 0.0588\n",
      "Epoch 1043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.0239 - accuracy: 0.0156 - val_loss: 94.1342 - val_accuracy: 0.0588\n",
      "Epoch 1044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9802 - accuracy: 0.0000e+00 - val_loss: 92.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 1045/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.4952 - accuracy: 0.0156 - val_loss: 90.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 1046/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.9654 - accuracy: 0.0000e+00 - val_loss: 89.9849 - val_accuracy: 0.0000e+00\n",
      "Epoch 1047/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2939 - accuracy: 0.0156 - val_loss: 93.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.8518 - accuracy: 0.0000e+00 - val_loss: 96.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 1049/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.0183 - accuracy: 0.0156 - val_loss: 94.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5713 - accuracy: 0.0000e+00 - val_loss: 91.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 1051/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.0669 - accuracy: 0.0000e+00 - val_loss: 85.2692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1052/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1572 - accuracy: 0.0000e+00 - val_loss: 81.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1053/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 66.2027 - accuracy: 0.0000e+00 - val_loss: 85.9873 - val_accuracy: 0.0000e+00\n",
      "Epoch 1054/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.4064 - accuracy: 0.0000e+00 - val_loss: 85.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 1055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1717 - accuracy: 0.0000e+00 - val_loss: 90.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6087 - accuracy: 0.0000e+00 - val_loss: 90.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8239 - accuracy: 0.0000e+00 - val_loss: 89.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1058/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0815 - accuracy: 0.0000e+00 - val_loss: 88.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 1059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5294 - accuracy: 0.0156 - val_loss: 88.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 1060/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9627 - accuracy: 0.0312 - val_loss: 87.3076 - val_accuracy: 0.0000e+00\n",
      "Epoch 1061/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1535 - accuracy: 0.0000e+00 - val_loss: 85.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 1062/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.5267 - accuracy: 0.0000e+00 - val_loss: 87.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1063/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.1130 - accuracy: 0.0156 - val_loss: 98.6041 - val_accuracy: 0.0588\n",
      "Epoch 1064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.9937 - accuracy: 0.0000e+00 - val_loss: 106.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.3581 - accuracy: 0.0000e+00 - val_loss: 100.5658 - val_accuracy: 0.0588\n",
      "Epoch 1066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4097 - accuracy: 0.0000e+00 - val_loss: 85.2509 - val_accuracy: 0.0000e+00\n",
      "Epoch 1067/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8117 - accuracy: 0.0000e+00 - val_loss: 77.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5491 - accuracy: 0.0312 - val_loss: 75.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 1069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.3538 - accuracy: 0.0000e+00 - val_loss: 78.5375 - val_accuracy: 0.0000e+00\n",
      "Epoch 1070/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.8788 - accuracy: 0.0000e+00 - val_loss: 95.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1071/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.6539 - accuracy: 0.0000e+00 - val_loss: 112.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 1072/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.7576 - accuracy: 0.0000e+00 - val_loss: 119.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1073/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 60.3864 - accuracy: 0.0000e+00 - val_loss: 107.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 1074/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 62.2661 - accuracy: 0.0156 - val_loss: 85.0251 - val_accuracy: 0.0000e+00\n",
      "Epoch 1075/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 71.0541 - accuracy: 0.0000e+00 - val_loss: 72.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 1076/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1974 - accuracy: 0.0000e+00 - val_loss: 73.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 1077/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.3829 - accuracy: 0.0156 - val_loss: 86.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 1078/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 66.9338 - accuracy: 0.0000e+00 - val_loss: 108.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 1079/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.6816 - accuracy: 0.0000e+00 - val_loss: 121.3207 - val_accuracy: 0.0000e+00\n",
      "Epoch 1080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0281 - accuracy: 0.0000e+00 - val_loss: 104.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 1081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4451 - accuracy: 0.0000e+00 - val_loss: 77.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9042 - accuracy: 0.0000e+00 - val_loss: 71.7720 - val_accuracy: 0.0000e+00\n",
      "Epoch 1083/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2032 - accuracy: 0.0312 - val_loss: 78.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 1084/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9112 - accuracy: 0.0000e+00 - val_loss: 85.4648 - val_accuracy: 0.0588\n",
      "Epoch 1085/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1236 - accuracy: 0.0000e+00 - val_loss: 96.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 1086/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.9646 - accuracy: 0.0000e+00 - val_loss: 103.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1087/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.8245 - accuracy: 0.0000e+00 - val_loss: 108.5532 - val_accuracy: 0.0000e+00\n",
      "Epoch 1088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1689 - accuracy: 0.0000e+00 - val_loss: 98.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 1089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.2849 - accuracy: 0.0000e+00 - val_loss: 83.3889 - val_accuracy: 0.0588\n",
      "Epoch 1090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2370 - accuracy: 0.0000e+00 - val_loss: 74.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1091/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.1316 - accuracy: 0.0156 - val_loss: 68.5488 - val_accuracy: 0.1176\n",
      "Epoch 1092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7290 - accuracy: 0.0156 - val_loss: 70.3176 - val_accuracy: 0.1176\n",
      "Epoch 1093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4886 - accuracy: 0.0000e+00 - val_loss: 85.2199 - val_accuracy: 0.1176\n",
      "Epoch 1094/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2127 - accuracy: 0.0000e+00 - val_loss: 96.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 1095/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.3344 - accuracy: 0.0000e+00 - val_loss: 108.3552 - val_accuracy: 0.0000e+00\n",
      "Epoch 1096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5753 - accuracy: 0.0156 - val_loss: 105.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1097/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.5561 - accuracy: 0.0000e+00 - val_loss: 90.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 1098/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 64.2873 - accuracy: 0.0156 - val_loss: 82.2106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5454 - accuracy: 0.0312 - val_loss: 86.7379 - val_accuracy: 0.0588\n",
      "Epoch 1100/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2974 - accuracy: 0.0000e+00 - val_loss: 96.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1101/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2117 - accuracy: 0.0000e+00 - val_loss: 102.6108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1102/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 69.8407 - accuracy: 0.0000e+00 - val_loss: 96.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 1103/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 72.8921 - accuracy: 0.0000e+00 - val_loss: 87.2866 - val_accuracy: 0.0000e+00\n",
      "Epoch 1104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 250us/step - loss: 56.1983 - accuracy: 0.0000e+00 - val_loss: 76.5265 - val_accuracy: 0.0588\n",
      "Epoch 1105/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 70.7474 - accuracy: 0.0000e+00 - val_loss: 85.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.6978 - accuracy: 0.0000e+00 - val_loss: 100.1880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.0665 - accuracy: 0.0000e+00 - val_loss: 110.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9461 - accuracy: 0.0000e+00 - val_loss: 109.9486 - val_accuracy: 0.0588\n",
      "Epoch 1109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.2923 - accuracy: 0.0156 - val_loss: 94.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 1110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.8911 - accuracy: 0.0000e+00 - val_loss: 77.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 1111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.6002 - accuracy: 0.0156 - val_loss: 76.0614 - val_accuracy: 0.0000e+00\n",
      "Epoch 1112/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.7560 - accuracy: 0.0000e+00 - val_loss: 85.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 1113/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.6427 - accuracy: 0.0000e+00 - val_loss: 100.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 1114/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0337 - accuracy: 0.0000e+00 - val_loss: 99.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1115/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.8245 - accuracy: 0.0156 - val_loss: 85.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 1116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.3536 - accuracy: 0.0156 - val_loss: 79.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 1117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1836 - accuracy: 0.0000e+00 - val_loss: 76.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.5765 - accuracy: 0.0000e+00 - val_loss: 83.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1200 - accuracy: 0.0156 - val_loss: 93.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.3826 - accuracy: 0.0000e+00 - val_loss: 93.0888 - val_accuracy: 0.0000e+00\n",
      "Epoch 1121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3431 - accuracy: 0.0000e+00 - val_loss: 83.8526 - val_accuracy: 0.0000e+00\n",
      "Epoch 1122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8600 - accuracy: 0.0000e+00 - val_loss: 83.1854 - val_accuracy: 0.0000e+00\n",
      "Epoch 1123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6572 - accuracy: 0.0156 - val_loss: 92.2014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1124/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 65.3429 - accuracy: 0.0156 - val_loss: 101.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1125/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3779 - accuracy: 0.0000e+00 - val_loss: 103.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.2804 - accuracy: 0.0000e+00 - val_loss: 97.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 1127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.6528 - accuracy: 0.0156 - val_loss: 89.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 1128/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.6615 - accuracy: 0.0000e+00 - val_loss: 87.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1129/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1509 - accuracy: 0.0312 - val_loss: 77.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 1130/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 57.4943 - accuracy: 0.0000e+00 - val_loss: 74.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1131/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6115 - accuracy: 0.0000e+00 - val_loss: 78.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6031 - accuracy: 0.0000e+00 - val_loss: 102.0894 - val_accuracy: 0.0588\n",
      "Epoch 1133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.4597 - accuracy: 0.0000e+00 - val_loss: 116.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 1134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1522 - accuracy: 0.0156 - val_loss: 104.3964 - val_accuracy: 0.0588\n",
      "Epoch 1135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6049 - accuracy: 0.0000e+00 - val_loss: 86.7921 - val_accuracy: 0.0000e+00\n",
      "Epoch 1136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4232 - accuracy: 0.0156 - val_loss: 76.8108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1137/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.1279 - accuracy: 0.0000e+00 - val_loss: 76.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 1138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7120 - accuracy: 0.0000e+00 - val_loss: 90.6188 - val_accuracy: 0.0588\n",
      "Epoch 1139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.9278 - accuracy: 0.0000e+00 - val_loss: 109.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 1140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.2685 - accuracy: 0.0000e+00 - val_loss: 118.7670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1789 - accuracy: 0.0156 - val_loss: 114.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8274 - accuracy: 0.0000e+00 - val_loss: 90.4654 - val_accuracy: 0.0588\n",
      "Epoch 1143/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 60.0701 - accuracy: 0.0000e+00 - val_loss: 73.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1144/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 85.0098 - accuracy: 0.0000e+00 - val_loss: 65.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 1145/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 85.6104 - accuracy: 0.0000e+00 - val_loss: 75.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 1146/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 65.1287 - accuracy: 0.0000e+00 - val_loss: 111.3395 - val_accuracy: 0.0000e+00\n",
      "Epoch 1147/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 75.0300 - accuracy: 0.0000e+00 - val_loss: 130.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 1148/10000\n",
      "64/64 [==============================] - 0s 314us/step - loss: 72.3327 - accuracy: 0.0000e+00 - val_loss: 129.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1149/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 67.7412 - accuracy: 0.0000e+00 - val_loss: 101.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 1150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8440 - accuracy: 0.0000e+00 - val_loss: 73.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 1151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6603 - accuracy: 0.0312 - val_loss: 68.6095 - val_accuracy: 0.0000e+00\n",
      "Epoch 1152/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 77.8444 - accuracy: 0.0156 - val_loss: 79.7994 - val_accuracy: 0.0000e+00\n",
      "Epoch 1153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.2905 - accuracy: 0.0000e+00 - val_loss: 99.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 1154/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 81.9868 - accuracy: 0.0000e+00 - val_loss: 113.6053 - val_accuracy: 0.0000e+00\n",
      "Epoch 1155/10000\n",
      "64/64 [==============================] - 0s 249us/step - loss: 79.9141 - accuracy: 0.0000e+00 - val_loss: 113.1476 - val_accuracy: 0.0000e+00\n",
      "Epoch 1156/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 67.6676 - accuracy: 0.0156 - val_loss: 108.3634 - val_accuracy: 0.0000e+00\n",
      "Epoch 1157/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 62.2024 - accuracy: 0.0000e+00 - val_loss: 101.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 1158/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 63.8773 - accuracy: 0.0000e+00 - val_loss: 99.4615 - val_accuracy: 0.0588\n",
      "Epoch 1159/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 85.7653 - accuracy: 0.0000e+00 - val_loss: 98.5954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1160/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 58.9090 - accuracy: 0.0000e+00 - val_loss: 106.1740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1161/10000\n",
      "64/64 [==============================] - 0s 293us/step - loss: 72.0423 - accuracy: 0.0000e+00 - val_loss: 113.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 1162/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 85.8119 - accuracy: 0.0000e+00 - val_loss: 112.8627 - val_accuracy: 0.0000e+00\n",
      "Epoch 1163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.3913 - accuracy: 0.0000e+00 - val_loss: 103.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 1164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.3075 - accuracy: 0.0000e+00 - val_loss: 90.3734 - val_accuracy: 0.0000e+00\n",
      "Epoch 1165/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.1407 - accuracy: 0.0000e+00 - val_loss: 86.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 1166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.7307 - accuracy: 0.0000e+00 - val_loss: 103.9950 - val_accuracy: 0.0000e+00\n",
      "Epoch 1167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6548 - accuracy: 0.0000e+00 - val_loss: 114.0006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.2164 - accuracy: 0.0000e+00 - val_loss: 104.5912 - val_accuracy: 0.0000e+00\n",
      "Epoch 1169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4704 - accuracy: 0.0156 - val_loss: 82.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.3942 - accuracy: 0.0000e+00 - val_loss: 67.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 1171/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 68.5517 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 84.9446 - accuracy: 0.0000e+00 - val_loss: 66.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 1172/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 65.0749 - accuracy: 0.0156 - val_loss: 79.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 78.9879 - accuracy: 0.0312 - val_loss: 103.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 1174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4965 - accuracy: 0.0000e+00 - val_loss: 125.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 1175/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.2013 - accuracy: 0.0000e+00 - val_loss: 118.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5647 - accuracy: 0.0000e+00 - val_loss: 96.1552 - val_accuracy: 0.0588\n",
      "Epoch 1177/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.3363 - accuracy: 0.0156 - val_loss: 77.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 1178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1433 - accuracy: 0.0000e+00 - val_loss: 76.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 1179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.2682 - accuracy: 0.0156 - val_loss: 92.5924 - val_accuracy: 0.0000e+00\n",
      "Epoch 1180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4760 - accuracy: 0.0000e+00 - val_loss: 121.5497 - val_accuracy: 0.0000e+00\n",
      "Epoch 1181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5576 - accuracy: 0.0000e+00 - val_loss: 116.5546 - val_accuracy: 0.0000e+00\n",
      "Epoch 1182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.6901 - accuracy: 0.0000e+00 - val_loss: 88.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 1183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.0569 - accuracy: 0.0000e+00 - val_loss: 71.2055 - val_accuracy: 0.0000e+00\n",
      "Epoch 1184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.9048 - accuracy: 0.0000e+00 - val_loss: 70.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 1185/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.5900 - accuracy: 0.0000e+00 - val_loss: 87.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 1186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 62.9155 - accuracy: 0.0156 - val_loss: 94.1659 - val_accuracy: 0.0588\n",
      "Epoch 1187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0007 - accuracy: 0.0156 - val_loss: 101.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1188/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 76.6757 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 68.4275 - accuracy: 0.0000e+00 - val_loss: 95.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 1189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.7056 - accuracy: 0.0156 - val_loss: 85.3995 - val_accuracy: 0.0000e+00\n",
      "Epoch 1190/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 66.9395 - accuracy: 0.0000e+00 - val_loss: 72.8280 - val_accuracy: 0.0588\n",
      "Epoch 1191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5767 - accuracy: 0.0312 - val_loss: 61.9557 - val_accuracy: 0.0000e+00\n",
      "Epoch 1192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.8136 - accuracy: 0.0156 - val_loss: 66.5691 - val_accuracy: 0.0588\n",
      "Epoch 1193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9142 - accuracy: 0.0156 - val_loss: 91.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.5057 - accuracy: 0.0000e+00 - val_loss: 124.8162 - val_accuracy: 0.0000e+00\n",
      "Epoch 1195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0506 - accuracy: 0.0000e+00 - val_loss: 110.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 1196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 97.7805 - accuracy: 0.0000e+00 - val_loss: 82.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 1197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.4762 - accuracy: 0.0000e+00 - val_loss: 73.5012 - val_accuracy: 0.0588\n",
      "Epoch 1198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.8519 - accuracy: 0.0000e+00 - val_loss: 79.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 1199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.1850 - accuracy: 0.0000e+00 - val_loss: 96.5314 - val_accuracy: 0.0000e+00\n",
      "Epoch 1200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.2388 - accuracy: 0.0000e+00 - val_loss: 115.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.7962 - accuracy: 0.0156 - val_loss: 115.5597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2834 - accuracy: 0.0000e+00 - val_loss: 100.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 1203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 69.7873 - accuracy: 0.0000e+00 - val_loss: 81.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 1204/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.5148 - accuracy: 0.0000e+00 - val_loss: 78.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 1205/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 74.4536 - accuracy: 0.0000e+00 - val_loss: 79.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 1206/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 72.0411 - accuracy: 0.0000e+00 - val_loss: 81.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 1207/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 63.9601 - accuracy: 0.0000e+00 - val_loss: 90.1776 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1208/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 52.9248 - accuracy: 0.0000e+00 - val_loss: 101.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 1209/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 62.0300 - accuracy: 0.0000e+00 - val_loss: 104.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 1210/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 72.1090 - accuracy: 0.0000e+00 - val_loss: 98.4408 - val_accuracy: 0.0000e+00\n",
      "Epoch 1211/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 67.7989 - accuracy: 0.0469 - val_loss: 87.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 1212/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 73.1960 - accuracy: 0.0000e+00 - val_loss: 83.0257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1213/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 52.9470 - accuracy: 0.0000e+00 - val_loss: 90.8031 - val_accuracy: 0.0000e+00\n",
      "Epoch 1214/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 61.7466 - accuracy: 0.0000e+00 - val_loss: 94.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 1215/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 54.4179 - accuracy: 0.0000e+00 - val_loss: 99.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1216/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 55.3773 - accuracy: 0.0156 - val_loss: 97.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1217/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 66.4427 - accuracy: 0.0000e+00 - val_loss: 91.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 1218/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 42.3595 - accuracy: 0.0000e+00 - val_loss: 85.3438 - val_accuracy: 0.0588\n",
      "Epoch 1219/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 76.5086 - accuracy: 0.0000e+00 - val_loss: 82.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 1220/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 65.0335 - accuracy: 0.0000e+00 - val_loss: 87.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1221/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 51.8629 - accuracy: 0.0156 - val_loss: 92.2534 - val_accuracy: 0.0588\n",
      "Epoch 1222/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 71.3950 - accuracy: 0.0000e+00 - val_loss: 97.0640 - val_accuracy: 0.0588\n",
      "Epoch 1223/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 60.7405 - accuracy: 0.0000e+00 - val_loss: 99.6791 - val_accuracy: 0.0588\n",
      "Epoch 1224/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 48.7190 - accuracy: 0.0000e+00 - val_loss: 99.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1225/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 73.8390 - accuracy: 0.0312 - val_loss: 92.1769 - val_accuracy: 0.0588\n",
      "Epoch 1226/10000\n",
      "64/64 [==============================] - 0s 322us/step - loss: 73.2397 - accuracy: 0.0156 - val_loss: 80.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4476 - accuracy: 0.0000e+00 - val_loss: 73.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1228/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.4705 - accuracy: 0.0000e+00 - val_loss: 72.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1229/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 75.2171 - accuracy: 0.0156 - val_loss: 88.8231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1230/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 82.6309 - accuracy: 0.0000e+00 - val_loss: 107.9852 - val_accuracy: 0.0000e+00\n",
      "Epoch 1231/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 55.1576 - accuracy: 0.0000e+00 - val_loss: 112.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 1232/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 56.1247 - accuracy: 0.0000e+00 - val_loss: 98.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 1233/10000\n",
      "64/64 [==============================] - 0s 252us/step - loss: 75.5129 - accuracy: 0.0156 - val_loss: 81.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 1234/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 73.4752 - accuracy: 0.0000e+00 - val_loss: 77.0491 - val_accuracy: 0.0000e+00\n",
      "Epoch 1235/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 84.0485 - accuracy: 0.0000e+00 - val_loss: 97.3618 - val_accuracy: 0.0588\n",
      "Epoch 1236/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 60.8554 - accuracy: 0.0000e+00 - val_loss: 114.2253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3408 - accuracy: 0.0000e+00 - val_loss: 111.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1238/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 68.1234 - accuracy: 0.0000e+00 - val_loss: 96.5917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6582 - accuracy: 0.0156 - val_loss: 84.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1240/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 57.8563 - accuracy: 0.0156 - val_loss: 78.8236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5946 - accuracy: 0.0000e+00 - val_loss: 80.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 1242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.7127 - accuracy: 0.0000e+00 - val_loss: 90.3300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1243/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.9571 - accuracy: 0.0000e+00 - val_loss: 101.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 68.0680 - accuracy: 0.0000e+00 - val_loss: 101.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.6023 - accuracy: 0.0000e+00 - val_loss: 90.3674 - val_accuracy: 0.0588\n",
      "Epoch 1246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5977 - accuracy: 0.0000e+00 - val_loss: 80.2353 - val_accuracy: 0.0588\n",
      "Epoch 1247/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.6523 - accuracy: 0.0156 - val_loss: 76.7981 - val_accuracy: 0.0588\n",
      "Epoch 1248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.7483 - accuracy: 0.0000e+00 - val_loss: 82.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 1249/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 69.1901 - accuracy: 0.0156 - val_loss: 91.0523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1250/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.9288 - accuracy: 0.0000e+00 - val_loss: 98.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 1251/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0454 - accuracy: 0.0000e+00 - val_loss: 102.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1252/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 58.9649 - accuracy: 0.0000e+00 - val_loss: 98.9925 - val_accuracy: 0.0000e+00\n",
      "Epoch 1253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2834 - accuracy: 0.0156 - val_loss: 88.8561 - val_accuracy: 0.0588\n",
      "Epoch 1254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.1454 - accuracy: 0.0000e+00 - val_loss: 81.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 1255/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 50.4857 - accuracy: 0.0000e+00 - val_loss: 90.3257 - val_accuracy: 0.0588\n",
      "Epoch 1256/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.4727 - accuracy: 0.0000e+00 - val_loss: 98.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 1257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.0660 - accuracy: 0.0000e+00 - val_loss: 91.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 1258/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.7160 - accuracy: 0.0000e+00 - val_loss: 93.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 1259/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2130 - accuracy: 0.0156 - val_loss: 88.6447 - val_accuracy: 0.0000e+00\n",
      "Epoch 1260/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7305 - accuracy: 0.0000e+00 - val_loss: 82.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 1261/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 74.2225 - accuracy: 0.031 - 0s 125us/step - loss: 65.8651 - accuracy: 0.0156 - val_loss: 81.9385 - val_accuracy: 0.0000e+00\n",
      "Epoch 1262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4780 - accuracy: 0.0000e+00 - val_loss: 90.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 1263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7433 - accuracy: 0.0000e+00 - val_loss: 104.8600 - val_accuracy: 0.0000e+00\n",
      "Epoch 1264/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.7256 - accuracy: 0.0000e+00 - val_loss: 97.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 1265/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 60.0940 - accuracy: 0.0312 - val_loss: 84.3077 - val_accuracy: 0.0000e+00\n",
      "Epoch 1266/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.0464 - accuracy: 0.0000e+00 - val_loss: 75.3254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1267/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.9889 - accuracy: 0.0000e+00 - val_loss: 80.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1268/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 71.6806 - accuracy: 0.0156 - val_loss: 81.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.9318 - accuracy: 0.0156 - val_loss: 88.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 1270/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.5098 - accuracy: 0.0156 - val_loss: 98.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 1271/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.3763 - accuracy: 0.0156 - val_loss: 105.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1272/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.8978 - accuracy: 0.0156 - val_loss: 102.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1273/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9472 - accuracy: 0.0000e+00 - val_loss: 95.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1274/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1160 - accuracy: 0.0000e+00 - val_loss: 90.8654 - val_accuracy: 0.0588\n",
      "Epoch 1275/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 52.1998 - accuracy: 0.0000e+00 - val_loss: 90.2103 - val_accuracy: 0.0588\n",
      "Epoch 1276/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1797 - accuracy: 0.0000e+00 - val_loss: 95.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 1277/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.0828 - accuracy: 0.0000e+00 - val_loss: 103.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1278/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 86.3838 - accuracy: 0.0000e+00 - val_loss: 94.9758 - val_accuracy: 0.0000e+00\n",
      "Epoch 1279/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3945 - accuracy: 0.0000e+00 - val_loss: 88.1435 - val_accuracy: 0.0000e+00\n",
      "Epoch 1280/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5943 - accuracy: 0.0000e+00 - val_loss: 90.7039 - val_accuracy: 0.0000e+00\n",
      "Epoch 1281/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.0818 - accuracy: 0.0000e+00 - val_loss: 84.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 1282/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.7033 - accuracy: 0.0000e+00 - val_loss: 84.7570 - val_accuracy: 0.0000e+00\n",
      "Epoch 1283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6348 - accuracy: 0.0000e+00 - val_loss: 90.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3825 - accuracy: 0.0000e+00 - val_loss: 97.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 1285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9178 - accuracy: 0.0000e+00 - val_loss: 97.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 1286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.2449 - accuracy: 0.0000e+00 - val_loss: 97.2529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.7981 - accuracy: 0.0312 - val_loss: 85.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 1288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9716 - accuracy: 0.0000e+00 - val_loss: 80.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5019 - accuracy: 0.0000e+00 - val_loss: 83.7996 - val_accuracy: 0.0000e+00\n",
      "Epoch 1290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2418 - accuracy: 0.0000e+00 - val_loss: 90.9434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2397 - accuracy: 0.0000e+00 - val_loss: 97.4587 - val_accuracy: 0.0000e+00\n",
      "Epoch 1292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0973 - accuracy: 0.0000e+00 - val_loss: 103.2108 - val_accuracy: 0.0588\n",
      "Epoch 1293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5695 - accuracy: 0.0156 - val_loss: 97.9612 - val_accuracy: 0.0588\n",
      "Epoch 1294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4733 - accuracy: 0.0000e+00 - val_loss: 82.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.9871 - accuracy: 0.0000e+00 - val_loss: 69.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 1296/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.6793 - accuracy: 0.0000e+00 - val_loss: 69.2864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2593 - accuracy: 0.0000e+00 - val_loss: 78.5943 - val_accuracy: 0.0000e+00\n",
      "Epoch 1298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2868 - accuracy: 0.0000e+00 - val_loss: 92.7621 - val_accuracy: 0.0000e+00\n",
      "Epoch 1299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.8732 - accuracy: 0.0156 - val_loss: 104.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 1300/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.3077 - accuracy: 0.0156 - val_loss: 98.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1301/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.0408 - accuracy: 0.0000e+00 - val_loss: 84.3840 - val_accuracy: 0.0588\n",
      "Epoch 1302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7318 - accuracy: 0.0156 - val_loss: 73.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 1303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.1782 - accuracy: 0.0156 - val_loss: 79.0882 - val_accuracy: 0.0000e+00\n",
      "Epoch 1304/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.5599 - accuracy: 0.0156 - val_loss: 93.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 1305/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.6858 - accuracy: 0.0000e+00 - val_loss: 111.6860 - val_accuracy: 0.0588\n",
      "Epoch 1306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0022 - accuracy: 0.0000e+00 - val_loss: 112.4358 - val_accuracy: 0.0588\n",
      "Epoch 1307/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3832 - accuracy: 0.0156 - val_loss: 105.9557 - val_accuracy: 0.0588\n",
      "Epoch 1308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.0148 - accuracy: 0.0156 - val_loss: 87.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 1309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.4668 - accuracy: 0.0000e+00 - val_loss: 70.8879 - val_accuracy: 0.0000e+00\n",
      "Epoch 1310/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.2374 - accuracy: 0.0000e+00 - val_loss: 71.6598 - val_accuracy: 0.0000e+00\n",
      "Epoch 1311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2429 - accuracy: 0.0000e+00 - val_loss: 84.3737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1312/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 45.4351 - accuracy: 0.0000e+00 - val_loss: 98.5283 - val_accuracy: 0.0588\n",
      "Epoch 1313/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.7249 - accuracy: 0.0000e+00 - val_loss: 101.4241 - val_accuracy: 0.0588\n",
      "Epoch 1314/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.6742 - accuracy: 0.0000e+00 - val_loss: 87.6471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1315/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1878 - accuracy: 0.0000e+00 - val_loss: 73.7876 - val_accuracy: 0.0000e+00\n",
      "Epoch 1316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3131 - accuracy: 0.0000e+00 - val_loss: 74.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9681 - accuracy: 0.0156 - val_loss: 84.4046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0518 - accuracy: 0.0000e+00 - val_loss: 90.3693 - val_accuracy: 0.0588\n",
      "Epoch 1319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.7421 - accuracy: 0.0000e+00 - val_loss: 98.2099 - val_accuracy: 0.0000e+00\n",
      "Epoch 1320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5653 - accuracy: 0.0000e+00 - val_loss: 91.0488 - val_accuracy: 0.0000e+00\n",
      "Epoch 1321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8929 - accuracy: 0.0000e+00 - val_loss: 87.8494 - val_accuracy: 0.0588\n",
      "Epoch 1322/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0058 - accuracy: 0.0000e+00 - val_loss: 79.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.0428 - accuracy: 0.0000e+00 - val_loss: 78.7512 - val_accuracy: 0.0000e+00\n",
      "Epoch 1324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.8397 - accuracy: 0.0312 - val_loss: 81.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 1325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2816 - accuracy: 0.0000e+00 - val_loss: 84.1581 - val_accuracy: 0.0588\n",
      "Epoch 1326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4589 - accuracy: 0.0156 - val_loss: 87.2961 - val_accuracy: 0.0588\n",
      "Epoch 1327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0849 - accuracy: 0.0000e+00 - val_loss: 84.9297 - val_accuracy: 0.0588\n",
      "Epoch 1328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.9184 - accuracy: 0.0000e+00 - val_loss: 82.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8639 - accuracy: 0.0000e+00 - val_loss: 86.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 1330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4037 - accuracy: 0.0156 - val_loss: 95.3284 - val_accuracy: 0.0588\n",
      "Epoch 1331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.9607 - accuracy: 0.0000e+00 - val_loss: 100.2414 - val_accuracy: 0.0588\n",
      "Epoch 1332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9988 - accuracy: 0.0000e+00 - val_loss: 99.9313 - val_accuracy: 0.0588\n",
      "Epoch 1333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.4161 - accuracy: 0.0000e+00 - val_loss: 91.3012 - val_accuracy: 0.0000e+00\n",
      "Epoch 1334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3824 - accuracy: 0.0000e+00 - val_loss: 84.5952 - val_accuracy: 0.0000e+00\n",
      "Epoch 1335/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.0746 - accuracy: 0.0000e+00 - val_loss: 83.4072 - val_accuracy: 0.0000e+00\n",
      "Epoch 1336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5242 - accuracy: 0.0312 - val_loss: 89.2119 - val_accuracy: 0.0588\n",
      "Epoch 1337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.1301 - accuracy: 0.0312 - val_loss: 105.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 1338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4093 - accuracy: 0.0000e+00 - val_loss: 108.3841 - val_accuracy: 0.0000e+00\n",
      "Epoch 1339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4734 - accuracy: 0.0156 - val_loss: 98.7082 - val_accuracy: 0.0000e+00\n",
      "Epoch 1340/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3281 - accuracy: 0.0156 - val_loss: 89.7788 - val_accuracy: 0.0588\n",
      "Epoch 1341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1809 - accuracy: 0.0000e+00 - val_loss: 83.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 1342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.4849 - accuracy: 0.0000e+00 - val_loss: 99.6446 - val_accuracy: 0.0000e+00\n",
      "Epoch 1343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.8307 - accuracy: 0.0000e+00 - val_loss: 102.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 1344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.0386 - accuracy: 0.0000e+00 - val_loss: 93.6200 - val_accuracy: 0.0588\n",
      "Epoch 1345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1378 - accuracy: 0.0000e+00 - val_loss: 85.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6784 - accuracy: 0.0000e+00 - val_loss: 78.2881 - val_accuracy: 0.0000e+00\n",
      "Epoch 1347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2459 - accuracy: 0.0000e+00 - val_loss: 75.9975 - val_accuracy: 0.0000e+00\n",
      "Epoch 1348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3632 - accuracy: 0.0000e+00 - val_loss: 86.4354 - val_accuracy: 0.0000e+00\n",
      "Epoch 1349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9051 - accuracy: 0.0000e+00 - val_loss: 98.7197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1063 - accuracy: 0.0000e+00 - val_loss: 96.8771 - val_accuracy: 0.0000e+00\n",
      "Epoch 1351/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.7986 - accuracy: 0.0000e+00 - val_loss: 89.9879 - val_accuracy: 0.0588\n",
      "Epoch 1352/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4389 - accuracy: 0.0000e+00 - val_loss: 91.3871 - val_accuracy: 0.0588\n",
      "Epoch 1353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1382 - accuracy: 0.0000e+00 - val_loss: 95.4655 - val_accuracy: 0.0588\n",
      "Epoch 1354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3316 - accuracy: 0.0156 - val_loss: 95.5454 - val_accuracy: 0.0000e+00\n",
      "Epoch 1355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.9498 - accuracy: 0.0000e+00 - val_loss: 98.3997 - val_accuracy: 0.0000e+00\n",
      "Epoch 1356/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.4659 - accuracy: 0.0000e+00 - val_loss: 93.2725 - val_accuracy: 0.0000e+00\n",
      "Epoch 1357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6885 - accuracy: 0.0000e+00 - val_loss: 93.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 1358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0240 - accuracy: 0.0000e+00 - val_loss: 92.2782 - val_accuracy: 0.0000e+00\n",
      "Epoch 1359/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 74.4669 - accuracy: 0.0000e+00 - val_loss: 103.6517 - val_accuracy: 0.0588\n",
      "Epoch 1360/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9601 - accuracy: 0.0000e+00 - val_loss: 112.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 1361/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.3064 - accuracy: 0.0156 - val_loss: 103.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 1362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4449 - accuracy: 0.0000e+00 - val_loss: 84.5293 - val_accuracy: 0.0588\n",
      "Epoch 1363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0926 - accuracy: 0.0156 - val_loss: 76.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 1364/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 88.2736 - accuracy: 0.0000e+00 - val_loss: 79.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 1365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.0049 - accuracy: 0.0000e+00 - val_loss: 91.3210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2744 - accuracy: 0.0000e+00 - val_loss: 98.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 1367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1114 - accuracy: 0.0000e+00 - val_loss: 94.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 1368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5747 - accuracy: 0.0000e+00 - val_loss: 86.3369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 61.7813 - accuracy: 0.0156 - val_loss: 82.3249 - val_accuracy: 0.0000e+00\n",
      "Epoch 1370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6208 - accuracy: 0.0156 - val_loss: 85.7313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7671 - accuracy: 0.0000e+00 - val_loss: 85.3707 - val_accuracy: 0.0000e+00\n",
      "Epoch 1372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8016 - accuracy: 0.0000e+00 - val_loss: 92.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.1172 - accuracy: 0.0000e+00 - val_loss: 100.8699 - val_accuracy: 0.0588\n",
      "Epoch 1374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6097 - accuracy: 0.0000e+00 - val_loss: 103.9951 - val_accuracy: 0.0588\n",
      "Epoch 1375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7086 - accuracy: 0.0000e+00 - val_loss: 96.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 1376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7636 - accuracy: 0.0000e+00 - val_loss: 92.1729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9718 - accuracy: 0.0156 - val_loss: 88.1304 - val_accuracy: 0.0588\n",
      "Epoch 1378/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1518 - accuracy: 0.0000e+00 - val_loss: 96.3391 - val_accuracy: 0.0000e+00\n",
      "Epoch 1379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.7790 - accuracy: 0.0000e+00 - val_loss: 103.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 1380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9063 - accuracy: 0.0000e+00 - val_loss: 112.5369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7686 - accuracy: 0.0000e+00 - val_loss: 102.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2287 - accuracy: 0.0000e+00 - val_loss: 93.5323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1383/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2345 - accuracy: 0.0000e+00 - val_loss: 86.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1384/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.3433 - accuracy: 0.0000e+00 - val_loss: 85.3105 - val_accuracy: 0.0000e+00\n",
      "Epoch 1385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1639 - accuracy: 0.0000e+00 - val_loss: 91.6142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2860 - accuracy: 0.0000e+00 - val_loss: 88.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 1387/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.8858 - accuracy: 0.0000e+00 - val_loss: 86.9920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1820 - accuracy: 0.0000e+00 - val_loss: 92.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4520 - accuracy: 0.0000e+00 - val_loss: 99.6287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1703 - accuracy: 0.0156 - val_loss: 98.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4041 - accuracy: 0.0156 - val_loss: 97.6340 - val_accuracy: 0.0000e+00\n",
      "Epoch 1392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9847 - accuracy: 0.0000e+00 - val_loss: 88.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1027 - accuracy: 0.0156 - val_loss: 75.8890 - val_accuracy: 0.0588\n",
      "Epoch 1394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2967 - accuracy: 0.0000e+00 - val_loss: 86.2720 - val_accuracy: 0.0000e+00\n",
      "Epoch 1395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1343 - accuracy: 0.0000e+00 - val_loss: 102.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 1396/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.0085 - accuracy: 0.0000e+00 - val_loss: 111.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 1397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.7639 - accuracy: 0.0156 - val_loss: 94.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6477 - accuracy: 0.0156 - val_loss: 83.3447 - val_accuracy: 0.0588\n",
      "Epoch 1399/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4387 - accuracy: 0.0000e+00 - val_loss: 82.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6615 - accuracy: 0.0000e+00 - val_loss: 92.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 1401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.5110 - accuracy: 0.0000e+00 - val_loss: 111.8509 - val_accuracy: 0.0000e+00\n",
      "Epoch 1402/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.9388 - accuracy: 0.0000e+00 - val_loss: 113.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 1403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.1840 - accuracy: 0.0000e+00 - val_loss: 96.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6943 - accuracy: 0.0000e+00 - val_loss: 75.8477 - val_accuracy: 0.0588\n",
      "Epoch 1405/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.7284 - accuracy: 0.0000e+00 - val_loss: 65.8787 - val_accuracy: 0.0000e+00\n",
      "Epoch 1406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9157 - accuracy: 0.0156 - val_loss: 75.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 1407/10000\n",
      "64/64 [==============================] - 0s 562us/step - loss: 68.5679 - accuracy: 0.0000e+00 - val_loss: 91.2931 - val_accuracy: 0.0000e+00\n",
      "Epoch 1408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2364 - accuracy: 0.0000e+00 - val_loss: 101.2953 - val_accuracy: 0.0588\n",
      "Epoch 1409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3825 - accuracy: 0.0000e+00 - val_loss: 105.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1410/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.2305 - accuracy: 0.0000e+00 - val_loss: 90.1148 - val_accuracy: 0.0588\n",
      "Epoch 1411/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 69.9170 - accuracy: 0.0000e+00 - val_loss: 78.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 1412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1636 - accuracy: 0.0000e+00 - val_loss: 74.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 1413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9938 - accuracy: 0.0000e+00 - val_loss: 90.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 1414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2550 - accuracy: 0.0000e+00 - val_loss: 100.4009 - val_accuracy: 0.0000e+00\n",
      "Epoch 1415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.9292 - accuracy: 0.0156 - val_loss: 98.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 1416/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 77.3152 - accuracy: 0.0000e+00 - val_loss: 87.6017 - val_accuracy: 0.0000e+00\n",
      "Epoch 1417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2751 - accuracy: 0.0000e+00 - val_loss: 83.2083 - val_accuracy: 0.0000e+00\n",
      "Epoch 1418/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 59.1849 - accuracy: 0.0156 - val_loss: 80.3922 - val_accuracy: 0.0000e+00\n",
      "Epoch 1419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.9974 - accuracy: 0.0156 - val_loss: 74.1124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.3497 - accuracy: 0.0000e+00 - val_loss: 69.8924 - val_accuracy: 0.0000e+00\n",
      "Epoch 1421/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.5884 - accuracy: 0.0156 - val_loss: 68.8023 - val_accuracy: 0.0000e+00\n",
      "Epoch 1422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9780 - accuracy: 0.0156 - val_loss: 67.1951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1423/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4632 - accuracy: 0.0156 - val_loss: 71.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1424/10000\n",
      "64/64 [==============================] - 0s 167us/step - loss: 62.9237 - accuracy: 0.0000e+00 - val_loss: 77.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1674 - accuracy: 0.0000e+00 - val_loss: 78.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 1426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2850 - accuracy: 0.0000e+00 - val_loss: 82.9391 - val_accuracy: 0.0000e+00\n",
      "Epoch 1427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.2613 - accuracy: 0.0000e+00 - val_loss: 85.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 1428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.7745 - accuracy: 0.0156 - val_loss: 86.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 1429/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.1366 - accuracy: 0.0000e+00 - val_loss: 78.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 1430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0278 - accuracy: 0.0156 - val_loss: 68.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5421 - accuracy: 0.0156 - val_loss: 66.9083 - val_accuracy: 0.0000e+00\n",
      "Epoch 1432/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9019 - accuracy: 0.0156 - val_loss: 75.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 1433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4896 - accuracy: 0.0000e+00 - val_loss: 88.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 1434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8656 - accuracy: 0.0000e+00 - val_loss: 94.7167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.3983 - accuracy: 0.0000e+00 - val_loss: 85.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1436/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.0057 - accuracy: 0.0000e+00 - val_loss: 77.3005 - val_accuracy: 0.0000e+00\n",
      "Epoch 1437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.8218 - accuracy: 0.0000e+00 - val_loss: 69.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 1438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4527 - accuracy: 0.0000e+00 - val_loss: 74.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 1439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0510 - accuracy: 0.0000e+00 - val_loss: 90.5736 - val_accuracy: 0.0000e+00\n",
      "Epoch 1440/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.2525 - accuracy: 0.0000e+00 - val_loss: 103.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1441/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.5508 - accuracy: 0.0000e+00 - val_loss: 99.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1442/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.3621 - accuracy: 0.0000e+00 - val_loss: 91.9120 - val_accuracy: 0.0588\n",
      "Epoch 1443/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.0887 - accuracy: 0.0000e+00 - val_loss: 78.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 1444/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.7316 - accuracy: 0.0156 - val_loss: 73.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 1445/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 51.1266 - accuracy: 0.0000e+00 - val_loss: 89.5049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1446/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.4277 - accuracy: 0.0000e+00 - val_loss: 103.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 1447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5339 - accuracy: 0.0156 - val_loss: 106.9407 - val_accuracy: 0.0000e+00\n",
      "Epoch 1448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.3221 - accuracy: 0.0000e+00 - val_loss: 98.3290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2810 - accuracy: 0.0000e+00 - val_loss: 86.8215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1450/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.5211 - accuracy: 0.0000e+00 - val_loss: 84.4399 - val_accuracy: 0.0588\n",
      "Epoch 1451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2455 - accuracy: 0.0000e+00 - val_loss: 87.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 1452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.2999 - accuracy: 0.0000e+00 - val_loss: 91.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1453/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.4667 - accuracy: 0.0156 - val_loss: 98.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 1454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9644 - accuracy: 0.0156 - val_loss: 93.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1455/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.7801 - accuracy: 0.0000e+00 - val_loss: 86.2739 - val_accuracy: 0.0000e+00\n",
      "Epoch 1456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9242 - accuracy: 0.0312 - val_loss: 81.7817 - val_accuracy: 0.0000e+00\n",
      "Epoch 1457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.3969 - accuracy: 0.0156 - val_loss: 76.9382 - val_accuracy: 0.0000e+00\n",
      "Epoch 1458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.1522 - accuracy: 0.0156 - val_loss: 90.6618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6290 - accuracy: 0.0000e+00 - val_loss: 103.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1460/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3407 - accuracy: 0.0156 - val_loss: 104.5560 - val_accuracy: 0.0000e+00\n",
      "Epoch 1461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1753 - accuracy: 0.0312 - val_loss: 103.3595 - val_accuracy: 0.0000e+00\n",
      "Epoch 1462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8407 - accuracy: 0.0000e+00 - val_loss: 91.4492 - val_accuracy: 0.0588\n",
      "Epoch 1463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.3412 - accuracy: 0.0000e+00 - val_loss: 79.8344 - val_accuracy: 0.0000e+00\n",
      "Epoch 1464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5307 - accuracy: 0.0156 - val_loss: 83.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7501 - accuracy: 0.0156 - val_loss: 95.9998 - val_accuracy: 0.0588\n",
      "Epoch 1466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0371 - accuracy: 0.0156 - val_loss: 101.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 1467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.1055 - accuracy: 0.0156 - val_loss: 99.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1468/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.7856 - accuracy: 0.0156 - val_loss: 90.0106 - val_accuracy: 0.0588\n",
      "Epoch 1469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3340 - accuracy: 0.0000e+00 - val_loss: 83.8114 - val_accuracy: 0.0588\n",
      "Epoch 1470/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.4533 - accuracy: 0.0000e+00 - val_loss: 75.5590 - val_accuracy: 0.0000e+00\n",
      "Epoch 1471/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.5361 - accuracy: 0.0000e+00 - val_loss: 75.4027 - val_accuracy: 0.0000e+00\n",
      "Epoch 1472/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 65.7234 - accuracy: 0.0000e+00 - val_loss: 73.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 1473/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2291 - accuracy: 0.0000e+00 - val_loss: 80.5792 - val_accuracy: 0.0588\n",
      "Epoch 1474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.7826 - accuracy: 0.0156 - val_loss: 81.4757 - val_accuracy: 0.0000e+00\n",
      "Epoch 1475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.3583 - accuracy: 0.0156 - val_loss: 83.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 1476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.5023 - accuracy: 0.0000e+00 - val_loss: 93.4680 - val_accuracy: 0.0000e+00\n",
      "Epoch 1477/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.8581 - accuracy: 0.0156 - val_loss: 90.5148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.7325 - accuracy: 0.0000e+00 - val_loss: 86.5654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1479/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.1097 - accuracy: 0.0000e+00 - val_loss: 80.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2560 - accuracy: 0.0000e+00 - val_loss: 84.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 1481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3231 - accuracy: 0.0000e+00 - val_loss: 87.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 1482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.5298 - accuracy: 0.0156 - val_loss: 99.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1483/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.8879 - accuracy: 0.0000e+00 - val_loss: 98.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 1484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.9614 - accuracy: 0.0000e+00 - val_loss: 92.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 1485/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 58.1942 - accuracy: 0.0000e+00 - val_loss: 86.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 1486/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5555 - accuracy: 0.0000e+00 - val_loss: 90.1527 - val_accuracy: 0.0588\n",
      "Epoch 1487/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.4638 - accuracy: 0.0000e+00 - val_loss: 101.8508 - val_accuracy: 0.0000e+00\n",
      "Epoch 1488/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1141 - accuracy: 0.0156 - val_loss: 108.3880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1489/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 54.7830 - accuracy: 0.0000e+00 - val_loss: 117.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 1490/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1488 - accuracy: 0.0156 - val_loss: 112.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1491/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.9960 - accuracy: 0.0156 - val_loss: 99.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1492/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.5890 - accuracy: 0.0156 - val_loss: 90.0798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1493/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.4509 - accuracy: 0.0156 - val_loss: 86.5935 - val_accuracy: 0.0000e+00\n",
      "Epoch 1494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5762 - accuracy: 0.0000e+00 - val_loss: 89.3930 - val_accuracy: 0.0000e+00\n",
      "Epoch 1495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1500 - accuracy: 0.0000e+00 - val_loss: 94.7684 - val_accuracy: 0.0000e+00\n",
      "Epoch 1496/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9255 - accuracy: 0.0000e+00 - val_loss: 94.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 1497/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.4274 - accuracy: 0.0000e+0 - 0s 250us/step - loss: 67.4783 - accuracy: 0.0000e+00 - val_loss: 90.3849 - val_accuracy: 0.0000e+00\n",
      "Epoch 1498/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1404 - accuracy: 0.0000e+00 - val_loss: 79.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1499/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0511 - accuracy: 0.0000e+00 - val_loss: 82.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6225 - accuracy: 0.0156 - val_loss: 92.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 1501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1922 - accuracy: 0.0156 - val_loss: 111.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 1502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8109 - accuracy: 0.0000e+00 - val_loss: 123.6012 - val_accuracy: 0.0000e+00\n",
      "Epoch 1503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.2252 - accuracy: 0.0156 - val_loss: 117.7444 - val_accuracy: 0.0000e+00\n",
      "Epoch 1504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2238 - accuracy: 0.0000e+00 - val_loss: 94.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 1505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0527 - accuracy: 0.0000e+00 - val_loss: 78.4942 - val_accuracy: 0.0000e+00\n",
      "Epoch 1506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6022 - accuracy: 0.0000e+00 - val_loss: 74.0222 - val_accuracy: 0.0588\n",
      "Epoch 1507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5942 - accuracy: 0.0156 - val_loss: 87.0889 - val_accuracy: 0.0000e+00\n",
      "Epoch 1508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8592 - accuracy: 0.0156 - val_loss: 106.6079 - val_accuracy: 0.0000e+00\n",
      "Epoch 1509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.6666 - accuracy: 0.0000e+00 - val_loss: 101.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 1510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9048 - accuracy: 0.0156 - val_loss: 87.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.5028 - accuracy: 0.0000e+00 - val_loss: 74.3946 - val_accuracy: 0.0000e+00\n",
      "Epoch 1512/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.9473 - accuracy: 0.0000e+00 - val_loss: 77.2193 - val_accuracy: 0.0588\n",
      "Epoch 1513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4525 - accuracy: 0.0000e+00 - val_loss: 88.5462 - val_accuracy: 0.0000e+00\n",
      "Epoch 1514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4369 - accuracy: 0.0000e+00 - val_loss: 97.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 1515/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 61.4509 - accuracy: 0.0156 - val_loss: 105.6461 - val_accuracy: 0.0000e+00\n",
      "Epoch 1516/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1784 - accuracy: 0.0000e+00 - val_loss: 106.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 1517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4291 - accuracy: 0.0156 - val_loss: 92.2813 - val_accuracy: 0.0000e+00\n",
      "Epoch 1518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5158 - accuracy: 0.0000e+00 - val_loss: 81.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 1519/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.3243 - accuracy: 0.0156 - val_loss: 85.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 1520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 55.9079 - accuracy: 0.0000e+00 - val_loss: 88.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 1521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8433 - accuracy: 0.0156 - val_loss: 94.9764 - val_accuracy: 0.0000e+00\n",
      "Epoch 1522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3150 - accuracy: 0.0000e+00 - val_loss: 99.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1523/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.8375 - accuracy: 0.0000e+00 - val_loss: 98.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1524/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1773 - accuracy: 0.0000e+00 - val_loss: 89.1108 - val_accuracy: 0.0588\n",
      "Epoch 1525/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.6226 - accuracy: 0.0000e+00 - val_loss: 82.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1526/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.2645 - accuracy: 0.0000e+00 - val_loss: 82.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 1527/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.7586 - accuracy: 0.0000e+00 - val_loss: 91.0481 - val_accuracy: 0.0000e+00\n",
      "Epoch 1528/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 71.2376 - accuracy: 0.0000e+00 - val_loss: 94.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 1529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4851 - accuracy: 0.0000e+00 - val_loss: 90.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1530/10000\n",
      "64/64 [==============================] - 0s 183us/step - loss: 60.3710 - accuracy: 0.0156 - val_loss: 73.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5201 - accuracy: 0.0156 - val_loss: 64.1532 - val_accuracy: 0.0588\n",
      "Epoch 1532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3593 - accuracy: 0.0000e+00 - val_loss: 70.0547 - val_accuracy: 0.0588\n",
      "Epoch 1533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1142 - accuracy: 0.0000e+00 - val_loss: 95.7158 - val_accuracy: 0.0000e+00\n",
      "Epoch 1534/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.6830 - accuracy: 0.0000e+00 - val_loss: 103.9107 - val_accuracy: 0.0000e+00\n",
      "Epoch 1535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5458 - accuracy: 0.0000e+00 - val_loss: 98.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 1536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2416 - accuracy: 0.0156 - val_loss: 86.2171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1441 - accuracy: 0.0156 - val_loss: 79.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 1538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4987 - accuracy: 0.0000e+00 - val_loss: 80.5230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.8332 - accuracy: 0.0000e+00 - val_loss: 95.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0873 - accuracy: 0.0000e+00 - val_loss: 115.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 1541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3010 - accuracy: 0.0000e+00 - val_loss: 124.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 1542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4027 - accuracy: 0.0000e+00 - val_loss: 107.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4076 - accuracy: 0.0156 - val_loss: 88.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 1544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.9933 - accuracy: 0.0000e+00 - val_loss: 70.7232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0209 - accuracy: 0.0000e+00 - val_loss: 71.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7324 - accuracy: 0.0000e+00 - val_loss: 87.9845 - val_accuracy: 0.0000e+00\n",
      "Epoch 1547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 67.9881 - accuracy: 0.0000e+00 - val_loss: 98.7060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7363 - accuracy: 0.0000e+00 - val_loss: 94.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 1549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.8144 - accuracy: 0.0000e+00 - val_loss: 79.0460 - val_accuracy: 0.0000e+00\n",
      "Epoch 1550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3254 - accuracy: 0.0000e+00 - val_loss: 79.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9861 - accuracy: 0.0156 - val_loss: 79.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5373 - accuracy: 0.0000e+00 - val_loss: 83.0718 - val_accuracy: 0.0588\n",
      "Epoch 1553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0555 - accuracy: 0.0000e+00 - val_loss: 88.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 1554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2779 - accuracy: 0.0000e+00 - val_loss: 93.7640 - val_accuracy: 0.0000e+00\n",
      "Epoch 1555/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.9978 - accuracy: 0.0000e+00 - val_loss: 102.9044 - val_accuracy: 0.0588\n",
      "Epoch 1556/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.4908 - accuracy: 0.0469 - val_loss: 100.8565 - val_accuracy: 0.0588\n",
      "Epoch 1557/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.7673 - accuracy: 0.0000e+00 - val_loss: 100.1230 - val_accuracy: 0.0588\n",
      "Epoch 1558/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 44.3828 - accuracy: 0.0156 - val_loss: 91.6088 - val_accuracy: 0.0000e+00\n",
      "Epoch 1559/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.9101 - accuracy: 0.0312 - val_loss: 85.8470 - val_accuracy: 0.0588\n",
      "Epoch 1560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4863 - accuracy: 0.0000e+00 - val_loss: 82.8389 - val_accuracy: 0.0588\n",
      "Epoch 1561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.2347 - accuracy: 0.0156 - val_loss: 81.2866 - val_accuracy: 0.0588\n",
      "Epoch 1562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9613 - accuracy: 0.0156 - val_loss: 92.9253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5054 - accuracy: 0.0000e+00 - val_loss: 94.0351 - val_accuracy: 0.0000e+00\n",
      "Epoch 1564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0645 - accuracy: 0.0000e+00 - val_loss: 96.5384 - val_accuracy: 0.0000e+00\n",
      "Epoch 1565/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.1488 - accuracy: 0.0000e+00 - val_loss: 91.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.8899 - accuracy: 0.0000e+00 - val_loss: 87.7466 - val_accuracy: 0.0000e+00\n",
      "Epoch 1567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1430 - accuracy: 0.0000e+00 - val_loss: 85.0985 - val_accuracy: 0.0000e+00\n",
      "Epoch 1568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.0363 - accuracy: 0.0000e+00 - val_loss: 90.7407 - val_accuracy: 0.0000e+00\n",
      "Epoch 1569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0087 - accuracy: 0.0000e+00 - val_loss: 99.6740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6119 - accuracy: 0.0000e+00 - val_loss: 99.5389 - val_accuracy: 0.0000e+00\n",
      "Epoch 1571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7222 - accuracy: 0.0000e+00 - val_loss: 96.8620 - val_accuracy: 0.0000e+00\n",
      "Epoch 1572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7674 - accuracy: 0.0000e+00 - val_loss: 100.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5716 - accuracy: 0.0000e+00 - val_loss: 96.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 1574/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.1446 - accuracy: 0.0000e+00 - val_loss: 93.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 1575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3899 - accuracy: 0.0000e+00 - val_loss: 95.2815 - val_accuracy: 0.0588\n",
      "Epoch 1576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5883 - accuracy: 0.0000e+00 - val_loss: 94.3538 - val_accuracy: 0.0588\n",
      "Epoch 1577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1741 - accuracy: 0.0000e+00 - val_loss: 85.0229 - val_accuracy: 0.0588\n",
      "Epoch 1578/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7658 - accuracy: 0.0000e+00 - val_loss: 78.0585 - val_accuracy: 0.0000e+00\n",
      "Epoch 1579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4474 - accuracy: 0.0000e+00 - val_loss: 87.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.2208 - accuracy: 0.0156 - val_loss: 109.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.6967 - accuracy: 0.0000e+00 - val_loss: 114.0655 - val_accuracy: 0.0000e+00\n",
      "Epoch 1582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.1097 - accuracy: 0.0000e+00 - val_loss: 100.2809 - val_accuracy: 0.0588\n",
      "Epoch 1583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8200 - accuracy: 0.0000e+00 - val_loss: 95.8925 - val_accuracy: 0.0588\n",
      "Epoch 1584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5542 - accuracy: 0.0000e+00 - val_loss: 87.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 1585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1312 - accuracy: 0.0156 - val_loss: 94.4067 - val_accuracy: 0.0588\n",
      "Epoch 1586/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.0881 - accuracy: 0.0000e+00 - val_loss: 99.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 1587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4399 - accuracy: 0.0000e+00 - val_loss: 109.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 1588/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.5537 - accuracy: 0.0000e+00 - val_loss: 107.2803 - val_accuracy: 0.0588\n",
      "Epoch 1589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6470 - accuracy: 0.0156 - val_loss: 100.5601 - val_accuracy: 0.0000e+00\n",
      "Epoch 1590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5696 - accuracy: 0.0000e+00 - val_loss: 85.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1591/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.2597 - accuracy: 0.0312 - val_loss: 77.2880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6460 - accuracy: 0.0000e+00 - val_loss: 72.2073 - val_accuracy: 0.0000e+00\n",
      "Epoch 1593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9523 - accuracy: 0.0000e+00 - val_loss: 85.4475 - val_accuracy: 0.0000e+00\n",
      "Epoch 1594/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2451 - accuracy: 0.0156 - val_loss: 101.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.6284 - accuracy: 0.0156 - val_loss: 102.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0182 - accuracy: 0.0000e+00 - val_loss: 97.2035 - val_accuracy: 0.0588\n",
      "Epoch 1597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2890 - accuracy: 0.0000e+00 - val_loss: 86.9481 - val_accuracy: 0.0000e+00\n",
      "Epoch 1598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1533 - accuracy: 0.0000e+00 - val_loss: 78.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 1599/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 45.3596 - accuracy: 0.0156 - val_loss: 82.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1600/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.9548 - accuracy: 0.0156 - val_loss: 94.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1601/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.4720 - accuracy: 0.0000e+00 - val_loss: 96.8573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5107 - accuracy: 0.0000e+00 - val_loss: 92.2755 - val_accuracy: 0.0588\n",
      "Epoch 1603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0087 - accuracy: 0.0000e+00 - val_loss: 84.1933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1604/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.3289 - accuracy: 0.0000e+00 - val_loss: 87.3490 - val_accuracy: 0.0588\n",
      "Epoch 1605/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0430 - accuracy: 0.0156 - val_loss: 93.1945 - val_accuracy: 0.0000e+00\n",
      "Epoch 1606/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.7708 - accuracy: 0.0000e+00 - val_loss: 90.9426 - val_accuracy: 0.0588\n",
      "Epoch 1607/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1746 - accuracy: 0.0156 - val_loss: 85.0404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1608/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.7859 - accuracy: 0.0000e+00 - val_loss: 84.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1609/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 66.2322 - accuracy: 0.0156 - val_loss: 91.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6204 - accuracy: 0.0000e+00 - val_loss: 93.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5824 - accuracy: 0.0000e+00 - val_loss: 96.9482 - val_accuracy: 0.0588\n",
      "Epoch 1612/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.5711 - accuracy: 0.0000e+00 - val_loss: 90.2493 - val_accuracy: 0.0588\n",
      "Epoch 1613/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 44.7009 - accuracy: 0.0156 - val_loss: 80.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 1614/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.7541 - accuracy: 0.0312 - val_loss: 79.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1615/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.8844 - accuracy: 0.0000e+00 - val_loss: 94.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 1616/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.8198 - accuracy: 0.0000e+00 - val_loss: 103.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1617/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4098 - accuracy: 0.0000e+00 - val_loss: 97.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1618/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1468 - accuracy: 0.0000e+00 - val_loss: 88.6843 - val_accuracy: 0.0000e+00\n",
      "Epoch 1619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5133 - accuracy: 0.0156 - val_loss: 87.2661 - val_accuracy: 0.0588\n",
      "Epoch 1620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.8342 - accuracy: 0.0156 - val_loss: 94.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1621/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9345 - accuracy: 0.0156 - val_loss: 100.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1622/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7259 - accuracy: 0.0156 - val_loss: 94.6618 - val_accuracy: 0.0588\n",
      "Epoch 1623/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.2598 - accuracy: 0.0000e+00 - val_loss: 99.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 1624/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.9600 - accuracy: 0.0000e+00 - val_loss: 108.0782 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1625/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 52.0761 - accuracy: 0.0000e+00 - val_loss: 114.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 1626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2987 - accuracy: 0.0000e+00 - val_loss: 111.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7361 - accuracy: 0.0000e+00 - val_loss: 104.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 1628/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3463 - accuracy: 0.0000e+00 - val_loss: 90.2674 - val_accuracy: 0.0000e+00\n",
      "Epoch 1629/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.1186 - accuracy: 0.0000e+00 - val_loss: 88.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5572 - accuracy: 0.0156 - val_loss: 89.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 1631/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 59.1404 - accuracy: 0.0000e+00 - val_loss: 86.9710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7922 - accuracy: 0.0000e+00 - val_loss: 81.7636 - val_accuracy: 0.0000e+00\n",
      "Epoch 1633/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.0382 - accuracy: 0.0312 - val_loss: 80.9495 - val_accuracy: 0.0000e+00\n",
      "Epoch 1634/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7026 - accuracy: 0.0156 - val_loss: 79.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1635/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 54.8925 - accuracy: 0.0000e+00 - val_loss: 75.3892 - val_accuracy: 0.0000e+00\n",
      "Epoch 1636/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.6540 - accuracy: 0.0000e+00 - val_loss: 69.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1637/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.3299 - accuracy: 0.0000e+00 - val_loss: 78.2058 - val_accuracy: 0.0000e+00\n",
      "Epoch 1638/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.6156 - accuracy: 0.0000e+00 - val_loss: 96.9966 - val_accuracy: 0.0000e+00\n",
      "Epoch 1639/10000\n",
      "64/64 [==============================] - 0s 258us/step - loss: 51.9060 - accuracy: 0.0156 - val_loss: 108.6116 - val_accuracy: 0.0000e+00\n",
      "Epoch 1640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5942 - accuracy: 0.0000e+00 - val_loss: 120.5060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1641/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 61.0139 - accuracy: 0.0000e+00 - val_loss: 122.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1642/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.5428 - accuracy: 0.0000e+00 - val_loss: 112.5975 - val_accuracy: 0.0588\n",
      "Epoch 1643/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.9404 - accuracy: 0.0000e+00 - val_loss: 91.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 1644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9205 - accuracy: 0.0312 - val_loss: 86.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1645/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4473 - accuracy: 0.0000e+00 - val_loss: 87.0317 - val_accuracy: 0.0000e+00\n",
      "Epoch 1646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6595 - accuracy: 0.0000e+00 - val_loss: 92.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 1647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6255 - accuracy: 0.0000e+00 - val_loss: 101.2704 - val_accuracy: 0.0000e+00\n",
      "Epoch 1648/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 46.0936 - accuracy: 0.0000e+00 - val_loss: 99.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 1649/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.9315 - accuracy: 0.0000e+00 - val_loss: 94.5316 - val_accuracy: 0.0000e+00\n",
      "Epoch 1650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5944 - accuracy: 0.0156 - val_loss: 98.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1651/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.0418 - accuracy: 0.0000e+00 - val_loss: 99.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1652/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.1232 - accuracy: 0.0000e+00 - val_loss: 87.4422 - val_accuracy: 0.0588\n",
      "Epoch 1653/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 53.1070 - accuracy: 0.0312 - val_loss: 85.0274 - val_accuracy: 0.0588\n",
      "Epoch 1654/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 49.1644 - accuracy: 0.0156 - val_loss: 83.0776 - val_accuracy: 0.0588\n",
      "Epoch 1655/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.2416 - accuracy: 0.0000e+00 - val_loss: 83.0865 - val_accuracy: 0.0588\n",
      "Epoch 1656/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.0109 - accuracy: 0.0156 - val_loss: 90.5086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1657/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.8060 - accuracy: 0.0000e+00 - val_loss: 99.4969 - val_accuracy: 0.0588\n",
      "Epoch 1658/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6397 - accuracy: 0.0000e+00 - val_loss: 99.9020 - val_accuracy: 0.0000e+00\n",
      "Epoch 1659/10000\n",
      "64/64 [==============================] - 0s 204us/step - loss: 58.4342 - accuracy: 0.0156 - val_loss: 90.4464 - val_accuracy: 0.0000e+00\n",
      "Epoch 1660/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 52.1400 - accuracy: 0.0000e+00 - val_loss: 81.2246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1661/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.2021 - accuracy: 0.0000e+00 - val_loss: 77.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5450 - accuracy: 0.0000e+00 - val_loss: 86.3298 - val_accuracy: 0.0588\n",
      "Epoch 1663/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 50.9454 - accuracy: 0.0156 - val_loss: 95.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 1664/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 49.3508 - accuracy: 0.0000e+00 - val_loss: 94.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 1665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8258 - accuracy: 0.0000e+00 - val_loss: 85.1094 - val_accuracy: 0.0588\n",
      "Epoch 1666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0088 - accuracy: 0.0000e+00 - val_loss: 91.9808 - val_accuracy: 0.0000e+00\n",
      "Epoch 1667/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.6298 - accuracy: 0.0000e+00 - val_loss: 94.5909 - val_accuracy: 0.0000e+00\n",
      "Epoch 1668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1689 - accuracy: 0.0156 - val_loss: 94.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 1669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.2469 - accuracy: 0.0000e+00 - val_loss: 97.5277 - val_accuracy: 0.0588\n",
      "Epoch 1670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9102 - accuracy: 0.0000e+00 - val_loss: 101.6350 - val_accuracy: 0.0588\n",
      "Epoch 1671/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.1323 - accuracy: 0.0000e+00 - val_loss: 98.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1672/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3084 - accuracy: 0.0156 - val_loss: 99.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 1673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.5143 - accuracy: 0.0000e+00 - val_loss: 92.7747 - val_accuracy: 0.0588\n",
      "Epoch 1674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2312 - accuracy: 0.0000e+00 - val_loss: 89.3047 - val_accuracy: 0.0588\n",
      "Epoch 1675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.6147 - accuracy: 0.0000e+00 - val_loss: 88.9565 - val_accuracy: 0.0588\n",
      "Epoch 1676/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.9668 - accuracy: 0.0000e+00 - val_loss: 91.0633 - val_accuracy: 0.0588\n",
      "Epoch 1677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.8697 - accuracy: 0.0156 - val_loss: 105.5082 - val_accuracy: 0.0588\n",
      "Epoch 1678/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.0295 - accuracy: 0.0156 - val_loss: 123.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 1679/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.7907 - accuracy: 0.0000e+00 - val_loss: 130.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 1680/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.5700 - accuracy: 0.0156 - val_loss: 116.9118 - val_accuracy: 0.0588\n",
      "Epoch 1681/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.8341 - accuracy: 0.0000e+00 - val_loss: 91.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5704 - accuracy: 0.0000e+00 - val_loss: 77.3679 - val_accuracy: 0.0588\n",
      "Epoch 1683/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.8740 - accuracy: 0.0000e+00 - val_loss: 82.6919 - val_accuracy: 0.0000e+00\n",
      "Epoch 1684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1011 - accuracy: 0.0000e+00 - val_loss: 102.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 1685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4595 - accuracy: 0.0000e+00 - val_loss: 111.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 1686/10000\n",
      "64/64 [==============================] - 0s 243us/step - loss: 66.8959 - accuracy: 0.0000e+00 - val_loss: 100.1652 - val_accuracy: 0.0000e+00\n",
      "Epoch 1687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8101 - accuracy: 0.0000e+00 - val_loss: 86.0942 - val_accuracy: 0.0000e+00\n",
      "Epoch 1688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3187 - accuracy: 0.0156 - val_loss: 77.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 1689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.9634 - accuracy: 0.0000e+00 - val_loss: 76.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0189 - accuracy: 0.0156 - val_loss: 88.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1691/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.9473 - accuracy: 0.0000e+00 - val_loss: 97.1616 - val_accuracy: 0.0000e+00\n",
      "Epoch 1692/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.3426 - accuracy: 0.0000e+00 - val_loss: 92.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 1693/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.8909 - accuracy: 0.0000e+00 - val_loss: 81.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 1694/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.1375 - accuracy: 0.0000e+00 - val_loss: 70.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 1695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.2116 - accuracy: 0.0000e+00 - val_loss: 72.3910 - val_accuracy: 0.0000e+00\n",
      "Epoch 1696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8530 - accuracy: 0.0000e+00 - val_loss: 89.5992 - val_accuracy: 0.0000e+00\n",
      "Epoch 1697/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.1486 - accuracy: 0.0000e+00 - val_loss: 99.2291 - val_accuracy: 0.0000e+00\n",
      "Epoch 1698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2989 - accuracy: 0.0000e+00 - val_loss: 105.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1699/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3435 - accuracy: 0.0000e+00 - val_loss: 103.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1700/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.7433 - accuracy: 0.0000e+00 - val_loss: 96.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.5011 - accuracy: 0.0156 - val_loss: 96.5536 - val_accuracy: 0.0000e+00\n",
      "Epoch 1702/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.4894 - accuracy: 0.0312 - val_loss: 108.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4755 - accuracy: 0.0000e+00 - val_loss: 116.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 1704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1741 - accuracy: 0.0000e+00 - val_loss: 102.8830 - val_accuracy: 0.0000e+00\n",
      "Epoch 1705/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.1903 - accuracy: 0.0000e+00 - val_loss: 84.5857 - val_accuracy: 0.0000e+00\n",
      "Epoch 1706/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.8431 - accuracy: 0.0156 - val_loss: 84.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 1707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4838 - accuracy: 0.0000e+00 - val_loss: 84.9564 - val_accuracy: 0.0000e+00\n",
      "Epoch 1708/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 67.6289 - accuracy: 0.0000e+00 - val_loss: 95.7894 - val_accuracy: 0.0000e+00\n",
      "Epoch 1709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7915 - accuracy: 0.0156 - val_loss: 120.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1710/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3027 - accuracy: 0.0000e+00 - val_loss: 120.5347 - val_accuracy: 0.0000e+00\n",
      "Epoch 1711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2753 - accuracy: 0.0000e+00 - val_loss: 104.3027 - val_accuracy: 0.0588\n",
      "Epoch 1712/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 52.7159 - accuracy: 0.0000e+00 - val_loss: 80.8280 - val_accuracy: 0.0000e+00\n",
      "Epoch 1713/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 54.0830 - accuracy: 0.0000e+00 - val_loss: 80.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 1714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8136 - accuracy: 0.0156 - val_loss: 88.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 1715/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 52.1770 - accuracy: 0.0000e+00 - val_loss: 100.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1716/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5307 - accuracy: 0.0000e+00 - val_loss: 100.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 1717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9587 - accuracy: 0.0000e+00 - val_loss: 95.5231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2084 - accuracy: 0.0000e+00 - val_loss: 93.3175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1719/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.6618 - accuracy: 0.0156 - val_loss: 80.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 1720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0759 - accuracy: 0.0156 - val_loss: 78.7222 - val_accuracy: 0.0000e+00\n",
      "Epoch 1721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.7479 - accuracy: 0.0156 - val_loss: 87.8352 - val_accuracy: 0.0588\n",
      "Epoch 1722/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 38.9997 - accuracy: 0.0000e+00 - val_loss: 104.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1723/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.5678 - accuracy: 0.0000e+00 - val_loss: 124.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 1724/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 60.5503 - accuracy: 0.0156 - val_loss: 104.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.6063 - accuracy: 0.0000e+00 - val_loss: 82.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1726/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.8163 - accuracy: 0.0000e+00 - val_loss: 77.7424 - val_accuracy: 0.0000e+00\n",
      "Epoch 1727/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.8022 - accuracy: 0.0156 - val_loss: 81.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1728/10000\n",
      "64/64 [==============================] - 0s 227us/step - loss: 69.5029 - accuracy: 0.0156 - val_loss: 91.8786 - val_accuracy: 0.0588\n",
      "Epoch 1729/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 38.3530 - accuracy: 0.0000e+00 - val_loss: 99.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1730/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.9909 - accuracy: 0.0156 - val_loss: 93.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 1731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.4944 - accuracy: 0.0000e+00 - val_loss: 80.2671 - val_accuracy: 0.0588\n",
      "Epoch 1732/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 55.2904 - accuracy: 0.0000e+00 - val_loss: 76.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 1733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2544 - accuracy: 0.0000e+00 - val_loss: 78.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1734/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 58.2914 - accuracy: 0.0000e+00 - val_loss: 90.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 1735/10000\n",
      "64/64 [==============================] - 0s 185us/step - loss: 51.2471 - accuracy: 0.0000e+00 - val_loss: 96.5457 - val_accuracy: 0.0588\n",
      "Epoch 1736/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 64.5556 - accuracy: 0.0000e+00 - val_loss: 96.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1737/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.6208 - accuracy: 0.0156 - val_loss: 91.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3793 - accuracy: 0.0156 - val_loss: 85.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1739/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 65.5605 - accuracy: 0.0156 - val_loss: 87.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 1740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7896 - accuracy: 0.0000e+00 - val_loss: 96.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 1741/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.2496 - accuracy: 0.0000e+00 - val_loss: 103.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 1742/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0847 - accuracy: 0.0156 - val_loss: 96.8297 - val_accuracy: 0.0000e+00\n",
      "Epoch 1743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.2738 - accuracy: 0.0312 - val_loss: 80.7521 - val_accuracy: 0.0000e+00\n",
      "Epoch 1744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5262 - accuracy: 0.0000e+00 - val_loss: 85.1731 - val_accuracy: 0.0588\n",
      "Epoch 1745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5310 - accuracy: 0.0000e+00 - val_loss: 102.8175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1746/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0375 - accuracy: 0.0156 - val_loss: 114.3986 - val_accuracy: 0.0000e+00\n",
      "Epoch 1747/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 56.2388 - accuracy: 0.0000e+00 - val_loss: 113.2951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1748/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.2222 - accuracy: 0.0156 - val_loss: 106.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1749/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.3193 - accuracy: 0.0156 - val_loss: 89.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 1750/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 52.9028 - accuracy: 0.0156 - val_loss: 86.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 1751/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9753 - accuracy: 0.0156 - val_loss: 87.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 1752/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7903 - accuracy: 0.0156 - val_loss: 97.3716 - val_accuracy: 0.0000e+00\n",
      "Epoch 1753/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.6358 - accuracy: 0.0000e+00 - val_loss: 99.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 1754/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 53.6912 - accuracy: 0.0000e+00 - val_loss: 104.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9976 - accuracy: 0.0156 - val_loss: 99.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1756/10000\n",
      "64/64 [==============================] - 0s 216us/step - loss: 53.7569 - accuracy: 0.0156 - val_loss: 84.9798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6675 - accuracy: 0.0156 - val_loss: 74.2738 - val_accuracy: 0.0000e+00\n",
      "Epoch 1758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3747 - accuracy: 0.0000e+00 - val_loss: 67.9981 - val_accuracy: 0.0000e+00\n",
      "Epoch 1759/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 68.5030 - accuracy: 0.0000e+00 - val_loss: 76.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 1760/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3674 - accuracy: 0.0000e+00 - val_loss: 92.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 1761/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0922 - accuracy: 0.0000e+00 - val_loss: 90.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 1762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1782 - accuracy: 0.0000e+00 - val_loss: 87.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 1763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.2861 - accuracy: 0.0000e+00 - val_loss: 80.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 1764/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.9352 - accuracy: 0.0000e+00 - val_loss: 81.9272 - val_accuracy: 0.0000e+00\n",
      "Epoch 1765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1480 - accuracy: 0.0000e+00 - val_loss: 87.1550 - val_accuracy: 0.0000e+00\n",
      "Epoch 1766/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 67.1688 - accuracy: 0.0000e+00 - val_loss: 90.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1767/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 53.1320 - accuracy: 0.0156 - val_loss: 89.5676 - val_accuracy: 0.0588\n",
      "Epoch 1768/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8865 - accuracy: 0.0156 - val_loss: 88.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 1769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.9801 - accuracy: 0.0000e+00 - val_loss: 96.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 1770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7201 - accuracy: 0.0000e+00 - val_loss: 96.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1771/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.4270 - accuracy: 0.0156 - val_loss: 99.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 1772/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3877 - accuracy: 0.0156 - val_loss: 97.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 1773/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.8502 - accuracy: 0.0156 - val_loss: 90.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 1774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.8664 - accuracy: 0.0156 - val_loss: 85.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 1775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0830 - accuracy: 0.0000e+00 - val_loss: 84.7404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1776/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.0331 - accuracy: 0.0156 - val_loss: 85.9836 - val_accuracy: 0.0588\n",
      "Epoch 1777/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 46.9491 - accuracy: 0.0000e+00 - val_loss: 90.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 1778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7106 - accuracy: 0.0000e+00 - val_loss: 96.7737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1779/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 70.7278 - accuracy: 0.0000e+00 - val_loss: 100.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 1780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5869 - accuracy: 0.0000e+00 - val_loss: 94.9663 - val_accuracy: 0.0000e+00\n",
      "Epoch 1781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.6468 - accuracy: 0.0000e+00 - val_loss: 80.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 1782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4515 - accuracy: 0.0156 - val_loss: 74.9606 - val_accuracy: 0.0000e+00\n",
      "Epoch 1783/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 64.2750 - accuracy: 0.0156 - val_loss: 84.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 1784/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.5682 - accuracy: 0.0156 - val_loss: 85.6722 - val_accuracy: 0.0000e+00\n",
      "Epoch 1785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7966 - accuracy: 0.0000e+00 - val_loss: 91.5235 - val_accuracy: 0.0588\n",
      "Epoch 1786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8506 - accuracy: 0.0000e+00 - val_loss: 86.6954 - val_accuracy: 0.0588\n",
      "Epoch 1787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3729 - accuracy: 0.0000e+00 - val_loss: 81.3878 - val_accuracy: 0.0588\n",
      "Epoch 1788/10000\n",
      "64/64 [==============================] - 0s 213us/step - loss: 52.2524 - accuracy: 0.0000e+00 - val_loss: 78.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 1789/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 54.8013 - accuracy: 0.0000e+00 - val_loss: 82.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 1790/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8859 - accuracy: 0.0000e+00 - val_loss: 86.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 1791/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 55.7221 - accuracy: 0.0156 - val_loss: 96.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4047 - accuracy: 0.0000e+00 - val_loss: 94.8151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1793/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 66.0332 - accuracy: 0.0156 - val_loss: 93.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 1794/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.3358 - accuracy: 0.0000e+00 - val_loss: 87.3864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4245 - accuracy: 0.0000e+00 - val_loss: 85.4618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3638 - accuracy: 0.0156 - val_loss: 96.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 1797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2717 - accuracy: 0.0000e+00 - val_loss: 104.2324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.0461 - accuracy: 0.0312 - val_loss: 89.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1799/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 57.4624 - accuracy: 0.0000e+00 - val_loss: 74.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1800/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 46.5889 - accuracy: 0.0156 - val_loss: 75.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1043 - accuracy: 0.0000e+00 - val_loss: 83.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1094 - accuracy: 0.0000e+00 - val_loss: 91.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 1803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.1480 - accuracy: 0.0156 - val_loss: 101.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 1804/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.3157 - accuracy: 0.0312 - val_loss: 104.9503 - val_accuracy: 0.0588\n",
      "Epoch 1805/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2610 - accuracy: 0.0000e+00 - val_loss: 95.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 1806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5499 - accuracy: 0.0000e+00 - val_loss: 89.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 1807/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 51.8137 - accuracy: 0.0000e+00 - val_loss: 87.3540 - val_accuracy: 0.0000e+00\n",
      "Epoch 1808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3791 - accuracy: 0.0000e+00 - val_loss: 84.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4398 - accuracy: 0.0000e+00 - val_loss: 85.3492 - val_accuracy: 0.0000e+00\n",
      "Epoch 1810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.1566 - accuracy: 0.0000e+00 - val_loss: 81.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9853 - accuracy: 0.0000e+00 - val_loss: 78.9747 - val_accuracy: 0.0000e+00\n",
      "Epoch 1812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4198 - accuracy: 0.0156 - val_loss: 80.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 1813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4160 - accuracy: 0.0156 - val_loss: 102.1330 - val_accuracy: 0.0588\n",
      "Epoch 1814/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8253 - accuracy: 0.0000e+00 - val_loss: 108.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 1815/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.8005 - accuracy: 0.0312 - val_loss: 97.4451 - val_accuracy: 0.0588\n",
      "Epoch 1816/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 56.0193 - accuracy: 0.0156 - val_loss: 85.2396 - val_accuracy: 0.0000e+00\n",
      "Epoch 1817/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 46.5892 - accuracy: 0.0000e+00 - val_loss: 80.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 1818/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 63.5668 - accuracy: 0.0000e+00 - val_loss: 86.1142 - val_accuracy: 0.0588\n",
      "Epoch 1819/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.4656 - accuracy: 0.0156 - val_loss: 96.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 1820/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.4490 - accuracy: 0.0469 - val_loss: 97.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 1821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.7280 - accuracy: 0.0000e+00 - val_loss: 94.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 1822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7536 - accuracy: 0.0156 - val_loss: 81.4467 - val_accuracy: 0.0588\n",
      "Epoch 1823/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.0350 - accuracy: 0.0312 - val_loss: 84.7762 - val_accuracy: 0.0588\n",
      "Epoch 1824/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.4686 - accuracy: 0.0000e+00 - val_loss: 84.8120 - val_accuracy: 0.0588\n",
      "Epoch 1825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2656 - accuracy: 0.0000e+00 - val_loss: 90.2585 - val_accuracy: 0.0588\n",
      "Epoch 1826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5419 - accuracy: 0.0156 - val_loss: 98.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 1827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2445 - accuracy: 0.0000e+00 - val_loss: 92.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 1828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.4802 - accuracy: 0.0000e+00 - val_loss: 92.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 1829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2204 - accuracy: 0.0000e+00 - val_loss: 98.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 1830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9909 - accuracy: 0.0000e+00 - val_loss: 96.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 1831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0380 - accuracy: 0.0469 - val_loss: 89.6673 - val_accuracy: 0.0000e+00\n",
      "Epoch 1832/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 59.8638 - accuracy: 0.0156 - val_loss: 86.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6260 - accuracy: 0.0000e+00 - val_loss: 80.3497 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1284 - accuracy: 0.0000e+00 - val_loss: 86.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 1835/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.5432 - accuracy: 0.0000e+00 - val_loss: 96.1655 - val_accuracy: 0.0000e+00\n",
      "Epoch 1836/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 64.5520 - accuracy: 0.0000e+00 - val_loss: 92.9854 - val_accuracy: 0.0000e+00\n",
      "Epoch 1837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5899 - accuracy: 0.0000e+00 - val_loss: 84.5026 - val_accuracy: 0.0588\n",
      "Epoch 1838/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 56.7222 - accuracy: 0.0000e+00 - val_loss: 73.4814 - val_accuracy: 0.0588\n",
      "Epoch 1839/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 59.8624 - accuracy: 0.0000e+00 - val_loss: 73.0497 - val_accuracy: 0.0588\n",
      "Epoch 1840/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2364 - accuracy: 0.0000e+00 - val_loss: 92.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 1841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4858 - accuracy: 0.0000e+00 - val_loss: 110.6705 - val_accuracy: 0.0000e+00\n",
      "Epoch 1842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6549 - accuracy: 0.0000e+00 - val_loss: 108.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 1843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9996 - accuracy: 0.0000e+00 - val_loss: 96.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 1844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5821 - accuracy: 0.0000e+00 - val_loss: 89.4179 - val_accuracy: 0.0588\n",
      "Epoch 1845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0553 - accuracy: 0.0156 - val_loss: 88.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 1846/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 65.6194 - accuracy: 0.0156 - val_loss: 94.6271 - val_accuracy: 0.0588\n",
      "Epoch 1847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8761 - accuracy: 0.0312 - val_loss: 107.7041 - val_accuracy: 0.0588\n",
      "Epoch 1848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1910 - accuracy: 0.0000e+00 - val_loss: 122.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 1849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5289 - accuracy: 0.0156 - val_loss: 123.1457 - val_accuracy: 0.0000e+00\n",
      "Epoch 1850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8538 - accuracy: 0.0000e+00 - val_loss: 100.5318 - val_accuracy: 0.0588\n",
      "Epoch 1851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6882 - accuracy: 0.0000e+00 - val_loss: 86.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 1852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9129 - accuracy: 0.0156 - val_loss: 82.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1853/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4190 - accuracy: 0.0312 - val_loss: 84.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 1854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7355 - accuracy: 0.0000e+00 - val_loss: 92.1310 - val_accuracy: 0.0588\n",
      "Epoch 1855/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 47.6932 - accuracy: 0.0000e+00 - val_loss: 96.8869 - val_accuracy: 0.0588\n",
      "Epoch 1856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2845 - accuracy: 0.0156 - val_loss: 98.8459 - val_accuracy: 0.0588\n",
      "Epoch 1857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1180 - accuracy: 0.0000e+00 - val_loss: 100.9430 - val_accuracy: 0.0588\n",
      "Epoch 1858/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 61.1154 - accuracy: 0.0000e+00 - val_loss: 92.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1859/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 48.9359 - accuracy: 0.0000e+00 - val_loss: 90.2838 - val_accuracy: 0.0000e+00\n",
      "Epoch 1860/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.8490 - accuracy: 0.0000e+00 - val_loss: 93.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8439 - accuracy: 0.0000e+00 - val_loss: 97.2806 - val_accuracy: 0.0000e+00\n",
      "Epoch 1862/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.6001 - accuracy: 0.0000e+00 - val_loss: 95.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1863/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.6027 - accuracy: 0.0156 - val_loss: 93.0610 - val_accuracy: 0.0588\n",
      "Epoch 1864/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 65.3778 - accuracy: 0.0000e+00 - val_loss: 99.2955 - val_accuracy: 0.0588\n",
      "Epoch 1865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1048 - accuracy: 0.0000e+00 - val_loss: 106.6160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6971 - accuracy: 0.0000e+00 - val_loss: 109.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3881 - accuracy: 0.0312 - val_loss: 104.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1868/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.2179 - accuracy: 0.031 - 0s 125us/step - loss: 49.2850 - accuracy: 0.0469 - val_loss: 91.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1869/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 54.1641 - accuracy: 0.0156 - val_loss: 92.4674 - val_accuracy: 0.0588\n",
      "Epoch 1870/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.9353 - accuracy: 0.0000e+00 - val_loss: 85.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 1871/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0972 - accuracy: 0.0156 - val_loss: 91.0233 - val_accuracy: 0.0588\n",
      "Epoch 1872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6191 - accuracy: 0.0000e+00 - val_loss: 91.6151 - val_accuracy: 0.0588\n",
      "Epoch 1873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4468 - accuracy: 0.0000e+00 - val_loss: 96.2569 - val_accuracy: 0.0000e+00\n",
      "Epoch 1874/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.4736 - accuracy: 0.0312 - val_loss: 90.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 1875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.3626 - accuracy: 0.0000e+00 - val_loss: 84.8433 - val_accuracy: 0.0588\n",
      "Epoch 1876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4210 - accuracy: 0.0000e+00 - val_loss: 78.3669 - val_accuracy: 0.0000e+00\n",
      "Epoch 1877/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2304 - accuracy: 0.0312 - val_loss: 72.4552 - val_accuracy: 0.0588\n",
      "Epoch 1878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.0953 - accuracy: 0.0000e+00 - val_loss: 74.9732 - val_accuracy: 0.0000e+00\n",
      "Epoch 1879/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 58.8609 - accuracy: 0.0000e+00 - val_loss: 94.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 1880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.7808 - accuracy: 0.0000e+00 - val_loss: 110.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 1881/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 64.9788 - accuracy: 0.0312 - val_loss: 95.5366 - val_accuracy: 0.0000e+00\n",
      "Epoch 1882/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0045 - accuracy: 0.0000e+00 - val_loss: 82.9538 - val_accuracy: 0.0000e+00\n",
      "Epoch 1883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9398 - accuracy: 0.0000e+00 - val_loss: 83.3954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1884/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0856 - accuracy: 0.0156 - val_loss: 90.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1885/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 57.1818 - accuracy: 0.0000e+00 - val_loss: 94.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 1886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6729 - accuracy: 0.0000e+00 - val_loss: 93.9934 - val_accuracy: 0.0588\n",
      "Epoch 1887/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.5129 - accuracy: 0.0312 - val_loss: 91.6025 - val_accuracy: 0.0000e+00\n",
      "Epoch 1888/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4879 - accuracy: 0.0000e+00 - val_loss: 86.7694 - val_accuracy: 0.0000e+00\n",
      "Epoch 1889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1425 - accuracy: 0.0000e+00 - val_loss: 86.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1013 - accuracy: 0.0000e+00 - val_loss: 91.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.0470 - accuracy: 0.0000e+00 - val_loss: 103.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 1892/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 55.3840 - accuracy: 0.0156 - val_loss: 105.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 1893/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.6867 - accuracy: 0.0312 - val_loss: 107.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 1894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5370 - accuracy: 0.0000e+00 - val_loss: 95.0602 - val_accuracy: 0.0000e+00\n",
      "Epoch 1895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5210 - accuracy: 0.0000e+00 - val_loss: 81.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 1896/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.8145 - accuracy: 0.0000e+00 - val_loss: 75.8453 - val_accuracy: 0.0000e+00\n",
      "Epoch 1897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6923 - accuracy: 0.0000e+00 - val_loss: 88.5328 - val_accuracy: 0.0000e+00\n",
      "Epoch 1898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0666 - accuracy: 0.0156 - val_loss: 95.6172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1899/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.5584 - accuracy: 0.0156 - val_loss: 98.5768 - val_accuracy: 0.0588\n",
      "Epoch 1900/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 42.0628 - accuracy: 0.0156 - val_loss: 92.3320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1901/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6900 - accuracy: 0.0000e+00 - val_loss: 89.1130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1902/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.7216 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 51.3457 - accuracy: 0.0000e+00 - val_loss: 92.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 1903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2030 - accuracy: 0.0000e+00 - val_loss: 87.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 1904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2467 - accuracy: 0.0000e+00 - val_loss: 84.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1905/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.5787 - accuracy: 0.0000e+00 - val_loss: 83.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2763 - accuracy: 0.0000e+00 - val_loss: 91.3200 - val_accuracy: 0.0000e+00\n",
      "Epoch 1907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9293 - accuracy: 0.0000e+00 - val_loss: 112.7712 - val_accuracy: 0.0000e+00\n",
      "Epoch 1908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3183 - accuracy: 0.0000e+00 - val_loss: 101.8605 - val_accuracy: 0.0000e+00\n",
      "Epoch 1909/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.2696 - accuracy: 0.0000e+00 - val_loss: 84.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6994 - accuracy: 0.0312 - val_loss: 83.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 1911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8202 - accuracy: 0.0000e+00 - val_loss: 81.3507 - val_accuracy: 0.0000e+00\n",
      "Epoch 1912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5486 - accuracy: 0.0000e+00 - val_loss: 81.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 1913/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.8665 - accuracy: 0.0156 - val_loss: 84.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 1914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9548 - accuracy: 0.0000e+00 - val_loss: 90.1856 - val_accuracy: 0.0000e+00\n",
      "Epoch 1915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6636 - accuracy: 0.0000e+00 - val_loss: 91.5356 - val_accuracy: 0.0000e+00\n",
      "Epoch 1916/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.5880 - accuracy: 0.0000e+00 - val_loss: 92.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 1917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6644 - accuracy: 0.0000e+00 - val_loss: 94.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 1918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.8105 - accuracy: 0.0000e+00 - val_loss: 87.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2308 - accuracy: 0.0000e+00 - val_loss: 77.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 1920/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.3931 - accuracy: 0.0156 - val_loss: 76.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 1921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9967 - accuracy: 0.0156 - val_loss: 76.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 1922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.7254 - accuracy: 0.0000e+00 - val_loss: 86.0897 - val_accuracy: 0.0000e+00\n",
      "Epoch 1923/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.7621 - accuracy: 0.0156 - val_loss: 85.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 1924/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0152 - accuracy: 0.0000e+00 - val_loss: 85.5672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1925/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.6627 - accuracy: 0.0000e+00 - val_loss: 81.5826 - val_accuracy: 0.0000e+00\n",
      "Epoch 1926/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.3830 - accuracy: 0.0000e+00 - val_loss: 82.6680 - val_accuracy: 0.0000e+00\n",
      "Epoch 1927/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.8706 - accuracy: 0.0000e+00 - val_loss: 80.3186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1928/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1496 - accuracy: 0.0312 - val_loss: 80.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 1929/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.7592 - accuracy: 0.0000e+00 - val_loss: 88.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1930/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4685 - accuracy: 0.0000e+00 - val_loss: 99.8360 - val_accuracy: 0.0000e+00\n",
      "Epoch 1931/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3880 - accuracy: 0.0312 - val_loss: 104.2643 - val_accuracy: 0.0000e+00\n",
      "Epoch 1932/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9194 - accuracy: 0.0000e+00 - val_loss: 93.6195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1323 - accuracy: 0.0000e+00 - val_loss: 80.3544 - val_accuracy: 0.0000e+00\n",
      "Epoch 1934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5259 - accuracy: 0.0000e+00 - val_loss: 73.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1935/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1980 - accuracy: 0.0312 - val_loss: 79.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 1936/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 46.3243 - accuracy: 0.0156 - val_loss: 92.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 1937/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 52.8988 - accuracy: 0.0000e+00 - val_loss: 103.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1938/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 124us/step - loss: 50.4147 - accuracy: 0.0156 - val_loss: 110.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8503 - accuracy: 0.0312 - val_loss: 104.7529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3894 - accuracy: 0.0000e+00 - val_loss: 83.4019 - val_accuracy: 0.0000e+00\n",
      "Epoch 1941/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.7224 - accuracy: 0.0000e+00 - val_loss: 76.7271 - val_accuracy: 0.0000e+00\n",
      "Epoch 1942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.7025 - accuracy: 0.0000e+00 - val_loss: 91.0523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3090 - accuracy: 0.0156 - val_loss: 115.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1944/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.0321 - accuracy: 0.0000e+00 - val_loss: 123.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 1945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1651 - accuracy: 0.0000e+00 - val_loss: 105.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6625 - accuracy: 0.0312 - val_loss: 83.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 1947/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2620 - accuracy: 0.0000e+00 - val_loss: 75.2878 - val_accuracy: 0.0000e+00\n",
      "Epoch 1948/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.2201 - accuracy: 0.0000e+00 - val_loss: 71.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1949/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1624 - accuracy: 0.0000e+00 - val_loss: 71.6531 - val_accuracy: 0.0000e+00\n",
      "Epoch 1950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1676 - accuracy: 0.0000e+00 - val_loss: 79.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 1951/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2000 - accuracy: 0.0000e+00 - val_loss: 90.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 1952/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2945 - accuracy: 0.0000e+00 - val_loss: 95.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 1953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1817 - accuracy: 0.0156 - val_loss: 88.7729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1954/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.7119 - accuracy: 0.0312 - val_loss: 85.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0741 - accuracy: 0.0000e+00 - val_loss: 81.3480 - val_accuracy: 0.0588\n",
      "Epoch 1956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 79.8568 - accuracy: 0.0000e+00 - val_loss: 84.8246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1957/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.6878 - accuracy: 0.0000e+00 - val_loss: 95.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 1958/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.6073 - accuracy: 0.0312 - val_loss: 99.3180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8858 - accuracy: 0.0000e+00 - val_loss: 86.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 1960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7281 - accuracy: 0.0000e+00 - val_loss: 72.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 1961/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5848 - accuracy: 0.0000e+00 - val_loss: 74.5006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.3616 - accuracy: 0.0000e+00 - val_loss: 101.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 1963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1090 - accuracy: 0.0000e+00 - val_loss: 125.8895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3890 - accuracy: 0.0156 - val_loss: 118.1678 - val_accuracy: 0.0000e+00\n",
      "Epoch 1965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9503 - accuracy: 0.0000e+00 - val_loss: 95.9920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1966/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.9999 - accuracy: 0.0000e+00 - val_loss: 89.0327 - val_accuracy: 0.0588\n",
      "Epoch 1967/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 75.7253 - accuracy: 0.0000e+00 - val_loss: 106.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 1968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1794 - accuracy: 0.0000e+00 - val_loss: 121.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5827 - accuracy: 0.0000e+00 - val_loss: 131.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1970/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 55.0974 - accuracy: 0.0312 - val_loss: 111.6700 - val_accuracy: 0.0000e+00\n",
      "Epoch 1971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6520 - accuracy: 0.0000e+00 - val_loss: 87.0155 - val_accuracy: 0.0588\n",
      "Epoch 1972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.9573 - accuracy: 0.0000e+00 - val_loss: 80.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1973/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.3971 - accuracy: 0.0156 - val_loss: 76.0427 - val_accuracy: 0.0000e+00\n",
      "Epoch 1974/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.7511 - accuracy: 0.0156 - val_loss: 81.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4202 - accuracy: 0.0000e+00 - val_loss: 87.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 1976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1586 - accuracy: 0.0000e+00 - val_loss: 85.8404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7097 - accuracy: 0.0000e+00 - val_loss: 92.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8910 - accuracy: 0.0000e+00 - val_loss: 97.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 1979/10000\n",
      "64/64 [==============================] - 0s 258us/step - loss: 49.1122 - accuracy: 0.0000e+00 - val_loss: 102.5018 - val_accuracy: 0.0000e+00\n",
      "Epoch 1980/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.6161 - accuracy: 0.0000e+00 - val_loss: 98.9526 - val_accuracy: 0.0000e+00\n",
      "Epoch 1981/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.6768 - accuracy: 0.0000e+00 - val_loss: 90.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1982/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 39.5370 - accuracy: 0.0156 - val_loss: 83.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 1983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6493 - accuracy: 0.0156 - val_loss: 80.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 1984/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.5542 - accuracy: 0.0000e+00 - val_loss: 86.0681 - val_accuracy: 0.0588\n",
      "Epoch 1985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4340 - accuracy: 0.0156 - val_loss: 109.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 1986/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 59.3694 - accuracy: 0.0000e+00 - val_loss: 128.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 1987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6595 - accuracy: 0.0156 - val_loss: 121.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 1988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9332 - accuracy: 0.0156 - val_loss: 98.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1972 - accuracy: 0.0000e+00 - val_loss: 87.7151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.0421 - accuracy: 0.0000e+00 - val_loss: 90.9662 - val_accuracy: 0.0000e+00\n",
      "Epoch 1991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.7242 - accuracy: 0.0156 - val_loss: 98.1451 - val_accuracy: 0.0588\n",
      "Epoch 1992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.6832 - accuracy: 0.0000e+00 - val_loss: 97.4739 - val_accuracy: 0.0588\n",
      "Epoch 1993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0204 - accuracy: 0.0000e+00 - val_loss: 96.3542 - val_accuracy: 0.0000e+00\n",
      "Epoch 1994/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 48.1650 - accuracy: 0.0156 - val_loss: 98.6735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8293 - accuracy: 0.0000e+00 - val_loss: 96.6480 - val_accuracy: 0.0000e+00\n",
      "Epoch 1996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6723 - accuracy: 0.0156 - val_loss: 94.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 1997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4580 - accuracy: 0.0000e+00 - val_loss: 94.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1998/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 49.9886 - accuracy: 0.0000e+00 - val_loss: 90.8818 - val_accuracy: 0.0588\n",
      "Epoch 1999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3358 - accuracy: 0.0000e+00 - val_loss: 94.6700 - val_accuracy: 0.0588\n",
      "Epoch 2000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4024 - accuracy: 0.0000e+00 - val_loss: 92.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 2001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0910 - accuracy: 0.0156 - val_loss: 93.5554 - val_accuracy: 0.0000e+00\n",
      "Epoch 2002/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 54.8498 - accuracy: 0.0000e+00 - val_loss: 98.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 2003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9065 - accuracy: 0.0000e+00 - val_loss: 99.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 2004/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 63.0215 - accuracy: 0.0000e+00 - val_loss: 99.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1433 - accuracy: 0.0000e+00 - val_loss: 91.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2006/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 48.7334 - accuracy: 0.0000e+00 - val_loss: 80.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2007/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 55.8248 - accuracy: 0.0000e+00 - val_loss: 68.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2008/10000\n",
      "64/64 [==============================] - 0s 185us/step - loss: 85.5239 - accuracy: 0.0000e+00 - val_loss: 74.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 2009/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.9928 - accuracy: 0.0000e+00 - val_loss: 84.2906 - val_accuracy: 0.0000e+00\n",
      "Epoch 2010/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.5461 - accuracy: 0.0000e+00 - val_loss: 83.7081 - val_accuracy: 0.0000e+00\n",
      "Epoch 2011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.7358 - accuracy: 0.0000e+00 - val_loss: 85.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 2012/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.3638 - accuracy: 0.0156 - val_loss: 87.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 2013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2920 - accuracy: 0.0000e+00 - val_loss: 85.2020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6370 - accuracy: 0.0000e+00 - val_loss: 79.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 2015/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 60.8512 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 65.1966 - accuracy: 0.0000e+00 - val_loss: 92.8911 - val_accuracy: 0.0000e+00\n",
      "Epoch 2016/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 57.5747 - accuracy: 0.0000e+00 - val_loss: 102.2088 - val_accuracy: 0.0000e+00\n",
      "Epoch 2017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5226 - accuracy: 0.0000e+00 - val_loss: 103.6869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1337 - accuracy: 0.0000e+00 - val_loss: 102.7249 - val_accuracy: 0.0000e+00\n",
      "Epoch 2019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3964 - accuracy: 0.0000e+00 - val_loss: 101.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 2020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4068 - accuracy: 0.0000e+00 - val_loss: 98.7020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4367 - accuracy: 0.0156 - val_loss: 85.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 2022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1053 - accuracy: 0.0156 - val_loss: 78.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 2023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5997 - accuracy: 0.0000e+00 - val_loss: 80.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1725 - accuracy: 0.0156 - val_loss: 87.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 2025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0019 - accuracy: 0.0000e+00 - val_loss: 93.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 2026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3455 - accuracy: 0.0156 - val_loss: 94.7468 - val_accuracy: 0.0000e+00\n",
      "Epoch 2027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2617 - accuracy: 0.0156 - val_loss: 87.9000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6197 - accuracy: 0.0000e+00 - val_loss: 87.1298 - val_accuracy: 0.0000e+00\n",
      "Epoch 2029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3861 - accuracy: 0.0156 - val_loss: 81.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 2030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0062 - accuracy: 0.0000e+00 - val_loss: 82.3531 - val_accuracy: 0.0000e+00\n",
      "Epoch 2031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0459 - accuracy: 0.0000e+00 - val_loss: 87.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.3662 - accuracy: 0.0000e+00 - val_loss: 94.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1083 - accuracy: 0.0000e+00 - val_loss: 100.5453 - val_accuracy: 0.0000e+00\n",
      "Epoch 2034/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1453 - accuracy: 0.0000e+00 - val_loss: 99.4012 - val_accuracy: 0.0000e+00\n",
      "Epoch 2035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6244 - accuracy: 0.0156 - val_loss: 93.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 2036/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0726 - accuracy: 0.0000e+00 - val_loss: 86.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1054 - accuracy: 0.0000e+00 - val_loss: 88.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 2038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0913 - accuracy: 0.0000e+00 - val_loss: 88.9619 - val_accuracy: 0.0588\n",
      "Epoch 2039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3655 - accuracy: 0.0000e+00 - val_loss: 94.7369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2040/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5046 - accuracy: 0.0000e+00 - val_loss: 97.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2988 - accuracy: 0.0156 - val_loss: 91.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 2042/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 50.3342 - accuracy: 0.0000e+00 - val_loss: 84.4871 - val_accuracy: 0.0000e+00\n",
      "Epoch 2043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1916 - accuracy: 0.0156 - val_loss: 85.8448 - val_accuracy: 0.0588\n",
      "Epoch 2044/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1327 - accuracy: 0.0000e+00 - val_loss: 101.9268 - val_accuracy: 0.0588\n",
      "Epoch 2045/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.3944 - accuracy: 0.0000e+00 - val_loss: 114.8315 - val_accuracy: 0.0000e+00\n",
      "Epoch 2046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3709 - accuracy: 0.0000e+00 - val_loss: 114.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 2047/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.8410 - accuracy: 0.0000e+00 - val_loss: 104.7463 - val_accuracy: 0.0588\n",
      "Epoch 2048/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.5805 - accuracy: 0.0312 - val_loss: 85.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3023 - accuracy: 0.0000e+00 - val_loss: 90.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 2050/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.8277 - accuracy: 0.0000e+00 - val_loss: 113.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 2051/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1654 - accuracy: 0.0156 - val_loss: 130.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 2052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8547 - accuracy: 0.0312 - val_loss: 122.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4155 - accuracy: 0.0000e+00 - val_loss: 97.2747 - val_accuracy: 0.0588\n",
      "Epoch 2054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.7859 - accuracy: 0.0000e+00 - val_loss: 84.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 2055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6397 - accuracy: 0.0000e+00 - val_loss: 85.5753 - val_accuracy: 0.0588\n",
      "Epoch 2056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3032 - accuracy: 0.0156 - val_loss: 96.0994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6839 - accuracy: 0.0000e+00 - val_loss: 107.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 2058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.6532 - accuracy: 0.0000e+00 - val_loss: 114.9651 - val_accuracy: 0.0000e+00\n",
      "Epoch 2059/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 57.7359 - accuracy: 0.0156 - val_loss: 98.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0426 - accuracy: 0.0000e+00 - val_loss: 79.1533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1177 - accuracy: 0.0000e+00 - val_loss: 75.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 2062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5273 - accuracy: 0.0156 - val_loss: 77.7230 - val_accuracy: 0.0000e+00\n",
      "Epoch 2063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.5177 - accuracy: 0.0000e+00 - val_loss: 85.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 2064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0870 - accuracy: 0.0000e+00 - val_loss: 91.0610 - val_accuracy: 0.0000e+00\n",
      "Epoch 2065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8642 - accuracy: 0.0000e+00 - val_loss: 98.7648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5530 - accuracy: 0.0156 - val_loss: 100.3137 - val_accuracy: 0.0588\n",
      "Epoch 2067/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.0652 - accuracy: 0.0156 - val_loss: 88.3596 - val_accuracy: 0.0588\n",
      "Epoch 2068/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.5759 - accuracy: 0.0000e+00 - val_loss: 88.9033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5883 - accuracy: 0.0000e+00 - val_loss: 93.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 2070/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7724 - accuracy: 0.0000e+00 - val_loss: 103.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 2071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9337 - accuracy: 0.0000e+00 - val_loss: 99.3199 - val_accuracy: 0.0588\n",
      "Epoch 2072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2372 - accuracy: 0.0000e+00 - val_loss: 97.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8157 - accuracy: 0.0000e+00 - val_loss: 101.1252 - val_accuracy: 0.0000e+00\n",
      "Epoch 2074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4727 - accuracy: 0.0000e+00 - val_loss: 110.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 2075/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.3298 - accuracy: 0.0156 - val_loss: 101.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6558 - accuracy: 0.0000e+00 - val_loss: 91.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 2077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5904 - accuracy: 0.0000e+00 - val_loss: 96.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 2078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6308 - accuracy: 0.0000e+00 - val_loss: 104.0073 - val_accuracy: 0.0588\n",
      "Epoch 2079/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 44.3990 - accuracy: 0.0000e+00 - val_loss: 97.8468 - val_accuracy: 0.0000e+00\n",
      "Epoch 2080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1771 - accuracy: 0.0000e+00 - val_loss: 88.6832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2081/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 44.4159 - accuracy: 0.0000e+00 - val_loss: 82.3836 - val_accuracy: 0.0000e+00\n",
      "Epoch 2082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6625 - accuracy: 0.0156 - val_loss: 95.7816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8071 - accuracy: 0.0000e+00 - val_loss: 117.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 2084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5487 - accuracy: 0.0000e+00 - val_loss: 122.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.8403 - accuracy: 0.0000e+00 - val_loss: 103.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 2086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2901 - accuracy: 0.0156 - val_loss: 83.2326 - val_accuracy: 0.0000e+00\n",
      "Epoch 2087/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.2605 - accuracy: 0.0000e+00 - val_loss: 80.7625 - val_accuracy: 0.0000e+00\n",
      "Epoch 2088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3790 - accuracy: 0.0000e+00 - val_loss: 90.1915 - val_accuracy: 0.0000e+00\n",
      "Epoch 2089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2884 - accuracy: 0.0000e+00 - val_loss: 94.8426 - val_accuracy: 0.0000e+00\n",
      "Epoch 2090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7322 - accuracy: 0.0000e+00 - val_loss: 86.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 2091/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 51.6034 - accuracy: 0.0000e+00 - val_loss: 83.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 2092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2050 - accuracy: 0.0000e+00 - val_loss: 100.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.8086 - accuracy: 0.0000e+00 - val_loss: 121.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4392 - accuracy: 0.0000e+00 - val_loss: 121.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7376 - accuracy: 0.0000e+00 - val_loss: 95.2808 - val_accuracy: 0.0588\n",
      "Epoch 2096/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.9962 - accuracy: 0.0000e+00 - val_loss: 79.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 2097/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 52.5315 - accuracy: 0.0000e+00 - val_loss: 82.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2098/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 68.3714 - accuracy: 0.0000e+00 - val_loss: 108.2496 - val_accuracy: 0.0000e+00\n",
      "Epoch 2099/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.0850 - accuracy: 0.0000e+00 - val_loss: 115.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.5319 - accuracy: 0.0000e+00 - val_loss: 92.7271 - val_accuracy: 0.0588\n",
      "Epoch 2101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0197 - accuracy: 0.0000e+00 - val_loss: 79.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3691 - accuracy: 0.0312 - val_loss: 76.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.4436 - accuracy: 0.0156 - val_loss: 88.5677 - val_accuracy: 0.0588\n",
      "Epoch 2104/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 45.2813 - accuracy: 0.0000e+00 - val_loss: 101.5595 - val_accuracy: 0.0000e+00\n",
      "Epoch 2105/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2877 - accuracy: 0.0000e+00 - val_loss: 104.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1151 - accuracy: 0.0156 - val_loss: 95.8134 - val_accuracy: 0.0588\n",
      "Epoch 2107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7789 - accuracy: 0.0000e+00 - val_loss: 86.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 2108/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0420 - accuracy: 0.0156 - val_loss: 91.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 2109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.2461 - accuracy: 0.0000e+00 - val_loss: 110.5816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1075 - accuracy: 0.0000e+00 - val_loss: 116.6485 - val_accuracy: 0.0000e+00\n",
      "Epoch 2111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.5714 - accuracy: 0.0156 - val_loss: 99.8495 - val_accuracy: 0.0000e+00\n",
      "Epoch 2112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1057 - accuracy: 0.0156 - val_loss: 85.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 2113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5678 - accuracy: 0.0000e+00 - val_loss: 82.0419 - val_accuracy: 0.0000e+00\n",
      "Epoch 2114/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 52.9302 - accuracy: 0.0000e+00 - val_loss: 79.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8230 - accuracy: 0.0000e+00 - val_loss: 87.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2116/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 40.9914 - accuracy: 0.0156 - val_loss: 102.5497 - val_accuracy: 0.0588\n",
      "Epoch 2117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3537 - accuracy: 0.0000e+00 - val_loss: 116.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 2118/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.6842 - accuracy: 0.0156 - val_loss: 112.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2119/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 38.6863 - accuracy: 0.0000e+00 - val_loss: 88.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 2120/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 63.0687 - accuracy: 0.0156 - val_loss: 71.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 2121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0278 - accuracy: 0.0000e+00 - val_loss: 72.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 2122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.6825 - accuracy: 0.0000e+00 - val_loss: 106.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 2123/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 66.9970 - accuracy: 0.0000e+00 - val_loss: 128.9579 - val_accuracy: 0.0000e+00\n",
      "Epoch 2124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8599 - accuracy: 0.0000e+00 - val_loss: 120.8682 - val_accuracy: 0.0000e+00\n",
      "Epoch 2125/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2506 - accuracy: 0.0000e+00 - val_loss: 104.0418 - val_accuracy: 0.0588\n",
      "Epoch 2126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1894 - accuracy: 0.0156 - val_loss: 96.9807 - val_accuracy: 0.0588\n",
      "Epoch 2127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2889 - accuracy: 0.0000e+00 - val_loss: 99.7954 - val_accuracy: 0.0588\n",
      "Epoch 2128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6125 - accuracy: 0.0000e+00 - val_loss: 95.6273 - val_accuracy: 0.0588\n",
      "Epoch 2129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4920 - accuracy: 0.0000e+00 - val_loss: 96.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2140 - accuracy: 0.0000e+00 - val_loss: 103.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 2131/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 45.6805 - accuracy: 0.0156 - val_loss: 100.3990 - val_accuracy: 0.0588\n",
      "Epoch 2132/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3790 - accuracy: 0.0000e+00 - val_loss: 90.9864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2133/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3021 - accuracy: 0.0156 - val_loss: 97.1188 - val_accuracy: 0.0000e+00\n",
      "Epoch 2134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5949 - accuracy: 0.0156 - val_loss: 99.8607 - val_accuracy: 0.0588\n",
      "Epoch 2135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5465 - accuracy: 0.0000e+00 - val_loss: 94.6976 - val_accuracy: 0.0588\n",
      "Epoch 2136/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.3645 - accuracy: 0.0000e+00 - val_loss: 87.6994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2137/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 43.2882 - accuracy: 0.0000e+00 - val_loss: 81.8460 - val_accuracy: 0.0000e+00\n",
      "Epoch 2138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1774 - accuracy: 0.0000e+00 - val_loss: 84.7511 - val_accuracy: 0.0588\n",
      "Epoch 2139/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 49.1784 - accuracy: 0.0000e+00 - val_loss: 102.0458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1979 - accuracy: 0.0312 - val_loss: 127.5569 - val_accuracy: 0.0000e+00\n",
      "Epoch 2141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.5067 - accuracy: 0.0000e+00 - val_loss: 131.4715 - val_accuracy: 0.0588\n",
      "Epoch 2142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2952 - accuracy: 0.0156 - val_loss: 122.5558 - val_accuracy: 0.0000e+00\n",
      "Epoch 2143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7896 - accuracy: 0.0000e+00 - val_loss: 121.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1369 - accuracy: 0.0000e+00 - val_loss: 126.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 2145/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2962 - accuracy: 0.0000e+00 - val_loss: 114.3383 - val_accuracy: 0.0000e+00\n",
      "Epoch 2146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 55.5571 - accuracy: 0.0000e+00 - val_loss: 102.3612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2147/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 62.7589 - accuracy: 0.0000e+00 - val_loss: 101.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9184 - accuracy: 0.0000e+00 - val_loss: 116.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4737 - accuracy: 0.0000e+00 - val_loss: 121.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 2150/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 45.0756 - accuracy: 0.0000e+00 - val_loss: 109.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 2151/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3818 - accuracy: 0.0000e+00 - val_loss: 97.4021 - val_accuracy: 0.0588\n",
      "Epoch 2152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0984 - accuracy: 0.0000e+00 - val_loss: 91.4623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1033 - accuracy: 0.0000e+00 - val_loss: 97.2542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2154/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 53.6848 - accuracy: 0.0000e+00 - val_loss: 104.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 2155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5997 - accuracy: 0.0000e+00 - val_loss: 111.6991 - val_accuracy: 0.0000e+00\n",
      "Epoch 2156/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.9068 - accuracy: 0.0156 - val_loss: 110.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 2157/10000\n",
      "64/64 [==============================] - 0s 213us/step - loss: 56.9797 - accuracy: 0.0312 - val_loss: 111.8793 - val_accuracy: 0.0588\n",
      "Epoch 2158/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2862 - accuracy: 0.0000e+00 - val_loss: 111.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 2159/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 50.2725 - accuracy: 0.0156 - val_loss: 110.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 2160/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 52.3084 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 46.7969 - accuracy: 0.0000e+00 - val_loss: 95.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2161/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.7153 - accuracy: 0.0156 - val_loss: 81.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 2162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9563 - accuracy: 0.0156 - val_loss: 90.3217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8920 - accuracy: 0.0000e+00 - val_loss: 112.5348 - val_accuracy: 0.0588\n",
      "Epoch 2164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9216 - accuracy: 0.0000e+00 - val_loss: 121.8403 - val_accuracy: 0.0000e+00\n",
      "Epoch 2165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.6207 - accuracy: 0.0156 - val_loss: 105.5281 - val_accuracy: 0.0588\n",
      "Epoch 2166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1204 - accuracy: 0.0000e+00 - val_loss: 92.4643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5708 - accuracy: 0.0000e+00 - val_loss: 91.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 2168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5940 - accuracy: 0.0156 - val_loss: 102.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 2169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1465 - accuracy: 0.0156 - val_loss: 111.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5353 - accuracy: 0.0000e+00 - val_loss: 118.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9008 - accuracy: 0.0156 - val_loss: 125.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 2172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4104 - accuracy: 0.0000e+00 - val_loss: 124.5212 - val_accuracy: 0.0000e+00\n",
      "Epoch 2173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1806 - accuracy: 0.0156 - val_loss: 108.7807 - val_accuracy: 0.0000e+00\n",
      "Epoch 2174/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 55.9812 - accuracy: 0.0156 - val_loss: 91.2697 - val_accuracy: 0.0588\n",
      "Epoch 2175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3023 - accuracy: 0.0000e+00 - val_loss: 82.9531 - val_accuracy: 0.0588\n",
      "Epoch 2176/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0975 - accuracy: 0.0312 - val_loss: 84.1840 - val_accuracy: 0.0588\n",
      "Epoch 2177/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.2123 - accuracy: 0.0000e+00 - val_loss: 97.3973 - val_accuracy: 0.0000e+00\n",
      "Epoch 2178/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 45.5778 - accuracy: 0.0000e+00 - val_loss: 113.3040 - val_accuracy: 0.0000e+00\n",
      "Epoch 2179/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.2583 - accuracy: 0.0000e+00 - val_loss: 126.8970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2180/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.4166 - accuracy: 0.0000e+00 - val_loss: 113.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 2181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5141 - accuracy: 0.0000e+00 - val_loss: 95.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9415 - accuracy: 0.0000e+00 - val_loss: 83.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1132 - accuracy: 0.0156 - val_loss: 94.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 2184/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.3744 - accuracy: 0.0469 - val_loss: 109.9247 - val_accuracy: 0.0588\n",
      "Epoch 2185/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.2271 - accuracy: 0.0000e+00 - val_loss: 124.2987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2186/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1396 - accuracy: 0.0000e+00 - val_loss: 124.6938 - val_accuracy: 0.0588\n",
      "Epoch 2187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.3481 - accuracy: 0.0000e+00 - val_loss: 109.8288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2188/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 44.1913 - accuracy: 0.0000e+00 - val_loss: 101.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 2189/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.5202 - accuracy: 0.0000e+00 - val_loss: 97.7685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.6977 - accuracy: 0.0000e+00 - val_loss: 106.5835 - val_accuracy: 0.0588\n",
      "Epoch 2191/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 49.3149 - accuracy: 0.0000e+00 - val_loss: 122.2924 - val_accuracy: 0.0000e+00\n",
      "Epoch 2192/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8262 - accuracy: 0.0156 - val_loss: 130.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 2193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.7051 - accuracy: 0.0000e+00 - val_loss: 121.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 2194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4859 - accuracy: 0.0156 - val_loss: 107.9997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1627 - accuracy: 0.0000e+00 - val_loss: 109.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2196/10000\n",
      "64/64 [==============================] - 0s 230us/step - loss: 57.6870 - accuracy: 0.0000e+00 - val_loss: 102.3740 - val_accuracy: 0.0588\n",
      "Epoch 2197/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1404 - accuracy: 0.0000e+00 - val_loss: 100.8011 - val_accuracy: 0.0588\n",
      "Epoch 2198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1880 - accuracy: 0.0000e+00 - val_loss: 110.2773 - val_accuracy: 0.0588\n",
      "Epoch 2199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0026 - accuracy: 0.0156 - val_loss: 111.9864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.2935 - accuracy: 0.0000e+00 - val_loss: 104.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 2201/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.0922 - accuracy: 0.0000e+00 - val_loss: 92.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7566 - accuracy: 0.0000e+00 - val_loss: 89.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 2203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3434 - accuracy: 0.0156 - val_loss: 100.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2204/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.7500 - accuracy: 0.0000e+00 - val_loss: 122.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 2205/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 51.1805 - accuracy: 0.0000e+00 - val_loss: 132.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 2206/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 43.4632 - accuracy: 0.0000e+00 - val_loss: 125.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 2207/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 52.8980 - accuracy: 0.0000e+00 - val_loss: 110.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0415 - accuracy: 0.0312 - val_loss: 107.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2209/10000\n",
      "64/64 [==============================] - 0s 205us/step - loss: 52.2974 - accuracy: 0.0000e+00 - val_loss: 109.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 2210/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 45.7648 - accuracy: 0.0156 - val_loss: 111.1840 - val_accuracy: 0.0000e+00\n",
      "Epoch 2211/10000\n",
      "64/64 [==============================] - 0s 181us/step - loss: 55.0482 - accuracy: 0.0000e+00 - val_loss: 100.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 2212/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 48.4330 - accuracy: 0.0000e+00 - val_loss: 102.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2213/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4478 - accuracy: 0.0000e+00 - val_loss: 107.8398 - val_accuracy: 0.0588\n",
      "Epoch 2214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0118 - accuracy: 0.0156 - val_loss: 109.0367 - val_accuracy: 0.0588\n",
      "Epoch 2215/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0996 - accuracy: 0.0000e+00 - val_loss: 104.4127 - val_accuracy: 0.0588\n",
      "Epoch 2216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9983 - accuracy: 0.0156 - val_loss: 107.7717 - val_accuracy: 0.0000e+00\n",
      "Epoch 2217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.0437 - accuracy: 0.0156 - val_loss: 112.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2218/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 39.6045 - accuracy: 0.0312 - val_loss: 108.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 2219/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 50.4744 - accuracy: 0.0000e+00 - val_loss: 106.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 2220/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 47.4021 - accuracy: 0.0000e+00 - val_loss: 102.2989 - val_accuracy: 0.0000e+00\n",
      "Epoch 2221/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 51.7418 - accuracy: 0.0156 - val_loss: 98.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 2222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2010 - accuracy: 0.0000e+00 - val_loss: 103.1500 - val_accuracy: 0.0588\n",
      "Epoch 2223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2350 - accuracy: 0.0312 - val_loss: 104.2224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.9294 - accuracy: 0.0000e+00 - val_loss: 97.3131 - val_accuracy: 0.0000e+00\n",
      "Epoch 2225/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 43.8866 - accuracy: 0.0000e+00 - val_loss: 100.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2226/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.2063 - accuracy: 0.0000e+00 - val_loss: 90.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7235 - accuracy: 0.0000e+00 - val_loss: 86.8427 - val_accuracy: 0.0588\n",
      "Epoch 2228/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.0974 - accuracy: 0.0000e+00 - val_loss: 90.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2229/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 57.9713 - accuracy: 0.0000e+00 - val_loss: 98.9768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6852 - accuracy: 0.0000e+00 - val_loss: 100.5162 - val_accuracy: 0.0000e+00\n",
      "Epoch 2231/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 53.0170 - accuracy: 0.0000e+00 - val_loss: 102.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 2232/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5371 - accuracy: 0.0000e+00 - val_loss: 102.6891 - val_accuracy: 0.0000e+00\n",
      "Epoch 2233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1330 - accuracy: 0.0156 - val_loss: 98.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 2234/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 60.3249 - accuracy: 0.0000e+00 - val_loss: 97.0384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2235/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 42.3190 - accuracy: 0.0000e+00 - val_loss: 100.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 2236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7537 - accuracy: 0.0156 - val_loss: 99.4370 - val_accuracy: 0.0588\n",
      "Epoch 2237/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 47.4683 - accuracy: 0.0000e+00 - val_loss: 90.9499 - val_accuracy: 0.0588\n",
      "Epoch 2238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0259 - accuracy: 0.0000e+00 - val_loss: 90.2019 - val_accuracy: 0.0588\n",
      "Epoch 2239/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 40.5798 - accuracy: 0.0000e+00 - val_loss: 101.0958 - val_accuracy: 0.0588\n",
      "Epoch 2240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9160 - accuracy: 0.0000e+00 - val_loss: 111.7151 - val_accuracy: 0.0588\n",
      "Epoch 2241/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 53.4437 - accuracy: 0.0000e+00 - val_loss: 115.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 2242/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 64.2680 - accuracy: 0.0000e+00 - val_loss: 122.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 2243/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 38.2981 - accuracy: 0.0000e+00 - val_loss: 123.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 2244/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 49.3838 - accuracy: 0.0156 - val_loss: 120.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 2245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6948 - accuracy: 0.0000e+00 - val_loss: 112.7592 - val_accuracy: 0.0588\n",
      "Epoch 2246/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 47.6345 - accuracy: 0.0000e+00 - val_loss: 105.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 2247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6292 - accuracy: 0.0000e+00 - val_loss: 98.1597 - val_accuracy: 0.0000e+00\n",
      "Epoch 2248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9426 - accuracy: 0.0000e+00 - val_loss: 99.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0288 - accuracy: 0.0000e+00 - val_loss: 113.0652 - val_accuracy: 0.0588\n",
      "Epoch 2250/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 46.2494 - accuracy: 0.0000e+00 - val_loss: 122.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2251/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 47.9707 - accuracy: 0.0312 - val_loss: 121.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 2252/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.6454 - accuracy: 0.0000e+00 - val_loss: 105.6500 - val_accuracy: 0.0000e+00\n",
      "Epoch 2253/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 56.0720 - accuracy: 0.0000e+00 - val_loss: 92.0236 - val_accuracy: 0.0588\n",
      "Epoch 2254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2417 - accuracy: 0.0000e+00 - val_loss: 85.2320 - val_accuracy: 0.0588\n",
      "Epoch 2255/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 62.2878 - accuracy: 0.0000e+00 - val_loss: 91.1877 - val_accuracy: 0.0588\n",
      "Epoch 2256/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.8192 - accuracy: 0.0312 - val_loss: 100.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.6656 - accuracy: 0.0000e+00 - val_loss: 113.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 2258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8871 - accuracy: 0.0000e+00 - val_loss: 102.0384 - val_accuracy: 0.0588\n",
      "Epoch 2259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1175 - accuracy: 0.0000e+00 - val_loss: 85.1589 - val_accuracy: 0.0588\n",
      "Epoch 2260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0592 - accuracy: 0.0312 - val_loss: 77.8474 - val_accuracy: 0.0588\n",
      "Epoch 2261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6764 - accuracy: 0.0000e+00 - val_loss: 83.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 2262/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 46.5649 - accuracy: 0.0000e+00 - val_loss: 99.1542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4200 - accuracy: 0.0156 - val_loss: 124.4047 - val_accuracy: 0.0000e+00\n",
      "Epoch 2264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7200 - accuracy: 0.0156 - val_loss: 127.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 2265/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 40.2169 - accuracy: 0.0156 - val_loss: 113.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 2266/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.5522 - accuracy: 0.0312 - val_loss: 94.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 2267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6748 - accuracy: 0.0000e+00 - val_loss: 87.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 2268/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 49.1391 - accuracy: 0.0000e+00 - val_loss: 93.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 2269/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1685 - accuracy: 0.0156 - val_loss: 99.4674 - val_accuracy: 0.0000e+00\n",
      "Epoch 2270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9703 - accuracy: 0.0156 - val_loss: 103.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 2271/10000\n",
      "64/64 [==============================] - 0s 59us/step - loss: 47.5907 - accuracy: 0.0000e+00 - val_loss: 113.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 2272/10000\n",
      "64/64 [==============================] - 0s 2us/step - loss: 47.2668 - accuracy: 0.0000e+00 - val_loss: 128.5689 - val_accuracy: 0.0000e+00\n",
      "Epoch 2273/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 57.0874 - accuracy: 0.0312 - val_loss: 125.4565 - val_accuracy: 0.0000e+00\n",
      "Epoch 2274/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 54.1164 - accuracy: 0.0000e+0 - 0s 96us/step - loss: 50.3370 - accuracy: 0.0000e+00 - val_loss: 109.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 2275/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 55.4810 - accuracy: 0.0469 - val_loss: 100.3336 - val_accuracy: 0.0588\n",
      "Epoch 2276/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 49.1475 - accuracy: 0.0000e+00 - val_loss: 105.2077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2277/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 42.3368 - accuracy: 0.0156 - val_loss: 103.5694 - val_accuracy: 0.0588\n",
      "Epoch 2278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7371 - accuracy: 0.0000e+00 - val_loss: 100.7903 - val_accuracy: 0.0588\n",
      "Epoch 2279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5478 - accuracy: 0.0156 - val_loss: 96.7410 - val_accuracy: 0.0588\n",
      "Epoch 2280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4891 - accuracy: 0.0000e+00 - val_loss: 93.4447 - val_accuracy: 0.0588\n",
      "Epoch 2281/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 53.5678 - accuracy: 0.0156 - val_loss: 101.4847 - val_accuracy: 0.0000e+00\n",
      "Epoch 2282/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 43.2855 - accuracy: 0.0000e+00 - val_loss: 97.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 2283/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 35.4973 - accuracy: 0.0156 - val_loss: 92.9592 - val_accuracy: 0.0000e+00\n",
      "Epoch 2284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6203 - accuracy: 0.0156 - val_loss: 102.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2285/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.8188 - accuracy: 0.0312 - val_loss: 106.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 2286/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.2577 - accuracy: 0.0156 - val_loss: 111.6550 - val_accuracy: 0.0000e+00\n",
      "Epoch 2287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0666 - accuracy: 0.0156 - val_loss: 102.7228 - val_accuracy: 0.0588\n",
      "Epoch 2288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8559 - accuracy: 0.0000e+00 - val_loss: 88.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7450 - accuracy: 0.0000e+00 - val_loss: 87.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.6776 - accuracy: 0.0000e+00 - val_loss: 114.1325 - val_accuracy: 0.0588\n",
      "Epoch 2291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3877 - accuracy: 0.0000e+00 - val_loss: 142.7544 - val_accuracy: 0.0000e+00\n",
      "Epoch 2292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1965 - accuracy: 0.0156 - val_loss: 134.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 2293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8396 - accuracy: 0.0000e+00 - val_loss: 107.4451 - val_accuracy: 0.0588\n",
      "Epoch 2294/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.9481 - accuracy: 0.0000e+00 - val_loss: 92.6024 - val_accuracy: 0.0000e+00\n",
      "Epoch 2295/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.2196 - accuracy: 0.0156 - val_loss: 93.5337 - val_accuracy: 0.0000e+00\n",
      "Epoch 2296/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.0312 - accuracy: 0.0156 - val_loss: 105.5644 - val_accuracy: 0.0000e+00\n",
      "Epoch 2297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5086 - accuracy: 0.0000e+00 - val_loss: 118.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2298/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1343 - accuracy: 0.0312 - val_loss: 127.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2299/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 64.5492 - accuracy: 0.0000e+00 - val_loss: 126.8177 - val_accuracy: 0.0000e+00\n",
      "Epoch 2300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9022 - accuracy: 0.0000e+00 - val_loss: 113.0197 - val_accuracy: 0.0588\n",
      "Epoch 2301/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 45.5422 - accuracy: 0.0000e+00 - val_loss: 98.1463 - val_accuracy: 0.0000e+00\n",
      "Epoch 2302/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 41.2255 - accuracy: 0.0156 - val_loss: 92.3570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.0740 - accuracy: 0.0000e+00 - val_loss: 99.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.3681 - accuracy: 0.0000e+00 - val_loss: 104.9583 - val_accuracy: 0.0000e+00\n",
      "Epoch 2305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.8784 - accuracy: 0.0156 - val_loss: 109.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 2306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9587 - accuracy: 0.0156 - val_loss: 113.2196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2823 - accuracy: 0.0000e+00 - val_loss: 114.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 2308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8521 - accuracy: 0.0156 - val_loss: 115.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0205 - accuracy: 0.0000e+00 - val_loss: 111.6564 - val_accuracy: 0.0000e+00\n",
      "Epoch 2310/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.7244 - accuracy: 0.0000e+00 - val_loss: 105.9904 - val_accuracy: 0.0000e+00\n",
      "Epoch 2311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.6916 - accuracy: 0.0000e+00 - val_loss: 110.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2312/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.6154 - accuracy: 0.0156 - val_loss: 117.1712 - val_accuracy: 0.0000e+00\n",
      "Epoch 2313/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.8975 - accuracy: 0.0000e+00 - val_loss: 122.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2314/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 36.2267 - accuracy: 0.0000e+00 - val_loss: 108.9655 - val_accuracy: 0.0000e+00\n",
      "Epoch 2315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.1418 - accuracy: 0.0000e+00 - val_loss: 98.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 2316/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 61.3267 - accuracy: 0.0156 - val_loss: 94.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 2317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9330 - accuracy: 0.0000e+00 - val_loss: 104.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 2318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.8582 - accuracy: 0.0000e+00 - val_loss: 116.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 2319/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.6683 - accuracy: 0.0000e+00 - val_loss: 116.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 2320/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 61.3561 - accuracy: 0.0156 - val_loss: 111.8521 - val_accuracy: 0.0588\n",
      "Epoch 2321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.1739 - accuracy: 0.0156 - val_loss: 117.3445 - val_accuracy: 0.0588\n",
      "Epoch 2322/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 39.6103 - accuracy: 0.0000e+00 - val_loss: 113.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 2323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2614 - accuracy: 0.0000e+00 - val_loss: 113.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2339 - accuracy: 0.0156 - val_loss: 105.7963 - val_accuracy: 0.0000e+00\n",
      "Epoch 2325/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 43.7751 - accuracy: 0.0000e+00 - val_loss: 107.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 2326/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.2970 - accuracy: 0.0312 - val_loss: 114.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 2327/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 54.6008 - accuracy: 0.0156 - val_loss: 115.5768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.0158 - accuracy: 0.0312 - val_loss: 102.3969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2329/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.7663 - accuracy: 0.0000e+00 - val_loss: 87.7636 - val_accuracy: 0.0000e+00\n",
      "Epoch 2330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2922 - accuracy: 0.0000e+00 - val_loss: 89.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 2331/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3938 - accuracy: 0.0156 - val_loss: 108.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2332/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 46.1295 - accuracy: 0.0000e+00 - val_loss: 117.2258 - val_accuracy: 0.0588\n",
      "Epoch 2333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4958 - accuracy: 0.0312 - val_loss: 110.2004 - val_accuracy: 0.0000e+00\n",
      "Epoch 2334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4885 - accuracy: 0.0000e+00 - val_loss: 97.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 2335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7657 - accuracy: 0.0156 - val_loss: 92.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 2336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6065 - accuracy: 0.0000e+00 - val_loss: 92.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 2337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8987 - accuracy: 0.0000e+00 - val_loss: 100.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6592 - accuracy: 0.0312 - val_loss: 104.1503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2339/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.2431 - accuracy: 0.0156 - val_loss: 104.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 2340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3770 - accuracy: 0.0000e+00 - val_loss: 93.8209 - val_accuracy: 0.0000e+00\n",
      "Epoch 2341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8918 - accuracy: 0.0156 - val_loss: 84.0903 - val_accuracy: 0.0588\n",
      "Epoch 2342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4783 - accuracy: 0.0156 - val_loss: 88.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.3766 - accuracy: 0.0000e+00 - val_loss: 94.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6501 - accuracy: 0.0312 - val_loss: 105.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 2345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7182 - accuracy: 0.0000e+00 - val_loss: 116.7639 - val_accuracy: 0.0000e+00\n",
      "Epoch 2346/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 45.4137 - accuracy: 0.0000e+00 - val_loss: 111.9979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2347/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 47.9798 - accuracy: 0.0156 - val_loss: 98.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 2348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1496 - accuracy: 0.0000e+00 - val_loss: 91.1806 - val_accuracy: 0.0000e+00\n",
      "Epoch 2349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6500 - accuracy: 0.0000e+00 - val_loss: 103.6648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9465 - accuracy: 0.0000e+00 - val_loss: 126.3100 - val_accuracy: 0.0000e+00\n",
      "Epoch 2351/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0882 - accuracy: 0.0156 - val_loss: 124.8453 - val_accuracy: 0.0000e+00\n",
      "Epoch 2352/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 49.8745 - accuracy: 0.0000e+00 - val_loss: 105.2779 - val_accuracy: 0.0000e+00\n",
      "Epoch 2353/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1842 - accuracy: 0.0000e+00 - val_loss: 89.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 2354/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 172us/step - loss: 57.3754 - accuracy: 0.0000e+00 - val_loss: 97.8172 - val_accuracy: 0.0000e+00\n",
      "Epoch 2355/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.1074 - accuracy: 0.0156 - val_loss: 118.1985 - val_accuracy: 0.0588\n",
      "Epoch 2356/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.7900 - accuracy: 0.0156 - val_loss: 132.5498 - val_accuracy: 0.0000e+00\n",
      "Epoch 2357/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 41.1988 - accuracy: 0.0000e+00 - val_loss: 137.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 2358/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 46.3007 - accuracy: 0.0000e+00 - val_loss: 127.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 2359/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.0443 - accuracy: 0.0000e+00 - val_loss: 110.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 2360/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2897 - accuracy: 0.0000e+00 - val_loss: 97.5980 - val_accuracy: 0.0588\n",
      "Epoch 2361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5084 - accuracy: 0.0156 - val_loss: 92.4240 - val_accuracy: 0.0588\n",
      "Epoch 2362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.6147 - accuracy: 0.0000e+00 - val_loss: 104.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 2363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1157 - accuracy: 0.0156 - val_loss: 114.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 2364/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.1852 - accuracy: 0.0000e+00 - val_loss: 110.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2365/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8395 - accuracy: 0.0000e+00 - val_loss: 100.7206 - val_accuracy: 0.0000e+00\n",
      "Epoch 2366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1915 - accuracy: 0.0000e+00 - val_loss: 94.5971 - val_accuracy: 0.0588\n",
      "Epoch 2367/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 35.2060 - accuracy: 0.0000e+00 - val_loss: 98.4496 - val_accuracy: 0.0588\n",
      "Epoch 2368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0201 - accuracy: 0.0000e+00 - val_loss: 109.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 2369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5177 - accuracy: 0.0000e+00 - val_loss: 104.8714 - val_accuracy: 0.0588\n",
      "Epoch 2370/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.4969 - accuracy: 0.0000e+00 - val_loss: 93.8566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9731 - accuracy: 0.0000e+00 - val_loss: 94.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8078 - accuracy: 0.0000e+00 - val_loss: 105.9595 - val_accuracy: 0.0000e+00\n",
      "Epoch 2373/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 49.2634 - accuracy: 0.0156 - val_loss: 108.7282 - val_accuracy: 0.0588\n",
      "Epoch 2374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.1767 - accuracy: 0.0000e+00 - val_loss: 106.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 2375/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 43.8840 - accuracy: 0.0000e+00 - val_loss: 107.0861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2376/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 69.0915 - accuracy: 0.0000e+00 - val_loss: 116.2291 - val_accuracy: 0.0000e+00\n",
      "Epoch 2377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5113 - accuracy: 0.0000e+00 - val_loss: 130.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 2378/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5397 - accuracy: 0.0000e+00 - val_loss: 129.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4342 - accuracy: 0.0000e+00 - val_loss: 123.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2380/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 58.6467 - accuracy: 0.0000e+00 - val_loss: 116.6227 - val_accuracy: 0.0000e+00\n",
      "Epoch 2381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5920 - accuracy: 0.0000e+00 - val_loss: 119.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 2382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.4021 - accuracy: 0.0156 - val_loss: 127.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 2383/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 49.2735 - accuracy: 0.0000e+00 - val_loss: 131.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 2384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0715 - accuracy: 0.0156 - val_loss: 122.0418 - val_accuracy: 0.0000e+00\n",
      "Epoch 2385/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5428 - accuracy: 0.0000e+00 - val_loss: 119.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 2386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0913 - accuracy: 0.0000e+00 - val_loss: 106.5329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9583 - accuracy: 0.0000e+00 - val_loss: 94.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3244 - accuracy: 0.0000e+00 - val_loss: 93.6963 - val_accuracy: 0.0000e+00\n",
      "Epoch 2389/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.0562 - accuracy: 0.0000e+00 - val_loss: 99.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 2390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.0746 - accuracy: 0.0156 - val_loss: 107.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 2391/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 42.0918 - accuracy: 0.0156 - val_loss: 112.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 2392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.5945 - accuracy: 0.0156 - val_loss: 103.7567 - val_accuracy: 0.0000e+00\n",
      "Epoch 2393/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.0778 - accuracy: 0.0156 - val_loss: 105.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2394/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8236 - accuracy: 0.0000e+00 - val_loss: 104.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2395/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.8000 - accuracy: 0.0156 - val_loss: 109.8308 - val_accuracy: 0.0000e+00\n",
      "Epoch 2396/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5166 - accuracy: 0.0000e+00 - val_loss: 114.1977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2397/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0378 - accuracy: 0.0156 - val_loss: 121.3830 - val_accuracy: 0.0000e+00\n",
      "Epoch 2398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9398 - accuracy: 0.0156 - val_loss: 114.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9304 - accuracy: 0.0000e+00 - val_loss: 104.3349 - val_accuracy: 0.0000e+00\n",
      "Epoch 2400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3246 - accuracy: 0.0000e+00 - val_loss: 101.7663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1290 - accuracy: 0.0156 - val_loss: 101.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 2402/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.4213 - accuracy: 0.0156 - val_loss: 107.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2403/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 31.7096 - accuracy: 0.0156 - val_loss: 113.8374 - val_accuracy: 0.0588\n",
      "Epoch 2404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2955 - accuracy: 0.0000e+00 - val_loss: 109.3179 - val_accuracy: 0.0588\n",
      "Epoch 2405/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 45.5035 - accuracy: 0.0000e+00 - val_loss: 94.5983 - val_accuracy: 0.0000e+00\n",
      "Epoch 2406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0689 - accuracy: 0.0000e+00 - val_loss: 87.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 2407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3740 - accuracy: 0.0156 - val_loss: 89.7438 - val_accuracy: 0.0588\n",
      "Epoch 2408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1107 - accuracy: 0.0000e+00 - val_loss: 99.9074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7021 - accuracy: 0.0000e+00 - val_loss: 109.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 2410/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 39.2576 - accuracy: 0.0000e+00 - val_loss: 111.3660 - val_accuracy: 0.0000e+00\n",
      "Epoch 2411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.6003 - accuracy: 0.0000e+00 - val_loss: 101.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 2412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4917 - accuracy: 0.0000e+00 - val_loss: 89.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2413/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4989 - accuracy: 0.0156 - val_loss: 83.9554 - val_accuracy: 0.0000e+00\n",
      "Epoch 2414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.7575 - accuracy: 0.0000e+00 - val_loss: 82.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 2415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.4105 - accuracy: 0.0000e+00 - val_loss: 83.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 2416/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.7613 - accuracy: 0.0000e+00 - val_loss: 92.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8342 - accuracy: 0.0000e+00 - val_loss: 96.3033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3082 - accuracy: 0.0000e+00 - val_loss: 96.8508 - val_accuracy: 0.0588\n",
      "Epoch 2419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8412 - accuracy: 0.0156 - val_loss: 96.3465 - val_accuracy: 0.0588\n",
      "Epoch 2420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7091 - accuracy: 0.0469 - val_loss: 84.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 2421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9525 - accuracy: 0.0000e+00 - val_loss: 81.4611 - val_accuracy: 0.0000e+00\n",
      "Epoch 2422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0178 - accuracy: 0.0000e+00 - val_loss: 93.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 2423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9866 - accuracy: 0.0156 - val_loss: 114.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 2424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4802 - accuracy: 0.0156 - val_loss: 128.3816 - val_accuracy: 0.0588\n",
      "Epoch 2425/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.4179 - accuracy: 0.0312 - val_loss: 120.3735 - val_accuracy: 0.0588\n",
      "Epoch 2426/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.8360 - accuracy: 0.0000e+00 - val_loss: 105.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 2427/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.0665 - accuracy: 0.0000e+00 - val_loss: 100.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 2428/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 41.7365 - accuracy: 0.0000e+00 - val_loss: 103.8608 - val_accuracy: 0.0588\n",
      "Epoch 2429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.3673 - accuracy: 0.0000e+00 - val_loss: 105.9426 - val_accuracy: 0.0588\n",
      "Epoch 2430/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.2062 - accuracy: 0.0156 - val_loss: 105.5178 - val_accuracy: 0.0588\n",
      "Epoch 2431/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.3906 - accuracy: 0.0156 - val_loss: 112.7551 - val_accuracy: 0.0588\n",
      "Epoch 2432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.6491 - accuracy: 0.0312 - val_loss: 115.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4352 - accuracy: 0.0312 - val_loss: 111.9515 - val_accuracy: 0.0000e+00\n",
      "Epoch 2434/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 60.4534 - accuracy: 0.0156 - val_loss: 105.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 2435/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9841 - accuracy: 0.0156 - val_loss: 101.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 2436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9651 - accuracy: 0.0000e+00 - val_loss: 106.1759 - val_accuracy: 0.0000e+00\n",
      "Epoch 2437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.9718 - accuracy: 0.0156 - val_loss: 105.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2438/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.9971 - accuracy: 0.0000e+00 - val_loss: 99.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2439/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.6453 - accuracy: 0.0156 - val_loss: 102.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 2440/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 50.7958 - accuracy: 0.0469 - val_loss: 97.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 2441/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2919 - accuracy: 0.0000e+00 - val_loss: 94.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 2442/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.1508 - accuracy: 0.0000e+00 - val_loss: 98.4703 - val_accuracy: 0.0588\n",
      "Epoch 2443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4821 - accuracy: 0.0000e+00 - val_loss: 97.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 2444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3524 - accuracy: 0.0000e+00 - val_loss: 98.3237 - val_accuracy: 0.0000e+00\n",
      "Epoch 2445/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 53.6460 - accuracy: 0.0000e+00 - val_loss: 92.1056 - val_accuracy: 0.0588\n",
      "Epoch 2446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8544 - accuracy: 0.0000e+00 - val_loss: 85.7057 - val_accuracy: 0.0000e+00\n",
      "Epoch 2447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5340 - accuracy: 0.0000e+00 - val_loss: 95.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3117 - accuracy: 0.0000e+00 - val_loss: 106.5755 - val_accuracy: 0.0588\n",
      "Epoch 2449/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.1668 - accuracy: 0.0156 - val_loss: 112.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 2450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2131 - accuracy: 0.0000e+00 - val_loss: 109.9670 - val_accuracy: 0.0588\n",
      "Epoch 2451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4394 - accuracy: 0.0000e+00 - val_loss: 109.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 2452/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.1876 - accuracy: 0.0156 - val_loss: 115.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 2453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7183 - accuracy: 0.0000e+00 - val_loss: 114.4091 - val_accuracy: 0.0588\n",
      "Epoch 2454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.8836 - accuracy: 0.0000e+00 - val_loss: 109.5537 - val_accuracy: 0.0588\n",
      "Epoch 2455/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.3316 - accuracy: 0.0156 - val_loss: 105.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1872 - accuracy: 0.0000e+00 - val_loss: 100.5706 - val_accuracy: 0.0588\n",
      "Epoch 2457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.3296 - accuracy: 0.0156 - val_loss: 100.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 2458/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.1443 - accuracy: 0.0000e+00 - val_loss: 128.2721 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0367 - accuracy: 0.0156 - val_loss: 148.6319 - val_accuracy: 0.0000e+00\n",
      "Epoch 2460/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.8829 - accuracy: 0.0000e+00 - val_loss: 133.3368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2461/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.9387 - accuracy: 0.0000e+00 - val_loss: 110.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7447 - accuracy: 0.0312 - val_loss: 100.6508 - val_accuracy: 0.0000e+00\n",
      "Epoch 2463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6050 - accuracy: 0.0000e+00 - val_loss: 93.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 2464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1213 - accuracy: 0.0000e+00 - val_loss: 88.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 2465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4846 - accuracy: 0.0000e+00 - val_loss: 94.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 2466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8993 - accuracy: 0.0312 - val_loss: 95.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 2467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8570 - accuracy: 0.0000e+00 - val_loss: 95.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 2468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2790 - accuracy: 0.0000e+00 - val_loss: 93.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 2469/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1168 - accuracy: 0.0156 - val_loss: 86.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 2470/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.2539 - accuracy: 0.0000e+00 - val_loss: 81.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2622 - accuracy: 0.0000e+00 - val_loss: 83.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 2472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2179 - accuracy: 0.0156 - val_loss: 91.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 2473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2678 - accuracy: 0.0156 - val_loss: 99.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2474/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 39.2119 - accuracy: 0.0156 - val_loss: 106.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 2475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.1880 - accuracy: 0.0000e+00 - val_loss: 103.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 2476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3570 - accuracy: 0.0156 - val_loss: 101.0686 - val_accuracy: 0.0588\n",
      "Epoch 2477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1324 - accuracy: 0.0156 - val_loss: 101.2002 - val_accuracy: 0.0588\n",
      "Epoch 2478/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 57.8623 - accuracy: 0.0000e+00 - val_loss: 99.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2145 - accuracy: 0.0000e+00 - val_loss: 103.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 2480/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 50.7890 - accuracy: 0.0000e+00 - val_loss: 106.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0500 - accuracy: 0.0156 - val_loss: 101.8910 - val_accuracy: 0.0000e+00\n",
      "Epoch 2482/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4727 - accuracy: 0.0000e+00 - val_loss: 92.1966 - val_accuracy: 0.0000e+00\n",
      "Epoch 2483/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 39.8777 - accuracy: 0.0000e+00 - val_loss: 97.3600 - val_accuracy: 0.0000e+00\n",
      "Epoch 2484/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 52.8270 - accuracy: 0.0156 - val_loss: 95.3644 - val_accuracy: 0.0000e+00\n",
      "Epoch 2485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0240 - accuracy: 0.0156 - val_loss: 102.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2486/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0445 - accuracy: 0.0000e+00 - val_loss: 112.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 2487/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2174 - accuracy: 0.0000e+00 - val_loss: 113.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 2488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.7751 - accuracy: 0.0156 - val_loss: 110.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 2489/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 54.5458 - accuracy: 0.0000e+00 - val_loss: 105.6060 - val_accuracy: 0.0588\n",
      "Epoch 2490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1875 - accuracy: 0.0000e+00 - val_loss: 97.7812 - val_accuracy: 0.0588\n",
      "Epoch 2491/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 51.3322 - accuracy: 0.0000e+00 - val_loss: 91.3777 - val_accuracy: 0.0000e+00\n",
      "Epoch 2492/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 49.8551 - accuracy: 0.0156 - val_loss: 104.7374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2493/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 54.4122 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 43.9676 - accuracy: 0.0000e+00 - val_loss: 117.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 2494/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 48.0303 - accuracy: 0.0000e+00 - val_loss: 117.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 2495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.2746 - accuracy: 0.0000e+00 - val_loss: 101.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 2496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7109 - accuracy: 0.0000e+00 - val_loss: 86.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 2497/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2845 - accuracy: 0.0000e+00 - val_loss: 85.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2498/10000\n",
      "64/64 [==============================] - 0s 243us/step - loss: 47.6252 - accuracy: 0.0000e+00 - val_loss: 90.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 2499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3470 - accuracy: 0.0000e+00 - val_loss: 93.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.3075 - accuracy: 0.0000e+00 - val_loss: 103.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2501/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 49.5404 - accuracy: 0.0000e+00 - val_loss: 106.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.8282 - accuracy: 0.0000e+00 - val_loss: 103.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 2503/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.7786 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 52.2226 - accuracy: 0.0000e+00 - val_loss: 96.2999 - val_accuracy: 0.0000e+00\n",
      "Epoch 2504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6941 - accuracy: 0.0000e+00 - val_loss: 87.2115 - val_accuracy: 0.0000e+00\n",
      "Epoch 2505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9682 - accuracy: 0.0000e+00 - val_loss: 86.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 2506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2285 - accuracy: 0.0000e+00 - val_loss: 88.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 2507/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0554 - accuracy: 0.0000e+00 - val_loss: 95.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2508/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 38.2821 - accuracy: 0.0000e+00 - val_loss: 104.6466 - val_accuracy: 0.0000e+00\n",
      "Epoch 2509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4176 - accuracy: 0.0156 - val_loss: 113.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2510/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 44.7444 - accuracy: 0.0156 - val_loss: 114.2623 - val_accuracy: 0.0588\n",
      "Epoch 2511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.4767 - accuracy: 0.0000e+00 - val_loss: 106.0698 - val_accuracy: 0.0588\n",
      "Epoch 2512/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 33.9547 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 36.7932 - accuracy: 0.0000e+00 - val_loss: 100.8062 - val_accuracy: 0.0588\n",
      "Epoch 2513/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 43.9846 - accuracy: 0.0625 - val_loss: 89.2757 - val_accuracy: 0.0588\n",
      "Epoch 2514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5720 - accuracy: 0.0000e+00 - val_loss: 95.3897 - val_accuracy: 0.0000e+00\n",
      "Epoch 2515/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 28.8495 - accuracy: 0.0000e+00 - val_loss: 108.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 2516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.8428 - accuracy: 0.0000e+00 - val_loss: 107.1417 - val_accuracy: 0.0000e+00\n",
      "Epoch 2517/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 43.1358 - accuracy: 0.0000e+00 - val_loss: 95.5549 - val_accuracy: 0.0588\n",
      "Epoch 2518/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.4240 - accuracy: 0.0000e+00 - val_loss: 92.2935 - val_accuracy: 0.0000e+00\n",
      "Epoch 2519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3672 - accuracy: 0.0000e+00 - val_loss: 94.2686 - val_accuracy: 0.0000e+00\n",
      "Epoch 2520/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 41.4943 - accuracy: 0.0156 - val_loss: 100.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8090 - accuracy: 0.0000e+00 - val_loss: 114.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 2522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7339 - accuracy: 0.0000e+00 - val_loss: 119.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 2523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5722 - accuracy: 0.0156 - val_loss: 108.3504 - val_accuracy: 0.0000e+00\n",
      "Epoch 2524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2389 - accuracy: 0.0156 - val_loss: 91.2623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1708 - accuracy: 0.0000e+00 - val_loss: 98.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 2526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9402 - accuracy: 0.0000e+00 - val_loss: 117.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 2527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9812 - accuracy: 0.0000e+00 - val_loss: 135.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2528/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.9613 - accuracy: 0.0000e+00 - val_loss: 144.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 2529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.4735 - accuracy: 0.0156 - val_loss: 130.1826 - val_accuracy: 0.0588\n",
      "Epoch 2530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9292 - accuracy: 0.0000e+00 - val_loss: 114.3374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2531/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.2528 - accuracy: 0.0000e+00 - val_loss: 101.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 2532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9531 - accuracy: 0.0000e+00 - val_loss: 104.8977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5212 - accuracy: 0.0156 - val_loss: 109.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2534/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.5982 - accuracy: 0.0000e+00 - val_loss: 101.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 2535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0671 - accuracy: 0.0000e+00 - val_loss: 98.0525 - val_accuracy: 0.0000e+00\n",
      "Epoch 2536/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 54.8138 - accuracy: 0.0000e+00 - val_loss: 100.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.8349 - accuracy: 0.0000e+00 - val_loss: 96.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 2538/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 55.9007 - accuracy: 0.0000e+00 - val_loss: 96.2932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2539/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 54.0236 - accuracy: 0.0156 - val_loss: 85.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9745 - accuracy: 0.0156 - val_loss: 73.6950 - val_accuracy: 0.0000e+00\n",
      "Epoch 2541/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 56.3372 - accuracy: 0.0000e+00 - val_loss: 66.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 2542/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 51.5204 - accuracy: 0.0000e+00 - val_loss: 74.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 2543/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.1463 - accuracy: 0.0156 - val_loss: 88.3732 - val_accuracy: 0.0588\n",
      "Epoch 2544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9782 - accuracy: 0.0156 - val_loss: 94.9591 - val_accuracy: 0.0000e+00\n",
      "Epoch 2545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.2215 - accuracy: 0.0156 - val_loss: 89.8648 - val_accuracy: 0.0588\n",
      "Epoch 2546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6087 - accuracy: 0.0000e+00 - val_loss: 80.6551 - val_accuracy: 0.0000e+00\n",
      "Epoch 2547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6052 - accuracy: 0.0312 - val_loss: 82.9986 - val_accuracy: 0.0000e+00\n",
      "Epoch 2548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0828 - accuracy: 0.0000e+00 - val_loss: 85.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 2549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7548 - accuracy: 0.0156 - val_loss: 87.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 2550/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 47.7167 - accuracy: 0.0000e+00 - val_loss: 94.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 2551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8795 - accuracy: 0.0000e+00 - val_loss: 99.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 2552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7722 - accuracy: 0.0000e+00 - val_loss: 105.6904 - val_accuracy: 0.0588\n",
      "Epoch 2553/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6900 - accuracy: 0.0156 - val_loss: 104.1725 - val_accuracy: 0.0588\n",
      "Epoch 2554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0175 - accuracy: 0.0312 - val_loss: 95.3709 - val_accuracy: 0.0000e+00\n",
      "Epoch 2555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.0446 - accuracy: 0.0000e+00 - val_loss: 94.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 2556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0308 - accuracy: 0.0000e+00 - val_loss: 99.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 2557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5113 - accuracy: 0.0156 - val_loss: 104.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2420 - accuracy: 0.0000e+00 - val_loss: 99.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 2559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.7436 - accuracy: 0.0000e+00 - val_loss: 90.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2560/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.7478 - accuracy: 0.0156 - val_loss: 92.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 2561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3889 - accuracy: 0.0000e+00 - val_loss: 98.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 2562/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 57.5104 - accuracy: 0.0156 - val_loss: 98.7750 - val_accuracy: 0.0000e+00\n",
      "Epoch 2563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2443 - accuracy: 0.0156 - val_loss: 96.3357 - val_accuracy: 0.0000e+00\n",
      "Epoch 2564/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 41.6884 - accuracy: 0.0000e+00 - val_loss: 100.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 2565/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 43.7648 - accuracy: 0.0156 - val_loss: 102.1993 - val_accuracy: 0.0000e+00\n",
      "Epoch 2566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1882 - accuracy: 0.0000e+00 - val_loss: 100.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 2567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9116 - accuracy: 0.0000e+00 - val_loss: 93.7051 - val_accuracy: 0.0588\n",
      "Epoch 2568/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.8246 - accuracy: 0.0000e+00 - val_loss: 97.5492 - val_accuracy: 0.0000e+00\n",
      "Epoch 2569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4603 - accuracy: 0.0000e+00 - val_loss: 113.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6513 - accuracy: 0.0156 - val_loss: 123.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2571/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 43.5954 - accuracy: 0.0000e+00 - val_loss: 123.5456 - val_accuracy: 0.0000e+00\n",
      "Epoch 2572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7105 - accuracy: 0.0156 - val_loss: 106.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2573/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 65.4808 - accuracy: 0.0156 - val_loss: 94.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2574/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 41.5436 - accuracy: 0.0000e+00 - val_loss: 103.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 2575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0166 - accuracy: 0.0000e+00 - val_loss: 111.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 2576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0050 - accuracy: 0.0000e+00 - val_loss: 114.9937 - val_accuracy: 0.0588\n",
      "Epoch 2577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0988 - accuracy: 0.0156 - val_loss: 115.2844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1005 - accuracy: 0.0000e+00 - val_loss: 102.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 2579/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.1368 - accuracy: 0.0156 - val_loss: 92.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 2580/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 43.6282 - accuracy: 0.0000e+00 - val_loss: 90.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 2581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3504 - accuracy: 0.0000e+00 - val_loss: 105.1825 - val_accuracy: 0.0000e+00\n",
      "Epoch 2582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4872 - accuracy: 0.0000e+00 - val_loss: 115.6807 - val_accuracy: 0.0000e+00\n",
      "Epoch 2583/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 59.5319 - accuracy: 0.0312 - val_loss: 116.5793 - val_accuracy: 0.0588\n",
      "Epoch 2584/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 43.8459 - accuracy: 0.0000e+00 - val_loss: 115.2918 - val_accuracy: 0.0000e+00\n",
      "Epoch 2585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2975 - accuracy: 0.0000e+00 - val_loss: 112.7802 - val_accuracy: 0.0000e+00\n",
      "Epoch 2586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8008 - accuracy: 0.0000e+00 - val_loss: 105.7965 - val_accuracy: 0.0000e+00\n",
      "Epoch 2587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4766 - accuracy: 0.0000e+00 - val_loss: 105.5241 - val_accuracy: 0.0000e+00\n",
      "Epoch 2588/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.4650 - accuracy: 0.0000e+00 - val_loss: 113.9323 - val_accuracy: 0.0588\n",
      "Epoch 2589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0524 - accuracy: 0.0000e+00 - val_loss: 119.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2590/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 41.6031 - accuracy: 0.0000e+00 - val_loss: 112.8692 - val_accuracy: 0.0588\n",
      "Epoch 2591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3736 - accuracy: 0.0156 - val_loss: 103.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.7044 - accuracy: 0.0156 - val_loss: 95.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4865 - accuracy: 0.0000e+00 - val_loss: 100.1201 - val_accuracy: 0.0588\n",
      "Epoch 2594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6460 - accuracy: 0.0312 - val_loss: 116.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 2595/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0649 - accuracy: 0.0000e+00 - val_loss: 119.0533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2863 - accuracy: 0.0000e+00 - val_loss: 103.9018 - val_accuracy: 0.0588\n",
      "Epoch 2597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4726 - accuracy: 0.0156 - val_loss: 98.6150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.9199 - accuracy: 0.0156 - val_loss: 96.7983 - val_accuracy: 0.0588\n",
      "Epoch 2599/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3465 - accuracy: 0.0000e+00 - val_loss: 102.1502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2600/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 40.8430 - accuracy: 0.0000e+00 - val_loss: 108.5620 - val_accuracy: 0.0000e+00\n",
      "Epoch 2601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0907 - accuracy: 0.0000e+00 - val_loss: 102.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 2602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9657 - accuracy: 0.0000e+00 - val_loss: 98.4443 - val_accuracy: 0.0000e+00\n",
      "Epoch 2603/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8314 - accuracy: 0.0000e+00 - val_loss: 93.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 2604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6593 - accuracy: 0.0156 - val_loss: 102.1463 - val_accuracy: 0.0000e+00\n",
      "Epoch 2605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8153 - accuracy: 0.0156 - val_loss: 114.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 2606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1071 - accuracy: 0.0000e+00 - val_loss: 117.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 2607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7065 - accuracy: 0.0000e+00 - val_loss: 107.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 2608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6402 - accuracy: 0.0000e+00 - val_loss: 97.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 2609/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.2993 - accuracy: 0.0312 - val_loss: 94.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2610/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 38.0145 - accuracy: 0.0000e+00 - val_loss: 108.5626 - val_accuracy: 0.0000e+00\n",
      "Epoch 2611/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.8071 - accuracy: 0.0000e+00 - val_loss: 130.8533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0274 - accuracy: 0.0156 - val_loss: 134.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4715 - accuracy: 0.0000e+00 - val_loss: 126.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.7610 - accuracy: 0.0156 - val_loss: 121.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2615/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 33.3940 - accuracy: 0.0156 - val_loss: 117.6232 - val_accuracy: 0.0588\n",
      "Epoch 2616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6610 - accuracy: 0.0000e+00 - val_loss: 116.3495 - val_accuracy: 0.0588\n",
      "Epoch 2617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4774 - accuracy: 0.0156 - val_loss: 117.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 2618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0571 - accuracy: 0.0000e+00 - val_loss: 118.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 2619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.9201 - accuracy: 0.0156 - val_loss: 118.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 2620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7074 - accuracy: 0.0156 - val_loss: 119.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 2621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4682 - accuracy: 0.0000e+00 - val_loss: 110.9509 - val_accuracy: 0.0588\n",
      "Epoch 2622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4496 - accuracy: 0.0000e+00 - val_loss: 105.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3877 - accuracy: 0.0000e+00 - val_loss: 111.2294 - val_accuracy: 0.0000e+00\n",
      "Epoch 2624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5423 - accuracy: 0.0156 - val_loss: 114.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 2625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4194 - accuracy: 0.0156 - val_loss: 105.5347 - val_accuracy: 0.0000e+00\n",
      "Epoch 2626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2335 - accuracy: 0.0312 - val_loss: 100.1788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2627/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.3257 - accuracy: 0.0000e+00 - val_loss: 100.6870 - val_accuracy: 0.0000e+00\n",
      "Epoch 2628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7816 - accuracy: 0.0156 - val_loss: 105.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 2629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0344 - accuracy: 0.0000e+00 - val_loss: 110.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 2630/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.3776 - accuracy: 0.0156 - val_loss: 108.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 2631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8349 - accuracy: 0.0000e+00 - val_loss: 104.9615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9591 - accuracy: 0.0000e+00 - val_loss: 94.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 2633/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.2188 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 33.6883 - accuracy: 0.0000e+00 - val_loss: 84.2300 - val_accuracy: 0.0588\n",
      "Epoch 2634/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3561 - accuracy: 0.0312 - val_loss: 91.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 2635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2824 - accuracy: 0.0000e+00 - val_loss: 101.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 2636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6710 - accuracy: 0.0156 - val_loss: 105.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 2637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6041 - accuracy: 0.0000e+00 - val_loss: 102.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 2638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.0893 - accuracy: 0.0000e+00 - val_loss: 101.9788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9244 - accuracy: 0.0000e+00 - val_loss: 99.8668 - val_accuracy: 0.0588\n",
      "Epoch 2640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5730 - accuracy: 0.0000e+00 - val_loss: 101.4485 - val_accuracy: 0.0588\n",
      "Epoch 2641/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0531 - accuracy: 0.0000e+00 - val_loss: 109.2602 - val_accuracy: 0.0588\n",
      "Epoch 2642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1588 - accuracy: 0.0000e+00 - val_loss: 119.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 2643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4097 - accuracy: 0.0000e+00 - val_loss: 121.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 2644/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 31.2571 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 37.1213 - accuracy: 0.0000e+00 - val_loss: 116.0423 - val_accuracy: 0.0000e+00\n",
      "Epoch 2645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8150 - accuracy: 0.0000e+00 - val_loss: 110.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2646/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 45.8017 - accuracy: 0.0000e+00 - val_loss: 103.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 2647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7144 - accuracy: 0.0156 - val_loss: 112.7228 - val_accuracy: 0.0000e+00\n",
      "Epoch 2648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1426 - accuracy: 0.0000e+00 - val_loss: 122.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5769 - accuracy: 0.0000e+00 - val_loss: 124.8325 - val_accuracy: 0.0588\n",
      "Epoch 2650/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.6581 - accuracy: 0.0156 - val_loss: 119.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 2651/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4355 - accuracy: 0.0312 - val_loss: 109.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2266 - accuracy: 0.0000e+00 - val_loss: 100.3339 - val_accuracy: 0.0000e+00\n",
      "Epoch 2653/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 39.7621 - accuracy: 0.0000e+00 - val_loss: 103.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 2654/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1045 - accuracy: 0.0000e+00 - val_loss: 118.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 2655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.8714 - accuracy: 0.0156 - val_loss: 126.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 2656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0531 - accuracy: 0.0000e+00 - val_loss: 123.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 2657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1043 - accuracy: 0.0000e+00 - val_loss: 122.2044 - val_accuracy: 0.0588\n",
      "Epoch 2658/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 54.6477 - accuracy: 0.0156 - val_loss: 123.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 2659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4281 - accuracy: 0.0000e+00 - val_loss: 121.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 2660/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.7784 - accuracy: 0.0000e+00 - val_loss: 123.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 2661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.8629 - accuracy: 0.0312 - val_loss: 120.9433 - val_accuracy: 0.0588\n",
      "Epoch 2662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6827 - accuracy: 0.0000e+00 - val_loss: 114.0387 - val_accuracy: 0.0000e+00\n",
      "Epoch 2663/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6324 - accuracy: 0.0000e+00 - val_loss: 119.8144 - val_accuracy: 0.0588\n",
      "Epoch 2664/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9725 - accuracy: 0.0000e+00 - val_loss: 130.9869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8478 - accuracy: 0.0156 - val_loss: 134.9922 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8265 - accuracy: 0.0000e+00 - val_loss: 132.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.8858 - accuracy: 0.0156 - val_loss: 113.9455 - val_accuracy: 0.0000e+00\n",
      "Epoch 2668/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 34.6074 - accuracy: 0.0000e+00 - val_loss: 98.1341 - val_accuracy: 0.0588\n",
      "Epoch 2669/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 51.2090 - accuracy: 0.0156 - val_loss: 86.4985 - val_accuracy: 0.0000e+00\n",
      "Epoch 2670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8932 - accuracy: 0.0156 - val_loss: 88.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 2671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4534 - accuracy: 0.0000e+00 - val_loss: 94.3830 - val_accuracy: 0.0588\n",
      "Epoch 2672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3368 - accuracy: 0.0000e+00 - val_loss: 100.1055 - val_accuracy: 0.0588\n",
      "Epoch 2673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9747 - accuracy: 0.0000e+00 - val_loss: 107.2155 - val_accuracy: 0.0588\n",
      "Epoch 2674/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.1934 - accuracy: 0.0000e+00 - val_loss: 115.9987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2724 - accuracy: 0.0000e+00 - val_loss: 138.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2137 - accuracy: 0.0000e+00 - val_loss: 140.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2677/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.8439 - accuracy: 0.0000e+00 - val_loss: 129.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 2678/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 44.8856 - accuracy: 0.0156 - val_loss: 122.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8830 - accuracy: 0.0000e+00 - val_loss: 134.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 2680/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.0264 - accuracy: 0.0156 - val_loss: 135.6302 - val_accuracy: 0.0000e+00\n",
      "Epoch 2681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2117 - accuracy: 0.0000e+00 - val_loss: 136.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2682/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.7972 - accuracy: 0.0000e+00 - val_loss: 129.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 2683/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 66.0293 - accuracy: 0.0156 - val_loss: 115.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 2684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8588 - accuracy: 0.0156 - val_loss: 108.2097 - val_accuracy: 0.0588\n",
      "Epoch 2685/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.0805 - accuracy: 0.0000e+00 - val_loss: 102.1643 - val_accuracy: 0.0588\n",
      "Epoch 2686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0355 - accuracy: 0.0156 - val_loss: 98.6180 - val_accuracy: 0.0588\n",
      "Epoch 2687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.0584 - accuracy: 0.0000e+00 - val_loss: 99.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2688/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 40.6570 - accuracy: 0.0156 - val_loss: 115.4861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7911 - accuracy: 0.0000e+00 - val_loss: 117.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 2690/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 43.1917 - accuracy: 0.0000e+00 - val_loss: 110.6635 - val_accuracy: 0.0000e+00\n",
      "Epoch 2691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8272 - accuracy: 0.0156 - val_loss: 113.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 2692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2173 - accuracy: 0.0156 - val_loss: 106.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5675 - accuracy: 0.0000e+00 - val_loss: 103.5468 - val_accuracy: 0.0588\n",
      "Epoch 2694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.5669 - accuracy: 0.0156 - val_loss: 108.1583 - val_accuracy: 0.0588\n",
      "Epoch 2695/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.7979 - accuracy: 0.0156 - val_loss: 114.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 2696/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.6839 - accuracy: 0.0000e+00 - val_loss: 113.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 2697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9300 - accuracy: 0.0156 - val_loss: 108.1957 - val_accuracy: 0.0000e+00\n",
      "Epoch 2698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2253 - accuracy: 0.0000e+00 - val_loss: 102.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 2699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.0914 - accuracy: 0.0156 - val_loss: 96.9861 - val_accuracy: 0.0588\n",
      "Epoch 2700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0350 - accuracy: 0.0156 - val_loss: 94.9668 - val_accuracy: 0.0588\n",
      "Epoch 2701/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 53.4425 - accuracy: 0.0000e+00 - val_loss: 95.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 2702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0581 - accuracy: 0.0000e+00 - val_loss: 98.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 2703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2894 - accuracy: 0.0000e+00 - val_loss: 105.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 2704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9934 - accuracy: 0.0000e+00 - val_loss: 114.8946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2705/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 48.2789 - accuracy: 0.0000e+00 - val_loss: 120.9993 - val_accuracy: 0.0000e+00\n",
      "Epoch 2706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9391 - accuracy: 0.0156 - val_loss: 124.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3045 - accuracy: 0.0156 - val_loss: 127.9757 - val_accuracy: 0.0000e+00\n",
      "Epoch 2708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1309 - accuracy: 0.0000e+00 - val_loss: 129.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2624 - accuracy: 0.0156 - val_loss: 119.2736 - val_accuracy: 0.0000e+00\n",
      "Epoch 2710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1392 - accuracy: 0.0000e+00 - val_loss: 110.7747 - val_accuracy: 0.0588\n",
      "Epoch 2711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6509 - accuracy: 0.0000e+00 - val_loss: 109.7873 - val_accuracy: 0.0588\n",
      "Epoch 2712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2209 - accuracy: 0.0156 - val_loss: 107.0777 - val_accuracy: 0.0000e+00\n",
      "Epoch 2713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3781 - accuracy: 0.0000e+00 - val_loss: 108.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5404 - accuracy: 0.0000e+00 - val_loss: 116.0444 - val_accuracy: 0.0000e+00\n",
      "Epoch 2715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3818 - accuracy: 0.0000e+00 - val_loss: 117.7175 - val_accuracy: 0.0000e+00\n",
      "Epoch 2716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.3209 - accuracy: 0.0000e+00 - val_loss: 105.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 2717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1959 - accuracy: 0.0000e+00 - val_loss: 94.3980 - val_accuracy: 0.0000e+00\n",
      "Epoch 2718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5656 - accuracy: 0.0000e+00 - val_loss: 96.5219 - val_accuracy: 0.0000e+00\n",
      "Epoch 2719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2670 - accuracy: 0.0000e+00 - val_loss: 99.5203 - val_accuracy: 0.0000e+00\n",
      "Epoch 2720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8658 - accuracy: 0.0000e+00 - val_loss: 106.5615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3042 - accuracy: 0.0312 - val_loss: 109.7725 - val_accuracy: 0.0588\n",
      "Epoch 2722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9656 - accuracy: 0.0156 - val_loss: 117.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 2723/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 35.3741 - accuracy: 0.0000e+00 - val_loss: 125.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2724/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.5031 - accuracy: 0.0000e+00 - val_loss: 126.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 2725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2258 - accuracy: 0.0000e+00 - val_loss: 113.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4550 - accuracy: 0.0000e+00 - val_loss: 118.7986 - val_accuracy: 0.0588\n",
      "Epoch 2727/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 41.0834 - accuracy: 0.0312 - val_loss: 120.8845 - val_accuracy: 0.0588\n",
      "Epoch 2728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1429 - accuracy: 0.0000e+00 - val_loss: 115.9061 - val_accuracy: 0.0588\n",
      "Epoch 2729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4309 - accuracy: 0.0000e+00 - val_loss: 114.9518 - val_accuracy: 0.0000e+00\n",
      "Epoch 2730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4667 - accuracy: 0.0000e+00 - val_loss: 120.6729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2731/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8847 - accuracy: 0.0156 - val_loss: 122.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 2732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6193 - accuracy: 0.0156 - val_loss: 122.7058 - val_accuracy: 0.0000e+00\n",
      "Epoch 2733/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 31.7004 - accuracy: 0.0000e+00 - val_loss: 114.3048 - val_accuracy: 0.0588\n",
      "Epoch 2734/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 61.8139 - accuracy: 0.0156 - val_loss: 113.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 2735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0234 - accuracy: 0.0000e+00 - val_loss: 124.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 2736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5099 - accuracy: 0.0156 - val_loss: 127.5517 - val_accuracy: 0.0000e+00\n",
      "Epoch 2737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.9771 - accuracy: 0.0156 - val_loss: 137.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2738/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 51.9019 - accuracy: 0.0312 - val_loss: 141.1163 - val_accuracy: 0.0000e+00\n",
      "Epoch 2739/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 40.9569 - accuracy: 0.0000e+00 - val_loss: 119.5069 - val_accuracy: 0.0000e+00\n",
      "Epoch 2740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.3283 - accuracy: 0.0000e+00 - val_loss: 103.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 2741/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2693 - accuracy: 0.0000e+00 - val_loss: 93.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 2742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6990 - accuracy: 0.0000e+00 - val_loss: 88.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 2743/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 55.8498 - accuracy: 0.0000e+00 - val_loss: 85.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 2744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9096 - accuracy: 0.0000e+00 - val_loss: 85.7619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9937 - accuracy: 0.0000e+00 - val_loss: 86.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 2746/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 42.4017 - accuracy: 0.0000e+00 - val_loss: 95.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3455 - accuracy: 0.0000e+00 - val_loss: 97.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7752 - accuracy: 0.0000e+00 - val_loss: 97.5630 - val_accuracy: 0.0000e+00\n",
      "Epoch 2749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1098 - accuracy: 0.0156 - val_loss: 98.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5235 - accuracy: 0.0156 - val_loss: 103.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 2751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5052 - accuracy: 0.0000e+00 - val_loss: 109.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 2752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3696 - accuracy: 0.0156 - val_loss: 124.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2753/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.1887 - accuracy: 0.0000e+00 - val_loss: 123.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 2754/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 41.4132 - accuracy: 0.0156 - val_loss: 111.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 2755/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.6689 - accuracy: 0.0000e+00 - val_loss: 109.3847 - val_accuracy: 0.0000e+00\n",
      "Epoch 2756/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 44.3043 - accuracy: 0.0000e+00 - val_loss: 115.6301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7178 - accuracy: 0.0156 - val_loss: 112.6070 - val_accuracy: 0.0588\n",
      "Epoch 2758/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 41.9314 - accuracy: 0.0156 - val_loss: 115.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 2759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9131 - accuracy: 0.0156 - val_loss: 122.7827 - val_accuracy: 0.0588\n",
      "Epoch 2760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5777 - accuracy: 0.0156 - val_loss: 127.3297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6270 - accuracy: 0.0000e+00 - val_loss: 124.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 2762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6853 - accuracy: 0.0000e+00 - val_loss: 120.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 2763/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 28.4189 - accuracy: 0.0156 - val_loss: 105.9496 - val_accuracy: 0.0000e+00\n",
      "Epoch 2764/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 45.6823 - accuracy: 0.0156 - val_loss: 94.3752 - val_accuracy: 0.0000e+00\n",
      "Epoch 2765/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 33.7618 - accuracy: 0.0312 - val_loss: 98.4677 - val_accuracy: 0.0000e+00\n",
      "Epoch 2766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.2808 - accuracy: 0.0156 - val_loss: 129.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2767/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 49.9011 - accuracy: 0.0000e+00 - val_loss: 140.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 2768/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.3246 - accuracy: 0.0000e+00 - val_loss: 130.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 2769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5981 - accuracy: 0.0156 - val_loss: 117.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2770/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 35.1897 - accuracy: 0.0156 - val_loss: 108.5879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2771/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.6699 - accuracy: 0.0156 - val_loss: 114.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8078 - accuracy: 0.0000e+00 - val_loss: 125.9701 - val_accuracy: 0.0000e+00\n",
      "Epoch 2773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3724 - accuracy: 0.0000e+00 - val_loss: 132.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3684 - accuracy: 0.0156 - val_loss: 131.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 2775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4214 - accuracy: 0.0000e+00 - val_loss: 123.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 2776/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.5584 - accuracy: 0.0000e+00 - val_loss: 115.2524 - val_accuracy: 0.0588\n",
      "Epoch 2777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7701 - accuracy: 0.0000e+00 - val_loss: 112.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2778/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 48.3259 - accuracy: 0.0000e+00 - val_loss: 115.9554 - val_accuracy: 0.0588\n",
      "Epoch 2779/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 51.1996 - accuracy: 0.0000e+00 - val_loss: 122.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 2780/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.3471 - accuracy: 0.0156 - val_loss: 122.9337 - val_accuracy: 0.0000e+00\n",
      "Epoch 2781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8480 - accuracy: 0.0000e+00 - val_loss: 117.6623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2782/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.7827 - accuracy: 0.0000e+00 - val_loss: 121.5655 - val_accuracy: 0.0000e+00\n",
      "Epoch 2783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1970 - accuracy: 0.0156 - val_loss: 128.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 2784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.9900 - accuracy: 0.0000e+00 - val_loss: 128.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 2785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1166 - accuracy: 0.0312 - val_loss: 111.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 2786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2165 - accuracy: 0.0000e+00 - val_loss: 96.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.7349 - accuracy: 0.0000e+00 - val_loss: 92.2009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2788/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5534 - accuracy: 0.0000e+00 - val_loss: 99.4680 - val_accuracy: 0.0000e+00\n",
      "Epoch 2789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8543 - accuracy: 0.0156 - val_loss: 118.3965 - val_accuracy: 0.0000e+00\n",
      "Epoch 2790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6115 - accuracy: 0.0000e+00 - val_loss: 127.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2791/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1178 - accuracy: 0.0156 - val_loss: 117.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 2792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0917 - accuracy: 0.0156 - val_loss: 110.3720 - val_accuracy: 0.0588\n",
      "Epoch 2793/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9993 - accuracy: 0.0000e+00 - val_loss: 112.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7280 - accuracy: 0.0156 - val_loss: 117.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 2795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1182 - accuracy: 0.0156 - val_loss: 119.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 2796/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 43.2982 - accuracy: 0.0000e+00 - val_loss: 117.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 2797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7927 - accuracy: 0.0000e+00 - val_loss: 116.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2798/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 35.3699 - accuracy: 0.0000e+00 - val_loss: 112.6568 - val_accuracy: 0.0588\n",
      "Epoch 2799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4496 - accuracy: 0.0156 - val_loss: 107.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 2800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8642 - accuracy: 0.0000e+00 - val_loss: 110.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 2801/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.8822 - accuracy: 0.0000e+00 - val_loss: 118.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 2802/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.6013 - accuracy: 0.0000e+00 - val_loss: 128.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2803/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.0302 - accuracy: 0.0156 - val_loss: 122.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4614 - accuracy: 0.0000e+00 - val_loss: 116.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 2805/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.2837 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.9804 - accuracy: 0.0000e+00 - val_loss: 106.7503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1526 - accuracy: 0.0156 - val_loss: 106.5464 - val_accuracy: 0.0000e+00\n",
      "Epoch 2807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0689 - accuracy: 0.0000e+00 - val_loss: 110.3381 - val_accuracy: 0.0000e+00\n",
      "Epoch 2808/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.8306 - accuracy: 0.0312 - val_loss: 113.4948 - val_accuracy: 0.0588\n",
      "Epoch 2809/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.3001 - accuracy: 0.0000e+00 - val_loss: 119.2117 - val_accuracy: 0.0000e+00\n",
      "Epoch 2810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0911 - accuracy: 0.0000e+00 - val_loss: 114.0832 - val_accuracy: 0.0588\n",
      "Epoch 2811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1653 - accuracy: 0.0000e+00 - val_loss: 114.2273 - val_accuracy: 0.0588\n",
      "Epoch 2812/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.7263 - accuracy: 0.0156 - val_loss: 115.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0953 - accuracy: 0.0156 - val_loss: 117.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 2814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1872 - accuracy: 0.0000e+00 - val_loss: 123.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 2815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7351 - accuracy: 0.0000e+00 - val_loss: 122.7959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3826 - accuracy: 0.0156 - val_loss: 118.2489 - val_accuracy: 0.0000e+00\n",
      "Epoch 2817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6057 - accuracy: 0.0000e+00 - val_loss: 119.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2818/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.9210 - accuracy: 0.0000e+00 - val_loss: 126.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7068 - accuracy: 0.0156 - val_loss: 117.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 2820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5368 - accuracy: 0.0156 - val_loss: 100.6871 - val_accuracy: 0.0000e+00\n",
      "Epoch 2821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9746 - accuracy: 0.0156 - val_loss: 101.5634 - val_accuracy: 0.0000e+00\n",
      "Epoch 2822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2097 - accuracy: 0.0000e+00 - val_loss: 114.6962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.9047 - accuracy: 0.0000e+00 - val_loss: 124.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2824/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 47.4392 - accuracy: 0.0000e+00 - val_loss: 124.8852 - val_accuracy: 0.0000e+00\n",
      "Epoch 2825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2038 - accuracy: 0.0000e+00 - val_loss: 108.5661 - val_accuracy: 0.0000e+00\n",
      "Epoch 2826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.7021 - accuracy: 0.0000e+00 - val_loss: 103.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 2827/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.4260 - accuracy: 0.0000e+00 - val_loss: 106.5299 - val_accuracy: 0.0000e+00\n",
      "Epoch 2828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1353 - accuracy: 0.0156 - val_loss: 124.2159 - val_accuracy: 0.0000e+00\n",
      "Epoch 2829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2169 - accuracy: 0.0000e+00 - val_loss: 129.7243 - val_accuracy: 0.0000e+00\n",
      "Epoch 2830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6648 - accuracy: 0.0156 - val_loss: 113.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 2831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7908 - accuracy: 0.0000e+00 - val_loss: 95.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2832/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 79.2239 - accuracy: 0.0156 - val_loss: 94.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 2833/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 51.0249 - accuracy: 0.0156 - val_loss: 111.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 2834/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.5403 - accuracy: 0.0000e+00 - val_loss: 112.9937 - val_accuracy: 0.0000e+00\n",
      "Epoch 2835/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 45.9191 - accuracy: 0.0000e+00 - val_loss: 111.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 2836/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 52.6180 - accuracy: 0.0156 - val_loss: 103.8052 - val_accuracy: 0.0000e+00\n",
      "Epoch 2837/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 36.2535 - accuracy: 0.0000e+00 - val_loss: 99.4617 - val_accuracy: 0.0588\n",
      "Epoch 2838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0250 - accuracy: 0.0156 - val_loss: 100.2908 - val_accuracy: 0.0588\n",
      "Epoch 2839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1843 - accuracy: 0.0000e+00 - val_loss: 102.1607 - val_accuracy: 0.0588\n",
      "Epoch 2840/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 37.0679 - accuracy: 0.0000e+00 - val_loss: 111.8520 - val_accuracy: 0.0000e+00\n",
      "Epoch 2841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8956 - accuracy: 0.0156 - val_loss: 116.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7528 - accuracy: 0.0000e+00 - val_loss: 119.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 2843/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 50.4758 - accuracy: 0.0000e+00 - val_loss: 128.9679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2844/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.5128 - accuracy: 0.0000e+00 - val_loss: 132.2404 - val_accuracy: 0.0000e+00\n",
      "Epoch 2845/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 55.9264 - accuracy: 0.0156 - val_loss: 126.9421 - val_accuracy: 0.0588\n",
      "Epoch 2846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3608 - accuracy: 0.0156 - val_loss: 109.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 2847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0225 - accuracy: 0.0312 - val_loss: 92.5006 - val_accuracy: 0.0588\n",
      "Epoch 2848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3388 - accuracy: 0.0000e+00 - val_loss: 98.1930 - val_accuracy: 0.0588\n",
      "Epoch 2849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2535 - accuracy: 0.0156 - val_loss: 121.6252 - val_accuracy: 0.0588\n",
      "Epoch 2850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1605 - accuracy: 0.0156 - val_loss: 135.7416 - val_accuracy: 0.0000e+00\n",
      "Epoch 2851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9455 - accuracy: 0.0156 - val_loss: 142.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2852/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 38.1853 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 43.1169 - accuracy: 0.0000e+00 - val_loss: 132.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 2853/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 48.2525 - accuracy: 0.0000e+00 - val_loss: 119.4656 - val_accuracy: 0.0588\n",
      "Epoch 2854/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 41.2273 - accuracy: 0.0156 - val_loss: 108.3932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4528 - accuracy: 0.0156 - val_loss: 110.2049 - val_accuracy: 0.0588\n",
      "Epoch 2856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2188 - accuracy: 0.0156 - val_loss: 115.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 2857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2867 - accuracy: 0.0000e+00 - val_loss: 118.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 2858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6191 - accuracy: 0.0000e+00 - val_loss: 115.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 2859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8823 - accuracy: 0.0000e+00 - val_loss: 113.4815 - val_accuracy: 0.0588\n",
      "Epoch 2860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1366 - accuracy: 0.0000e+00 - val_loss: 112.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 2861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2146 - accuracy: 0.0156 - val_loss: 114.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 2862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9108 - accuracy: 0.0156 - val_loss: 117.3598 - val_accuracy: 0.0000e+00\n",
      "Epoch 2863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0587 - accuracy: 0.0000e+00 - val_loss: 115.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 2864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4438 - accuracy: 0.0000e+00 - val_loss: 112.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 2865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.1114 - accuracy: 0.0000e+00 - val_loss: 115.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 2866/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.2627 - accuracy: 0.0312 - val_loss: 136.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 2867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4559 - accuracy: 0.0156 - val_loss: 130.8479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5242 - accuracy: 0.0000e+00 - val_loss: 107.6115 - val_accuracy: 0.0000e+00\n",
      "Epoch 2869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.8410 - accuracy: 0.0312 - val_loss: 99.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 2870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8835 - accuracy: 0.0000e+00 - val_loss: 98.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 2871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9171 - accuracy: 0.0000e+00 - val_loss: 105.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 2872/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.8100 - accuracy: 0.0156 - val_loss: 122.3163 - val_accuracy: 0.0588\n",
      "Epoch 2873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1831 - accuracy: 0.0000e+00 - val_loss: 128.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 2874/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 51.8562 - accuracy: 0.0312 - val_loss: 127.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2603 - accuracy: 0.0000e+00 - val_loss: 119.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 2876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.2674 - accuracy: 0.0156 - val_loss: 117.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8871 - accuracy: 0.0000e+00 - val_loss: 123.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 2878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5712 - accuracy: 0.0000e+00 - val_loss: 134.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 2879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2414 - accuracy: 0.0156 - val_loss: 126.5653 - val_accuracy: 0.0000e+00\n",
      "Epoch 2880/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.1862 - accuracy: 0.0000e+00 - val_loss: 115.4605 - val_accuracy: 0.0588\n",
      "Epoch 2881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7307 - accuracy: 0.0000e+00 - val_loss: 104.9612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.9228 - accuracy: 0.0000e+00 - val_loss: 109.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 2883/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4955 - accuracy: 0.0156 - val_loss: 118.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 2884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5628 - accuracy: 0.0156 - val_loss: 125.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 2885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0200 - accuracy: 0.0156 - val_loss: 128.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6646 - accuracy: 0.0156 - val_loss: 111.6528 - val_accuracy: 0.0000e+00\n",
      "Epoch 2887/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.7686 - accuracy: 0.0156 - val_loss: 103.7820 - val_accuracy: 0.0000e+00\n",
      "Epoch 2888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4586 - accuracy: 0.0156 - val_loss: 107.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1430 - accuracy: 0.0000e+00 - val_loss: 110.5155 - val_accuracy: 0.0000e+00\n",
      "Epoch 2890/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.3850 - accuracy: 0.0000e+00 - val_loss: 117.6297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2891/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.8220 - accuracy: 0.0156 - val_loss: 121.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7349 - accuracy: 0.0000e+00 - val_loss: 127.9112 - val_accuracy: 0.0588\n",
      "Epoch 2893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7591 - accuracy: 0.0312 - val_loss: 129.9979 - val_accuracy: 0.0588\n",
      "Epoch 2894/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.1791 - accuracy: 0.0000e+00 - val_loss: 126.6844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0836 - accuracy: 0.0000e+00 - val_loss: 114.7864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9652 - accuracy: 0.0000e+00 - val_loss: 104.1989 - val_accuracy: 0.0000e+00\n",
      "Epoch 2897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.0980 - accuracy: 0.0000e+00 - val_loss: 99.6844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6247 - accuracy: 0.0000e+00 - val_loss: 111.6959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3067 - accuracy: 0.0000e+00 - val_loss: 116.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 2900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7110 - accuracy: 0.0000e+00 - val_loss: 121.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 2901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.8496 - accuracy: 0.0000e+00 - val_loss: 121.3939 - val_accuracy: 0.0588\n",
      "Epoch 2902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8847 - accuracy: 0.0000e+00 - val_loss: 128.3743 - val_accuracy: 0.0588\n",
      "Epoch 2903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5594 - accuracy: 0.0000e+00 - val_loss: 135.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 2904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9274 - accuracy: 0.0156 - val_loss: 140.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 2905/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6355 - accuracy: 0.0000e+00 - val_loss: 139.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 2906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6912 - accuracy: 0.0000e+00 - val_loss: 128.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 2907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5678 - accuracy: 0.0000e+00 - val_loss: 108.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 2908/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 47.8400 - accuracy: 0.0000e+00 - val_loss: 107.5919 - val_accuracy: 0.0000e+00\n",
      "Epoch 2909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7883 - accuracy: 0.0000e+00 - val_loss: 109.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 2910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4468 - accuracy: 0.0312 - val_loss: 116.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 2911/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 37.4460 - accuracy: 0.0000e+00 - val_loss: 119.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.7236 - accuracy: 0.0000e+00 - val_loss: 124.3538 - val_accuracy: 0.0000e+00\n",
      "Epoch 2913/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 48.1976 - accuracy: 0.0156 - val_loss: 125.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 2914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9278 - accuracy: 0.0000e+00 - val_loss: 126.5414 - val_accuracy: 0.0000e+00\n",
      "Epoch 2915/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3698 - accuracy: 0.0156 - val_loss: 119.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 2916/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.7700 - accuracy: 0.0000e+00 - val_loss: 110.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 2917/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5206 - accuracy: 0.0156 - val_loss: 103.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1560 - accuracy: 0.0000e+00 - val_loss: 97.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 2919/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 42.8514 - accuracy: 0.0000e+00 - val_loss: 103.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2920/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 36.4228 - accuracy: 0.0156 - val_loss: 119.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2297 - accuracy: 0.0312 - val_loss: 134.1469 - val_accuracy: 0.0000e+00\n",
      "Epoch 2922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3258 - accuracy: 0.0156 - val_loss: 127.5565 - val_accuracy: 0.0000e+00\n",
      "Epoch 2923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5166 - accuracy: 0.0156 - val_loss: 120.1007 - val_accuracy: 0.0000e+00\n",
      "Epoch 2924/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1481 - accuracy: 0.0000e+00 - val_loss: 115.7946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7542 - accuracy: 0.0000e+00 - val_loss: 113.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 2926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8803 - accuracy: 0.0000e+00 - val_loss: 126.3861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2927/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.6140 - accuracy: 0.0312 - val_loss: 136.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 2928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0910 - accuracy: 0.0156 - val_loss: 130.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3532 - accuracy: 0.0000e+00 - val_loss: 112.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 2930/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 55.9770 - accuracy: 0.0000e+00 - val_loss: 111.9818 - val_accuracy: 0.0588\n",
      "Epoch 2931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1977 - accuracy: 0.0000e+00 - val_loss: 119.0504 - val_accuracy: 0.0588\n",
      "Epoch 2932/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 43.0395 - accuracy: 0.0000e+00 - val_loss: 125.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 2933/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 51.0803 - accuracy: 0.0312 - val_loss: 126.8014 - val_accuracy: 0.0000e+00\n",
      "Epoch 2934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1526 - accuracy: 0.0000e+00 - val_loss: 119.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 2935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4866 - accuracy: 0.0312 - val_loss: 113.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.8055 - accuracy: 0.0000e+00 - val_loss: 122.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8793 - accuracy: 0.0000e+00 - val_loss: 129.2450 - val_accuracy: 0.0000e+00\n",
      "Epoch 2938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4710 - accuracy: 0.0156 - val_loss: 139.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 2939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.4675 - accuracy: 0.0000e+00 - val_loss: 144.8236 - val_accuracy: 0.0000e+00\n",
      "Epoch 2940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.0356 - accuracy: 0.0000e+00 - val_loss: 130.6119 - val_accuracy: 0.0000e+00\n",
      "Epoch 2941/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.3148 - accuracy: 0.0000e+00 - val_loss: 117.3394 - val_accuracy: 0.0588\n",
      "Epoch 2942/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 62.1521 - accuracy: 0.0156 - val_loss: 121.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.9729 - accuracy: 0.0156 - val_loss: 127.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 2944/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 32.7131 - accuracy: 0.0156 - val_loss: 130.8941 - val_accuracy: 0.0000e+00\n",
      "Epoch 2945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2842 - accuracy: 0.0156 - val_loss: 128.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 2946/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 42.7986 - accuracy: 0.0156 - val_loss: 117.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5172 - accuracy: 0.0156 - val_loss: 108.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6185 - accuracy: 0.0156 - val_loss: 107.6591 - val_accuracy: 0.0588\n",
      "Epoch 2949/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.5010 - accuracy: 0.0156 - val_loss: 111.9297 - val_accuracy: 0.0588\n",
      "Epoch 2950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2278 - accuracy: 0.0000e+00 - val_loss: 116.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 2951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3745 - accuracy: 0.0000e+00 - val_loss: 118.0360 - val_accuracy: 0.0000e+00\n",
      "Epoch 2952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6773 - accuracy: 0.0000e+00 - val_loss: 121.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 2953/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.6746 - accuracy: 0.0000e+00 - val_loss: 120.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 2954/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 43.6828 - accuracy: 0.0000e+00 - val_loss: 118.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 2955/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7230 - accuracy: 0.0000e+00 - val_loss: 123.6603 - val_accuracy: 0.0000e+00\n",
      "Epoch 2956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1456 - accuracy: 0.0000e+00 - val_loss: 129.4005 - val_accuracy: 0.0000e+00\n",
      "Epoch 2957/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 43.4517 - accuracy: 0.0000e+00 - val_loss: 129.9032 - val_accuracy: 0.0000e+00\n",
      "Epoch 2958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5996 - accuracy: 0.0000e+00 - val_loss: 122.9545 - val_accuracy: 0.0000e+00\n",
      "Epoch 2959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0926 - accuracy: 0.0156 - val_loss: 115.3420 - val_accuracy: 0.0588\n",
      "Epoch 2960/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 56.9089 - accuracy: 0.0000e+00 - val_loss: 113.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5750 - accuracy: 0.0156 - val_loss: 120.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 2962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3434 - accuracy: 0.0000e+00 - val_loss: 128.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 2963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1828 - accuracy: 0.0000e+00 - val_loss: 125.1502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2964/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6309 - accuracy: 0.0000e+00 - val_loss: 115.9901 - val_accuracy: 0.0588\n",
      "Epoch 2965/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 46.7964 - accuracy: 0.0000e+00 - val_loss: 111.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 2966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4491 - accuracy: 0.0000e+00 - val_loss: 107.6157 - val_accuracy: 0.0000e+00\n",
      "Epoch 2967/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.5109 - accuracy: 0.0156 - val_loss: 109.3725 - val_accuracy: 0.0000e+00\n",
      "Epoch 2968/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.7603 - accuracy: 0.0000e+00 - val_loss: 114.6637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2969/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.3386 - accuracy: 0.0156 - val_loss: 125.3826 - val_accuracy: 0.0000e+00\n",
      "Epoch 2970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5446 - accuracy: 0.0156 - val_loss: 140.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7468 - accuracy: 0.0156 - val_loss: 146.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 2972/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 37.8948 - accuracy: 0.0000e+00 - val_loss: 139.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 2973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1342 - accuracy: 0.0000e+00 - val_loss: 122.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.5700 - accuracy: 0.0156 - val_loss: 116.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 2975/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5788 - accuracy: 0.0000e+00 - val_loss: 116.9369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2976/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 50.6994 - accuracy: 0.0000e+00 - val_loss: 122.4366 - val_accuracy: 0.0588\n",
      "Epoch 2977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8364 - accuracy: 0.0156 - val_loss: 127.1969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2978/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 45.4937 - accuracy: 0.0156 - val_loss: 124.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 2979/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 59.2251 - accuracy: 0.0156 - val_loss: 125.8039 - val_accuracy: 0.0000e+00\n",
      "Epoch 2980/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 48.5768 - accuracy: 0.0000e+00 - val_loss: 123.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2981/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 56.4083 - accuracy: 0.0469 - val_loss: 124.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 2982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9719 - accuracy: 0.0000e+00 - val_loss: 126.5175 - val_accuracy: 0.0000e+00\n",
      "Epoch 2983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9962 - accuracy: 0.0000e+00 - val_loss: 127.1879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3639 - accuracy: 0.0156 - val_loss: 127.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 2985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7262 - accuracy: 0.0000e+00 - val_loss: 121.3421 - val_accuracy: 0.0000e+00\n",
      "Epoch 2986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5438 - accuracy: 0.0156 - val_loss: 113.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 2987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5569 - accuracy: 0.0312 - val_loss: 115.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 2988/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 41.3640 - accuracy: 0.0000e+00 - val_loss: 116.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0268 - accuracy: 0.0000e+00 - val_loss: 114.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 2990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.1467 - accuracy: 0.0000e+00 - val_loss: 112.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2991/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4245 - accuracy: 0.0000e+00 - val_loss: 117.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2992/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 42.9170 - accuracy: 0.0156 - val_loss: 122.4594 - val_accuracy: 0.0588\n",
      "Epoch 2993/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.1438 - accuracy: 0.0156 - val_loss: 125.1486 - val_accuracy: 0.0000e+00\n",
      "Epoch 2994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4197 - accuracy: 0.0000e+00 - val_loss: 123.4451 - val_accuracy: 0.0588\n",
      "Epoch 2995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6181 - accuracy: 0.0312 - val_loss: 122.9945 - val_accuracy: 0.0588\n",
      "Epoch 2996/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 37.6168 - accuracy: 0.0156 - val_loss: 124.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 2997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.7287 - accuracy: 0.0000e+00 - val_loss: 121.5195 - val_accuracy: 0.0588\n",
      "Epoch 2998/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0958 - accuracy: 0.0000e+00 - val_loss: 118.7551 - val_accuracy: 0.0588\n",
      "Epoch 2999/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.5320 - accuracy: 0.0000e+00 - val_loss: 120.7692 - val_accuracy: 0.0588\n",
      "Epoch 3000/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 43.4916 - accuracy: 0.0156 - val_loss: 123.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 3001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3187 - accuracy: 0.0156 - val_loss: 123.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 3002/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6361 - accuracy: 0.0156 - val_loss: 123.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 3003/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8995 - accuracy: 0.0000e+00 - val_loss: 125.9347 - val_accuracy: 0.0588\n",
      "Epoch 3004/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7735 - accuracy: 0.0000e+00 - val_loss: 130.0230 - val_accuracy: 0.0588\n",
      "Epoch 3005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0592 - accuracy: 0.0000e+00 - val_loss: 126.2358 - val_accuracy: 0.0588\n",
      "Epoch 3006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0479 - accuracy: 0.0000e+00 - val_loss: 116.4515 - val_accuracy: 0.0588\n",
      "Epoch 3007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1182 - accuracy: 0.0156 - val_loss: 112.1770 - val_accuracy: 0.1176\n",
      "Epoch 3008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5395 - accuracy: 0.0156 - val_loss: 117.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 3009/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.2357 - accuracy: 0.0156 - val_loss: 122.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 3010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9877 - accuracy: 0.0000e+00 - val_loss: 116.7399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3011/10000\n",
      "64/64 [==============================] - 0s 52us/step - loss: 48.6586 - accuracy: 0.0000e+00 - val_loss: 111.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 3012/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 41.1274 - accuracy: 0.0000e+00 - val_loss: 108.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 3013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1399 - accuracy: 0.0156 - val_loss: 111.7234 - val_accuracy: 0.0000e+00\n",
      "Epoch 3014/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5188 - accuracy: 0.0312 - val_loss: 119.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 3015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2617 - accuracy: 0.0312 - val_loss: 126.9794 - val_accuracy: 0.0000e+00\n",
      "Epoch 3016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8473 - accuracy: 0.0000e+00 - val_loss: 123.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 3017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4693 - accuracy: 0.0156 - val_loss: 115.7812 - val_accuracy: 0.0588\n",
      "Epoch 3018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7113 - accuracy: 0.0156 - val_loss: 118.6259 - val_accuracy: 0.0588\n",
      "Epoch 3019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0890 - accuracy: 0.0156 - val_loss: 127.3113 - val_accuracy: 0.0000e+00\n",
      "Epoch 3020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5444 - accuracy: 0.0000e+00 - val_loss: 136.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 3021/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.5972 - accuracy: 0.0312 - val_loss: 129.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 3022/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 45.7816 - accuracy: 0.0156 - val_loss: 117.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 3023/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.4510 - accuracy: 0.0156 - val_loss: 115.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 3024/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 74.4445 - accuracy: 0.0000e+00 - val_loss: 123.7797 - val_accuracy: 0.0000e+00\n",
      "Epoch 3025/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 45.7013 - accuracy: 0.0000e+00 - val_loss: 123.4771 - val_accuracy: 0.0000e+00\n",
      "Epoch 3026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5907 - accuracy: 0.0156 - val_loss: 116.6741 - val_accuracy: 0.0588\n",
      "Epoch 3027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5952 - accuracy: 0.0156 - val_loss: 104.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 3028/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.0307 - accuracy: 0.0000e+00 - val_loss: 99.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 3029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2795 - accuracy: 0.0000e+00 - val_loss: 106.5617 - val_accuracy: 0.0000e+00\n",
      "Epoch 3030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.3506 - accuracy: 0.0156 - val_loss: 126.7453 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0578 - accuracy: 0.0000e+00 - val_loss: 146.0973 - val_accuracy: 0.0000e+00\n",
      "Epoch 3032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6670 - accuracy: 0.0000e+00 - val_loss: 143.5786 - val_accuracy: 0.0000e+00\n",
      "Epoch 3033/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5635 - accuracy: 0.0156 - val_loss: 124.6148 - val_accuracy: 0.0000e+00\n",
      "Epoch 3034/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 56.1101 - accuracy: 0.0156 - val_loss: 109.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 3035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8480 - accuracy: 0.0156 - val_loss: 111.1654 - val_accuracy: 0.0588\n",
      "Epoch 3036/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 46.0772 - accuracy: 0.0156 - val_loss: 121.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 3037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1758 - accuracy: 0.0000e+00 - val_loss: 131.2552 - val_accuracy: 0.0000e+00\n",
      "Epoch 3038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6875 - accuracy: 0.0000e+00 - val_loss: 120.7794 - val_accuracy: 0.0000e+00\n",
      "Epoch 3039/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0170 - accuracy: 0.0156 - val_loss: 108.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 3040/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.1768 - accuracy: 0.0000e+00 - val_loss: 106.7485 - val_accuracy: 0.0000e+00\n",
      "Epoch 3041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4644 - accuracy: 0.0000e+00 - val_loss: 105.3025 - val_accuracy: 0.0000e+00\n",
      "Epoch 3042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8653 - accuracy: 0.0156 - val_loss: 103.9374 - val_accuracy: 0.0000e+00\n",
      "Epoch 3043/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4716 - accuracy: 0.0156 - val_loss: 106.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 3044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0673 - accuracy: 0.0312 - val_loss: 114.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 3045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1945 - accuracy: 0.0000e+00 - val_loss: 114.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 3046/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.3897 - accuracy: 0.0000e+00 - val_loss: 118.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3047/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0110 - accuracy: 0.0000e+00 - val_loss: 128.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 3048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7032 - accuracy: 0.0000e+00 - val_loss: 131.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 3049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2150 - accuracy: 0.0156 - val_loss: 125.6613 - val_accuracy: 0.0588\n",
      "Epoch 3050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0286 - accuracy: 0.0000e+00 - val_loss: 119.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3051/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7993 - accuracy: 0.0000e+00 - val_loss: 121.0637 - val_accuracy: 0.0000e+00\n",
      "Epoch 3052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8447 - accuracy: 0.0000e+00 - val_loss: 122.2777 - val_accuracy: 0.0000e+00\n",
      "Epoch 3053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1914 - accuracy: 0.0156 - val_loss: 131.9077 - val_accuracy: 0.0588\n",
      "Epoch 3054/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6364 - accuracy: 0.0156 - val_loss: 134.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 3055/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.9099 - accuracy: 0.0000e+00 - val_loss: 127.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 3056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3192 - accuracy: 0.0000e+00 - val_loss: 111.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 3057/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 37.8232 - accuracy: 0.0000e+00 - val_loss: 104.3403 - val_accuracy: 0.0000e+00\n",
      "Epoch 3058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0338 - accuracy: 0.0000e+00 - val_loss: 99.5241 - val_accuracy: 0.0588\n",
      "Epoch 3059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5500 - accuracy: 0.0156 - val_loss: 112.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 3060/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.0684 - accuracy: 0.0000e+00 - val_loss: 117.7621 - val_accuracy: 0.0588\n",
      "Epoch 3061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1987 - accuracy: 0.0156 - val_loss: 112.9035 - val_accuracy: 0.0588\n",
      "Epoch 3062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.3989 - accuracy: 0.0000e+00 - val_loss: 99.8800 - val_accuracy: 0.1176\n",
      "Epoch 3063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1718 - accuracy: 0.0156 - val_loss: 99.1243 - val_accuracy: 0.1176\n",
      "Epoch 3064/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.7802 - accuracy: 0.0000e+00 - val_loss: 106.3018 - val_accuracy: 0.0588\n",
      "Epoch 3065/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9247 - accuracy: 0.0156 - val_loss: 118.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 3066/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5699 - accuracy: 0.0156 - val_loss: 132.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 3067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9786 - accuracy: 0.0156 - val_loss: 128.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3068/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 37.0582 - accuracy: 0.0000e+00 - val_loss: 123.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 3069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1509 - accuracy: 0.0000e+00 - val_loss: 122.1702 - val_accuracy: 0.0588\n",
      "Epoch 3070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1408 - accuracy: 0.0156 - val_loss: 116.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 3071/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 49.1423 - accuracy: 0.0156 - val_loss: 111.8038 - val_accuracy: 0.0000e+00\n",
      "Epoch 3072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2422 - accuracy: 0.0156 - val_loss: 105.0864 - val_accuracy: 0.0588\n",
      "Epoch 3073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8554 - accuracy: 0.0000e+00 - val_loss: 104.3377 - val_accuracy: 0.0588\n",
      "Epoch 3074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7912 - accuracy: 0.0000e+00 - val_loss: 102.6717 - val_accuracy: 0.0588\n",
      "Epoch 3075/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.0793 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 29.1891 - accuracy: 0.0156 - val_loss: 107.0271 - val_accuracy: 0.0588\n",
      "Epoch 3076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2093 - accuracy: 0.0000e+00 - val_loss: 102.9057 - val_accuracy: 0.0588\n",
      "Epoch 3077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7564 - accuracy: 0.0156 - val_loss: 95.7460 - val_accuracy: 0.0588\n",
      "Epoch 3078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6852 - accuracy: 0.0000e+00 - val_loss: 104.2736 - val_accuracy: 0.0588\n",
      "Epoch 3079/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 42.5574 - accuracy: 0.0156 - val_loss: 119.7770 - val_accuracy: 0.0000e+00\n",
      "Epoch 3080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6430 - accuracy: 0.0000e+00 - val_loss: 129.4722 - val_accuracy: 0.0000e+00\n",
      "Epoch 3081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1573 - accuracy: 0.0000e+00 - val_loss: 125.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 3082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0990 - accuracy: 0.0156 - val_loss: 117.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 3083/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 44.6984 - accuracy: 0.0000e+00 - val_loss: 111.6803 - val_accuracy: 0.0000e+00\n",
      "Epoch 3084/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.8959 - accuracy: 0.0000e+00 - val_loss: 115.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 3085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8730 - accuracy: 0.0000e+00 - val_loss: 117.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 3086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7040 - accuracy: 0.0000e+00 - val_loss: 120.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 3087/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.8721 - accuracy: 0.0156 - val_loss: 129.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 3088/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1442 - accuracy: 0.0156 - val_loss: 132.3589 - val_accuracy: 0.0588\n",
      "Epoch 3089/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 56.8920 - accuracy: 0.0000e+00 - val_loss: 127.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 3090/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5987 - accuracy: 0.0000e+00 - val_loss: 111.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 3091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0359 - accuracy: 0.0000e+00 - val_loss: 104.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 3092/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 59.8525 - accuracy: 0.0000e+00 - val_loss: 106.8759 - val_accuracy: 0.0000e+00\n",
      "Epoch 3093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5477 - accuracy: 0.0312 - val_loss: 111.6664 - val_accuracy: 0.0000e+00\n",
      "Epoch 3094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5045 - accuracy: 0.0156 - val_loss: 113.2582 - val_accuracy: 0.0000e+00\n",
      "Epoch 3095/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 45.4550 - accuracy: 0.0000e+00 - val_loss: 115.1499 - val_accuracy: 0.0000e+00\n",
      "Epoch 3096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0391 - accuracy: 0.0156 - val_loss: 112.4963 - val_accuracy: 0.0000e+00\n",
      "Epoch 3097/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.6136 - accuracy: 0.0156 - val_loss: 114.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 3098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.3983 - accuracy: 0.0000e+00 - val_loss: 117.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 3099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9948 - accuracy: 0.0000e+00 - val_loss: 119.3608 - val_accuracy: 0.0000e+00\n",
      "Epoch 3100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3064 - accuracy: 0.0000e+00 - val_loss: 119.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 3101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5914 - accuracy: 0.0000e+00 - val_loss: 119.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3102/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 43.3841 - accuracy: 0.0000e+00 - val_loss: 119.7836 - val_accuracy: 0.0588\n",
      "Epoch 3103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3203 - accuracy: 0.0156 - val_loss: 124.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 3104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6572 - accuracy: 0.0000e+00 - val_loss: 126.7448 - val_accuracy: 0.0000e+00\n",
      "Epoch 3105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0399 - accuracy: 0.0000e+00 - val_loss: 116.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 3106/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 53.4623 - accuracy: 0.0000e+00 - val_loss: 114.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3107/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 52.4382 - accuracy: 0.0000e+00 - val_loss: 117.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 3108/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4666 - accuracy: 0.0000e+00 - val_loss: 123.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 3109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3352 - accuracy: 0.0000e+00 - val_loss: 123.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 3110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8533 - accuracy: 0.0156 - val_loss: 125.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 3111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1608 - accuracy: 0.0000e+00 - val_loss: 130.1239 - val_accuracy: 0.0000e+00\n",
      "Epoch 3112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9111 - accuracy: 0.0156 - val_loss: 128.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 3113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3809 - accuracy: 0.0000e+00 - val_loss: 125.2884 - val_accuracy: 0.0588\n",
      "Epoch 3114/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 41.2540 - accuracy: 0.0156 - val_loss: 121.4897 - val_accuracy: 0.0588\n",
      "Epoch 3115/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.5982 - accuracy: 0.0156 - val_loss: 123.6673 - val_accuracy: 0.0588\n",
      "Epoch 3116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4920 - accuracy: 0.0000e+00 - val_loss: 122.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 3117/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.4832 - accuracy: 0.0000e+00 - val_loss: 125.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 3118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6359 - accuracy: 0.0000e+00 - val_loss: 126.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 3119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2763 - accuracy: 0.0000e+00 - val_loss: 127.8725 - val_accuracy: 0.1176\n",
      "Epoch 3120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2510 - accuracy: 0.0000e+00 - val_loss: 122.1743 - val_accuracy: 0.1176\n",
      "Epoch 3121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0190 - accuracy: 0.0156 - val_loss: 117.6445 - val_accuracy: 0.1176\n",
      "Epoch 3122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0435 - accuracy: 0.0000e+00 - val_loss: 121.0463 - val_accuracy: 0.0588\n",
      "Epoch 3123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9345 - accuracy: 0.0000e+00 - val_loss: 121.5483 - val_accuracy: 0.0588\n",
      "Epoch 3124/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2852 - accuracy: 0.0156 - val_loss: 118.9978 - val_accuracy: 0.0588\n",
      "Epoch 3125/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 36.9857 - accuracy: 0.0156 - val_loss: 114.0909 - val_accuracy: 0.0588\n",
      "Epoch 3126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0616 - accuracy: 0.0000e+00 - val_loss: 119.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 3127/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.4905 - accuracy: 0.0000e+0 - 0s 78us/step - loss: 35.3215 - accuracy: 0.0000e+00 - val_loss: 125.9702 - val_accuracy: 0.0588\n",
      "Epoch 3128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9938 - accuracy: 0.0156 - val_loss: 126.8516 - val_accuracy: 0.0588\n",
      "Epoch 3129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6538 - accuracy: 0.0156 - val_loss: 117.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 3130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0573 - accuracy: 0.0156 - val_loss: 108.1367 - val_accuracy: 0.0588\n",
      "Epoch 3131/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.0210 - accuracy: 0.0000e+00 - val_loss: 106.4344 - val_accuracy: 0.0588\n",
      "Epoch 3132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2460 - accuracy: 0.0000e+00 - val_loss: 108.1702 - val_accuracy: 0.0588\n",
      "Epoch 3133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0867 - accuracy: 0.0000e+00 - val_loss: 118.3483 - val_accuracy: 0.0588\n",
      "Epoch 3134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6616 - accuracy: 0.0000e+00 - val_loss: 126.2635 - val_accuracy: 0.0588\n",
      "Epoch 3135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 63us/step - loss: 59.8597 - accuracy: 0.0156 - val_loss: 130.5265 - val_accuracy: 0.0588\n",
      "Epoch 3136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7035 - accuracy: 0.0000e+00 - val_loss: 122.4548 - val_accuracy: 0.1176\n",
      "Epoch 3137/10000\n",
      "64/64 [==============================] - 0s 106us/step - loss: 34.3083 - accuracy: 0.0156 - val_loss: 113.0562 - val_accuracy: 0.0588\n",
      "Epoch 3138/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 50.3550 - accuracy: 0.0000e+00 - val_loss: 110.6300 - val_accuracy: 0.0588\n",
      "Epoch 3139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3036 - accuracy: 0.0156 - val_loss: 112.6880 - val_accuracy: 0.0588\n",
      "Epoch 3140/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.5435 - accuracy: 0.0000e+00 - val_loss: 130.4685 - val_accuracy: 0.0588\n",
      "Epoch 3141/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3417 - accuracy: 0.0000e+00 - val_loss: 130.8810 - val_accuracy: 0.0000e+00\n",
      "Epoch 3142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2572 - accuracy: 0.0156 - val_loss: 121.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 3143/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 50.4368 - accuracy: 0.0156 - val_loss: 112.1593 - val_accuracy: 0.0000e+00\n",
      "Epoch 3144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4870 - accuracy: 0.0000e+00 - val_loss: 106.4786 - val_accuracy: 0.0588\n",
      "Epoch 3145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5413 - accuracy: 0.0156 - val_loss: 106.0336 - val_accuracy: 0.0000e+00\n",
      "Epoch 3146/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 49.9560 - accuracy: 0.0000e+00 - val_loss: 114.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8091 - accuracy: 0.0156 - val_loss: 115.9135 - val_accuracy: 0.0588\n",
      "Epoch 3148/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.8008 - accuracy: 0.0000e+00 - val_loss: 111.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 3149/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 48.3813 - accuracy: 0.0156 - val_loss: 108.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 3150/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8673 - accuracy: 0.0000e+00 - val_loss: 113.9658 - val_accuracy: 0.0588\n",
      "Epoch 3151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0319 - accuracy: 0.0000e+00 - val_loss: 124.3212 - val_accuracy: 0.0000e+00\n",
      "Epoch 3152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7995 - accuracy: 0.0000e+00 - val_loss: 131.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 3153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6060 - accuracy: 0.0156 - val_loss: 135.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 3154/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 34.8663 - accuracy: 0.0000e+00 - val_loss: 132.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 3155/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1540 - accuracy: 0.0156 - val_loss: 131.7027 - val_accuracy: 0.0588\n",
      "Epoch 3156/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9896 - accuracy: 0.0000e+00 - val_loss: 128.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 3157/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 44.4923 - accuracy: 0.0000e+00 - val_loss: 127.8526 - val_accuracy: 0.0588\n",
      "Epoch 3158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1638 - accuracy: 0.0000e+00 - val_loss: 135.3377 - val_accuracy: 0.0000e+00\n",
      "Epoch 3159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1132 - accuracy: 0.0000e+00 - val_loss: 128.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 3160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6696 - accuracy: 0.0000e+00 - val_loss: 120.0983 - val_accuracy: 0.0588\n",
      "Epoch 3161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7084 - accuracy: 0.0000e+00 - val_loss: 113.9500 - val_accuracy: 0.0588\n",
      "Epoch 3162/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 46.3981 - accuracy: 0.0000e+00 - val_loss: 106.2584 - val_accuracy: 0.0588\n",
      "Epoch 3163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.5072 - accuracy: 0.0156 - val_loss: 109.4782 - val_accuracy: 0.0000e+00\n",
      "Epoch 3164/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.6066 - accuracy: 0.0000e+00 - val_loss: 122.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 3165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6557 - accuracy: 0.0000e+00 - val_loss: 135.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 3166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4706 - accuracy: 0.0000e+00 - val_loss: 140.2027 - val_accuracy: 0.0000e+00\n",
      "Epoch 3167/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.9293 - accuracy: 0.0000e+00 - val_loss: 124.8704 - val_accuracy: 0.0000e+00\n",
      "Epoch 3168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6817 - accuracy: 0.0000e+00 - val_loss: 109.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 3169/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.3889 - accuracy: 0.0000e+00 - val_loss: 98.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9188 - accuracy: 0.0000e+00 - val_loss: 93.8601 - val_accuracy: 0.0000e+00\n",
      "Epoch 3171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3402 - accuracy: 0.0000e+00 - val_loss: 94.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 3172/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 32.8484 - accuracy: 0.0312 - val_loss: 100.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 3173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7081 - accuracy: 0.0000e+00 - val_loss: 105.2830 - val_accuracy: 0.0000e+00\n",
      "Epoch 3174/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.4229 - accuracy: 0.0000e+00 - val_loss: 110.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 3175/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4999 - accuracy: 0.0156 - val_loss: 112.2236 - val_accuracy: 0.0000e+00\n",
      "Epoch 3176/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3649 - accuracy: 0.0156 - val_loss: 110.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 3177/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 39.1278 - accuracy: 0.0000e+00 - val_loss: 111.8717 - val_accuracy: 0.0000e+00\n",
      "Epoch 3178/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 33.0150 - accuracy: 0.0000e+00 - val_loss: 118.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 3179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3798 - accuracy: 0.0000e+00 - val_loss: 125.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3180/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0502 - accuracy: 0.0156 - val_loss: 130.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 3181/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4871 - accuracy: 0.0000e+00 - val_loss: 133.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2330 - accuracy: 0.0000e+00 - val_loss: 134.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 3183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7215 - accuracy: 0.0000e+00 - val_loss: 133.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 3184/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 39.3460 - accuracy: 0.0000e+00 - val_loss: 129.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 3185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6509 - accuracy: 0.0312 - val_loss: 120.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 3186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3067 - accuracy: 0.0156 - val_loss: 117.9283 - val_accuracy: 0.0000e+00\n",
      "Epoch 3187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4883 - accuracy: 0.0156 - val_loss: 120.2806 - val_accuracy: 0.0588\n",
      "Epoch 3188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9757 - accuracy: 0.0156 - val_loss: 125.8109 - val_accuracy: 0.0588\n",
      "Epoch 3189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4391 - accuracy: 0.0156 - val_loss: 128.9913 - val_accuracy: 0.0588\n",
      "Epoch 3190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8583 - accuracy: 0.0000e+00 - val_loss: 129.1149 - val_accuracy: 0.0588\n",
      "Epoch 3191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5904 - accuracy: 0.0156 - val_loss: 121.9317 - val_accuracy: 0.0000e+00\n",
      "Epoch 3192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3136 - accuracy: 0.0000e+00 - val_loss: 115.2644 - val_accuracy: 0.0588\n",
      "Epoch 3193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.7265 - accuracy: 0.0000e+00 - val_loss: 114.2933 - val_accuracy: 0.0588\n",
      "Epoch 3194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9618 - accuracy: 0.0156 - val_loss: 109.4461 - val_accuracy: 0.0588\n",
      "Epoch 3195/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.4388 - accuracy: 0.0156 - val_loss: 101.6058 - val_accuracy: 0.0588\n",
      "Epoch 3196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0386 - accuracy: 0.0000e+00 - val_loss: 100.3942 - val_accuracy: 0.0588\n",
      "Epoch 3197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7670 - accuracy: 0.0156 - val_loss: 112.6618 - val_accuracy: 0.0588\n",
      "Epoch 3198/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 37.4396 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.3340 - accuracy: 0.0156 - val_loss: 134.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 3199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1460 - accuracy: 0.0000e+00 - val_loss: 141.6888 - val_accuracy: 0.0000e+00\n",
      "Epoch 3200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8651 - accuracy: 0.0000e+00 - val_loss: 132.8426 - val_accuracy: 0.0000e+00\n",
      "Epoch 3201/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 35.0588 - accuracy: 0.0000e+00 - val_loss: 122.9974 - val_accuracy: 0.0000e+00\n",
      "Epoch 3202/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.3213 - accuracy: 0.0000e+00 - val_loss: 117.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 3203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5265 - accuracy: 0.0000e+00 - val_loss: 121.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 3204/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 40.2133 - accuracy: 0.0312 - val_loss: 130.3890 - val_accuracy: 0.0000e+00\n",
      "Epoch 3205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5816 - accuracy: 0.0156 - val_loss: 134.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4523 - accuracy: 0.0156 - val_loss: 129.2822 - val_accuracy: 0.0000e+00\n",
      "Epoch 3207/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 48.7837 - accuracy: 0.0312 - val_loss: 113.8467 - val_accuracy: 0.0588\n",
      "Epoch 3208/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3565 - accuracy: 0.0000e+00 - val_loss: 99.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 3209/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 41.5166 - accuracy: 0.0312 - val_loss: 96.1935 - val_accuracy: 0.0588\n",
      "Epoch 3210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4455 - accuracy: 0.0000e+00 - val_loss: 96.8006 - val_accuracy: 0.0588\n",
      "Epoch 3211/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8663 - accuracy: 0.0000e+00 - val_loss: 103.3420 - val_accuracy: 0.0000e+00\n",
      "Epoch 3212/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 33.2381 - accuracy: 0.0000e+00 - val_loss: 112.5255 - val_accuracy: 0.0588\n",
      "Epoch 3213/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.7367 - accuracy: 0.0000e+00 - val_loss: 126.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 3214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0213 - accuracy: 0.0000e+00 - val_loss: 133.9479 - val_accuracy: 0.0588\n",
      "Epoch 3215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8304 - accuracy: 0.0156 - val_loss: 133.7750 - val_accuracy: 0.0588\n",
      "Epoch 3216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1699 - accuracy: 0.0000e+00 - val_loss: 129.2972 - val_accuracy: 0.0588\n",
      "Epoch 3217/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 33.4892 - accuracy: 0.0000e+00 - val_loss: 122.5565 - val_accuracy: 0.1176\n",
      "Epoch 3218/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 38.4531 - accuracy: 0.0000e+00 - val_loss: 121.0384 - val_accuracy: 0.0000e+00\n",
      "Epoch 3219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8226 - accuracy: 0.0000e+00 - val_loss: 135.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 3220/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 40.1985 - accuracy: 0.0156 - val_loss: 139.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 3221/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 43.1853 - accuracy: 0.0000e+00 - val_loss: 126.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 3222/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9979 - accuracy: 0.0000e+00 - val_loss: 120.4292 - val_accuracy: 0.0588\n",
      "Epoch 3223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1506 - accuracy: 0.0156 - val_loss: 118.7639 - val_accuracy: 0.0000e+00\n",
      "Epoch 3224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8673 - accuracy: 0.0156 - val_loss: 125.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 3225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7434 - accuracy: 0.0156 - val_loss: 136.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 3226/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7548 - accuracy: 0.0156 - val_loss: 138.9849 - val_accuracy: 0.0000e+00\n",
      "Epoch 3227/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.9118 - accuracy: 0.0000e+00 - val_loss: 137.8969 - val_accuracy: 0.0588\n",
      "Epoch 3228/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.7093 - accuracy: 0.0156 - val_loss: 133.0310 - val_accuracy: 0.0588\n",
      "Epoch 3229/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 47.9109 - accuracy: 0.0312 - val_loss: 127.9020 - val_accuracy: 0.0588\n",
      "Epoch 3230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3876 - accuracy: 0.0000e+00 - val_loss: 126.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 3231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3975 - accuracy: 0.0000e+00 - val_loss: 142.2879 - val_accuracy: 0.0000e+00\n",
      "Epoch 3232/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 41.4335 - accuracy: 0.0000e+00 - val_loss: 137.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 3233/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7895 - accuracy: 0.0000e+00 - val_loss: 134.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 3234/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.3468 - accuracy: 0.0156 - val_loss: 120.9960 - val_accuracy: 0.0000e+00\n",
      "Epoch 3235/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 40.6222 - accuracy: 0.0312 - val_loss: 111.8023 - val_accuracy: 0.0588\n",
      "Epoch 3236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6254 - accuracy: 0.0156 - val_loss: 110.1171 - val_accuracy: 0.0588\n",
      "Epoch 3237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1141 - accuracy: 0.0156 - val_loss: 109.8487 - val_accuracy: 0.0588\n",
      "Epoch 3238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.0057 - accuracy: 0.0156 - val_loss: 117.3154 - val_accuracy: 0.0588\n",
      "Epoch 3239/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.1693 - accuracy: 0.0156 - val_loss: 118.6235 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5069 - accuracy: 0.0000e+00 - val_loss: 117.0894 - val_accuracy: 0.0588\n",
      "Epoch 3241/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8797 - accuracy: 0.0156 - val_loss: 125.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 3242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1530 - accuracy: 0.0000e+00 - val_loss: 135.1611 - val_accuracy: 0.0000e+00\n",
      "Epoch 3243/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 25.9247 - accuracy: 0.0156 - val_loss: 132.7943 - val_accuracy: 0.0000e+00\n",
      "Epoch 3244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1763 - accuracy: 0.0000e+00 - val_loss: 138.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 3245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0580 - accuracy: 0.0156 - val_loss: 137.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 3246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2783 - accuracy: 0.0312 - val_loss: 135.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 3247/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 46.7579 - accuracy: 0.0156 - val_loss: 141.0329 - val_accuracy: 0.0000e+00\n",
      "Epoch 3248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8604 - accuracy: 0.0156 - val_loss: 136.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 3249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0204 - accuracy: 0.0000e+00 - val_loss: 132.9650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1509 - accuracy: 0.0000e+00 - val_loss: 130.8727 - val_accuracy: 0.0588\n",
      "Epoch 3251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0149 - accuracy: 0.0156 - val_loss: 127.8063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7810 - accuracy: 0.0000e+00 - val_loss: 121.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 3253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2332 - accuracy: 0.0000e+00 - val_loss: 124.8194 - val_accuracy: 0.0000e+00\n",
      "Epoch 3254/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.8689 - accuracy: 0.0000e+00 - val_loss: 139.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 3255/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 44.0262 - accuracy: 0.0000e+00 - val_loss: 131.4372 - val_accuracy: 0.0000e+00\n",
      "Epoch 3256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3196 - accuracy: 0.0000e+00 - val_loss: 127.2418 - val_accuracy: 0.0000e+00\n",
      "Epoch 3257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0007 - accuracy: 0.0156 - val_loss: 119.4833 - val_accuracy: 0.0000e+00\n",
      "Epoch 3258/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 42.9765 - accuracy: 0.0156 - val_loss: 119.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 3259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8656 - accuracy: 0.0000e+00 - val_loss: 127.9444 - val_accuracy: 0.0000e+00\n",
      "Epoch 3260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4477 - accuracy: 0.0156 - val_loss: 127.4167 - val_accuracy: 0.0588\n",
      "Epoch 3261/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 55.0016 - accuracy: 0.0156 - val_loss: 124.0186 - val_accuracy: 0.0588\n",
      "Epoch 3262/10000\n",
      "64/64 [==============================] - 0s 24us/step - loss: 37.1891 - accuracy: 0.0156 - val_loss: 121.9527 - val_accuracy: 0.0588\n",
      "Epoch 3263/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 44.4377 - accuracy: 0.0000e+00 - val_loss: 125.2979 - val_accuracy: 0.0588\n",
      "Epoch 3264/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 35.6456 - accuracy: 0.0000e+00 - val_loss: 125.2975 - val_accuracy: 0.0588\n",
      "Epoch 3265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7130 - accuracy: 0.0156 - val_loss: 129.7230 - val_accuracy: 0.0588\n",
      "Epoch 3266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2267 - accuracy: 0.0156 - val_loss: 132.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6473 - accuracy: 0.0000e+00 - val_loss: 134.1828 - val_accuracy: 0.0588\n",
      "Epoch 3268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3421 - accuracy: 0.0000e+00 - val_loss: 144.2561 - val_accuracy: 0.0000e+00\n",
      "Epoch 3269/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 43.8405 - accuracy: 0.0156 - val_loss: 146.2200 - val_accuracy: 0.0000e+00\n",
      "Epoch 3270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5406 - accuracy: 0.0000e+00 - val_loss: 131.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 3271/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 43.2059 - accuracy: 0.0156 - val_loss: 123.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 3272/10000\n",
      "64/64 [==============================] - 0s 206us/step - loss: 40.7412 - accuracy: 0.0000e+00 - val_loss: 118.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 3273/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 34.7759 - accuracy: 0.0156 - val_loss: 111.4893 - val_accuracy: 0.0588\n",
      "Epoch 3274/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 40.9580 - accuracy: 0.0000e+00 - val_loss: 111.3870 - val_accuracy: 0.0588\n",
      "Epoch 3275/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.8319 - accuracy: 0.0000e+00 - val_loss: 107.9874 - val_accuracy: 0.0588\n",
      "Epoch 3276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6237 - accuracy: 0.0000e+00 - val_loss: 107.3785 - val_accuracy: 0.0588\n",
      "Epoch 3277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9022 - accuracy: 0.0000e+00 - val_loss: 117.8431 - val_accuracy: 0.0588\n",
      "Epoch 3278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3211 - accuracy: 0.0000e+00 - val_loss: 137.6960 - val_accuracy: 0.0588\n",
      "Epoch 3279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0693 - accuracy: 0.0000e+00 - val_loss: 146.0438 - val_accuracy: 0.0588\n",
      "Epoch 3280/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 48.4760 - accuracy: 0.0000e+00 - val_loss: 147.5387 - val_accuracy: 0.0588\n",
      "Epoch 3281/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8258 - accuracy: 0.0156 - val_loss: 137.7582 - val_accuracy: 0.0588\n",
      "Epoch 3282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0625 - accuracy: 0.0156 - val_loss: 131.2625 - val_accuracy: 0.0000e+00\n",
      "Epoch 3283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9829 - accuracy: 0.0156 - val_loss: 122.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 3284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4898 - accuracy: 0.0156 - val_loss: 127.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 3285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0430 - accuracy: 0.0000e+00 - val_loss: 127.2648 - val_accuracy: 0.0588\n",
      "Epoch 3286/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 40.0261 - accuracy: 0.0312 - val_loss: 120.5667 - val_accuracy: 0.0000e+00\n",
      "Epoch 3287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.7904 - accuracy: 0.0156 - val_loss: 113.3173 - val_accuracy: 0.0588\n",
      "Epoch 3288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9707 - accuracy: 0.0000e+00 - val_loss: 111.8536 - val_accuracy: 0.0588\n",
      "Epoch 3289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7087 - accuracy: 0.0156 - val_loss: 119.3333 - val_accuracy: 0.0588\n",
      "Epoch 3290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8091 - accuracy: 0.0000e+00 - val_loss: 122.7539 - val_accuracy: 0.0588\n",
      "Epoch 3291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9130 - accuracy: 0.0000e+00 - val_loss: 119.9146 - val_accuracy: 0.0588\n",
      "Epoch 3292/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5024 - accuracy: 0.0312 - val_loss: 113.1930 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.4692 - accuracy: 0.0156 - val_loss: 106.3669 - val_accuracy: 0.1176\n",
      "Epoch 3294/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.8377 - accuracy: 0.0000e+00 - val_loss: 105.0050 - val_accuracy: 0.0588\n",
      "Epoch 3295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0940 - accuracy: 0.0156 - val_loss: 109.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 3296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8144 - accuracy: 0.0000e+00 - val_loss: 117.4660 - val_accuracy: 0.1176\n",
      "Epoch 3297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1410 - accuracy: 0.0156 - val_loss: 123.4695 - val_accuracy: 0.0588\n",
      "Epoch 3298/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3627 - accuracy: 0.0000e+00 - val_loss: 129.8802 - val_accuracy: 0.0588\n",
      "Epoch 3299/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 46.2455 - accuracy: 0.0000e+00 - val_loss: 128.8410 - val_accuracy: 0.0588\n",
      "Epoch 3300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5712 - accuracy: 0.0000e+00 - val_loss: 130.3410 - val_accuracy: 0.0588\n",
      "Epoch 3301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9443 - accuracy: 0.0156 - val_loss: 137.4290 - val_accuracy: 0.0588\n",
      "Epoch 3302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3331 - accuracy: 0.0000e+00 - val_loss: 138.0370 - val_accuracy: 0.0588\n",
      "Epoch 3303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3073 - accuracy: 0.0000e+00 - val_loss: 134.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 3304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0530 - accuracy: 0.0156 - val_loss: 127.2699 - val_accuracy: 0.0000e+00\n",
      "Epoch 3305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9519 - accuracy: 0.0000e+00 - val_loss: 127.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 3306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4868 - accuracy: 0.0469 - val_loss: 133.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 3307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4528 - accuracy: 0.0156 - val_loss: 137.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 3308/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 40.1047 - accuracy: 0.0312 - val_loss: 128.6210 - val_accuracy: 0.0588\n",
      "Epoch 3309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9806 - accuracy: 0.0000e+00 - val_loss: 118.1849 - val_accuracy: 0.0588\n",
      "Epoch 3310/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.2158 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 44.2104 - accuracy: 0.0000e+00 - val_loss: 113.9879 - val_accuracy: 0.0588\n",
      "Epoch 3311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7950 - accuracy: 0.0156 - val_loss: 115.9861 - val_accuracy: 0.0588\n",
      "Epoch 3312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6673 - accuracy: 0.0000e+00 - val_loss: 128.1174 - val_accuracy: 0.1176\n",
      "Epoch 3313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8427 - accuracy: 0.0312 - val_loss: 139.3143 - val_accuracy: 0.0588\n",
      "Epoch 3314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1962 - accuracy: 0.0000e+00 - val_loss: 134.6307 - val_accuracy: 0.0588\n",
      "Epoch 3315/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.8326 - accuracy: 0.0312 - val_loss: 123.2180 - val_accuracy: 0.1176\n",
      "Epoch 3316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5767 - accuracy: 0.0000e+00 - val_loss: 124.3953 - val_accuracy: 0.0588\n",
      "Epoch 3317/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.0970 - accuracy: 0.0000e+00 - val_loss: 130.6713 - val_accuracy: 0.1176\n",
      "Epoch 3318/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 40.6379 - accuracy: 0.0156 - val_loss: 132.4328 - val_accuracy: 0.0588\n",
      "Epoch 3319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.2456 - accuracy: 0.0000e+00 - val_loss: 130.4855 - val_accuracy: 0.0588\n",
      "Epoch 3320/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.4089 - accuracy: 0.0000e+00 - val_loss: 131.3481 - val_accuracy: 0.0588\n",
      "Epoch 3321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.4147 - accuracy: 0.0000e+00 - val_loss: 131.5954 - val_accuracy: 0.1176\n",
      "Epoch 3322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3622 - accuracy: 0.0000e+00 - val_loss: 125.7878 - val_accuracy: 0.0588\n",
      "Epoch 3323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7153 - accuracy: 0.0000e+00 - val_loss: 128.3188 - val_accuracy: 0.0588\n",
      "Epoch 3324/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.1961 - accuracy: 0.0000e+00 - val_loss: 131.1199 - val_accuracy: 0.0588\n",
      "Epoch 3325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9897 - accuracy: 0.0156 - val_loss: 133.1288 - val_accuracy: 0.0588\n",
      "Epoch 3326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0145 - accuracy: 0.0000e+00 - val_loss: 133.7321 - val_accuracy: 0.0588\n",
      "Epoch 3327/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.1478 - accuracy: 0.0000e+00 - val_loss: 127.5802 - val_accuracy: 0.0588\n",
      "Epoch 3328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7376 - accuracy: 0.0000e+00 - val_loss: 116.2138 - val_accuracy: 0.0588\n",
      "Epoch 3329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4417 - accuracy: 0.0000e+00 - val_loss: 117.7606 - val_accuracy: 0.0588\n",
      "Epoch 3330/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 54.7825 - accuracy: 0.0156 - val_loss: 125.6730 - val_accuracy: 0.0588\n",
      "Epoch 3331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6544 - accuracy: 0.0156 - val_loss: 136.0020 - val_accuracy: 0.0588\n",
      "Epoch 3332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7142 - accuracy: 0.0000e+00 - val_loss: 135.4454 - val_accuracy: 0.0588\n",
      "Epoch 3333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6457 - accuracy: 0.0156 - val_loss: 133.1674 - val_accuracy: 0.0588\n",
      "Epoch 3334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9213 - accuracy: 0.0000e+00 - val_loss: 120.1371 - val_accuracy: 0.0588\n",
      "Epoch 3335/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 35.0859 - accuracy: 0.0000e+00 - val_loss: 114.3670 - val_accuracy: 0.0588\n",
      "Epoch 3336/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.8360 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 39.5226 - accuracy: 0.0000e+00 - val_loss: 110.5435 - val_accuracy: 0.1176\n",
      "Epoch 3337/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.4404 - accuracy: 0.0156 - val_loss: 113.0922 - val_accuracy: 0.1176\n",
      "Epoch 3338/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.6046 - accuracy: 0.0000e+00 - val_loss: 117.3129 - val_accuracy: 0.0588\n",
      "Epoch 3339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3782 - accuracy: 0.0000e+00 - val_loss: 122.0039 - val_accuracy: 0.0588\n",
      "Epoch 3340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1840 - accuracy: 0.0000e+00 - val_loss: 117.2241 - val_accuracy: 0.0588\n",
      "Epoch 3341/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 52.9903 - accuracy: 0.0000e+0 - 0s 188us/step - loss: 45.3172 - accuracy: 0.0000e+00 - val_loss: 105.8530 - val_accuracy: 0.0588\n",
      "Epoch 3342/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.2643 - accuracy: 0.0156 - val_loss: 97.8566 - val_accuracy: 0.1176\n",
      "Epoch 3343/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 40.1432 - accuracy: 0.0000e+00 - val_loss: 97.8547 - val_accuracy: 0.1176\n",
      "Epoch 3344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4427 - accuracy: 0.0000e+00 - val_loss: 111.9190 - val_accuracy: 0.0588\n",
      "Epoch 3345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5933 - accuracy: 0.0000e+00 - val_loss: 130.8279 - val_accuracy: 0.0588\n",
      "Epoch 3346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1122 - accuracy: 0.0312 - val_loss: 143.5716 - val_accuracy: 0.0588\n",
      "Epoch 3347/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.9887 - accuracy: 0.0000e+00 - val_loss: 136.0825 - val_accuracy: 0.0588\n",
      "Epoch 3348/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 50.5051 - accuracy: 0.0312 - val_loss: 123.9676 - val_accuracy: 0.0588\n",
      "Epoch 3349/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.6488 - accuracy: 0.0156 - val_loss: 109.0905 - val_accuracy: 0.0588\n",
      "Epoch 3350/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3908 - accuracy: 0.0000e+00 - val_loss: 106.2762 - val_accuracy: 0.0588\n",
      "Epoch 3351/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2536 - accuracy: 0.0000e+00 - val_loss: 112.5581 - val_accuracy: 0.0588\n",
      "Epoch 3352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2226 - accuracy: 0.0000e+00 - val_loss: 123.4275 - val_accuracy: 0.0588\n",
      "Epoch 3353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1987 - accuracy: 0.0000e+00 - val_loss: 124.5860 - val_accuracy: 0.1176\n",
      "Epoch 3354/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.5282 - accuracy: 0.0156 - val_loss: 116.9504 - val_accuracy: 0.0588\n",
      "Epoch 3355/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6495 - accuracy: 0.0000e+00 - val_loss: 117.5285 - val_accuracy: 0.0588\n",
      "Epoch 3356/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 39.3447 - accuracy: 0.0000e+00 - val_loss: 120.2017 - val_accuracy: 0.0000e+00\n",
      "Epoch 3357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8538 - accuracy: 0.0156 - val_loss: 126.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.2000 - accuracy: 0.0312 - val_loss: 124.2574 - val_accuracy: 0.0000e+00\n",
      "Epoch 3359/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3574 - accuracy: 0.0000e+00 - val_loss: 121.8653 - val_accuracy: 0.0000e+00\n",
      "Epoch 3360/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 38.0248 - accuracy: 0.0000e+00 - val_loss: 119.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 3361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6793 - accuracy: 0.0156 - val_loss: 119.8922 - val_accuracy: 0.1176\n",
      "Epoch 3362/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7258 - accuracy: 0.0000e+00 - val_loss: 126.3129 - val_accuracy: 0.0588\n",
      "Epoch 3363/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 37.7946 - accuracy: 0.0156 - val_loss: 124.7135 - val_accuracy: 0.0000e+00\n",
      "Epoch 3364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8157 - accuracy: 0.0000e+00 - val_loss: 118.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 3365/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 35.1683 - accuracy: 0.0156 - val_loss: 109.8026 - val_accuracy: 0.0588\n",
      "Epoch 3366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7069 - accuracy: 0.0156 - val_loss: 100.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 3367/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 33.6883 - accuracy: 0.0000e+00 - val_loss: 96.2406 - val_accuracy: 0.0588\n",
      "Epoch 3368/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.5378 - accuracy: 0.0000e+00 - val_loss: 106.2473 - val_accuracy: 0.0588\n",
      "Epoch 3369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3823 - accuracy: 0.0000e+00 - val_loss: 114.9488 - val_accuracy: 0.0588\n",
      "Epoch 3370/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.5407 - accuracy: 0.0000e+00 - val_loss: 112.1186 - val_accuracy: 0.0588\n",
      "Epoch 3371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8736 - accuracy: 0.0000e+00 - val_loss: 112.3516 - val_accuracy: 0.0588\n",
      "Epoch 3372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7925 - accuracy: 0.0000e+00 - val_loss: 113.1072 - val_accuracy: 0.1176\n",
      "Epoch 3373/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4265 - accuracy: 0.0000e+00 - val_loss: 113.7780 - val_accuracy: 0.0588\n",
      "Epoch 3374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.9798 - accuracy: 0.0312 - val_loss: 121.7571 - val_accuracy: 0.1176\n",
      "Epoch 3375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3465 - accuracy: 0.0156 - val_loss: 125.6756 - val_accuracy: 0.1176\n",
      "Epoch 3376/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 38.9960 - accuracy: 0.0156 - val_loss: 121.3040 - val_accuracy: 0.0588\n",
      "Epoch 3377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6696 - accuracy: 0.0000e+00 - val_loss: 110.3646 - val_accuracy: 0.0000e+00\n",
      "Epoch 3378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5270 - accuracy: 0.0156 - val_loss: 105.7150 - val_accuracy: 0.0588\n",
      "Epoch 3379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6906 - accuracy: 0.0156 - val_loss: 114.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 3380/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.4730 - accuracy: 0.0000e+00 - val_loss: 121.6051 - val_accuracy: 0.0000e+00\n",
      "Epoch 3381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7609 - accuracy: 0.0156 - val_loss: 121.3928 - val_accuracy: 0.0000e+00\n",
      "Epoch 3382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7717 - accuracy: 0.0156 - val_loss: 114.3287 - val_accuracy: 0.0000e+00\n",
      "Epoch 3383/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.3815 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 30.0537 - accuracy: 0.0000e+00 - val_loss: 112.6779 - val_accuracy: 0.0000e+00\n",
      "Epoch 3384/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 36.2712 - accuracy: 0.0000e+00 - val_loss: 112.3937 - val_accuracy: 0.0000e+00\n",
      "Epoch 3385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6166 - accuracy: 0.0000e+00 - val_loss: 113.7477 - val_accuracy: 0.0588\n",
      "Epoch 3386/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 40.4234 - accuracy: 0.0000e+00 - val_loss: 114.2513 - val_accuracy: 0.0588\n",
      "Epoch 3387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7030 - accuracy: 0.0000e+00 - val_loss: 118.0973 - val_accuracy: 0.0588\n",
      "Epoch 3388/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 36.6198 - accuracy: 0.0000e+00 - val_loss: 130.3096 - val_accuracy: 0.0000e+00\n",
      "Epoch 3389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0239 - accuracy: 0.0000e+00 - val_loss: 130.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 3390/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 27.3774 - accuracy: 0.0000e+00 - val_loss: 122.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 3391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8505 - accuracy: 0.0000e+00 - val_loss: 116.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 3392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9659 - accuracy: 0.0000e+00 - val_loss: 115.6666 - val_accuracy: 0.0588\n",
      "Epoch 3393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.8557 - accuracy: 0.0000e+00 - val_loss: 121.2037 - val_accuracy: 0.0588\n",
      "Epoch 3394/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.7988 - accuracy: 0.0000e+00 - val_loss: 121.7196 - val_accuracy: 0.0588\n",
      "Epoch 3395/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0551 - accuracy: 0.0000e+00 - val_loss: 130.0410 - val_accuracy: 0.1176\n",
      "Epoch 3396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1943 - accuracy: 0.0000e+00 - val_loss: 141.0738 - val_accuracy: 0.0588\n",
      "Epoch 3397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4398 - accuracy: 0.0000e+00 - val_loss: 141.6385 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3398/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.4028 - accuracy: 0.0000e+00 - val_loss: 129.9256 - val_accuracy: 0.0588\n",
      "Epoch 3399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7845 - accuracy: 0.0000e+00 - val_loss: 110.2715 - val_accuracy: 0.0588\n",
      "Epoch 3400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8182 - accuracy: 0.0312 - val_loss: 102.1626 - val_accuracy: 0.0588\n",
      "Epoch 3401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4501 - accuracy: 0.0156 - val_loss: 106.2796 - val_accuracy: 0.0588\n",
      "Epoch 3402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5435 - accuracy: 0.0000e+00 - val_loss: 114.5258 - val_accuracy: 0.0588\n",
      "Epoch 3403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2286 - accuracy: 0.0156 - val_loss: 118.6368 - val_accuracy: 0.0588\n",
      "Epoch 3404/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0359 - accuracy: 0.0000e+00 - val_loss: 120.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 3405/10000\n",
      "64/64 [==============================] - 0s 68us/step - loss: 41.9858 - accuracy: 0.0000e+00 - val_loss: 115.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 3406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7186 - accuracy: 0.0000e+00 - val_loss: 106.0163 - val_accuracy: 0.0588\n",
      "Epoch 3407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4028 - accuracy: 0.0000e+00 - val_loss: 100.6543 - val_accuracy: 0.0588\n",
      "Epoch 3408/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 35.3319 - accuracy: 0.0156 - val_loss: 102.8099 - val_accuracy: 0.0588\n",
      "Epoch 3409/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 42.8213 - accuracy: 0.0156 - val_loss: 111.9898 - val_accuracy: 0.1176\n",
      "Epoch 3410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4557 - accuracy: 0.0156 - val_loss: 125.8163 - val_accuracy: 0.0588\n",
      "Epoch 3411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1986 - accuracy: 0.0312 - val_loss: 137.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 3412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0642 - accuracy: 0.0000e+00 - val_loss: 131.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 3413/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.5385 - accuracy: 0.0000e+00 - val_loss: 112.6758 - val_accuracy: 0.1176\n",
      "Epoch 3414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.3235 - accuracy: 0.0000e+00 - val_loss: 101.2466 - val_accuracy: 0.0588\n",
      "Epoch 3415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5488 - accuracy: 0.0156 - val_loss: 97.1123 - val_accuracy: 0.1176\n",
      "Epoch 3416/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 35.1078 - accuracy: 0.0000e+00 - val_loss: 102.8066 - val_accuracy: 0.0588\n",
      "Epoch 3417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8472 - accuracy: 0.0000e+00 - val_loss: 117.3733 - val_accuracy: 0.0588\n",
      "Epoch 3418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8262 - accuracy: 0.0156 - val_loss: 114.1322 - val_accuracy: 0.0588\n",
      "Epoch 3419/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 46.1397 - accuracy: 0.0000e+00 - val_loss: 109.5021 - val_accuracy: 0.0588\n",
      "Epoch 3420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9200 - accuracy: 0.0312 - val_loss: 103.9060 - val_accuracy: 0.1176\n",
      "Epoch 3421/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.0942 - accuracy: 0.0000e+00 - val_loss: 104.2871 - val_accuracy: 0.0588\n",
      "Epoch 3422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6213 - accuracy: 0.0000e+00 - val_loss: 104.9681 - val_accuracy: 0.0588\n",
      "Epoch 3423/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.5046 - accuracy: 0.0000e+00 - val_loss: 105.6097 - val_accuracy: 0.0588\n",
      "Epoch 3424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0552 - accuracy: 0.0312 - val_loss: 106.1593 - val_accuracy: 0.0588\n",
      "Epoch 3425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2931 - accuracy: 0.0000e+00 - val_loss: 106.3796 - val_accuracy: 0.0588\n",
      "Epoch 3426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5911 - accuracy: 0.0156 - val_loss: 103.8104 - val_accuracy: 0.0588\n",
      "Epoch 3427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5435 - accuracy: 0.0156 - val_loss: 101.1526 - val_accuracy: 0.0588\n",
      "Epoch 3428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0446 - accuracy: 0.0000e+00 - val_loss: 103.2204 - val_accuracy: 0.0000e+00\n",
      "Epoch 3429/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 55.3312 - accuracy: 0.0156 - val_loss: 102.8271 - val_accuracy: 0.0588\n",
      "Epoch 3430/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 39.9584 - accuracy: 0.0000e+00 - val_loss: 102.5206 - val_accuracy: 0.0588\n",
      "Epoch 3431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2774 - accuracy: 0.0000e+00 - val_loss: 103.8018 - val_accuracy: 0.0588\n",
      "Epoch 3432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3530 - accuracy: 0.0156 - val_loss: 106.6614 - val_accuracy: 0.1176\n",
      "Epoch 3433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3253 - accuracy: 0.0000e+00 - val_loss: 116.6677 - val_accuracy: 0.0588\n",
      "Epoch 3434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4157 - accuracy: 0.0000e+00 - val_loss: 117.4401 - val_accuracy: 0.0588\n",
      "Epoch 3435/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.7915 - accuracy: 0.0000e+00 - val_loss: 107.2241 - val_accuracy: 0.0588\n",
      "Epoch 3436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6762 - accuracy: 0.0000e+00 - val_loss: 101.8319 - val_accuracy: 0.0588\n",
      "Epoch 3437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5973 - accuracy: 0.0000e+00 - val_loss: 106.5946 - val_accuracy: 0.0588\n",
      "Epoch 3438/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.6898 - accuracy: 0.0000e+00 - val_loss: 109.1168 - val_accuracy: 0.1176\n",
      "Epoch 3439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8324 - accuracy: 0.0000e+00 - val_loss: 115.7991 - val_accuracy: 0.0588\n",
      "Epoch 3440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3172 - accuracy: 0.0000e+00 - val_loss: 123.0382 - val_accuracy: 0.0588\n",
      "Epoch 3441/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1817 - accuracy: 0.0000e+00 - val_loss: 125.6914 - val_accuracy: 0.1176\n",
      "Epoch 3442/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.2303 - accuracy: 0.0156 - val_loss: 132.5251 - val_accuracy: 0.0588\n",
      "Epoch 3443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5710 - accuracy: 0.0156 - val_loss: 138.7085 - val_accuracy: 0.0588\n",
      "Epoch 3444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5387 - accuracy: 0.0156 - val_loss: 139.2910 - val_accuracy: 0.0588\n",
      "Epoch 3445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3737 - accuracy: 0.0000e+00 - val_loss: 130.7611 - val_accuracy: 0.0588\n",
      "Epoch 3446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5300 - accuracy: 0.0000e+00 - val_loss: 125.5393 - val_accuracy: 0.0588\n",
      "Epoch 3447/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8777 - accuracy: 0.0000e+00 - val_loss: 127.2776 - val_accuracy: 0.0000e+00\n",
      "Epoch 3448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7489 - accuracy: 0.0000e+00 - val_loss: 131.3192 - val_accuracy: 0.0000e+00\n",
      "Epoch 3449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5777 - accuracy: 0.0000e+00 - val_loss: 139.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 3450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5166 - accuracy: 0.0000e+00 - val_loss: 131.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 3451/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 61.5886 - accuracy: 0.0000e+00 - val_loss: 123.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 3452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6556 - accuracy: 0.0156 - val_loss: 117.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 3453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1036 - accuracy: 0.0000e+00 - val_loss: 120.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 3454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6799 - accuracy: 0.0000e+00 - val_loss: 131.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 3455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1128 - accuracy: 0.0000e+00 - val_loss: 136.0694 - val_accuracy: 0.0588\n",
      "Epoch 3456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2631 - accuracy: 0.0000e+00 - val_loss: 136.6710 - val_accuracy: 0.0588\n",
      "Epoch 3457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6096 - accuracy: 0.0156 - val_loss: 133.7530 - val_accuracy: 0.0588\n",
      "Epoch 3458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5724 - accuracy: 0.0156 - val_loss: 129.5584 - val_accuracy: 0.1176\n",
      "Epoch 3459/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.3820 - accuracy: 0.0000e+00 - val_loss: 126.2467 - val_accuracy: 0.1176\n",
      "Epoch 3460/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 28.3140 - accuracy: 0.0156 - val_loss: 129.8951 - val_accuracy: 0.0588\n",
      "Epoch 3461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0467 - accuracy: 0.0156 - val_loss: 136.4743 - val_accuracy: 0.0588\n",
      "Epoch 3462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5899 - accuracy: 0.0156 - val_loss: 129.2471 - val_accuracy: 0.0588\n",
      "Epoch 3463/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 38.5206 - accuracy: 0.0000e+00 - val_loss: 125.9959 - val_accuracy: 0.0588\n",
      "Epoch 3464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3470 - accuracy: 0.0312 - val_loss: 130.7907 - val_accuracy: 0.0588\n",
      "Epoch 3465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6984 - accuracy: 0.0000e+00 - val_loss: 133.1999 - val_accuracy: 0.0588\n",
      "Epoch 3466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8041 - accuracy: 0.0000e+00 - val_loss: 132.1951 - val_accuracy: 0.0588\n",
      "Epoch 3467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3770 - accuracy: 0.0000e+00 - val_loss: 134.3948 - val_accuracy: 0.0588\n",
      "Epoch 3468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2715 - accuracy: 0.0156 - val_loss: 121.1444 - val_accuracy: 0.0588\n",
      "Epoch 3469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7013 - accuracy: 0.0000e+00 - val_loss: 117.1128 - val_accuracy: 0.0588\n",
      "Epoch 3470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8839 - accuracy: 0.0000e+00 - val_loss: 114.7128 - val_accuracy: 0.0588\n",
      "Epoch 3471/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.2981 - accuracy: 0.0000e+00 - val_loss: 118.3704 - val_accuracy: 0.0588\n",
      "Epoch 3472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0437 - accuracy: 0.0156 - val_loss: 132.6689 - val_accuracy: 0.0588\n",
      "Epoch 3473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5015 - accuracy: 0.0000e+00 - val_loss: 130.5774 - val_accuracy: 0.0588\n",
      "Epoch 3474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.2016 - accuracy: 0.0000e+00 - val_loss: 136.1351 - val_accuracy: 0.0588\n",
      "Epoch 3475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4467 - accuracy: 0.0000e+00 - val_loss: 134.7344 - val_accuracy: 0.0588\n",
      "Epoch 3476/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9475 - accuracy: 0.0000e+00 - val_loss: 131.7140 - val_accuracy: 0.0588\n",
      "Epoch 3477/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 31.5284 - accuracy: 0.0156 - val_loss: 127.8865 - val_accuracy: 0.0588\n",
      "Epoch 3478/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9392 - accuracy: 0.0000e+00 - val_loss: 125.4911 - val_accuracy: 0.0588\n",
      "Epoch 3479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.8115 - accuracy: 0.0000e+00 - val_loss: 118.9741 - val_accuracy: 0.0588\n",
      "Epoch 3480/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5881 - accuracy: 0.0000e+00 - val_loss: 127.8182 - val_accuracy: 0.0588\n",
      "Epoch 3481/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 32.1451 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 36.1771 - accuracy: 0.0000e+00 - val_loss: 138.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5736 - accuracy: 0.0312 - val_loss: 139.6881 - val_accuracy: 0.0588\n",
      "Epoch 3483/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 45.9268 - accuracy: 0.0000e+00 - val_loss: 130.7517 - val_accuracy: 0.0588\n",
      "Epoch 3484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8778 - accuracy: 0.0000e+00 - val_loss: 120.7008 - val_accuracy: 0.0588\n",
      "Epoch 3485/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5491 - accuracy: 0.0000e+00 - val_loss: 115.3249 - val_accuracy: 0.0588\n",
      "Epoch 3486/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 37.6052 - accuracy: 0.0000e+00 - val_loss: 114.2790 - val_accuracy: 0.0588\n",
      "Epoch 3487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6189 - accuracy: 0.0000e+00 - val_loss: 123.1870 - val_accuracy: 0.0588\n",
      "Epoch 3488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.8959 - accuracy: 0.0000e+00 - val_loss: 147.7010 - val_accuracy: 0.0588\n",
      "Epoch 3489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.6732 - accuracy: 0.0156 - val_loss: 163.8936 - val_accuracy: 0.0588\n",
      "Epoch 3490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2681 - accuracy: 0.0000e+00 - val_loss: 151.9969 - val_accuracy: 0.0588\n",
      "Epoch 3491/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 37.6278 - accuracy: 0.0000e+00 - val_loss: 138.0656 - val_accuracy: 0.0588\n",
      "Epoch 3492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5432 - accuracy: 0.0156 - val_loss: 122.0087 - val_accuracy: 0.1176\n",
      "Epoch 3493/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.1819 - accuracy: 0.0000e+00 - val_loss: 119.6037 - val_accuracy: 0.1176\n",
      "Epoch 3494/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 34.8468 - accuracy: 0.0000e+00 - val_loss: 128.0375 - val_accuracy: 0.0588\n",
      "Epoch 3495/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 36.4675 - accuracy: 0.0000e+00 - val_loss: 145.9003 - val_accuracy: 0.0588\n",
      "Epoch 3496/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 40.3151 - accuracy: 0.0000e+00 - val_loss: 147.5926 - val_accuracy: 0.0588\n",
      "Epoch 3497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.4659 - accuracy: 0.0000e+00 - val_loss: 132.2088 - val_accuracy: 0.0588\n",
      "Epoch 3498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7620 - accuracy: 0.0156 - val_loss: 121.4927 - val_accuracy: 0.0588\n",
      "Epoch 3499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7055 - accuracy: 0.0000e+00 - val_loss: 115.9607 - val_accuracy: 0.0588\n",
      "Epoch 3500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4333 - accuracy: 0.0000e+00 - val_loss: 123.7913 - val_accuracy: 0.0588\n",
      "Epoch 3501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6267 - accuracy: 0.0000e+00 - val_loss: 142.1627 - val_accuracy: 0.0588\n",
      "Epoch 3502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8202 - accuracy: 0.0000e+00 - val_loss: 152.8898 - val_accuracy: 0.0588\n",
      "Epoch 3503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1483 - accuracy: 0.0156 - val_loss: 153.5370 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3504/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 39.0451 - accuracy: 0.0000e+00 - val_loss: 144.7825 - val_accuracy: 0.0588\n",
      "Epoch 3505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9888 - accuracy: 0.0000e+00 - val_loss: 128.7711 - val_accuracy: 0.0588\n",
      "Epoch 3506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9337 - accuracy: 0.0000e+00 - val_loss: 125.1293 - val_accuracy: 0.0588\n",
      "Epoch 3507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6236 - accuracy: 0.0156 - val_loss: 133.3610 - val_accuracy: 0.0588\n",
      "Epoch 3508/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4005 - accuracy: 0.0312 - val_loss: 140.3737 - val_accuracy: 0.0588\n",
      "Epoch 3509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9544 - accuracy: 0.0156 - val_loss: 132.8483 - val_accuracy: 0.0588\n",
      "Epoch 3510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4088 - accuracy: 0.0000e+00 - val_loss: 121.7625 - val_accuracy: 0.0588\n",
      "Epoch 3511/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0394 - accuracy: 0.0000e+00 - val_loss: 125.3913 - val_accuracy: 0.1176\n",
      "Epoch 3512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6782 - accuracy: 0.0000e+00 - val_loss: 132.9203 - val_accuracy: 0.0588\n",
      "Epoch 3513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0620 - accuracy: 0.0000e+00 - val_loss: 143.0502 - val_accuracy: 0.1176\n",
      "Epoch 3514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5544 - accuracy: 0.0156 - val_loss: 151.0084 - val_accuracy: 0.1176\n",
      "Epoch 3515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5975 - accuracy: 0.0000e+00 - val_loss: 152.2187 - val_accuracy: 0.0588\n",
      "Epoch 3516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2131 - accuracy: 0.0000e+00 - val_loss: 149.8131 - val_accuracy: 0.0588\n",
      "Epoch 3517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1096 - accuracy: 0.0000e+00 - val_loss: 144.1530 - val_accuracy: 0.0588\n",
      "Epoch 3518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6391 - accuracy: 0.0000e+00 - val_loss: 142.8463 - val_accuracy: 0.0588\n",
      "Epoch 3519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2592 - accuracy: 0.0000e+00 - val_loss: 141.5249 - val_accuracy: 0.0588\n",
      "Epoch 3520/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2376 - accuracy: 0.0156 - val_loss: 133.3788 - val_accuracy: 0.0588\n",
      "Epoch 3521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8161 - accuracy: 0.0000e+00 - val_loss: 127.8551 - val_accuracy: 0.0000e+00\n",
      "Epoch 3522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0278 - accuracy: 0.0156 - val_loss: 125.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0558 - accuracy: 0.0156 - val_loss: 122.2528 - val_accuracy: 0.0000e+00\n",
      "Epoch 3524/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 32.6200 - accuracy: 0.0000e+00 - val_loss: 121.3829 - val_accuracy: 0.0000e+00\n",
      "Epoch 3525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4901 - accuracy: 0.0000e+00 - val_loss: 129.2953 - val_accuracy: 0.0000e+00\n",
      "Epoch 3526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6075 - accuracy: 0.0312 - val_loss: 135.8520 - val_accuracy: 0.0588\n",
      "Epoch 3527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2151 - accuracy: 0.0156 - val_loss: 134.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 3528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9188 - accuracy: 0.0000e+00 - val_loss: 123.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 3529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7812 - accuracy: 0.0000e+00 - val_loss: 119.5150 - val_accuracy: 0.0000e+00\n",
      "Epoch 3530/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.7484 - accuracy: 0.0156 - val_loss: 119.5407 - val_accuracy: 0.0588\n",
      "Epoch 3531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1777 - accuracy: 0.0156 - val_loss: 125.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 3532/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.6435 - accuracy: 0.0000e+00 - val_loss: 130.4716 - val_accuracy: 0.0588\n",
      "Epoch 3533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8861 - accuracy: 0.0156 - val_loss: 128.7461 - val_accuracy: 0.0588\n",
      "Epoch 3534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0153 - accuracy: 0.0156 - val_loss: 128.5075 - val_accuracy: 0.0588\n",
      "Epoch 3535/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 38.4563 - accuracy: 0.0156 - val_loss: 124.6608 - val_accuracy: 0.0588\n",
      "Epoch 3536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2975 - accuracy: 0.0156 - val_loss: 122.6686 - val_accuracy: 0.0588\n",
      "Epoch 3537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2278 - accuracy: 0.0000e+00 - val_loss: 117.8664 - val_accuracy: 0.0588\n",
      "Epoch 3538/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8936 - accuracy: 0.0000e+00 - val_loss: 118.3648 - val_accuracy: 0.0588\n",
      "Epoch 3539/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4777 - accuracy: 0.0156 - val_loss: 122.8662 - val_accuracy: 0.0588\n",
      "Epoch 3540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9567 - accuracy: 0.0000e+00 - val_loss: 127.4602 - val_accuracy: 0.0588\n",
      "Epoch 3541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3796 - accuracy: 0.0000e+00 - val_loss: 131.5602 - val_accuracy: 0.0588\n",
      "Epoch 3542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4435 - accuracy: 0.0000e+00 - val_loss: 131.2219 - val_accuracy: 0.0588\n",
      "Epoch 3543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2894 - accuracy: 0.0156 - val_loss: 125.8370 - val_accuracy: 0.0588\n",
      "Epoch 3544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5969 - accuracy: 0.0000e+00 - val_loss: 125.9151 - val_accuracy: 0.0588\n",
      "Epoch 3545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.4893 - accuracy: 0.0156 - val_loss: 131.1734 - val_accuracy: 0.0588\n",
      "Epoch 3546/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.8857 - accuracy: 0.0156 - val_loss: 136.1902 - val_accuracy: 0.0588\n",
      "Epoch 3547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9712 - accuracy: 0.0000e+00 - val_loss: 133.4469 - val_accuracy: 0.0588\n",
      "Epoch 3548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0920 - accuracy: 0.0312 - val_loss: 135.7957 - val_accuracy: 0.0588\n",
      "Epoch 3549/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.1325 - accuracy: 0.0000e+00 - val_loss: 125.6920 - val_accuracy: 0.0588\n",
      "Epoch 3550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8407 - accuracy: 0.0156 - val_loss: 115.8303 - val_accuracy: 0.0588\n",
      "Epoch 3551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9737 - accuracy: 0.0000e+00 - val_loss: 116.4359 - val_accuracy: 0.0588\n",
      "Epoch 3552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5570 - accuracy: 0.0156 - val_loss: 123.5292 - val_accuracy: 0.0588\n",
      "Epoch 3553/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7396 - accuracy: 0.0312 - val_loss: 129.4042 - val_accuracy: 0.0588\n",
      "Epoch 3554/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 50.0654 - accuracy: 0.0156 - val_loss: 133.8990 - val_accuracy: 0.0588\n",
      "Epoch 3555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2933 - accuracy: 0.0000e+00 - val_loss: 143.0954 - val_accuracy: 0.0588\n",
      "Epoch 3556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1912 - accuracy: 0.0000e+00 - val_loss: 147.0469 - val_accuracy: 0.1176\n",
      "Epoch 3557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8910 - accuracy: 0.0312 - val_loss: 148.1236 - val_accuracy: 0.0588\n",
      "Epoch 3558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2174 - accuracy: 0.0156 - val_loss: 144.4283 - val_accuracy: 0.0588\n",
      "Epoch 3559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3381 - accuracy: 0.0000e+00 - val_loss: 133.4205 - val_accuracy: 0.1176\n",
      "Epoch 3560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4333 - accuracy: 0.0000e+00 - val_loss: 127.0234 - val_accuracy: 0.1176\n",
      "Epoch 3561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0487 - accuracy: 0.0156 - val_loss: 130.0294 - val_accuracy: 0.0588\n",
      "Epoch 3562/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3873 - accuracy: 0.0312 - val_loss: 132.4250 - val_accuracy: 0.0588\n",
      "Epoch 3563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5977 - accuracy: 0.0156 - val_loss: 124.9199 - val_accuracy: 0.0588\n",
      "Epoch 3564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6946 - accuracy: 0.0625 - val_loss: 119.1349 - val_accuracy: 0.0588\n",
      "Epoch 3565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3871 - accuracy: 0.0156 - val_loss: 115.7026 - val_accuracy: 0.1176\n",
      "Epoch 3566/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5277 - accuracy: 0.0000e+00 - val_loss: 113.4851 - val_accuracy: 0.0588\n",
      "Epoch 3567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2401 - accuracy: 0.0156 - val_loss: 121.0042 - val_accuracy: 0.1176\n",
      "Epoch 3568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5033 - accuracy: 0.0000e+00 - val_loss: 133.3510 - val_accuracy: 0.0588\n",
      "Epoch 3569/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 37.1899 - accuracy: 0.0156 - val_loss: 137.9650 - val_accuracy: 0.0588\n",
      "Epoch 3570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.3870 - accuracy: 0.0000e+00 - val_loss: 129.7012 - val_accuracy: 0.0588\n",
      "Epoch 3571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1204 - accuracy: 0.0000e+00 - val_loss: 123.0111 - val_accuracy: 0.0588\n",
      "Epoch 3572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4239 - accuracy: 0.0312 - val_loss: 123.4136 - val_accuracy: 0.0588\n",
      "Epoch 3573/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.4877 - accuracy: 0.0000e+00 - val_loss: 128.0623 - val_accuracy: 0.0588\n",
      "Epoch 3574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4884 - accuracy: 0.0000e+00 - val_loss: 123.9815 - val_accuracy: 0.0588\n",
      "Epoch 3575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7454 - accuracy: 0.0000e+00 - val_loss: 115.8109 - val_accuracy: 0.0588\n",
      "Epoch 3576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8862 - accuracy: 0.0156 - val_loss: 113.5925 - val_accuracy: 0.0588\n",
      "Epoch 3577/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 33.3317 - accuracy: 0.0000e+00 - val_loss: 116.7405 - val_accuracy: 0.0588\n",
      "Epoch 3578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5791 - accuracy: 0.0312 - val_loss: 120.2933 - val_accuracy: 0.0588\n",
      "Epoch 3579/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 29.2825 - accuracy: 0.0312 - val_loss: 135.6321 - val_accuracy: 0.0588\n",
      "Epoch 3580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9012 - accuracy: 0.0156 - val_loss: 151.1228 - val_accuracy: 0.0588\n",
      "Epoch 3581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1278 - accuracy: 0.0000e+00 - val_loss: 148.1175 - val_accuracy: 0.0588\n",
      "Epoch 3582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2219 - accuracy: 0.0156 - val_loss: 133.9722 - val_accuracy: 0.0588\n",
      "Epoch 3583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7739 - accuracy: 0.0000e+00 - val_loss: 130.3371 - val_accuracy: 0.0588\n",
      "Epoch 3584/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.0314 - accuracy: 0.0000e+00 - val_loss: 130.3063 - val_accuracy: 0.0588\n",
      "Epoch 3585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2226 - accuracy: 0.0156 - val_loss: 144.6648 - val_accuracy: 0.0588\n",
      "Epoch 3586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0402 - accuracy: 0.0156 - val_loss: 155.7528 - val_accuracy: 0.0588\n",
      "Epoch 3587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3638 - accuracy: 0.0000e+00 - val_loss: 154.4678 - val_accuracy: 0.0588\n",
      "Epoch 3588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1548 - accuracy: 0.0156 - val_loss: 135.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 3589/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 43.8677 - accuracy: 0.0156 - val_loss: 117.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 3590/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6164 - accuracy: 0.0000e+00 - val_loss: 120.2043 - val_accuracy: 0.0000e+00\n",
      "Epoch 3591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6357 - accuracy: 0.0000e+00 - val_loss: 125.6701 - val_accuracy: 0.0000e+00\n",
      "Epoch 3592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0240 - accuracy: 0.0000e+00 - val_loss: 135.2737 - val_accuracy: 0.0588\n",
      "Epoch 3593/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 48.4852 - accuracy: 0.0156 - val_loss: 137.2322 - val_accuracy: 0.0588\n",
      "Epoch 3594/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 44.2073 - accuracy: 0.0156 - val_loss: 129.1624 - val_accuracy: 0.0588\n",
      "Epoch 3595/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 36.1183 - accuracy: 0.0000e+00 - val_loss: 115.1110 - val_accuracy: 0.0588\n",
      "Epoch 3596/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 39.5931 - accuracy: 0.0000e+00 - val_loss: 107.8449 - val_accuracy: 0.0588\n",
      "Epoch 3597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2685 - accuracy: 0.0000e+00 - val_loss: 108.3264 - val_accuracy: 0.0588\n",
      "Epoch 3598/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 35.9889 - accuracy: 0.0000e+00 - val_loss: 121.6351 - val_accuracy: 0.0588\n",
      "Epoch 3599/10000\n",
      "64/64 [==============================] - 0s 219us/step - loss: 23.1312 - accuracy: 0.0156 - val_loss: 135.0422 - val_accuracy: 0.0588\n",
      "Epoch 3600/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 33.9101 - accuracy: 0.0156 - val_loss: 134.3109 - val_accuracy: 0.0588\n",
      "Epoch 3601/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 41.0242 - accuracy: 0.0156 - val_loss: 124.6924 - val_accuracy: 0.0588\n",
      "Epoch 3602/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 27.9918 - accuracy: 0.0000e+00 - val_loss: 118.6724 - val_accuracy: 0.0588\n",
      "Epoch 3603/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 26.4964 - accuracy: 0.0000e+00 - val_loss: 120.4080 - val_accuracy: 0.0588\n",
      "Epoch 3604/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 37.2526 - accuracy: 0.0156 - val_loss: 124.5899 - val_accuracy: 0.0588\n",
      "Epoch 3605/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.9099 - accuracy: 0.0156 - val_loss: 131.1334 - val_accuracy: 0.1176\n",
      "Epoch 3606/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 42.2920 - accuracy: 0.0000e+00 - val_loss: 139.8013 - val_accuracy: 0.0588\n",
      "Epoch 3607/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 34.6667 - accuracy: 0.0156 - val_loss: 137.6305 - val_accuracy: 0.0588\n",
      "Epoch 3608/10000\n",
      "64/64 [==============================] - 0s 219us/step - loss: 43.7948 - accuracy: 0.0000e+00 - val_loss: 134.7238 - val_accuracy: 0.0588\n",
      "Epoch 3609/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 37.2052 - accuracy: 0.0000e+00 - val_loss: 129.7184 - val_accuracy: 0.0588\n",
      "Epoch 3610/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 198us/step - loss: 41.9284 - accuracy: 0.0000e+00 - val_loss: 123.5745 - val_accuracy: 0.1176\n",
      "Epoch 3611/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.6214 - accuracy: 0.0000e+00 - val_loss: 122.7261 - val_accuracy: 0.1176\n",
      "Epoch 3612/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 37.5607 - accuracy: 0.0000e+00 - val_loss: 131.0331 - val_accuracy: 0.0588\n",
      "Epoch 3613/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 36.9657 - accuracy: 0.0156 - val_loss: 141.3878 - val_accuracy: 0.0588\n",
      "Epoch 3614/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 31.3578 - accuracy: 0.0156 - val_loss: 138.5567 - val_accuracy: 0.0588\n",
      "Epoch 3615/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 36.6171 - accuracy: 0.0156 - val_loss: 129.4194 - val_accuracy: 0.1176\n",
      "Epoch 3616/10000\n",
      "64/64 [==============================] - 0s 212us/step - loss: 25.5110 - accuracy: 0.0156 - val_loss: 120.7453 - val_accuracy: 0.1176\n",
      "Epoch 3617/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 46.2580 - accuracy: 0.0156 - val_loss: 112.5363 - val_accuracy: 0.0588\n",
      "Epoch 3618/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 45.1876 - accuracy: 0.0000e+00 - val_loss: 110.3796 - val_accuracy: 0.0588\n",
      "Epoch 3619/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 27.2591 - accuracy: 0.0000e+00 - val_loss: 116.5886 - val_accuracy: 0.0588\n",
      "Epoch 3620/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.8011 - accuracy: 0.0156 - val_loss: 123.1484 - val_accuracy: 0.0588\n",
      "Epoch 3621/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 33.7419 - accuracy: 0.0469 - val_loss: 131.8248 - val_accuracy: 0.0588\n",
      "Epoch 3622/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 38.0851 - accuracy: 0.0156 - val_loss: 124.0455 - val_accuracy: 0.0588\n",
      "Epoch 3623/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 37.6356 - accuracy: 0.0000e+00 - val_loss: 123.0142 - val_accuracy: 0.0588\n",
      "Epoch 3624/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 48.8943 - accuracy: 0.0000e+00 - val_loss: 123.4488 - val_accuracy: 0.0588\n",
      "Epoch 3625/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.8804 - accuracy: 0.0000e+00 - val_loss: 126.0437 - val_accuracy: 0.0588\n",
      "Epoch 3626/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.3230 - accuracy: 0.0000e+00 - val_loss: 134.9064 - val_accuracy: 0.0588\n",
      "Epoch 3627/10000\n",
      "64/64 [==============================] - 0s 252us/step - loss: 36.7672 - accuracy: 0.0000e+00 - val_loss: 136.2915 - val_accuracy: 0.0588\n",
      "Epoch 3628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.9286 - accuracy: 0.0000e+00 - val_loss: 127.6899 - val_accuracy: 0.0588\n",
      "Epoch 3629/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 31.3360 - accuracy: 0.0000e+00 - val_loss: 113.9641 - val_accuracy: 0.0588\n",
      "Epoch 3630/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 50.6569 - accuracy: 0.0000e+00 - val_loss: 105.2984 - val_accuracy: 0.0588\n",
      "Epoch 3631/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 45.0248 - accuracy: 0.0156 - val_loss: 102.0959 - val_accuracy: 0.0588\n",
      "Epoch 3632/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 41.1121 - accuracy: 0.0000e+00 - val_loss: 115.2248 - val_accuracy: 0.0588\n",
      "Epoch 3633/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 44.5603 - accuracy: 0.0156 - val_loss: 138.1491 - val_accuracy: 0.0588\n",
      "Epoch 3634/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 46.9183 - accuracy: 0.0000e+00 - val_loss: 155.5193 - val_accuracy: 0.0588\n",
      "Epoch 3635/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.8229 - accuracy: 0.0000e+00 - val_loss: 151.0028 - val_accuracy: 0.0588\n",
      "Epoch 3636/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 35.8091 - accuracy: 0.0156 - val_loss: 129.9526 - val_accuracy: 0.0588\n",
      "Epoch 3637/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.4561 - accuracy: 0.0000e+00 - val_loss: 115.5442 - val_accuracy: 0.0588\n",
      "Epoch 3638/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.8299 - accuracy: 0.0000e+00 - val_loss: 110.7184 - val_accuracy: 0.0588\n",
      "Epoch 3639/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 37.9504 - accuracy: 0.0312 - val_loss: 119.0907 - val_accuracy: 0.0588\n",
      "Epoch 3640/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 37.7811 - accuracy: 0.0000e+00 - val_loss: 127.9027 - val_accuracy: 0.1176\n",
      "Epoch 3641/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.8517 - accuracy: 0.0625 - val_loss: 131.6795 - val_accuracy: 0.0588\n",
      "Epoch 3642/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.1618 - accuracy: 0.0156 - val_loss: 120.4655 - val_accuracy: 0.0588\n",
      "Epoch 3643/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 50.5131 - accuracy: 0.0156 - val_loss: 115.7133 - val_accuracy: 0.1176\n",
      "Epoch 3644/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.6464 - accuracy: 0.0000e+00 - val_loss: 117.9547 - val_accuracy: 0.1176\n",
      "Epoch 3645/10000\n",
      "64/64 [==============================] - 0s 166us/step - loss: 31.2356 - accuracy: 0.0156 - val_loss: 121.4702 - val_accuracy: 0.1176\n",
      "Epoch 3646/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 36.9287 - accuracy: 0.0000e+00 - val_loss: 122.0532 - val_accuracy: 0.1176\n",
      "Epoch 3647/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 47.9725 - accuracy: 0.0156 - val_loss: 122.8805 - val_accuracy: 0.1176\n",
      "Epoch 3648/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 47.8370 - accuracy: 0.0000e+00 - val_loss: 122.7758 - val_accuracy: 0.0588\n",
      "Epoch 3649/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.4302 - accuracy: 0.0156 - val_loss: 120.9639 - val_accuracy: 0.0588\n",
      "Epoch 3650/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.2436 - accuracy: 0.0000e+00 - val_loss: 127.4310 - val_accuracy: 0.0588\n",
      "Epoch 3651/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.5789 - accuracy: 0.0000e+00 - val_loss: 132.1439 - val_accuracy: 0.0588\n",
      "Epoch 3652/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 42.9430 - accuracy: 0.0156 - val_loss: 128.4573 - val_accuracy: 0.0588\n",
      "Epoch 3653/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 43.4291 - accuracy: 0.0000e+00 - val_loss: 129.4936 - val_accuracy: 0.0588\n",
      "Epoch 3654/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.8333 - accuracy: 0.0156 - val_loss: 130.0127 - val_accuracy: 0.0588\n",
      "Epoch 3655/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 28.9740 - accuracy: 0.0000e+00 - val_loss: 127.1843 - val_accuracy: 0.1176\n",
      "Epoch 3656/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 54.0185 - accuracy: 0.0000e+00 - val_loss: 123.4061 - val_accuracy: 0.0588\n",
      "Epoch 3657/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 38.9115 - accuracy: 0.0000e+00 - val_loss: 123.0864 - val_accuracy: 0.0588\n",
      "Epoch 3658/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.9956 - accuracy: 0.0000e+00 - val_loss: 123.3392 - val_accuracy: 0.0588\n",
      "Epoch 3659/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.6954 - accuracy: 0.0156 - val_loss: 123.4831 - val_accuracy: 0.0588\n",
      "Epoch 3660/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 39.3978 - accuracy: 0.0156 - val_loss: 135.5121 - val_accuracy: 0.0588\n",
      "Epoch 3661/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 41.2595 - accuracy: 0.0000e+00 - val_loss: 144.2235 - val_accuracy: 0.0588\n",
      "Epoch 3662/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 42.6947 - accuracy: 0.0312 - val_loss: 142.7358 - val_accuracy: 0.0588\n",
      "Epoch 3663/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 26.7461 - accuracy: 0.0312 - val_loss: 138.5460 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3664/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 36.5674 - accuracy: 0.0000e+00 - val_loss: 134.8834 - val_accuracy: 0.0588\n",
      "Epoch 3665/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.8218 - accuracy: 0.0312 - val_loss: 127.2359 - val_accuracy: 0.0588\n",
      "Epoch 3666/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 43.5826 - accuracy: 0.0156 - val_loss: 124.4204 - val_accuracy: 0.0588\n",
      "Epoch 3667/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.2820 - accuracy: 0.0000e+00 - val_loss: 124.6757 - val_accuracy: 0.1176\n",
      "Epoch 3668/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.1168 - accuracy: 0.0000e+00 - val_loss: 137.4374 - val_accuracy: 0.0588\n",
      "Epoch 3669/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 29.5408 - accuracy: 0.0156 - val_loss: 144.0367 - val_accuracy: 0.0588\n",
      "Epoch 3670/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 51.3262 - accuracy: 0.0000e+00 - val_loss: 133.7022 - val_accuracy: 0.0588\n",
      "Epoch 3671/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 30.6482 - accuracy: 0.0312 - val_loss: 122.3210 - val_accuracy: 0.0588\n",
      "Epoch 3672/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 36.3021 - accuracy: 0.0156 - val_loss: 115.5915 - val_accuracy: 0.0588\n",
      "Epoch 3673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.6723 - accuracy: 0.0000e+00 - val_loss: 114.3739 - val_accuracy: 0.0588\n",
      "Epoch 3674/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 64.7727 - accuracy: 0.0469 - val_loss: 123.9517 - val_accuracy: 0.0000e+00\n",
      "Epoch 3675/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 35.0563 - accuracy: 0.0312 - val_loss: 131.7881 - val_accuracy: 0.0000e+00\n",
      "Epoch 3676/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.7856 - accuracy: 0.0000e+00 - val_loss: 133.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 3677/10000\n",
      "64/64 [==============================] - 0s 208us/step - loss: 30.3854 - accuracy: 0.0156 - val_loss: 136.1741 - val_accuracy: 0.0588\n",
      "Epoch 3678/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 39.0432 - accuracy: 0.0312 - val_loss: 131.8311 - val_accuracy: 0.0588\n",
      "Epoch 3679/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 34.8325 - accuracy: 0.0000e+00 - val_loss: 123.3106 - val_accuracy: 0.0588\n",
      "Epoch 3680/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.0329 - accuracy: 0.0000e+00 - val_loss: 114.6016 - val_accuracy: 0.0588\n",
      "Epoch 3681/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.6878 - accuracy: 0.0000e+00 - val_loss: 105.2196 - val_accuracy: 0.0588\n",
      "Epoch 3682/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 37.6288 - accuracy: 0.0000e+00 - val_loss: 99.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 3683/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 36.3006 - accuracy: 0.0000e+00 - val_loss: 111.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 3684/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 36.2532 - accuracy: 0.0156 - val_loss: 118.6949 - val_accuracy: 0.0000e+00\n",
      "Epoch 3685/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.2606 - accuracy: 0.0156 - val_loss: 116.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 3686/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 47.1273 - accuracy: 0.0000e+00 - val_loss: 111.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3687/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1116 - accuracy: 0.0000e+00 - val_loss: 103.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 3688/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 52.9620 - accuracy: 0.0000e+00 - val_loss: 100.3202 - val_accuracy: 0.0000e+00\n",
      "Epoch 3689/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 38.2614 - accuracy: 0.0156 - val_loss: 104.2124 - val_accuracy: 0.0000e+00\n",
      "Epoch 3690/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 27.1721 - accuracy: 0.0156 - val_loss: 109.4008 - val_accuracy: 0.0588\n",
      "Epoch 3691/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 40.4896 - accuracy: 0.0000e+00 - val_loss: 125.9389 - val_accuracy: 0.0000e+00\n",
      "Epoch 3692/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.6952 - accuracy: 0.0312 - val_loss: 150.9591 - val_accuracy: 0.0000e+00\n",
      "Epoch 3693/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 45.7780 - accuracy: 0.0312 - val_loss: 151.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 3694/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 66.8003 - accuracy: 0.0156 - val_loss: 127.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 3695/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.5784 - accuracy: 0.0156 - val_loss: 106.5801 - val_accuracy: 0.0588\n",
      "Epoch 3696/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.5054 - accuracy: 0.0156 - val_loss: 102.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 3697/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 63.1004 - accuracy: 0.0000e+00 - val_loss: 103.2716 - val_accuracy: 0.0000e+00\n",
      "Epoch 3698/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 48.5241 - accuracy: 0.0156 - val_loss: 117.3573 - val_accuracy: 0.0588\n",
      "Epoch 3699/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 32.0806 - accuracy: 0.0156 - val_loss: 135.1287 - val_accuracy: 0.0588\n",
      "Epoch 3700/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.8758 - accuracy: 0.0156 - val_loss: 138.9446 - val_accuracy: 0.0588\n",
      "Epoch 3701/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.0773 - accuracy: 0.0156 - val_loss: 131.0329 - val_accuracy: 0.0588\n",
      "Epoch 3702/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 30.6758 - accuracy: 0.0312 - val_loss: 117.6527 - val_accuracy: 0.0000e+00\n",
      "Epoch 3703/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 30.4013 - accuracy: 0.0000e+00 - val_loss: 110.8807 - val_accuracy: 0.0588\n",
      "Epoch 3704/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 42.9156 - accuracy: 0.0000e+00 - val_loss: 114.7569 - val_accuracy: 0.0588\n",
      "Epoch 3705/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 32.8422 - accuracy: 0.0000e+00 - val_loss: 126.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 3706/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 31.0452 - accuracy: 0.0000e+00 - val_loss: 139.2571 - val_accuracy: 0.0588\n",
      "Epoch 3707/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 30.0758 - accuracy: 0.0156 - val_loss: 144.6449 - val_accuracy: 0.0588\n",
      "Epoch 3708/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 38.6184 - accuracy: 0.0000e+00 - val_loss: 137.6405 - val_accuracy: 0.0588\n",
      "Epoch 3709/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8247 - accuracy: 0.0000e+00 - val_loss: 136.0161 - val_accuracy: 0.0588\n",
      "Epoch 3710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3143 - accuracy: 0.0000e+00 - val_loss: 129.6769 - val_accuracy: 0.0588\n",
      "Epoch 3711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4773 - accuracy: 0.0156 - val_loss: 119.6992 - val_accuracy: 0.1176\n",
      "Epoch 3712/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 29.6155 - accuracy: 0.0000e+00 - val_loss: 115.0339 - val_accuracy: 0.0588\n",
      "Epoch 3713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5688 - accuracy: 0.0156 - val_loss: 115.9796 - val_accuracy: 0.0588\n",
      "Epoch 3714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.0337 - accuracy: 0.0156 - val_loss: 140.2581 - val_accuracy: 0.0588\n",
      "Epoch 3715/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.9896 - accuracy: 0.0156 - val_loss: 157.6743 - val_accuracy: 0.0588\n",
      "Epoch 3716/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 44.9932 - accuracy: 0.0156 - val_loss: 155.8367 - val_accuracy: 0.0588\n",
      "Epoch 3717/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 32.1588 - accuracy: 0.0156 - val_loss: 137.8895 - val_accuracy: 0.0588\n",
      "Epoch 3718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1888 - accuracy: 0.0000e+00 - val_loss: 123.6043 - val_accuracy: 0.0588\n",
      "Epoch 3719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1437 - accuracy: 0.0156 - val_loss: 120.2000 - val_accuracy: 0.1176\n",
      "Epoch 3720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4887 - accuracy: 0.0156 - val_loss: 135.9581 - val_accuracy: 0.0588\n",
      "Epoch 3721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7309 - accuracy: 0.0000e+00 - val_loss: 141.6222 - val_accuracy: 0.0588\n",
      "Epoch 3722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2598 - accuracy: 0.0000e+00 - val_loss: 123.8623 - val_accuracy: 0.0588\n",
      "Epoch 3723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5308 - accuracy: 0.0312 - val_loss: 109.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4999 - accuracy: 0.0156 - val_loss: 103.8158 - val_accuracy: 0.0588\n",
      "Epoch 3725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8358 - accuracy: 0.0000e+00 - val_loss: 106.7937 - val_accuracy: 0.0588\n",
      "Epoch 3726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3783 - accuracy: 0.0000e+00 - val_loss: 105.6747 - val_accuracy: 0.0588\n",
      "Epoch 3727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9323 - accuracy: 0.0156 - val_loss: 107.4082 - val_accuracy: 0.0588\n",
      "Epoch 3728/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.8958 - accuracy: 0.0000e+00 - val_loss: 113.4205 - val_accuracy: 0.0588\n",
      "Epoch 3729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6437 - accuracy: 0.0156 - val_loss: 121.3686 - val_accuracy: 0.0000e+00\n",
      "Epoch 3730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0175 - accuracy: 0.0000e+00 - val_loss: 123.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 3731/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 41.0032 - accuracy: 0.0156 - val_loss: 127.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 3732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0527 - accuracy: 0.0000e+00 - val_loss: 126.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 3733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1575 - accuracy: 0.0000e+00 - val_loss: 129.3701 - val_accuracy: 0.0000e+00\n",
      "Epoch 3734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9860 - accuracy: 0.0000e+00 - val_loss: 136.3055 - val_accuracy: 0.0588\n",
      "Epoch 3735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4737 - accuracy: 0.0000e+00 - val_loss: 139.8511 - val_accuracy: 0.0588\n",
      "Epoch 3736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8607 - accuracy: 0.0000e+00 - val_loss: 136.9650 - val_accuracy: 0.0588\n",
      "Epoch 3737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2143 - accuracy: 0.0000e+00 - val_loss: 132.8741 - val_accuracy: 0.1176\n",
      "Epoch 3738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0960 - accuracy: 0.0156 - val_loss: 127.8439 - val_accuracy: 0.1176\n",
      "Epoch 3739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6419 - accuracy: 0.0000e+00 - val_loss: 119.2495 - val_accuracy: 0.1176\n",
      "Epoch 3740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6602 - accuracy: 0.0312 - val_loss: 118.7572 - val_accuracy: 0.1176\n",
      "Epoch 3741/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 29.2666 - accuracy: 0.0000e+00 - val_loss: 123.3303 - val_accuracy: 0.0588\n",
      "Epoch 3742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3906 - accuracy: 0.0156 - val_loss: 133.2939 - val_accuracy: 0.0588\n",
      "Epoch 3743/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8229 - accuracy: 0.0000e+00 - val_loss: 152.9276 - val_accuracy: 0.0588\n",
      "Epoch 3744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1422 - accuracy: 0.0000e+00 - val_loss: 159.8643 - val_accuracy: 0.0588\n",
      "Epoch 3745/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6519 - accuracy: 0.0000e+00 - val_loss: 152.7955 - val_accuracy: 0.0588\n",
      "Epoch 3746/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0203 - accuracy: 0.0156 - val_loss: 144.4373 - val_accuracy: 0.0588\n",
      "Epoch 3747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9403 - accuracy: 0.0000e+00 - val_loss: 142.5860 - val_accuracy: 0.0588\n",
      "Epoch 3748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7594 - accuracy: 0.0000e+00 - val_loss: 141.1530 - val_accuracy: 0.0588\n",
      "Epoch 3749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1482 - accuracy: 0.0156 - val_loss: 137.5367 - val_accuracy: 0.0588\n",
      "Epoch 3750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1716 - accuracy: 0.0000e+00 - val_loss: 133.7225 - val_accuracy: 0.0588\n",
      "Epoch 3751/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.2496 - accuracy: 0.0000e+00 - val_loss: 130.1820 - val_accuracy: 0.0588\n",
      "Epoch 3752/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.8680 - accuracy: 0.0000e+00 - val_loss: 131.2682 - val_accuracy: 0.0588\n",
      "Epoch 3753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7738 - accuracy: 0.0156 - val_loss: 136.6602 - val_accuracy: 0.0588\n",
      "Epoch 3754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4832 - accuracy: 0.0000e+00 - val_loss: 141.8241 - val_accuracy: 0.0588\n",
      "Epoch 3755/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 46.4109 - accuracy: 0.0000e+00 - val_loss: 139.6339 - val_accuracy: 0.0588\n",
      "Epoch 3756/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9211 - accuracy: 0.0156 - val_loss: 136.7585 - val_accuracy: 0.1176\n",
      "Epoch 3757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0909 - accuracy: 0.0000e+00 - val_loss: 129.6088 - val_accuracy: 0.0588\n",
      "Epoch 3758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4930 - accuracy: 0.0156 - val_loss: 134.4464 - val_accuracy: 0.0588\n",
      "Epoch 3759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4259 - accuracy: 0.0000e+00 - val_loss: 140.5321 - val_accuracy: 0.0588\n",
      "Epoch 3760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3578 - accuracy: 0.0156 - val_loss: 144.2290 - val_accuracy: 0.1176\n",
      "Epoch 3761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2492 - accuracy: 0.0156 - val_loss: 138.4528 - val_accuracy: 0.1176\n",
      "Epoch 3762/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.2097 - accuracy: 0.0000e+00 - val_loss: 129.3848 - val_accuracy: 0.0588\n",
      "Epoch 3763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5572 - accuracy: 0.0156 - val_loss: 126.4485 - val_accuracy: 0.1176\n",
      "Epoch 3764/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 51.6307 - accuracy: 0.0156 - val_loss: 128.3698 - val_accuracy: 0.0588\n",
      "Epoch 3765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2805 - accuracy: 0.0156 - val_loss: 131.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9195 - accuracy: 0.0156 - val_loss: 135.7890 - val_accuracy: 0.0000e+00\n",
      "Epoch 3767/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6011 - accuracy: 0.0000e+00 - val_loss: 135.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 3768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2144 - accuracy: 0.0312 - val_loss: 129.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 3769/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 34.1632 - accuracy: 0.0000e+00 - val_loss: 130.8677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3770/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 42.2902 - accuracy: 0.0000e+00 - val_loss: 132.8121 - val_accuracy: 0.0588\n",
      "Epoch 3771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6067 - accuracy: 0.0000e+00 - val_loss: 136.7819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7718 - accuracy: 0.0312 - val_loss: 144.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 3773/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3958 - accuracy: 0.0000e+00 - val_loss: 140.6785 - val_accuracy: 0.0588\n",
      "Epoch 3774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7734 - accuracy: 0.0000e+00 - val_loss: 131.6897 - val_accuracy: 0.0000e+00\n",
      "Epoch 3775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3139 - accuracy: 0.0156 - val_loss: 119.0385 - val_accuracy: 0.0000e+00\n",
      "Epoch 3776/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 31.5430 - accuracy: 0.0000e+00 - val_loss: 117.2769 - val_accuracy: 0.0000e+00\n",
      "Epoch 3777/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.2676 - accuracy: 0.0000e+00 - val_loss: 126.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 3778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5338 - accuracy: 0.0000e+00 - val_loss: 138.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 3779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2799 - accuracy: 0.0000e+00 - val_loss: 147.3073 - val_accuracy: 0.0000e+00\n",
      "Epoch 3780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9477 - accuracy: 0.0000e+00 - val_loss: 145.1568 - val_accuracy: 0.0588\n",
      "Epoch 3781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4408 - accuracy: 0.0000e+00 - val_loss: 145.2951 - val_accuracy: 0.0000e+00\n",
      "Epoch 3782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6769 - accuracy: 0.0156 - val_loss: 140.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 3783/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3710 - accuracy: 0.0156 - val_loss: 135.0831 - val_accuracy: 0.0588\n",
      "Epoch 3784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.1035 - accuracy: 0.0000e+00 - val_loss: 127.4543 - val_accuracy: 0.0588\n",
      "Epoch 3785/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9040 - accuracy: 0.0000e+00 - val_loss: 120.3822 - val_accuracy: 0.0588\n",
      "Epoch 3786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8087 - accuracy: 0.0000e+00 - val_loss: 119.9554 - val_accuracy: 0.0588\n",
      "Epoch 3787/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 39.7625 - accuracy: 0.0156 - val_loss: 117.4164 - val_accuracy: 0.0588\n",
      "Epoch 3788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5237 - accuracy: 0.0000e+00 - val_loss: 119.1342 - val_accuracy: 0.0588\n",
      "Epoch 3789/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.5380 - accuracy: 0.0156 - val_loss: 123.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 3790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0428 - accuracy: 0.0000e+00 - val_loss: 130.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 3791/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 29.1821 - accuracy: 0.0000e+00 - val_loss: 136.8939 - val_accuracy: 0.0588\n",
      "Epoch 3792/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2200 - accuracy: 0.0000e+00 - val_loss: 142.4931 - val_accuracy: 0.0588\n",
      "Epoch 3793/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3831 - accuracy: 0.0000e+00 - val_loss: 146.9351 - val_accuracy: 0.0588\n",
      "Epoch 3794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6714 - accuracy: 0.0000e+00 - val_loss: 132.4756 - val_accuracy: 0.0588\n",
      "Epoch 3795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8628 - accuracy: 0.0156 - val_loss: 120.2564 - val_accuracy: 0.1176\n",
      "Epoch 3796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9944 - accuracy: 0.0469 - val_loss: 114.4909 - val_accuracy: 0.0588\n",
      "Epoch 3797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5230 - accuracy: 0.0156 - val_loss: 122.1566 - val_accuracy: 0.0588\n",
      "Epoch 3798/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 48.4881 - accuracy: 0.0000e+00 - val_loss: 129.9696 - val_accuracy: 0.1176\n",
      "Epoch 3799/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 38.8098 - accuracy: 0.0000e+00 - val_loss: 127.5656 - val_accuracy: 0.0588\n",
      "Epoch 3800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6975 - accuracy: 0.0000e+00 - val_loss: 125.1249 - val_accuracy: 0.0588\n",
      "Epoch 3801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8297 - accuracy: 0.0000e+00 - val_loss: 132.0846 - val_accuracy: 0.0588\n",
      "Epoch 3802/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.0595 - accuracy: 0.0000e+00 - val_loss: 137.2363 - val_accuracy: 0.0588\n",
      "Epoch 3803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6290 - accuracy: 0.0156 - val_loss: 141.0486 - val_accuracy: 0.0588\n",
      "Epoch 3804/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8734 - accuracy: 0.0000e+00 - val_loss: 142.3187 - val_accuracy: 0.0588\n",
      "Epoch 3805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8694 - accuracy: 0.0000e+00 - val_loss: 135.5204 - val_accuracy: 0.0588\n",
      "Epoch 3806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9750 - accuracy: 0.0000e+00 - val_loss: 139.0461 - val_accuracy: 0.0588\n",
      "Epoch 3807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0853 - accuracy: 0.0000e+00 - val_loss: 141.8850 - val_accuracy: 0.0588\n",
      "Epoch 3808/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.5905 - accuracy: 0.0000e+00 - val_loss: 138.5618 - val_accuracy: 0.0588\n",
      "Epoch 3809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8439 - accuracy: 0.0156 - val_loss: 131.2656 - val_accuracy: 0.0588\n",
      "Epoch 3810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6987 - accuracy: 0.0156 - val_loss: 125.9536 - val_accuracy: 0.0588\n",
      "Epoch 3811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9876 - accuracy: 0.0000e+00 - val_loss: 122.1668 - val_accuracy: 0.0588\n",
      "Epoch 3812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2082 - accuracy: 0.0000e+00 - val_loss: 124.2552 - val_accuracy: 0.0588\n",
      "Epoch 3813/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 34.2806 - accuracy: 0.0156 - val_loss: 128.8634 - val_accuracy: 0.0588\n",
      "Epoch 3814/10000\n",
      "64/64 [==============================] - 0s 202us/step - loss: 43.2412 - accuracy: 0.0000e+00 - val_loss: 132.4486 - val_accuracy: 0.0588\n",
      "Epoch 3815/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 33.8642 - accuracy: 0.0000e+00 - val_loss: 135.8373 - val_accuracy: 0.0588\n",
      "Epoch 3816/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.5985 - accuracy: 0.0000e+00 - val_loss: 137.6210 - val_accuracy: 0.0588\n",
      "Epoch 3817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6476 - accuracy: 0.0000e+00 - val_loss: 140.4191 - val_accuracy: 0.0588\n",
      "Epoch 3818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1904 - accuracy: 0.0000e+00 - val_loss: 134.8389 - val_accuracy: 0.0588\n",
      "Epoch 3819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9353 - accuracy: 0.0156 - val_loss: 130.8927 - val_accuracy: 0.0588\n",
      "Epoch 3820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3583 - accuracy: 0.0312 - val_loss: 130.1658 - val_accuracy: 0.0588\n",
      "Epoch 3821/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.9769 - accuracy: 0.0156 - val_loss: 133.7444 - val_accuracy: 0.0588\n",
      "Epoch 3822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7896 - accuracy: 0.0000e+00 - val_loss: 145.8733 - val_accuracy: 0.0588\n",
      "Epoch 3823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0303 - accuracy: 0.0000e+00 - val_loss: 141.1445 - val_accuracy: 0.0588\n",
      "Epoch 3824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2492 - accuracy: 0.0000e+00 - val_loss: 128.4461 - val_accuracy: 0.0588\n",
      "Epoch 3825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4839 - accuracy: 0.0000e+00 - val_loss: 124.0897 - val_accuracy: 0.0588\n",
      "Epoch 3826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4569 - accuracy: 0.0000e+00 - val_loss: 124.5715 - val_accuracy: 0.0588\n",
      "Epoch 3827/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 48.5742 - accuracy: 0.0156 - val_loss: 121.3135 - val_accuracy: 0.0588\n",
      "Epoch 3828/10000\n",
      "64/64 [==============================] - 0s 687us/step - loss: 34.2138 - accuracy: 0.0312 - val_loss: 127.7781 - val_accuracy: 0.0588\n",
      "Epoch 3829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1338 - accuracy: 0.0000e+00 - val_loss: 126.3745 - val_accuracy: 0.0588\n",
      "Epoch 3830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3661 - accuracy: 0.0156 - val_loss: 119.6941 - val_accuracy: 0.0588\n",
      "Epoch 3831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3204 - accuracy: 0.0156 - val_loss: 122.5589 - val_accuracy: 0.0588\n",
      "Epoch 3832/10000\n",
      "64/64 [==============================] - 0s 266us/step - loss: 21.8102 - accuracy: 0.0312 - val_loss: 125.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 3833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4317 - accuracy: 0.0156 - val_loss: 135.8198 - val_accuracy: 0.0000e+00\n",
      "Epoch 3834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9486 - accuracy: 0.0156 - val_loss: 150.4502 - val_accuracy: 0.0000e+00\n",
      "Epoch 3835/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.4979 - accuracy: 0.0156 - val_loss: 159.4111 - val_accuracy: 0.0000e+00\n",
      "Epoch 3836/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 28.5393 - accuracy: 0.0000e+00 - val_loss: 148.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 3837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1489 - accuracy: 0.0000e+00 - val_loss: 136.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 3838/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 44.7596 - accuracy: 0.0156 - val_loss: 124.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 3839/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.8975 - accuracy: 0.0156 - val_loss: 118.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3840/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5403 - accuracy: 0.0000e+00 - val_loss: 117.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 3841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7686 - accuracy: 0.0000e+00 - val_loss: 118.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 3842/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 39.4006 - accuracy: 0.0156 - val_loss: 122.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 3843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1757 - accuracy: 0.0000e+00 - val_loss: 119.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 3844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2046 - accuracy: 0.0000e+00 - val_loss: 122.7452 - val_accuracy: 0.0000e+00\n",
      "Epoch 3845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1621 - accuracy: 0.0156 - val_loss: 124.6911 - val_accuracy: 0.0000e+00\n",
      "Epoch 3846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1623 - accuracy: 0.0156 - val_loss: 125.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 3847/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3535 - accuracy: 0.0000e+00 - val_loss: 132.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 3848/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.5510 - accuracy: 0.0156 - val_loss: 129.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 3849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1817 - accuracy: 0.0156 - val_loss: 126.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 3850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5274 - accuracy: 0.0000e+00 - val_loss: 125.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 3851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2088 - accuracy: 0.0312 - val_loss: 128.1919 - val_accuracy: 0.0000e+00\n",
      "Epoch 3852/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2657 - accuracy: 0.0312 - val_loss: 132.3464 - val_accuracy: 0.0000e+00\n",
      "Epoch 3853/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 27.3090 - accuracy: 0.0156 - val_loss: 134.5660 - val_accuracy: 0.0588\n",
      "Epoch 3854/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.2812 - accuracy: 0.0000e+00 - val_loss: 131.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9417 - accuracy: 0.0000e+00 - val_loss: 127.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 3856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1638 - accuracy: 0.0156 - val_loss: 125.7386 - val_accuracy: 0.0588\n",
      "Epoch 3857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2514 - accuracy: 0.0000e+00 - val_loss: 127.8120 - val_accuracy: 0.0588\n",
      "Epoch 3858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5016 - accuracy: 0.0000e+00 - val_loss: 129.5303 - val_accuracy: 0.0588\n",
      "Epoch 3859/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3923 - accuracy: 0.0000e+00 - val_loss: 137.0466 - val_accuracy: 0.0000e+00\n",
      "Epoch 3860/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2309 - accuracy: 0.0000e+00 - val_loss: 139.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 3861/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5967 - accuracy: 0.0312 - val_loss: 139.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 3862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3142 - accuracy: 0.0156 - val_loss: 127.8842 - val_accuracy: 0.0588\n",
      "Epoch 3863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.9227 - accuracy: 0.0156 - val_loss: 111.1274 - val_accuracy: 0.0588\n",
      "Epoch 3864/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 36.9487 - accuracy: 0.0000e+00 - val_loss: 107.2343 - val_accuracy: 0.0588\n",
      "Epoch 3865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7982 - accuracy: 0.0000e+00 - val_loss: 113.0953 - val_accuracy: 0.0588\n",
      "Epoch 3866/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 31.8566 - accuracy: 0.0156 - val_loss: 121.4624 - val_accuracy: 0.0588\n",
      "Epoch 3867/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6264 - accuracy: 0.0000e+00 - val_loss: 133.7416 - val_accuracy: 0.0588\n",
      "Epoch 3868/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.9135 - accuracy: 0.0156 - val_loss: 148.9909 - val_accuracy: 0.0000e+00\n",
      "Epoch 3869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3606 - accuracy: 0.0000e+00 - val_loss: 155.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 3870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6119 - accuracy: 0.0156 - val_loss: 148.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 3871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3219 - accuracy: 0.0000e+00 - val_loss: 139.3820 - val_accuracy: 0.0000e+00\n",
      "Epoch 3872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9781 - accuracy: 0.0000e+00 - val_loss: 126.7990 - val_accuracy: 0.0000e+00\n",
      "Epoch 3873/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 31.2950 - accuracy: 0.0000e+00 - val_loss: 121.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 3874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9861 - accuracy: 0.0000e+00 - val_loss: 122.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 3875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2936 - accuracy: 0.0000e+00 - val_loss: 127.3329 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3876/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.8007 - accuracy: 0.0156 - val_loss: 131.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 3877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.3296 - accuracy: 0.0000e+00 - val_loss: 128.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 3878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5315 - accuracy: 0.0000e+00 - val_loss: 126.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 3879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1599 - accuracy: 0.0156 - val_loss: 130.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 3880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8047 - accuracy: 0.0000e+00 - val_loss: 140.2530 - val_accuracy: 0.0000e+00\n",
      "Epoch 3881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0446 - accuracy: 0.0000e+00 - val_loss: 148.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2690 - accuracy: 0.0000e+00 - val_loss: 151.6032 - val_accuracy: 0.0000e+00\n",
      "Epoch 3883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1972 - accuracy: 0.0156 - val_loss: 142.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 3884/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2486 - accuracy: 0.0156 - val_loss: 127.2042 - val_accuracy: 0.0000e+00\n",
      "Epoch 3885/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.5140 - accuracy: 0.0000e+00 - val_loss: 117.1518 - val_accuracy: 0.0000e+00\n",
      "Epoch 3886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5929 - accuracy: 0.0156 - val_loss: 115.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3887/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 27.8050 - accuracy: 0.0000e+00 - val_loss: 125.7615 - val_accuracy: 0.0000e+00\n",
      "Epoch 3888/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 24.9229 - accuracy: 0.0156 - val_loss: 129.2870 - val_accuracy: 0.0000e+00\n",
      "Epoch 3889/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8920 - accuracy: 0.0000e+00 - val_loss: 135.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 3890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4247 - accuracy: 0.0000e+00 - val_loss: 136.7446 - val_accuracy: 0.0000e+00\n",
      "Epoch 3891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4035 - accuracy: 0.0156 - val_loss: 129.5936 - val_accuracy: 0.0588\n",
      "Epoch 3892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3147 - accuracy: 0.0000e+00 - val_loss: 129.7677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7363 - accuracy: 0.0000e+00 - val_loss: 140.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 3894/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3583 - accuracy: 0.0156 - val_loss: 137.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 3895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8703 - accuracy: 0.0000e+00 - val_loss: 133.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 3896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6541 - accuracy: 0.0156 - val_loss: 129.6221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5650 - accuracy: 0.0000e+00 - val_loss: 129.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 3898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7529 - accuracy: 0.0000e+00 - val_loss: 131.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3899/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 36.7047 - accuracy: 0.0156 - val_loss: 131.6177 - val_accuracy: 0.0588\n",
      "Epoch 3900/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 34.8210 - accuracy: 0.0156 - val_loss: 128.7391 - val_accuracy: 0.0588\n",
      "Epoch 3901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7495 - accuracy: 0.0000e+00 - val_loss: 127.4633 - val_accuracy: 0.0588\n",
      "Epoch 3902/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3032 - accuracy: 0.0000e+00 - val_loss: 124.1994 - val_accuracy: 0.0588\n",
      "Epoch 3903/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.4553 - accuracy: 0.0000e+00 - val_loss: 130.2303 - val_accuracy: 0.0588\n",
      "Epoch 3904/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3971 - accuracy: 0.0000e+00 - val_loss: 132.7901 - val_accuracy: 0.0588\n",
      "Epoch 3905/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.9641 - accuracy: 0.0000e+00 - val_loss: 137.4878 - val_accuracy: 0.0588\n",
      "Epoch 3906/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 29.2749 - accuracy: 0.0000e+00 - val_loss: 134.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 3907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4224 - accuracy: 0.0000e+00 - val_loss: 124.7557 - val_accuracy: 0.0000e+00\n",
      "Epoch 3908/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.6854 - accuracy: 0.0000e+00 - val_loss: 119.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 3909/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.6013 - accuracy: 0.0156 - val_loss: 120.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 3910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4917 - accuracy: 0.0000e+00 - val_loss: 127.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3911/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 33.0269 - accuracy: 0.0000e+00 - val_loss: 131.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 3912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5996 - accuracy: 0.0156 - val_loss: 141.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 3913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3557 - accuracy: 0.0156 - val_loss: 135.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 3914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0301 - accuracy: 0.0156 - val_loss: 127.4795 - val_accuracy: 0.0000e+00\n",
      "Epoch 3915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2914 - accuracy: 0.0000e+00 - val_loss: 127.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 3916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1726 - accuracy: 0.0000e+00 - val_loss: 134.3076 - val_accuracy: 0.0000e+00\n",
      "Epoch 3917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1115 - accuracy: 0.0156 - val_loss: 138.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 3918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0379 - accuracy: 0.0156 - val_loss: 134.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 3919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3747 - accuracy: 0.0000e+00 - val_loss: 127.8318 - val_accuracy: 0.0000e+00\n",
      "Epoch 3920/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3412 - accuracy: 0.0000e+00 - val_loss: 124.8296 - val_accuracy: 0.0000e+00\n",
      "Epoch 3921/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3896 - accuracy: 0.0000e+00 - val_loss: 121.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 3922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3945 - accuracy: 0.0156 - val_loss: 120.7194 - val_accuracy: 0.0000e+00\n",
      "Epoch 3923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1659 - accuracy: 0.0156 - val_loss: 128.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 3924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0151 - accuracy: 0.0156 - val_loss: 134.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 3925/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3345 - accuracy: 0.0156 - val_loss: 143.3596 - val_accuracy: 0.0000e+00\n",
      "Epoch 3926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5922 - accuracy: 0.0156 - val_loss: 139.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 3927/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 23.2438 - accuracy: 0.0312 - val_loss: 130.5819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0727 - accuracy: 0.0156 - val_loss: 119.9720 - val_accuracy: 0.0000e+00\n",
      "Epoch 3929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0536 - accuracy: 0.0000e+00 - val_loss: 116.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 3930/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4848 - accuracy: 0.0156 - val_loss: 119.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3931/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.5728 - accuracy: 0.0000e+00 - val_loss: 133.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 3932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5398 - accuracy: 0.0156 - val_loss: 140.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 3933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5685 - accuracy: 0.0156 - val_loss: 143.8178 - val_accuracy: 0.0000e+00\n",
      "Epoch 3934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2220 - accuracy: 0.0000e+00 - val_loss: 142.8742 - val_accuracy: 0.0000e+00\n",
      "Epoch 3935/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 27.6159 - accuracy: 0.0156 - val_loss: 133.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 3936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2733 - accuracy: 0.0000e+00 - val_loss: 127.0813 - val_accuracy: 0.0588\n",
      "Epoch 3937/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6923 - accuracy: 0.0156 - val_loss: 130.5514 - val_accuracy: 0.0000e+00\n",
      "Epoch 3938/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 52.9908 - accuracy: 0.0000e+00 - val_loss: 134.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 3939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5162 - accuracy: 0.0000e+00 - val_loss: 133.0399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0990 - accuracy: 0.0156 - val_loss: 126.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 3941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4121 - accuracy: 0.0156 - val_loss: 124.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 3942/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.9786 - accuracy: 0.0312 - val_loss: 124.6106 - val_accuracy: 0.0000e+00\n",
      "Epoch 3943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8574 - accuracy: 0.0156 - val_loss: 127.7596 - val_accuracy: 0.0000e+00\n",
      "Epoch 3944/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 22.6956 - accuracy: 0.0156 - val_loss: 134.7487 - val_accuracy: 0.0000e+00\n",
      "Epoch 3945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4287 - accuracy: 0.0156 - val_loss: 142.5105 - val_accuracy: 0.0588\n",
      "Epoch 3946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3074 - accuracy: 0.0469 - val_loss: 148.9816 - val_accuracy: 0.0588\n",
      "Epoch 3947/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 38.7044 - accuracy: 0.0000e+00 - val_loss: 150.6023 - val_accuracy: 0.0588\n",
      "Epoch 3948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2987 - accuracy: 0.0156 - val_loss: 135.4866 - val_accuracy: 0.0588\n",
      "Epoch 3949/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6080 - accuracy: 0.0156 - val_loss: 121.5172 - val_accuracy: 0.1176\n",
      "Epoch 3950/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 32.7109 - accuracy: 0.0156 - val_loss: 117.3961 - val_accuracy: 0.1176\n",
      "Epoch 3951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5179 - accuracy: 0.0156 - val_loss: 119.3598 - val_accuracy: 0.0588\n",
      "Epoch 3952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8057 - accuracy: 0.0156 - val_loss: 124.3844 - val_accuracy: 0.0588\n",
      "Epoch 3953/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 25.9623 - accuracy: 0.0000e+00 - val_loss: 123.6912 - val_accuracy: 0.0588\n",
      "Epoch 3954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3450 - accuracy: 0.0156 - val_loss: 122.6670 - val_accuracy: 0.0588\n",
      "Epoch 3955/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 41.9432 - accuracy: 0.0000e+00 - val_loss: 121.4738 - val_accuracy: 0.0588\n",
      "Epoch 3956/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.3702 - accuracy: 0.0156 - val_loss: 124.6300 - val_accuracy: 0.0588\n",
      "Epoch 3957/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7823 - accuracy: 0.0156 - val_loss: 126.1946 - val_accuracy: 0.0588\n",
      "Epoch 3958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6105 - accuracy: 0.0000e+00 - val_loss: 136.7112 - val_accuracy: 0.0588\n",
      "Epoch 3959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2836 - accuracy: 0.0156 - val_loss: 139.0418 - val_accuracy: 0.0588\n",
      "Epoch 3960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6224 - accuracy: 0.0000e+00 - val_loss: 130.4984 - val_accuracy: 0.0588\n",
      "Epoch 3961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6726 - accuracy: 0.0156 - val_loss: 119.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 3962/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2235 - accuracy: 0.0000e+00 - val_loss: 119.7220 - val_accuracy: 0.0000e+00\n",
      "Epoch 3963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7524 - accuracy: 0.0000e+00 - val_loss: 128.0892 - val_accuracy: 0.0000e+00\n",
      "Epoch 3964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2758 - accuracy: 0.0000e+00 - val_loss: 134.1756 - val_accuracy: 0.0000e+00\n",
      "Epoch 3965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9964 - accuracy: 0.0312 - val_loss: 129.7875 - val_accuracy: 0.0000e+00\n",
      "Epoch 3966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2363 - accuracy: 0.0156 - val_loss: 124.2538 - val_accuracy: 0.0588\n",
      "Epoch 3967/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 44.1919 - accuracy: 0.0000e+00 - val_loss: 123.5894 - val_accuracy: 0.0588\n",
      "Epoch 3968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7269 - accuracy: 0.0000e+00 - val_loss: 128.1440 - val_accuracy: 0.0000e+00\n",
      "Epoch 3969/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.9601 - accuracy: 0.0000e+00 - val_loss: 134.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 3970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0230 - accuracy: 0.0156 - val_loss: 130.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 3971/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8386 - accuracy: 0.0000e+00 - val_loss: 113.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 3972/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4739 - accuracy: 0.0312 - val_loss: 105.0081 - val_accuracy: 0.0588\n",
      "Epoch 3973/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3127 - accuracy: 0.0156 - val_loss: 104.9332 - val_accuracy: 0.0588\n",
      "Epoch 3974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1489 - accuracy: 0.0000e+00 - val_loss: 116.2688 - val_accuracy: 0.0588\n",
      "Epoch 3975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6873 - accuracy: 0.0312 - val_loss: 125.2331 - val_accuracy: 0.0588\n",
      "Epoch 3976/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 30.0620 - accuracy: 0.0000e+00 - val_loss: 129.9372 - val_accuracy: 0.0588\n",
      "Epoch 3977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5559 - accuracy: 0.0156 - val_loss: 128.7714 - val_accuracy: 0.0588\n",
      "Epoch 3978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7190 - accuracy: 0.0000e+00 - val_loss: 124.5787 - val_accuracy: 0.1176\n",
      "Epoch 3979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5063 - accuracy: 0.0156 - val_loss: 120.0876 - val_accuracy: 0.1176\n",
      "Epoch 3980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5781 - accuracy: 0.0156 - val_loss: 123.9947 - val_accuracy: 0.1176\n",
      "Epoch 3981/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 30.0894 - accuracy: 0.0156 - val_loss: 135.6472 - val_accuracy: 0.0588\n",
      "Epoch 3982/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 23.6684 - accuracy: 0.0000e+00 - val_loss: 150.8576 - val_accuracy: 0.0588\n",
      "Epoch 3983/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9486 - accuracy: 0.0156 - val_loss: 154.6888 - val_accuracy: 0.0588\n",
      "Epoch 3984/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 35.8280 - accuracy: 0.0156 - val_loss: 132.7230 - val_accuracy: 0.0588\n",
      "Epoch 3985/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0756 - accuracy: 0.0000e+00 - val_loss: 122.2883 - val_accuracy: 0.0588\n",
      "Epoch 3986/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6565 - accuracy: 0.0000e+00 - val_loss: 116.9219 - val_accuracy: 0.0588\n",
      "Epoch 3987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4604 - accuracy: 0.0000e+00 - val_loss: 117.7571 - val_accuracy: 0.1176\n",
      "Epoch 3988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5994 - accuracy: 0.0156 - val_loss: 125.2608 - val_accuracy: 0.0588\n",
      "Epoch 3989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4806 - accuracy: 0.0000e+00 - val_loss: 125.4307 - val_accuracy: 0.1176\n",
      "Epoch 3990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1711 - accuracy: 0.0000e+00 - val_loss: 127.8253 - val_accuracy: 0.1176\n",
      "Epoch 3991/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 39.1965 - accuracy: 0.0000e+00 - val_loss: 127.5874 - val_accuracy: 0.1176\n",
      "Epoch 3992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5513 - accuracy: 0.0000e+00 - val_loss: 131.2761 - val_accuracy: 0.1176\n",
      "Epoch 3993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1306 - accuracy: 0.0156 - val_loss: 138.5721 - val_accuracy: 0.0588\n",
      "Epoch 3994/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.5736 - accuracy: 0.0000e+00 - val_loss: 141.9705 - val_accuracy: 0.0588\n",
      "Epoch 3995/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2074 - accuracy: 0.0156 - val_loss: 136.0161 - val_accuracy: 0.1176\n",
      "Epoch 3996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6473 - accuracy: 0.0156 - val_loss: 129.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3730 - accuracy: 0.0312 - val_loss: 125.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3431 - accuracy: 0.0000e+00 - val_loss: 125.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 3999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4411 - accuracy: 0.0000e+00 - val_loss: 131.9384 - val_accuracy: 0.0000e+00\n",
      "Epoch 4000/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9337 - accuracy: 0.0156 - val_loss: 139.1002 - val_accuracy: 0.0588\n",
      "Epoch 4001/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9285 - accuracy: 0.0156 - val_loss: 138.6139 - val_accuracy: 0.0000e+00\n",
      "Epoch 4002/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0841 - accuracy: 0.0156 - val_loss: 132.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 4003/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 34.5260 - accuracy: 0.0156 - val_loss: 136.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 4004/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.5119 - accuracy: 0.0156 - val_loss: 133.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 4005/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.7891 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 56.3997 - accuracy: 0.0000e+00 - val_loss: 132.2330 - val_accuracy: 0.0000e+00\n",
      "Epoch 4006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5620 - accuracy: 0.0156 - val_loss: 137.8499 - val_accuracy: 0.0000e+00\n",
      "Epoch 4007/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 45.7712 - accuracy: 0.0000e+00 - val_loss: 137.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 4008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4711 - accuracy: 0.0312 - val_loss: 130.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 4009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7871 - accuracy: 0.0156 - val_loss: 123.1560 - val_accuracy: 0.0000e+00\n",
      "Epoch 4010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9821 - accuracy: 0.0000e+00 - val_loss: 126.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 4011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1609 - accuracy: 0.0156 - val_loss: 139.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 4012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3506 - accuracy: 0.0312 - val_loss: 145.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4013/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.7909 - accuracy: 0.0000e+00 - val_loss: 145.5510 - val_accuracy: 0.0000e+00\n",
      "Epoch 4014/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6804 - accuracy: 0.0156 - val_loss: 139.5876 - val_accuracy: 0.0000e+00\n",
      "Epoch 4015/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 28.0572 - accuracy: 0.0000e+00 - val_loss: 132.4734 - val_accuracy: 0.0000e+00\n",
      "Epoch 4016/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3826 - accuracy: 0.0000e+00 - val_loss: 124.9470 - val_accuracy: 0.0588\n",
      "Epoch 4017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.7398 - accuracy: 0.0000e+00 - val_loss: 129.6881 - val_accuracy: 0.0588\n",
      "Epoch 4018/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7252 - accuracy: 0.0312 - val_loss: 131.8136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4019/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.0308 - accuracy: 0.0312 - val_loss: 138.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 4020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2457 - accuracy: 0.0156 - val_loss: 130.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 4021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6219 - accuracy: 0.0000e+00 - val_loss: 129.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 4022/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 23.6804 - accuracy: 0.0156 - val_loss: 124.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 4023/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 38.9349 - accuracy: 0.0156 - val_loss: 115.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 4024/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 26.1951 - accuracy: 0.0312 - val_loss: 110.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4025/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 38.4433 - accuracy: 0.0156 - val_loss: 114.4529 - val_accuracy: 0.0000e+00\n",
      "Epoch 4026/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 29.0786 - accuracy: 0.0156 - val_loss: 122.8676 - val_accuracy: 0.0000e+00\n",
      "Epoch 4027/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.6130 - accuracy: 0.0000e+00 - val_loss: 122.9382 - val_accuracy: 0.0000e+00\n",
      "Epoch 4028/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.9370 - accuracy: 0.0000e+00 - val_loss: 121.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 4029/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 48.8210 - accuracy: 0.0156 - val_loss: 129.0756 - val_accuracy: 0.0588\n",
      "Epoch 4030/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 29.0341 - accuracy: 0.0000e+00 - val_loss: 145.6063 - val_accuracy: 0.0588\n",
      "Epoch 4031/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 44.3588 - accuracy: 0.0156 - val_loss: 153.5206 - val_accuracy: 0.0588\n",
      "Epoch 4032/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.3366 - accuracy: 0.0000e+00 - val_loss: 140.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4033/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 42.4659 - accuracy: 0.0156 - val_loss: 120.4555 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4034/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.7158 - accuracy: 0.0000e+00 - val_loss: 108.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 4035/10000\n",
      "64/64 [==============================] - 0s 208us/step - loss: 38.6047 - accuracy: 0.0000e+00 - val_loss: 108.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4036/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 42.9014 - accuracy: 0.0000e+00 - val_loss: 130.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 4037/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 35.0122 - accuracy: 0.0000e+00 - val_loss: 148.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 4038/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.9299 - accuracy: 0.0000e+00 - val_loss: 145.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 4039/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.0876 - accuracy: 0.0312 - val_loss: 135.4015 - val_accuracy: 0.0000e+00\n",
      "Epoch 4040/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.9494 - accuracy: 0.0000e+00 - val_loss: 129.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 4041/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 42.5257 - accuracy: 0.0000e+00 - val_loss: 123.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 4042/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 33.8951 - accuracy: 0.0000e+00 - val_loss: 128.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 4043/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.5758 - accuracy: 0.0156 - val_loss: 129.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 4044/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.2602 - accuracy: 0.0000e+00 - val_loss: 130.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 4045/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.2805 - accuracy: 0.0469 - val_loss: 127.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 4046/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.7707 - accuracy: 0.0156 - val_loss: 131.2127 - val_accuracy: 0.0000e+00\n",
      "Epoch 4047/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 32.8113 - accuracy: 0.0156 - val_loss: 129.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 4048/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 32.9193 - accuracy: 0.0156 - val_loss: 126.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 4049/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.7941 - accuracy: 0.0156 - val_loss: 127.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 4050/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.2561 - accuracy: 0.0000e+00 - val_loss: 132.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 4051/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.4527 - accuracy: 0.0312 - val_loss: 132.5596 - val_accuracy: 0.0000e+00\n",
      "Epoch 4052/10000\n",
      "64/64 [==============================] - 0s 169us/step - loss: 36.6215 - accuracy: 0.0312 - val_loss: 132.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 4053/10000\n",
      "64/64 [==============================] - 0s 32us/step - loss: 33.4010 - accuracy: 0.0000e+00 - val_loss: 133.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 4054/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 24.7768 - accuracy: 0.0000e+00 - val_loss: 132.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4055/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.4176 - accuracy: 0.0469 - val_loss: 136.7145 - val_accuracy: 0.0000e+00\n",
      "Epoch 4056/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 38.7741 - accuracy: 0.0156 - val_loss: 143.3221 - val_accuracy: 0.0000e+00\n",
      "Epoch 4057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4943 - accuracy: 0.0156 - val_loss: 143.5260 - val_accuracy: 0.0588\n",
      "Epoch 4058/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 46.3690 - accuracy: 0.0000e+00 - val_loss: 132.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 4059/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.6741 - accuracy: 0.0156 - val_loss: 124.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 4060/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 40.0709 - accuracy: 0.0000e+00 - val_loss: 120.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 4061/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 32.8215 - accuracy: 0.0000e+00 - val_loss: 126.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 4062/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 29.3521 - accuracy: 0.0156 - val_loss: 132.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 4063/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 36.1368 - accuracy: 0.0000e+00 - val_loss: 137.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 4064/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.8226 - accuracy: 0.0312 - val_loss: 136.7204 - val_accuracy: 0.0000e+00\n",
      "Epoch 4065/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 23.1191 - accuracy: 0.0000e+00 - val_loss: 137.7907 - val_accuracy: 0.0588\n",
      "Epoch 4066/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.1088 - accuracy: 0.0156 - val_loss: 134.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 4067/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.4665 - accuracy: 0.0000e+00 - val_loss: 127.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 4068/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 39.0031 - accuracy: 0.0000e+00 - val_loss: 125.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 4069/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 21.9249 - accuracy: 0.0000e+00 - val_loss: 123.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 4070/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 38.1790 - accuracy: 0.0156 - val_loss: 125.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 4071/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 39.1918 - accuracy: 0.0000e+00 - val_loss: 128.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 4072/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1005 - accuracy: 0.0469 - val_loss: 134.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 4073/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.8554 - accuracy: 0.0000e+00 - val_loss: 136.5602 - val_accuracy: 0.0000e+00\n",
      "Epoch 4074/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 22.7954 - accuracy: 0.0000e+00 - val_loss: 140.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4075/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.3658 - accuracy: 0.0000e+0 - 0s 0us/step - loss: 32.7789 - accuracy: 0.0000e+00 - val_loss: 141.8250 - val_accuracy: 0.0000e+00\n",
      "Epoch 4076/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.0537 - accuracy: 0.0156 - val_loss: 139.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4077/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.7633 - accuracy: 0.0000e+00 - val_loss: 139.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 4078/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 35.4562 - accuracy: 0.0000e+00 - val_loss: 145.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 4079/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 34.7304 - accuracy: 0.0312 - val_loss: 147.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 4080/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 27.3180 - accuracy: 0.0156 - val_loss: 134.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 4081/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 34.9185 - accuracy: 0.0312 - val_loss: 128.1631 - val_accuracy: 0.0588\n",
      "Epoch 4082/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 55.8509 - accuracy: 0.0156 - val_loss: 128.3521 - val_accuracy: 0.0000e+00\n",
      "Epoch 4083/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 21.3705 - accuracy: 0.0000e+00 - val_loss: 131.7111 - val_accuracy: 0.1176\n",
      "Epoch 4084/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 37.9524 - accuracy: 0.0000e+00 - val_loss: 133.7082 - val_accuracy: 0.1176\n",
      "Epoch 4085/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 31.3121 - accuracy: 0.0000e+00 - val_loss: 132.9488 - val_accuracy: 0.0588\n",
      "Epoch 4086/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 40.5742 - accuracy: 0.0156 - val_loss: 132.7668 - val_accuracy: 0.1176\n",
      "Epoch 4087/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.5726 - accuracy: 0.0156 - val_loss: 133.9728 - val_accuracy: 0.0588\n",
      "Epoch 4088/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.1179 - accuracy: 0.0156 - val_loss: 128.7126 - val_accuracy: 0.0588\n",
      "Epoch 4089/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 32.2683 - accuracy: 0.0156 - val_loss: 132.3616 - val_accuracy: 0.1176\n",
      "Epoch 4090/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 25.1904 - accuracy: 0.0000e+00 - val_loss: 138.5789 - val_accuracy: 0.0588\n",
      "Epoch 4091/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 38.5431 - accuracy: 0.0156 - val_loss: 140.0363 - val_accuracy: 0.0588\n",
      "Epoch 4092/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.9967 - accuracy: 0.0156 - val_loss: 138.1344 - val_accuracy: 0.0588\n",
      "Epoch 4093/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.7403 - accuracy: 0.0000e+00 - val_loss: 135.1857 - val_accuracy: 0.0588\n",
      "Epoch 4094/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.8749 - accuracy: 0.0156 - val_loss: 137.1438 - val_accuracy: 0.1176\n",
      "Epoch 4095/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 35.3643 - accuracy: 0.0000e+00 - val_loss: 140.7285 - val_accuracy: 0.0588\n",
      "Epoch 4096/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 27.6126 - accuracy: 0.0312 - val_loss: 145.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 4097/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.3458 - accuracy: 0.0000e+00 - val_loss: 136.7436 - val_accuracy: 0.0588\n",
      "Epoch 4098/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.6159 - accuracy: 0.0000e+00 - val_loss: 129.0040 - val_accuracy: 0.0588\n",
      "Epoch 4099/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.0720 - accuracy: 0.0000e+00 - val_loss: 127.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4100/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 43.5325 - accuracy: 0.0000e+00 - val_loss: 133.0914 - val_accuracy: 0.0000e+00\n",
      "Epoch 4101/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.4549 - accuracy: 0.0000e+00 - val_loss: 145.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 4102/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 30.2116 - accuracy: 0.0000e+00 - val_loss: 151.3409 - val_accuracy: 0.0000e+00\n",
      "Epoch 4103/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 32.9472 - accuracy: 0.0156 - val_loss: 143.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 4104/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 24.1518 - accuracy: 0.0000e+00 - val_loss: 138.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 4105/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 40.4763 - accuracy: 0.0156 - val_loss: 145.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 4106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8345 - accuracy: 0.0156 - val_loss: 150.5189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9392 - accuracy: 0.0156 - val_loss: 142.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4108/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.9359 - accuracy: 0.0000e+00 - val_loss: 132.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 4109/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.7877 - accuracy: 0.0000e+00 - val_loss: 119.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 4110/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 31.3146 - accuracy: 0.0156 - val_loss: 112.6022 - val_accuracy: 0.0588\n",
      "Epoch 4111/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 31.6889 - accuracy: 0.0156 - val_loss: 122.0264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4112/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 29.6022 - accuracy: 0.0156 - val_loss: 144.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 4113/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.1243 - accuracy: 0.0156 - val_loss: 155.2802 - val_accuracy: 0.0000e+00\n",
      "Epoch 4114/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.5028 - accuracy: 0.0000e+00 - val_loss: 142.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 4115/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 44.8839 - accuracy: 0.0156 - val_loss: 139.9929 - val_accuracy: 0.0000e+00\n",
      "Epoch 4116/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 33.5489 - accuracy: 0.0000e+00 - val_loss: 140.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 4117/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 34.0728 - accuracy: 0.0156 - val_loss: 140.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 4118/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.8061 - accuracy: 0.0000e+00 - val_loss: 136.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 4119/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.7450 - accuracy: 0.0000e+00 - val_loss: 134.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 4120/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 42.5710 - accuracy: 0.0000e+00 - val_loss: 129.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 4121/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 36.3654 - accuracy: 0.0312 - val_loss: 131.8797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4122/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 31.0835 - accuracy: 0.0000e+00 - val_loss: 135.4702 - val_accuracy: 0.0588\n",
      "Epoch 4123/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.9173 - accuracy: 0.0156 - val_loss: 136.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 4124/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.5665 - accuracy: 0.0000e+00 - val_loss: 136.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 4125/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1379 - accuracy: 0.0000e+00 - val_loss: 139.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 4126/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 32.0938 - accuracy: 0.0000e+00 - val_loss: 142.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 4127/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 38.7242 - accuracy: 0.0000e+00 - val_loss: 147.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 4128/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 24.3040 - accuracy: 0.0156 - val_loss: 144.2264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4129/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.7560 - accuracy: 0.0156 - val_loss: 134.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4130/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.6078 - accuracy: 0.0000e+00 - val_loss: 130.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 4131/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.3298 - accuracy: 0.0156 - val_loss: 133.6915 - val_accuracy: 0.0000e+00\n",
      "Epoch 4132/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.5264 - accuracy: 0.0156 - val_loss: 136.3289 - val_accuracy: 0.0000e+00\n",
      "Epoch 4133/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 29.9887 - accuracy: 0.0156 - val_loss: 133.4579 - val_accuracy: 0.0000e+00\n",
      "Epoch 4134/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.1092 - accuracy: 0.0156 - val_loss: 132.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 4135/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.5267 - accuracy: 0.0000e+00 - val_loss: 129.9400 - val_accuracy: 0.0000e+00\n",
      "Epoch 4136/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.5054 - accuracy: 0.0000e+00 - val_loss: 128.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4137/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.5296 - accuracy: 0.0312 - val_loss: 132.5145 - val_accuracy: 0.0000e+00\n",
      "Epoch 4138/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 22.5760 - accuracy: 0.0000e+00 - val_loss: 137.6239 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4139/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 22.9322 - accuracy: 0.0312 - val_loss: 138.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 4140/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 28.5749 - accuracy: 0.0156 - val_loss: 133.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 4141/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9793 - accuracy: 0.0156 - val_loss: 126.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 4142/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 44.3482 - accuracy: 0.0156 - val_loss: 131.4672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4364 - accuracy: 0.0156 - val_loss: 137.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 4144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2100 - accuracy: 0.0000e+00 - val_loss: 137.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 4145/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 24.5956 - accuracy: 0.0312 - val_loss: 138.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 4146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0592 - accuracy: 0.0000e+00 - val_loss: 136.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 4147/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.1817 - accuracy: 0.0156 - val_loss: 132.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 4148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7265 - accuracy: 0.0156 - val_loss: 135.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 4149/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4343 - accuracy: 0.0156 - val_loss: 142.9446 - val_accuracy: 0.0000e+00\n",
      "Epoch 4150/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6366 - accuracy: 0.0312 - val_loss: 151.3855 - val_accuracy: 0.0000e+00\n",
      "Epoch 4151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0273 - accuracy: 0.0000e+00 - val_loss: 141.9490 - val_accuracy: 0.0000e+00\n",
      "Epoch 4152/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8040 - accuracy: 0.0000e+00 - val_loss: 137.1702 - val_accuracy: 0.0588\n",
      "Epoch 4153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0612 - accuracy: 0.0156 - val_loss: 128.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.0972 - accuracy: 0.0156 - val_loss: 132.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 4155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4851 - accuracy: 0.0156 - val_loss: 134.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 4156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0827 - accuracy: 0.0000e+00 - val_loss: 136.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 4157/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 35.0677 - accuracy: 0.0000e+00 - val_loss: 141.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 4158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1130 - accuracy: 0.0000e+00 - val_loss: 145.8301 - val_accuracy: 0.0000e+00\n",
      "Epoch 4159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3393 - accuracy: 0.0000e+00 - val_loss: 138.9408 - val_accuracy: 0.0000e+00\n",
      "Epoch 4160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0531 - accuracy: 0.0312 - val_loss: 129.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7411 - accuracy: 0.0000e+00 - val_loss: 127.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 4162/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5911 - accuracy: 0.0000e+00 - val_loss: 144.4805 - val_accuracy: 0.0000e+00\n",
      "Epoch 4163/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4692 - accuracy: 0.0000e+00 - val_loss: 158.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 4164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.7316 - accuracy: 0.0156 - val_loss: 156.7151 - val_accuracy: 0.0588\n",
      "Epoch 4165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5113 - accuracy: 0.0000e+00 - val_loss: 141.5894 - val_accuracy: 0.0588\n",
      "Epoch 4166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5046 - accuracy: 0.0000e+00 - val_loss: 130.5770 - val_accuracy: 0.0588\n",
      "Epoch 4167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6498 - accuracy: 0.0000e+00 - val_loss: 128.5023 - val_accuracy: 0.1176\n",
      "Epoch 4168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5551 - accuracy: 0.0156 - val_loss: 134.9267 - val_accuracy: 0.0588\n",
      "Epoch 4169/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 32.1312 - accuracy: 0.0156 - val_loss: 141.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 4170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2622 - accuracy: 0.0156 - val_loss: 142.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 4171/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0628 - accuracy: 0.0000e+00 - val_loss: 139.9931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4172/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7432 - accuracy: 0.0000e+00 - val_loss: 139.6838 - val_accuracy: 0.0588\n",
      "Epoch 4173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.1602 - accuracy: 0.0000e+00 - val_loss: 147.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 4174/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.1148 - accuracy: 0.0000e+00 - val_loss: 149.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 4175/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 35.5757 - accuracy: 0.0156 - val_loss: 146.2553 - val_accuracy: 0.0000e+00\n",
      "Epoch 4176/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.9050 - accuracy: 0.0156 - val_loss: 137.8851 - val_accuracy: 0.0000e+00\n",
      "Epoch 4177/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 44.6190 - accuracy: 0.0156 - val_loss: 133.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 4178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6768 - accuracy: 0.0312 - val_loss: 128.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 4179/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 38.9316 - accuracy: 0.0000e+00 - val_loss: 125.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 4180/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.5734 - accuracy: 0.0156 - val_loss: 133.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 4181/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3036 - accuracy: 0.0156 - val_loss: 140.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 4182/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0150 - accuracy: 0.0000e+00 - val_loss: 140.4079 - val_accuracy: 0.0000e+00\n",
      "Epoch 4183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8919 - accuracy: 0.0156 - val_loss: 132.3864 - val_accuracy: 0.0000e+00\n",
      "Epoch 4184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4683 - accuracy: 0.0156 - val_loss: 129.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 4185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7481 - accuracy: 0.0000e+00 - val_loss: 133.4806 - val_accuracy: 0.0588\n",
      "Epoch 4186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4898 - accuracy: 0.0000e+00 - val_loss: 143.2058 - val_accuracy: 0.0000e+00\n",
      "Epoch 4187/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 43.8883 - accuracy: 0.0000e+00 - val_loss: 156.0111 - val_accuracy: 0.0588\n",
      "Epoch 4188/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 25.1675 - accuracy: 0.0000e+00 - val_loss: 159.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4189/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.2325 - accuracy: 0.0312 - val_loss: 152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2022 - accuracy: 0.0156 - val_loss: 143.0378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3187 - accuracy: 0.0000e+00 - val_loss: 139.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 4192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6181 - accuracy: 0.0000e+00 - val_loss: 141.5652 - val_accuracy: 0.0000e+00\n",
      "Epoch 4193/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 37.9335 - accuracy: 0.0156 - val_loss: 142.2904 - val_accuracy: 0.0000e+00\n",
      "Epoch 4194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0808 - accuracy: 0.0000e+00 - val_loss: 142.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 4195/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 33.3873 - accuracy: 0.0000e+00 - val_loss: 130.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3804 - accuracy: 0.0156 - val_loss: 129.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 4197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4320 - accuracy: 0.0156 - val_loss: 136.4432 - val_accuracy: 0.0588\n",
      "Epoch 4198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2332 - accuracy: 0.0000e+00 - val_loss: 150.5208 - val_accuracy: 0.0000e+00\n",
      "Epoch 4199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3774 - accuracy: 0.0156 - val_loss: 160.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 4200/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 35.4488 - accuracy: 0.0000e+00 - val_loss: 148.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 4201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8143 - accuracy: 0.0000e+00 - val_loss: 136.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 4202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1111 - accuracy: 0.0156 - val_loss: 127.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 4203/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 44.2214 - accuracy: 0.0156 - val_loss: 130.9908 - val_accuracy: 0.0588\n",
      "Epoch 4204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7773 - accuracy: 0.0000e+00 - val_loss: 135.9466 - val_accuracy: 0.0588\n",
      "Epoch 4205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2539 - accuracy: 0.0156 - val_loss: 142.3152 - val_accuracy: 0.0588\n",
      "Epoch 4206/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 42.6465 - accuracy: 0.0312 - val_loss: 135.7182 - val_accuracy: 0.0588\n",
      "Epoch 4207/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.0999 - accuracy: 0.0000e+00 - val_loss: 129.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 4208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1215 - accuracy: 0.0312 - val_loss: 125.2397 - val_accuracy: 0.0000e+00\n",
      "Epoch 4209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3008 - accuracy: 0.0000e+00 - val_loss: 135.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 4210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8731 - accuracy: 0.0156 - val_loss: 146.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 4211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8302 - accuracy: 0.0000e+00 - val_loss: 150.1558 - val_accuracy: 0.0588\n",
      "Epoch 4212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8373 - accuracy: 0.0312 - val_loss: 149.1588 - val_accuracy: 0.0588\n",
      "Epoch 4213/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.6851 - accuracy: 0.0000e+00 - val_loss: 148.0128 - val_accuracy: 0.0588\n",
      "Epoch 4214/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5009 - accuracy: 0.0000e+00 - val_loss: 139.9625 - val_accuracy: 0.0000e+00\n",
      "Epoch 4215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0657 - accuracy: 0.0000e+00 - val_loss: 125.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 4216/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 40.7726 - accuracy: 0.0000e+00 - val_loss: 120.5949 - val_accuracy: 0.0000e+00\n",
      "Epoch 4217/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.2604 - accuracy: 0.0000e+00 - val_loss: 117.5786 - val_accuracy: 0.0588\n",
      "Epoch 4218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8503 - accuracy: 0.0000e+00 - val_loss: 127.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6425 - accuracy: 0.0000e+00 - val_loss: 135.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 4220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.3687 - accuracy: 0.0000e+00 - val_loss: 136.8714 - val_accuracy: 0.0000e+00\n",
      "Epoch 4221/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1541 - accuracy: 0.0000e+00 - val_loss: 131.4472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8301 - accuracy: 0.0156 - val_loss: 122.3615 - val_accuracy: 0.0000e+00\n",
      "Epoch 4223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9723 - accuracy: 0.0156 - val_loss: 117.4040 - val_accuracy: 0.0000e+00\n",
      "Epoch 4224/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.8129 - accuracy: 0.0000e+00 - val_loss: 116.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 4225/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.9946 - accuracy: 0.0000e+00 - val_loss: 123.0893 - val_accuracy: 0.0000e+00\n",
      "Epoch 4226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4927 - accuracy: 0.0000e+00 - val_loss: 133.6919 - val_accuracy: 0.0000e+00\n",
      "Epoch 4227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2880 - accuracy: 0.0156 - val_loss: 136.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 4228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8733 - accuracy: 0.0156 - val_loss: 128.2234 - val_accuracy: 0.0588\n",
      "Epoch 4229/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5286 - accuracy: 0.0469 - val_loss: 129.2386 - val_accuracy: 0.0000e+00\n",
      "Epoch 4230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8353 - accuracy: 0.0000e+00 - val_loss: 130.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 4231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1621 - accuracy: 0.0000e+00 - val_loss: 136.1225 - val_accuracy: 0.0588\n",
      "Epoch 4232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9202 - accuracy: 0.0000e+00 - val_loss: 137.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 4233/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 35.0430 - accuracy: 0.0156 - val_loss: 135.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 4234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3933 - accuracy: 0.0000e+00 - val_loss: 123.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 4235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6452 - accuracy: 0.0000e+00 - val_loss: 118.9045 - val_accuracy: 0.0588\n",
      "Epoch 4236/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.3902 - accuracy: 0.0156 - val_loss: 116.2988 - val_accuracy: 0.0000e+00\n",
      "Epoch 4237/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6920 - accuracy: 0.0000e+00 - val_loss: 120.1346 - val_accuracy: 0.0588\n",
      "Epoch 4238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5372 - accuracy: 0.0156 - val_loss: 133.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 4239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4958 - accuracy: 0.0000e+00 - val_loss: 149.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 4240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8877 - accuracy: 0.0000e+00 - val_loss: 151.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 4241/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0703 - accuracy: 0.0000e+00 - val_loss: 155.6190 - val_accuracy: 0.0588\n",
      "Epoch 4242/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 35.8455 - accuracy: 0.0000e+00 - val_loss: 143.8988 - val_accuracy: 0.1176\n",
      "Epoch 4243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 37.7248 - accuracy: 0.0000e+00 - val_loss: 131.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 4244/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 39.1343 - accuracy: 0.0000e+00 - val_loss: 120.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0125 - accuracy: 0.0312 - val_loss: 119.0065 - val_accuracy: 0.0588\n",
      "Epoch 4246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2743 - accuracy: 0.0000e+00 - val_loss: 122.2552 - val_accuracy: 0.0588\n",
      "Epoch 4247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9464 - accuracy: 0.0000e+00 - val_loss: 134.1994 - val_accuracy: 0.0588\n",
      "Epoch 4248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2635 - accuracy: 0.0000e+00 - val_loss: 146.5063 - val_accuracy: 0.0588\n",
      "Epoch 4249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6663 - accuracy: 0.0000e+00 - val_loss: 135.6739 - val_accuracy: 0.0588\n",
      "Epoch 4250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6574 - accuracy: 0.0000e+00 - val_loss: 126.1804 - val_accuracy: 0.0588\n",
      "Epoch 4251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4722 - accuracy: 0.0156 - val_loss: 127.6828 - val_accuracy: 0.0588\n",
      "Epoch 4252/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 32.1960 - accuracy: 0.0000e+00 - val_loss: 128.1935 - val_accuracy: 0.0588\n",
      "Epoch 4253/10000\n",
      "64/64 [==============================] - 0s 189us/step - loss: 44.1853 - accuracy: 0.0000e+00 - val_loss: 129.4035 - val_accuracy: 0.1176\n",
      "Epoch 4254/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.5239 - accuracy: 0.0000e+00 - val_loss: 135.2065 - val_accuracy: 0.0588\n",
      "Epoch 4255/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 31.4995 - accuracy: 0.0000e+00 - val_loss: 138.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 4256/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 36.3288 - accuracy: 0.0156 - val_loss: 136.3422 - val_accuracy: 0.0000e+00\n",
      "Epoch 4257/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 35.7547 - accuracy: 0.0000e+00 - val_loss: 136.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 4258/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 25.2721 - accuracy: 0.0156 - val_loss: 138.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 4259/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.8118 - accuracy: 0.0000e+00 - val_loss: 135.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 4260/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.6772 - accuracy: 0.0156 - val_loss: 133.2764 - val_accuracy: 0.0000e+00\n",
      "Epoch 4261/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 50.1474 - accuracy: 0.0156 - val_loss: 140.9239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4262/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.4096 - accuracy: 0.0312 - val_loss: 147.8781 - val_accuracy: 0.0000e+00\n",
      "Epoch 4263/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 27.5289 - accuracy: 0.0000e+00 - val_loss: 145.3912 - val_accuracy: 0.0000e+00\n",
      "Epoch 4264/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 36.5986 - accuracy: 0.0312 - val_loss: 148.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4265/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 43.4175 - accuracy: 0.0000e+00 - val_loss: 150.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 4266/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 32.4229 - accuracy: 0.0156 - val_loss: 146.3805 - val_accuracy: 0.0000e+00\n",
      "Epoch 4267/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 36.7071 - accuracy: 0.0000e+00 - val_loss: 139.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 4268/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.0183 - accuracy: 0.0156 - val_loss: 132.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4269/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.9600 - accuracy: 0.0156 - val_loss: 132.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 4270/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 29.0002 - accuracy: 0.0156 - val_loss: 138.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 4271/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.6347 - accuracy: 0.0000e+00 - val_loss: 147.5728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4272/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 31.7958 - accuracy: 0.0000e+00 - val_loss: 143.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 4273/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 23.6584 - accuracy: 0.0000e+00 - val_loss: 141.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 4274/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 34.1590 - accuracy: 0.0156 - val_loss: 144.2152 - val_accuracy: 0.0588\n",
      "Epoch 4275/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 29.6399 - accuracy: 0.0000e+00 - val_loss: 141.6906 - val_accuracy: 0.0588\n",
      "Epoch 4276/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 29.0195 - accuracy: 0.0000e+00 - val_loss: 137.0780 - val_accuracy: 0.0588\n",
      "Epoch 4277/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 35.6975 - accuracy: 0.0000e+00 - val_loss: 134.7287 - val_accuracy: 0.1176\n",
      "Epoch 4278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8007 - accuracy: 0.0000e+00 - val_loss: 127.2420 - val_accuracy: 0.0588\n",
      "Epoch 4279/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.3275 - accuracy: 0.0000e+00 - val_loss: 122.4088 - val_accuracy: 0.0588\n",
      "Epoch 4280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7285 - accuracy: 0.0000e+00 - val_loss: 122.2051 - val_accuracy: 0.0000e+00\n",
      "Epoch 4281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9071 - accuracy: 0.0156 - val_loss: 126.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 4282/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.1988 - accuracy: 0.0156 - val_loss: 125.9612 - val_accuracy: 0.0000e+00\n",
      "Epoch 4283/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 32.1169 - accuracy: 0.0000e+00 - val_loss: 122.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 4284/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 35.0245 - accuracy: 0.0156 - val_loss: 120.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4285/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 39.2008 - accuracy: 0.0000e+00 - val_loss: 123.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4286/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 25.4999 - accuracy: 0.0000e+00 - val_loss: 124.9569 - val_accuracy: 0.0588\n",
      "Epoch 4287/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 30.6294 - accuracy: 0.0156 - val_loss: 124.7338 - val_accuracy: 0.0588\n",
      "Epoch 4288/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 31.7635 - accuracy: 0.0000e+00 - val_loss: 126.9842 - val_accuracy: 0.0000e+00\n",
      "Epoch 4289/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.8624 - accuracy: 0.0000e+00 - val_loss: 132.7610 - val_accuracy: 0.0000e+00\n",
      "Epoch 4290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5613 - accuracy: 0.0000e+00 - val_loss: 133.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 4291/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.0871 - accuracy: 0.0000e+00 - val_loss: 124.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8652 - accuracy: 0.0156 - val_loss: 124.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 4293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.4533 - accuracy: 0.0156 - val_loss: 135.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 4294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3176 - accuracy: 0.0000e+00 - val_loss: 146.8107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.0230 - accuracy: 0.0156 - val_loss: 151.0629 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0228 - accuracy: 0.0156 - val_loss: 142.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 4297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7244 - accuracy: 0.0000e+00 - val_loss: 126.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 4298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8988 - accuracy: 0.0000e+00 - val_loss: 121.1810 - val_accuracy: 0.0000e+00\n",
      "Epoch 4299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7465 - accuracy: 0.0000e+00 - val_loss: 127.8890 - val_accuracy: 0.0000e+00\n",
      "Epoch 4300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0358 - accuracy: 0.0000e+00 - val_loss: 137.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6077 - accuracy: 0.0156 - val_loss: 134.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 4302/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 38.4957 - accuracy: 0.0000e+00 - val_loss: 131.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 4303/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.1992 - accuracy: 0.0000e+00 - val_loss: 130.5094 - val_accuracy: 0.0000e+00\n",
      "Epoch 4304/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 36.5188 - accuracy: 0.0000e+00 - val_loss: 129.9559 - val_accuracy: 0.0000e+00\n",
      "Epoch 4305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8728 - accuracy: 0.0156 - val_loss: 126.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 4306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8020 - accuracy: 0.0000e+00 - val_loss: 119.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 4307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6524 - accuracy: 0.0312 - val_loss: 122.9098 - val_accuracy: 0.0000e+00\n",
      "Epoch 4308/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.9539 - accuracy: 0.0000e+00 - val_loss: 123.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 4309/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.0332 - accuracy: 0.0000e+00 - val_loss: 126.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 4310/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.8458 - accuracy: 0.0000e+00 - val_loss: 131.9045 - val_accuracy: 0.0000e+00\n",
      "Epoch 4311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8384 - accuracy: 0.0156 - val_loss: 131.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 4312/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.8087 - accuracy: 0.0156 - val_loss: 135.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4313/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 29.9726 - accuracy: 0.0156 - val_loss: 132.9745 - val_accuracy: 0.0000e+00\n",
      "Epoch 4314/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.4319 - accuracy: 0.0000e+00 - val_loss: 130.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 4315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9891 - accuracy: 0.0000e+00 - val_loss: 126.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 4316/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2290 - accuracy: 0.0156 - val_loss: 127.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 4317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6571 - accuracy: 0.0000e+00 - val_loss: 133.3152 - val_accuracy: 0.0000e+00\n",
      "Epoch 4318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1881 - accuracy: 0.0000e+00 - val_loss: 144.3800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1196 - accuracy: 0.0000e+00 - val_loss: 146.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 4320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1793 - accuracy: 0.0000e+00 - val_loss: 139.3699 - val_accuracy: 0.0000e+00\n",
      "Epoch 4321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4082 - accuracy: 0.0156 - val_loss: 128.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4322/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 32.9125 - accuracy: 0.0000e+00 - val_loss: 121.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4323/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.6613 - accuracy: 0.0312 - val_loss: 129.1442 - val_accuracy: 0.0588\n",
      "Epoch 4324/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7818 - accuracy: 0.0000e+00 - val_loss: 138.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 4325/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.7712 - accuracy: 0.0312 - val_loss: 138.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 4326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4958 - accuracy: 0.0000e+00 - val_loss: 133.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 4327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0380 - accuracy: 0.0000e+00 - val_loss: 137.5724 - val_accuracy: 0.0588\n",
      "Epoch 4328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3119 - accuracy: 0.0000e+00 - val_loss: 131.7231 - val_accuracy: 0.0588\n",
      "Epoch 4329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1448 - accuracy: 0.0000e+00 - val_loss: 115.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 4330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4172 - accuracy: 0.0156 - val_loss: 108.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 4331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9863 - accuracy: 0.0000e+00 - val_loss: 108.5711 - val_accuracy: 0.0000e+00\n",
      "Epoch 4332/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 38.9634 - accuracy: 0.0156 - val_loss: 114.5486 - val_accuracy: 0.0000e+00\n",
      "Epoch 4333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7763 - accuracy: 0.0000e+00 - val_loss: 122.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2440 - accuracy: 0.0156 - val_loss: 126.4509 - val_accuracy: 0.0000e+00\n",
      "Epoch 4335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4998 - accuracy: 0.0156 - val_loss: 125.6645 - val_accuracy: 0.0000e+00\n",
      "Epoch 4336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3632 - accuracy: 0.0156 - val_loss: 125.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 4337/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6317 - accuracy: 0.0000e+00 - val_loss: 122.8102 - val_accuracy: 0.0000e+00\n",
      "Epoch 4338/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3091 - accuracy: 0.0312 - val_loss: 122.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 4339/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 34.1457 - accuracy: 0.0156 - val_loss: 128.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4340/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 35.3817 - accuracy: 0.0156 - val_loss: 123.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 4341/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.8711 - accuracy: 0.0312 - val_loss: 114.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 4342/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 31.3734 - accuracy: 0.0156 - val_loss: 110.7984 - val_accuracy: 0.0000e+00\n",
      "Epoch 4343/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 27.0952 - accuracy: 0.0312 - val_loss: 114.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 4344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5171 - accuracy: 0.0156 - val_loss: 117.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 4345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2602 - accuracy: 0.0156 - val_loss: 118.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 4346/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.8524 - accuracy: 0.0312 - val_loss: 120.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 4347/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8501 - accuracy: 0.0000e+00 - val_loss: 124.1229 - val_accuracy: 0.0000e+00\n",
      "Epoch 4348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8604 - accuracy: 0.0000e+00 - val_loss: 131.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 4349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2253 - accuracy: 0.0156 - val_loss: 128.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 4350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1856 - accuracy: 0.0000e+00 - val_loss: 121.8873 - val_accuracy: 0.0000e+00\n",
      "Epoch 4351/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.8818 - accuracy: 0.0469 - val_loss: 118.5987 - val_accuracy: 0.0000e+00\n",
      "Epoch 4352/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.7702 - accuracy: 0.0000e+00 - val_loss: 117.6598 - val_accuracy: 0.0000e+00\n",
      "Epoch 4353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6454 - accuracy: 0.0000e+00 - val_loss: 117.1853 - val_accuracy: 0.0000e+00\n",
      "Epoch 4354/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 34.0775 - accuracy: 0.0156 - val_loss: 126.2338 - val_accuracy: 0.0000e+00\n",
      "Epoch 4355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0509 - accuracy: 0.0000e+00 - val_loss: 127.0386 - val_accuracy: 0.0588\n",
      "Epoch 4356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6786 - accuracy: 0.0000e+00 - val_loss: 132.3024 - val_accuracy: 0.0588\n",
      "Epoch 4357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3331 - accuracy: 0.0000e+00 - val_loss: 137.3741 - val_accuracy: 0.0588\n",
      "Epoch 4358/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.6866 - accuracy: 0.0000e+00 - val_loss: 137.5373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4359/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 37.8736 - accuracy: 0.0000e+00 - val_loss: 127.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 4360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4227 - accuracy: 0.0000e+00 - val_loss: 111.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 4361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6712 - accuracy: 0.0000e+00 - val_loss: 103.7012 - val_accuracy: 0.0588\n",
      "Epoch 4362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0042 - accuracy: 0.0156 - val_loss: 106.7124 - val_accuracy: 0.0000e+00\n",
      "Epoch 4363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0490 - accuracy: 0.0156 - val_loss: 114.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 4364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3724 - accuracy: 0.0000e+00 - val_loss: 121.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 4365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5582 - accuracy: 0.0000e+00 - val_loss: 111.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1572 - accuracy: 0.0000e+00 - val_loss: 99.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4367/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.7104 - accuracy: 0.0000e+00 - val_loss: 102.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 4368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4474 - accuracy: 0.0156 - val_loss: 104.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 4369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8515 - accuracy: 0.0000e+00 - val_loss: 108.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 4370/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 23.2739 - accuracy: 0.0156 - val_loss: 118.4956 - val_accuracy: 0.0000e+00\n",
      "Epoch 4371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5869 - accuracy: 0.0000e+00 - val_loss: 133.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 4372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0390 - accuracy: 0.0000e+00 - val_loss: 136.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 4373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8980 - accuracy: 0.0156 - val_loss: 129.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4840 - accuracy: 0.0000e+00 - val_loss: 121.0521 - val_accuracy: 0.0000e+00\n",
      "Epoch 4375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6102 - accuracy: 0.0156 - val_loss: 123.6525 - val_accuracy: 0.0588\n",
      "Epoch 4376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9289 - accuracy: 0.0156 - val_loss: 132.2821 - val_accuracy: 0.0588\n",
      "Epoch 4377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6626 - accuracy: 0.0000e+00 - val_loss: 130.4566 - val_accuracy: 0.0588\n",
      "Epoch 4378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0442 - accuracy: 0.0156 - val_loss: 119.6643 - val_accuracy: 0.0588\n",
      "Epoch 4379/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 32.8034 - accuracy: 0.0156 - val_loss: 117.2412 - val_accuracy: 0.0000e+00\n",
      "Epoch 4380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4107 - accuracy: 0.0000e+00 - val_loss: 123.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 4381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2920 - accuracy: 0.0000e+00 - val_loss: 125.2018 - val_accuracy: 0.0588\n",
      "Epoch 4382/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 30.8404 - accuracy: 0.0156 - val_loss: 122.9062 - val_accuracy: 0.0588\n",
      "Epoch 4383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0581 - accuracy: 0.0000e+00 - val_loss: 111.6372 - val_accuracy: 0.1176\n",
      "Epoch 4384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5755 - accuracy: 0.0312 - val_loss: 109.2568 - val_accuracy: 0.0588\n",
      "Epoch 4385/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.1382 - accuracy: 0.0000e+00 - val_loss: 112.3403 - val_accuracy: 0.0588\n",
      "Epoch 4386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2392 - accuracy: 0.0000e+00 - val_loss: 113.1410 - val_accuracy: 0.0588\n",
      "Epoch 4387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9639 - accuracy: 0.0156 - val_loss: 116.9792 - val_accuracy: 0.0588\n",
      "Epoch 4388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7643 - accuracy: 0.0156 - val_loss: 119.4455 - val_accuracy: 0.0588\n",
      "Epoch 4389/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 44.1983 - accuracy: 0.0312 - val_loss: 116.5337 - val_accuracy: 0.0588\n",
      "Epoch 4390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3764 - accuracy: 0.0000e+00 - val_loss: 121.3791 - val_accuracy: 0.0588\n",
      "Epoch 4391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6148 - accuracy: 0.0000e+00 - val_loss: 134.2123 - val_accuracy: 0.0588\n",
      "Epoch 4392/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.5230 - accuracy: 0.0156 - val_loss: 131.4742 - val_accuracy: 0.0588\n",
      "Epoch 4393/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.4903 - accuracy: 0.0156 - val_loss: 119.7199 - val_accuracy: 0.0588\n",
      "Epoch 4394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1118 - accuracy: 0.0000e+00 - val_loss: 116.3230 - val_accuracy: 0.1176\n",
      "Epoch 4395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6894 - accuracy: 0.0000e+00 - val_loss: 120.0808 - val_accuracy: 0.0588\n",
      "Epoch 4396/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 35.9192 - accuracy: 0.0312 - val_loss: 116.1213 - val_accuracy: 0.0588\n",
      "Epoch 4397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4705 - accuracy: 0.0000e+00 - val_loss: 111.5677 - val_accuracy: 0.0588\n",
      "Epoch 4398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8578 - accuracy: 0.0000e+00 - val_loss: 109.4411 - val_accuracy: 0.0588\n",
      "Epoch 4399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5206 - accuracy: 0.0000e+00 - val_loss: 106.2963 - val_accuracy: 0.1176\n",
      "Epoch 4400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7895 - accuracy: 0.0000e+00 - val_loss: 103.6029 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0399 - accuracy: 0.0000e+00 - val_loss: 106.0927 - val_accuracy: 0.0588\n",
      "Epoch 4402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4599 - accuracy: 0.0312 - val_loss: 115.9115 - val_accuracy: 0.0588\n",
      "Epoch 4403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2127 - accuracy: 0.0000e+00 - val_loss: 122.6572 - val_accuracy: 0.0588\n",
      "Epoch 4404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5937 - accuracy: 0.0000e+00 - val_loss: 113.8510 - val_accuracy: 0.0588\n",
      "Epoch 4405/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.1926 - accuracy: 0.0000e+00 - val_loss: 105.8844 - val_accuracy: 0.0588\n",
      "Epoch 4406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4252 - accuracy: 0.0156 - val_loss: 111.1243 - val_accuracy: 0.0588\n",
      "Epoch 4407/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 37.1821 - accuracy: 0.0156 - val_loss: 118.2575 - val_accuracy: 0.0588\n",
      "Epoch 4408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6409 - accuracy: 0.0000e+00 - val_loss: 128.4849 - val_accuracy: 0.0588\n",
      "Epoch 4409/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.5329 - accuracy: 0.031 - 0s 125us/step - loss: 39.1282 - accuracy: 0.0156 - val_loss: 132.1153 - val_accuracy: 0.0588\n",
      "Epoch 4410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3323 - accuracy: 0.0000e+00 - val_loss: 126.2701 - val_accuracy: 0.1176\n",
      "Epoch 4411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9919 - accuracy: 0.0312 - val_loss: 123.5750 - val_accuracy: 0.0588\n",
      "Epoch 4412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7362 - accuracy: 0.0156 - val_loss: 126.1332 - val_accuracy: 0.0588\n",
      "Epoch 4413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6964 - accuracy: 0.0312 - val_loss: 133.6628 - val_accuracy: 0.0588\n",
      "Epoch 4414/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.3316 - accuracy: 0.0000e+00 - val_loss: 140.9293 - val_accuracy: 0.0588\n",
      "Epoch 4415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3641 - accuracy: 0.0000e+00 - val_loss: 139.0007 - val_accuracy: 0.1176\n",
      "Epoch 4416/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8869 - accuracy: 0.0000e+00 - val_loss: 123.2994 - val_accuracy: 0.0588\n",
      "Epoch 4417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6235 - accuracy: 0.0156 - val_loss: 107.8964 - val_accuracy: 0.0588\n",
      "Epoch 4418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5119 - accuracy: 0.0312 - val_loss: 96.1038 - val_accuracy: 0.0588\n",
      "Epoch 4419/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.4653 - accuracy: 0.0156 - val_loss: 95.9483 - val_accuracy: 0.0588\n",
      "Epoch 4420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7311 - accuracy: 0.0000e+00 - val_loss: 114.3791 - val_accuracy: 0.0588\n",
      "Epoch 4421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2561 - accuracy: 0.0000e+00 - val_loss: 129.1957 - val_accuracy: 0.0588\n",
      "Epoch 4422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1919 - accuracy: 0.0000e+00 - val_loss: 118.3185 - val_accuracy: 0.0588\n",
      "Epoch 4423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2229 - accuracy: 0.0000e+00 - val_loss: 107.3015 - val_accuracy: 0.0588\n",
      "Epoch 4424/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 29.2726 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 33.1768 - accuracy: 0.0000e+00 - val_loss: 101.3876 - val_accuracy: 0.0588\n",
      "Epoch 4425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6711 - accuracy: 0.0156 - val_loss: 104.5054 - val_accuracy: 0.0588\n",
      "Epoch 4426/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.6179 - accuracy: 0.0312 - val_loss: 118.5682 - val_accuracy: 0.0588\n",
      "Epoch 4427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5144 - accuracy: 0.0156 - val_loss: 135.4597 - val_accuracy: 0.0588\n",
      "Epoch 4428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9085 - accuracy: 0.0000e+00 - val_loss: 137.4394 - val_accuracy: 0.0588\n",
      "Epoch 4429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6252 - accuracy: 0.0000e+00 - val_loss: 128.6487 - val_accuracy: 0.0588\n",
      "Epoch 4430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8461 - accuracy: 0.0000e+00 - val_loss: 118.1713 - val_accuracy: 0.0588\n",
      "Epoch 4431/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 33.2134 - accuracy: 0.0000e+00 - val_loss: 110.8653 - val_accuracy: 0.0588\n",
      "Epoch 4432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.2813 - accuracy: 0.0156 - val_loss: 110.8914 - val_accuracy: 0.0588\n",
      "Epoch 4433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4769 - accuracy: 0.0000e+00 - val_loss: 112.8881 - val_accuracy: 0.1176\n",
      "Epoch 4434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3913 - accuracy: 0.0000e+00 - val_loss: 107.2661 - val_accuracy: 0.0588\n",
      "Epoch 4435/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2663 - accuracy: 0.0156 - val_loss: 99.7058 - val_accuracy: 0.0588\n",
      "Epoch 4436/10000\n",
      "64/64 [==============================] - 0s 39us/step - loss: 22.4585 - accuracy: 0.0156 - val_loss: 93.6206 - val_accuracy: 0.0588\n",
      "Epoch 4437/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 53.4384 - accuracy: 0.0156 - val_loss: 94.0767 - val_accuracy: 0.0588\n",
      "Epoch 4438/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 28.0647 - accuracy: 0.0000e+00 - val_loss: 97.7718 - val_accuracy: 0.0588\n",
      "Epoch 4439/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 55.5721 - accuracy: 0.0156 - val_loss: 117.4104 - val_accuracy: 0.0588\n",
      "Epoch 4440/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 33.7609 - accuracy: 0.0156 - val_loss: 127.4873 - val_accuracy: 0.0588\n",
      "Epoch 4441/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.2322 - accuracy: 0.0156 - val_loss: 120.8939 - val_accuracy: 0.0588\n",
      "Epoch 4442/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 36.7054 - accuracy: 0.0000e+00 - val_loss: 121.4326 - val_accuracy: 0.0588\n",
      "Epoch 4443/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.4465 - accuracy: 0.0156 - val_loss: 125.6477 - val_accuracy: 0.0588\n",
      "Epoch 4444/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 35.9618 - accuracy: 0.0000e+00 - val_loss: 124.7989 - val_accuracy: 0.0588\n",
      "Epoch 4445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7770 - accuracy: 0.0156 - val_loss: 117.7807 - val_accuracy: 0.0588\n",
      "Epoch 4446/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 34.9262 - accuracy: 0.0000e+00 - val_loss: 119.6358 - val_accuracy: 0.0588\n",
      "Epoch 4447/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 48.1248 - accuracy: 0.0312 - val_loss: 125.1043 - val_accuracy: 0.0588\n",
      "Epoch 4448/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.1331 - accuracy: 0.0000e+00 - val_loss: 117.5360 - val_accuracy: 0.0588\n",
      "Epoch 4449/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.4173 - accuracy: 0.0000e+00 - val_loss: 110.2127 - val_accuracy: 0.0588\n",
      "Epoch 4450/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 32.5048 - accuracy: 0.0000e+00 - val_loss: 115.4952 - val_accuracy: 0.0588\n",
      "Epoch 4451/10000\n",
      "64/64 [==============================] - 0s 217us/step - loss: 27.9068 - accuracy: 0.0000e+00 - val_loss: 125.8645 - val_accuracy: 0.0588\n",
      "Epoch 4452/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 35.1372 - accuracy: 0.0156 - val_loss: 133.0878 - val_accuracy: 0.0588\n",
      "Epoch 4453/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.2373 - accuracy: 0.0156 - val_loss: 127.4169 - val_accuracy: 0.0588\n",
      "Epoch 4454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 134us/step - loss: 31.2107 - accuracy: 0.0000e+00 - val_loss: 116.9935 - val_accuracy: 0.0588\n",
      "Epoch 4455/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 32.8048 - accuracy: 0.0312 - val_loss: 111.8525 - val_accuracy: 0.0588\n",
      "Epoch 4456/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 32.2413 - accuracy: 0.0000e+00 - val_loss: 113.3358 - val_accuracy: 0.0588\n",
      "Epoch 4457/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 35.9804 - accuracy: 0.0000e+00 - val_loss: 114.6839 - val_accuracy: 0.0588\n",
      "Epoch 4458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4847 - accuracy: 0.0156 - val_loss: 122.4813 - val_accuracy: 0.0588\n",
      "Epoch 4459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3642 - accuracy: 0.0000e+00 - val_loss: 133.7202 - val_accuracy: 0.0588\n",
      "Epoch 4460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8009 - accuracy: 0.0156 - val_loss: 135.4605 - val_accuracy: 0.0588\n",
      "Epoch 4461/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8476 - accuracy: 0.0156 - val_loss: 139.1949 - val_accuracy: 0.0588\n",
      "Epoch 4462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5508 - accuracy: 0.0000e+00 - val_loss: 128.5672 - val_accuracy: 0.0588\n",
      "Epoch 4463/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 43.4223 - accuracy: 0.0000e+00 - val_loss: 125.4174 - val_accuracy: 0.0588\n",
      "Epoch 4464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6825 - accuracy: 0.0000e+00 - val_loss: 126.1331 - val_accuracy: 0.0588\n",
      "Epoch 4465/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 34.9326 - accuracy: 0.0000e+00 - val_loss: 128.3024 - val_accuracy: 0.0588\n",
      "Epoch 4466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8907 - accuracy: 0.0156 - val_loss: 128.0430 - val_accuracy: 0.0588\n",
      "Epoch 4467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2429 - accuracy: 0.0156 - val_loss: 123.5880 - val_accuracy: 0.0588\n",
      "Epoch 4468/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 33.6633 - accuracy: 0.0000e+00 - val_loss: 117.7468 - val_accuracy: 0.0588\n",
      "Epoch 4469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5633 - accuracy: 0.0000e+00 - val_loss: 114.3127 - val_accuracy: 0.0588\n",
      "Epoch 4470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8718 - accuracy: 0.0312 - val_loss: 115.3148 - val_accuracy: 0.0588\n",
      "Epoch 4471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8449 - accuracy: 0.0156 - val_loss: 119.9543 - val_accuracy: 0.0588\n",
      "Epoch 4472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6974 - accuracy: 0.0000e+00 - val_loss: 135.7455 - val_accuracy: 0.0588\n",
      "Epoch 4473/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 27.3257 - accuracy: 0.0000e+00 - val_loss: 145.0990 - val_accuracy: 0.0588\n",
      "Epoch 4474/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7039 - accuracy: 0.0000e+00 - val_loss: 140.9252 - val_accuracy: 0.0588\n",
      "Epoch 4475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2316 - accuracy: 0.0000e+00 - val_loss: 136.9046 - val_accuracy: 0.0588\n",
      "Epoch 4476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1463 - accuracy: 0.0156 - val_loss: 136.1897 - val_accuracy: 0.0588\n",
      "Epoch 4477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6101 - accuracy: 0.0156 - val_loss: 138.8283 - val_accuracy: 0.0000e+00\n",
      "Epoch 4478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4813 - accuracy: 0.0156 - val_loss: 136.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4479/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 28.0024 - accuracy: 0.0156 - val_loss: 121.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 4480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3559 - accuracy: 0.0000e+00 - val_loss: 109.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 4481/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4179 - accuracy: 0.0156 - val_loss: 104.7943 - val_accuracy: 0.0588\n",
      "Epoch 4482/10000\n",
      "64/64 [==============================] - 0s 108us/step - loss: 34.3845 - accuracy: 0.0000e+00 - val_loss: 109.5455 - val_accuracy: 0.0588\n",
      "Epoch 4483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7835 - accuracy: 0.0000e+00 - val_loss: 120.5704 - val_accuracy: 0.0000e+00\n",
      "Epoch 4484/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.9290 - accuracy: 0.0000e+00 - val_loss: 126.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 4485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5899 - accuracy: 0.0000e+00 - val_loss: 126.7875 - val_accuracy: 0.0588\n",
      "Epoch 4486/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 39.0447 - accuracy: 0.0156 - val_loss: 122.6175 - val_accuracy: 0.0588\n",
      "Epoch 4487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6820 - accuracy: 0.0000e+00 - val_loss: 119.7028 - val_accuracy: 0.0588\n",
      "Epoch 4488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6103 - accuracy: 0.0000e+00 - val_loss: 114.9673 - val_accuracy: 0.0588\n",
      "Epoch 4489/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0673 - accuracy: 0.0156 - val_loss: 114.9404 - val_accuracy: 0.0588\n",
      "Epoch 4490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9531 - accuracy: 0.0156 - val_loss: 115.0713 - val_accuracy: 0.0588\n",
      "Epoch 4491/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0084 - accuracy: 0.0000e+00 - val_loss: 122.1132 - val_accuracy: 0.0588\n",
      "Epoch 4492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1235 - accuracy: 0.0000e+00 - val_loss: 130.5724 - val_accuracy: 0.0588\n",
      "Epoch 4493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9540 - accuracy: 0.0000e+00 - val_loss: 132.5314 - val_accuracy: 0.0588\n",
      "Epoch 4494/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8699 - accuracy: 0.0000e+00 - val_loss: 129.1611 - val_accuracy: 0.0588\n",
      "Epoch 4495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2782 - accuracy: 0.0000e+00 - val_loss: 125.6954 - val_accuracy: 0.0588\n",
      "Epoch 4496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8346 - accuracy: 0.0000e+00 - val_loss: 114.8671 - val_accuracy: 0.0588\n",
      "Epoch 4497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2868 - accuracy: 0.0000e+00 - val_loss: 104.3082 - val_accuracy: 0.0588\n",
      "Epoch 4498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4101 - accuracy: 0.0000e+00 - val_loss: 104.1004 - val_accuracy: 0.0588\n",
      "Epoch 4499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4715 - accuracy: 0.0312 - val_loss: 117.0654 - val_accuracy: 0.0588\n",
      "Epoch 4500/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 32.0233 - accuracy: 0.0156 - val_loss: 131.6710 - val_accuracy: 0.0588\n",
      "Epoch 4501/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 30.1084 - accuracy: 0.0000e+00 - val_loss: 128.1903 - val_accuracy: 0.0588\n",
      "Epoch 4502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4649 - accuracy: 0.0000e+00 - val_loss: 122.1039 - val_accuracy: 0.0588\n",
      "Epoch 4503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4689 - accuracy: 0.0000e+00 - val_loss: 113.9533 - val_accuracy: 0.0588\n",
      "Epoch 4504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8421 - accuracy: 0.0000e+00 - val_loss: 108.3213 - val_accuracy: 0.0588\n",
      "Epoch 4505/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 28.4383 - accuracy: 0.0000e+00 - val_loss: 107.9985 - val_accuracy: 0.0588\n",
      "Epoch 4506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7667 - accuracy: 0.0156 - val_loss: 116.7375 - val_accuracy: 0.0588\n",
      "Epoch 4507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3097 - accuracy: 0.0000e+00 - val_loss: 121.1766 - val_accuracy: 0.0588\n",
      "Epoch 4508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9152 - accuracy: 0.0156 - val_loss: 116.6841 - val_accuracy: 0.0588\n",
      "Epoch 4509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5130 - accuracy: 0.0000e+00 - val_loss: 113.9090 - val_accuracy: 0.0588\n",
      "Epoch 4510/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.1199 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 26.5671 - accuracy: 0.0312 - val_loss: 118.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6240 - accuracy: 0.0000e+00 - val_loss: 131.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 4512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0408 - accuracy: 0.0312 - val_loss: 138.3515 - val_accuracy: 0.0588\n",
      "Epoch 4513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8239 - accuracy: 0.0156 - val_loss: 144.1143 - val_accuracy: 0.0588\n",
      "Epoch 4514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3139 - accuracy: 0.0156 - val_loss: 148.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 4515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5011 - accuracy: 0.0000e+00 - val_loss: 145.8331 - val_accuracy: 0.0588\n",
      "Epoch 4516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5240 - accuracy: 0.0156 - val_loss: 139.7181 - val_accuracy: 0.0588\n",
      "Epoch 4517/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.4430 - accuracy: 0.0000e+00 - val_loss: 137.6691 - val_accuracy: 0.0588\n",
      "Epoch 4518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2921 - accuracy: 0.0000e+00 - val_loss: 131.9271 - val_accuracy: 0.0000e+00\n",
      "Epoch 4519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8932 - accuracy: 0.0156 - val_loss: 124.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 4520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4843 - accuracy: 0.0156 - val_loss: 126.3404 - val_accuracy: 0.0000e+00\n",
      "Epoch 4521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6358 - accuracy: 0.0000e+00 - val_loss: 123.7342 - val_accuracy: 0.0588\n",
      "Epoch 4522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6712 - accuracy: 0.0156 - val_loss: 120.7460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9803 - accuracy: 0.0000e+00 - val_loss: 122.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 4524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7206 - accuracy: 0.0000e+00 - val_loss: 128.2077 - val_accuracy: 0.0588\n",
      "Epoch 4525/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5172 - accuracy: 0.0000e+00 - val_loss: 136.7884 - val_accuracy: 0.0000e+00\n",
      "Epoch 4526/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.2569 - accuracy: 0.0156 - val_loss: 141.2531 - val_accuracy: 0.0000e+00\n",
      "Epoch 4527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1010 - accuracy: 0.0000e+00 - val_loss: 141.4405 - val_accuracy: 0.0000e+00\n",
      "Epoch 4528/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5431 - accuracy: 0.0000e+00 - val_loss: 137.5243 - val_accuracy: 0.0000e+00\n",
      "Epoch 4529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6721 - accuracy: 0.0000e+00 - val_loss: 132.7590 - val_accuracy: 0.0000e+00\n",
      "Epoch 4530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7033 - accuracy: 0.0000e+00 - val_loss: 132.9902 - val_accuracy: 0.0588\n",
      "Epoch 4531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8359 - accuracy: 0.0156 - val_loss: 127.9171 - val_accuracy: 0.0588\n",
      "Epoch 4532/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3114 - accuracy: 0.0156 - val_loss: 124.9230 - val_accuracy: 0.0588\n",
      "Epoch 4533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5212 - accuracy: 0.0156 - val_loss: 124.1406 - val_accuracy: 0.0588\n",
      "Epoch 4534/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.1366 - accuracy: 0.0000e+00 - val_loss: 126.6993 - val_accuracy: 0.0588\n",
      "Epoch 4535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2338 - accuracy: 0.0000e+00 - val_loss: 128.4571 - val_accuracy: 0.0588\n",
      "Epoch 4536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4215 - accuracy: 0.0156 - val_loss: 125.7048 - val_accuracy: 0.0588\n",
      "Epoch 4537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7899 - accuracy: 0.0000e+00 - val_loss: 119.5231 - val_accuracy: 0.0588\n",
      "Epoch 4538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3641 - accuracy: 0.0156 - val_loss: 114.9580 - val_accuracy: 0.0588\n",
      "Epoch 4539/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5469 - accuracy: 0.0000e+00 - val_loss: 118.1656 - val_accuracy: 0.0588\n",
      "Epoch 4540/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0947 - accuracy: 0.0000e+00 - val_loss: 120.2613 - val_accuracy: 0.0588\n",
      "Epoch 4541/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7278 - accuracy: 0.0000e+00 - val_loss: 124.6406 - val_accuracy: 0.0588\n",
      "Epoch 4542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2041 - accuracy: 0.0156 - val_loss: 115.5304 - val_accuracy: 0.0588\n",
      "Epoch 4543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4139 - accuracy: 0.0000e+00 - val_loss: 112.3425 - val_accuracy: 0.0588\n",
      "Epoch 4544/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8319 - accuracy: 0.0156 - val_loss: 113.5551 - val_accuracy: 0.0588\n",
      "Epoch 4545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9397 - accuracy: 0.0000e+00 - val_loss: 121.7065 - val_accuracy: 0.0588\n",
      "Epoch 4546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7942 - accuracy: 0.0000e+00 - val_loss: 133.7908 - val_accuracy: 0.0588\n",
      "Epoch 4547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0927 - accuracy: 0.0000e+00 - val_loss: 136.4560 - val_accuracy: 0.0588\n",
      "Epoch 4548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6809 - accuracy: 0.0000e+00 - val_loss: 136.8749 - val_accuracy: 0.0588\n",
      "Epoch 4549/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.9000 - accuracy: 0.0312 - val_loss: 135.0464 - val_accuracy: 0.0588\n",
      "Epoch 4550/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3345 - accuracy: 0.0156 - val_loss: 128.8254 - val_accuracy: 0.1176\n",
      "Epoch 4551/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9834 - accuracy: 0.0156 - val_loss: 126.9065 - val_accuracy: 0.0588\n",
      "Epoch 4552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3125 - accuracy: 0.0156 - val_loss: 132.5761 - val_accuracy: 0.0588\n",
      "Epoch 4553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8680 - accuracy: 0.0156 - val_loss: 142.7581 - val_accuracy: 0.0588\n",
      "Epoch 4554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2607 - accuracy: 0.0000e+00 - val_loss: 146.2858 - val_accuracy: 0.0588\n",
      "Epoch 4555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5906 - accuracy: 0.0000e+00 - val_loss: 135.5030 - val_accuracy: 0.0588\n",
      "Epoch 4556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3316 - accuracy: 0.0156 - val_loss: 126.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 4557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2940 - accuracy: 0.0000e+00 - val_loss: 122.5071 - val_accuracy: 0.0588\n",
      "Epoch 4558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5949 - accuracy: 0.0000e+00 - val_loss: 117.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 4559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7505 - accuracy: 0.0156 - val_loss: 119.5593 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4560/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.0520 - accuracy: 0.0000e+00 - val_loss: 126.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 4561/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8147 - accuracy: 0.0000e+00 - val_loss: 142.2278 - val_accuracy: 0.0000e+00\n",
      "Epoch 4562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1048 - accuracy: 0.0312 - val_loss: 146.2740 - val_accuracy: 0.0000e+00\n",
      "Epoch 4563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0818 - accuracy: 0.0000e+00 - val_loss: 135.5144 - val_accuracy: 0.0000e+00\n",
      "Epoch 4564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3768 - accuracy: 0.0156 - val_loss: 127.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 4565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4672 - accuracy: 0.0156 - val_loss: 122.3471 - val_accuracy: 0.1176\n",
      "Epoch 4566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5328 - accuracy: 0.0469 - val_loss: 121.6938 - val_accuracy: 0.1176\n",
      "Epoch 4567/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.3936 - accuracy: 0.0156 - val_loss: 124.0589 - val_accuracy: 0.0588\n",
      "Epoch 4568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9567 - accuracy: 0.0000e+00 - val_loss: 129.1380 - val_accuracy: 0.0588\n",
      "Epoch 4569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2824 - accuracy: 0.0156 - val_loss: 139.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8736 - accuracy: 0.0000e+00 - val_loss: 141.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 4571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5665 - accuracy: 0.0000e+00 - val_loss: 133.3478 - val_accuracy: 0.0000e+00\n",
      "Epoch 4572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0056 - accuracy: 0.0000e+00 - val_loss: 124.4797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7654 - accuracy: 0.0000e+00 - val_loss: 130.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 4574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0013 - accuracy: 0.0000e+00 - val_loss: 134.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 4575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4762 - accuracy: 0.0000e+00 - val_loss: 132.6593 - val_accuracy: 0.0588\n",
      "Epoch 4576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2914 - accuracy: 0.0156 - val_loss: 123.4565 - val_accuracy: 0.0588\n",
      "Epoch 4577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0197 - accuracy: 0.0000e+00 - val_loss: 117.9925 - val_accuracy: 0.0588\n",
      "Epoch 4578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5590 - accuracy: 0.0156 - val_loss: 114.9055 - val_accuracy: 0.0588\n",
      "Epoch 4579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0052 - accuracy: 0.0156 - val_loss: 117.4484 - val_accuracy: 0.0588\n",
      "Epoch 4580/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8011 - accuracy: 0.0156 - val_loss: 119.1021 - val_accuracy: 0.0000e+00\n",
      "Epoch 4581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9072 - accuracy: 0.0000e+00 - val_loss: 123.1932 - val_accuracy: 0.0000e+00\n",
      "Epoch 4582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1880 - accuracy: 0.0312 - val_loss: 128.9944 - val_accuracy: 0.0000e+00\n",
      "Epoch 4583/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.6793 - accuracy: 0.0312 - val_loss: 132.8485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9146 - accuracy: 0.0000e+00 - val_loss: 135.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3494 - accuracy: 0.0000e+00 - val_loss: 136.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 4586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6026 - accuracy: 0.0000e+00 - val_loss: 132.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 4587/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5801 - accuracy: 0.0156 - val_loss: 131.8045 - val_accuracy: 0.0588\n",
      "Epoch 4588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7948 - accuracy: 0.0000e+00 - val_loss: 128.5218 - val_accuracy: 0.0588\n",
      "Epoch 4589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3805 - accuracy: 0.0000e+00 - val_loss: 122.1030 - val_accuracy: 0.0588\n",
      "Epoch 4590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9489 - accuracy: 0.0156 - val_loss: 126.2519 - val_accuracy: 0.0588\n",
      "Epoch 4591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1799 - accuracy: 0.0000e+00 - val_loss: 126.9876 - val_accuracy: 0.0588\n",
      "Epoch 4592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4329 - accuracy: 0.0000e+00 - val_loss: 123.2593 - val_accuracy: 0.0588\n",
      "Epoch 4593/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.6442 - accuracy: 0.062 - 0s 125us/step - loss: 42.0719 - accuracy: 0.0312 - val_loss: 118.2932 - val_accuracy: 0.0588\n",
      "Epoch 4594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6483 - accuracy: 0.0000e+00 - val_loss: 120.3557 - val_accuracy: 0.0588\n",
      "Epoch 4595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1611 - accuracy: 0.0156 - val_loss: 131.9572 - val_accuracy: 0.0588\n",
      "Epoch 4596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6855 - accuracy: 0.0000e+00 - val_loss: 146.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 4597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9580 - accuracy: 0.0000e+00 - val_loss: 145.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 4598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6055 - accuracy: 0.0156 - val_loss: 132.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3548 - accuracy: 0.0312 - val_loss: 119.2888 - val_accuracy: 0.1176\n",
      "Epoch 4600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0307 - accuracy: 0.0000e+00 - val_loss: 115.8228 - val_accuracy: 0.0588\n",
      "Epoch 4601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5092 - accuracy: 0.0156 - val_loss: 115.6539 - val_accuracy: 0.0588\n",
      "Epoch 4602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1898 - accuracy: 0.0000e+00 - val_loss: 122.9951 - val_accuracy: 0.0588\n",
      "Epoch 4603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8315 - accuracy: 0.0000e+00 - val_loss: 125.6328 - val_accuracy: 0.0588\n",
      "Epoch 4604/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.1130 - accuracy: 0.0156 - val_loss: 125.3412 - val_accuracy: 0.0588\n",
      "Epoch 4605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8348 - accuracy: 0.0156 - val_loss: 124.0375 - val_accuracy: 0.0588\n",
      "Epoch 4606/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5992 - accuracy: 0.0000e+00 - val_loss: 118.4490 - val_accuracy: 0.0588\n",
      "Epoch 4607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0697 - accuracy: 0.0000e+00 - val_loss: 123.5912 - val_accuracy: 0.0588\n",
      "Epoch 4608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5930 - accuracy: 0.0000e+00 - val_loss: 127.5750 - val_accuracy: 0.0000e+00\n",
      "Epoch 4609/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.8569 - accuracy: 0.0000e+00 - val_loss: 135.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 4610/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9550 - accuracy: 0.0000e+00 - val_loss: 138.7740 - val_accuracy: 0.0000e+00\n",
      "Epoch 4611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2047 - accuracy: 0.0000e+00 - val_loss: 143.8734 - val_accuracy: 0.0000e+00\n",
      "Epoch 4612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7776 - accuracy: 0.0000e+00 - val_loss: 141.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 4613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8809 - accuracy: 0.0000e+00 - val_loss: 135.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 4614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7965 - accuracy: 0.0000e+00 - val_loss: 125.5381 - val_accuracy: 0.1176\n",
      "Epoch 4615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9623 - accuracy: 0.0000e+00 - val_loss: 116.6789 - val_accuracy: 0.1176\n",
      "Epoch 4616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4692 - accuracy: 0.0000e+00 - val_loss: 110.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 4617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4315 - accuracy: 0.0156 - val_loss: 117.4969 - val_accuracy: 0.0000e+00\n",
      "Epoch 4618/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9211 - accuracy: 0.0156 - val_loss: 130.3262 - val_accuracy: 0.0000e+00\n",
      "Epoch 4619/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.7091 - accuracy: 0.0000e+00 - val_loss: 120.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 4620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7533 - accuracy: 0.0000e+00 - val_loss: 103.1825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8180 - accuracy: 0.0000e+00 - val_loss: 99.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 4622/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8814 - accuracy: 0.0000e+00 - val_loss: 106.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 4623/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3631 - accuracy: 0.0156 - val_loss: 121.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6842 - accuracy: 0.0000e+00 - val_loss: 140.6537 - val_accuracy: 0.0000e+00\n",
      "Epoch 4625/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.3544 - accuracy: 0.0000e+00 - val_loss: 149.2159 - val_accuracy: 0.0000e+00\n",
      "Epoch 4626/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9332 - accuracy: 0.0000e+00 - val_loss: 145.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 4627/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4930 - accuracy: 0.0000e+00 - val_loss: 127.0330 - val_accuracy: 0.0000e+00\n",
      "Epoch 4628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8781 - accuracy: 0.0000e+00 - val_loss: 117.4408 - val_accuracy: 0.0000e+00\n",
      "Epoch 4629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4009 - accuracy: 0.0312 - val_loss: 115.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 4630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9062 - accuracy: 0.0312 - val_loss: 119.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 4631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5202 - accuracy: 0.0156 - val_loss: 124.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 4632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6381 - accuracy: 0.0156 - val_loss: 132.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4633/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5839 - accuracy: 0.0312 - val_loss: 132.3829 - val_accuracy: 0.0000e+00\n",
      "Epoch 4634/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.3379 - accuracy: 0.0000e+00 - val_loss: 125.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 4635/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4930 - accuracy: 0.0156 - val_loss: 117.2896 - val_accuracy: 0.0588\n",
      "Epoch 4636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4650 - accuracy: 0.0000e+00 - val_loss: 119.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 4637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6422 - accuracy: 0.0156 - val_loss: 122.5101 - val_accuracy: 0.0588\n",
      "Epoch 4638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8272 - accuracy: 0.0000e+00 - val_loss: 130.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 4639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4249 - accuracy: 0.0000e+00 - val_loss: 131.9834 - val_accuracy: 0.0588\n",
      "Epoch 4640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7772 - accuracy: 0.0156 - val_loss: 121.4413 - val_accuracy: 0.0588\n",
      "Epoch 4641/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3622 - accuracy: 0.0156 - val_loss: 111.5839 - val_accuracy: 0.0588\n",
      "Epoch 4642/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.1248 - accuracy: 0.0000e+00 - val_loss: 111.9612 - val_accuracy: 0.0588\n",
      "Epoch 4643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3803 - accuracy: 0.0469 - val_loss: 125.0765 - val_accuracy: 0.0588\n",
      "Epoch 4644/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.2207 - accuracy: 0.0000e+00 - val_loss: 132.5220 - val_accuracy: 0.0588\n",
      "Epoch 4645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9615 - accuracy: 0.0000e+00 - val_loss: 132.8236 - val_accuracy: 0.0588\n",
      "Epoch 4646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1521 - accuracy: 0.0000e+00 - val_loss: 131.7897 - val_accuracy: 0.0000e+00\n",
      "Epoch 4647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7367 - accuracy: 0.0000e+00 - val_loss: 136.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 4648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9572 - accuracy: 0.0000e+00 - val_loss: 135.2020 - val_accuracy: 0.0000e+00\n",
      "Epoch 4649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2716 - accuracy: 0.0000e+00 - val_loss: 129.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7284 - accuracy: 0.0312 - val_loss: 124.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 4651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8515 - accuracy: 0.0000e+00 - val_loss: 126.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 4652/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.6509 - accuracy: 0.0000e+00 - val_loss: 131.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 4653/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2534 - accuracy: 0.0000e+00 - val_loss: 127.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 4654/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.9937 - accuracy: 0.0000e+00 - val_loss: 125.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 4655/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5164 - accuracy: 0.0000e+00 - val_loss: 128.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 4656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5280 - accuracy: 0.0000e+00 - val_loss: 126.3180 - val_accuracy: 0.0588\n",
      "Epoch 4657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6744 - accuracy: 0.0156 - val_loss: 127.3583 - val_accuracy: 0.0588\n",
      "Epoch 4658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2274 - accuracy: 0.0156 - val_loss: 131.1875 - val_accuracy: 0.0588\n",
      "Epoch 4659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6941 - accuracy: 0.0156 - val_loss: 137.6465 - val_accuracy: 0.0000e+00\n",
      "Epoch 4660/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.8063 - accuracy: 0.0000e+00 - val_loss: 137.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 4661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8559 - accuracy: 0.0156 - val_loss: 128.9800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6481 - accuracy: 0.0312 - val_loss: 122.5793 - val_accuracy: 0.0000e+00\n",
      "Epoch 4663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8317 - accuracy: 0.0000e+00 - val_loss: 121.2872 - val_accuracy: 0.0000e+00\n",
      "Epoch 4664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 24.8744 - accuracy: 0.0156 - val_loss: 123.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 4665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4395 - accuracy: 0.0156 - val_loss: 120.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 4666/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0768 - accuracy: 0.0156 - val_loss: 119.9693 - val_accuracy: 0.0588\n",
      "Epoch 4667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2628 - accuracy: 0.0000e+00 - val_loss: 123.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 4668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0554 - accuracy: 0.0000e+00 - val_loss: 126.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4669/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7995 - accuracy: 0.0000e+00 - val_loss: 122.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 4670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6008 - accuracy: 0.0156 - val_loss: 120.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 4671/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5417 - accuracy: 0.0000e+00 - val_loss: 118.7876 - val_accuracy: 0.1176\n",
      "Epoch 4672/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1736 - accuracy: 0.0000e+00 - val_loss: 121.4433 - val_accuracy: 0.0588\n",
      "Epoch 4673/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3513 - accuracy: 0.0156 - val_loss: 127.7337 - val_accuracy: 0.0588\n",
      "Epoch 4674/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.2270 - accuracy: 0.0312 - val_loss: 135.2723 - val_accuracy: 0.0588\n",
      "Epoch 4675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4477 - accuracy: 0.0000e+00 - val_loss: 138.7209 - val_accuracy: 0.0588\n",
      "Epoch 4676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1429 - accuracy: 0.0000e+00 - val_loss: 133.4893 - val_accuracy: 0.0588\n",
      "Epoch 4677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9662 - accuracy: 0.0156 - val_loss: 130.3027 - val_accuracy: 0.0588\n",
      "Epoch 4678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9962 - accuracy: 0.0156 - val_loss: 122.1549 - val_accuracy: 0.0588\n",
      "Epoch 4679/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0492 - accuracy: 0.0000e+00 - val_loss: 117.0720 - val_accuracy: 0.0588\n",
      "Epoch 4680/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4257 - accuracy: 0.0000e+00 - val_loss: 112.2199 - val_accuracy: 0.0588\n",
      "Epoch 4681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6306 - accuracy: 0.0156 - val_loss: 118.0243 - val_accuracy: 0.0588\n",
      "Epoch 4682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9416 - accuracy: 0.0000e+00 - val_loss: 130.4801 - val_accuracy: 0.0588\n",
      "Epoch 4683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6660 - accuracy: 0.0000e+00 - val_loss: 141.9000 - val_accuracy: 0.0588\n",
      "Epoch 4684/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.2013 - accuracy: 0.031 - 0s 62us/step - loss: 40.6002 - accuracy: 0.0156 - val_loss: 146.0704 - val_accuracy: 0.0588\n",
      "Epoch 4685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8541 - accuracy: 0.0000e+00 - val_loss: 135.5488 - val_accuracy: 0.0588\n",
      "Epoch 4686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0858 - accuracy: 0.0000e+00 - val_loss: 118.6547 - val_accuracy: 0.0588\n",
      "Epoch 4687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2517 - accuracy: 0.0156 - val_loss: 108.7105 - val_accuracy: 0.0588\n",
      "Epoch 4688/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.8373 - accuracy: 0.0000e+00 - val_loss: 103.5560 - val_accuracy: 0.0588\n",
      "Epoch 4689/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0913 - accuracy: 0.0000e+00 - val_loss: 111.5406 - val_accuracy: 0.0000e+00\n",
      "Epoch 4690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8302 - accuracy: 0.0000e+00 - val_loss: 119.2257 - val_accuracy: 0.0000e+00\n",
      "Epoch 4691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0558 - accuracy: 0.0000e+00 - val_loss: 125.3581 - val_accuracy: 0.0000e+00\n",
      "Epoch 4692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0548 - accuracy: 0.0156 - val_loss: 132.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 4693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8470 - accuracy: 0.0000e+00 - val_loss: 134.8075 - val_accuracy: 0.0000e+00\n",
      "Epoch 4694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2377 - accuracy: 0.0000e+00 - val_loss: 127.8241 - val_accuracy: 0.0000e+00\n",
      "Epoch 4695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6581 - accuracy: 0.0000e+00 - val_loss: 121.1592 - val_accuracy: 0.0588\n",
      "Epoch 4696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0245 - accuracy: 0.0000e+00 - val_loss: 118.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 4697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0751 - accuracy: 0.0000e+00 - val_loss: 121.3049 - val_accuracy: 0.0588\n",
      "Epoch 4698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8414 - accuracy: 0.0000e+00 - val_loss: 127.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 4699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7496 - accuracy: 0.0156 - val_loss: 141.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 4700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0832 - accuracy: 0.0312 - val_loss: 140.7357 - val_accuracy: 0.0000e+00\n",
      "Epoch 4701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0484 - accuracy: 0.0156 - val_loss: 136.9842 - val_accuracy: 0.0588\n",
      "Epoch 4702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.4729 - accuracy: 0.0000e+00 - val_loss: 135.3475 - val_accuracy: 0.0588\n",
      "Epoch 4703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9996 - accuracy: 0.0000e+00 - val_loss: 134.4850 - val_accuracy: 0.0588\n",
      "Epoch 4704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7145 - accuracy: 0.0000e+00 - val_loss: 137.2465 - val_accuracy: 0.0588\n",
      "Epoch 4705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9939 - accuracy: 0.0000e+00 - val_loss: 138.5542 - val_accuracy: 0.1176\n",
      "Epoch 4706/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.1518 - accuracy: 0.0000e+00 - val_loss: 140.6373 - val_accuracy: 0.0588\n",
      "Epoch 4707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7647 - accuracy: 0.0156 - val_loss: 144.3104 - val_accuracy: 0.0588\n",
      "Epoch 4708/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.9162 - accuracy: 0.0312 - val_loss: 143.1315 - val_accuracy: 0.0588\n",
      "Epoch 4709/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6009 - accuracy: 0.0000e+00 - val_loss: 129.7695 - val_accuracy: 0.0588\n",
      "Epoch 4710/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4758 - accuracy: 0.0000e+00 - val_loss: 120.3929 - val_accuracy: 0.0588\n",
      "Epoch 4711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6128 - accuracy: 0.0000e+00 - val_loss: 122.2746 - val_accuracy: 0.0588\n",
      "Epoch 4712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4251 - accuracy: 0.0000e+00 - val_loss: 130.5350 - val_accuracy: 0.0588\n",
      "Epoch 4713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6965 - accuracy: 0.0000e+00 - val_loss: 135.2626 - val_accuracy: 0.0588\n",
      "Epoch 4714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2322 - accuracy: 0.0000e+00 - val_loss: 145.7061 - val_accuracy: 0.0588\n",
      "Epoch 4715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4314 - accuracy: 0.0000e+00 - val_loss: 144.7124 - val_accuracy: 0.0588\n",
      "Epoch 4716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.5137 - accuracy: 0.0156 - val_loss: 139.7368 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4717/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5611 - accuracy: 0.0312 - val_loss: 140.2079 - val_accuracy: 0.0588\n",
      "Epoch 4718/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0927 - accuracy: 0.0000e+00 - val_loss: 133.7344 - val_accuracy: 0.1176\n",
      "Epoch 4719/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.9327 - accuracy: 0.0156 - val_loss: 126.0607 - val_accuracy: 0.0588\n",
      "Epoch 4720/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.2058 - accuracy: 0.0000e+00 - val_loss: 122.3253 - val_accuracy: 0.0588\n",
      "Epoch 4721/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.1599 - accuracy: 0.0156 - val_loss: 127.8654 - val_accuracy: 0.0588\n",
      "Epoch 4722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1292 - accuracy: 0.0156 - val_loss: 132.2300 - val_accuracy: 0.0588\n",
      "Epoch 4723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8216 - accuracy: 0.0000e+00 - val_loss: 126.3826 - val_accuracy: 0.0588\n",
      "Epoch 4724/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7740 - accuracy: 0.0312 - val_loss: 116.7067 - val_accuracy: 0.0588\n",
      "Epoch 4725/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7537 - accuracy: 0.0156 - val_loss: 113.5798 - val_accuracy: 0.0588\n",
      "Epoch 4726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5678 - accuracy: 0.0000e+00 - val_loss: 116.6696 - val_accuracy: 0.0588\n",
      "Epoch 4727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8078 - accuracy: 0.0000e+00 - val_loss: 128.8009 - val_accuracy: 0.0588\n",
      "Epoch 4728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7743 - accuracy: 0.0156 - val_loss: 133.2878 - val_accuracy: 0.0588\n",
      "Epoch 4729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4850 - accuracy: 0.0156 - val_loss: 126.1022 - val_accuracy: 0.0588\n",
      "Epoch 4730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9422 - accuracy: 0.0000e+00 - val_loss: 120.0147 - val_accuracy: 0.0588\n",
      "Epoch 4731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6317 - accuracy: 0.0000e+00 - val_loss: 120.5570 - val_accuracy: 0.0588\n",
      "Epoch 4732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5809 - accuracy: 0.0156 - val_loss: 113.0423 - val_accuracy: 0.0588\n",
      "Epoch 4733/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4214 - accuracy: 0.0156 - val_loss: 105.6257 - val_accuracy: 0.0588\n",
      "Epoch 4734/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.7201 - accuracy: 0.0000e+00 - val_loss: 105.2177 - val_accuracy: 0.0588\n",
      "Epoch 4735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6479 - accuracy: 0.0000e+00 - val_loss: 101.4806 - val_accuracy: 0.0588\n",
      "Epoch 4736/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.3705 - accuracy: 0.0156 - val_loss: 120.1765 - val_accuracy: 0.0588\n",
      "Epoch 4737/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9062 - accuracy: 0.0000e+00 - val_loss: 141.2640 - val_accuracy: 0.0588\n",
      "Epoch 4738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3562 - accuracy: 0.0000e+00 - val_loss: 137.9740 - val_accuracy: 0.0588\n",
      "Epoch 4739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0816 - accuracy: 0.0000e+00 - val_loss: 123.4790 - val_accuracy: 0.1176\n",
      "Epoch 4740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9443 - accuracy: 0.0000e+00 - val_loss: 113.6138 - val_accuracy: 0.0588\n",
      "Epoch 4741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0778 - accuracy: 0.0000e+00 - val_loss: 112.8005 - val_accuracy: 0.0588\n",
      "Epoch 4742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2735 - accuracy: 0.0156 - val_loss: 113.0975 - val_accuracy: 0.0588\n",
      "Epoch 4743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9109 - accuracy: 0.0000e+00 - val_loss: 108.9004 - val_accuracy: 0.0588\n",
      "Epoch 4744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4384 - accuracy: 0.0156 - val_loss: 103.3215 - val_accuracy: 0.0588\n",
      "Epoch 4745/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.6576 - accuracy: 0.0156 - val_loss: 103.6563 - val_accuracy: 0.0588\n",
      "Epoch 4746/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3087 - accuracy: 0.0312 - val_loss: 109.3022 - val_accuracy: 0.0588\n",
      "Epoch 4747/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1022 - accuracy: 0.0000e+00 - val_loss: 115.0375 - val_accuracy: 0.0588\n",
      "Epoch 4748/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9438 - accuracy: 0.0156 - val_loss: 118.6997 - val_accuracy: 0.0588\n",
      "Epoch 4749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7367 - accuracy: 0.0156 - val_loss: 121.9203 - val_accuracy: 0.0588\n",
      "Epoch 4750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9369 - accuracy: 0.0156 - val_loss: 115.3095 - val_accuracy: 0.0588\n",
      "Epoch 4751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5427 - accuracy: 0.0156 - val_loss: 116.0434 - val_accuracy: 0.0588\n",
      "Epoch 4752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5490 - accuracy: 0.0156 - val_loss: 123.0928 - val_accuracy: 0.0588\n",
      "Epoch 4753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6483 - accuracy: 0.0000e+00 - val_loss: 129.1101 - val_accuracy: 0.0588\n",
      "Epoch 4754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7359 - accuracy: 0.0156 - val_loss: 135.5909 - val_accuracy: 0.0588\n",
      "Epoch 4755/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3999 - accuracy: 0.0000e+00 - val_loss: 140.3935 - val_accuracy: 0.0588\n",
      "Epoch 4756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6998 - accuracy: 0.0000e+00 - val_loss: 146.0316 - val_accuracy: 0.1176\n",
      "Epoch 4757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9973 - accuracy: 0.0156 - val_loss: 145.7159 - val_accuracy: 0.0588\n",
      "Epoch 4758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4273 - accuracy: 0.0156 - val_loss: 138.4665 - val_accuracy: 0.0588\n",
      "Epoch 4759/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.8527 - accuracy: 0.0000e+00 - val_loss: 131.6822 - val_accuracy: 0.0588\n",
      "Epoch 4760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0525 - accuracy: 0.0000e+00 - val_loss: 121.1803 - val_accuracy: 0.0588\n",
      "Epoch 4761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6506 - accuracy: 0.0000e+00 - val_loss: 116.2366 - val_accuracy: 0.0588\n",
      "Epoch 4762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0336 - accuracy: 0.0156 - val_loss: 114.9071 - val_accuracy: 0.0588\n",
      "Epoch 4763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6871 - accuracy: 0.0000e+00 - val_loss: 113.5400 - val_accuracy: 0.0588\n",
      "Epoch 4764/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1469 - accuracy: 0.0156 - val_loss: 118.4264 - val_accuracy: 0.0588\n",
      "Epoch 4765/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6525 - accuracy: 0.0000e+00 - val_loss: 127.5555 - val_accuracy: 0.0588\n",
      "Epoch 4766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0552 - accuracy: 0.0000e+00 - val_loss: 129.6335 - val_accuracy: 0.1176\n",
      "Epoch 4767/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1181 - accuracy: 0.0000e+00 - val_loss: 134.9105 - val_accuracy: 0.0588\n",
      "Epoch 4768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5984 - accuracy: 0.0000e+00 - val_loss: 138.1430 - val_accuracy: 0.0588\n",
      "Epoch 4769/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3621 - accuracy: 0.0156 - val_loss: 140.6962 - val_accuracy: 0.0588\n",
      "Epoch 4770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4679 - accuracy: 0.0156 - val_loss: 135.6747 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4771/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.1735 - accuracy: 0.0000e+00 - val_loss: 132.4204 - val_accuracy: 0.0588\n",
      "Epoch 4772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4145 - accuracy: 0.0156 - val_loss: 126.6248 - val_accuracy: 0.0588\n",
      "Epoch 4773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8604 - accuracy: 0.0000e+00 - val_loss: 119.2832 - val_accuracy: 0.0588\n",
      "Epoch 4774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8602 - accuracy: 0.0156 - val_loss: 117.5487 - val_accuracy: 0.0588\n",
      "Epoch 4775/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.2587 - accuracy: 0.0000e+00 - val_loss: 113.8217 - val_accuracy: 0.0588\n",
      "Epoch 4776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7710 - accuracy: 0.0000e+00 - val_loss: 117.1573 - val_accuracy: 0.0588\n",
      "Epoch 4777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8269 - accuracy: 0.0000e+00 - val_loss: 121.9071 - val_accuracy: 0.0588\n",
      "Epoch 4778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5064 - accuracy: 0.0156 - val_loss: 146.1628 - val_accuracy: 0.0588\n",
      "Epoch 4779/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.9387 - accuracy: 0.0156 - val_loss: 147.3952 - val_accuracy: 0.0588\n",
      "Epoch 4780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5129 - accuracy: 0.0000e+00 - val_loss: 138.8865 - val_accuracy: 0.0588\n",
      "Epoch 4781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5241 - accuracy: 0.0000e+00 - val_loss: 129.6111 - val_accuracy: 0.0588\n",
      "Epoch 4782/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.5911 - accuracy: 0.0000e+00 - val_loss: 128.9529 - val_accuracy: 0.0588\n",
      "Epoch 4783/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.9405 - accuracy: 0.0000e+00 - val_loss: 128.2919 - val_accuracy: 0.0588\n",
      "Epoch 4784/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.0212 - accuracy: 0.0156 - val_loss: 128.2254 - val_accuracy: 0.0588\n",
      "Epoch 4785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.0616 - accuracy: 0.0000e+00 - val_loss: 129.0447 - val_accuracy: 0.0588\n",
      "Epoch 4786/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 23.6487 - accuracy: 0.0156 - val_loss: 131.1225 - val_accuracy: 0.0588\n",
      "Epoch 4787/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4219 - accuracy: 0.0000e+00 - val_loss: 132.6113 - val_accuracy: 0.0588\n",
      "Epoch 4788/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9112 - accuracy: 0.0156 - val_loss: 124.0958 - val_accuracy: 0.0588\n",
      "Epoch 4789/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1969 - accuracy: 0.0156 - val_loss: 118.5900 - val_accuracy: 0.0588\n",
      "Epoch 4790/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.0608 - accuracy: 0.0000e+00 - val_loss: 117.0075 - val_accuracy: 0.0588\n",
      "Epoch 4791/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8613 - accuracy: 0.0000e+00 - val_loss: 126.4737 - val_accuracy: 0.0588\n",
      "Epoch 4792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1540 - accuracy: 0.0000e+00 - val_loss: 143.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 4793/10000\n",
      "64/64 [==============================] - 0s 206us/step - loss: 34.1213 - accuracy: 0.0000e+00 - val_loss: 143.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 4794/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 30.1053 - accuracy: 0.0156 - val_loss: 136.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 4795/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 23.1801 - accuracy: 0.0000e+00 - val_loss: 129.1235 - val_accuracy: 0.0000e+00\n",
      "Epoch 4796/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 34.2535 - accuracy: 0.0000e+00 - val_loss: 121.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 4797/10000\n",
      "64/64 [==============================] - 0s 49us/step - loss: 37.3099 - accuracy: 0.0312 - val_loss: 115.9666 - val_accuracy: 0.0000e+00\n",
      "Epoch 4798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4909 - accuracy: 0.0156 - val_loss: 120.3410 - val_accuracy: 0.0588\n",
      "Epoch 4799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5893 - accuracy: 0.0156 - val_loss: 138.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 4800/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4212 - accuracy: 0.0000e+00 - val_loss: 157.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8279 - accuracy: 0.0000e+00 - val_loss: 152.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 4802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6718 - accuracy: 0.0000e+00 - val_loss: 129.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 4803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7492 - accuracy: 0.0000e+00 - val_loss: 118.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 4804/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 37.6661 - accuracy: 0.0156 - val_loss: 118.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4805/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 33.0463 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 26.6533 - accuracy: 0.0156 - val_loss: 125.3512 - val_accuracy: 0.0588\n",
      "Epoch 4806/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.3315 - accuracy: 0.0312 - val_loss: 137.4168 - val_accuracy: 0.0588\n",
      "Epoch 4807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8963 - accuracy: 0.0156 - val_loss: 136.7420 - val_accuracy: 0.0588\n",
      "Epoch 4808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0082 - accuracy: 0.0000e+00 - val_loss: 135.3894 - val_accuracy: 0.0588\n",
      "Epoch 4809/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 23.7687 - accuracy: 0.0156 - val_loss: 133.6747 - val_accuracy: 0.0588\n",
      "Epoch 4810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9167 - accuracy: 0.0000e+00 - val_loss: 129.1966 - val_accuracy: 0.0588\n",
      "Epoch 4811/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5167 - accuracy: 0.0156 - val_loss: 125.7334 - val_accuracy: 0.0588\n",
      "Epoch 4812/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.3207 - accuracy: 0.0156 - val_loss: 126.2121 - val_accuracy: 0.0588\n",
      "Epoch 4813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5970 - accuracy: 0.0312 - val_loss: 127.6076 - val_accuracy: 0.0000e+00\n",
      "Epoch 4814/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 27.3352 - accuracy: 0.0156 - val_loss: 127.2800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9883 - accuracy: 0.0312 - val_loss: 127.6811 - val_accuracy: 0.0000e+00\n",
      "Epoch 4816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3782 - accuracy: 0.0156 - val_loss: 134.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 4817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0358 - accuracy: 0.0312 - val_loss: 141.3675 - val_accuracy: 0.0000e+00\n",
      "Epoch 4818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9817 - accuracy: 0.0000e+00 - val_loss: 142.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 4819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4050 - accuracy: 0.0000e+00 - val_loss: 140.5576 - val_accuracy: 0.1176\n",
      "Epoch 4820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3742 - accuracy: 0.0000e+00 - val_loss: 136.5948 - val_accuracy: 0.1176\n",
      "Epoch 4821/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2958 - accuracy: 0.0000e+00 - val_loss: 135.3503 - val_accuracy: 0.0588\n",
      "Epoch 4822/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 36.9541 - accuracy: 0.0469 - val_loss: 131.5566 - val_accuracy: 0.0588\n",
      "Epoch 4823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8381 - accuracy: 0.0156 - val_loss: 124.9467 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0800 - accuracy: 0.0156 - val_loss: 121.0568 - val_accuracy: 0.0588\n",
      "Epoch 4825/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.3263 - accuracy: 0.0156 - val_loss: 129.9779 - val_accuracy: 0.0000e+00\n",
      "Epoch 4826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7789 - accuracy: 0.0156 - val_loss: 132.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8273 - accuracy: 0.0156 - val_loss: 130.3708 - val_accuracy: 0.0588\n",
      "Epoch 4828/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.6394 - accuracy: 0.0000e+00 - val_loss: 128.5004 - val_accuracy: 0.0588\n",
      "Epoch 4829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2161 - accuracy: 0.0156 - val_loss: 121.0837 - val_accuracy: 0.0588\n",
      "Epoch 4830/10000\n",
      "64/64 [==============================] - 0s 191us/step - loss: 29.0917 - accuracy: 0.0000e+00 - val_loss: 116.1151 - val_accuracy: 0.0588\n",
      "Epoch 4831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4276 - accuracy: 0.0000e+00 - val_loss: 118.8554 - val_accuracy: 0.0588\n",
      "Epoch 4832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4664 - accuracy: 0.0156 - val_loss: 131.9387 - val_accuracy: 0.0000e+00\n",
      "Epoch 4833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0350 - accuracy: 0.0000e+00 - val_loss: 140.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 4834/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.2131 - accuracy: 0.0000e+00 - val_loss: 141.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 4835/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.4872 - accuracy: 0.0156 - val_loss: 138.6646 - val_accuracy: 0.0588\n",
      "Epoch 4836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6898 - accuracy: 0.0312 - val_loss: 134.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 4837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4067 - accuracy: 0.0156 - val_loss: 134.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 4838/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 35.4039 - accuracy: 0.0000e+00 - val_loss: 133.3254 - val_accuracy: 0.0588\n",
      "Epoch 4839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3593 - accuracy: 0.0156 - val_loss: 136.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 4840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8979 - accuracy: 0.0000e+00 - val_loss: 140.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 4841/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.4316 - accuracy: 0.0000e+00 - val_loss: 146.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 4842/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5359 - accuracy: 0.0156 - val_loss: 144.4041 - val_accuracy: 0.0000e+00\n",
      "Epoch 4843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7259 - accuracy: 0.0000e+00 - val_loss: 132.3076 - val_accuracy: 0.0588\n",
      "Epoch 4844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7045 - accuracy: 0.0000e+00 - val_loss: 117.4917 - val_accuracy: 0.0588\n",
      "Epoch 4845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3792 - accuracy: 0.0000e+00 - val_loss: 106.0106 - val_accuracy: 0.1176\n",
      "Epoch 4846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7919 - accuracy: 0.0000e+00 - val_loss: 105.1441 - val_accuracy: 0.1176\n",
      "Epoch 4847/10000\n",
      "64/64 [==============================] - 0s 183us/step - loss: 28.4724 - accuracy: 0.0000e+00 - val_loss: 108.3193 - val_accuracy: 0.1176\n",
      "Epoch 4848/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 38.5957 - accuracy: 0.0000e+00 - val_loss: 123.4880 - val_accuracy: 0.0588\n",
      "Epoch 4849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8135 - accuracy: 0.0000e+00 - val_loss: 143.3354 - val_accuracy: 0.0588\n",
      "Epoch 4850/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 33.3765 - accuracy: 0.0000e+00 - val_loss: 137.1508 - val_accuracy: 0.0588\n",
      "Epoch 4851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6259 - accuracy: 0.0156 - val_loss: 119.8637 - val_accuracy: 0.0588\n",
      "Epoch 4852/10000\n",
      "64/64 [==============================] - 0s 570us/step - loss: 44.4322 - accuracy: 0.0156 - val_loss: 113.9996 - val_accuracy: 0.0588\n",
      "Epoch 4853/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9924 - accuracy: 0.0000e+00 - val_loss: 112.9694 - val_accuracy: 0.0588\n",
      "Epoch 4854/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.0908 - accuracy: 0.0000e+00 - val_loss: 118.6413 - val_accuracy: 0.1176\n",
      "Epoch 4855/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.3431 - accuracy: 0.0000e+00 - val_loss: 120.5791 - val_accuracy: 0.1176\n",
      "Epoch 4856/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.4439 - accuracy: 0.0000e+00 - val_loss: 115.6243 - val_accuracy: 0.1176\n",
      "Epoch 4857/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 21.0654 - accuracy: 0.0000e+00 - val_loss: 113.8159 - val_accuracy: 0.0588\n",
      "Epoch 4858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3195 - accuracy: 0.0156 - val_loss: 124.9600 - val_accuracy: 0.0588\n",
      "Epoch 4859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0953 - accuracy: 0.0000e+00 - val_loss: 135.4394 - val_accuracy: 0.0588\n",
      "Epoch 4860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1537 - accuracy: 0.0156 - val_loss: 136.3217 - val_accuracy: 0.0588\n",
      "Epoch 4861/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 35.4502 - accuracy: 0.0156 - val_loss: 122.4523 - val_accuracy: 0.0588\n",
      "Epoch 4862/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 29.8698 - accuracy: 0.0000e+00 - val_loss: 115.5168 - val_accuracy: 0.1176\n",
      "Epoch 4863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9854 - accuracy: 0.0156 - val_loss: 116.0353 - val_accuracy: 0.0588\n",
      "Epoch 4864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0085 - accuracy: 0.0156 - val_loss: 116.5183 - val_accuracy: 0.0588\n",
      "Epoch 4865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8991 - accuracy: 0.0156 - val_loss: 125.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 4866/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0710 - accuracy: 0.0000e+00 - val_loss: 133.6557 - val_accuracy: 0.0588\n",
      "Epoch 4867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1186 - accuracy: 0.0000e+00 - val_loss: 138.1697 - val_accuracy: 0.0000e+00\n",
      "Epoch 4868/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.1643 - accuracy: 0.0156 - val_loss: 133.9398 - val_accuracy: 0.0000e+00\n",
      "Epoch 4869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4893 - accuracy: 0.0156 - val_loss: 122.3688 - val_accuracy: 0.0588\n",
      "Epoch 4870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6905 - accuracy: 0.0000e+00 - val_loss: 112.6743 - val_accuracy: 0.0588\n",
      "Epoch 4871/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.5202 - accuracy: 0.0000e+00 - val_loss: 111.3106 - val_accuracy: 0.0588\n",
      "Epoch 4872/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 25.4098 - accuracy: 0.0312 - val_loss: 118.0555 - val_accuracy: 0.0588\n",
      "Epoch 4873/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.8718 - accuracy: 0.0469 - val_loss: 134.0043 - val_accuracy: 0.0588\n",
      "Epoch 4874/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.6569 - accuracy: 0.0156 - val_loss: 143.9270 - val_accuracy: 0.0588\n",
      "Epoch 4875/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3899 - accuracy: 0.0000e+00 - val_loss: 143.0477 - val_accuracy: 0.0588\n",
      "Epoch 4876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8568 - accuracy: 0.0000e+00 - val_loss: 142.3092 - val_accuracy: 0.0588\n",
      "Epoch 4877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9103 - accuracy: 0.0156 - val_loss: 138.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 4878/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.8266 - accuracy: 0.0000e+00 - val_loss: 135.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 4879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9326 - accuracy: 0.0156 - val_loss: 128.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 4880/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 27.6084 - accuracy: 0.0000e+00 - val_loss: 121.9730 - val_accuracy: 0.0000e+00\n",
      "Epoch 4881/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.2049 - accuracy: 0.0156 - val_loss: 122.4315 - val_accuracy: 0.0588\n",
      "Epoch 4882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8236 - accuracy: 0.0000e+00 - val_loss: 135.8333 - val_accuracy: 0.0000e+00\n",
      "Epoch 4883/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.0391 - accuracy: 0.0156 - val_loss: 146.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 4884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1078 - accuracy: 0.0000e+00 - val_loss: 145.4593 - val_accuracy: 0.0000e+00\n",
      "Epoch 4885/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.2867 - accuracy: 0.0156 - val_loss: 126.6013 - val_accuracy: 0.0000e+00\n",
      "Epoch 4886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4986 - accuracy: 0.0000e+00 - val_loss: 118.8702 - val_accuracy: 0.0588\n",
      "Epoch 4887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9700 - accuracy: 0.0156 - val_loss: 118.6629 - val_accuracy: 0.0588\n",
      "Epoch 4888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4145 - accuracy: 0.0156 - val_loss: 124.9752 - val_accuracy: 0.0588\n",
      "Epoch 4889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1059 - accuracy: 0.0000e+00 - val_loss: 132.1615 - val_accuracy: 0.0588\n",
      "Epoch 4890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6394 - accuracy: 0.0156 - val_loss: 132.9706 - val_accuracy: 0.0588\n",
      "Epoch 4891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7283 - accuracy: 0.0156 - val_loss: 123.8517 - val_accuracy: 0.0588\n",
      "Epoch 4892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8179 - accuracy: 0.0000e+00 - val_loss: 118.4311 - val_accuracy: 0.1176\n",
      "Epoch 4893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9065 - accuracy: 0.0312 - val_loss: 121.1026 - val_accuracy: 0.1176\n",
      "Epoch 4894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9368 - accuracy: 0.0000e+00 - val_loss: 128.6778 - val_accuracy: 0.0588\n",
      "Epoch 4895/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7533 - accuracy: 0.0000e+00 - val_loss: 137.6140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0117 - accuracy: 0.0000e+00 - val_loss: 144.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 4897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1657 - accuracy: 0.0000e+00 - val_loss: 147.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 4898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3095 - accuracy: 0.0000e+00 - val_loss: 134.8376 - val_accuracy: 0.0000e+00\n",
      "Epoch 4899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0999 - accuracy: 0.0156 - val_loss: 117.8134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3065 - accuracy: 0.0000e+00 - val_loss: 115.3278 - val_accuracy: 0.0000e+00\n",
      "Epoch 4901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0748 - accuracy: 0.0469 - val_loss: 120.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9715 - accuracy: 0.0156 - val_loss: 123.9555 - val_accuracy: 0.0000e+00\n",
      "Epoch 4903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0601 - accuracy: 0.0469 - val_loss: 126.8902 - val_accuracy: 0.0000e+00\n",
      "Epoch 4904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9604 - accuracy: 0.0156 - val_loss: 143.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5124 - accuracy: 0.0156 - val_loss: 153.5114 - val_accuracy: 0.0588\n",
      "Epoch 4906/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9701 - accuracy: 0.0000e+00 - val_loss: 150.4069 - val_accuracy: 0.0588\n",
      "Epoch 4907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6044 - accuracy: 0.0000e+00 - val_loss: 140.4689 - val_accuracy: 0.0588\n",
      "Epoch 4908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8802 - accuracy: 0.0000e+00 - val_loss: 129.2467 - val_accuracy: 0.0588\n",
      "Epoch 4909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3765 - accuracy: 0.0000e+00 - val_loss: 121.2387 - val_accuracy: 0.0588\n",
      "Epoch 4910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6639 - accuracy: 0.0000e+00 - val_loss: 125.7512 - val_accuracy: 0.0000e+00\n",
      "Epoch 4911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2808 - accuracy: 0.0000e+00 - val_loss: 129.2572 - val_accuracy: 0.0000e+00\n",
      "Epoch 4912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9147 - accuracy: 0.0469 - val_loss: 125.1139 - val_accuracy: 0.0000e+00\n",
      "Epoch 4913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8956 - accuracy: 0.0000e+00 - val_loss: 117.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 4914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7197 - accuracy: 0.0000e+00 - val_loss: 116.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 4915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2754 - accuracy: 0.0000e+00 - val_loss: 112.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 4916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1350 - accuracy: 0.0000e+00 - val_loss: 117.2797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9019 - accuracy: 0.0000e+00 - val_loss: 128.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 4918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9847 - accuracy: 0.0000e+00 - val_loss: 143.4786 - val_accuracy: 0.0000e+00\n",
      "Epoch 4919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5623 - accuracy: 0.0000e+00 - val_loss: 141.6354 - val_accuracy: 0.0000e+00\n",
      "Epoch 4920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8246 - accuracy: 0.0000e+00 - val_loss: 137.1232 - val_accuracy: 0.0000e+00\n",
      "Epoch 4921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9267 - accuracy: 0.0156 - val_loss: 133.7260 - val_accuracy: 0.0000e+00\n",
      "Epoch 4922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9682 - accuracy: 0.0000e+00 - val_loss: 127.4582 - val_accuracy: 0.0000e+00\n",
      "Epoch 4923/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4991 - accuracy: 0.0156 - val_loss: 121.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 4924/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 37.3534 - accuracy: 0.0000e+00 - val_loss: 125.2890 - val_accuracy: 0.0000e+00\n",
      "Epoch 4925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9050 - accuracy: 0.0156 - val_loss: 145.3825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8840 - accuracy: 0.0156 - val_loss: 152.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 4927/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9363 - accuracy: 0.0156 - val_loss: 143.8671 - val_accuracy: 0.0000e+00\n",
      "Epoch 4928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1790 - accuracy: 0.0000e+00 - val_loss: 145.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 4929/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 40.2370 - accuracy: 0.0000e+00 - val_loss: 140.7140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9911 - accuracy: 0.0000e+00 - val_loss: 134.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 4931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8366 - accuracy: 0.0000e+00 - val_loss: 125.7008 - val_accuracy: 0.0000e+00\n",
      "Epoch 4932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7898 - accuracy: 0.0156 - val_loss: 118.7721 - val_accuracy: 0.0588\n",
      "Epoch 4933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0476 - accuracy: 0.0156 - val_loss: 111.6619 - val_accuracy: 0.0588\n",
      "Epoch 4934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5641 - accuracy: 0.0000e+00 - val_loss: 108.2448 - val_accuracy: 0.0588\n",
      "Epoch 4935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2779 - accuracy: 0.0156 - val_loss: 117.7867 - val_accuracy: 0.0588\n",
      "Epoch 4936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9574 - accuracy: 0.0000e+00 - val_loss: 134.1375 - val_accuracy: 0.0588\n",
      "Epoch 4937/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0729 - accuracy: 0.0000e+00 - val_loss: 133.9941 - val_accuracy: 0.0588\n",
      "Epoch 4938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3849 - accuracy: 0.0156 - val_loss: 118.9854 - val_accuracy: 0.0588\n",
      "Epoch 4939/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9148 - accuracy: 0.0000e+00 - val_loss: 116.3774 - val_accuracy: 0.0588\n",
      "Epoch 4940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5286 - accuracy: 0.0312 - val_loss: 120.1381 - val_accuracy: 0.0588\n",
      "Epoch 4941/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 31.7571 - accuracy: 0.0000e+00 - val_loss: 126.5790 - val_accuracy: 0.0588\n",
      "Epoch 4942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0212 - accuracy: 0.0156 - val_loss: 135.7319 - val_accuracy: 0.0588\n",
      "Epoch 4943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7886 - accuracy: 0.0000e+00 - val_loss: 143.0108 - val_accuracy: 0.0588\n",
      "Epoch 4944/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5423 - accuracy: 0.0000e+00 - val_loss: 138.5458 - val_accuracy: 0.0588\n",
      "Epoch 4945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4860 - accuracy: 0.0000e+00 - val_loss: 130.1643 - val_accuracy: 0.0588\n",
      "Epoch 4946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6821 - accuracy: 0.0000e+00 - val_loss: 121.0681 - val_accuracy: 0.0588\n",
      "Epoch 4947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8407 - accuracy: 0.0156 - val_loss: 125.0108 - val_accuracy: 0.0588\n",
      "Epoch 4948/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3644 - accuracy: 0.0156 - val_loss: 131.4257 - val_accuracy: 0.0588\n",
      "Epoch 4949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5348 - accuracy: 0.0000e+00 - val_loss: 134.1639 - val_accuracy: 0.0588\n",
      "Epoch 4950/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 34.4452 - accuracy: 0.0000e+00 - val_loss: 140.7177 - val_accuracy: 0.0588\n",
      "Epoch 4951/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.7729 - accuracy: 0.0000e+00 - val_loss: 137.6395 - val_accuracy: 0.0588\n",
      "Epoch 4952/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 38.7192 - accuracy: 0.0000e+00 - val_loss: 130.4460 - val_accuracy: 0.0588\n",
      "Epoch 4953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8991 - accuracy: 0.0156 - val_loss: 128.3408 - val_accuracy: 0.0588\n",
      "Epoch 4954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9037 - accuracy: 0.0000e+00 - val_loss: 127.1458 - val_accuracy: 0.0588\n",
      "Epoch 4955/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.7539 - accuracy: 0.0156 - val_loss: 125.6311 - val_accuracy: 0.0588\n",
      "Epoch 4956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1391 - accuracy: 0.0156 - val_loss: 132.0844 - val_accuracy: 0.0588\n",
      "Epoch 4957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5869 - accuracy: 0.0156 - val_loss: 138.8631 - val_accuracy: 0.0588\n",
      "Epoch 4958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3837 - accuracy: 0.0000e+00 - val_loss: 140.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9120 - accuracy: 0.0156 - val_loss: 138.5939 - val_accuracy: 0.0000e+00\n",
      "Epoch 4960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6266 - accuracy: 0.0000e+00 - val_loss: 130.3460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4961/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8018 - accuracy: 0.0156 - val_loss: 118.6867 - val_accuracy: 0.0588\n",
      "Epoch 4962/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0524 - accuracy: 0.0000e+00 - val_loss: 109.4342 - val_accuracy: 0.0588\n",
      "Epoch 4963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2435 - accuracy: 0.0000e+00 - val_loss: 113.0558 - val_accuracy: 0.0588\n",
      "Epoch 4964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9996 - accuracy: 0.0000e+00 - val_loss: 123.2062 - val_accuracy: 0.0588\n",
      "Epoch 4965/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.5038 - accuracy: 0.0312 - val_loss: 127.7361 - val_accuracy: 0.0588\n",
      "Epoch 4966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1130 - accuracy: 0.0156 - val_loss: 127.9225 - val_accuracy: 0.0588\n",
      "Epoch 4967/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5624 - accuracy: 0.0312 - val_loss: 133.3495 - val_accuracy: 0.0588\n",
      "Epoch 4968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8271 - accuracy: 0.0000e+00 - val_loss: 128.5624 - val_accuracy: 0.0588\n",
      "Epoch 4969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9000 - accuracy: 0.0156 - val_loss: 127.9454 - val_accuracy: 0.0588\n",
      "Epoch 4970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4686 - accuracy: 0.0000e+00 - val_loss: 135.3765 - val_accuracy: 0.0588\n",
      "Epoch 4971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7942 - accuracy: 0.0000e+00 - val_loss: 143.0865 - val_accuracy: 0.0588\n",
      "Epoch 4972/10000\n",
      "64/64 [==============================] - 0s 99us/step - loss: 36.2996 - accuracy: 0.0156 - val_loss: 151.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 4973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3914 - accuracy: 0.0156 - val_loss: 145.6996 - val_accuracy: 0.0000e+00\n",
      "Epoch 4974/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.6731 - accuracy: 0.0312 - val_loss: 135.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 4975/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 18.4711 - accuracy: 0.0000e+00 - val_loss: 121.0077 - val_accuracy: 0.0588\n",
      "Epoch 4976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7059 - accuracy: 0.0312 - val_loss: 109.4722 - val_accuracy: 0.0588\n",
      "Epoch 4977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.6993 - accuracy: 0.0156 - val_loss: 112.9162 - val_accuracy: 0.0588\n",
      "Epoch 4978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5368 - accuracy: 0.0000e+00 - val_loss: 114.3303 - val_accuracy: 0.0588\n",
      "Epoch 4979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0713 - accuracy: 0.0000e+00 - val_loss: 120.8036 - val_accuracy: 0.0588\n",
      "Epoch 4980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6870 - accuracy: 0.0000e+00 - val_loss: 122.0911 - val_accuracy: 0.0588\n",
      "Epoch 4981/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3781 - accuracy: 0.0000e+00 - val_loss: 122.5873 - val_accuracy: 0.0588\n",
      "Epoch 4982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2507 - accuracy: 0.0156 - val_loss: 125.6184 - val_accuracy: 0.0588\n",
      "Epoch 4983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2584 - accuracy: 0.0000e+00 - val_loss: 127.6134 - val_accuracy: 0.0588\n",
      "Epoch 4984/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3067 - accuracy: 0.0000e+00 - val_loss: 131.2030 - val_accuracy: 0.0588\n",
      "Epoch 4985/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.1230 - accuracy: 0.0000e+00 - val_loss: 123.4598 - val_accuracy: 0.0588\n",
      "Epoch 4986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6256 - accuracy: 0.0312 - val_loss: 113.1561 - val_accuracy: 0.0588\n",
      "Epoch 4987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9821 - accuracy: 0.0156 - val_loss: 112.6432 - val_accuracy: 0.1176\n",
      "Epoch 4988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3080 - accuracy: 0.0000e+00 - val_loss: 119.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 4989/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7849 - accuracy: 0.0000e+00 - val_loss: 131.3126 - val_accuracy: 0.0588\n",
      "Epoch 4990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6061 - accuracy: 0.0000e+00 - val_loss: 146.3314 - val_accuracy: 0.0588\n",
      "Epoch 4991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8116 - accuracy: 0.0000e+00 - val_loss: 146.7036 - val_accuracy: 0.0588\n",
      "Epoch 4992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4814 - accuracy: 0.0000e+00 - val_loss: 139.0651 - val_accuracy: 0.0588\n",
      "Epoch 4993/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 28.1726 - accuracy: 0.0312 - val_loss: 137.4003 - val_accuracy: 0.0588\n",
      "Epoch 4994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2336 - accuracy: 0.0000e+00 - val_loss: 134.4182 - val_accuracy: 0.0588\n",
      "Epoch 4995/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 31.8790 - accuracy: 0.0000e+00 - val_loss: 131.4052 - val_accuracy: 0.0588\n",
      "Epoch 4996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0412 - accuracy: 0.0156 - val_loss: 127.6952 - val_accuracy: 0.0588\n",
      "Epoch 4997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4942 - accuracy: 0.0312 - val_loss: 125.8011 - val_accuracy: 0.0588\n",
      "Epoch 4998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3863 - accuracy: 0.0312 - val_loss: 126.6958 - val_accuracy: 0.0588\n",
      "Epoch 4999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8601 - accuracy: 0.0156 - val_loss: 125.1687 - val_accuracy: 0.0588\n",
      "Epoch 5000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1934 - accuracy: 0.0156 - val_loss: 126.1779 - val_accuracy: 0.0588\n",
      "Epoch 5001/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8945 - accuracy: 0.0000e+00 - val_loss: 130.2623 - val_accuracy: 0.0588\n",
      "Epoch 5002/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6005 - accuracy: 0.0000e+00 - val_loss: 130.4492 - val_accuracy: 0.0588\n",
      "Epoch 5003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6277 - accuracy: 0.0156 - val_loss: 125.2013 - val_accuracy: 0.0588\n",
      "Epoch 5004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1351 - accuracy: 0.0000e+00 - val_loss: 119.9809 - val_accuracy: 0.0588\n",
      "Epoch 5005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7408 - accuracy: 0.0156 - val_loss: 122.7736 - val_accuracy: 0.0588\n",
      "Epoch 5006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4884 - accuracy: 0.0000e+00 - val_loss: 131.1320 - val_accuracy: 0.0588\n",
      "Epoch 5007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1935 - accuracy: 0.0156 - val_loss: 141.5454 - val_accuracy: 0.0588\n",
      "Epoch 5008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4055 - accuracy: 0.0000e+00 - val_loss: 145.4222 - val_accuracy: 0.0588\n",
      "Epoch 5009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0394 - accuracy: 0.0156 - val_loss: 137.0329 - val_accuracy: 0.0588\n",
      "Epoch 5010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0530 - accuracy: 0.0000e+00 - val_loss: 123.3015 - val_accuracy: 0.0588\n",
      "Epoch 5011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0573 - accuracy: 0.0000e+00 - val_loss: 122.9426 - val_accuracy: 0.0588\n",
      "Epoch 5012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2909 - accuracy: 0.0000e+00 - val_loss: 126.8232 - val_accuracy: 0.0588\n",
      "Epoch 5013/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7099 - accuracy: 0.0000e+00 - val_loss: 128.0818 - val_accuracy: 0.0588\n",
      "Epoch 5014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1673 - accuracy: 0.0000e+00 - val_loss: 126.3518 - val_accuracy: 0.0588\n",
      "Epoch 5015/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 41.2369 - accuracy: 0.0000e+00 - val_loss: 130.7705 - val_accuracy: 0.0588\n",
      "Epoch 5016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4811 - accuracy: 0.0000e+00 - val_loss: 136.7850 - val_accuracy: 0.0588\n",
      "Epoch 5017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4689 - accuracy: 0.0000e+00 - val_loss: 134.8497 - val_accuracy: 0.0588\n",
      "Epoch 5018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9374 - accuracy: 0.0312 - val_loss: 132.4167 - val_accuracy: 0.0588\n",
      "Epoch 5019/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3588 - accuracy: 0.0156 - val_loss: 125.6408 - val_accuracy: 0.0588\n",
      "Epoch 5020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5386 - accuracy: 0.0000e+00 - val_loss: 120.7606 - val_accuracy: 0.0588\n",
      "Epoch 5021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1237 - accuracy: 0.0000e+00 - val_loss: 117.2489 - val_accuracy: 0.0588\n",
      "Epoch 5022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1175 - accuracy: 0.0000e+00 - val_loss: 117.7962 - val_accuracy: 0.0588\n",
      "Epoch 5023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2396 - accuracy: 0.0156 - val_loss: 119.9571 - val_accuracy: 0.0588\n",
      "Epoch 5024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1436 - accuracy: 0.0156 - val_loss: 131.3383 - val_accuracy: 0.0588\n",
      "Epoch 5025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8647 - accuracy: 0.0312 - val_loss: 138.8011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5026/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 29.3642 - accuracy: 0.0156 - val_loss: 136.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 5027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0128 - accuracy: 0.0156 - val_loss: 131.0582 - val_accuracy: 0.0000e+00\n",
      "Epoch 5028/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1227 - accuracy: 0.0000e+00 - val_loss: 126.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9577 - accuracy: 0.0000e+00 - val_loss: 126.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 5030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4964 - accuracy: 0.0156 - val_loss: 131.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 5031/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.2985 - accuracy: 0.0000e+00 - val_loss: 137.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5032/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2338 - accuracy: 0.0156 - val_loss: 136.4033 - val_accuracy: 0.0000e+00\n",
      "Epoch 5033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3844 - accuracy: 0.0000e+00 - val_loss: 134.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 5034/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2889 - accuracy: 0.0156 - val_loss: 131.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 5035/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 63us/step - loss: 38.1948 - accuracy: 0.0469 - val_loss: 132.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5036/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 37.9350 - accuracy: 0.0156 - val_loss: 135.3933 - val_accuracy: 0.0588\n",
      "Epoch 5037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6696 - accuracy: 0.0156 - val_loss: 130.8718 - val_accuracy: 0.0588\n",
      "Epoch 5038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5815 - accuracy: 0.0156 - val_loss: 122.0525 - val_accuracy: 0.0588\n",
      "Epoch 5039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6588 - accuracy: 0.0000e+00 - val_loss: 115.5396 - val_accuracy: 0.0588\n",
      "Epoch 5040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3856 - accuracy: 0.0156 - val_loss: 123.9427 - val_accuracy: 0.0588\n",
      "Epoch 5041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6552 - accuracy: 0.0000e+00 - val_loss: 139.7038 - val_accuracy: 0.0588\n",
      "Epoch 5042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1143 - accuracy: 0.0156 - val_loss: 144.6114 - val_accuracy: 0.0000e+00\n",
      "Epoch 5043/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7556 - accuracy: 0.0156 - val_loss: 138.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 5044/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5117 - accuracy: 0.0000e+00 - val_loss: 130.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 5045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7126 - accuracy: 0.0156 - val_loss: 132.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 5046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7152 - accuracy: 0.0000e+00 - val_loss: 137.7254 - val_accuracy: 0.0000e+00\n",
      "Epoch 5047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2181 - accuracy: 0.0000e+00 - val_loss: 138.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3607 - accuracy: 0.0000e+00 - val_loss: 132.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 5049/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.7715 - accuracy: 0.0000e+00 - val_loss: 128.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 5050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8522 - accuracy: 0.0469 - val_loss: 128.7962 - val_accuracy: 0.0000e+00\n",
      "Epoch 5051/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4690 - accuracy: 0.0000e+00 - val_loss: 129.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 5052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8137 - accuracy: 0.0312 - val_loss: 129.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 5053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1024 - accuracy: 0.0156 - val_loss: 123.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 5054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9006 - accuracy: 0.0000e+00 - val_loss: 124.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4937 - accuracy: 0.0000e+00 - val_loss: 127.5440 - val_accuracy: 0.0000e+00\n",
      "Epoch 5056/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.5275 - accuracy: 0.0000e+00 - val_loss: 131.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 5057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9319 - accuracy: 0.0000e+00 - val_loss: 130.8605 - val_accuracy: 0.0000e+00\n",
      "Epoch 5058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2119 - accuracy: 0.0000e+00 - val_loss: 129.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5059/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 30.3308 - accuracy: 0.0156 - val_loss: 123.8564 - val_accuracy: 0.0588\n",
      "Epoch 5060/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0045 - accuracy: 0.0000e+00 - val_loss: 121.0227 - val_accuracy: 0.0588\n",
      "Epoch 5061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6687 - accuracy: 0.0000e+00 - val_loss: 120.6086 - val_accuracy: 0.0588\n",
      "Epoch 5062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3592 - accuracy: 0.0000e+00 - val_loss: 130.2876 - val_accuracy: 0.0588\n",
      "Epoch 5063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9538 - accuracy: 0.0156 - val_loss: 134.9242 - val_accuracy: 0.0588\n",
      "Epoch 5064/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4931 - accuracy: 0.0156 - val_loss: 142.7007 - val_accuracy: 0.0000e+00\n",
      "Epoch 5065/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3244 - accuracy: 0.0000e+00 - val_loss: 144.7552 - val_accuracy: 0.0000e+00\n",
      "Epoch 5066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6392 - accuracy: 0.0156 - val_loss: 142.9918 - val_accuracy: 0.0000e+00\n",
      "Epoch 5067/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6061 - accuracy: 0.0000e+00 - val_loss: 138.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0121 - accuracy: 0.0156 - val_loss: 127.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 5069/10000\n",
      "64/64 [==============================] - 0s 115us/step - loss: 19.1252 - accuracy: 0.0000e+00 - val_loss: 111.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5070/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.7539 - accuracy: 0.0312 - val_loss: 101.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 5071/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4412 - accuracy: 0.0156 - val_loss: 110.7580 - val_accuracy: 0.0000e+00\n",
      "Epoch 5072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8245 - accuracy: 0.0312 - val_loss: 130.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 5073/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 39.8133 - accuracy: 0.0000e+00 - val_loss: 134.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 5074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3947 - accuracy: 0.0000e+00 - val_loss: 131.5198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5297 - accuracy: 0.0000e+00 - val_loss: 128.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4757 - accuracy: 0.0000e+00 - val_loss: 128.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 5077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6705 - accuracy: 0.0312 - val_loss: 128.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 5078/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2032 - accuracy: 0.0000e+00 - val_loss: 130.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 5079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0175 - accuracy: 0.0000e+00 - val_loss: 134.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 5080/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0294 - accuracy: 0.0156 - val_loss: 134.3121 - val_accuracy: 0.0000e+00\n",
      "Epoch 5081/10000\n",
      "64/64 [==============================] - 0s 192us/step - loss: 21.7568 - accuracy: 0.0156 - val_loss: 131.2108 - val_accuracy: 0.0588\n",
      "Epoch 5082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0922 - accuracy: 0.0000e+00 - val_loss: 118.9898 - val_accuracy: 0.0000e+00\n",
      "Epoch 5083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2099 - accuracy: 0.0000e+00 - val_loss: 109.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2190 - accuracy: 0.0000e+00 - val_loss: 113.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8796 - accuracy: 0.0156 - val_loss: 129.9438 - val_accuracy: 0.0000e+00\n",
      "Epoch 5086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7054 - accuracy: 0.0000e+00 - val_loss: 146.9051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8391 - accuracy: 0.0000e+00 - val_loss: 151.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 5088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9883 - accuracy: 0.0000e+00 - val_loss: 140.2041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8912 - accuracy: 0.0000e+00 - val_loss: 127.3663 - val_accuracy: 0.0588\n",
      "Epoch 5090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2475 - accuracy: 0.0000e+00 - val_loss: 116.0192 - val_accuracy: 0.0588\n",
      "Epoch 5091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8853 - accuracy: 0.0000e+00 - val_loss: 108.9296 - val_accuracy: 0.0588\n",
      "Epoch 5092/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2351 - accuracy: 0.0000e+00 - val_loss: 112.9271 - val_accuracy: 0.0588\n",
      "Epoch 5093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8765 - accuracy: 0.0000e+00 - val_loss: 124.1749 - val_accuracy: 0.0588\n",
      "Epoch 5094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6759 - accuracy: 0.0000e+00 - val_loss: 126.1770 - val_accuracy: 0.0588\n",
      "Epoch 5095/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0843 - accuracy: 0.0000e+00 - val_loss: 130.4027 - val_accuracy: 0.0588\n",
      "Epoch 5096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7032 - accuracy: 0.0000e+00 - val_loss: 132.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 5097/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 16.8444 - accuracy: 0.0000e+00 - val_loss: 129.5016 - val_accuracy: 0.0000e+00\n",
      "Epoch 5098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.6237 - accuracy: 0.0000e+00 - val_loss: 129.2077 - val_accuracy: 0.0588\n",
      "Epoch 5099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7432 - accuracy: 0.0156 - val_loss: 126.3721 - val_accuracy: 0.0588\n",
      "Epoch 5100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3241 - accuracy: 0.0156 - val_loss: 124.8450 - val_accuracy: 0.1176\n",
      "Epoch 5101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5065 - accuracy: 0.0000e+00 - val_loss: 126.2924 - val_accuracy: 0.0588\n",
      "Epoch 5102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2835 - accuracy: 0.0000e+00 - val_loss: 127.2842 - val_accuracy: 0.0588\n",
      "Epoch 5103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7290 - accuracy: 0.0156 - val_loss: 130.4154 - val_accuracy: 0.0588\n",
      "Epoch 5104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9169 - accuracy: 0.0000e+00 - val_loss: 124.1773 - val_accuracy: 0.0588\n",
      "Epoch 5105/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8557 - accuracy: 0.0000e+00 - val_loss: 120.2348 - val_accuracy: 0.0588\n",
      "Epoch 5106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2905 - accuracy: 0.0156 - val_loss: 122.4195 - val_accuracy: 0.0588\n",
      "Epoch 5107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2307 - accuracy: 0.0000e+00 - val_loss: 124.5643 - val_accuracy: 0.0588\n",
      "Epoch 5108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5959 - accuracy: 0.0000e+00 - val_loss: 126.8778 - val_accuracy: 0.0588\n",
      "Epoch 5109/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6923 - accuracy: 0.0156 - val_loss: 127.8305 - val_accuracy: 0.0588\n",
      "Epoch 5110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3117 - accuracy: 0.0000e+00 - val_loss: 128.4528 - val_accuracy: 0.0588\n",
      "Epoch 5111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8105 - accuracy: 0.0000e+00 - val_loss: 130.6227 - val_accuracy: 0.0588\n",
      "Epoch 5112/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 31.8418 - accuracy: 0.0156 - val_loss: 133.7731 - val_accuracy: 0.0588\n",
      "Epoch 5113/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5421 - accuracy: 0.0156 - val_loss: 129.3599 - val_accuracy: 0.0588\n",
      "Epoch 5114/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6601 - accuracy: 0.0000e+00 - val_loss: 123.1591 - val_accuracy: 0.0588\n",
      "Epoch 5115/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9239 - accuracy: 0.0312 - val_loss: 118.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5341 - accuracy: 0.0312 - val_loss: 115.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4304 - accuracy: 0.0000e+00 - val_loss: 116.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 5118/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.2266 - accuracy: 0.0156 - val_loss: 122.4815 - val_accuracy: 0.0000e+00\n",
      "Epoch 5119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5487 - accuracy: 0.0000e+00 - val_loss: 127.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 5120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8473 - accuracy: 0.0000e+00 - val_loss: 132.0536 - val_accuracy: 0.0588\n",
      "Epoch 5121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0215 - accuracy: 0.0156 - val_loss: 134.7985 - val_accuracy: 0.0588\n",
      "Epoch 5122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9194 - accuracy: 0.0312 - val_loss: 132.4414 - val_accuracy: 0.0588\n",
      "Epoch 5123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9051 - accuracy: 0.0000e+00 - val_loss: 135.0977 - val_accuracy: 0.0588\n",
      "Epoch 5124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8578 - accuracy: 0.0156 - val_loss: 133.8418 - val_accuracy: 0.0588\n",
      "Epoch 5125/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0194 - accuracy: 0.0312 - val_loss: 125.4687 - val_accuracy: 0.0588\n",
      "Epoch 5126/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6364 - accuracy: 0.0000e+00 - val_loss: 120.7464 - val_accuracy: 0.0588\n",
      "Epoch 5127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1823 - accuracy: 0.0000e+00 - val_loss: 123.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 5128/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5223 - accuracy: 0.0156 - val_loss: 127.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 5129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7012 - accuracy: 0.0000e+00 - val_loss: 122.5626 - val_accuracy: 0.0000e+00\n",
      "Epoch 5130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3738 - accuracy: 0.0000e+00 - val_loss: 113.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4643 - accuracy: 0.0156 - val_loss: 106.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5132/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8909 - accuracy: 0.0156 - val_loss: 103.5350 - val_accuracy: 0.0000e+00\n",
      "Epoch 5133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9224 - accuracy: 0.0000e+00 - val_loss: 108.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 5134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3912 - accuracy: 0.0312 - val_loss: 128.8589 - val_accuracy: 0.0000e+00\n",
      "Epoch 5135/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 30.3091 - accuracy: 0.0000e+0 - 0s 102us/step - loss: 29.0674 - accuracy: 0.0000e+00 - val_loss: 146.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8376 - accuracy: 0.0000e+00 - val_loss: 142.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 5137/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 49.2717 - accuracy: 0.0000e+00 - val_loss: 127.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 5138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4184 - accuracy: 0.0000e+00 - val_loss: 114.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 5139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 20.2972 - accuracy: 0.0000e+00 - val_loss: 108.3654 - val_accuracy: 0.0000e+00\n",
      "Epoch 5140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2279 - accuracy: 0.0312 - val_loss: 111.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 5141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6328 - accuracy: 0.0000e+00 - val_loss: 114.2821 - val_accuracy: 0.0000e+00\n",
      "Epoch 5142/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5815 - accuracy: 0.0156 - val_loss: 122.3666 - val_accuracy: 0.0000e+00\n",
      "Epoch 5143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2183 - accuracy: 0.0000e+00 - val_loss: 125.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 5144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9738 - accuracy: 0.0000e+00 - val_loss: 119.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 5145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2966 - accuracy: 0.0000e+00 - val_loss: 108.7337 - val_accuracy: 0.0588\n",
      "Epoch 5146/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8507 - accuracy: 0.0000e+00 - val_loss: 101.2826 - val_accuracy: 0.0588\n",
      "Epoch 5147/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 31.5192 - accuracy: 0.0000e+00 - val_loss: 107.0747 - val_accuracy: 0.0588\n",
      "Epoch 5148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8188 - accuracy: 0.0000e+00 - val_loss: 139.7275 - val_accuracy: 0.0588\n",
      "Epoch 5149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1449 - accuracy: 0.0000e+00 - val_loss: 150.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 5150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5455 - accuracy: 0.0000e+00 - val_loss: 132.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2328 - accuracy: 0.0000e+00 - val_loss: 121.9627 - val_accuracy: 0.1176\n",
      "Epoch 5152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8905 - accuracy: 0.0000e+00 - val_loss: 117.0729 - val_accuracy: 0.0588\n",
      "Epoch 5153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9968 - accuracy: 0.0156 - val_loss: 118.6366 - val_accuracy: 0.0588\n",
      "Epoch 5154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5385 - accuracy: 0.0156 - val_loss: 127.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5155/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.1181 - accuracy: 0.0156 - val_loss: 134.0459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2097 - accuracy: 0.0000e+00 - val_loss: 138.3056 - val_accuracy: 0.0000e+00\n",
      "Epoch 5157/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4850 - accuracy: 0.0000e+00 - val_loss: 136.8978 - val_accuracy: 0.0000e+00\n",
      "Epoch 5158/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 32.2921 - accuracy: 0.0000e+00 - val_loss: 135.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 5159/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.7119 - accuracy: 0.0000e+00 - val_loss: 144.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0872 - accuracy: 0.0000e+00 - val_loss: 147.1455 - val_accuracy: 0.0000e+00\n",
      "Epoch 5161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2915 - accuracy: 0.0156 - val_loss: 137.9619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4033 - accuracy: 0.0000e+00 - val_loss: 131.8343 - val_accuracy: 0.0000e+00\n",
      "Epoch 5163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.5637 - accuracy: 0.0156 - val_loss: 140.6540 - val_accuracy: 0.0000e+00\n",
      "Epoch 5164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7263 - accuracy: 0.0000e+00 - val_loss: 140.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 5165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5678 - accuracy: 0.0156 - val_loss: 134.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6883 - accuracy: 0.0156 - val_loss: 126.1032 - val_accuracy: 0.0000e+00\n",
      "Epoch 5167/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4392 - accuracy: 0.0000e+00 - val_loss: 122.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 5168/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 32.6634 - accuracy: 0.0000e+00 - val_loss: 124.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 5169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1021 - accuracy: 0.0000e+00 - val_loss: 128.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 5170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9757 - accuracy: 0.0000e+00 - val_loss: 128.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 5171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8881 - accuracy: 0.0156 - val_loss: 126.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 5172/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 22.1224 - accuracy: 0.0312 - val_loss: 121.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 5173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5404 - accuracy: 0.0156 - val_loss: 120.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 5174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6241 - accuracy: 0.0156 - val_loss: 121.6237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7332 - accuracy: 0.0156 - val_loss: 124.9237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5176/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6334 - accuracy: 0.0156 - val_loss: 123.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 5177/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.5062 - accuracy: 0.0156 - val_loss: 124.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3085 - accuracy: 0.0000e+00 - val_loss: 126.4903 - val_accuracy: 0.0000e+00\n",
      "Epoch 5179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2764 - accuracy: 0.0000e+00 - val_loss: 127.8918 - val_accuracy: 0.0000e+00\n",
      "Epoch 5180/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 28.0637 - accuracy: 0.0156 - val_loss: 128.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5181/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.1668 - accuracy: 0.0000e+00 - val_loss: 132.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 5182/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 30.8001 - accuracy: 0.0000e+00 - val_loss: 138.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 5183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6677 - accuracy: 0.0000e+00 - val_loss: 143.7113 - val_accuracy: 0.0000e+00\n",
      "Epoch 5184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1832 - accuracy: 0.0000e+00 - val_loss: 138.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1499 - accuracy: 0.0312 - val_loss: 132.2052 - val_accuracy: 0.0000e+00\n",
      "Epoch 5186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4177 - accuracy: 0.0000e+00 - val_loss: 126.3126 - val_accuracy: 0.0000e+00\n",
      "Epoch 5187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5935 - accuracy: 0.0000e+00 - val_loss: 123.1637 - val_accuracy: 0.0000e+00\n",
      "Epoch 5188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7731 - accuracy: 0.0156 - val_loss: 127.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 5189/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6437 - accuracy: 0.0000e+00 - val_loss: 137.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5190/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0419 - accuracy: 0.0000e+00 - val_loss: 137.2723 - val_accuracy: 0.0000e+00\n",
      "Epoch 5191/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 26.4432 - accuracy: 0.0000e+00 - val_loss: 134.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 5192/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 21.0325 - accuracy: 0.0000e+00 - val_loss: 129.7608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6079 - accuracy: 0.0000e+00 - val_loss: 130.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 5194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4829 - accuracy: 0.0000e+00 - val_loss: 127.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8693 - accuracy: 0.0312 - val_loss: 120.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 5196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3888 - accuracy: 0.0000e+00 - val_loss: 114.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4909 - accuracy: 0.0312 - val_loss: 111.8346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5198/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4807 - accuracy: 0.0000e+00 - val_loss: 119.3736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0848 - accuracy: 0.0000e+00 - val_loss: 122.7736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8273 - accuracy: 0.0312 - val_loss: 125.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 5201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7887 - accuracy: 0.0000e+00 - val_loss: 127.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5202/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 31.8924 - accuracy: 0.0000e+00 - val_loss: 126.7264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7746 - accuracy: 0.0469 - val_loss: 125.9491 - val_accuracy: 0.0588\n",
      "Epoch 5204/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 34.7307 - accuracy: 0.0156 - val_loss: 125.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 5205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7665 - accuracy: 0.0000e+00 - val_loss: 123.4485 - val_accuracy: 0.0000e+00\n",
      "Epoch 5206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1857 - accuracy: 0.0000e+00 - val_loss: 119.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 5207/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1783 - accuracy: 0.0000e+00 - val_loss: 106.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 5208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7465 - accuracy: 0.0000e+00 - val_loss: 102.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 5209/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.5206 - accuracy: 0.0156 - val_loss: 112.9410 - val_accuracy: 0.0000e+00\n",
      "Epoch 5210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7175 - accuracy: 0.0312 - val_loss: 133.3412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3794 - accuracy: 0.0156 - val_loss: 137.5593 - val_accuracy: 0.0588\n",
      "Epoch 5212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2204 - accuracy: 0.0000e+00 - val_loss: 134.1844 - val_accuracy: 0.0588\n",
      "Epoch 5213/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5248 - accuracy: 0.0156 - val_loss: 132.4024 - val_accuracy: 0.0588\n",
      "Epoch 5214/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 30.9068 - accuracy: 0.0469 - val_loss: 131.8937 - val_accuracy: 0.0588\n",
      "Epoch 5215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8435 - accuracy: 0.0000e+00 - val_loss: 135.2794 - val_accuracy: 0.0588\n",
      "Epoch 5216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4397 - accuracy: 0.0000e+00 - val_loss: 139.8160 - val_accuracy: 0.0588\n",
      "Epoch 5217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6936 - accuracy: 0.0000e+00 - val_loss: 139.4723 - val_accuracy: 0.0588\n",
      "Epoch 5218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9542 - accuracy: 0.0000e+00 - val_loss: 129.1225 - val_accuracy: 0.0588\n",
      "Epoch 5219/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6624 - accuracy: 0.0156 - val_loss: 120.8217 - val_accuracy: 0.0588\n",
      "Epoch 5220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1698 - accuracy: 0.0312 - val_loss: 117.4123 - val_accuracy: 0.0588\n",
      "Epoch 5221/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4503 - accuracy: 0.0000e+00 - val_loss: 117.2546 - val_accuracy: 0.0588\n",
      "Epoch 5222/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1956 - accuracy: 0.0000e+00 - val_loss: 111.4763 - val_accuracy: 0.0000e+00\n",
      "Epoch 5223/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7019 - accuracy: 0.0000e+00 - val_loss: 109.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 5224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1123 - accuracy: 0.0156 - val_loss: 114.1291 - val_accuracy: 0.0000e+00\n",
      "Epoch 5225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6310 - accuracy: 0.0000e+00 - val_loss: 123.6453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5226/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2350 - accuracy: 0.0000e+00 - val_loss: 134.3523 - val_accuracy: 0.0000e+00\n",
      "Epoch 5227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5380 - accuracy: 0.0000e+00 - val_loss: 142.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 5228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5685 - accuracy: 0.0156 - val_loss: 143.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 5229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2939 - accuracy: 0.0156 - val_loss: 139.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1277 - accuracy: 0.0000e+00 - val_loss: 132.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0985 - accuracy: 0.0156 - val_loss: 127.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 5232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1652 - accuracy: 0.0000e+00 - val_loss: 127.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4673 - accuracy: 0.0000e+00 - val_loss: 131.0901 - val_accuracy: 0.0000e+00\n",
      "Epoch 5234/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6718 - accuracy: 0.0000e+00 - val_loss: 127.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 5235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3831 - accuracy: 0.0156 - val_loss: 120.5639 - val_accuracy: 0.0588\n",
      "Epoch 5236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4981 - accuracy: 0.0156 - val_loss: 116.9414 - val_accuracy: 0.0588\n",
      "Epoch 5237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0660 - accuracy: 0.0000e+00 - val_loss: 112.5179 - val_accuracy: 0.1176\n",
      "Epoch 5238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1828 - accuracy: 0.0156 - val_loss: 109.2510 - val_accuracy: 0.0588\n",
      "Epoch 5239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3761 - accuracy: 0.0312 - val_loss: 112.3896 - val_accuracy: 0.0588\n",
      "Epoch 5240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7071 - accuracy: 0.0000e+00 - val_loss: 125.6951 - val_accuracy: 0.0588\n",
      "Epoch 5241/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0111 - accuracy: 0.0156 - val_loss: 142.3996 - val_accuracy: 0.0588\n",
      "Epoch 5242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7161 - accuracy: 0.0156 - val_loss: 152.7144 - val_accuracy: 0.0588\n",
      "Epoch 5243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6438 - accuracy: 0.0469 - val_loss: 150.8363 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4347 - accuracy: 0.0156 - val_loss: 146.2566 - val_accuracy: 0.0588\n",
      "Epoch 5245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9944 - accuracy: 0.0000e+00 - val_loss: 142.1284 - val_accuracy: 0.0000e+00\n",
      "Epoch 5246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6683 - accuracy: 0.0000e+00 - val_loss: 137.0933 - val_accuracy: 0.0000e+00\n",
      "Epoch 5247/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9726 - accuracy: 0.0000e+00 - val_loss: 135.6394 - val_accuracy: 0.0588\n",
      "Epoch 5248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7702 - accuracy: 0.0000e+00 - val_loss: 128.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2366 - accuracy: 0.0000e+00 - val_loss: 119.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1130 - accuracy: 0.0000e+00 - val_loss: 119.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 5251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6978 - accuracy: 0.0000e+00 - val_loss: 129.8661 - val_accuracy: 0.0000e+00\n",
      "Epoch 5252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7326 - accuracy: 0.0156 - val_loss: 133.0697 - val_accuracy: 0.0588\n",
      "Epoch 5253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0476 - accuracy: 0.0000e+00 - val_loss: 127.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8561 - accuracy: 0.0000e+00 - val_loss: 124.1233 - val_accuracy: 0.0000e+00\n",
      "Epoch 5255/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6759 - accuracy: 0.0156 - val_loss: 118.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6165 - accuracy: 0.0469 - val_loss: 114.7847 - val_accuracy: 0.0000e+00\n",
      "Epoch 5257/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.9681 - accuracy: 0.0156 - val_loss: 124.8765 - val_accuracy: 0.0000e+00\n",
      "Epoch 5258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7115 - accuracy: 0.0156 - val_loss: 134.3378 - val_accuracy: 0.0588\n",
      "Epoch 5259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9831 - accuracy: 0.0000e+00 - val_loss: 126.4705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6322 - accuracy: 0.0000e+00 - val_loss: 115.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 5261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9736 - accuracy: 0.0000e+00 - val_loss: 113.3302 - val_accuracy: 0.0000e+00\n",
      "Epoch 5262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3641 - accuracy: 0.0000e+00 - val_loss: 116.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7318 - accuracy: 0.0312 - val_loss: 122.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 5264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4534 - accuracy: 0.0156 - val_loss: 126.1719 - val_accuracy: 0.0588\n",
      "Epoch 5265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1271 - accuracy: 0.0000e+00 - val_loss: 130.1533 - val_accuracy: 0.0588\n",
      "Epoch 5266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0512 - accuracy: 0.0000e+00 - val_loss: 131.6356 - val_accuracy: 0.0588\n",
      "Epoch 5267/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0096 - accuracy: 0.0156 - val_loss: 138.1840 - val_accuracy: 0.0588\n",
      "Epoch 5268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4221 - accuracy: 0.0156 - val_loss: 136.2006 - val_accuracy: 0.0588\n",
      "Epoch 5269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4077 - accuracy: 0.0000e+00 - val_loss: 129.0468 - val_accuracy: 0.0588\n",
      "Epoch 5270/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0065 - accuracy: 0.0156 - val_loss: 121.5791 - val_accuracy: 0.1176\n",
      "Epoch 5271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6262 - accuracy: 0.0000e+00 - val_loss: 120.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5272/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5345 - accuracy: 0.0000e+00 - val_loss: 134.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 5273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5058 - accuracy: 0.0000e+00 - val_loss: 147.6005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5274/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6945 - accuracy: 0.0156 - val_loss: 150.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 5275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6870 - accuracy: 0.0156 - val_loss: 144.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7020 - accuracy: 0.0000e+00 - val_loss: 132.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 5277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8007 - accuracy: 0.0000e+00 - val_loss: 121.2591 - val_accuracy: 0.0000e+00\n",
      "Epoch 5278/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7207 - accuracy: 0.0000e+00 - val_loss: 118.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 5279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5926 - accuracy: 0.0000e+00 - val_loss: 130.6801 - val_accuracy: 0.0000e+00\n",
      "Epoch 5280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2945 - accuracy: 0.0000e+00 - val_loss: 146.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5281/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3865 - accuracy: 0.0312 - val_loss: 143.9652 - val_accuracy: 0.0000e+00\n",
      "Epoch 5282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2980 - accuracy: 0.0156 - val_loss: 134.8070 - val_accuracy: 0.0000e+00\n",
      "Epoch 5283/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1218 - accuracy: 0.0000e+00 - val_loss: 125.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7969 - accuracy: 0.0000e+00 - val_loss: 124.8367 - val_accuracy: 0.0000e+00\n",
      "Epoch 5285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1440 - accuracy: 0.0000e+00 - val_loss: 124.6197 - val_accuracy: 0.0000e+00\n",
      "Epoch 5286/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6994 - accuracy: 0.0312 - val_loss: 132.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 5287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6105 - accuracy: 0.0156 - val_loss: 142.4543 - val_accuracy: 0.0588\n",
      "Epoch 5288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3309 - accuracy: 0.0156 - val_loss: 144.6058 - val_accuracy: 0.0588\n",
      "Epoch 5289/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7505 - accuracy: 0.0625 - val_loss: 132.3165 - val_accuracy: 0.0588\n",
      "Epoch 5290/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9692 - accuracy: 0.0000e+00 - val_loss: 124.8355 - val_accuracy: 0.0000e+00\n",
      "Epoch 5291/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 23.6325 - accuracy: 0.0156 - val_loss: 124.9150 - val_accuracy: 0.0588\n",
      "Epoch 5292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1998 - accuracy: 0.0000e+00 - val_loss: 125.9162 - val_accuracy: 0.0588\n",
      "Epoch 5293/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0955 - accuracy: 0.0000e+00 - val_loss: 128.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 5294/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 29.5508 - accuracy: 0.0000e+00 - val_loss: 126.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 5295/10000\n",
      "64/64 [==============================] - 0s 453us/step - loss: 28.5393 - accuracy: 0.0000e+00 - val_loss: 115.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 5296/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4136 - accuracy: 0.0156 - val_loss: 116.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 5297/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.3562 - accuracy: 0.0000e+00 - val_loss: 117.8073 - val_accuracy: 0.0000e+00\n",
      "Epoch 5298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5438 - accuracy: 0.0312 - val_loss: 126.1650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9870 - accuracy: 0.0000e+00 - val_loss: 129.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4020 - accuracy: 0.0000e+00 - val_loss: 131.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 5301/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1178 - accuracy: 0.0000e+00 - val_loss: 133.8759 - val_accuracy: 0.0588\n",
      "Epoch 5302/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9096 - accuracy: 0.0156 - val_loss: 134.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 5303/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 43.5217 - accuracy: 0.0156 - val_loss: 129.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 5304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5991 - accuracy: 0.0000e+00 - val_loss: 125.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 5305/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.4317 - accuracy: 0.0000e+00 - val_loss: 120.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 5306/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 35.1623 - accuracy: 0.0000e+00 - val_loss: 118.6548 - val_accuracy: 0.0000e+00\n",
      "Epoch 5307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6112 - accuracy: 0.0000e+00 - val_loss: 117.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9737 - accuracy: 0.0156 - val_loss: 119.8433 - val_accuracy: 0.0000e+00\n",
      "Epoch 5309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7585 - accuracy: 0.0000e+00 - val_loss: 127.1858 - val_accuracy: 0.0000e+00\n",
      "Epoch 5310/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 30.5842 - accuracy: 0.0000e+00 - val_loss: 133.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 5311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4544 - accuracy: 0.0000e+00 - val_loss: 140.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 5312/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 31.4408 - accuracy: 0.0000e+00 - val_loss: 147.6668 - val_accuracy: 0.0000e+00\n",
      "Epoch 5313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1863 - accuracy: 0.0000e+00 - val_loss: 149.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 5314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3266 - accuracy: 0.0000e+00 - val_loss: 141.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 5315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1056 - accuracy: 0.0000e+00 - val_loss: 133.0492 - val_accuracy: 0.0000e+00\n",
      "Epoch 5316/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 31.7379 - accuracy: 0.0312 - val_loss: 123.0505 - val_accuracy: 0.0588\n",
      "Epoch 5317/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3000 - accuracy: 0.0156 - val_loss: 123.4018 - val_accuracy: 0.0588\n",
      "Epoch 5318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9437 - accuracy: 0.0000e+00 - val_loss: 131.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5319/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 36.6607 - accuracy: 0.0312 - val_loss: 139.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5320/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5238 - accuracy: 0.0469 - val_loss: 143.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 5321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4773 - accuracy: 0.0000e+00 - val_loss: 135.7157 - val_accuracy: 0.0000e+00\n",
      "Epoch 5322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2679 - accuracy: 0.0000e+00 - val_loss: 128.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5662 - accuracy: 0.0000e+00 - val_loss: 124.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1847 - accuracy: 0.0156 - val_loss: 130.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 5325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1430 - accuracy: 0.0156 - val_loss: 138.2021 - val_accuracy: 0.0588\n",
      "Epoch 5326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8470 - accuracy: 0.0000e+00 - val_loss: 144.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4968 - accuracy: 0.0156 - val_loss: 147.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8376 - accuracy: 0.0000e+00 - val_loss: 141.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5329/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 23.7259 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 36.0559 - accuracy: 0.0000e+00 - val_loss: 131.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 5330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2672 - accuracy: 0.0156 - val_loss: 123.3218 - val_accuracy: 0.0000e+00\n",
      "Epoch 5331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6549 - accuracy: 0.0000e+00 - val_loss: 120.9557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8449 - accuracy: 0.0312 - val_loss: 125.3307 - val_accuracy: 0.0000e+00\n",
      "Epoch 5333/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 37.8043 - accuracy: 0.0156 - val_loss: 129.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5334/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 42.0358 - accuracy: 0.0156 - val_loss: 138.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 5335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1909 - accuracy: 0.0000e+00 - val_loss: 140.9896 - val_accuracy: 0.0000e+00\n",
      "Epoch 5336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4727 - accuracy: 0.0000e+00 - val_loss: 136.4852 - val_accuracy: 0.0000e+00\n",
      "Epoch 5337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2783 - accuracy: 0.0000e+00 - val_loss: 128.9817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5338/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 34.0338 - accuracy: 0.0000e+00 - val_loss: 126.9950 - val_accuracy: 0.0000e+00\n",
      "Epoch 5339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3287 - accuracy: 0.0156 - val_loss: 129.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 5340/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8547 - accuracy: 0.0156 - val_loss: 124.8696 - val_accuracy: 0.0588\n",
      "Epoch 5341/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3413 - accuracy: 0.0000e+00 - val_loss: 120.2388 - val_accuracy: 0.0588\n",
      "Epoch 5342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6367 - accuracy: 0.0312 - val_loss: 119.5937 - val_accuracy: 0.0588\n",
      "Epoch 5343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2614 - accuracy: 0.0156 - val_loss: 117.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 5344/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 24.5230 - accuracy: 0.0312 - val_loss: 118.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 5345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4934 - accuracy: 0.0000e+00 - val_loss: 129.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 5346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4751 - accuracy: 0.0156 - val_loss: 141.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 5347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0020 - accuracy: 0.0000e+00 - val_loss: 133.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 5348/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 35.3921 - accuracy: 0.0156 - val_loss: 127.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 5349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2035 - accuracy: 0.0156 - val_loss: 125.7610 - val_accuracy: 0.0000e+00\n",
      "Epoch 5350/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 28.7625 - accuracy: 0.0156 - val_loss: 125.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 5351/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.5523 - accuracy: 0.031 - 0s 62us/step - loss: 44.1878 - accuracy: 0.0156 - val_loss: 130.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 5352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0934 - accuracy: 0.0000e+00 - val_loss: 140.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 5353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2818 - accuracy: 0.0000e+00 - val_loss: 155.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 5354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6665 - accuracy: 0.0156 - val_loss: 155.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 5355/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.7238 - accuracy: 0.0000e+00 - val_loss: 145.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1154 - accuracy: 0.0156 - val_loss: 127.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 5357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0871 - accuracy: 0.0156 - val_loss: 119.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 5358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.0844 - accuracy: 0.0000e+00 - val_loss: 121.4051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6727 - accuracy: 0.0000e+00 - val_loss: 125.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 5360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0580 - accuracy: 0.0000e+00 - val_loss: 121.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 5361/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5389 - accuracy: 0.0156 - val_loss: 123.1961 - val_accuracy: 0.0000e+00\n",
      "Epoch 5362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5394 - accuracy: 0.0156 - val_loss: 128.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 5363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1782 - accuracy: 0.0000e+00 - val_loss: 132.6674 - val_accuracy: 0.0588\n",
      "Epoch 5364/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.8124 - accuracy: 0.0000e+00 - val_loss: 128.1431 - val_accuracy: 0.0588\n",
      "Epoch 5365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0261 - accuracy: 0.0156 - val_loss: 132.0577 - val_accuracy: 0.0588\n",
      "Epoch 5366/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 30.5735 - accuracy: 0.0156 - val_loss: 139.5980 - val_accuracy: 0.0588\n",
      "Epoch 5367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7517 - accuracy: 0.0000e+00 - val_loss: 143.7604 - val_accuracy: 0.0588\n",
      "Epoch 5368/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0377 - accuracy: 0.0000e+00 - val_loss: 131.6118 - val_accuracy: 0.0588\n",
      "Epoch 5369/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.5343 - accuracy: 0.0000e+00 - val_loss: 122.0679 - val_accuracy: 0.0588\n",
      "Epoch 5370/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 23.6256 - accuracy: 0.0312 - val_loss: 121.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 5371/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 42.2746 - accuracy: 0.0156 - val_loss: 129.3663 - val_accuracy: 0.0000e+00\n",
      "Epoch 5372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5267 - accuracy: 0.0000e+00 - val_loss: 132.0572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3367 - accuracy: 0.0000e+00 - val_loss: 128.2963 - val_accuracy: 0.0000e+00\n",
      "Epoch 5374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8030 - accuracy: 0.0156 - val_loss: 123.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 5375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6445 - accuracy: 0.0156 - val_loss: 127.9720 - val_accuracy: 0.0000e+00\n",
      "Epoch 5376/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 18.1215 - accuracy: 0.0156 - val_loss: 132.9334 - val_accuracy: 0.0000e+00\n",
      "Epoch 5377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9360 - accuracy: 0.0000e+00 - val_loss: 131.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 5378/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 35.1928 - accuracy: 0.0000e+00 - val_loss: 134.3529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8264 - accuracy: 0.0000e+00 - val_loss: 139.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 5380/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2730 - accuracy: 0.0156 - val_loss: 141.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 5381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6358 - accuracy: 0.0000e+00 - val_loss: 136.3346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6896 - accuracy: 0.0156 - val_loss: 135.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 5383/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3071 - accuracy: 0.0000e+00 - val_loss: 131.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 5384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3920 - accuracy: 0.0156 - val_loss: 123.2203 - val_accuracy: 0.0588\n",
      "Epoch 5385/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4256 - accuracy: 0.0156 - val_loss: 121.2540 - val_accuracy: 0.0588\n",
      "Epoch 5386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1455 - accuracy: 0.0000e+00 - val_loss: 132.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5387/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 26.2361 - accuracy: 0.0156 - val_loss: 140.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 5388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7645 - accuracy: 0.0312 - val_loss: 141.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 5389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0567 - accuracy: 0.0156 - val_loss: 138.9342 - val_accuracy: 0.0000e+00\n",
      "Epoch 5390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3593 - accuracy: 0.0156 - val_loss: 133.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 5391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6209 - accuracy: 0.0312 - val_loss: 125.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 5392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9100 - accuracy: 0.0000e+00 - val_loss: 120.7693 - val_accuracy: 0.0000e+00\n",
      "Epoch 5393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2685 - accuracy: 0.0156 - val_loss: 122.8763 - val_accuracy: 0.0000e+00\n",
      "Epoch 5394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1022 - accuracy: 0.0469 - val_loss: 122.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 5395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2808 - accuracy: 0.0000e+00 - val_loss: 125.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 5396/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8515 - accuracy: 0.0156 - val_loss: 123.5848 - val_accuracy: 0.0000e+00\n",
      "Epoch 5397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8457 - accuracy: 0.0000e+00 - val_loss: 130.0516 - val_accuracy: 0.0588\n",
      "Epoch 5398/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 25.9523 - accuracy: 0.0156 - val_loss: 132.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 5399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9743 - accuracy: 0.0156 - val_loss: 129.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 5400/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5231 - accuracy: 0.0312 - val_loss: 126.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 5401/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.4536 - accuracy: 0.0000e+00 - val_loss: 125.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 5402/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 26.0161 - accuracy: 0.0000e+00 - val_loss: 125.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 5403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1455 - accuracy: 0.0312 - val_loss: 128.8844 - val_accuracy: 0.0000e+00\n",
      "Epoch 5404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5031 - accuracy: 0.0000e+00 - val_loss: 135.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 5405/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 30.9564 - accuracy: 0.0156 - val_loss: 130.1017 - val_accuracy: 0.0000e+00\n",
      "Epoch 5406/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9841 - accuracy: 0.0000e+00 - val_loss: 119.9833 - val_accuracy: 0.0000e+00\n",
      "Epoch 5407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0152 - accuracy: 0.0000e+00 - val_loss: 127.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5408/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 17.9421 - accuracy: 0.0156 - val_loss: 133.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 5409/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 38.5689 - accuracy: 0.0156 - val_loss: 131.7216 - val_accuracy: 0.0000e+00\n",
      "Epoch 5410/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 43.9222 - accuracy: 0.0156 - val_loss: 130.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8271 - accuracy: 0.0156 - val_loss: 130.9622 - val_accuracy: 0.0588\n",
      "Epoch 5412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9201 - accuracy: 0.0000e+00 - val_loss: 137.1941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5605 - accuracy: 0.0000e+00 - val_loss: 140.9693 - val_accuracy: 0.0000e+00\n",
      "Epoch 5414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9286 - accuracy: 0.0312 - val_loss: 144.7909 - val_accuracy: 0.0000e+00\n",
      "Epoch 5415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6506 - accuracy: 0.0000e+00 - val_loss: 145.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 5416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1664 - accuracy: 0.0000e+00 - val_loss: 134.3739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3320 - accuracy: 0.0156 - val_loss: 124.3111 - val_accuracy: 0.0000e+00\n",
      "Epoch 5418/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1708 - accuracy: 0.0000e+00 - val_loss: 121.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5419/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 21.3726 - accuracy: 0.0156 - val_loss: 119.1950 - val_accuracy: 0.0000e+00\n",
      "Epoch 5420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4338 - accuracy: 0.0000e+00 - val_loss: 117.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 5421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4104 - accuracy: 0.0312 - val_loss: 119.1125 - val_accuracy: 0.0588\n",
      "Epoch 5422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6479 - accuracy: 0.0000e+00 - val_loss: 117.4385 - val_accuracy: 0.0588\n",
      "Epoch 5423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7220 - accuracy: 0.0000e+00 - val_loss: 121.7658 - val_accuracy: 0.0588\n",
      "Epoch 5424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5455 - accuracy: 0.0000e+00 - val_loss: 133.7918 - val_accuracy: 0.0588\n",
      "Epoch 5425/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 29.3442 - accuracy: 0.0156 - val_loss: 142.6763 - val_accuracy: 0.0588\n",
      "Epoch 5426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3066 - accuracy: 0.0000e+00 - val_loss: 146.2336 - val_accuracy: 0.0588\n",
      "Epoch 5427/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.5765 - accuracy: 0.0000e+00 - val_loss: 147.3121 - val_accuracy: 0.0588\n",
      "Epoch 5428/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 34.0216 - accuracy: 0.0156 - val_loss: 146.9053 - val_accuracy: 0.0588\n",
      "Epoch 5429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3002 - accuracy: 0.0156 - val_loss: 133.8719 - val_accuracy: 0.0588\n",
      "Epoch 5430/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 19.3297 - accuracy: 0.0469 - val_loss: 125.3450 - val_accuracy: 0.0588\n",
      "Epoch 5431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7374 - accuracy: 0.0000e+00 - val_loss: 125.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 5432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1310 - accuracy: 0.0156 - val_loss: 129.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 5433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1175 - accuracy: 0.0156 - val_loss: 129.4041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9496 - accuracy: 0.0156 - val_loss: 124.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 5435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0423 - accuracy: 0.0000e+00 - val_loss: 114.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 5436/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9002 - accuracy: 0.0156 - val_loss: 119.6705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7185 - accuracy: 0.0000e+00 - val_loss: 130.5111 - val_accuracy: 0.0000e+00\n",
      "Epoch 5438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7347 - accuracy: 0.0000e+00 - val_loss: 139.6622 - val_accuracy: 0.0000e+00\n",
      "Epoch 5439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0509 - accuracy: 0.0156 - val_loss: 148.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5440/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.2523 - accuracy: 0.0156 - val_loss: 150.7968 - val_accuracy: 0.0000e+00\n",
      "Epoch 5441/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 29.4440 - accuracy: 0.0000e+00 - val_loss: 143.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 5442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3671 - accuracy: 0.0000e+00 - val_loss: 132.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 5443/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 30.5459 - accuracy: 0.0312 - val_loss: 121.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5444/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.4515 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.9990 - accuracy: 0.0000e+00 - val_loss: 126.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 5445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7609 - accuracy: 0.0000e+00 - val_loss: 130.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 5446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6224 - accuracy: 0.0000e+00 - val_loss: 123.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 5447/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1607 - accuracy: 0.0000e+00 - val_loss: 122.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 5448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6754 - accuracy: 0.0000e+00 - val_loss: 119.6087 - val_accuracy: 0.0000e+00\n",
      "Epoch 5449/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7424 - accuracy: 0.0000e+00 - val_loss: 116.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 5450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6252 - accuracy: 0.0156 - val_loss: 116.7721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8188 - accuracy: 0.0000e+00 - val_loss: 127.0619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5452/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 151us/step - loss: 32.4656 - accuracy: 0.0156 - val_loss: 136.5644 - val_accuracy: 0.0000e+00\n",
      "Epoch 5453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0031 - accuracy: 0.0000e+00 - val_loss: 142.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 5454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.6073 - accuracy: 0.0156 - val_loss: 143.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 5455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8713 - accuracy: 0.0156 - val_loss: 140.3900 - val_accuracy: 0.0000e+00\n",
      "Epoch 5456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7717 - accuracy: 0.0000e+00 - val_loss: 142.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 5457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5635 - accuracy: 0.0000e+00 - val_loss: 133.5260 - val_accuracy: 0.0000e+00\n",
      "Epoch 5458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0642 - accuracy: 0.0000e+00 - val_loss: 125.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 5459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6444 - accuracy: 0.0156 - val_loss: 124.2562 - val_accuracy: 0.0000e+00\n",
      "Epoch 5460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5073 - accuracy: 0.0000e+00 - val_loss: 135.3400 - val_accuracy: 0.0000e+00\n",
      "Epoch 5461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5535 - accuracy: 0.0000e+00 - val_loss: 150.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 5462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8146 - accuracy: 0.0312 - val_loss: 157.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 5463/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 37.3408 - accuracy: 0.0000e+00 - val_loss: 158.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 5464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1706 - accuracy: 0.0312 - val_loss: 151.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3324 - accuracy: 0.0312 - val_loss: 130.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5466/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3164 - accuracy: 0.0156 - val_loss: 116.0753 - val_accuracy: 0.0588\n",
      "Epoch 5467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1997 - accuracy: 0.0312 - val_loss: 117.4145 - val_accuracy: 0.0588\n",
      "Epoch 5468/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 27.7642 - accuracy: 0.0000e+00 - val_loss: 119.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3166 - accuracy: 0.0000e+00 - val_loss: 117.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 5470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4093 - accuracy: 0.0000e+00 - val_loss: 123.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 5471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6345 - accuracy: 0.0156 - val_loss: 127.3175 - val_accuracy: 0.0000e+00\n",
      "Epoch 5472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9795 - accuracy: 0.0156 - val_loss: 123.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 5473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9973 - accuracy: 0.0000e+00 - val_loss: 120.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 5474/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 32.5414 - accuracy: 0.0000e+00 - val_loss: 129.5381 - val_accuracy: 0.0588\n",
      "Epoch 5475/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1244 - accuracy: 0.0312 - val_loss: 134.9761 - val_accuracy: 0.0588\n",
      "Epoch 5476/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 42.2796 - accuracy: 0.0312 - val_loss: 136.5360 - val_accuracy: 0.0588\n",
      "Epoch 5477/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5338 - accuracy: 0.0156 - val_loss: 129.1989 - val_accuracy: 0.0588\n",
      "Epoch 5478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9253 - accuracy: 0.0000e+00 - val_loss: 123.8406 - val_accuracy: 0.0588\n",
      "Epoch 5479/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 40.6472 - accuracy: 0.0000e+00 - val_loss: 129.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 5480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9968 - accuracy: 0.0312 - val_loss: 138.2557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5481/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1023 - accuracy: 0.0000e+00 - val_loss: 128.5719 - val_accuracy: 0.0000e+00\n",
      "Epoch 5482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6799 - accuracy: 0.0156 - val_loss: 121.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 5483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4482 - accuracy: 0.0000e+00 - val_loss: 119.0902 - val_accuracy: 0.0588\n",
      "Epoch 5484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6785 - accuracy: 0.0312 - val_loss: 122.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 5485/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8799 - accuracy: 0.0000e+00 - val_loss: 130.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 5486/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 22.5910 - accuracy: 0.0000e+00 - val_loss: 141.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 5487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3236 - accuracy: 0.0469 - val_loss: 143.6549 - val_accuracy: 0.0000e+00\n",
      "Epoch 5488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5842 - accuracy: 0.0000e+00 - val_loss: 144.6452 - val_accuracy: 0.0588\n",
      "Epoch 5489/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 28.8460 - accuracy: 0.0000e+00 - val_loss: 141.3625 - val_accuracy: 0.0588\n",
      "Epoch 5490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4299 - accuracy: 0.0156 - val_loss: 134.5299 - val_accuracy: 0.0588\n",
      "Epoch 5491/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.7844 - accuracy: 0.0156 - val_loss: 132.2800 - val_accuracy: 0.0588\n",
      "Epoch 5492/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 26.9524 - accuracy: 0.0156 - val_loss: 134.1494 - val_accuracy: 0.0588\n",
      "Epoch 5493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4687 - accuracy: 0.0000e+00 - val_loss: 136.9075 - val_accuracy: 0.0588\n",
      "Epoch 5494/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2136 - accuracy: 0.0000e+00 - val_loss: 128.4189 - val_accuracy: 0.0588\n",
      "Epoch 5495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0314 - accuracy: 0.0000e+00 - val_loss: 116.8686 - val_accuracy: 0.0588\n",
      "Epoch 5496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4906 - accuracy: 0.0156 - val_loss: 109.4725 - val_accuracy: 0.0588\n",
      "Epoch 5497/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 34.4651 - accuracy: 0.0312 - val_loss: 109.7413 - val_accuracy: 0.0588\n",
      "Epoch 5498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3029 - accuracy: 0.0000e+00 - val_loss: 117.1901 - val_accuracy: 0.0588\n",
      "Epoch 5499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0737 - accuracy: 0.0000e+00 - val_loss: 126.4212 - val_accuracy: 0.0588\n",
      "Epoch 5500/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 33.1286 - accuracy: 0.0156 - val_loss: 128.5812 - val_accuracy: 0.0000e+00\n",
      "Epoch 5501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4146 - accuracy: 0.0000e+00 - val_loss: 137.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 5502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9922 - accuracy: 0.0156 - val_loss: 140.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5503/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4146 - accuracy: 0.0156 - val_loss: 132.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 5504/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8689 - accuracy: 0.0000e+00 - val_loss: 124.3671 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5505/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1102 - accuracy: 0.0156 - val_loss: 122.1548 - val_accuracy: 0.0588\n",
      "Epoch 5506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6799 - accuracy: 0.0000e+00 - val_loss: 125.9915 - val_accuracy: 0.0588\n",
      "Epoch 5507/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4661 - accuracy: 0.0000e+00 - val_loss: 125.8051 - val_accuracy: 0.0588\n",
      "Epoch 5508/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.5011 - accuracy: 0.0000e+00 - val_loss: 126.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 5509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6492 - accuracy: 0.0312 - val_loss: 125.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 5510/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 40.1675 - accuracy: 0.0000e+00 - val_loss: 122.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 5511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5246 - accuracy: 0.0000e+00 - val_loss: 128.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6706 - accuracy: 0.0000e+00 - val_loss: 134.8254 - val_accuracy: 0.0000e+00\n",
      "Epoch 5513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2959 - accuracy: 0.0000e+00 - val_loss: 137.2407 - val_accuracy: 0.0000e+00\n",
      "Epoch 5514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3675 - accuracy: 0.0000e+00 - val_loss: 138.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 5515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6611 - accuracy: 0.0156 - val_loss: 144.6194 - val_accuracy: 0.0588\n",
      "Epoch 5516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0435 - accuracy: 0.0000e+00 - val_loss: 135.9518 - val_accuracy: 0.0588\n",
      "Epoch 5517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3268 - accuracy: 0.0000e+00 - val_loss: 117.5718 - val_accuracy: 0.0588\n",
      "Epoch 5518/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.4578 - accuracy: 0.0000e+00 - val_loss: 117.1231 - val_accuracy: 0.1176\n",
      "Epoch 5519/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 34.7942 - accuracy: 0.0000e+00 - val_loss: 124.5594 - val_accuracy: 0.1176\n",
      "Epoch 5520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5752 - accuracy: 0.0000e+00 - val_loss: 138.8026 - val_accuracy: 0.0588\n",
      "Epoch 5521/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9714 - accuracy: 0.0000e+00 - val_loss: 143.9232 - val_accuracy: 0.0588\n",
      "Epoch 5522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5856 - accuracy: 0.0000e+00 - val_loss: 140.3849 - val_accuracy: 0.0588\n",
      "Epoch 5523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7958 - accuracy: 0.0156 - val_loss: 134.3818 - val_accuracy: 0.0588\n",
      "Epoch 5524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8822 - accuracy: 0.0156 - val_loss: 126.8789 - val_accuracy: 0.0588\n",
      "Epoch 5525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3821 - accuracy: 0.0000e+00 - val_loss: 120.9305 - val_accuracy: 0.0588\n",
      "Epoch 5526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9158 - accuracy: 0.0000e+00 - val_loss: 117.6798 - val_accuracy: 0.0588\n",
      "Epoch 5527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6845 - accuracy: 0.0000e+00 - val_loss: 119.7529 - val_accuracy: 0.0588\n",
      "Epoch 5528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7416 - accuracy: 0.0000e+00 - val_loss: 125.3562 - val_accuracy: 0.0588\n",
      "Epoch 5529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3738 - accuracy: 0.0000e+00 - val_loss: 131.2841 - val_accuracy: 0.0588\n",
      "Epoch 5530/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.6400 - accuracy: 0.0000e+00 - val_loss: 132.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 5531/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 21.9013 - accuracy: 0.0000e+00 - val_loss: 138.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1855 - accuracy: 0.0156 - val_loss: 139.8169 - val_accuracy: 0.0000e+00\n",
      "Epoch 5533/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 23.9603 - accuracy: 0.0156 - val_loss: 132.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 5534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3534 - accuracy: 0.0000e+00 - val_loss: 126.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 5535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6811 - accuracy: 0.0000e+00 - val_loss: 129.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 5536/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6151 - accuracy: 0.0000e+00 - val_loss: 133.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 5537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1475 - accuracy: 0.0156 - val_loss: 136.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 5538/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4895 - accuracy: 0.0000e+00 - val_loss: 136.7025 - val_accuracy: 0.0000e+00\n",
      "Epoch 5539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7613 - accuracy: 0.0156 - val_loss: 135.5513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8341 - accuracy: 0.0000e+00 - val_loss: 127.5831 - val_accuracy: 0.0588\n",
      "Epoch 5541/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.3216 - accuracy: 0.0156 - val_loss: 123.7849 - val_accuracy: 0.0588\n",
      "Epoch 5542/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 35.3729 - accuracy: 0.0000e+00 - val_loss: 124.3312 - val_accuracy: 0.0588\n",
      "Epoch 5543/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.3814 - accuracy: 0.0156 - val_loss: 129.5257 - val_accuracy: 0.0588\n",
      "Epoch 5544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3050 - accuracy: 0.0156 - val_loss: 135.5724 - val_accuracy: 0.0000e+00\n",
      "Epoch 5545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3077 - accuracy: 0.0312 - val_loss: 142.6810 - val_accuracy: 0.0000e+00\n",
      "Epoch 5546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6632 - accuracy: 0.0000e+00 - val_loss: 133.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 5547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1375 - accuracy: 0.0156 - val_loss: 119.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 5548/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6621 - accuracy: 0.0156 - val_loss: 108.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 5549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1777 - accuracy: 0.0000e+00 - val_loss: 108.3795 - val_accuracy: 0.0000e+00\n",
      "Epoch 5550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4527 - accuracy: 0.0156 - val_loss: 115.7746 - val_accuracy: 0.0000e+00\n",
      "Epoch 5551/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 43.3356 - accuracy: 0.0000e+00 - val_loss: 123.7116 - val_accuracy: 0.0000e+00\n",
      "Epoch 5552/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 25.3992 - accuracy: 0.0156 - val_loss: 128.9318 - val_accuracy: 0.0000e+00\n",
      "Epoch 5553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6600 - accuracy: 0.0156 - val_loss: 127.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5554/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8605 - accuracy: 0.0000e+00 - val_loss: 126.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 5555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7896 - accuracy: 0.0000e+00 - val_loss: 122.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 5556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3443 - accuracy: 0.0000e+00 - val_loss: 121.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 5557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2803 - accuracy: 0.0000e+00 - val_loss: 122.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 5558/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8596 - accuracy: 0.0156 - val_loss: 133.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 5559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4814 - accuracy: 0.0156 - val_loss: 131.0414 - val_accuracy: 0.0000e+00\n",
      "Epoch 5560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0005 - accuracy: 0.0312 - val_loss: 122.5739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5561/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3968 - accuracy: 0.0000e+00 - val_loss: 117.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8215 - accuracy: 0.0156 - val_loss: 116.4733 - val_accuracy: 0.0000e+00\n",
      "Epoch 5563/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 30.9250 - accuracy: 0.0000e+00 - val_loss: 119.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 5564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9145 - accuracy: 0.0156 - val_loss: 129.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 5565/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4504 - accuracy: 0.0156 - val_loss: 145.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 5566/10000\n",
      "64/64 [==============================] - 0s 56us/step - loss: 27.6577 - accuracy: 0.0156 - val_loss: 152.0598 - val_accuracy: 0.0000e+00\n",
      "Epoch 5567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3503 - accuracy: 0.0156 - val_loss: 150.7602 - val_accuracy: 0.0000e+00\n",
      "Epoch 5568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6754 - accuracy: 0.0469 - val_loss: 137.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6220 - accuracy: 0.0000e+00 - val_loss: 118.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 5570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4276 - accuracy: 0.0000e+00 - val_loss: 107.3226 - val_accuracy: 0.0588\n",
      "Epoch 5571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8638 - accuracy: 0.0000e+00 - val_loss: 109.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 5572/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9594 - accuracy: 0.0000e+00 - val_loss: 120.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 5573/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.6821 - accuracy: 0.0000e+00 - val_loss: 130.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 5574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8784 - accuracy: 0.0000e+00 - val_loss: 135.9059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1029 - accuracy: 0.0156 - val_loss: 128.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 5576/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5796 - accuracy: 0.0312 - val_loss: 122.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 5577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9833 - accuracy: 0.0000e+00 - val_loss: 128.0863 - val_accuracy: 0.0000e+00\n",
      "Epoch 5578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4741 - accuracy: 0.0312 - val_loss: 135.4479 - val_accuracy: 0.0000e+00\n",
      "Epoch 5579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1202 - accuracy: 0.0000e+00 - val_loss: 145.6507 - val_accuracy: 0.0000e+00\n",
      "Epoch 5580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9202 - accuracy: 0.0000e+00 - val_loss: 147.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 5581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3409 - accuracy: 0.0156 - val_loss: 136.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5582/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6950 - accuracy: 0.0312 - val_loss: 126.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 5583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4850 - accuracy: 0.0156 - val_loss: 123.6332 - val_accuracy: 0.0000e+00\n",
      "Epoch 5584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7346 - accuracy: 0.0156 - val_loss: 128.5648 - val_accuracy: 0.0000e+00\n",
      "Epoch 5585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5333 - accuracy: 0.0156 - val_loss: 131.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9525 - accuracy: 0.0156 - val_loss: 135.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 5587/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7203 - accuracy: 0.0156 - val_loss: 128.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5588/10000\n",
      "64/64 [==============================] - 0s 68us/step - loss: 42.5660 - accuracy: 0.0312 - val_loss: 124.2187 - val_accuracy: 0.0000e+00\n",
      "Epoch 5589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4635 - accuracy: 0.0156 - val_loss: 123.6067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1533 - accuracy: 0.0156 - val_loss: 124.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 5591/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9243 - accuracy: 0.0156 - val_loss: 121.1875 - val_accuracy: 0.0588\n",
      "Epoch 5592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3938 - accuracy: 0.0000e+00 - val_loss: 117.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 5593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2083 - accuracy: 0.0000e+00 - val_loss: 124.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5594/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.9811 - accuracy: 0.0312 - val_loss: 141.5939 - val_accuracy: 0.0000e+00\n",
      "Epoch 5595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3022 - accuracy: 0.0312 - val_loss: 143.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 5596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0953 - accuracy: 0.0000e+00 - val_loss: 134.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 5597/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 24.5994 - accuracy: 0.0000e+00 - val_loss: 121.1203 - val_accuracy: 0.0000e+00\n",
      "Epoch 5598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5845 - accuracy: 0.0156 - val_loss: 114.9320 - val_accuracy: 0.0000e+00\n",
      "Epoch 5599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7706 - accuracy: 0.0312 - val_loss: 114.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 5600/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7215 - accuracy: 0.0312 - val_loss: 122.7875 - val_accuracy: 0.0000e+00\n",
      "Epoch 5601/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0877 - accuracy: 0.0000e+00 - val_loss: 142.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5602/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.5886 - accuracy: 0.0000e+00 - val_loss: 151.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 5603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7984 - accuracy: 0.0156 - val_loss: 138.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 5604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9957 - accuracy: 0.0312 - val_loss: 130.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 5605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5460 - accuracy: 0.0156 - val_loss: 125.7444 - val_accuracy: 0.0588\n",
      "Epoch 5606/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4861 - accuracy: 0.0312 - val_loss: 122.1471 - val_accuracy: 0.0000e+00\n",
      "Epoch 5607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5784 - accuracy: 0.0000e+00 - val_loss: 118.9620 - val_accuracy: 0.0000e+00\n",
      "Epoch 5608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3870 - accuracy: 0.0000e+00 - val_loss: 114.7375 - val_accuracy: 0.0000e+00\n",
      "Epoch 5609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5664 - accuracy: 0.0156 - val_loss: 110.3582 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5610/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9194 - accuracy: 0.0156 - val_loss: 111.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 5611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2383 - accuracy: 0.0000e+00 - val_loss: 122.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 5612/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5843 - accuracy: 0.0156 - val_loss: 137.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 5613/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4936 - accuracy: 0.0000e+00 - val_loss: 138.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 5614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4017 - accuracy: 0.0000e+00 - val_loss: 128.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 5615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8805 - accuracy: 0.0312 - val_loss: 126.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2722 - accuracy: 0.0312 - val_loss: 125.5412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1409 - accuracy: 0.0000e+00 - val_loss: 121.7489 - val_accuracy: 0.0588\n",
      "Epoch 5618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8022 - accuracy: 0.0000e+00 - val_loss: 118.0789 - val_accuracy: 0.0588\n",
      "Epoch 5619/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 31.6762 - accuracy: 0.0156 - val_loss: 118.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2104 - accuracy: 0.0312 - val_loss: 124.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 5621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6183 - accuracy: 0.0156 - val_loss: 130.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 5622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5869 - accuracy: 0.0156 - val_loss: 127.8004 - val_accuracy: 0.0000e+00\n",
      "Epoch 5623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5056 - accuracy: 0.0000e+00 - val_loss: 123.7513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5920 - accuracy: 0.0000e+00 - val_loss: 124.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 5625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2727 - accuracy: 0.0156 - val_loss: 127.9621 - val_accuracy: 0.0000e+00\n",
      "Epoch 5626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9923 - accuracy: 0.0000e+00 - val_loss: 133.9553 - val_accuracy: 0.0000e+00\n",
      "Epoch 5627/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 43.4829 - accuracy: 0.0000e+00 - val_loss: 132.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2244 - accuracy: 0.0000e+00 - val_loss: 135.0865 - val_accuracy: 0.0588\n",
      "Epoch 5629/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2389 - accuracy: 0.0156 - val_loss: 134.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 5630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2796 - accuracy: 0.0000e+00 - val_loss: 130.4105 - val_accuracy: 0.0000e+00\n",
      "Epoch 5631/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.6499 - accuracy: 0.0000e+00 - val_loss: 125.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 5632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0932 - accuracy: 0.0000e+00 - val_loss: 123.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 5633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3215 - accuracy: 0.0312 - val_loss: 122.8003 - val_accuracy: 0.0588\n",
      "Epoch 5634/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1372 - accuracy: 0.0000e+00 - val_loss: 125.5926 - val_accuracy: 0.0588\n",
      "Epoch 5635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5827 - accuracy: 0.0156 - val_loss: 127.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 5636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4670 - accuracy: 0.0000e+00 - val_loss: 127.9608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5637/10000\n",
      "64/64 [==============================] - 0s 109us/step - loss: 30.9651 - accuracy: 0.0156 - val_loss: 127.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 5638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6225 - accuracy: 0.0000e+00 - val_loss: 127.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5639/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7697 - accuracy: 0.0000e+00 - val_loss: 125.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0653 - accuracy: 0.0000e+00 - val_loss: 121.7756 - val_accuracy: 0.0000e+00\n",
      "Epoch 5641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3111 - accuracy: 0.0156 - val_loss: 120.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5642/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4415 - accuracy: 0.0000e+00 - val_loss: 130.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 5643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6851 - accuracy: 0.0156 - val_loss: 139.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3661 - accuracy: 0.0000e+00 - val_loss: 137.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 5645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7383 - accuracy: 0.0000e+00 - val_loss: 127.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 5646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3653 - accuracy: 0.0000e+00 - val_loss: 123.8775 - val_accuracy: 0.0000e+00\n",
      "Epoch 5647/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.5315 - accuracy: 0.0156 - val_loss: 124.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 5648/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 24.4067 - accuracy: 0.0000e+00 - val_loss: 127.6917 - val_accuracy: 0.0588\n",
      "Epoch 5649/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.4882 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 39.6593 - accuracy: 0.0000e+00 - val_loss: 140.5058 - val_accuracy: 0.0588\n",
      "Epoch 5650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5729 - accuracy: 0.0156 - val_loss: 158.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 5651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2329 - accuracy: 0.0312 - val_loss: 165.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5652/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.8768 - accuracy: 0.0156 - val_loss: 158.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2068 - accuracy: 0.0000e+00 - val_loss: 146.9878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1276 - accuracy: 0.0156 - val_loss: 136.0496 - val_accuracy: 0.0588\n",
      "Epoch 5655/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4402 - accuracy: 0.0312 - val_loss: 129.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 5656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7880 - accuracy: 0.0156 - val_loss: 131.9696 - val_accuracy: 0.0000e+00\n",
      "Epoch 5657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1864 - accuracy: 0.0000e+00 - val_loss: 134.7122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5658/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 26.5471 - accuracy: 0.0156 - val_loss: 134.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 5659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9852 - accuracy: 0.0156 - val_loss: 125.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 5660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0611 - accuracy: 0.0000e+00 - val_loss: 121.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 5661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2147 - accuracy: 0.0000e+00 - val_loss: 131.5004 - val_accuracy: 0.0000e+00\n",
      "Epoch 5662/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.2407 - accuracy: 0.0000e+00 - val_loss: 141.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 5663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1667 - accuracy: 0.0156 - val_loss: 141.0538 - val_accuracy: 0.0000e+00\n",
      "Epoch 5664/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8255 - accuracy: 0.0156 - val_loss: 132.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 5665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3385 - accuracy: 0.0156 - val_loss: 128.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 5666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2767 - accuracy: 0.0000e+00 - val_loss: 127.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 5667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4895 - accuracy: 0.0000e+00 - val_loss: 136.8116 - val_accuracy: 0.0000e+00\n",
      "Epoch 5668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1641 - accuracy: 0.0156 - val_loss: 141.3026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5669/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 23.0006 - accuracy: 0.0000e+00 - val_loss: 143.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2231 - accuracy: 0.0000e+00 - val_loss: 141.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 5671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1114 - accuracy: 0.0000e+00 - val_loss: 145.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 5672/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 35.8552 - accuracy: 0.0000e+00 - val_loss: 144.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5673/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.2729 - accuracy: 0.0000e+00 - val_loss: 142.2753 - val_accuracy: 0.0000e+00\n",
      "Epoch 5674/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.6224 - accuracy: 0.0469 - val_loss: 138.4352 - val_accuracy: 0.0588\n",
      "Epoch 5675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9010 - accuracy: 0.0156 - val_loss: 142.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 5676/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 41.5825 - accuracy: 0.0000e+00 - val_loss: 141.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 5677/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 35.7423 - accuracy: 0.0000e+00 - val_loss: 133.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 5678/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9498 - accuracy: 0.0156 - val_loss: 128.8362 - val_accuracy: 0.0000e+00\n",
      "Epoch 5679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5668 - accuracy: 0.0156 - val_loss: 129.3557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5680/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.5694 - accuracy: 0.0000e+00 - val_loss: 131.5796 - val_accuracy: 0.0000e+00\n",
      "Epoch 5681/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1813 - accuracy: 0.0156 - val_loss: 134.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5682/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3395 - accuracy: 0.0000e+00 - val_loss: 131.2786 - val_accuracy: 0.0588\n",
      "Epoch 5683/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3170 - accuracy: 0.0000e+00 - val_loss: 127.7604 - val_accuracy: 0.0000e+00\n",
      "Epoch 5684/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7578 - accuracy: 0.0156 - val_loss: 128.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 5685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0751 - accuracy: 0.0156 - val_loss: 130.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 5686/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 41.1218 - accuracy: 0.0156 - val_loss: 133.4349 - val_accuracy: 0.0588\n",
      "Epoch 5687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.1204 - accuracy: 0.0000e+00 - val_loss: 131.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 5688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7042 - accuracy: 0.0312 - val_loss: 128.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 5689/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 30.3352 - accuracy: 0.0000e+00 - val_loss: 124.3362 - val_accuracy: 0.0000e+00\n",
      "Epoch 5690/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 31.2310 - accuracy: 0.0156 - val_loss: 124.7882 - val_accuracy: 0.0000e+00\n",
      "Epoch 5691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8137 - accuracy: 0.0156 - val_loss: 131.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5692/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.2227 - accuracy: 0.0312 - val_loss: 131.2787 - val_accuracy: 0.0000e+00\n",
      "Epoch 5693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0741 - accuracy: 0.0156 - val_loss: 128.9027 - val_accuracy: 0.0000e+00\n",
      "Epoch 5694/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8494 - accuracy: 0.0156 - val_loss: 125.1525 - val_accuracy: 0.0588\n",
      "Epoch 5695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9869 - accuracy: 0.0156 - val_loss: 132.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 5696/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6771 - accuracy: 0.0156 - val_loss: 137.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5697/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.6106 - accuracy: 0.0469 - val_loss: 140.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 5698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2842 - accuracy: 0.0156 - val_loss: 144.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 5699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5335 - accuracy: 0.0000e+00 - val_loss: 145.0592 - val_accuracy: 0.0000e+00\n",
      "Epoch 5700/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.4423 - accuracy: 0.0156 - val_loss: 140.6524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5701/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.7983 - accuracy: 0.0156 - val_loss: 136.2202 - val_accuracy: 0.0000e+00\n",
      "Epoch 5702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5450 - accuracy: 0.0000e+00 - val_loss: 130.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 5703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6200 - accuracy: 0.0000e+00 - val_loss: 123.7675 - val_accuracy: 0.0000e+00\n",
      "Epoch 5704/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.6408 - accuracy: 0.062 - 0s 125us/step - loss: 20.6543 - accuracy: 0.0469 - val_loss: 121.7681 - val_accuracy: 0.0000e+00\n",
      "Epoch 5705/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 24.8241 - accuracy: 0.0000e+00 - val_loss: 125.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 5706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3827 - accuracy: 0.0156 - val_loss: 128.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 5707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8403 - accuracy: 0.0000e+00 - val_loss: 126.7809 - val_accuracy: 0.0000e+00\n",
      "Epoch 5708/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 16.4964 - accuracy: 0.0312 - val_loss: 125.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 5709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1876 - accuracy: 0.0156 - val_loss: 126.0289 - val_accuracy: 0.0000e+00\n",
      "Epoch 5710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9266 - accuracy: 0.0312 - val_loss: 132.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 5711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7529 - accuracy: 0.0000e+00 - val_loss: 129.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 5712/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.5197 - accuracy: 0.0312 - val_loss: 118.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 5713/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 30.8816 - accuracy: 0.0000e+00 - val_loss: 109.9715 - val_accuracy: 0.0000e+00\n",
      "Epoch 5714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 21.5415 - accuracy: 0.0000e+00 - val_loss: 106.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5715/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.3695 - accuracy: 0.0156 - val_loss: 109.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 5716/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.0484 - accuracy: 0.0000e+00 - val_loss: 115.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 5717/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 30.8604 - accuracy: 0.0156 - val_loss: 133.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 5718/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 22.7296 - accuracy: 0.0156 - val_loss: 138.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 5719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7740 - accuracy: 0.0000e+00 - val_loss: 133.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 5720/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6193 - accuracy: 0.0000e+00 - val_loss: 130.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 5721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8741 - accuracy: 0.0312 - val_loss: 132.3937 - val_accuracy: 0.0000e+00\n",
      "Epoch 5722/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4197 - accuracy: 0.0156 - val_loss: 134.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 5723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7716 - accuracy: 0.0312 - val_loss: 136.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9085 - accuracy: 0.0000e+00 - val_loss: 136.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 5725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1640 - accuracy: 0.0469 - val_loss: 137.4776 - val_accuracy: 0.0000e+00\n",
      "Epoch 5726/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 36.2161 - accuracy: 0.031 - 0s 56us/step - loss: 31.7214 - accuracy: 0.0156 - val_loss: 132.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 5727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5156 - accuracy: 0.0312 - val_loss: 128.4619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5728/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6479 - accuracy: 0.0000e+00 - val_loss: 120.7234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2135 - accuracy: 0.0312 - val_loss: 119.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 5730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8670 - accuracy: 0.0000e+00 - val_loss: 130.0548 - val_accuracy: 0.0000e+00\n",
      "Epoch 5731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6675 - accuracy: 0.0312 - val_loss: 139.2304 - val_accuracy: 0.0000e+00\n",
      "Epoch 5732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9844 - accuracy: 0.0000e+00 - val_loss: 135.3348 - val_accuracy: 0.0000e+00\n",
      "Epoch 5733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9497 - accuracy: 0.0000e+00 - val_loss: 132.8834 - val_accuracy: 0.0000e+00\n",
      "Epoch 5734/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.5471 - accuracy: 0.0000e+0 - 0s 70us/step - loss: 27.8178 - accuracy: 0.0312 - val_loss: 131.1481 - val_accuracy: 0.0588\n",
      "Epoch 5735/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7691 - accuracy: 0.0000e+00 - val_loss: 129.2407 - val_accuracy: 0.1176\n",
      "Epoch 5736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.5061 - accuracy: 0.0000e+00 - val_loss: 131.4570 - val_accuracy: 0.1176\n",
      "Epoch 5737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4712 - accuracy: 0.0000e+00 - val_loss: 132.1462 - val_accuracy: 0.0588\n",
      "Epoch 5738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0253 - accuracy: 0.0000e+00 - val_loss: 143.8240 - val_accuracy: 0.0588\n",
      "Epoch 5739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9702 - accuracy: 0.0156 - val_loss: 152.2957 - val_accuracy: 0.0588\n",
      "Epoch 5740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7421 - accuracy: 0.0000e+00 - val_loss: 142.6071 - val_accuracy: 0.0588\n",
      "Epoch 5741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9818 - accuracy: 0.0000e+00 - val_loss: 123.9908 - val_accuracy: 0.0588\n",
      "Epoch 5742/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 34.3086 - accuracy: 0.0312 - val_loss: 121.6712 - val_accuracy: 0.0000e+00\n",
      "Epoch 5743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9481 - accuracy: 0.0000e+00 - val_loss: 134.2436 - val_accuracy: 0.0000e+00\n",
      "Epoch 5744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1403 - accuracy: 0.0000e+00 - val_loss: 141.5708 - val_accuracy: 0.0000e+00\n",
      "Epoch 5745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4270 - accuracy: 0.0156 - val_loss: 142.7774 - val_accuracy: 0.0000e+00\n",
      "Epoch 5746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7536 - accuracy: 0.0156 - val_loss: 137.0650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5747/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7373 - accuracy: 0.0000e+00 - val_loss: 131.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 5748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9368 - accuracy: 0.0000e+00 - val_loss: 128.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 5749/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9830 - accuracy: 0.0000e+00 - val_loss: 124.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0876 - accuracy: 0.0156 - val_loss: 120.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 5751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3012 - accuracy: 0.0000e+00 - val_loss: 120.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 5752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0941 - accuracy: 0.0000e+00 - val_loss: 112.9691 - val_accuracy: 0.0588\n",
      "Epoch 5753/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 30.5101 - accuracy: 0.0000e+00 - val_loss: 105.7762 - val_accuracy: 0.0588\n",
      "Epoch 5754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4178 - accuracy: 0.0156 - val_loss: 105.6732 - val_accuracy: 0.0588\n",
      "Epoch 5755/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 34.9929 - accuracy: 0.0000e+00 - val_loss: 111.9921 - val_accuracy: 0.0000e+00\n",
      "Epoch 5756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6022 - accuracy: 0.0156 - val_loss: 121.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 5757/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3095 - accuracy: 0.0000e+00 - val_loss: 131.1764 - val_accuracy: 0.0000e+00\n",
      "Epoch 5758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8115 - accuracy: 0.0156 - val_loss: 134.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 5759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1995 - accuracy: 0.0000e+00 - val_loss: 127.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 5760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1905 - accuracy: 0.0156 - val_loss: 118.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 5761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4200 - accuracy: 0.0156 - val_loss: 111.9052 - val_accuracy: 0.0588\n",
      "Epoch 5762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9193 - accuracy: 0.0156 - val_loss: 110.5473 - val_accuracy: 0.0588\n",
      "Epoch 5763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0218 - accuracy: 0.0156 - val_loss: 117.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 5764/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 36.9782 - accuracy: 0.0156 - val_loss: 127.3936 - val_accuracy: 0.0000e+00\n",
      "Epoch 5765/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2387 - accuracy: 0.0156 - val_loss: 135.8268 - val_accuracy: 0.0000e+00\n",
      "Epoch 5766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7309 - accuracy: 0.0000e+00 - val_loss: 132.3572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5767/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.6000 - accuracy: 0.0000e+00 - val_loss: 123.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 5768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9299 - accuracy: 0.0156 - val_loss: 119.5897 - val_accuracy: 0.0000e+00\n",
      "Epoch 5769/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 32.8291 - accuracy: 0.0156 - val_loss: 120.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 5770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4163 - accuracy: 0.0312 - val_loss: 125.6186 - val_accuracy: 0.0000e+00\n",
      "Epoch 5771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3520 - accuracy: 0.0000e+00 - val_loss: 130.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 5772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9295 - accuracy: 0.0156 - val_loss: 126.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 5773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9976 - accuracy: 0.0156 - val_loss: 125.6955 - val_accuracy: 0.0000e+00\n",
      "Epoch 5774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4725 - accuracy: 0.0000e+00 - val_loss: 126.5518 - val_accuracy: 0.0000e+00\n",
      "Epoch 5775/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 29.1379 - accuracy: 0.0000e+00 - val_loss: 124.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 5776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5124 - accuracy: 0.0000e+00 - val_loss: 118.8233 - val_accuracy: 0.0000e+00\n",
      "Epoch 5777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2461 - accuracy: 0.0000e+00 - val_loss: 112.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 5778/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9433 - accuracy: 0.0000e+00 - val_loss: 113.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3770 - accuracy: 0.0000e+00 - val_loss: 119.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5780/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 15.3013 - accuracy: 0.0000e+00 - val_loss: 124.4736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5781/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8056 - accuracy: 0.0312 - val_loss: 124.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 5782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0905 - accuracy: 0.0156 - val_loss: 121.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 5783/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.9755 - accuracy: 0.0312 - val_loss: 115.9915 - val_accuracy: 0.0000e+00\n",
      "Epoch 5784/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 33.0280 - accuracy: 0.0000e+00 - val_loss: 118.2794 - val_accuracy: 0.0000e+00\n",
      "Epoch 5785/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 22.3816 - accuracy: 0.0156 - val_loss: 120.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 5786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9033 - accuracy: 0.0000e+00 - val_loss: 125.6521 - val_accuracy: 0.0000e+00\n",
      "Epoch 5787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7921 - accuracy: 0.0000e+00 - val_loss: 128.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 5788/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 26.0366 - accuracy: 0.0156 - val_loss: 128.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 5789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7191 - accuracy: 0.0000e+00 - val_loss: 122.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 5790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2979 - accuracy: 0.0156 - val_loss: 117.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 5791/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 32.3562 - accuracy: 0.0000e+00 - val_loss: 112.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 5792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6529 - accuracy: 0.0156 - val_loss: 106.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 5793/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 25.3886 - accuracy: 0.0000e+00 - val_loss: 106.1996 - val_accuracy: 0.0588\n",
      "Epoch 5794/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3770 - accuracy: 0.0156 - val_loss: 107.6387 - val_accuracy: 0.0588\n",
      "Epoch 5795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5246 - accuracy: 0.0156 - val_loss: 114.1435 - val_accuracy: 0.0588\n",
      "Epoch 5796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0635 - accuracy: 0.0000e+00 - val_loss: 124.1308 - val_accuracy: 0.0588\n",
      "Epoch 5797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4959 - accuracy: 0.0000e+00 - val_loss: 135.4268 - val_accuracy: 0.0588\n",
      "Epoch 5798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5625 - accuracy: 0.0000e+00 - val_loss: 141.9417 - val_accuracy: 0.0588\n",
      "Epoch 5799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3402 - accuracy: 0.0000e+00 - val_loss: 139.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 5800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9824 - accuracy: 0.0000e+00 - val_loss: 131.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3708 - accuracy: 0.0000e+00 - val_loss: 123.2413 - val_accuracy: 0.0000e+00\n",
      "Epoch 5802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5275 - accuracy: 0.0000e+00 - val_loss: 117.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 5803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9784 - accuracy: 0.0000e+00 - val_loss: 114.9511 - val_accuracy: 0.0000e+00\n",
      "Epoch 5804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1025 - accuracy: 0.0000e+00 - val_loss: 117.5041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6660 - accuracy: 0.0000e+00 - val_loss: 127.3050 - val_accuracy: 0.0588\n",
      "Epoch 5806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3837 - accuracy: 0.0156 - val_loss: 134.1830 - val_accuracy: 0.0000e+00\n",
      "Epoch 5807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9705 - accuracy: 0.0000e+00 - val_loss: 131.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 5808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6640 - accuracy: 0.0000e+00 - val_loss: 127.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9015 - accuracy: 0.0156 - val_loss: 125.3453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6476 - accuracy: 0.0000e+00 - val_loss: 122.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 5811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0613 - accuracy: 0.0156 - val_loss: 121.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 5812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7824 - accuracy: 0.0156 - val_loss: 129.7751 - val_accuracy: 0.0588\n",
      "Epoch 5813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8301 - accuracy: 0.0000e+00 - val_loss: 130.2993 - val_accuracy: 0.0588\n",
      "Epoch 5814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1018 - accuracy: 0.0000e+00 - val_loss: 122.2314 - val_accuracy: 0.0588\n",
      "Epoch 5815/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4324 - accuracy: 0.0000e+00 - val_loss: 114.9807 - val_accuracy: 0.0588\n",
      "Epoch 5816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1712 - accuracy: 0.0000e+00 - val_loss: 112.7208 - val_accuracy: 0.0588\n",
      "Epoch 5817/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7518 - accuracy: 0.0000e+00 - val_loss: 116.3091 - val_accuracy: 0.0000e+00\n",
      "Epoch 5818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 74us/step - loss: 36.6499 - accuracy: 0.0000e+00 - val_loss: 123.3102 - val_accuracy: 0.0588\n",
      "Epoch 5819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6970 - accuracy: 0.0000e+00 - val_loss: 129.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 5820/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.4303 - accuracy: 0.0156 - val_loss: 127.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 5821/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2823 - accuracy: 0.0000e+00 - val_loss: 124.8954 - val_accuracy: 0.0000e+00\n",
      "Epoch 5822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7577 - accuracy: 0.0000e+00 - val_loss: 129.2142 - val_accuracy: 0.0000e+00\n",
      "Epoch 5823/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 20.0492 - accuracy: 0.0000e+00 - val_loss: 130.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2245 - accuracy: 0.0156 - val_loss: 125.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 5825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8248 - accuracy: 0.0156 - val_loss: 121.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 5826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5785 - accuracy: 0.0156 - val_loss: 126.0354 - val_accuracy: 0.0000e+00\n",
      "Epoch 5827/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.6424 - accuracy: 0.0156 - val_loss: 131.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 5828/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 38.5038 - accuracy: 0.0156 - val_loss: 135.5264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5829/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2063 - accuracy: 0.0312 - val_loss: 132.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4454 - accuracy: 0.0625 - val_loss: 132.3897 - val_accuracy: 0.0000e+00\n",
      "Epoch 5831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7200 - accuracy: 0.0000e+00 - val_loss: 128.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 5832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8899 - accuracy: 0.0000e+00 - val_loss: 122.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 5833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1094 - accuracy: 0.0156 - val_loss: 116.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 5834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4100 - accuracy: 0.0000e+00 - val_loss: 114.8085 - val_accuracy: 0.0000e+00\n",
      "Epoch 5835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6994 - accuracy: 0.0000e+00 - val_loss: 115.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 5836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8938 - accuracy: 0.0000e+00 - val_loss: 127.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 5837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4905 - accuracy: 0.0156 - val_loss: 138.9326 - val_accuracy: 0.0000e+00\n",
      "Epoch 5838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3031 - accuracy: 0.0156 - val_loss: 144.9432 - val_accuracy: 0.0000e+00\n",
      "Epoch 5839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6506 - accuracy: 0.0000e+00 - val_loss: 143.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 5840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9259 - accuracy: 0.0000e+00 - val_loss: 143.0277 - val_accuracy: 0.0000e+00\n",
      "Epoch 5841/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0967 - accuracy: 0.0000e+00 - val_loss: 141.7989 - val_accuracy: 0.0000e+00\n",
      "Epoch 5842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2528 - accuracy: 0.0312 - val_loss: 137.8547 - val_accuracy: 0.0588\n",
      "Epoch 5843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6539 - accuracy: 0.0000e+00 - val_loss: 141.1733 - val_accuracy: 0.0588\n",
      "Epoch 5844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3391 - accuracy: 0.0312 - val_loss: 145.6499 - val_accuracy: 0.0588\n",
      "Epoch 5845/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3936 - accuracy: 0.0000e+00 - val_loss: 148.8891 - val_accuracy: 0.0588\n",
      "Epoch 5846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0449 - accuracy: 0.0156 - val_loss: 140.0226 - val_accuracy: 0.0588\n",
      "Epoch 5847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1793 - accuracy: 0.0156 - val_loss: 132.2346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3266 - accuracy: 0.0000e+00 - val_loss: 124.9779 - val_accuracy: 0.0588\n",
      "Epoch 5849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0844 - accuracy: 0.0000e+00 - val_loss: 122.5735 - val_accuracy: 0.0000e+00\n",
      "Epoch 5850/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2781 - accuracy: 0.0000e+00 - val_loss: 124.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3493 - accuracy: 0.0000e+00 - val_loss: 137.7862 - val_accuracy: 0.0588\n",
      "Epoch 5852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9939 - accuracy: 0.0156 - val_loss: 140.4689 - val_accuracy: 0.0588\n",
      "Epoch 5853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2610 - accuracy: 0.0156 - val_loss: 136.8670 - val_accuracy: 0.0588\n",
      "Epoch 5854/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3861 - accuracy: 0.0156 - val_loss: 136.8363 - val_accuracy: 0.0588\n",
      "Epoch 5855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2960 - accuracy: 0.0156 - val_loss: 130.5350 - val_accuracy: 0.0588\n",
      "Epoch 5856/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9367 - accuracy: 0.0156 - val_loss: 120.1404 - val_accuracy: 0.0588\n",
      "Epoch 5857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8887 - accuracy: 0.0156 - val_loss: 114.1176 - val_accuracy: 0.1176\n",
      "Epoch 5858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1909 - accuracy: 0.0156 - val_loss: 117.3015 - val_accuracy: 0.0588\n",
      "Epoch 5859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6029 - accuracy: 0.0000e+00 - val_loss: 128.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 5860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6207 - accuracy: 0.0156 - val_loss: 136.6557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1911 - accuracy: 0.0000e+00 - val_loss: 138.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 5862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1316 - accuracy: 0.0312 - val_loss: 136.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 5863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3364 - accuracy: 0.0000e+00 - val_loss: 126.4182 - val_accuracy: 0.0000e+00\n",
      "Epoch 5864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5439 - accuracy: 0.0156 - val_loss: 120.0842 - val_accuracy: 0.0588\n",
      "Epoch 5865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0014 - accuracy: 0.0156 - val_loss: 121.7418 - val_accuracy: 0.0588\n",
      "Epoch 5866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3931 - accuracy: 0.0156 - val_loss: 129.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 5867/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7715 - accuracy: 0.0156 - val_loss: 135.7451 - val_accuracy: 0.0588\n",
      "Epoch 5868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2924 - accuracy: 0.0000e+00 - val_loss: 136.4084 - val_accuracy: 0.0588\n",
      "Epoch 5869/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7835 - accuracy: 0.0000e+00 - val_loss: 130.2957 - val_accuracy: 0.0588\n",
      "Epoch 5870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1348 - accuracy: 0.0156 - val_loss: 125.6718 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5871/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0129 - accuracy: 0.0156 - val_loss: 125.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5872/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.0233 - accuracy: 0.0156 - val_loss: 131.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 5873/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 36.7872 - accuracy: 0.0156 - val_loss: 145.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 5874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1556 - accuracy: 0.0156 - val_loss: 153.3032 - val_accuracy: 0.0000e+00\n",
      "Epoch 5875/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.0529 - accuracy: 0.0000e+00 - val_loss: 151.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 5876/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 38.6622 - accuracy: 0.0000e+00 - val_loss: 149.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 5877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9393 - accuracy: 0.0156 - val_loss: 135.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 5878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6397 - accuracy: 0.0000e+00 - val_loss: 123.9411 - val_accuracy: 0.0588\n",
      "Epoch 5879/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 32.1490 - accuracy: 0.0000e+00 - val_loss: 120.6619 - val_accuracy: 0.0588\n",
      "Epoch 5880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5980 - accuracy: 0.0156 - val_loss: 128.2130 - val_accuracy: 0.0588\n",
      "Epoch 5881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4048 - accuracy: 0.0000e+00 - val_loss: 131.1670 - val_accuracy: 0.0588\n",
      "Epoch 5882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.6198 - accuracy: 0.0312 - val_loss: 122.3732 - val_accuracy: 0.0000e+00\n",
      "Epoch 5883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2098 - accuracy: 0.0000e+00 - val_loss: 113.9890 - val_accuracy: 0.0588\n",
      "Epoch 5884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4677 - accuracy: 0.0000e+00 - val_loss: 111.5024 - val_accuracy: 0.0588\n",
      "Epoch 5885/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.7852 - accuracy: 0.0312 - val_loss: 111.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 5886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3648 - accuracy: 0.0156 - val_loss: 111.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 5887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8560 - accuracy: 0.0156 - val_loss: 108.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 5888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2576 - accuracy: 0.0312 - val_loss: 111.9595 - val_accuracy: 0.0000e+00\n",
      "Epoch 5889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0872 - accuracy: 0.0156 - val_loss: 119.0917 - val_accuracy: 0.0588\n",
      "Epoch 5890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2403 - accuracy: 0.0000e+00 - val_loss: 129.2728 - val_accuracy: 0.0588\n",
      "Epoch 5891/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7503 - accuracy: 0.0156 - val_loss: 139.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 5892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6375 - accuracy: 0.0156 - val_loss: 142.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 5893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.2001 - accuracy: 0.0156 - val_loss: 136.3011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4412 - accuracy: 0.0000e+00 - val_loss: 127.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 5895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7437 - accuracy: 0.0156 - val_loss: 125.3031 - val_accuracy: 0.0588\n",
      "Epoch 5896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2171 - accuracy: 0.0000e+00 - val_loss: 131.8498 - val_accuracy: 0.0000e+00\n",
      "Epoch 5897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9807 - accuracy: 0.0000e+00 - val_loss: 137.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 5898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5089 - accuracy: 0.0156 - val_loss: 139.8581 - val_accuracy: 0.0000e+00\n",
      "Epoch 5899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3687 - accuracy: 0.0000e+00 - val_loss: 132.6995 - val_accuracy: 0.0000e+00\n",
      "Epoch 5900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9668 - accuracy: 0.0156 - val_loss: 118.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 5901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4796 - accuracy: 0.0000e+00 - val_loss: 110.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 5902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0900 - accuracy: 0.0000e+00 - val_loss: 109.3317 - val_accuracy: 0.0000e+00\n",
      "Epoch 5903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2922 - accuracy: 0.0000e+00 - val_loss: 127.0456 - val_accuracy: 0.0000e+00\n",
      "Epoch 5904/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.9359 - accuracy: 0.0000e+00 - val_loss: 143.7391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8224 - accuracy: 0.0156 - val_loss: 147.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 5906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1993 - accuracy: 0.0156 - val_loss: 148.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 5907/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5498 - accuracy: 0.0000e+00 - val_loss: 142.3532 - val_accuracy: 0.0000e+00\n",
      "Epoch 5908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7004 - accuracy: 0.0000e+00 - val_loss: 138.8386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9732 - accuracy: 0.0156 - val_loss: 135.7881 - val_accuracy: 0.0000e+00\n",
      "Epoch 5910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4437 - accuracy: 0.0156 - val_loss: 135.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 5911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4217 - accuracy: 0.0000e+00 - val_loss: 132.5032 - val_accuracy: 0.0588\n",
      "Epoch 5912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2453 - accuracy: 0.0156 - val_loss: 128.8812 - val_accuracy: 0.0588\n",
      "Epoch 5913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6289 - accuracy: 0.0156 - val_loss: 125.8777 - val_accuracy: 0.0588\n",
      "Epoch 5914/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7341 - accuracy: 0.0000e+00 - val_loss: 123.7722 - val_accuracy: 0.0588\n",
      "Epoch 5915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6099 - accuracy: 0.0312 - val_loss: 114.3724 - val_accuracy: 0.0588\n",
      "Epoch 5916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5350 - accuracy: 0.0312 - val_loss: 109.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5917/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 30.6034 - accuracy: 0.0000e+00 - val_loss: 118.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3773 - accuracy: 0.0156 - val_loss: 127.8126 - val_accuracy: 0.0000e+00\n",
      "Epoch 5919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0457 - accuracy: 0.0000e+00 - val_loss: 128.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 5920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7071 - accuracy: 0.0156 - val_loss: 125.8441 - val_accuracy: 0.0588\n",
      "Epoch 5921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9821 - accuracy: 0.0000e+00 - val_loss: 127.4569 - val_accuracy: 0.0588\n",
      "Epoch 5922/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 34.1431 - accuracy: 0.0156 - val_loss: 132.3512 - val_accuracy: 0.0588\n",
      "Epoch 5923/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6914 - accuracy: 0.0000e+00 - val_loss: 137.6294 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6074 - accuracy: 0.0000e+00 - val_loss: 139.8447 - val_accuracy: 0.0588\n",
      "Epoch 5925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6829 - accuracy: 0.0312 - val_loss: 135.5025 - val_accuracy: 0.0588\n",
      "Epoch 5926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6770 - accuracy: 0.0312 - val_loss: 132.8520 - val_accuracy: 0.0588\n",
      "Epoch 5927/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 33.0535 - accuracy: 0.0156 - val_loss: 131.2137 - val_accuracy: 0.0588\n",
      "Epoch 5928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2617 - accuracy: 0.0000e+00 - val_loss: 129.0251 - val_accuracy: 0.0588\n",
      "Epoch 5929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0597 - accuracy: 0.0312 - val_loss: 127.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 5930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9742 - accuracy: 0.0000e+00 - val_loss: 131.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 5931/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 41.7358 - accuracy: 0.0000e+00 - val_loss: 136.8279 - val_accuracy: 0.0000e+00\n",
      "Epoch 5932/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3345 - accuracy: 0.0000e+00 - val_loss: 135.9160 - val_accuracy: 0.0588\n",
      "Epoch 5933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6121 - accuracy: 0.0156 - val_loss: 136.3733 - val_accuracy: 0.0588\n",
      "Epoch 5934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5197 - accuracy: 0.0000e+00 - val_loss: 138.1032 - val_accuracy: 0.1176\n",
      "Epoch 5935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2617 - accuracy: 0.0156 - val_loss: 137.3277 - val_accuracy: 0.0588\n",
      "Epoch 5936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7570 - accuracy: 0.0000e+00 - val_loss: 138.5240 - val_accuracy: 0.0000e+00\n",
      "Epoch 5937/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 19.9242 - accuracy: 0.0000e+00 - val_loss: 137.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7390 - accuracy: 0.0000e+00 - val_loss: 132.2679 - val_accuracy: 0.0588\n",
      "Epoch 5939/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 20.7819 - accuracy: 0.031 - 0s 97us/step - loss: 29.0366 - accuracy: 0.0156 - val_loss: 123.7280 - val_accuracy: 0.0588\n",
      "Epoch 5940/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 25.7665 - accuracy: 0.0000e+00 - val_loss: 120.3478 - val_accuracy: 0.0588\n",
      "Epoch 5941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1772 - accuracy: 0.0156 - val_loss: 124.4391 - val_accuracy: 0.0588\n",
      "Epoch 5942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5044 - accuracy: 0.0156 - val_loss: 131.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 5943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7282 - accuracy: 0.0156 - val_loss: 141.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 5944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8657 - accuracy: 0.0000e+00 - val_loss: 147.4094 - val_accuracy: 0.0000e+00\n",
      "Epoch 5945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3445 - accuracy: 0.0000e+00 - val_loss: 143.7550 - val_accuracy: 0.0000e+00\n",
      "Epoch 5946/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.1873 - accuracy: 0.0156 - val_loss: 136.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0699 - accuracy: 0.0000e+00 - val_loss: 127.8577 - val_accuracy: 0.0588\n",
      "Epoch 5948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0136 - accuracy: 0.0000e+00 - val_loss: 126.2529 - val_accuracy: 0.0588\n",
      "Epoch 5949/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 21.6489 - accuracy: 0.0000e+00 - val_loss: 120.0388 - val_accuracy: 0.0588\n",
      "Epoch 5950/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 28.1214 - accuracy: 0.0000e+00 - val_loss: 116.8581 - val_accuracy: 0.0588\n",
      "Epoch 5951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9486 - accuracy: 0.0156 - val_loss: 117.6727 - val_accuracy: 0.0588\n",
      "Epoch 5952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5104 - accuracy: 0.0156 - val_loss: 120.2059 - val_accuracy: 0.0588\n",
      "Epoch 5953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4188 - accuracy: 0.0000e+00 - val_loss: 123.5321 - val_accuracy: 0.0588\n",
      "Epoch 5954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5085 - accuracy: 0.0000e+00 - val_loss: 129.3792 - val_accuracy: 0.0588\n",
      "Epoch 5955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5261 - accuracy: 0.0000e+00 - val_loss: 129.8121 - val_accuracy: 0.0588\n",
      "Epoch 5956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4415 - accuracy: 0.0312 - val_loss: 125.3856 - val_accuracy: 0.0588\n",
      "Epoch 5957/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5019 - accuracy: 0.0000e+00 - val_loss: 131.3719 - val_accuracy: 0.0588\n",
      "Epoch 5958/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 24.0674 - accuracy: 0.0156 - val_loss: 136.0228 - val_accuracy: 0.0588\n",
      "Epoch 5959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9477 - accuracy: 0.0312 - val_loss: 135.4907 - val_accuracy: 0.0588\n",
      "Epoch 5960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4876 - accuracy: 0.0156 - val_loss: 123.1417 - val_accuracy: 0.0588\n",
      "Epoch 5961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7223 - accuracy: 0.0000e+00 - val_loss: 115.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 5962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6752 - accuracy: 0.0156 - val_loss: 113.3212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7797 - accuracy: 0.0000e+00 - val_loss: 124.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 5964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1516 - accuracy: 0.0000e+00 - val_loss: 141.3477 - val_accuracy: 0.0000e+00\n",
      "Epoch 5965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7953 - accuracy: 0.0156 - val_loss: 152.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 5966/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5735 - accuracy: 0.0156 - val_loss: 145.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 5967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1457 - accuracy: 0.0000e+00 - val_loss: 138.6668 - val_accuracy: 0.0000e+00\n",
      "Epoch 5968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3329 - accuracy: 0.0000e+00 - val_loss: 127.8759 - val_accuracy: 0.0588\n",
      "Epoch 5969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0369 - accuracy: 0.0000e+00 - val_loss: 123.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 5970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0600 - accuracy: 0.0156 - val_loss: 127.0027 - val_accuracy: 0.0588\n",
      "Epoch 5971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0930 - accuracy: 0.0156 - val_loss: 136.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 5972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9976 - accuracy: 0.0312 - val_loss: 145.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5986 - accuracy: 0.0000e+00 - val_loss: 148.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 5974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2186 - accuracy: 0.0000e+00 - val_loss: 141.1086 - val_accuracy: 0.0000e+00\n",
      "Epoch 5975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6440 - accuracy: 0.0156 - val_loss: 129.4647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4407 - accuracy: 0.0000e+00 - val_loss: 128.5394 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9560 - accuracy: 0.0156 - val_loss: 130.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6916 - accuracy: 0.0000e+00 - val_loss: 137.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 5979/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6450 - accuracy: 0.0312 - val_loss: 142.3016 - val_accuracy: 0.0000e+00\n",
      "Epoch 5980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0380 - accuracy: 0.0000e+00 - val_loss: 148.2796 - val_accuracy: 0.0000e+00\n",
      "Epoch 5981/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7472 - accuracy: 0.0000e+00 - val_loss: 142.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5982/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4911 - accuracy: 0.0000e+00 - val_loss: 132.3308 - val_accuracy: 0.0000e+00\n",
      "Epoch 5983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5114 - accuracy: 0.0000e+00 - val_loss: 121.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 5984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1387 - accuracy: 0.0156 - val_loss: 119.7558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5985/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8199 - accuracy: 0.0000e+00 - val_loss: 125.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 5986/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0305 - accuracy: 0.0625 - val_loss: 132.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 5987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1449 - accuracy: 0.0000e+00 - val_loss: 133.8228 - val_accuracy: 0.0000e+00\n",
      "Epoch 5988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0120 - accuracy: 0.0000e+00 - val_loss: 132.3415 - val_accuracy: 0.0000e+00\n",
      "Epoch 5989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7839 - accuracy: 0.0469 - val_loss: 133.5928 - val_accuracy: 0.0588\n",
      "Epoch 5990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9797 - accuracy: 0.0156 - val_loss: 140.8633 - val_accuracy: 0.0588\n",
      "Epoch 5991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1514 - accuracy: 0.0000e+00 - val_loss: 139.5397 - val_accuracy: 0.0588\n",
      "Epoch 5992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1453 - accuracy: 0.0000e+00 - val_loss: 140.7541 - val_accuracy: 0.0588\n",
      "Epoch 5993/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9976 - accuracy: 0.0312 - val_loss: 140.9387 - val_accuracy: 0.0000e+00\n",
      "Epoch 5994/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1749 - accuracy: 0.0000e+00 - val_loss: 140.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5995/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.0714 - accuracy: 0.0312 - val_loss: 132.9931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5996/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 25.9033 - accuracy: 0.0156 - val_loss: 123.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 5997/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 27.7869 - accuracy: 0.0312 - val_loss: 126.2372 - val_accuracy: 0.0000e+00\n",
      "Epoch 5998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8273 - accuracy: 0.0156 - val_loss: 135.3857 - val_accuracy: 0.0588\n",
      "Epoch 5999/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 32.1999 - accuracy: 0.0000e+00 - val_loss: 140.3900 - val_accuracy: 0.0588\n",
      "Epoch 6000/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 30.1715 - accuracy: 0.0156 - val_loss: 137.3134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6001/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.0279 - accuracy: 0.0000e+00 - val_loss: 131.8832 - val_accuracy: 0.0588\n",
      "Epoch 6002/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 33.8234 - accuracy: 0.0156 - val_loss: 126.6591 - val_accuracy: 0.0588\n",
      "Epoch 6003/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 26.1932 - accuracy: 0.0000e+00 - val_loss: 128.1120 - val_accuracy: 0.0588\n",
      "Epoch 6004/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 26.4543 - accuracy: 0.0000e+00 - val_loss: 130.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 6005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0158 - accuracy: 0.0000e+00 - val_loss: 129.9505 - val_accuracy: 0.0000e+00\n",
      "Epoch 6006/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 20.7924 - accuracy: 0.0000e+00 - val_loss: 117.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 6007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2137 - accuracy: 0.0156 - val_loss: 120.4972 - val_accuracy: 0.0588\n",
      "Epoch 6008/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3526 - accuracy: 0.0000e+00 - val_loss: 127.6661 - val_accuracy: 0.0588\n",
      "Epoch 6009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1145 - accuracy: 0.0000e+00 - val_loss: 139.1438 - val_accuracy: 0.0588\n",
      "Epoch 6010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4481 - accuracy: 0.0000e+00 - val_loss: 145.0682 - val_accuracy: 0.0588\n",
      "Epoch 6011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5306 - accuracy: 0.0312 - val_loss: 136.7424 - val_accuracy: 0.0588\n",
      "Epoch 6012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2315 - accuracy: 0.0000e+00 - val_loss: 131.4878 - val_accuracy: 0.0588\n",
      "Epoch 6013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9917 - accuracy: 0.0156 - val_loss: 130.5126 - val_accuracy: 0.1176\n",
      "Epoch 6014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6683 - accuracy: 0.0000e+00 - val_loss: 132.3676 - val_accuracy: 0.0588\n",
      "Epoch 6015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5898 - accuracy: 0.0156 - val_loss: 139.3578 - val_accuracy: 0.0588\n",
      "Epoch 6016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0187 - accuracy: 0.0312 - val_loss: 147.3806 - val_accuracy: 0.0588\n",
      "Epoch 6017/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3900 - accuracy: 0.0156 - val_loss: 137.3584 - val_accuracy: 0.0588\n",
      "Epoch 6018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2423 - accuracy: 0.0000e+00 - val_loss: 128.7104 - val_accuracy: 0.1176\n",
      "Epoch 6019/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0534 - accuracy: 0.0000e+00 - val_loss: 124.5535 - val_accuracy: 0.0588\n",
      "Epoch 6020/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3989 - accuracy: 0.0000e+00 - val_loss: 127.8340 - val_accuracy: 0.0588\n",
      "Epoch 6021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1169 - accuracy: 0.0156 - val_loss: 131.4279 - val_accuracy: 0.1176\n",
      "Epoch 6022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0647 - accuracy: 0.0000e+00 - val_loss: 133.1188 - val_accuracy: 0.1176\n",
      "Epoch 6023/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0267 - accuracy: 0.0156 - val_loss: 132.2258 - val_accuracy: 0.1176\n",
      "Epoch 6024/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2264 - accuracy: 0.0000e+00 - val_loss: 129.9165 - val_accuracy: 0.1176\n",
      "Epoch 6025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3034 - accuracy: 0.0000e+00 - val_loss: 128.2572 - val_accuracy: 0.1176\n",
      "Epoch 6026/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2470 - accuracy: 0.0000e+00 - val_loss: 126.5798 - val_accuracy: 0.0588\n",
      "Epoch 6027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2568 - accuracy: 0.0000e+00 - val_loss: 129.8072 - val_accuracy: 0.0588\n",
      "Epoch 6028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5353 - accuracy: 0.0000e+00 - val_loss: 133.1541 - val_accuracy: 0.0588\n",
      "Epoch 6029/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 42.6771 - accuracy: 0.0156 - val_loss: 133.8542 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6030/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.3664 - accuracy: 0.0469 - val_loss: 136.9678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1560 - accuracy: 0.0000e+00 - val_loss: 144.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6032/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.3954 - accuracy: 0.0000e+00 - val_loss: 147.9522 - val_accuracy: 0.0000e+00\n",
      "Epoch 6033/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.1804 - accuracy: 0.0000e+00 - val_loss: 143.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6034/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 24.7604 - accuracy: 0.0000e+00 - val_loss: 131.6500 - val_accuracy: 0.0588\n",
      "Epoch 6035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6186 - accuracy: 0.0156 - val_loss: 122.6100 - val_accuracy: 0.0588\n",
      "Epoch 6036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7206 - accuracy: 0.0000e+00 - val_loss: 117.1700 - val_accuracy: 0.0588\n",
      "Epoch 6037/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 19.2457 - accuracy: 0.0000e+00 - val_loss: 116.1734 - val_accuracy: 0.0588\n",
      "Epoch 6038/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5752 - accuracy: 0.0000e+00 - val_loss: 126.8543 - val_accuracy: 0.0588\n",
      "Epoch 6039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4745 - accuracy: 0.0156 - val_loss: 134.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 6040/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 28.3360 - accuracy: 0.0156 - val_loss: 134.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 6041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0552 - accuracy: 0.0000e+00 - val_loss: 132.6153 - val_accuracy: 0.0000e+00\n",
      "Epoch 6042/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2417 - accuracy: 0.0000e+00 - val_loss: 128.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 6043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0812 - accuracy: 0.0000e+00 - val_loss: 122.2026 - val_accuracy: 0.0000e+00\n",
      "Epoch 6044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2575 - accuracy: 0.0000e+00 - val_loss: 115.2653 - val_accuracy: 0.0588\n",
      "Epoch 6045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5015 - accuracy: 0.0000e+00 - val_loss: 113.9052 - val_accuracy: 0.0588\n",
      "Epoch 6046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9571 - accuracy: 0.0000e+00 - val_loss: 119.2571 - val_accuracy: 0.0588\n",
      "Epoch 6047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3485 - accuracy: 0.0000e+00 - val_loss: 125.8454 - val_accuracy: 0.0588\n",
      "Epoch 6048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5142 - accuracy: 0.0156 - val_loss: 131.9256 - val_accuracy: 0.0588\n",
      "Epoch 6049/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1929 - accuracy: 0.0156 - val_loss: 131.8705 - val_accuracy: 0.0588\n",
      "Epoch 6050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1034 - accuracy: 0.0000e+00 - val_loss: 137.7044 - val_accuracy: 0.0588\n",
      "Epoch 6051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0984 - accuracy: 0.0156 - val_loss: 140.1025 - val_accuracy: 0.0588\n",
      "Epoch 6052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2022 - accuracy: 0.0000e+00 - val_loss: 147.4531 - val_accuracy: 0.0588\n",
      "Epoch 6053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3002 - accuracy: 0.0156 - val_loss: 141.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 6054/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3896 - accuracy: 0.0000e+00 - val_loss: 136.3834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6055/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.3698 - accuracy: 0.0000e+00 - val_loss: 131.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9125 - accuracy: 0.0000e+00 - val_loss: 129.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 6057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4707 - accuracy: 0.0156 - val_loss: 129.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 6058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2056 - accuracy: 0.0469 - val_loss: 126.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 6059/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9387 - accuracy: 0.0000e+00 - val_loss: 122.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 6060/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8481 - accuracy: 0.0156 - val_loss: 118.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0237 - accuracy: 0.0312 - val_loss: 121.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 6062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3922 - accuracy: 0.0156 - val_loss: 123.7410 - val_accuracy: 0.0000e+00\n",
      "Epoch 6063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7025 - accuracy: 0.0156 - val_loss: 119.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 6064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1292 - accuracy: 0.0000e+00 - val_loss: 124.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3990 - accuracy: 0.0469 - val_loss: 123.8653 - val_accuracy: 0.0000e+00\n",
      "Epoch 6066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9435 - accuracy: 0.0000e+00 - val_loss: 120.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 6067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9228 - accuracy: 0.0312 - val_loss: 129.5895 - val_accuracy: 0.0000e+00\n",
      "Epoch 6068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.1130 - accuracy: 0.0469 - val_loss: 135.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 6069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1395 - accuracy: 0.0000e+00 - val_loss: 123.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1311 - accuracy: 0.0000e+00 - val_loss: 111.2827 - val_accuracy: 0.0000e+00\n",
      "Epoch 6071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1373 - accuracy: 0.0000e+00 - val_loss: 106.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 6072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9110 - accuracy: 0.0156 - val_loss: 110.3728 - val_accuracy: 0.0000e+00\n",
      "Epoch 6073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2912 - accuracy: 0.0000e+00 - val_loss: 116.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 6074/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2099 - accuracy: 0.0156 - val_loss: 117.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 6075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7851 - accuracy: 0.0000e+00 - val_loss: 114.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 6076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5438 - accuracy: 0.0000e+00 - val_loss: 117.7660 - val_accuracy: 0.0000e+00\n",
      "Epoch 6077/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2731 - accuracy: 0.0000e+00 - val_loss: 125.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 6078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3826 - accuracy: 0.0156 - val_loss: 132.3068 - val_accuracy: 0.0000e+00\n",
      "Epoch 6079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2964 - accuracy: 0.0156 - val_loss: 130.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 6080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6209 - accuracy: 0.0156 - val_loss: 122.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 6081/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5439 - accuracy: 0.0000e+00 - val_loss: 118.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 6082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4589 - accuracy: 0.0000e+00 - val_loss: 122.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 6083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4692 - accuracy: 0.0000e+00 - val_loss: 130.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 6084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3338 - accuracy: 0.0000e+00 - val_loss: 131.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5074 - accuracy: 0.0156 - val_loss: 118.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 6086/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3788 - accuracy: 0.0000e+00 - val_loss: 111.3443 - val_accuracy: 0.0000e+00\n",
      "Epoch 6087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6190 - accuracy: 0.0000e+00 - val_loss: 116.7742 - val_accuracy: 0.0588\n",
      "Epoch 6088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0051 - accuracy: 0.0156 - val_loss: 128.1568 - val_accuracy: 0.0588\n",
      "Epoch 6089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2890 - accuracy: 0.0156 - val_loss: 136.1527 - val_accuracy: 0.0588\n",
      "Epoch 6090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9170 - accuracy: 0.0000e+00 - val_loss: 124.8119 - val_accuracy: 0.0588\n",
      "Epoch 6091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8190 - accuracy: 0.0000e+00 - val_loss: 118.1565 - val_accuracy: 0.0588\n",
      "Epoch 6092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8339 - accuracy: 0.0000e+00 - val_loss: 115.2189 - val_accuracy: 0.1176\n",
      "Epoch 6093/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 49.2254 - accuracy: 0.0156 - val_loss: 113.8703 - val_accuracy: 0.1176\n",
      "Epoch 6094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1540 - accuracy: 0.0000e+00 - val_loss: 119.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 6095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5581 - accuracy: 0.0156 - val_loss: 129.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 6096/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7524 - accuracy: 0.0000e+00 - val_loss: 138.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 6097/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1696 - accuracy: 0.0000e+00 - val_loss: 147.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 6098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2001 - accuracy: 0.0156 - val_loss: 144.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 6099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5595 - accuracy: 0.0312 - val_loss: 132.2508 - val_accuracy: 0.0000e+00\n",
      "Epoch 6100/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 23.5110 - accuracy: 0.0156 - val_loss: 125.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 6101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8704 - accuracy: 0.0000e+00 - val_loss: 126.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4929 - accuracy: 0.0000e+00 - val_loss: 123.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 6103/10000\n",
      "64/64 [==============================] - 0s 169us/step - loss: 24.5787 - accuracy: 0.0156 - val_loss: 124.1997 - val_accuracy: 0.0000e+00\n",
      "Epoch 6104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8434 - accuracy: 0.0156 - val_loss: 127.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 6105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7239 - accuracy: 0.0000e+00 - val_loss: 122.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 6106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.9091 - accuracy: 0.0000e+00 - val_loss: 118.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 6107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5103 - accuracy: 0.0469 - val_loss: 113.9692 - val_accuracy: 0.0000e+00\n",
      "Epoch 6108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0121 - accuracy: 0.0000e+00 - val_loss: 108.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4295 - accuracy: 0.0156 - val_loss: 104.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 6110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2170 - accuracy: 0.0000e+00 - val_loss: 105.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 6111/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6257 - accuracy: 0.0000e+00 - val_loss: 119.6617 - val_accuracy: 0.0000e+00\n",
      "Epoch 6112/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6303 - accuracy: 0.0000e+00 - val_loss: 134.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 6113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6642 - accuracy: 0.0156 - val_loss: 136.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 6114/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2509 - accuracy: 0.0156 - val_loss: 131.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 6115/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 33.5140 - accuracy: 0.0000e+00 - val_loss: 125.3711 - val_accuracy: 0.0588\n",
      "Epoch 6116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7943 - accuracy: 0.0312 - val_loss: 122.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 6117/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9591 - accuracy: 0.0156 - val_loss: 119.3511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3906 - accuracy: 0.0000e+00 - val_loss: 125.7187 - val_accuracy: 0.0000e+00\n",
      "Epoch 6119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5823 - accuracy: 0.0000e+00 - val_loss: 131.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 6120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4463 - accuracy: 0.0156 - val_loss: 131.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 6121/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6390 - accuracy: 0.0000e+00 - val_loss: 128.7194 - val_accuracy: 0.0000e+00\n",
      "Epoch 6122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3491 - accuracy: 0.0000e+00 - val_loss: 129.3833 - val_accuracy: 0.0000e+00\n",
      "Epoch 6123/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0646 - accuracy: 0.0000e+00 - val_loss: 132.8652 - val_accuracy: 0.0000e+00\n",
      "Epoch 6124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4719 - accuracy: 0.0000e+00 - val_loss: 130.9672 - val_accuracy: 0.0000e+00\n",
      "Epoch 6125/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 27.9312 - accuracy: 0.0000e+00 - val_loss: 130.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 6126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.1571 - accuracy: 0.0156 - val_loss: 127.0422 - val_accuracy: 0.0000e+00\n",
      "Epoch 6127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7954 - accuracy: 0.0156 - val_loss: 127.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7660 - accuracy: 0.0000e+00 - val_loss: 138.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 6129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2445 - accuracy: 0.0156 - val_loss: 144.9339 - val_accuracy: 0.0000e+00\n",
      "Epoch 6130/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.8080 - accuracy: 0.0156 - val_loss: 138.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 6131/10000\n",
      "64/64 [==============================] - 0s 204us/step - loss: 25.2684 - accuracy: 0.0000e+00 - val_loss: 139.6808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6132/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7091 - accuracy: 0.0156 - val_loss: 141.5906 - val_accuracy: 0.0588\n",
      "Epoch 6133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4858 - accuracy: 0.0156 - val_loss: 139.8093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 30.7099 - accuracy: 0.0156 - val_loss: 141.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 6135/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 39.6252 - accuracy: 0.0000e+00 - val_loss: 140.1349 - val_accuracy: 0.0588\n",
      "Epoch 6136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8815 - accuracy: 0.0156 - val_loss: 139.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6137/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 18.7181 - accuracy: 0.0000e+00 - val_loss: 134.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 6138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0392 - accuracy: 0.0000e+00 - val_loss: 127.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 6139/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 27.7053 - accuracy: 0.0156 - val_loss: 130.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6140/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 40.8239 - accuracy: 0.0000e+00 - val_loss: 132.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 6141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7762 - accuracy: 0.0156 - val_loss: 122.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 6142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5739 - accuracy: 0.0000e+00 - val_loss: 116.6593 - val_accuracy: 0.0000e+00\n",
      "Epoch 6143/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0535 - accuracy: 0.0156 - val_loss: 122.0375 - val_accuracy: 0.0000e+00\n",
      "Epoch 6144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0642 - accuracy: 0.0156 - val_loss: 129.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 6145/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4090 - accuracy: 0.0156 - val_loss: 135.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 6146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3583 - accuracy: 0.0156 - val_loss: 138.8111 - val_accuracy: 0.0000e+00\n",
      "Epoch 6147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6147 - accuracy: 0.0156 - val_loss: 143.1393 - val_accuracy: 0.0588\n",
      "Epoch 6148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8259 - accuracy: 0.0000e+00 - val_loss: 149.8855 - val_accuracy: 0.0588\n",
      "Epoch 6149/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5193 - accuracy: 0.0000e+00 - val_loss: 153.4155 - val_accuracy: 0.0588\n",
      "Epoch 6150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4304 - accuracy: 0.0156 - val_loss: 146.6185 - val_accuracy: 0.0588\n",
      "Epoch 6151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3981 - accuracy: 0.0156 - val_loss: 139.8076 - val_accuracy: 0.0000e+00\n",
      "Epoch 6152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9465 - accuracy: 0.0000e+00 - val_loss: 136.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 6153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6117 - accuracy: 0.0000e+00 - val_loss: 133.4063 - val_accuracy: 0.0000e+00\n",
      "Epoch 6154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6506 - accuracy: 0.0000e+00 - val_loss: 130.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 6155/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.2011 - accuracy: 0.0156 - val_loss: 119.8543 - val_accuracy: 0.0000e+00\n",
      "Epoch 6156/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.2292 - accuracy: 0.0000e+00 - val_loss: 109.3107 - val_accuracy: 0.0000e+00\n",
      "Epoch 6157/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 28.6857 - accuracy: 0.0156 - val_loss: 104.2760 - val_accuracy: 0.0000e+00\n",
      "Epoch 6158/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9055 - accuracy: 0.0000e+00 - val_loss: 115.7937 - val_accuracy: 0.0000e+00\n",
      "Epoch 6159/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2639 - accuracy: 0.0156 - val_loss: 136.3354 - val_accuracy: 0.0588\n",
      "Epoch 6160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9024 - accuracy: 0.0000e+00 - val_loss: 134.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 6161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4746 - accuracy: 0.0156 - val_loss: 130.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 6162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6373 - accuracy: 0.0000e+00 - val_loss: 136.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 6163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0737 - accuracy: 0.0000e+00 - val_loss: 140.9840 - val_accuracy: 0.0000e+00\n",
      "Epoch 6164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.1393 - accuracy: 0.0312 - val_loss: 138.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 6165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2039 - accuracy: 0.0156 - val_loss: 128.2823 - val_accuracy: 0.0000e+00\n",
      "Epoch 6166/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 26.2367 - accuracy: 0.0000e+00 - val_loss: 118.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 6167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8556 - accuracy: 0.0000e+00 - val_loss: 110.6814 - val_accuracy: 0.0000e+00\n",
      "Epoch 6168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6308 - accuracy: 0.0156 - val_loss: 116.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 6169/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2854 - accuracy: 0.0312 - val_loss: 129.7402 - val_accuracy: 0.0000e+00\n",
      "Epoch 6170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6056 - accuracy: 0.0156 - val_loss: 127.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 6171/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1215 - accuracy: 0.0000e+00 - val_loss: 126.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2169 - accuracy: 0.0000e+00 - val_loss: 129.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 6173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2509 - accuracy: 0.0156 - val_loss: 133.2887 - val_accuracy: 0.0588\n",
      "Epoch 6174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7212 - accuracy: 0.0156 - val_loss: 138.4267 - val_accuracy: 0.0588\n",
      "Epoch 6175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4330 - accuracy: 0.0000e+00 - val_loss: 142.5428 - val_accuracy: 0.0588\n",
      "Epoch 6176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9911 - accuracy: 0.0156 - val_loss: 145.2825 - val_accuracy: 0.0588\n",
      "Epoch 6177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6550 - accuracy: 0.0000e+00 - val_loss: 141.7472 - val_accuracy: 0.0588\n",
      "Epoch 6178/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1065 - accuracy: 0.0000e+00 - val_loss: 135.7541 - val_accuracy: 0.0000e+00\n",
      "Epoch 6179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5319 - accuracy: 0.0000e+00 - val_loss: 130.5166 - val_accuracy: 0.0588\n",
      "Epoch 6180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9031 - accuracy: 0.0156 - val_loss: 125.2691 - val_accuracy: 0.0588\n",
      "Epoch 6181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9229 - accuracy: 0.0156 - val_loss: 123.8322 - val_accuracy: 0.0588\n",
      "Epoch 6182/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.2928 - accuracy: 0.0000e+00 - val_loss: 120.1792 - val_accuracy: 0.0588\n",
      "Epoch 6183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3643 - accuracy: 0.0000e+00 - val_loss: 119.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 6184/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6462 - accuracy: 0.0156 - val_loss: 122.3863 - val_accuracy: 0.0000e+00\n",
      "Epoch 6185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9567 - accuracy: 0.0000e+00 - val_loss: 127.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 6186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5163 - accuracy: 0.0156 - val_loss: 131.2743 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2249 - accuracy: 0.0156 - val_loss: 134.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 6188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0399 - accuracy: 0.0156 - val_loss: 133.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 6189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9101 - accuracy: 0.0000e+00 - val_loss: 129.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 6190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.1736 - accuracy: 0.0312 - val_loss: 133.3062 - val_accuracy: 0.0000e+00\n",
      "Epoch 6191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3140 - accuracy: 0.0156 - val_loss: 132.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 6192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4440 - accuracy: 0.0156 - val_loss: 132.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.5711 - accuracy: 0.0469 - val_loss: 133.7035 - val_accuracy: 0.0000e+00\n",
      "Epoch 6194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2417 - accuracy: 0.0000e+00 - val_loss: 135.6129 - val_accuracy: 0.0588\n",
      "Epoch 6195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9704 - accuracy: 0.0000e+00 - val_loss: 132.4719 - val_accuracy: 0.0588\n",
      "Epoch 6196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3786 - accuracy: 0.0312 - val_loss: 127.0475 - val_accuracy: 0.0588\n",
      "Epoch 6197/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0387 - accuracy: 0.0156 - val_loss: 121.5523 - val_accuracy: 0.0588\n",
      "Epoch 6198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4432 - accuracy: 0.0000e+00 - val_loss: 117.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 6199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6650 - accuracy: 0.0000e+00 - val_loss: 118.8565 - val_accuracy: 0.0588\n",
      "Epoch 6200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1571 - accuracy: 0.0156 - val_loss: 123.0951 - val_accuracy: 0.0588\n",
      "Epoch 6201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7878 - accuracy: 0.0000e+00 - val_loss: 130.7173 - val_accuracy: 0.0588\n",
      "Epoch 6202/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 25.0092 - accuracy: 0.0156 - val_loss: 135.3593 - val_accuracy: 0.0588\n",
      "Epoch 6203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9690 - accuracy: 0.0156 - val_loss: 136.9345 - val_accuracy: 0.0588\n",
      "Epoch 6204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9777 - accuracy: 0.0000e+00 - val_loss: 134.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 6205/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 28.3654 - accuracy: 0.0156 - val_loss: 128.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 6206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5315 - accuracy: 0.0156 - val_loss: 124.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 6207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4314 - accuracy: 0.0000e+00 - val_loss: 125.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 6208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0967 - accuracy: 0.0156 - val_loss: 131.5249 - val_accuracy: 0.0000e+00\n",
      "Epoch 6209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4894 - accuracy: 0.0000e+00 - val_loss: 135.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 6210/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8112 - accuracy: 0.0312 - val_loss: 141.1662 - val_accuracy: 0.0000e+00\n",
      "Epoch 6211/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0429 - accuracy: 0.0000e+00 - val_loss: 143.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 6212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5285 - accuracy: 0.0156 - val_loss: 141.4040 - val_accuracy: 0.0000e+00\n",
      "Epoch 6213/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0557 - accuracy: 0.0000e+00 - val_loss: 134.6184 - val_accuracy: 0.0000e+00\n",
      "Epoch 6214/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 36.2776 - accuracy: 0.0000e+00 - val_loss: 129.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 6215/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3423 - accuracy: 0.0000e+00 - val_loss: 136.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 6216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1905 - accuracy: 0.0156 - val_loss: 141.7177 - val_accuracy: 0.0000e+00\n",
      "Epoch 6217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0662 - accuracy: 0.0156 - val_loss: 151.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 6218/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6325 - accuracy: 0.0156 - val_loss: 153.5455 - val_accuracy: 0.0000e+00\n",
      "Epoch 6219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8348 - accuracy: 0.0000e+00 - val_loss: 139.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 6220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7198 - accuracy: 0.0000e+00 - val_loss: 135.3772 - val_accuracy: 0.0588\n",
      "Epoch 6221/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.8018 - accuracy: 0.0000e+00 - val_loss: 139.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 6222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8529 - accuracy: 0.0000e+00 - val_loss: 142.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 6223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2285 - accuracy: 0.0156 - val_loss: 144.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 6224/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8870 - accuracy: 0.0156 - val_loss: 146.0549 - val_accuracy: 0.0000e+00\n",
      "Epoch 6225/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.6388 - accuracy: 0.0000e+0 - 0s 71us/step - loss: 32.1787 - accuracy: 0.0000e+00 - val_loss: 143.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 6226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0175 - accuracy: 0.0156 - val_loss: 142.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 6227/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0356 - accuracy: 0.0156 - val_loss: 142.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6228/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 24.4871 - accuracy: 0.0156 - val_loss: 141.3873 - val_accuracy: 0.0000e+00\n",
      "Epoch 6229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6286 - accuracy: 0.0000e+00 - val_loss: 137.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 6230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8037 - accuracy: 0.0156 - val_loss: 134.2704 - val_accuracy: 0.0588\n",
      "Epoch 6231/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9450 - accuracy: 0.0000e+00 - val_loss: 129.9285 - val_accuracy: 0.0588\n",
      "Epoch 6232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9774 - accuracy: 0.0000e+00 - val_loss: 123.4296 - val_accuracy: 0.0588\n",
      "Epoch 6233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6128 - accuracy: 0.0000e+00 - val_loss: 131.1332 - val_accuracy: 0.0588\n",
      "Epoch 6234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4975 - accuracy: 0.0000e+00 - val_loss: 141.2680 - val_accuracy: 0.0588\n",
      "Epoch 6235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7820 - accuracy: 0.0000e+00 - val_loss: 147.4174 - val_accuracy: 0.0588\n",
      "Epoch 6236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6586 - accuracy: 0.0156 - val_loss: 148.8269 - val_accuracy: 0.0588\n",
      "Epoch 6237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5255 - accuracy: 0.0000e+00 - val_loss: 137.7564 - val_accuracy: 0.0588\n",
      "Epoch 6238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3737 - accuracy: 0.0156 - val_loss: 131.4538 - val_accuracy: 0.0588\n",
      "Epoch 6239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4049 - accuracy: 0.0312 - val_loss: 123.6179 - val_accuracy: 0.0588\n",
      "Epoch 6240/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1888 - accuracy: 0.0156 - val_loss: 113.8193 - val_accuracy: 0.0588\n",
      "Epoch 6241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8680 - accuracy: 0.0000e+00 - val_loss: 112.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 6242/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.5847 - accuracy: 0.0000e+00 - val_loss: 118.2050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1864 - accuracy: 0.0156 - val_loss: 123.9043 - val_accuracy: 0.0000e+00\n",
      "Epoch 6244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9372 - accuracy: 0.0000e+00 - val_loss: 132.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 6245/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2161 - accuracy: 0.0000e+00 - val_loss: 143.9517 - val_accuracy: 0.0000e+00\n",
      "Epoch 6246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2175 - accuracy: 0.0156 - val_loss: 148.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 6247/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 26.0284 - accuracy: 0.0312 - val_loss: 143.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 6248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1560 - accuracy: 0.0156 - val_loss: 133.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 6249/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4810 - accuracy: 0.0312 - val_loss: 127.2404 - val_accuracy: 0.0000e+00\n",
      "Epoch 6250/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.7744 - accuracy: 0.0156 - val_loss: 126.5488 - val_accuracy: 0.0000e+00\n",
      "Epoch 6251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1288 - accuracy: 0.0000e+00 - val_loss: 132.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6370 - accuracy: 0.0000e+00 - val_loss: 141.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 6253/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7621 - accuracy: 0.0000e+00 - val_loss: 133.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 6254/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0364 - accuracy: 0.0156 - val_loss: 127.7561 - val_accuracy: 0.0000e+00\n",
      "Epoch 6255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6133 - accuracy: 0.0000e+00 - val_loss: 131.0003 - val_accuracy: 0.0000e+00\n",
      "Epoch 6256/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4205 - accuracy: 0.0000e+00 - val_loss: 135.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 6257/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 25.2417 - accuracy: 0.0312 - val_loss: 139.1132 - val_accuracy: 0.0588\n",
      "Epoch 6258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9267 - accuracy: 0.0000e+00 - val_loss: 135.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 6259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1983 - accuracy: 0.0156 - val_loss: 128.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 6260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0171 - accuracy: 0.0000e+00 - val_loss: 129.3735 - val_accuracy: 0.0000e+00\n",
      "Epoch 6261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3024 - accuracy: 0.0156 - val_loss: 131.2770 - val_accuracy: 0.0000e+00\n",
      "Epoch 6262/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8716 - accuracy: 0.0312 - val_loss: 127.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 6263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8206 - accuracy: 0.0156 - val_loss: 121.9806 - val_accuracy: 0.0000e+00\n",
      "Epoch 6264/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 20.2463 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 23.5119 - accuracy: 0.0156 - val_loss: 119.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0951 - accuracy: 0.0156 - val_loss: 125.2380 - val_accuracy: 0.0000e+00\n",
      "Epoch 6266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8441 - accuracy: 0.0000e+00 - val_loss: 129.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 6267/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 33.1964 - accuracy: 0.0312 - val_loss: 131.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 6268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4162 - accuracy: 0.0312 - val_loss: 141.4034 - val_accuracy: 0.0000e+00\n",
      "Epoch 6269/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4190 - accuracy: 0.0156 - val_loss: 140.9684 - val_accuracy: 0.0000e+00\n",
      "Epoch 6270/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 40.9014 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 29.7937 - accuracy: 0.0000e+00 - val_loss: 136.4017 - val_accuracy: 0.0000e+00\n",
      "Epoch 6271/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 33.9735 - accuracy: 0.0312 - val_loss: 137.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6272/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.7235 - accuracy: 0.0000e+00 - val_loss: 139.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8840 - accuracy: 0.0312 - val_loss: 144.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 6274/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 41.0406 - accuracy: 0.0000e+00 - val_loss: 133.2814 - val_accuracy: 0.0588\n",
      "Epoch 6275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9069 - accuracy: 0.0156 - val_loss: 124.0994 - val_accuracy: 0.0000e+00\n",
      "Epoch 6276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4025 - accuracy: 0.0156 - val_loss: 118.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 6277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5309 - accuracy: 0.0000e+00 - val_loss: 119.5535 - val_accuracy: 0.0000e+00\n",
      "Epoch 6278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1399 - accuracy: 0.0156 - val_loss: 129.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 6279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7291 - accuracy: 0.0000e+00 - val_loss: 134.4908 - val_accuracy: 0.0588\n",
      "Epoch 6280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4093 - accuracy: 0.0000e+00 - val_loss: 131.8741 - val_accuracy: 0.0000e+00\n",
      "Epoch 6281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7757 - accuracy: 0.0312 - val_loss: 127.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 6282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3554 - accuracy: 0.0000e+00 - val_loss: 121.1213 - val_accuracy: 0.0000e+00\n",
      "Epoch 6283/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.4115 - accuracy: 0.0156 - val_loss: 115.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 6284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2872 - accuracy: 0.0156 - val_loss: 115.8730 - val_accuracy: 0.0588\n",
      "Epoch 6285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2922 - accuracy: 0.0312 - val_loss: 116.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 6286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0330 - accuracy: 0.0000e+00 - val_loss: 124.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1213 - accuracy: 0.0156 - val_loss: 131.8300 - val_accuracy: 0.0000e+00\n",
      "Epoch 6288/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3866 - accuracy: 0.0000e+00 - val_loss: 135.3479 - val_accuracy: 0.0000e+00\n",
      "Epoch 6289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2191 - accuracy: 0.0156 - val_loss: 138.5220 - val_accuracy: 0.0000e+00\n",
      "Epoch 6290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3406 - accuracy: 0.0000e+00 - val_loss: 136.8113 - val_accuracy: 0.0000e+00\n",
      "Epoch 6291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 18.6987 - accuracy: 0.0000e+00 - val_loss: 133.6296 - val_accuracy: 0.0588\n",
      "Epoch 6292/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 22.8179 - accuracy: 0.0000e+00 - val_loss: 132.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7689 - accuracy: 0.0156 - val_loss: 132.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 6294/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8662 - accuracy: 0.0156 - val_loss: 132.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 6295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5718 - accuracy: 0.0156 - val_loss: 136.6009 - val_accuracy: 0.0000e+00\n",
      "Epoch 6296/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.5516 - accuracy: 0.0469 - val_loss: 141.7700 - val_accuracy: 0.0000e+00\n",
      "Epoch 6297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7473 - accuracy: 0.0000e+00 - val_loss: 138.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 6298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4704 - accuracy: 0.0156 - val_loss: 133.8073 - val_accuracy: 0.0588\n",
      "Epoch 6299/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 17.0576 - accuracy: 0.0000e+00 - val_loss: 120.5682 - val_accuracy: 0.0588\n",
      "Epoch 6300/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 25.6630 - accuracy: 0.0469 - val_loss: 110.3660 - val_accuracy: 0.0588\n",
      "Epoch 6301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3084 - accuracy: 0.0312 - val_loss: 111.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 6302/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 28.7448 - accuracy: 0.0000e+00 - val_loss: 123.0644 - val_accuracy: 0.0000e+00\n",
      "Epoch 6303/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 28.1414 - accuracy: 0.0156 - val_loss: 138.2211 - val_accuracy: 0.0588\n",
      "Epoch 6304/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 19.4018 - accuracy: 0.0000e+00 - val_loss: 145.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 6305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1951 - accuracy: 0.0000e+00 - val_loss: 144.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 6306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1341 - accuracy: 0.0000e+00 - val_loss: 134.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6307/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7782 - accuracy: 0.0156 - val_loss: 128.0253 - val_accuracy: 0.0588\n",
      "Epoch 6308/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2620 - accuracy: 0.0156 - val_loss: 119.1688 - val_accuracy: 0.0588\n",
      "Epoch 6309/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4205 - accuracy: 0.0000e+00 - val_loss: 116.2914 - val_accuracy: 0.0588\n",
      "Epoch 6310/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 21.6191 - accuracy: 0.0156 - val_loss: 121.3847 - val_accuracy: 0.0000e+00\n",
      "Epoch 6311/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 21.6151 - accuracy: 0.0156 - val_loss: 134.0473 - val_accuracy: 0.0000e+00\n",
      "Epoch 6312/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6568 - accuracy: 0.0156 - val_loss: 147.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6313/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 44.0446 - accuracy: 0.0000e+00 - val_loss: 143.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 6314/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5398 - accuracy: 0.0156 - val_loss: 135.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6315/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 20.9024 - accuracy: 0.0312 - val_loss: 130.1677 - val_accuracy: 0.0000e+00\n",
      "Epoch 6316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7213 - accuracy: 0.0312 - val_loss: 129.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 6317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3350 - accuracy: 0.0156 - val_loss: 129.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 6318/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 18.1441 - accuracy: 0.0000e+00 - val_loss: 132.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6319/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9845 - accuracy: 0.0000e+00 - val_loss: 132.9858 - val_accuracy: 0.0000e+00\n",
      "Epoch 6320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0234 - accuracy: 0.0000e+00 - val_loss: 133.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 6321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4325 - accuracy: 0.0000e+00 - val_loss: 140.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 6322/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 28.2634 - accuracy: 0.0156 - val_loss: 144.7985 - val_accuracy: 0.0000e+00\n",
      "Epoch 6323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8867 - accuracy: 0.0156 - val_loss: 149.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 6324/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9641 - accuracy: 0.0000e+00 - val_loss: 152.9138 - val_accuracy: 0.0588\n",
      "Epoch 6325/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 21.2882 - accuracy: 0.0312 - val_loss: 148.3446 - val_accuracy: 0.0588\n",
      "Epoch 6326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3577 - accuracy: 0.0156 - val_loss: 144.0157 - val_accuracy: 0.0588\n",
      "Epoch 6327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3861 - accuracy: 0.0312 - val_loss: 139.9483 - val_accuracy: 0.0588\n",
      "Epoch 6328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4032 - accuracy: 0.0156 - val_loss: 137.7457 - val_accuracy: 0.0588\n",
      "Epoch 6329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9289 - accuracy: 0.0156 - val_loss: 134.4517 - val_accuracy: 0.0588\n",
      "Epoch 6330/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5774 - accuracy: 0.0156 - val_loss: 131.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 6331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5438 - accuracy: 0.0000e+00 - val_loss: 133.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 6332/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8300 - accuracy: 0.0000e+00 - val_loss: 128.7633 - val_accuracy: 0.0000e+00\n",
      "Epoch 6333/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 21.6645 - accuracy: 0.0156 - val_loss: 121.5928 - val_accuracy: 0.0000e+00\n",
      "Epoch 6334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3614 - accuracy: 0.0000e+00 - val_loss: 120.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 6335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7722 - accuracy: 0.0156 - val_loss: 115.8872 - val_accuracy: 0.0000e+00\n",
      "Epoch 6336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5334 - accuracy: 0.0156 - val_loss: 112.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 6337/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.1427 - accuracy: 0.0156 - val_loss: 116.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 6338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8685 - accuracy: 0.0156 - val_loss: 125.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6339/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 37.3265 - accuracy: 0.0000e+00 - val_loss: 141.6861 - val_accuracy: 0.0000e+00\n",
      "Epoch 6340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2541 - accuracy: 0.0156 - val_loss: 148.5052 - val_accuracy: 0.0000e+00\n",
      "Epoch 6341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3886 - accuracy: 0.0156 - val_loss: 151.1312 - val_accuracy: 0.0588\n",
      "Epoch 6342/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3268 - accuracy: 0.0156 - val_loss: 146.9067 - val_accuracy: 0.0000e+00\n",
      "Epoch 6343/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 26.1055 - accuracy: 0.0000e+00 - val_loss: 139.9932 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7332 - accuracy: 0.0156 - val_loss: 136.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6464 - accuracy: 0.0156 - val_loss: 136.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 6346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5027 - accuracy: 0.0000e+00 - val_loss: 136.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 6347/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1924 - accuracy: 0.0000e+00 - val_loss: 131.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 6348/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4119 - accuracy: 0.0000e+00 - val_loss: 123.5000 - val_accuracy: 0.0588\n",
      "Epoch 6349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5190 - accuracy: 0.0000e+00 - val_loss: 118.9842 - val_accuracy: 0.0588\n",
      "Epoch 6350/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 23.6254 - accuracy: 0.0000e+00 - val_loss: 128.2396 - val_accuracy: 0.0588\n",
      "Epoch 6351/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3869 - accuracy: 0.0000e+00 - val_loss: 139.5653 - val_accuracy: 0.0588\n",
      "Epoch 6352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7857 - accuracy: 0.0312 - val_loss: 136.5016 - val_accuracy: 0.0000e+00\n",
      "Epoch 6353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3136 - accuracy: 0.0156 - val_loss: 131.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 6354/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0867 - accuracy: 0.0312 - val_loss: 128.3208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5853 - accuracy: 0.0000e+00 - val_loss: 130.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 6356/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3160 - accuracy: 0.0156 - val_loss: 140.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 6357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4838 - accuracy: 0.0000e+00 - val_loss: 152.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 6358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2402 - accuracy: 0.0156 - val_loss: 153.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 6359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4370 - accuracy: 0.0156 - val_loss: 137.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 6360/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 23.4686 - accuracy: 0.062 - 0s 62us/step - loss: 24.1868 - accuracy: 0.0312 - val_loss: 121.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 6361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1400 - accuracy: 0.0000e+00 - val_loss: 118.9474 - val_accuracy: 0.0000e+00\n",
      "Epoch 6362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1480 - accuracy: 0.0000e+00 - val_loss: 117.9290 - val_accuracy: 0.0000e+00\n",
      "Epoch 6363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0760 - accuracy: 0.0156 - val_loss: 125.3928 - val_accuracy: 0.0588\n",
      "Epoch 6364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9261 - accuracy: 0.0156 - val_loss: 131.7847 - val_accuracy: 0.0588\n",
      "Epoch 6365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4263 - accuracy: 0.0156 - val_loss: 130.5753 - val_accuracy: 0.0588\n",
      "Epoch 6366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6130 - accuracy: 0.0156 - val_loss: 123.9012 - val_accuracy: 0.0588\n",
      "Epoch 6367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3636 - accuracy: 0.0000e+00 - val_loss: 121.2479 - val_accuracy: 0.0588\n",
      "Epoch 6368/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.1752 - accuracy: 0.0000e+00 - val_loss: 116.4048 - val_accuracy: 0.0588\n",
      "Epoch 6369/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.4011 - accuracy: 0.0000e+00 - val_loss: 115.6035 - val_accuracy: 0.0588\n",
      "Epoch 6370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6097 - accuracy: 0.0312 - val_loss: 125.1321 - val_accuracy: 0.0588\n",
      "Epoch 6371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2262 - accuracy: 0.0156 - val_loss: 135.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 6372/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8558 - accuracy: 0.0312 - val_loss: 136.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1369 - accuracy: 0.0156 - val_loss: 132.7395 - val_accuracy: 0.0000e+00\n",
      "Epoch 6374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9830 - accuracy: 0.0000e+00 - val_loss: 131.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6375/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.8868 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 36.7507 - accuracy: 0.0000e+00 - val_loss: 137.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0241 - accuracy: 0.0156 - val_loss: 141.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 6377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1627 - accuracy: 0.0312 - val_loss: 145.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 6378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7169 - accuracy: 0.0000e+00 - val_loss: 147.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 6379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7301 - accuracy: 0.0156 - val_loss: 142.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 6380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0322 - accuracy: 0.0000e+00 - val_loss: 138.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 6381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2264 - accuracy: 0.0156 - val_loss: 131.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 6382/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0169 - accuracy: 0.0000e+00 - val_loss: 129.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 6383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5092 - accuracy: 0.0000e+00 - val_loss: 130.2993 - val_accuracy: 0.0000e+00\n",
      "Epoch 6384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2404 - accuracy: 0.0156 - val_loss: 131.2059 - val_accuracy: 0.0000e+00\n",
      "Epoch 6385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8855 - accuracy: 0.0156 - val_loss: 131.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6386/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 22.5191 - accuracy: 0.0156 - val_loss: 129.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 6387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9749 - accuracy: 0.0312 - val_loss: 121.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 6388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5326 - accuracy: 0.0156 - val_loss: 115.1540 - val_accuracy: 0.0000e+00\n",
      "Epoch 6389/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 31.4248 - accuracy: 0.0000e+00 - val_loss: 119.7659 - val_accuracy: 0.0588\n",
      "Epoch 6390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.9813 - accuracy: 0.0000e+00 - val_loss: 130.7160 - val_accuracy: 0.0588\n",
      "Epoch 6391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9201 - accuracy: 0.0156 - val_loss: 138.9698 - val_accuracy: 0.0588\n",
      "Epoch 6392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2921 - accuracy: 0.0000e+00 - val_loss: 145.4462 - val_accuracy: 0.0588\n",
      "Epoch 6393/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0101 - accuracy: 0.0156 - val_loss: 150.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 6394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2538 - accuracy: 0.0000e+00 - val_loss: 154.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 6395/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 40.3365 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 28.1320 - accuracy: 0.0000e+00 - val_loss: 150.9560 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6396/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 25.1577 - accuracy: 0.0156 - val_loss: 140.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 6397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2444 - accuracy: 0.0000e+00 - val_loss: 133.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 6398/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7257 - accuracy: 0.0156 - val_loss: 132.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 6399/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8903 - accuracy: 0.0000e+00 - val_loss: 129.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7327 - accuracy: 0.0000e+00 - val_loss: 130.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 6401/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 22.3030 - accuracy: 0.0000e+00 - val_loss: 131.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 6402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8516 - accuracy: 0.0156 - val_loss: 130.7796 - val_accuracy: 0.0000e+00\n",
      "Epoch 6403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9662 - accuracy: 0.0000e+00 - val_loss: 131.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 6404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3227 - accuracy: 0.0000e+00 - val_loss: 132.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3838 - accuracy: 0.0156 - val_loss: 125.4676 - val_accuracy: 0.0000e+00\n",
      "Epoch 6406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0607 - accuracy: 0.0156 - val_loss: 122.9762 - val_accuracy: 0.0000e+00\n",
      "Epoch 6407/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 25.4281 - accuracy: 0.0000e+00 - val_loss: 123.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 6408/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6922 - accuracy: 0.0000e+00 - val_loss: 131.1508 - val_accuracy: 0.0588\n",
      "Epoch 6409/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6412 - accuracy: 0.0156 - val_loss: 141.4328 - val_accuracy: 0.0588\n",
      "Epoch 6410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5379 - accuracy: 0.0156 - val_loss: 138.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 6411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6418 - accuracy: 0.0312 - val_loss: 138.6661 - val_accuracy: 0.0000e+00\n",
      "Epoch 6412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6859 - accuracy: 0.0000e+00 - val_loss: 141.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 6413/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 37.3466 - accuracy: 0.0000e+00 - val_loss: 140.3952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6748 - accuracy: 0.0000e+00 - val_loss: 137.9754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3437 - accuracy: 0.0156 - val_loss: 139.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 6416/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.3222 - accuracy: 0.0000e+00 - val_loss: 142.0417 - val_accuracy: 0.0588\n",
      "Epoch 6417/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 32.0655 - accuracy: 0.0469 - val_loss: 139.0011 - val_accuracy: 0.0588\n",
      "Epoch 6418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5680 - accuracy: 0.0312 - val_loss: 137.0087 - val_accuracy: 0.0588\n",
      "Epoch 6419/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.5249 - accuracy: 0.0156 - val_loss: 130.1246 - val_accuracy: 0.0588\n",
      "Epoch 6420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4446 - accuracy: 0.0312 - val_loss: 126.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 6421/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.2366 - accuracy: 0.0156 - val_loss: 127.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2714 - accuracy: 0.0156 - val_loss: 128.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 6423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1549 - accuracy: 0.0312 - val_loss: 129.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6424/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 26.8213 - accuracy: 0.0156 - val_loss: 127.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6425/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 26.5917 - accuracy: 0.0156 - val_loss: 130.3834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6426/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.3609 - accuracy: 0.0156 - val_loss: 137.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 6427/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1906 - accuracy: 0.0156 - val_loss: 147.8507 - val_accuracy: 0.0000e+00\n",
      "Epoch 6428/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 24.3518 - accuracy: 0.0469 - val_loss: 143.7916 - val_accuracy: 0.0000e+00\n",
      "Epoch 6429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4289 - accuracy: 0.0156 - val_loss: 130.8197 - val_accuracy: 0.0588\n",
      "Epoch 6430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1288 - accuracy: 0.0000e+00 - val_loss: 124.9773 - val_accuracy: 0.0588\n",
      "Epoch 6431/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0028 - accuracy: 0.0000e+00 - val_loss: 131.0533 - val_accuracy: 0.0588\n",
      "Epoch 6432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2664 - accuracy: 0.0156 - val_loss: 136.4717 - val_accuracy: 0.0588\n",
      "Epoch 6433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6909 - accuracy: 0.0156 - val_loss: 136.5438 - val_accuracy: 0.0588\n",
      "Epoch 6434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7695 - accuracy: 0.0000e+00 - val_loss: 132.0491 - val_accuracy: 0.0588\n",
      "Epoch 6435/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.4853 - accuracy: 0.0156 - val_loss: 125.5450 - val_accuracy: 0.0588\n",
      "Epoch 6436/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.8134 - accuracy: 0.0000e+00 - val_loss: 120.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 6437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3754 - accuracy: 0.0156 - val_loss: 118.1305 - val_accuracy: 0.0588\n",
      "Epoch 6438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4367 - accuracy: 0.0000e+00 - val_loss: 117.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 6439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2509 - accuracy: 0.0000e+00 - val_loss: 126.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 6440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6503 - accuracy: 0.0156 - val_loss: 136.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 6441/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9891 - accuracy: 0.0000e+00 - val_loss: 137.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4147 - accuracy: 0.0000e+00 - val_loss: 134.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6967 - accuracy: 0.0000e+00 - val_loss: 127.8109 - val_accuracy: 0.0000e+00\n",
      "Epoch 6444/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 28.4973 - accuracy: 0.0000e+00 - val_loss: 123.3439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0725 - accuracy: 0.0156 - val_loss: 122.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 6446/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.3354 - accuracy: 0.0000e+00 - val_loss: 123.8870 - val_accuracy: 0.0000e+00\n",
      "Epoch 6447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7687 - accuracy: 0.0000e+00 - val_loss: 129.5914 - val_accuracy: 0.0000e+00\n",
      "Epoch 6448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0781 - accuracy: 0.0156 - val_loss: 134.6084 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4306 - accuracy: 0.0156 - val_loss: 132.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 6450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3074 - accuracy: 0.0000e+00 - val_loss: 139.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 6451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9073 - accuracy: 0.0000e+00 - val_loss: 138.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 6452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3122 - accuracy: 0.0156 - val_loss: 136.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 6453/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3219 - accuracy: 0.0156 - val_loss: 134.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 6454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9417 - accuracy: 0.0312 - val_loss: 133.3149 - val_accuracy: 0.0000e+00\n",
      "Epoch 6455/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1602 - accuracy: 0.0000e+00 - val_loss: 139.2307 - val_accuracy: 0.0000e+00\n",
      "Epoch 6456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3594 - accuracy: 0.0156 - val_loss: 143.6522 - val_accuracy: 0.0000e+00\n",
      "Epoch 6457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1984 - accuracy: 0.0000e+00 - val_loss: 142.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 6458/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5634 - accuracy: 0.0000e+00 - val_loss: 134.8245 - val_accuracy: 0.0000e+00\n",
      "Epoch 6459/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 20.5655 - accuracy: 0.0000e+00 - val_loss: 133.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 6460/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.4430 - accuracy: 0.0000e+00 - val_loss: 134.2225 - val_accuracy: 0.0000e+00\n",
      "Epoch 6461/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8710 - accuracy: 0.0000e+00 - val_loss: 134.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 6462/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.7288 - accuracy: 0.0000e+00 - val_loss: 139.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4387 - accuracy: 0.0156 - val_loss: 143.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 6464/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.9229 - accuracy: 0.0156 - val_loss: 139.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 6465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9937 - accuracy: 0.0156 - val_loss: 130.8538 - val_accuracy: 0.0000e+00\n",
      "Epoch 6466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1725 - accuracy: 0.0156 - val_loss: 126.9425 - val_accuracy: 0.0000e+00\n",
      "Epoch 6467/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3491 - accuracy: 0.0469 - val_loss: 129.4053 - val_accuracy: 0.0000e+00\n",
      "Epoch 6468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6647 - accuracy: 0.0156 - val_loss: 133.0852 - val_accuracy: 0.0000e+00\n",
      "Epoch 6469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3235 - accuracy: 0.0312 - val_loss: 141.8056 - val_accuracy: 0.0588\n",
      "Epoch 6470/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 27.9689 - accuracy: 0.0000e+00 - val_loss: 145.8983 - val_accuracy: 0.0000e+00\n",
      "Epoch 6471/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8109 - accuracy: 0.0000e+00 - val_loss: 141.0129 - val_accuracy: 0.0588\n",
      "Epoch 6472/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8557 - accuracy: 0.0000e+00 - val_loss: 127.0311 - val_accuracy: 0.0588\n",
      "Epoch 6473/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7062 - accuracy: 0.0000e+00 - val_loss: 113.6875 - val_accuracy: 0.0588\n",
      "Epoch 6474/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 19.5784 - accuracy: 0.0156 - val_loss: 116.1086 - val_accuracy: 0.0588\n",
      "Epoch 6475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6546 - accuracy: 0.0156 - val_loss: 126.6429 - val_accuracy: 0.0588\n",
      "Epoch 6476/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.2203 - accuracy: 0.0156 - val_loss: 128.1016 - val_accuracy: 0.0588\n",
      "Epoch 6477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2186 - accuracy: 0.0000e+00 - val_loss: 124.5188 - val_accuracy: 0.0588\n",
      "Epoch 6478/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7882 - accuracy: 0.0156 - val_loss: 128.0824 - val_accuracy: 0.0588\n",
      "Epoch 6479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0429 - accuracy: 0.0312 - val_loss: 131.4419 - val_accuracy: 0.0588\n",
      "Epoch 6480/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.4595 - accuracy: 0.0156 - val_loss: 130.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 6481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2030 - accuracy: 0.0000e+00 - val_loss: 137.9704 - val_accuracy: 0.0000e+00\n",
      "Epoch 6482/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 17.9913 - accuracy: 0.0312 - val_loss: 138.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 6483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0348 - accuracy: 0.0000e+00 - val_loss: 145.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 6484/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9967 - accuracy: 0.0000e+00 - val_loss: 147.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 6485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3187 - accuracy: 0.0000e+00 - val_loss: 147.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 6486/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.5588 - accuracy: 0.0000e+00 - val_loss: 149.1830 - val_accuracy: 0.0000e+00\n",
      "Epoch 6487/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 34.5062 - accuracy: 0.0000e+00 - val_loss: 145.1346 - val_accuracy: 0.0588\n",
      "Epoch 6488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7954 - accuracy: 0.0000e+00 - val_loss: 138.1271 - val_accuracy: 0.1176\n",
      "Epoch 6489/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4290 - accuracy: 0.0156 - val_loss: 128.5827 - val_accuracy: 0.0588\n",
      "Epoch 6490/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 20.2938 - accuracy: 0.0156 - val_loss: 120.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 6491/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.8426 - accuracy: 0.0156 - val_loss: 120.2976 - val_accuracy: 0.0588\n",
      "Epoch 6492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1802 - accuracy: 0.0000e+00 - val_loss: 119.0464 - val_accuracy: 0.0588\n",
      "Epoch 6493/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 30.7036 - accuracy: 0.0000e+00 - val_loss: 119.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 6494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5985 - accuracy: 0.0000e+00 - val_loss: 128.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 6495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8378 - accuracy: 0.0000e+00 - val_loss: 128.9803 - val_accuracy: 0.0000e+00\n",
      "Epoch 6496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4039 - accuracy: 0.0156 - val_loss: 127.6621 - val_accuracy: 0.0000e+00\n",
      "Epoch 6497/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5940 - accuracy: 0.0469 - val_loss: 123.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 6498/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2688 - accuracy: 0.0156 - val_loss: 129.3790 - val_accuracy: 0.0000e+00\n",
      "Epoch 6499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6111 - accuracy: 0.0156 - val_loss: 132.7848 - val_accuracy: 0.0000e+00\n",
      "Epoch 6500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7571 - accuracy: 0.0156 - val_loss: 136.6911 - val_accuracy: 0.0588\n",
      "Epoch 6501/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9192 - accuracy: 0.0000e+00 - val_loss: 137.8642 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1031 - accuracy: 0.0156 - val_loss: 139.6928 - val_accuracy: 0.0588\n",
      "Epoch 6503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5810 - accuracy: 0.0000e+00 - val_loss: 139.9901 - val_accuracy: 0.0000e+00\n",
      "Epoch 6504/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2965 - accuracy: 0.0000e+00 - val_loss: 135.0807 - val_accuracy: 0.0588\n",
      "Epoch 6505/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.3920 - accuracy: 0.0156 - val_loss: 133.1392 - val_accuracy: 0.0588\n",
      "Epoch 6506/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9158 - accuracy: 0.0156 - val_loss: 130.4741 - val_accuracy: 0.0588\n",
      "Epoch 6507/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.5755 - accuracy: 0.0312 - val_loss: 131.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 6508/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.6647 - accuracy: 0.0156 - val_loss: 127.8510 - val_accuracy: 0.0000e+00\n",
      "Epoch 6509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7276 - accuracy: 0.0156 - val_loss: 126.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 6510/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 24.8918 - accuracy: 0.0000e+00 - val_loss: 124.3824 - val_accuracy: 0.0000e+00\n",
      "Epoch 6511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1458 - accuracy: 0.0156 - val_loss: 122.6761 - val_accuracy: 0.0000e+00\n",
      "Epoch 6512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4359 - accuracy: 0.0000e+00 - val_loss: 120.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 6513/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.0501 - accuracy: 0.0000e+00 - val_loss: 124.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 6514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7635 - accuracy: 0.0000e+00 - val_loss: 135.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 6515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0834 - accuracy: 0.0000e+00 - val_loss: 146.7657 - val_accuracy: 0.0000e+00\n",
      "Epoch 6516/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4583 - accuracy: 0.0312 - val_loss: 148.7324 - val_accuracy: 0.0588\n",
      "Epoch 6517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0190 - accuracy: 0.0156 - val_loss: 147.0313 - val_accuracy: 0.0588\n",
      "Epoch 6518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9434 - accuracy: 0.0156 - val_loss: 137.2259 - val_accuracy: 0.0588\n",
      "Epoch 6519/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8857 - accuracy: 0.0156 - val_loss: 125.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 6520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4623 - accuracy: 0.0000e+00 - val_loss: 118.9338 - val_accuracy: 0.0000e+00\n",
      "Epoch 6521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7817 - accuracy: 0.0000e+00 - val_loss: 116.8208 - val_accuracy: 0.0588\n",
      "Epoch 6522/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9977 - accuracy: 0.0000e+00 - val_loss: 121.2039 - val_accuracy: 0.0588\n",
      "Epoch 6523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2816 - accuracy: 0.0156 - val_loss: 127.4878 - val_accuracy: 0.0588\n",
      "Epoch 6524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2090 - accuracy: 0.0000e+00 - val_loss: 126.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 6525/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2930 - accuracy: 0.0000e+00 - val_loss: 128.9589 - val_accuracy: 0.0000e+00\n",
      "Epoch 6526/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0161 - accuracy: 0.0312 - val_loss: 133.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 6527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5260 - accuracy: 0.0000e+00 - val_loss: 128.9661 - val_accuracy: 0.0588\n",
      "Epoch 6528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0178 - accuracy: 0.0000e+00 - val_loss: 128.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6529/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8522 - accuracy: 0.0000e+00 - val_loss: 133.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 6530/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 22.9082 - accuracy: 0.0000e+00 - val_loss: 134.1805 - val_accuracy: 0.0588\n",
      "Epoch 6531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5466 - accuracy: 0.0156 - val_loss: 130.3922 - val_accuracy: 0.0588\n",
      "Epoch 6532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4051 - accuracy: 0.0156 - val_loss: 129.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 6533/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.6054 - accuracy: 0.0156 - val_loss: 130.3489 - val_accuracy: 0.0000e+00\n",
      "Epoch 6534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7043 - accuracy: 0.0156 - val_loss: 129.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6535/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.1340 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 26.8182 - accuracy: 0.0000e+00 - val_loss: 122.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 6536/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.0194 - accuracy: 0.0312 - val_loss: 117.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 6537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8744 - accuracy: 0.0156 - val_loss: 119.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 6538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2318 - accuracy: 0.0000e+00 - val_loss: 119.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 6539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1347 - accuracy: 0.0156 - val_loss: 113.4674 - val_accuracy: 0.0588\n",
      "Epoch 6540/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 32.0994 - accuracy: 0.0156 - val_loss: 113.5701 - val_accuracy: 0.0588\n",
      "Epoch 6541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9184 - accuracy: 0.0156 - val_loss: 117.2731 - val_accuracy: 0.0588\n",
      "Epoch 6542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2871 - accuracy: 0.0000e+00 - val_loss: 117.2167 - val_accuracy: 0.0588\n",
      "Epoch 6543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4223 - accuracy: 0.0156 - val_loss: 120.9397 - val_accuracy: 0.0000e+00\n",
      "Epoch 6544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3016 - accuracy: 0.0000e+00 - val_loss: 122.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 6545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6769 - accuracy: 0.0000e+00 - val_loss: 122.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 6546/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9434 - accuracy: 0.0000e+00 - val_loss: 119.5913 - val_accuracy: 0.0588\n",
      "Epoch 6547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1644 - accuracy: 0.0000e+00 - val_loss: 117.6911 - val_accuracy: 0.0000e+00\n",
      "Epoch 6548/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4746 - accuracy: 0.0312 - val_loss: 116.2925 - val_accuracy: 0.0000e+00\n",
      "Epoch 6549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6017 - accuracy: 0.0156 - val_loss: 117.5210 - val_accuracy: 0.0588\n",
      "Epoch 6550/10000\n",
      "64/64 [==============================] - 0s 173us/step - loss: 23.1931 - accuracy: 0.0312 - val_loss: 124.7562 - val_accuracy: 0.0000e+00\n",
      "Epoch 6551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8428 - accuracy: 0.0312 - val_loss: 129.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 6552/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 24.6077 - accuracy: 0.0000e+00 - val_loss: 133.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 6553/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 31.6085 - accuracy: 0.0000e+00 - val_loss: 132.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 6554/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 21.9029 - accuracy: 0.0000e+00 - val_loss: 132.1920 - val_accuracy: 0.0588\n",
      "Epoch 6555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2329 - accuracy: 0.0000e+00 - val_loss: 132.3058 - val_accuracy: 0.0588\n",
      "Epoch 6556/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8224 - accuracy: 0.0000e+00 - val_loss: 133.5569 - val_accuracy: 0.0588\n",
      "Epoch 6557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0733 - accuracy: 0.0000e+00 - val_loss: 129.5921 - val_accuracy: 0.0588\n",
      "Epoch 6558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8123 - accuracy: 0.0156 - val_loss: 130.6219 - val_accuracy: 0.0000e+00\n",
      "Epoch 6559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5834 - accuracy: 0.0156 - val_loss: 135.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 6560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7598 - accuracy: 0.0156 - val_loss: 141.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 6561/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8203 - accuracy: 0.0000e+00 - val_loss: 147.0078 - val_accuracy: 0.0588\n",
      "Epoch 6562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6987 - accuracy: 0.0000e+00 - val_loss: 139.2061 - val_accuracy: 0.0588\n",
      "Epoch 6563/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 33.3127 - accuracy: 0.0000e+00 - val_loss: 123.2994 - val_accuracy: 0.0588\n",
      "Epoch 6564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8230 - accuracy: 0.0000e+00 - val_loss: 116.8312 - val_accuracy: 0.0588\n",
      "Epoch 6565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4313 - accuracy: 0.0000e+00 - val_loss: 121.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 6566/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.3486 - accuracy: 0.0156 - val_loss: 127.8089 - val_accuracy: 0.0000e+00\n",
      "Epoch 6567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4977 - accuracy: 0.0156 - val_loss: 135.7772 - val_accuracy: 0.0000e+00\n",
      "Epoch 6568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8823 - accuracy: 0.0156 - val_loss: 134.8552 - val_accuracy: 0.0000e+00\n",
      "Epoch 6569/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8740 - accuracy: 0.0156 - val_loss: 132.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 6570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3402 - accuracy: 0.0000e+00 - val_loss: 129.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 6571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7965 - accuracy: 0.0000e+00 - val_loss: 124.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6572/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 36.4897 - accuracy: 0.0156 - val_loss: 122.9994 - val_accuracy: 0.0588\n",
      "Epoch 6573/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0248 - accuracy: 0.0156 - val_loss: 127.8273 - val_accuracy: 0.0000e+00\n",
      "Epoch 6574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6856 - accuracy: 0.0156 - val_loss: 137.4110 - val_accuracy: 0.0588\n",
      "Epoch 6575/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9736 - accuracy: 0.0000e+00 - val_loss: 138.8326 - val_accuracy: 0.0588\n",
      "Epoch 6576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4428 - accuracy: 0.0156 - val_loss: 131.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 6577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6051 - accuracy: 0.0000e+00 - val_loss: 125.9714 - val_accuracy: 0.0588\n",
      "Epoch 6578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4205 - accuracy: 0.0000e+00 - val_loss: 121.8622 - val_accuracy: 0.0000e+00\n",
      "Epoch 6579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7586 - accuracy: 0.0000e+00 - val_loss: 122.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 6580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8082 - accuracy: 0.0000e+00 - val_loss: 125.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 6581/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6710 - accuracy: 0.0000e+00 - val_loss: 125.1487 - val_accuracy: 0.0000e+00\n",
      "Epoch 6582/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 26.8448 - accuracy: 0.0156 - val_loss: 127.9754 - val_accuracy: 0.0588\n",
      "Epoch 6583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4702 - accuracy: 0.0000e+00 - val_loss: 127.6210 - val_accuracy: 0.0000e+00\n",
      "Epoch 6584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2621 - accuracy: 0.0156 - val_loss: 123.2244 - val_accuracy: 0.0000e+00\n",
      "Epoch 6585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6120 - accuracy: 0.0156 - val_loss: 118.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 6586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7208 - accuracy: 0.0312 - val_loss: 114.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 6587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9623 - accuracy: 0.0156 - val_loss: 121.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 6588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8752 - accuracy: 0.0312 - val_loss: 124.5103 - val_accuracy: 0.0000e+00\n",
      "Epoch 6589/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0322 - accuracy: 0.0000e+00 - val_loss: 122.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 6590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0874 - accuracy: 0.0156 - val_loss: 117.7999 - val_accuracy: 0.0000e+00\n",
      "Epoch 6591/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.6780 - accuracy: 0.0000e+00 - val_loss: 112.3929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5726 - accuracy: 0.0000e+00 - val_loss: 113.1252 - val_accuracy: 0.0000e+00\n",
      "Epoch 6593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2822 - accuracy: 0.0000e+00 - val_loss: 116.9706 - val_accuracy: 0.0588\n",
      "Epoch 6594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5829 - accuracy: 0.0000e+00 - val_loss: 120.6997 - val_accuracy: 0.0588\n",
      "Epoch 6595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4160 - accuracy: 0.0469 - val_loss: 121.1543 - val_accuracy: 0.0588\n",
      "Epoch 6596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3195 - accuracy: 0.0156 - val_loss: 115.1089 - val_accuracy: 0.0588\n",
      "Epoch 6597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1452 - accuracy: 0.0000e+00 - val_loss: 118.9383 - val_accuracy: 0.0588\n",
      "Epoch 6598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4602 - accuracy: 0.0000e+00 - val_loss: 121.1099 - val_accuracy: 0.0588\n",
      "Epoch 6599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6684 - accuracy: 0.0000e+00 - val_loss: 117.1917 - val_accuracy: 0.0588\n",
      "Epoch 6600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4250 - accuracy: 0.0000e+00 - val_loss: 113.6731 - val_accuracy: 0.0588\n",
      "Epoch 6601/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 32.5682 - accuracy: 0.0000e+00 - val_loss: 115.8059 - val_accuracy: 0.0588\n",
      "Epoch 6602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2502 - accuracy: 0.0312 - val_loss: 124.2008 - val_accuracy: 0.0000e+00\n",
      "Epoch 6603/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2655 - accuracy: 0.0156 - val_loss: 130.3427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4185 - accuracy: 0.0156 - val_loss: 132.8700 - val_accuracy: 0.0000e+00\n",
      "Epoch 6605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2200 - accuracy: 0.0000e+00 - val_loss: 128.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 6606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1712 - accuracy: 0.0156 - val_loss: 125.0731 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7714 - accuracy: 0.0156 - val_loss: 125.8056 - val_accuracy: 0.0588\n",
      "Epoch 6608/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9200 - accuracy: 0.0000e+00 - val_loss: 125.9731 - val_accuracy: 0.0588\n",
      "Epoch 6609/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1087 - accuracy: 0.0156 - val_loss: 128.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 6610/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 15.2859 - accuracy: 0.0156 - val_loss: 126.3004 - val_accuracy: 0.0000e+00\n",
      "Epoch 6611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2510 - accuracy: 0.0156 - val_loss: 127.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 6612/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5140 - accuracy: 0.0000e+00 - val_loss: 130.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 6613/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 20.8281 - accuracy: 0.0000e+00 - val_loss: 131.5772 - val_accuracy: 0.0000e+00\n",
      "Epoch 6614/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3852 - accuracy: 0.0312 - val_loss: 132.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 6615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2328 - accuracy: 0.0156 - val_loss: 134.2973 - val_accuracy: 0.0000e+00\n",
      "Epoch 6616/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7084 - accuracy: 0.0156 - val_loss: 128.0591 - val_accuracy: 0.0000e+00\n",
      "Epoch 6617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1184 - accuracy: 0.0000e+00 - val_loss: 126.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 6618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7221 - accuracy: 0.0000e+00 - val_loss: 127.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 6619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1631 - accuracy: 0.0156 - val_loss: 130.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 6620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4238 - accuracy: 0.0156 - val_loss: 134.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7695 - accuracy: 0.0000e+00 - val_loss: 129.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 6622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4471 - accuracy: 0.0000e+00 - val_loss: 129.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6951 - accuracy: 0.0000e+00 - val_loss: 126.6739 - val_accuracy: 0.0000e+00\n",
      "Epoch 6624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8078 - accuracy: 0.0000e+00 - val_loss: 128.8719 - val_accuracy: 0.0588\n",
      "Epoch 6625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5343 - accuracy: 0.0312 - val_loss: 126.4917 - val_accuracy: 0.0588\n",
      "Epoch 6626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1461 - accuracy: 0.0000e+00 - val_loss: 120.4086 - val_accuracy: 0.0588\n",
      "Epoch 6627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0096 - accuracy: 0.0000e+00 - val_loss: 113.6787 - val_accuracy: 0.0588\n",
      "Epoch 6628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0539 - accuracy: 0.0000e+00 - val_loss: 115.4687 - val_accuracy: 0.0000e+00\n",
      "Epoch 6629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3626 - accuracy: 0.0156 - val_loss: 120.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 6630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3751 - accuracy: 0.0000e+00 - val_loss: 123.2689 - val_accuracy: 0.0000e+00\n",
      "Epoch 6631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3761 - accuracy: 0.0000e+00 - val_loss: 118.8638 - val_accuracy: 0.0000e+00\n",
      "Epoch 6632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7866 - accuracy: 0.0156 - val_loss: 116.6496 - val_accuracy: 0.0000e+00\n",
      "Epoch 6633/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4507 - accuracy: 0.0312 - val_loss: 123.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 6634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0319 - accuracy: 0.0156 - val_loss: 128.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 6635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3586 - accuracy: 0.0156 - val_loss: 127.8731 - val_accuracy: 0.0588\n",
      "Epoch 6636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4549 - accuracy: 0.0000e+00 - val_loss: 128.1302 - val_accuracy: 0.0588\n",
      "Epoch 6637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1457 - accuracy: 0.0156 - val_loss: 127.7830 - val_accuracy: 0.0588\n",
      "Epoch 6638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0782 - accuracy: 0.0312 - val_loss: 129.3582 - val_accuracy: 0.0588\n",
      "Epoch 6639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2757 - accuracy: 0.0000e+00 - val_loss: 128.0610 - val_accuracy: 0.0588\n",
      "Epoch 6640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0689 - accuracy: 0.0000e+00 - val_loss: 125.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 6641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2485 - accuracy: 0.0000e+00 - val_loss: 121.5588 - val_accuracy: 0.0000e+00\n",
      "Epoch 6642/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 31.8505 - accuracy: 0.0156 - val_loss: 117.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 6643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9864 - accuracy: 0.0156 - val_loss: 111.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 6644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2992 - accuracy: 0.0000e+00 - val_loss: 113.2594 - val_accuracy: 0.0000e+00\n",
      "Epoch 6645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0038 - accuracy: 0.0156 - val_loss: 116.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1434 - accuracy: 0.0000e+00 - val_loss: 119.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 6647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6606 - accuracy: 0.0000e+00 - val_loss: 126.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 6648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4921 - accuracy: 0.0156 - val_loss: 125.5515 - val_accuracy: 0.0000e+00\n",
      "Epoch 6649/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.9941 - accuracy: 0.0000e+00 - val_loss: 125.0569 - val_accuracy: 0.0000e+00\n",
      "Epoch 6650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2520 - accuracy: 0.0000e+00 - val_loss: 122.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 6651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3981 - accuracy: 0.0156 - val_loss: 119.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2071 - accuracy: 0.0000e+00 - val_loss: 124.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6653/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 27.4252 - accuracy: 0.0000e+00 - val_loss: 135.2811 - val_accuracy: 0.0000e+00\n",
      "Epoch 6654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7358 - accuracy: 0.0000e+00 - val_loss: 147.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6655/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.8846 - accuracy: 0.0156 - val_loss: 146.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 6656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7804 - accuracy: 0.0000e+00 - val_loss: 140.4502 - val_accuracy: 0.0000e+00\n",
      "Epoch 6657/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 29.8474 - accuracy: 0.0156 - val_loss: 127.5343 - val_accuracy: 0.0000e+00\n",
      "Epoch 6658/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 41.3669 - accuracy: 0.0000e+00 - val_loss: 118.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 6659/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 28.3901 - accuracy: 0.0000e+00 - val_loss: 115.5412 - val_accuracy: 0.0588\n",
      "Epoch 6660/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.1650 - accuracy: 0.0000e+00 - val_loss: 129.4802 - val_accuracy: 0.0588\n",
      "Epoch 6661/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5924 - accuracy: 0.0000e+00 - val_loss: 140.8028 - val_accuracy: 0.0588\n",
      "Epoch 6662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1324 - accuracy: 0.0312 - val_loss: 140.0893 - val_accuracy: 0.0588\n",
      "Epoch 6663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1071 - accuracy: 0.0000e+00 - val_loss: 135.3899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0825 - accuracy: 0.0156 - val_loss: 130.5478 - val_accuracy: 0.0588\n",
      "Epoch 6665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2825 - accuracy: 0.0312 - val_loss: 130.5226 - val_accuracy: 0.0588\n",
      "Epoch 6666/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8705 - accuracy: 0.0000e+00 - val_loss: 128.0607 - val_accuracy: 0.0588\n",
      "Epoch 6667/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 27.2617 - accuracy: 0.0312 - val_loss: 126.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 6668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9467 - accuracy: 0.0000e+00 - val_loss: 126.8737 - val_accuracy: 0.0588\n",
      "Epoch 6669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8206 - accuracy: 0.0000e+00 - val_loss: 131.8976 - val_accuracy: 0.0588\n",
      "Epoch 6670/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.6016 - accuracy: 0.0000e+00 - val_loss: 129.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 6671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6416 - accuracy: 0.0000e+00 - val_loss: 115.2986 - val_accuracy: 0.0000e+00\n",
      "Epoch 6672/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6360 - accuracy: 0.0156 - val_loss: 114.0157 - val_accuracy: 0.0588\n",
      "Epoch 6673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0205 - accuracy: 0.0000e+00 - val_loss: 119.1805 - val_accuracy: 0.0000e+00\n",
      "Epoch 6674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4340 - accuracy: 0.0469 - val_loss: 124.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 6675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4115 - accuracy: 0.0156 - val_loss: 125.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 6676/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.4232 - accuracy: 0.0000e+00 - val_loss: 125.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 6677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2271 - accuracy: 0.0312 - val_loss: 126.3478 - val_accuracy: 0.0000e+00\n",
      "Epoch 6678/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.1316 - accuracy: 0.0000e+00 - val_loss: 128.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 6679/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6326 - accuracy: 0.0000e+00 - val_loss: 133.2060 - val_accuracy: 0.0588\n",
      "Epoch 6680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0897 - accuracy: 0.0000e+00 - val_loss: 129.4544 - val_accuracy: 0.0588\n",
      "Epoch 6681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8924 - accuracy: 0.0312 - val_loss: 115.3609 - val_accuracy: 0.0588\n",
      "Epoch 6682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0860 - accuracy: 0.0312 - val_loss: 107.9240 - val_accuracy: 0.0588\n",
      "Epoch 6683/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.5142 - accuracy: 0.0000e+00 - val_loss: 111.3752 - val_accuracy: 0.0588\n",
      "Epoch 6684/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 31.8394 - accuracy: 0.0156 - val_loss: 121.2688 - val_accuracy: 0.0000e+00\n",
      "Epoch 6685/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 30.0651 - accuracy: 0.0312 - val_loss: 136.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 6686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3391 - accuracy: 0.0000e+00 - val_loss: 141.5050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8302 - accuracy: 0.0000e+00 - val_loss: 138.5422 - val_accuracy: 0.0588\n",
      "Epoch 6688/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3284 - accuracy: 0.0000e+00 - val_loss: 130.3685 - val_accuracy: 0.0588\n",
      "Epoch 6689/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3446 - accuracy: 0.0156 - val_loss: 125.8992 - val_accuracy: 0.0588\n",
      "Epoch 6690/10000\n",
      "64/64 [==============================] - 0s 199us/step - loss: 29.5910 - accuracy: 0.0312 - val_loss: 143.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6691/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 28.8228 - accuracy: 0.0000e+00 - val_loss: 157.1952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1754 - accuracy: 0.0156 - val_loss: 146.0092 - val_accuracy: 0.0588\n",
      "Epoch 6693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6832 - accuracy: 0.0000e+00 - val_loss: 133.5065 - val_accuracy: 0.0588\n",
      "Epoch 6694/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.8134 - accuracy: 0.0000e+00 - val_loss: 133.1422 - val_accuracy: 0.0000e+00\n",
      "Epoch 6695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8381 - accuracy: 0.0000e+00 - val_loss: 131.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7149 - accuracy: 0.0000e+00 - val_loss: 128.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 6697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3235 - accuracy: 0.0156 - val_loss: 126.4400 - val_accuracy: 0.0588\n",
      "Epoch 6698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8303 - accuracy: 0.0000e+00 - val_loss: 119.7225 - val_accuracy: 0.0588\n",
      "Epoch 6699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2259 - accuracy: 0.0156 - val_loss: 121.4745 - val_accuracy: 0.0588\n",
      "Epoch 6700/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6170 - accuracy: 0.0156 - val_loss: 128.1539 - val_accuracy: 0.0588\n",
      "Epoch 6701/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9274 - accuracy: 0.0156 - val_loss: 128.6881 - val_accuracy: 0.0588\n",
      "Epoch 6702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9856 - accuracy: 0.0312 - val_loss: 128.9020 - val_accuracy: 0.0588\n",
      "Epoch 6703/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.0412 - accuracy: 0.0156 - val_loss: 124.9985 - val_accuracy: 0.0588\n",
      "Epoch 6704/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.4984 - accuracy: 0.0000e+00 - val_loss: 119.8799 - val_accuracy: 0.1176\n",
      "Epoch 6705/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5281 - accuracy: 0.0000e+00 - val_loss: 121.5036 - val_accuracy: 0.0588\n",
      "Epoch 6706/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 24.6508 - accuracy: 0.0000e+00 - val_loss: 128.4031 - val_accuracy: 0.0588\n",
      "Epoch 6707/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1861 - accuracy: 0.0000e+00 - val_loss: 129.7457 - val_accuracy: 0.0588\n",
      "Epoch 6708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1595 - accuracy: 0.0000e+00 - val_loss: 127.6443 - val_accuracy: 0.0588\n",
      "Epoch 6709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6199 - accuracy: 0.0156 - val_loss: 127.5342 - val_accuracy: 0.0588\n",
      "Epoch 6710/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8500 - accuracy: 0.0000e+00 - val_loss: 130.8031 - val_accuracy: 0.0588\n",
      "Epoch 6711/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.6278 - accuracy: 0.0156 - val_loss: 130.8918 - val_accuracy: 0.0588\n",
      "Epoch 6712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 104us/step - loss: 26.3799 - accuracy: 0.0312 - val_loss: 129.4120 - val_accuracy: 0.0588\n",
      "Epoch 6713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4553 - accuracy: 0.0000e+00 - val_loss: 127.0516 - val_accuracy: 0.0588\n",
      "Epoch 6714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0034 - accuracy: 0.0000e+00 - val_loss: 118.8956 - val_accuracy: 0.0588\n",
      "Epoch 6715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7060 - accuracy: 0.0000e+00 - val_loss: 112.7055 - val_accuracy: 0.0588\n",
      "Epoch 6716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7538 - accuracy: 0.0000e+00 - val_loss: 117.0490 - val_accuracy: 0.0588\n",
      "Epoch 6717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7013 - accuracy: 0.0156 - val_loss: 123.6628 - val_accuracy: 0.0588\n",
      "Epoch 6718/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 24.6450 - accuracy: 0.0156 - val_loss: 126.0763 - val_accuracy: 0.0588\n",
      "Epoch 6719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8888 - accuracy: 0.0000e+00 - val_loss: 126.1827 - val_accuracy: 0.1176\n",
      "Epoch 6720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1276 - accuracy: 0.0156 - val_loss: 121.4478 - val_accuracy: 0.1176\n",
      "Epoch 6721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8759 - accuracy: 0.0000e+00 - val_loss: 116.9760 - val_accuracy: 0.1176\n",
      "Epoch 6722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6754 - accuracy: 0.0000e+00 - val_loss: 121.3678 - val_accuracy: 0.0588\n",
      "Epoch 6723/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.8510 - accuracy: 0.0000e+00 - val_loss: 122.8974 - val_accuracy: 0.0588\n",
      "Epoch 6724/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 28.8660 - accuracy: 0.0000e+00 - val_loss: 127.3021 - val_accuracy: 0.0588\n",
      "Epoch 6725/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 20.5140 - accuracy: 0.0156 - val_loss: 124.7450 - val_accuracy: 0.0588\n",
      "Epoch 6726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5461 - accuracy: 0.0000e+00 - val_loss: 124.3557 - val_accuracy: 0.0588\n",
      "Epoch 6727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4525 - accuracy: 0.0000e+00 - val_loss: 117.6771 - val_accuracy: 0.0588\n",
      "Epoch 6728/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 26.5692 - accuracy: 0.0156 - val_loss: 107.1137 - val_accuracy: 0.1176\n",
      "Epoch 6729/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.6909 - accuracy: 0.0469 - val_loss: 106.1540 - val_accuracy: 0.1176\n",
      "Epoch 6730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5361 - accuracy: 0.0000e+00 - val_loss: 104.2915 - val_accuracy: 0.0588\n",
      "Epoch 6731/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 35.3734 - accuracy: 0.0156 - val_loss: 111.3962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6732/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.1723 - accuracy: 0.0000e+00 - val_loss: 120.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 6733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3305 - accuracy: 0.0312 - val_loss: 127.3303 - val_accuracy: 0.0000e+00\n",
      "Epoch 6734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2085 - accuracy: 0.0000e+00 - val_loss: 126.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 6735/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 34.3443 - accuracy: 0.0000e+00 - val_loss: 127.9442 - val_accuracy: 0.0000e+00\n",
      "Epoch 6736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6355 - accuracy: 0.0156 - val_loss: 131.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 6737/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6099 - accuracy: 0.0156 - val_loss: 134.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 6738/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 34.6363 - accuracy: 0.0469 - val_loss: 136.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 6739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9609 - accuracy: 0.0156 - val_loss: 135.7630 - val_accuracy: 0.0588\n",
      "Epoch 6740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1431 - accuracy: 0.0000e+00 - val_loss: 133.6134 - val_accuracy: 0.0588\n",
      "Epoch 6741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0968 - accuracy: 0.0000e+00 - val_loss: 128.3624 - val_accuracy: 0.0588\n",
      "Epoch 6742/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.4453 - accuracy: 0.0156 - val_loss: 125.8208 - val_accuracy: 0.0588\n",
      "Epoch 6743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5172 - accuracy: 0.0000e+00 - val_loss: 131.4504 - val_accuracy: 0.0588\n",
      "Epoch 6744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0381 - accuracy: 0.0000e+00 - val_loss: 133.0186 - val_accuracy: 0.0588\n",
      "Epoch 6745/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8260 - accuracy: 0.0000e+00 - val_loss: 129.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 6746/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 32.8097 - accuracy: 0.0156 - val_loss: 129.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 6747/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 21.0258 - accuracy: 0.0000e+00 - val_loss: 128.8006 - val_accuracy: 0.0000e+00\n",
      "Epoch 6748/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9684 - accuracy: 0.0000e+00 - val_loss: 126.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1314 - accuracy: 0.0000e+00 - val_loss: 125.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 6750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2179 - accuracy: 0.0156 - val_loss: 125.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 6751/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4247 - accuracy: 0.0000e+00 - val_loss: 131.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 6752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1806 - accuracy: 0.0000e+00 - val_loss: 129.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 6753/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4875 - accuracy: 0.0000e+00 - val_loss: 128.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 6754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1578 - accuracy: 0.0469 - val_loss: 119.6655 - val_accuracy: 0.0000e+00\n",
      "Epoch 6755/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 33.3350 - accuracy: 0.0000e+00 - val_loss: 117.7457 - val_accuracy: 0.0588\n",
      "Epoch 6756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7569 - accuracy: 0.0000e+00 - val_loss: 120.9258 - val_accuracy: 0.0588\n",
      "Epoch 6757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7854 - accuracy: 0.0312 - val_loss: 124.9777 - val_accuracy: 0.0588\n",
      "Epoch 6758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8725 - accuracy: 0.0312 - val_loss: 129.8688 - val_accuracy: 0.0588\n",
      "Epoch 6759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7358 - accuracy: 0.0156 - val_loss: 135.8167 - val_accuracy: 0.0588\n",
      "Epoch 6760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7271 - accuracy: 0.0156 - val_loss: 128.2707 - val_accuracy: 0.0588\n",
      "Epoch 6761/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1586 - accuracy: 0.0000e+00 - val_loss: 124.4343 - val_accuracy: 0.0588\n",
      "Epoch 6762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8549 - accuracy: 0.0000e+00 - val_loss: 123.3091 - val_accuracy: 0.0588\n",
      "Epoch 6763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2953 - accuracy: 0.0000e+00 - val_loss: 124.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 6764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8144 - accuracy: 0.0000e+00 - val_loss: 123.0918 - val_accuracy: 0.0588\n",
      "Epoch 6765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6518 - accuracy: 0.0312 - val_loss: 121.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 6766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7482 - accuracy: 0.0156 - val_loss: 126.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6767/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 24.0250 - accuracy: 0.0000e+00 - val_loss: 130.9056 - val_accuracy: 0.0000e+00\n",
      "Epoch 6768/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 21.3610 - accuracy: 0.0000e+00 - val_loss: 136.2808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6769/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 22.6005 - accuracy: 0.0000e+00 - val_loss: 131.0399 - val_accuracy: 0.0588\n",
      "Epoch 6770/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 18.8021 - accuracy: 0.0000e+00 - val_loss: 122.7709 - val_accuracy: 0.0588\n",
      "Epoch 6771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5276 - accuracy: 0.0000e+00 - val_loss: 113.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 6772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0978 - accuracy: 0.0156 - val_loss: 118.3007 - val_accuracy: 0.0000e+00\n",
      "Epoch 6773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3752 - accuracy: 0.0000e+00 - val_loss: 123.0184 - val_accuracy: 0.0588\n",
      "Epoch 6774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3355 - accuracy: 0.0000e+00 - val_loss: 122.8118 - val_accuracy: 0.0588\n",
      "Epoch 6775/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8452 - accuracy: 0.0156 - val_loss: 126.6162 - val_accuracy: 0.1176\n",
      "Epoch 6776/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 18.6823 - accuracy: 0.0000e+00 - val_loss: 126.8628 - val_accuracy: 0.0588\n",
      "Epoch 6777/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7590 - accuracy: 0.0000e+00 - val_loss: 126.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 6778/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6412 - accuracy: 0.0000e+00 - val_loss: 127.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6779/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 27.6512 - accuracy: 0.0000e+00 - val_loss: 130.4193 - val_accuracy: 0.0588\n",
      "Epoch 6780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3104 - accuracy: 0.0000e+00 - val_loss: 133.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 6781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1653 - accuracy: 0.0312 - val_loss: 128.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0756 - accuracy: 0.0156 - val_loss: 118.8369 - val_accuracy: 0.0588\n",
      "Epoch 6783/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0880 - accuracy: 0.0156 - val_loss: 112.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 6784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9629 - accuracy: 0.0000e+00 - val_loss: 117.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 6785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6724 - accuracy: 0.0312 - val_loss: 123.1961 - val_accuracy: 0.0588\n",
      "Epoch 6786/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 36.4996 - accuracy: 0.0000e+00 - val_loss: 126.2488 - val_accuracy: 0.0588\n",
      "Epoch 6787/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 43.3797 - accuracy: 0.0000e+00 - val_loss: 121.2172 - val_accuracy: 0.0588\n",
      "Epoch 6788/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 16.2383 - accuracy: 0.0000e+00 - val_loss: 112.3806 - val_accuracy: 0.0588\n",
      "Epoch 6789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1510 - accuracy: 0.0156 - val_loss: 106.6964 - val_accuracy: 0.0588\n",
      "Epoch 6790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7864 - accuracy: 0.0000e+00 - val_loss: 111.2325 - val_accuracy: 0.0000e+00\n",
      "Epoch 6791/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.2513 - accuracy: 0.0156 - val_loss: 124.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 6792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1571 - accuracy: 0.0156 - val_loss: 138.8755 - val_accuracy: 0.0588\n",
      "Epoch 6793/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7285 - accuracy: 0.0156 - val_loss: 139.9808 - val_accuracy: 0.0588\n",
      "Epoch 6794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0702 - accuracy: 0.0469 - val_loss: 138.9275 - val_accuracy: 0.0588\n",
      "Epoch 6795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7716 - accuracy: 0.0156 - val_loss: 133.6324 - val_accuracy: 0.0588\n",
      "Epoch 6796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0417 - accuracy: 0.0000e+00 - val_loss: 127.6972 - val_accuracy: 0.0588\n",
      "Epoch 6797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9786 - accuracy: 0.0000e+00 - val_loss: 126.1755 - val_accuracy: 0.0000e+00\n",
      "Epoch 6798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9616 - accuracy: 0.0000e+00 - val_loss: 125.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 6799/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 28.5707 - accuracy: 0.0000e+00 - val_loss: 126.8023 - val_accuracy: 0.0000e+00\n",
      "Epoch 6800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6316 - accuracy: 0.0000e+00 - val_loss: 131.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 6801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0205 - accuracy: 0.0156 - val_loss: 136.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 6802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8018 - accuracy: 0.0000e+00 - val_loss: 138.5770 - val_accuracy: 0.0588\n",
      "Epoch 6803/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6427 - accuracy: 0.0156 - val_loss: 136.4146 - val_accuracy: 0.1176\n",
      "Epoch 6804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7108 - accuracy: 0.0156 - val_loss: 133.4857 - val_accuracy: 0.0000e+00\n",
      "Epoch 6805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3279 - accuracy: 0.0000e+00 - val_loss: 133.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 6806/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7825 - accuracy: 0.0000e+00 - val_loss: 132.5641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7803 - accuracy: 0.0156 - val_loss: 136.6145 - val_accuracy: 0.1176\n",
      "Epoch 6808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8307 - accuracy: 0.0000e+00 - val_loss: 141.4711 - val_accuracy: 0.0588\n",
      "Epoch 6809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3789 - accuracy: 0.0000e+00 - val_loss: 143.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7222 - accuracy: 0.0156 - val_loss: 144.4638 - val_accuracy: 0.0000e+00\n",
      "Epoch 6811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8903 - accuracy: 0.0156 - val_loss: 141.4827 - val_accuracy: 0.0000e+00\n",
      "Epoch 6812/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 36.7584 - accuracy: 0.0156 - val_loss: 133.6260 - val_accuracy: 0.0588\n",
      "Epoch 6813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6667 - accuracy: 0.0156 - val_loss: 126.0223 - val_accuracy: 0.0588\n",
      "Epoch 6814/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6694 - accuracy: 0.0156 - val_loss: 122.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 6815/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 25.2613 - accuracy: 0.0312 - val_loss: 118.9361 - val_accuracy: 0.0000e+00\n",
      "Epoch 6816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7001 - accuracy: 0.0000e+00 - val_loss: 117.5023 - val_accuracy: 0.0588\n",
      "Epoch 6817/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4969 - accuracy: 0.0000e+00 - val_loss: 113.9259 - val_accuracy: 0.0588\n",
      "Epoch 6818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 32.5564 - accuracy: 0.0000e+00 - val_loss: 110.4482 - val_accuracy: 0.0588\n",
      "Epoch 6819/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.3732 - accuracy: 0.0312 - val_loss: 114.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6820/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 30.8904 - accuracy: 0.0000e+00 - val_loss: 122.4036 - val_accuracy: 0.0588\n",
      "Epoch 6821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5643 - accuracy: 0.0000e+00 - val_loss: 134.1804 - val_accuracy: 0.0588\n",
      "Epoch 6822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7899 - accuracy: 0.0000e+00 - val_loss: 130.4634 - val_accuracy: 0.0000e+00\n",
      "Epoch 6823/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.7357 - accuracy: 0.0156 - val_loss: 121.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 6824/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0410 - accuracy: 0.0000e+00 - val_loss: 117.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 6825/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3735 - accuracy: 0.0000e+00 - val_loss: 116.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 6826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1836 - accuracy: 0.0000e+00 - val_loss: 122.2145 - val_accuracy: 0.0588\n",
      "Epoch 6827/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.6757 - accuracy: 0.0312 - val_loss: 127.2941 - val_accuracy: 0.0588\n",
      "Epoch 6828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5778 - accuracy: 0.0156 - val_loss: 130.0657 - val_accuracy: 0.0588\n",
      "Epoch 6829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9480 - accuracy: 0.0000e+00 - val_loss: 127.1331 - val_accuracy: 0.0588\n",
      "Epoch 6830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6157 - accuracy: 0.0000e+00 - val_loss: 122.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 6831/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 25.6230 - accuracy: 0.0000e+00 - val_loss: 119.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8494 - accuracy: 0.0156 - val_loss: 115.6996 - val_accuracy: 0.0588\n",
      "Epoch 6833/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3492 - accuracy: 0.0000e+00 - val_loss: 116.3995 - val_accuracy: 0.0588\n",
      "Epoch 6834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8259 - accuracy: 0.0000e+00 - val_loss: 120.9999 - val_accuracy: 0.0588\n",
      "Epoch 6835/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7266 - accuracy: 0.0000e+00 - val_loss: 123.5747 - val_accuracy: 0.0588\n",
      "Epoch 6836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0840 - accuracy: 0.0000e+00 - val_loss: 120.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 6837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5726 - accuracy: 0.0000e+00 - val_loss: 121.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 6838/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2560 - accuracy: 0.0312 - val_loss: 128.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 6839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1494 - accuracy: 0.0156 - val_loss: 135.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 6840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7655 - accuracy: 0.0625 - val_loss: 147.5371 - val_accuracy: 0.0588\n",
      "Epoch 6841/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.4979 - accuracy: 0.0000e+00 - val_loss: 145.5546 - val_accuracy: 0.0588\n",
      "Epoch 6842/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.8276 - accuracy: 0.0000e+00 - val_loss: 128.1020 - val_accuracy: 0.1176\n",
      "Epoch 6843/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7072 - accuracy: 0.0156 - val_loss: 121.8577 - val_accuracy: 0.0000e+00\n",
      "Epoch 6844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7450 - accuracy: 0.0156 - val_loss: 121.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 6845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1230 - accuracy: 0.0000e+00 - val_loss: 128.1859 - val_accuracy: 0.0000e+00\n",
      "Epoch 6846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9301 - accuracy: 0.0312 - val_loss: 135.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 6847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6733 - accuracy: 0.0000e+00 - val_loss: 136.1950 - val_accuracy: 0.0000e+00\n",
      "Epoch 6848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0551 - accuracy: 0.0156 - val_loss: 128.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 6849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4496 - accuracy: 0.0312 - val_loss: 123.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 6850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2227 - accuracy: 0.0000e+00 - val_loss: 114.0676 - val_accuracy: 0.0588\n",
      "Epoch 6851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6163 - accuracy: 0.0156 - val_loss: 112.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6852/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3496 - accuracy: 0.0000e+00 - val_loss: 116.4173 - val_accuracy: 0.0588\n",
      "Epoch 6853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5967 - accuracy: 0.0000e+00 - val_loss: 130.1024 - val_accuracy: 0.0588\n",
      "Epoch 6854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7521 - accuracy: 0.0000e+00 - val_loss: 140.9796 - val_accuracy: 0.0588\n",
      "Epoch 6855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1569 - accuracy: 0.0156 - val_loss: 141.7514 - val_accuracy: 0.0000e+00\n",
      "Epoch 6856/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.7372 - accuracy: 0.0000e+00 - val_loss: 137.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 6857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8761 - accuracy: 0.0156 - val_loss: 132.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9654 - accuracy: 0.0000e+00 - val_loss: 128.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 6859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6927 - accuracy: 0.0156 - val_loss: 124.9834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0891 - accuracy: 0.0156 - val_loss: 125.0628 - val_accuracy: 0.0000e+00\n",
      "Epoch 6861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2268 - accuracy: 0.0000e+00 - val_loss: 126.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 6862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2229 - accuracy: 0.0000e+00 - val_loss: 129.7276 - val_accuracy: 0.0000e+00\n",
      "Epoch 6863/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 20.5303 - accuracy: 0.0000e+00 - val_loss: 138.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 6864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1188 - accuracy: 0.0000e+00 - val_loss: 145.5293 - val_accuracy: 0.0000e+00\n",
      "Epoch 6865/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.0220 - accuracy: 0.0000e+00 - val_loss: 142.4010 - val_accuracy: 0.0000e+00\n",
      "Epoch 6866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7487 - accuracy: 0.0312 - val_loss: 132.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9426 - accuracy: 0.0156 - val_loss: 124.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 6868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1668 - accuracy: 0.0000e+00 - val_loss: 127.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 6869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4774 - accuracy: 0.0156 - val_loss: 134.6920 - val_accuracy: 0.0000e+00\n",
      "Epoch 6870/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 10.2175 - accuracy: 0.0000e+00 - val_loss: 136.8701 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7140 - accuracy: 0.0156 - val_loss: 134.7614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4925 - accuracy: 0.0156 - val_loss: 124.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 6873/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 25.8759 - accuracy: 0.0000e+00 - val_loss: 119.2240 - val_accuracy: 0.0000e+00\n",
      "Epoch 6874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3392 - accuracy: 0.0000e+00 - val_loss: 121.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 6875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1369 - accuracy: 0.0156 - val_loss: 128.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 6876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0358 - accuracy: 0.0000e+00 - val_loss: 140.3839 - val_accuracy: 0.0000e+00\n",
      "Epoch 6877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1787 - accuracy: 0.0000e+00 - val_loss: 144.6080 - val_accuracy: 0.0588\n",
      "Epoch 6878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0710 - accuracy: 0.0156 - val_loss: 142.0568 - val_accuracy: 0.0588\n",
      "Epoch 6879/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.3251 - accuracy: 0.0156 - val_loss: 133.1828 - val_accuracy: 0.1176\n",
      "Epoch 6880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7626 - accuracy: 0.0156 - val_loss: 125.6065 - val_accuracy: 0.1176\n",
      "Epoch 6881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7465 - accuracy: 0.0000e+00 - val_loss: 121.9081 - val_accuracy: 0.1176\n",
      "Epoch 6882/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 24.3912 - accuracy: 0.0000e+00 - val_loss: 121.4704 - val_accuracy: 0.0588\n",
      "Epoch 6883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0612 - accuracy: 0.0000e+00 - val_loss: 127.6182 - val_accuracy: 0.0588\n",
      "Epoch 6884/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.5869 - accuracy: 0.0000e+00 - val_loss: 132.5367 - val_accuracy: 0.0588\n",
      "Epoch 6885/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 28.7386 - accuracy: 0.0156 - val_loss: 131.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 6886/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 22.4256 - accuracy: 0.0156 - val_loss: 125.6612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6887/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 27.2255 - accuracy: 0.0156 - val_loss: 120.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 6888/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 28.2840 - accuracy: 0.0156 - val_loss: 120.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 6889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7766 - accuracy: 0.0156 - val_loss: 130.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 6890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5931 - accuracy: 0.0000e+00 - val_loss: 133.1892 - val_accuracy: 0.0000e+00\n",
      "Epoch 6891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3867 - accuracy: 0.0000e+00 - val_loss: 132.0433 - val_accuracy: 0.0588\n",
      "Epoch 6892/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8011 - accuracy: 0.0156 - val_loss: 134.4425 - val_accuracy: 0.0588\n",
      "Epoch 6893/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 28.5797 - accuracy: 0.0156 - val_loss: 136.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 6894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9886 - accuracy: 0.0312 - val_loss: 135.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 6895/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 20.7101 - accuracy: 0.0156 - val_loss: 133.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 6896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2087 - accuracy: 0.0000e+00 - val_loss: 132.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 6897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1884 - accuracy: 0.0312 - val_loss: 138.2581 - val_accuracy: 0.0000e+00\n",
      "Epoch 6898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4527 - accuracy: 0.0000e+00 - val_loss: 139.9613 - val_accuracy: 0.0588\n",
      "Epoch 6899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6630 - accuracy: 0.0156 - val_loss: 137.9805 - val_accuracy: 0.0588\n",
      "Epoch 6900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4633 - accuracy: 0.0000e+00 - val_loss: 133.1068 - val_accuracy: 0.0588\n",
      "Epoch 6901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0063 - accuracy: 0.0156 - val_loss: 127.4675 - val_accuracy: 0.0588\n",
      "Epoch 6902/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.0662 - accuracy: 0.0000e+00 - val_loss: 129.2436 - val_accuracy: 0.0588\n",
      "Epoch 6903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6855 - accuracy: 0.0156 - val_loss: 129.3474 - val_accuracy: 0.0588\n",
      "Epoch 6904/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.4139 - accuracy: 0.0000e+00 - val_loss: 130.6934 - val_accuracy: 0.0588\n",
      "Epoch 6905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9624 - accuracy: 0.0312 - val_loss: 131.9380 - val_accuracy: 0.0588\n",
      "Epoch 6906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3759 - accuracy: 0.0000e+00 - val_loss: 130.2829 - val_accuracy: 0.0588\n",
      "Epoch 6907/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0528 - accuracy: 0.0156 - val_loss: 121.1936 - val_accuracy: 0.0588\n",
      "Epoch 6908/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4321 - accuracy: 0.0312 - val_loss: 119.3551 - val_accuracy: 0.0588\n",
      "Epoch 6909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4346 - accuracy: 0.0000e+00 - val_loss: 120.2491 - val_accuracy: 0.0588\n",
      "Epoch 6910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2963 - accuracy: 0.0156 - val_loss: 130.1434 - val_accuracy: 0.0588\n",
      "Epoch 6911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4344 - accuracy: 0.0156 - val_loss: 140.3197 - val_accuracy: 0.0000e+00\n",
      "Epoch 6912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6405 - accuracy: 0.0000e+00 - val_loss: 150.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 6913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6011 - accuracy: 0.0156 - val_loss: 155.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 6914/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4796 - accuracy: 0.0000e+00 - val_loss: 153.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 6915/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.3627 - accuracy: 0.0000e+00 - val_loss: 147.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 6916/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.3297 - accuracy: 0.0156 - val_loss: 138.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 6917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5314 - accuracy: 0.0000e+00 - val_loss: 134.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 6918/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 23.1204 - accuracy: 0.0156 - val_loss: 132.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 6919/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.9046 - accuracy: 0.0000e+00 - val_loss: 131.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7076 - accuracy: 0.0156 - val_loss: 133.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3529 - accuracy: 0.0156 - val_loss: 133.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 6922/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 17.8920 - accuracy: 0.0156 - val_loss: 133.1607 - val_accuracy: 0.0000e+00\n",
      "Epoch 6923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9474 - accuracy: 0.0000e+00 - val_loss: 130.3487 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8377 - accuracy: 0.0156 - val_loss: 130.6620 - val_accuracy: 0.0588\n",
      "Epoch 6925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4368 - accuracy: 0.0000e+00 - val_loss: 137.6691 - val_accuracy: 0.0000e+00\n",
      "Epoch 6926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8405 - accuracy: 0.0000e+00 - val_loss: 150.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 6927/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 33.5474 - accuracy: 0.0156 - val_loss: 151.9947 - val_accuracy: 0.0000e+00\n",
      "Epoch 6928/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7373 - accuracy: 0.0156 - val_loss: 139.3641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7028 - accuracy: 0.0000e+00 - val_loss: 117.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6930/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 26.8723 - accuracy: 0.0156 - val_loss: 107.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6931/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6043 - accuracy: 0.0156 - val_loss: 107.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 6932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9791 - accuracy: 0.0156 - val_loss: 111.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 6933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6656 - accuracy: 0.0000e+00 - val_loss: 122.5295 - val_accuracy: 0.0000e+00\n",
      "Epoch 6934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6794 - accuracy: 0.0000e+00 - val_loss: 133.5874 - val_accuracy: 0.0000e+00\n",
      "Epoch 6935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1739 - accuracy: 0.0000e+00 - val_loss: 137.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 6936/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6126 - accuracy: 0.0312 - val_loss: 132.6998 - val_accuracy: 0.0588\n",
      "Epoch 6937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9975 - accuracy: 0.0000e+00 - val_loss: 126.2447 - val_accuracy: 0.0588\n",
      "Epoch 6938/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.9358 - accuracy: 0.0156 - val_loss: 124.9667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6939/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.1082 - accuracy: 0.0156 - val_loss: 126.0795 - val_accuracy: 0.0588\n",
      "Epoch 6940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9135 - accuracy: 0.0000e+00 - val_loss: 131.0326 - val_accuracy: 0.0588\n",
      "Epoch 6941/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 19.0239 - accuracy: 0.0312 - val_loss: 135.6707 - val_accuracy: 0.0588\n",
      "Epoch 6942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5884 - accuracy: 0.0156 - val_loss: 140.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 6943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8408 - accuracy: 0.0156 - val_loss: 141.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 6944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2092 - accuracy: 0.0156 - val_loss: 141.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 6945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7167 - accuracy: 0.0000e+00 - val_loss: 142.7762 - val_accuracy: 0.0000e+00\n",
      "Epoch 6946/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.1778 - accuracy: 0.0000e+00 - val_loss: 145.5298 - val_accuracy: 0.0000e+00\n",
      "Epoch 6947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6726 - accuracy: 0.0000e+00 - val_loss: 146.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9555 - accuracy: 0.0156 - val_loss: 141.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6949/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 36.8482 - accuracy: 0.0312 - val_loss: 134.3972 - val_accuracy: 0.0000e+00\n",
      "Epoch 6950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6504 - accuracy: 0.0000e+00 - val_loss: 125.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 6951/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 19.1638 - accuracy: 0.0000e+00 - val_loss: 117.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 6952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0569 - accuracy: 0.0469 - val_loss: 120.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 6953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5158 - accuracy: 0.0000e+00 - val_loss: 126.7804 - val_accuracy: 0.0000e+00\n",
      "Epoch 6954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2633 - accuracy: 0.0000e+00 - val_loss: 124.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8047 - accuracy: 0.0000e+00 - val_loss: 136.4296 - val_accuracy: 0.0000e+00\n",
      "Epoch 6956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4050 - accuracy: 0.0000e+00 - val_loss: 146.1744 - val_accuracy: 0.0588\n",
      "Epoch 6957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6023 - accuracy: 0.0000e+00 - val_loss: 155.4180 - val_accuracy: 0.0588\n",
      "Epoch 6958/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.8723 - accuracy: 0.0156 - val_loss: 157.4693 - val_accuracy: 0.0588\n",
      "Epoch 6959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9395 - accuracy: 0.0000e+00 - val_loss: 143.4741 - val_accuracy: 0.0588\n",
      "Epoch 6960/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.7841 - accuracy: 0.0000e+00 - val_loss: 122.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1619 - accuracy: 0.0000e+00 - val_loss: 105.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 6962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5786 - accuracy: 0.0156 - val_loss: 103.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 6963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1234 - accuracy: 0.0156 - val_loss: 106.7836 - val_accuracy: 0.0000e+00\n",
      "Epoch 6964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2784 - accuracy: 0.0156 - val_loss: 117.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 6965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4522 - accuracy: 0.0156 - val_loss: 126.9653 - val_accuracy: 0.0000e+00\n",
      "Epoch 6966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4809 - accuracy: 0.0000e+00 - val_loss: 127.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 6967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6074 - accuracy: 0.0000e+00 - val_loss: 129.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 6968/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1748 - accuracy: 0.0000e+00 - val_loss: 133.4357 - val_accuracy: 0.0000e+00\n",
      "Epoch 6969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1995 - accuracy: 0.0156 - val_loss: 133.8064 - val_accuracy: 0.0000e+00\n",
      "Epoch 6970/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 33.1622 - accuracy: 0.0156 - val_loss: 136.9608 - val_accuracy: 0.0588\n",
      "Epoch 6971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8432 - accuracy: 0.0000e+00 - val_loss: 140.7182 - val_accuracy: 0.0588\n",
      "Epoch 6972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1868 - accuracy: 0.0000e+00 - val_loss: 142.4135 - val_accuracy: 0.0588\n",
      "Epoch 6973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3342 - accuracy: 0.0000e+00 - val_loss: 144.2523 - val_accuracy: 0.0588\n",
      "Epoch 6974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6951 - accuracy: 0.0156 - val_loss: 144.6121 - val_accuracy: 0.0588\n",
      "Epoch 6975/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2923 - accuracy: 0.0000e+00 - val_loss: 138.4971 - val_accuracy: 0.0588\n",
      "Epoch 6976/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5896 - accuracy: 0.0312 - val_loss: 129.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 6977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0752 - accuracy: 0.0000e+00 - val_loss: 127.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 6978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0134 - accuracy: 0.0000e+00 - val_loss: 130.4078 - val_accuracy: 0.0000e+00\n",
      "Epoch 6979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8529 - accuracy: 0.0156 - val_loss: 137.7863 - val_accuracy: 0.0000e+00\n",
      "Epoch 6980/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 30.6840 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 24.6438 - accuracy: 0.0156 - val_loss: 140.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 6981/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 21.1244 - accuracy: 0.0156 - val_loss: 142.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 6982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6500 - accuracy: 0.0000e+00 - val_loss: 147.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 6983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4305 - accuracy: 0.0000e+00 - val_loss: 151.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 6984/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.1629 - accuracy: 0.0000e+00 - val_loss: 152.5880 - val_accuracy: 0.0000e+00\n",
      "Epoch 6985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9213 - accuracy: 0.0312 - val_loss: 152.5718 - val_accuracy: 0.0588\n",
      "Epoch 6986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7272 - accuracy: 0.0000e+00 - val_loss: 147.0879 - val_accuracy: 0.0588\n",
      "Epoch 6987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9597 - accuracy: 0.0000e+00 - val_loss: 138.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 6988/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9068 - accuracy: 0.0000e+00 - val_loss: 137.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 6989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6654 - accuracy: 0.0000e+00 - val_loss: 141.0963 - val_accuracy: 0.0588\n",
      "Epoch 6990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0181 - accuracy: 0.0156 - val_loss: 147.1517 - val_accuracy: 0.0588\n",
      "Epoch 6991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6666 - accuracy: 0.0000e+00 - val_loss: 149.0218 - val_accuracy: 0.0588\n",
      "Epoch 6992/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7963 - accuracy: 0.0156 - val_loss: 143.6116 - val_accuracy: 0.0588\n",
      "Epoch 6993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4764 - accuracy: 0.0000e+00 - val_loss: 128.1806 - val_accuracy: 0.0588\n",
      "Epoch 6994/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 23.6141 - accuracy: 0.0156 - val_loss: 112.3800 - val_accuracy: 0.0588\n",
      "Epoch 6995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6754 - accuracy: 0.0000e+00 - val_loss: 107.5126 - val_accuracy: 0.0588\n",
      "Epoch 6996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0204 - accuracy: 0.0156 - val_loss: 112.1348 - val_accuracy: 0.0588\n",
      "Epoch 6997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4374 - accuracy: 0.0156 - val_loss: 121.4963 - val_accuracy: 0.0588\n",
      "Epoch 6998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8118 - accuracy: 0.0000e+00 - val_loss: 123.5408 - val_accuracy: 0.0588\n",
      "Epoch 6999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0426 - accuracy: 0.0156 - val_loss: 114.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 7000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0154 - accuracy: 0.0312 - val_loss: 110.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 7001/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.7843 - accuracy: 0.0000e+00 - val_loss: 118.6778 - val_accuracy: 0.0000e+00\n",
      "Epoch 7002/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9244 - accuracy: 0.0000e+00 - val_loss: 133.9828 - val_accuracy: 0.0000e+00\n",
      "Epoch 7003/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 21.9372 - accuracy: 0.0000e+00 - val_loss: 144.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 7004/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.2274 - accuracy: 0.0000e+00 - val_loss: 148.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 7005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0689 - accuracy: 0.0156 - val_loss: 141.8805 - val_accuracy: 0.0000e+00\n",
      "Epoch 7006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1015 - accuracy: 0.0000e+00 - val_loss: 138.6532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3603 - accuracy: 0.0312 - val_loss: 134.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 7008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1759 - accuracy: 0.0156 - val_loss: 133.8073 - val_accuracy: 0.0000e+00\n",
      "Epoch 7009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3332 - accuracy: 0.0156 - val_loss: 133.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 7010/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5085 - accuracy: 0.0000e+00 - val_loss: 136.7293 - val_accuracy: 0.0588\n",
      "Epoch 7011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.1763 - accuracy: 0.0000e+00 - val_loss: 131.6222 - val_accuracy: 0.0588\n",
      "Epoch 7012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1461 - accuracy: 0.0156 - val_loss: 128.3195 - val_accuracy: 0.0000e+00\n",
      "Epoch 7013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8707 - accuracy: 0.0312 - val_loss: 130.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 7014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1378 - accuracy: 0.0000e+00 - val_loss: 132.7790 - val_accuracy: 0.0000e+00\n",
      "Epoch 7015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7936 - accuracy: 0.0000e+00 - val_loss: 139.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4352 - accuracy: 0.0000e+00 - val_loss: 139.5382 - val_accuracy: 0.0588\n",
      "Epoch 7017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0200 - accuracy: 0.0000e+00 - val_loss: 129.8808 - val_accuracy: 0.0588\n",
      "Epoch 7018/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 26.8836 - accuracy: 0.0156 - val_loss: 127.5108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7019/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0106 - accuracy: 0.0000e+00 - val_loss: 130.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 7020/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2683 - accuracy: 0.0000e+00 - val_loss: 131.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 7021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0559 - accuracy: 0.0000e+00 - val_loss: 128.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 7022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2359 - accuracy: 0.0000e+00 - val_loss: 124.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5343 - accuracy: 0.0156 - val_loss: 126.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 7024/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 27.4078 - accuracy: 0.0156 - val_loss: 133.3108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7025/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 30.5346 - accuracy: 0.0000e+00 - val_loss: 140.3680 - val_accuracy: 0.0000e+00\n",
      "Epoch 7026/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6845 - accuracy: 0.0156 - val_loss: 138.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 7027/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2884 - accuracy: 0.0156 - val_loss: 137.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 7028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 23.8081 - accuracy: 0.0000e+00 - val_loss: 137.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 7029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2551 - accuracy: 0.0000e+00 - val_loss: 134.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 7030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8954 - accuracy: 0.0000e+00 - val_loss: 133.8545 - val_accuracy: 0.0588\n",
      "Epoch 7031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8500 - accuracy: 0.0000e+00 - val_loss: 131.7464 - val_accuracy: 0.0588\n",
      "Epoch 7032/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 30.8674 - accuracy: 0.0156 - val_loss: 134.8424 - val_accuracy: 0.0588\n",
      "Epoch 7033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3293 - accuracy: 0.0000e+00 - val_loss: 143.4429 - val_accuracy: 0.0588\n",
      "Epoch 7034/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7447 - accuracy: 0.0156 - val_loss: 141.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 7035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9196 - accuracy: 0.0156 - val_loss: 131.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 7036/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1497 - accuracy: 0.0000e+00 - val_loss: 126.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 7037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7469 - accuracy: 0.0000e+00 - val_loss: 126.6454 - val_accuracy: 0.0588\n",
      "Epoch 7038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8627 - accuracy: 0.0156 - val_loss: 130.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 7039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4924 - accuracy: 0.0156 - val_loss: 139.6600 - val_accuracy: 0.0000e+00\n",
      "Epoch 7040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1468 - accuracy: 0.0312 - val_loss: 148.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 7041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3606 - accuracy: 0.0156 - val_loss: 146.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 7042/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.1771 - accuracy: 0.0000e+00 - val_loss: 133.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3315 - accuracy: 0.0000e+00 - val_loss: 123.9942 - val_accuracy: 0.0000e+00\n",
      "Epoch 7044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0102 - accuracy: 0.0156 - val_loss: 120.9395 - val_accuracy: 0.0588\n",
      "Epoch 7045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7412 - accuracy: 0.0156 - val_loss: 127.0591 - val_accuracy: 0.0588\n",
      "Epoch 7046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5226 - accuracy: 0.0000e+00 - val_loss: 121.5781 - val_accuracy: 0.1176\n",
      "Epoch 7047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1627 - accuracy: 0.0156 - val_loss: 122.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 7048/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.3190 - accuracy: 0.0000e+00 - val_loss: 125.2653 - val_accuracy: 0.0000e+00\n",
      "Epoch 7049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6105 - accuracy: 0.0312 - val_loss: 130.5535 - val_accuracy: 0.0588\n",
      "Epoch 7050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3784 - accuracy: 0.0000e+00 - val_loss: 139.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4009 - accuracy: 0.0156 - val_loss: 142.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 7052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3415 - accuracy: 0.0000e+00 - val_loss: 138.3294 - val_accuracy: 0.0000e+00\n",
      "Epoch 7053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4425 - accuracy: 0.0000e+00 - val_loss: 128.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 7054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4097 - accuracy: 0.0000e+00 - val_loss: 120.7907 - val_accuracy: 0.0000e+00\n",
      "Epoch 7055/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0252 - accuracy: 0.0156 - val_loss: 118.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7056/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3614 - accuracy: 0.0000e+00 - val_loss: 122.9809 - val_accuracy: 0.0000e+00\n",
      "Epoch 7057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0956 - accuracy: 0.0000e+00 - val_loss: 126.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 7058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0923 - accuracy: 0.0312 - val_loss: 123.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 7059/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 41.4791 - accuracy: 0.0000e+00 - val_loss: 122.4006 - val_accuracy: 0.0000e+00\n",
      "Epoch 7060/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 16.8441 - accuracy: 0.0156 - val_loss: 122.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 7061/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3688 - accuracy: 0.0000e+00 - val_loss: 118.5163 - val_accuracy: 0.0588\n",
      "Epoch 7062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9180 - accuracy: 0.0000e+00 - val_loss: 107.8544 - val_accuracy: 0.0588\n",
      "Epoch 7063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8104 - accuracy: 0.0469 - val_loss: 101.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 7064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1365 - accuracy: 0.0312 - val_loss: 101.6649 - val_accuracy: 0.0000e+00\n",
      "Epoch 7065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6444 - accuracy: 0.0312 - val_loss: 110.9013 - val_accuracy: 0.0000e+00\n",
      "Epoch 7066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0000 - accuracy: 0.0156 - val_loss: 126.4215 - val_accuracy: 0.0588\n",
      "Epoch 7067/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.6818 - accuracy: 0.0000e+00 - val_loss: 136.5104 - val_accuracy: 0.0000e+00\n",
      "Epoch 7068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8349 - accuracy: 0.0000e+00 - val_loss: 136.0282 - val_accuracy: 0.0000e+00\n",
      "Epoch 7069/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 23.8893 - accuracy: 0.0156 - val_loss: 135.2706 - val_accuracy: 0.0000e+00\n",
      "Epoch 7070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4299 - accuracy: 0.0000e+00 - val_loss: 136.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 7071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7027 - accuracy: 0.0156 - val_loss: 131.7307 - val_accuracy: 0.0000e+00\n",
      "Epoch 7072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2802 - accuracy: 0.0156 - val_loss: 119.2783 - val_accuracy: 0.0000e+00\n",
      "Epoch 7073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3176 - accuracy: 0.0000e+00 - val_loss: 110.1296 - val_accuracy: 0.0000e+00\n",
      "Epoch 7074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5490 - accuracy: 0.0469 - val_loss: 109.6613 - val_accuracy: 0.0588\n",
      "Epoch 7075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4648 - accuracy: 0.0000e+00 - val_loss: 109.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2820 - accuracy: 0.0000e+00 - val_loss: 107.8727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7077/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 18.7439 - accuracy: 0.0469 - val_loss: 108.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 7078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5179 - accuracy: 0.0000e+00 - val_loss: 118.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 7079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0967 - accuracy: 0.0312 - val_loss: 125.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 7080/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 32.7824 - accuracy: 0.0156 - val_loss: 132.0148 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7736 - accuracy: 0.0156 - val_loss: 138.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 7082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5826 - accuracy: 0.0156 - val_loss: 137.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 7083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1112 - accuracy: 0.0156 - val_loss: 129.0916 - val_accuracy: 0.0000e+00\n",
      "Epoch 7084/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 30.9199 - accuracy: 0.0156 - val_loss: 135.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 7085/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1807 - accuracy: 0.0000e+00 - val_loss: 143.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 7086/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.3565 - accuracy: 0.0156 - val_loss: 147.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 7087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1839 - accuracy: 0.0000e+00 - val_loss: 144.5490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8980 - accuracy: 0.0000e+00 - val_loss: 141.4415 - val_accuracy: 0.0000e+00\n",
      "Epoch 7089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4056 - accuracy: 0.0156 - val_loss: 133.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 7090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7711 - accuracy: 0.0000e+00 - val_loss: 127.4983 - val_accuracy: 0.0588\n",
      "Epoch 7091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5970 - accuracy: 0.0312 - val_loss: 122.5370 - val_accuracy: 0.0588\n",
      "Epoch 7092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7929 - accuracy: 0.0156 - val_loss: 126.7513 - val_accuracy: 0.0588\n",
      "Epoch 7093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7481 - accuracy: 0.0000e+00 - val_loss: 131.1269 - val_accuracy: 0.0000e+00\n",
      "Epoch 7094/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.1767 - accuracy: 0.0000e+00 - val_loss: 121.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 7095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6444 - accuracy: 0.0312 - val_loss: 122.9211 - val_accuracy: 0.1176\n",
      "Epoch 7096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4699 - accuracy: 0.0469 - val_loss: 129.9479 - val_accuracy: 0.1176\n",
      "Epoch 7097/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1629 - accuracy: 0.0156 - val_loss: 141.7874 - val_accuracy: 0.0000e+00\n",
      "Epoch 7098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8486 - accuracy: 0.0000e+00 - val_loss: 155.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 7099/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1690 - accuracy: 0.0469 - val_loss: 159.4257 - val_accuracy: 0.0000e+00\n",
      "Epoch 7100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0356 - accuracy: 0.0000e+00 - val_loss: 155.6718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6343 - accuracy: 0.0312 - val_loss: 143.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 7102/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.0267 - accuracy: 0.0469 - val_loss: 135.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 7103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6994 - accuracy: 0.0000e+00 - val_loss: 128.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 7104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8212 - accuracy: 0.0000e+00 - val_loss: 132.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7105/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.5133 - accuracy: 0.0156 - val_loss: 144.1268 - val_accuracy: 0.0588\n",
      "Epoch 7106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0176 - accuracy: 0.0156 - val_loss: 151.0748 - val_accuracy: 0.0588\n",
      "Epoch 7107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4468 - accuracy: 0.0156 - val_loss: 147.6131 - val_accuracy: 0.0588\n",
      "Epoch 7108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5826 - accuracy: 0.0312 - val_loss: 131.8407 - val_accuracy: 0.0588\n",
      "Epoch 7109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4711 - accuracy: 0.0000e+00 - val_loss: 130.4822 - val_accuracy: 0.0588\n",
      "Epoch 7110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8227 - accuracy: 0.0156 - val_loss: 125.7587 - val_accuracy: 0.0588\n",
      "Epoch 7111/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 19.0150 - accuracy: 0.0000e+00 - val_loss: 121.0865 - val_accuracy: 0.0588\n",
      "Epoch 7112/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3492 - accuracy: 0.0000e+00 - val_loss: 119.9115 - val_accuracy: 0.0588\n",
      "Epoch 7113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3946 - accuracy: 0.0000e+00 - val_loss: 121.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7114/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7507 - accuracy: 0.0312 - val_loss: 129.6226 - val_accuracy: 0.0000e+00\n",
      "Epoch 7115/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0903 - accuracy: 0.0000e+00 - val_loss: 135.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5333 - accuracy: 0.0000e+00 - val_loss: 141.0991 - val_accuracy: 0.0588\n",
      "Epoch 7117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2731 - accuracy: 0.0156 - val_loss: 139.2424 - val_accuracy: 0.0588\n",
      "Epoch 7118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5785 - accuracy: 0.0156 - val_loss: 138.0395 - val_accuracy: 0.0588\n",
      "Epoch 7119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0481 - accuracy: 0.0156 - val_loss: 135.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 7120/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9101 - accuracy: 0.0156 - val_loss: 132.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 7121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5798 - accuracy: 0.0000e+00 - val_loss: 133.3966 - val_accuracy: 0.0000e+00\n",
      "Epoch 7122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7795 - accuracy: 0.0156 - val_loss: 136.3060 - val_accuracy: 0.0588\n",
      "Epoch 7123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7624 - accuracy: 0.0156 - val_loss: 138.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 7124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1563 - accuracy: 0.0000e+00 - val_loss: 136.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 7125/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.8549 - accuracy: 0.0156 - val_loss: 123.1217 - val_accuracy: 0.0588\n",
      "Epoch 7126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0659 - accuracy: 0.0156 - val_loss: 114.0211 - val_accuracy: 0.0588\n",
      "Epoch 7127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1980 - accuracy: 0.0156 - val_loss: 118.5300 - val_accuracy: 0.0588\n",
      "Epoch 7128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7051 - accuracy: 0.0000e+00 - val_loss: 126.9884 - val_accuracy: 0.0588\n",
      "Epoch 7129/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.5847 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 17.6533 - accuracy: 0.0000e+00 - val_loss: 136.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4153 - accuracy: 0.0000e+00 - val_loss: 143.5379 - val_accuracy: 0.0000e+00\n",
      "Epoch 7131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8610 - accuracy: 0.0000e+00 - val_loss: 143.0763 - val_accuracy: 0.0588\n",
      "Epoch 7132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1340 - accuracy: 0.0000e+00 - val_loss: 135.4794 - val_accuracy: 0.0588\n",
      "Epoch 7133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4687 - accuracy: 0.0000e+00 - val_loss: 130.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 7134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4308 - accuracy: 0.0156 - val_loss: 127.8669 - val_accuracy: 0.1176\n",
      "Epoch 7135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1873 - accuracy: 0.0312 - val_loss: 127.3675 - val_accuracy: 0.0588\n",
      "Epoch 7136/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5868 - accuracy: 0.0000e+00 - val_loss: 140.0546 - val_accuracy: 0.0588\n",
      "Epoch 7137/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7901 - accuracy: 0.0000e+00 - val_loss: 141.2690 - val_accuracy: 0.0588\n",
      "Epoch 7138/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4688 - accuracy: 0.0000e+00 - val_loss: 131.3631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7139/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 17.4699 - accuracy: 0.0312 - val_loss: 125.4957 - val_accuracy: 0.0000e+00\n",
      "Epoch 7140/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.6172 - accuracy: 0.0000e+00 - val_loss: 124.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 7141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9681 - accuracy: 0.0000e+00 - val_loss: 133.8646 - val_accuracy: 0.0000e+00\n",
      "Epoch 7142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2937 - accuracy: 0.0000e+00 - val_loss: 143.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 7143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8596 - accuracy: 0.0000e+00 - val_loss: 149.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8971 - accuracy: 0.0000e+00 - val_loss: 147.5606 - val_accuracy: 0.0588\n",
      "Epoch 7145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3767 - accuracy: 0.0000e+00 - val_loss: 143.0667 - val_accuracy: 0.0588\n",
      "Epoch 7146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3349 - accuracy: 0.0000e+00 - val_loss: 136.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 7147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6724 - accuracy: 0.0000e+00 - val_loss: 129.8761 - val_accuracy: 0.0000e+00\n",
      "Epoch 7148/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 27.2980 - accuracy: 0.0000e+00 - val_loss: 133.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 7149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5933 - accuracy: 0.0000e+00 - val_loss: 131.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 7150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9547 - accuracy: 0.0000e+00 - val_loss: 130.6307 - val_accuracy: 0.0588\n",
      "Epoch 7151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4538 - accuracy: 0.0156 - val_loss: 132.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 7152/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3695 - accuracy: 0.0000e+00 - val_loss: 129.8589 - val_accuracy: 0.0000e+00\n",
      "Epoch 7153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8233 - accuracy: 0.0312 - val_loss: 125.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 7154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9118 - accuracy: 0.0000e+00 - val_loss: 127.6420 - val_accuracy: 0.0000e+00\n",
      "Epoch 7155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6000 - accuracy: 0.0000e+00 - val_loss: 124.3861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7156/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8947 - accuracy: 0.0156 - val_loss: 124.8382 - val_accuracy: 0.0000e+00\n",
      "Epoch 7157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7060 - accuracy: 0.0000e+00 - val_loss: 131.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 7158/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9551 - accuracy: 0.0000e+00 - val_loss: 135.2494 - val_accuracy: 0.0588\n",
      "Epoch 7159/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 43.2104 - accuracy: 0.0156 - val_loss: 133.8125 - val_accuracy: 0.0588\n",
      "Epoch 7160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3246 - accuracy: 0.0000e+00 - val_loss: 133.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 7161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3171 - accuracy: 0.0000e+00 - val_loss: 129.5791 - val_accuracy: 0.0000e+00\n",
      "Epoch 7162/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.6463 - accuracy: 0.0000e+00 - val_loss: 119.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 7163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0526 - accuracy: 0.0000e+00 - val_loss: 114.1839 - val_accuracy: 0.0000e+00\n",
      "Epoch 7164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0854 - accuracy: 0.0156 - val_loss: 115.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8409 - accuracy: 0.0156 - val_loss: 120.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 7166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7159 - accuracy: 0.0156 - val_loss: 129.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 7167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6059 - accuracy: 0.0156 - val_loss: 127.9082 - val_accuracy: 0.0588\n",
      "Epoch 7168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2603 - accuracy: 0.0156 - val_loss: 128.9594 - val_accuracy: 0.0588\n",
      "Epoch 7169/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 25.4067 - accuracy: 0.0156 - val_loss: 129.9905 - val_accuracy: 0.0000e+00\n",
      "Epoch 7170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5437 - accuracy: 0.0156 - val_loss: 137.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7171/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 31.9049 - accuracy: 0.0156 - val_loss: 145.5733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7172/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.7749 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 23.0006 - accuracy: 0.0000e+00 - val_loss: 151.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 7173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1493 - accuracy: 0.0312 - val_loss: 151.1639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2222 - accuracy: 0.0000e+00 - val_loss: 144.8846 - val_accuracy: 0.0588\n",
      "Epoch 7175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4616 - accuracy: 0.0000e+00 - val_loss: 140.7117 - val_accuracy: 0.0588\n",
      "Epoch 7176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0537 - accuracy: 0.0156 - val_loss: 145.9990 - val_accuracy: 0.0588\n",
      "Epoch 7177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4858 - accuracy: 0.0000e+00 - val_loss: 136.2711 - val_accuracy: 0.0000e+00\n",
      "Epoch 7178/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 18.8990 - accuracy: 0.0000e+00 - val_loss: 127.5149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7179/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.6992 - accuracy: 0.0000e+00 - val_loss: 120.5182 - val_accuracy: 0.0588\n",
      "Epoch 7180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9714 - accuracy: 0.0156 - val_loss: 119.4416 - val_accuracy: 0.0588\n",
      "Epoch 7181/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 27.6889 - accuracy: 0.0000e+00 - val_loss: 124.5152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1207 - accuracy: 0.0312 - val_loss: 130.9902 - val_accuracy: 0.0000e+00\n",
      "Epoch 7183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8901 - accuracy: 0.0156 - val_loss: 131.1918 - val_accuracy: 0.0000e+00\n",
      "Epoch 7184/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6208 - accuracy: 0.0156 - val_loss: 129.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 7185/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 24.2812 - accuracy: 0.0156 - val_loss: 130.2046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7513 - accuracy: 0.0156 - val_loss: 131.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 7187/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 34.6112 - accuracy: 0.0000e+00 - val_loss: 136.7606 - val_accuracy: 0.0588\n",
      "Epoch 7188/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0253 - accuracy: 0.0156 - val_loss: 139.6613 - val_accuracy: 0.0588\n",
      "Epoch 7189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9697 - accuracy: 0.0312 - val_loss: 139.0854 - val_accuracy: 0.0588\n",
      "Epoch 7190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1560 - accuracy: 0.0156 - val_loss: 140.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 7191/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1521 - accuracy: 0.0000e+00 - val_loss: 137.1880 - val_accuracy: 0.0588\n",
      "Epoch 7192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3706 - accuracy: 0.0000e+00 - val_loss: 130.0461 - val_accuracy: 0.0588\n",
      "Epoch 7193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0833 - accuracy: 0.0156 - val_loss: 119.3224 - val_accuracy: 0.0588\n",
      "Epoch 7194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8911 - accuracy: 0.0000e+00 - val_loss: 118.6168 - val_accuracy: 0.1176\n",
      "Epoch 7195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8393 - accuracy: 0.0000e+00 - val_loss: 125.0472 - val_accuracy: 0.0588\n",
      "Epoch 7196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2146 - accuracy: 0.0156 - val_loss: 130.0506 - val_accuracy: 0.0000e+00\n",
      "Epoch 7197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4800 - accuracy: 0.0156 - val_loss: 129.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 7198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1980 - accuracy: 0.0156 - val_loss: 124.2949 - val_accuracy: 0.0588\n",
      "Epoch 7199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3754 - accuracy: 0.0000e+00 - val_loss: 123.2600 - val_accuracy: 0.0000e+00\n",
      "Epoch 7200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.9215 - accuracy: 0.0000e+00 - val_loss: 128.0391 - val_accuracy: 0.0588\n",
      "Epoch 7201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6321 - accuracy: 0.0000e+00 - val_loss: 133.5995 - val_accuracy: 0.0000e+00\n",
      "Epoch 7202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0964 - accuracy: 0.0000e+00 - val_loss: 136.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2915 - accuracy: 0.0156 - val_loss: 136.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 7204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7487 - accuracy: 0.0312 - val_loss: 135.7467 - val_accuracy: 0.0000e+00\n",
      "Epoch 7205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7768 - accuracy: 0.0000e+00 - val_loss: 136.7590 - val_accuracy: 0.0000e+00\n",
      "Epoch 7206/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3908 - accuracy: 0.0000e+00 - val_loss: 146.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 7207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7211 - accuracy: 0.0312 - val_loss: 150.2925 - val_accuracy: 0.0000e+00\n",
      "Epoch 7208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1904 - accuracy: 0.0000e+00 - val_loss: 146.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 7209/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6986 - accuracy: 0.0312 - val_loss: 136.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 7210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8128 - accuracy: 0.0000e+00 - val_loss: 131.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 7211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0531 - accuracy: 0.0000e+00 - val_loss: 132.4532 - val_accuracy: 0.0588\n",
      "Epoch 7212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6438 - accuracy: 0.0000e+00 - val_loss: 136.7315 - val_accuracy: 0.0588\n",
      "Epoch 7213/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 22.1221 - accuracy: 0.0156 - val_loss: 136.6610 - val_accuracy: 0.0588\n",
      "Epoch 7214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3793 - accuracy: 0.0156 - val_loss: 132.4345 - val_accuracy: 0.0588\n",
      "Epoch 7215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3293 - accuracy: 0.0156 - val_loss: 129.2243 - val_accuracy: 0.0588\n",
      "Epoch 7216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4476 - accuracy: 0.0312 - val_loss: 121.5911 - val_accuracy: 0.0588\n",
      "Epoch 7217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6263 - accuracy: 0.0000e+00 - val_loss: 108.4667 - val_accuracy: 0.0588\n",
      "Epoch 7218/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.7654 - accuracy: 0.0000e+00 - val_loss: 104.9272 - val_accuracy: 0.0588\n",
      "Epoch 7219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1775 - accuracy: 0.0000e+00 - val_loss: 115.6585 - val_accuracy: 0.0588\n",
      "Epoch 7220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9509 - accuracy: 0.0000e+00 - val_loss: 136.1793 - val_accuracy: 0.0000e+00\n",
      "Epoch 7221/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 23.5489 - accuracy: 0.0469 - val_loss: 149.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1791 - accuracy: 0.0000e+00 - val_loss: 151.8485 - val_accuracy: 0.0588\n",
      "Epoch 7223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8416 - accuracy: 0.0000e+00 - val_loss: 142.9645 - val_accuracy: 0.0000e+00\n",
      "Epoch 7224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0360 - accuracy: 0.0000e+00 - val_loss: 130.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2681 - accuracy: 0.0000e+00 - val_loss: 120.2254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2935 - accuracy: 0.0000e+00 - val_loss: 122.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 7227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7469 - accuracy: 0.0000e+00 - val_loss: 135.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 7228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0297 - accuracy: 0.0000e+00 - val_loss: 140.6861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2543 - accuracy: 0.0000e+00 - val_loss: 143.9450 - val_accuracy: 0.0000e+00\n",
      "Epoch 7230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0937 - accuracy: 0.0156 - val_loss: 142.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8044 - accuracy: 0.0312 - val_loss: 137.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 7232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4811 - accuracy: 0.0312 - val_loss: 130.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 7233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9485 - accuracy: 0.0156 - val_loss: 125.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 7234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0345 - accuracy: 0.0000e+00 - val_loss: 130.2015 - val_accuracy: 0.0000e+00\n",
      "Epoch 7235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8812 - accuracy: 0.0000e+00 - val_loss: 138.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 7236/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5744 - accuracy: 0.0156 - val_loss: 137.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 7237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0860 - accuracy: 0.0000e+00 - val_loss: 136.2314 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6457 - accuracy: 0.0156 - val_loss: 133.8310 - val_accuracy: 0.0000e+00\n",
      "Epoch 7239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3312 - accuracy: 0.0000e+00 - val_loss: 136.5045 - val_accuracy: 0.0588\n",
      "Epoch 7240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6870 - accuracy: 0.0000e+00 - val_loss: 138.3139 - val_accuracy: 0.0000e+00\n",
      "Epoch 7241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0185 - accuracy: 0.0000e+00 - val_loss: 139.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2086 - accuracy: 0.0312 - val_loss: 133.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 7243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0622 - accuracy: 0.0156 - val_loss: 138.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 7244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4237 - accuracy: 0.0000e+00 - val_loss: 142.0585 - val_accuracy: 0.0588\n",
      "Epoch 7245/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.1954 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 28.9025 - accuracy: 0.0000e+00 - val_loss: 137.2698 - val_accuracy: 0.0588\n",
      "Epoch 7246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5505 - accuracy: 0.0000e+00 - val_loss: 128.3779 - val_accuracy: 0.0588\n",
      "Epoch 7247/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1915 - accuracy: 0.0156 - val_loss: 129.0472 - val_accuracy: 0.0000e+00\n",
      "Epoch 7248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2085 - accuracy: 0.0000e+00 - val_loss: 134.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 7249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9626 - accuracy: 0.0000e+00 - val_loss: 137.2714 - val_accuracy: 0.0000e+00\n",
      "Epoch 7250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5499 - accuracy: 0.0000e+00 - val_loss: 135.9400 - val_accuracy: 0.0000e+00\n",
      "Epoch 7251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1283 - accuracy: 0.0312 - val_loss: 136.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7468 - accuracy: 0.0000e+00 - val_loss: 142.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7253/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 18.5672 - accuracy: 0.0000e+00 - val_loss: 146.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 7254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3532 - accuracy: 0.0000e+00 - val_loss: 143.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 7255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0588 - accuracy: 0.0000e+00 - val_loss: 142.3102 - val_accuracy: 0.0000e+00\n",
      "Epoch 7256/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7692 - accuracy: 0.0000e+00 - val_loss: 139.8853 - val_accuracy: 0.0000e+00\n",
      "Epoch 7257/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7315 - accuracy: 0.0156 - val_loss: 133.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 7258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2809 - accuracy: 0.0000e+00 - val_loss: 131.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 7259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4915 - accuracy: 0.0156 - val_loss: 133.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 7260/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.9863 - accuracy: 0.0000e+00 - val_loss: 134.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7261/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5293 - accuracy: 0.0000e+00 - val_loss: 130.7229 - val_accuracy: 0.0000e+00\n",
      "Epoch 7262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8793 - accuracy: 0.0156 - val_loss: 126.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 7263/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9236 - accuracy: 0.0000e+00 - val_loss: 126.6803 - val_accuracy: 0.0588\n",
      "Epoch 7264/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 23.6787 - accuracy: 0.0156 - val_loss: 131.3265 - val_accuracy: 0.0588\n",
      "Epoch 7265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5131 - accuracy: 0.0156 - val_loss: 140.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 7266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0883 - accuracy: 0.0156 - val_loss: 146.0586 - val_accuracy: 0.0000e+00\n",
      "Epoch 7267/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.3037 - accuracy: 0.0156 - val_loss: 143.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7268/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5383 - accuracy: 0.0000e+00 - val_loss: 138.9810 - val_accuracy: 0.0588\n",
      "Epoch 7269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4621 - accuracy: 0.0000e+00 - val_loss: 131.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 7270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2347 - accuracy: 0.0312 - val_loss: 127.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5626 - accuracy: 0.0000e+00 - val_loss: 129.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 7272/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5644 - accuracy: 0.0156 - val_loss: 133.6824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3381 - accuracy: 0.0312 - val_loss: 134.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 7274/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.5796 - accuracy: 0.0156 - val_loss: 131.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 7275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2084 - accuracy: 0.0000e+00 - val_loss: 122.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 7276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7918 - accuracy: 0.0000e+00 - val_loss: 114.5536 - val_accuracy: 0.0000e+00\n",
      "Epoch 7277/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 28.9625 - accuracy: 0.0156 - val_loss: 117.5191 - val_accuracy: 0.0000e+00\n",
      "Epoch 7278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3161 - accuracy: 0.0000e+00 - val_loss: 130.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 7279/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1689 - accuracy: 0.0156 - val_loss: 141.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 7280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0221 - accuracy: 0.0156 - val_loss: 144.8559 - val_accuracy: 0.0000e+00\n",
      "Epoch 7281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3376 - accuracy: 0.0000e+00 - val_loss: 137.0188 - val_accuracy: 0.0588\n",
      "Epoch 7282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1056 - accuracy: 0.0156 - val_loss: 125.2098 - val_accuracy: 0.0588\n",
      "Epoch 7283/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.1281 - accuracy: 0.0000e+00 - val_loss: 122.4118 - val_accuracy: 0.0588\n",
      "Epoch 7284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7691 - accuracy: 0.0000e+00 - val_loss: 122.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2261 - accuracy: 0.0156 - val_loss: 123.9698 - val_accuracy: 0.0000e+00\n",
      "Epoch 7286/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.5447 - accuracy: 0.0156 - val_loss: 134.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 7287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5988 - accuracy: 0.0156 - val_loss: 138.7954 - val_accuracy: 0.0000e+00\n",
      "Epoch 7288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7577 - accuracy: 0.0000e+00 - val_loss: 141.6220 - val_accuracy: 0.0000e+00\n",
      "Epoch 7289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8921 - accuracy: 0.0000e+00 - val_loss: 141.0968 - val_accuracy: 0.0000e+00\n",
      "Epoch 7290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1389 - accuracy: 0.0156 - val_loss: 140.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 7291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4486 - accuracy: 0.0156 - val_loss: 140.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 7292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2243 - accuracy: 0.0312 - val_loss: 141.4888 - val_accuracy: 0.0000e+00\n",
      "Epoch 7293/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.0159 - accuracy: 0.031 - 0s 125us/step - loss: 18.3628 - accuracy: 0.0156 - val_loss: 142.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 7294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9091 - accuracy: 0.0000e+00 - val_loss: 139.6358 - val_accuracy: 0.0588\n",
      "Epoch 7295/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 18.5073 - accuracy: 0.0000e+00 - val_loss: 131.9465 - val_accuracy: 0.0000e+00\n",
      "Epoch 7296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6269 - accuracy: 0.0000e+00 - val_loss: 125.4319 - val_accuracy: 0.0588\n",
      "Epoch 7297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5829 - accuracy: 0.0000e+00 - val_loss: 122.6451 - val_accuracy: 0.0588\n",
      "Epoch 7298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9921 - accuracy: 0.0000e+00 - val_loss: 119.8073 - val_accuracy: 0.0588\n",
      "Epoch 7299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2209 - accuracy: 0.0000e+00 - val_loss: 122.0223 - val_accuracy: 0.0000e+00\n",
      "Epoch 7300/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.8268 - accuracy: 0.0156 - val_loss: 125.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 7301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2081 - accuracy: 0.0156 - val_loss: 126.3170 - val_accuracy: 0.0000e+00\n",
      "Epoch 7302/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4088 - accuracy: 0.0156 - val_loss: 128.8638 - val_accuracy: 0.0000e+00\n",
      "Epoch 7303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9236 - accuracy: 0.0000e+00 - val_loss: 129.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0792 - accuracy: 0.0000e+00 - val_loss: 130.3702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1312 - accuracy: 0.0156 - val_loss: 138.3245 - val_accuracy: 0.0588\n",
      "Epoch 7306/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1997 - accuracy: 0.0000e+00 - val_loss: 142.8558 - val_accuracy: 0.0000e+00\n",
      "Epoch 7307/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 27.2078 - accuracy: 0.0156 - val_loss: 140.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 7308/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.8288 - accuracy: 0.0000e+00 - val_loss: 131.4856 - val_accuracy: 0.0000e+00\n",
      "Epoch 7309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2454 - accuracy: 0.0156 - val_loss: 126.3762 - val_accuracy: 0.0000e+00\n",
      "Epoch 7310/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7823 - accuracy: 0.0000e+00 - val_loss: 124.5108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2010 - accuracy: 0.0156 - val_loss: 124.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 7312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8197 - accuracy: 0.0000e+00 - val_loss: 129.4607 - val_accuracy: 0.0000e+00\n",
      "Epoch 7313/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6854 - accuracy: 0.0469 - val_loss: 126.6558 - val_accuracy: 0.0588\n",
      "Epoch 7314/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7063 - accuracy: 0.0000e+00 - val_loss: 123.7247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2844 - accuracy: 0.0469 - val_loss: 124.3811 - val_accuracy: 0.0588\n",
      "Epoch 7316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6367 - accuracy: 0.0000e+00 - val_loss: 131.7975 - val_accuracy: 0.0000e+00\n",
      "Epoch 7317/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0614 - accuracy: 0.0000e+00 - val_loss: 140.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7318/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.3439 - accuracy: 0.0000e+0 - 0s 39us/step - loss: 22.5448 - accuracy: 0.0000e+00 - val_loss: 144.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 7319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8752 - accuracy: 0.0000e+00 - val_loss: 145.1374 - val_accuracy: 0.0588\n",
      "Epoch 7320/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8147 - accuracy: 0.0156 - val_loss: 138.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7321/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 28.2966 - accuracy: 0.0000e+00 - val_loss: 129.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7322/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3280 - accuracy: 0.0000e+00 - val_loss: 128.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 7323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6228 - accuracy: 0.0312 - val_loss: 133.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 7324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2002 - accuracy: 0.0156 - val_loss: 136.2022 - val_accuracy: 0.0000e+00\n",
      "Epoch 7325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6929 - accuracy: 0.0000e+00 - val_loss: 132.3744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.3530 - accuracy: 0.0156 - val_loss: 127.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 7327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8058 - accuracy: 0.0156 - val_loss: 130.1424 - val_accuracy: 0.0588\n",
      "Epoch 7328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8338 - accuracy: 0.0000e+00 - val_loss: 132.1267 - val_accuracy: 0.0588\n",
      "Epoch 7329/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 30.2457 - accuracy: 0.0156 - val_loss: 129.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 7330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0350 - accuracy: 0.0000e+00 - val_loss: 128.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 7331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3062 - accuracy: 0.0000e+00 - val_loss: 128.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 7332/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4233 - accuracy: 0.0312 - val_loss: 122.6817 - val_accuracy: 0.1176\n",
      "Epoch 7333/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 14.0393 - accuracy: 0.0469 - val_loss: 117.3306 - val_accuracy: 0.1176\n",
      "Epoch 7334/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2301 - accuracy: 0.0000e+00 - val_loss: 116.4525 - val_accuracy: 0.0588\n",
      "Epoch 7335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3337 - accuracy: 0.0000e+00 - val_loss: 126.0365 - val_accuracy: 0.0588\n",
      "Epoch 7336/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.4884 - accuracy: 0.0000e+00 - val_loss: 130.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 7337/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2002 - accuracy: 0.0000e+00 - val_loss: 126.3651 - val_accuracy: 0.0000e+00\n",
      "Epoch 7338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4590 - accuracy: 0.0156 - val_loss: 121.8370 - val_accuracy: 0.0000e+00\n",
      "Epoch 7339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9349 - accuracy: 0.0000e+00 - val_loss: 119.7704 - val_accuracy: 0.0000e+00\n",
      "Epoch 7340/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2328 - accuracy: 0.0156 - val_loss: 127.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 7341/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 22.1937 - accuracy: 0.0000e+00 - val_loss: 129.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 7342/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 23.5934 - accuracy: 0.0000e+00 - val_loss: 123.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 7343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7404 - accuracy: 0.0156 - val_loss: 116.7734 - val_accuracy: 0.0588\n",
      "Epoch 7344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4013 - accuracy: 0.0000e+00 - val_loss: 122.8673 - val_accuracy: 0.0588\n",
      "Epoch 7345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4569 - accuracy: 0.0156 - val_loss: 130.7116 - val_accuracy: 0.0588\n",
      "Epoch 7346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4149 - accuracy: 0.0000e+00 - val_loss: 134.3315 - val_accuracy: 0.0588\n",
      "Epoch 7347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9403 - accuracy: 0.0156 - val_loss: 131.8832 - val_accuracy: 0.0000e+00\n",
      "Epoch 7348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8040 - accuracy: 0.0000e+00 - val_loss: 126.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9981 - accuracy: 0.0156 - val_loss: 122.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 7350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3769 - accuracy: 0.0000e+00 - val_loss: 128.5266 - val_accuracy: 0.0000e+00\n",
      "Epoch 7351/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 36.7076 - accuracy: 0.0000e+00 - val_loss: 137.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 7352/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 24.7051 - accuracy: 0.0000e+00 - val_loss: 143.3935 - val_accuracy: 0.0588\n",
      "Epoch 7353/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.2504 - accuracy: 0.0156 - val_loss: 145.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 7354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0877 - accuracy: 0.0000e+00 - val_loss: 140.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 7355/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.8920 - accuracy: 0.0156 - val_loss: 132.1567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7727 - accuracy: 0.0312 - val_loss: 123.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 7357/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9462 - accuracy: 0.0156 - val_loss: 121.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 7358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2505 - accuracy: 0.0000e+00 - val_loss: 122.8617 - val_accuracy: 0.0000e+00\n",
      "Epoch 7359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3751 - accuracy: 0.0156 - val_loss: 126.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 7360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5638 - accuracy: 0.0000e+00 - val_loss: 132.6357 - val_accuracy: 0.0588\n",
      "Epoch 7361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0707 - accuracy: 0.0156 - val_loss: 137.7129 - val_accuracy: 0.0588\n",
      "Epoch 7362/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 23.8340 - accuracy: 0.0000e+00 - val_loss: 139.9539 - val_accuracy: 0.0588\n",
      "Epoch 7363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6022 - accuracy: 0.0000e+00 - val_loss: 132.0808 - val_accuracy: 0.0588\n",
      "Epoch 7364/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.4649 - accuracy: 0.0000e+00 - val_loss: 120.6018 - val_accuracy: 0.0588\n",
      "Epoch 7365/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0900 - accuracy: 0.0156 - val_loss: 113.8996 - val_accuracy: 0.0588\n",
      "Epoch 7366/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7258 - accuracy: 0.0000e+00 - val_loss: 124.2350 - val_accuracy: 0.0588\n",
      "Epoch 7367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5727 - accuracy: 0.0156 - val_loss: 140.1811 - val_accuracy: 0.0588\n",
      "Epoch 7368/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4792 - accuracy: 0.0156 - val_loss: 146.9068 - val_accuracy: 0.0588\n",
      "Epoch 7369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7355 - accuracy: 0.0312 - val_loss: 147.4946 - val_accuracy: 0.1176\n",
      "Epoch 7370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9719 - accuracy: 0.0000e+00 - val_loss: 143.1221 - val_accuracy: 0.0588\n",
      "Epoch 7371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7272 - accuracy: 0.0156 - val_loss: 138.3929 - val_accuracy: 0.1176\n",
      "Epoch 7372/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1839 - accuracy: 0.0156 - val_loss: 131.0270 - val_accuracy: 0.0588\n",
      "Epoch 7373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6714 - accuracy: 0.0156 - val_loss: 127.9178 - val_accuracy: 0.0588\n",
      "Epoch 7374/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 24.1616 - accuracy: 0.0000e+00 - val_loss: 134.7498 - val_accuracy: 0.0588\n",
      "Epoch 7375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4687 - accuracy: 0.0000e+00 - val_loss: 141.3537 - val_accuracy: 0.0588\n",
      "Epoch 7376/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9153 - accuracy: 0.0156 - val_loss: 144.9472 - val_accuracy: 0.0588\n",
      "Epoch 7377/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3986 - accuracy: 0.0000e+00 - val_loss: 143.7198 - val_accuracy: 0.0588\n",
      "Epoch 7378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8392 - accuracy: 0.0000e+00 - val_loss: 140.4272 - val_accuracy: 0.0588\n",
      "Epoch 7379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6051 - accuracy: 0.0000e+00 - val_loss: 135.2568 - val_accuracy: 0.0588\n",
      "Epoch 7380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1057 - accuracy: 0.0156 - val_loss: 130.2038 - val_accuracy: 0.0000e+00\n",
      "Epoch 7381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1302 - accuracy: 0.0000e+00 - val_loss: 123.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5521 - accuracy: 0.0000e+00 - val_loss: 123.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3044 - accuracy: 0.0156 - val_loss: 124.3664 - val_accuracy: 0.0000e+00\n",
      "Epoch 7384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7944 - accuracy: 0.0312 - val_loss: 127.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 7385/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 20.4914 - accuracy: 0.0312 - val_loss: 130.3388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7386/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9729 - accuracy: 0.0000e+00 - val_loss: 132.7600 - val_accuracy: 0.0588\n",
      "Epoch 7387/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6872 - accuracy: 0.0156 - val_loss: 139.6659 - val_accuracy: 0.0588\n",
      "Epoch 7388/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1331 - accuracy: 0.0000e+00 - val_loss: 146.3619 - val_accuracy: 0.0588\n",
      "Epoch 7389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9085 - accuracy: 0.0000e+00 - val_loss: 147.7374 - val_accuracy: 0.0588\n",
      "Epoch 7390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4277 - accuracy: 0.0156 - val_loss: 144.4924 - val_accuracy: 0.0000e+00\n",
      "Epoch 7391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8775 - accuracy: 0.0000e+00 - val_loss: 139.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 7392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0719 - accuracy: 0.0156 - val_loss: 138.9012 - val_accuracy: 0.0588\n",
      "Epoch 7393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7010 - accuracy: 0.0156 - val_loss: 137.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 7394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8284 - accuracy: 0.0000e+00 - val_loss: 136.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 7395/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 19.3868 - accuracy: 0.0156 - val_loss: 137.4305 - val_accuracy: 0.0588\n",
      "Epoch 7396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5534 - accuracy: 0.0000e+00 - val_loss: 131.5473 - val_accuracy: 0.0588\n",
      "Epoch 7397/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 17.4015 - accuracy: 0.0156 - val_loss: 127.7285 - val_accuracy: 0.0588\n",
      "Epoch 7398/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2493 - accuracy: 0.0156 - val_loss: 125.0948 - val_accuracy: 0.0000e+00\n",
      "Epoch 7399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7548 - accuracy: 0.0156 - val_loss: 127.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 7400/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2992 - accuracy: 0.0156 - val_loss: 129.5748 - val_accuracy: 0.0000e+00\n",
      "Epoch 7401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2069 - accuracy: 0.0156 - val_loss: 126.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 7402/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5948 - accuracy: 0.0156 - val_loss: 129.1599 - val_accuracy: 0.0588\n",
      "Epoch 7403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4343 - accuracy: 0.0156 - val_loss: 125.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 7404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3999 - accuracy: 0.0156 - val_loss: 126.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.0525 - accuracy: 0.0469 - val_loss: 131.0509 - val_accuracy: 0.0588\n",
      "Epoch 7406/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 18.8642 - accuracy: 0.0156 - val_loss: 132.4939 - val_accuracy: 0.0588\n",
      "Epoch 7407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4496 - accuracy: 0.0156 - val_loss: 135.8622 - val_accuracy: 0.0000e+00\n",
      "Epoch 7408/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.8022 - accuracy: 0.0000e+00 - val_loss: 139.9848 - val_accuracy: 0.0000e+00\n",
      "Epoch 7409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2206 - accuracy: 0.0000e+00 - val_loss: 138.0463 - val_accuracy: 0.0000e+00\n",
      "Epoch 7410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2273 - accuracy: 0.0000e+00 - val_loss: 136.8024 - val_accuracy: 0.0588\n",
      "Epoch 7411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5888 - accuracy: 0.0156 - val_loss: 139.4359 - val_accuracy: 0.0588\n",
      "Epoch 7412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7017 - accuracy: 0.0156 - val_loss: 141.6357 - val_accuracy: 0.0588\n",
      "Epoch 7413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8008 - accuracy: 0.0000e+00 - val_loss: 144.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 7414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6140 - accuracy: 0.0312 - val_loss: 143.7868 - val_accuracy: 0.0000e+00\n",
      "Epoch 7415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0996 - accuracy: 0.0000e+00 - val_loss: 138.1125 - val_accuracy: 0.0588\n",
      "Epoch 7416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5955 - accuracy: 0.0469 - val_loss: 138.9357 - val_accuracy: 0.0588\n",
      "Epoch 7417/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5078 - accuracy: 0.0156 - val_loss: 141.4992 - val_accuracy: 0.0588\n",
      "Epoch 7418/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 20.8541 - accuracy: 0.0156 - val_loss: 140.3371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7419/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6697 - accuracy: 0.0000e+00 - val_loss: 135.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 7420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2284 - accuracy: 0.0156 - val_loss: 134.1636 - val_accuracy: 0.0000e+00\n",
      "Epoch 7421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4107 - accuracy: 0.0000e+00 - val_loss: 135.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 7422/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3976 - accuracy: 0.0156 - val_loss: 137.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1706 - accuracy: 0.0000e+00 - val_loss: 139.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 7424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9726 - accuracy: 0.0000e+00 - val_loss: 141.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 7425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9744 - accuracy: 0.0469 - val_loss: 141.8119 - val_accuracy: 0.0000e+00\n",
      "Epoch 7426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7036 - accuracy: 0.0156 - val_loss: 135.6266 - val_accuracy: 0.0588\n",
      "Epoch 7427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0697 - accuracy: 0.0000e+00 - val_loss: 124.4140 - val_accuracy: 0.0588\n",
      "Epoch 7428/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8502 - accuracy: 0.0000e+00 - val_loss: 121.0051 - val_accuracy: 0.0588\n",
      "Epoch 7429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9186 - accuracy: 0.0156 - val_loss: 120.2671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7430/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 32.1980 - accuracy: 0.0000e+00 - val_loss: 121.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 7431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5263 - accuracy: 0.0312 - val_loss: 123.3114 - val_accuracy: 0.0588\n",
      "Epoch 7432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0123 - accuracy: 0.0000e+00 - val_loss: 123.6576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7433/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3461 - accuracy: 0.0312 - val_loss: 125.6850 - val_accuracy: 0.0588\n",
      "Epoch 7434/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 21.3900 - accuracy: 0.0000e+00 - val_loss: 123.9100 - val_accuracy: 0.0000e+00\n",
      "Epoch 7435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4228 - accuracy: 0.0000e+00 - val_loss: 129.9516 - val_accuracy: 0.0588\n",
      "Epoch 7436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1631 - accuracy: 0.0000e+00 - val_loss: 138.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7437/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3118 - accuracy: 0.0156 - val_loss: 140.0785 - val_accuracy: 0.0588\n",
      "Epoch 7438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1318 - accuracy: 0.0156 - val_loss: 134.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 7439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3727 - accuracy: 0.0000e+00 - val_loss: 128.7371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9256 - accuracy: 0.0000e+00 - val_loss: 121.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 7441/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.5688 - accuracy: 0.0156 - val_loss: 122.2857 - val_accuracy: 0.0000e+00\n",
      "Epoch 7442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9508 - accuracy: 0.0156 - val_loss: 127.3889 - val_accuracy: 0.0000e+00\n",
      "Epoch 7443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0359 - accuracy: 0.0000e+00 - val_loss: 135.7779 - val_accuracy: 0.0000e+00\n",
      "Epoch 7444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2568 - accuracy: 0.0469 - val_loss: 146.2771 - val_accuracy: 0.0000e+00\n",
      "Epoch 7445/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9670 - accuracy: 0.0156 - val_loss: 151.5379 - val_accuracy: 0.0588\n",
      "Epoch 7446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2932 - accuracy: 0.0000e+00 - val_loss: 152.4220 - val_accuracy: 0.0588\n",
      "Epoch 7447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3582 - accuracy: 0.0312 - val_loss: 138.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 7448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 22.7600 - accuracy: 0.0156 - val_loss: 131.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2821 - accuracy: 0.0156 - val_loss: 127.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 7450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8173 - accuracy: 0.0000e+00 - val_loss: 128.9753 - val_accuracy: 0.0000e+00\n",
      "Epoch 7451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3771 - accuracy: 0.0156 - val_loss: 133.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 7452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8491 - accuracy: 0.0156 - val_loss: 134.5292 - val_accuracy: 0.0000e+00\n",
      "Epoch 7453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9423 - accuracy: 0.0156 - val_loss: 142.0368 - val_accuracy: 0.0000e+00\n",
      "Epoch 7454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1780 - accuracy: 0.0156 - val_loss: 143.9655 - val_accuracy: 0.0588\n",
      "Epoch 7455/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0025 - accuracy: 0.0156 - val_loss: 135.2306 - val_accuracy: 0.0588\n",
      "Epoch 7456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9862 - accuracy: 0.0312 - val_loss: 132.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 7457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2999 - accuracy: 0.0000e+00 - val_loss: 132.9360 - val_accuracy: 0.0000e+00\n",
      "Epoch 7458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5513 - accuracy: 0.0000e+00 - val_loss: 131.3288 - val_accuracy: 0.0000e+00\n",
      "Epoch 7459/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3113 - accuracy: 0.0156 - val_loss: 126.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 7460/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7617 - accuracy: 0.0000e+00 - val_loss: 121.5731 - val_accuracy: 0.0588\n",
      "Epoch 7461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9977 - accuracy: 0.0156 - val_loss: 119.2215 - val_accuracy: 0.0588\n",
      "Epoch 7462/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7364 - accuracy: 0.0000e+00 - val_loss: 118.8170 - val_accuracy: 0.0588\n",
      "Epoch 7463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0859 - accuracy: 0.0000e+00 - val_loss: 120.2907 - val_accuracy: 0.0588\n",
      "Epoch 7464/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2023 - accuracy: 0.0000e+00 - val_loss: 130.8267 - val_accuracy: 0.0000e+00\n",
      "Epoch 7465/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 23.6895 - accuracy: 0.0156 - val_loss: 134.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 7466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2109 - accuracy: 0.0156 - val_loss: 133.7945 - val_accuracy: 0.0588\n",
      "Epoch 7467/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2618 - accuracy: 0.0156 - val_loss: 137.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 7468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1246 - accuracy: 0.0000e+00 - val_loss: 141.0655 - val_accuracy: 0.0588\n",
      "Epoch 7469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9197 - accuracy: 0.0156 - val_loss: 143.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 7470/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.8255 - accuracy: 0.0156 - val_loss: 143.2437 - val_accuracy: 0.0000e+00\n",
      "Epoch 7471/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 22.3755 - accuracy: 0.0000e+00 - val_loss: 142.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 7472/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 30.0500 - accuracy: 0.0000e+00 - val_loss: 142.0347 - val_accuracy: 0.0588\n",
      "Epoch 7473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0850 - accuracy: 0.0000e+00 - val_loss: 142.3245 - val_accuracy: 0.0000e+00\n",
      "Epoch 7474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4598 - accuracy: 0.0000e+00 - val_loss: 137.3372 - val_accuracy: 0.0000e+00\n",
      "Epoch 7475/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 17.8666 - accuracy: 0.0000e+00 - val_loss: 129.4731 - val_accuracy: 0.0000e+00\n",
      "Epoch 7476/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 24.5973 - accuracy: 0.0156 - val_loss: 121.2979 - val_accuracy: 0.0588\n",
      "Epoch 7477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3974 - accuracy: 0.0000e+00 - val_loss: 115.8476 - val_accuracy: 0.0588\n",
      "Epoch 7478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4656 - accuracy: 0.0000e+00 - val_loss: 112.9741 - val_accuracy: 0.0588\n",
      "Epoch 7479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9250 - accuracy: 0.0312 - val_loss: 118.0633 - val_accuracy: 0.0588\n",
      "Epoch 7480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0875 - accuracy: 0.0312 - val_loss: 125.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 7481/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4402 - accuracy: 0.0156 - val_loss: 132.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 7482/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 24.6656 - accuracy: 0.0312 - val_loss: 136.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 7483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2606 - accuracy: 0.0000e+00 - val_loss: 139.3978 - val_accuracy: 0.0588\n",
      "Epoch 7484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0231 - accuracy: 0.0156 - val_loss: 135.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 7485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1410 - accuracy: 0.0156 - val_loss: 132.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 7486/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8666 - accuracy: 0.0156 - val_loss: 136.3458 - val_accuracy: 0.0000e+00\n",
      "Epoch 7487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8188 - accuracy: 0.0000e+00 - val_loss: 138.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6895 - accuracy: 0.0156 - val_loss: 141.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 7489/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0906 - accuracy: 0.0156 - val_loss: 137.9507 - val_accuracy: 0.0000e+00\n",
      "Epoch 7490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2645 - accuracy: 0.0156 - val_loss: 128.9896 - val_accuracy: 0.0000e+00\n",
      "Epoch 7491/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 17.5792 - accuracy: 0.0156 - val_loss: 123.3142 - val_accuracy: 0.0588\n",
      "Epoch 7492/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.1250 - accuracy: 0.0156 - val_loss: 123.8241 - val_accuracy: 0.0588\n",
      "Epoch 7493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6459 - accuracy: 0.0000e+00 - val_loss: 136.8460 - val_accuracy: 0.0588\n",
      "Epoch 7494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2747 - accuracy: 0.0000e+00 - val_loss: 143.4293 - val_accuracy: 0.0588\n",
      "Epoch 7495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.6044 - accuracy: 0.0156 - val_loss: 131.0000 - val_accuracy: 0.0588\n",
      "Epoch 7496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2551 - accuracy: 0.0000e+00 - val_loss: 125.6139 - val_accuracy: 0.0588\n",
      "Epoch 7497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1911 - accuracy: 0.0156 - val_loss: 126.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7498/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0015 - accuracy: 0.0156 - val_loss: 126.1476 - val_accuracy: 0.0000e+00\n",
      "Epoch 7499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8104 - accuracy: 0.0000e+00 - val_loss: 131.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9167 - accuracy: 0.0156 - val_loss: 141.9301 - val_accuracy: 0.0000e+00\n",
      "Epoch 7501/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 28.5917 - accuracy: 0.0312 - val_loss: 149.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.1664 - accuracy: 0.0000e+00 - val_loss: 149.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 7503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3097 - accuracy: 0.0156 - val_loss: 141.2351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0285 - accuracy: 0.0000e+00 - val_loss: 137.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 7505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8335 - accuracy: 0.0156 - val_loss: 138.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 7506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.8606 - accuracy: 0.0469 - val_loss: 144.6811 - val_accuracy: 0.0588\n",
      "Epoch 7507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4905 - accuracy: 0.0312 - val_loss: 147.1034 - val_accuracy: 0.0588\n",
      "Epoch 7508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5241 - accuracy: 0.0469 - val_loss: 144.2018 - val_accuracy: 0.0588\n",
      "Epoch 7509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4147 - accuracy: 0.0000e+00 - val_loss: 143.1407 - val_accuracy: 0.0588\n",
      "Epoch 7510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1017 - accuracy: 0.0000e+00 - val_loss: 144.7118 - val_accuracy: 0.0588\n",
      "Epoch 7511/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 17.9094 - accuracy: 0.0000e+00 - val_loss: 144.6680 - val_accuracy: 0.0588\n",
      "Epoch 7512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1498 - accuracy: 0.0156 - val_loss: 147.1527 - val_accuracy: 0.0588\n",
      "Epoch 7513/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5285 - accuracy: 0.0312 - val_loss: 148.6960 - val_accuracy: 0.0588\n",
      "Epoch 7514/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7244 - accuracy: 0.0312 - val_loss: 145.0225 - val_accuracy: 0.0588\n",
      "Epoch 7515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6101 - accuracy: 0.0000e+00 - val_loss: 135.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 7516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2088 - accuracy: 0.0156 - val_loss: 127.5392 - val_accuracy: 0.0000e+00\n",
      "Epoch 7517/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1302 - accuracy: 0.0312 - val_loss: 124.4194 - val_accuracy: 0.0588\n",
      "Epoch 7518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6926 - accuracy: 0.0156 - val_loss: 120.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 7519/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 35.5816 - accuracy: 0.0000e+00 - val_loss: 121.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7520/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.8399 - accuracy: 0.0156 - val_loss: 120.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 7521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2655 - accuracy: 0.0156 - val_loss: 123.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7522/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.5844 - accuracy: 0.0156 - val_loss: 129.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8937 - accuracy: 0.0156 - val_loss: 140.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7524/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 24.9597 - accuracy: 0.0156 - val_loss: 149.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 7525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6404 - accuracy: 0.0156 - val_loss: 148.3275 - val_accuracy: 0.0588\n",
      "Epoch 7526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2723 - accuracy: 0.0156 - val_loss: 136.4298 - val_accuracy: 0.1176\n",
      "Epoch 7527/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.2731 - accuracy: 0.0000e+00 - val_loss: 130.5034 - val_accuracy: 0.0588\n",
      "Epoch 7528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4457 - accuracy: 0.0156 - val_loss: 129.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 7529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2891 - accuracy: 0.0312 - val_loss: 129.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 7530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0529 - accuracy: 0.0000e+00 - val_loss: 129.9885 - val_accuracy: 0.0588\n",
      "Epoch 7531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7648 - accuracy: 0.0000e+00 - val_loss: 127.3174 - val_accuracy: 0.0588\n",
      "Epoch 7532/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0302 - accuracy: 0.0312 - val_loss: 122.2676 - val_accuracy: 0.0588\n",
      "Epoch 7533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6022 - accuracy: 0.0000e+00 - val_loss: 118.7342 - val_accuracy: 0.0588\n",
      "Epoch 7534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4218 - accuracy: 0.0000e+00 - val_loss: 123.9433 - val_accuracy: 0.0588\n",
      "Epoch 7535/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8402 - accuracy: 0.0156 - val_loss: 134.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 7536/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4863 - accuracy: 0.0312 - val_loss: 139.7335 - val_accuracy: 0.0000e+00\n",
      "Epoch 7537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0610 - accuracy: 0.0312 - val_loss: 141.6832 - val_accuracy: 0.0000e+00\n",
      "Epoch 7538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1194 - accuracy: 0.0000e+00 - val_loss: 137.3623 - val_accuracy: 0.0000e+00\n",
      "Epoch 7539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1525 - accuracy: 0.0312 - val_loss: 134.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 7540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1271 - accuracy: 0.0156 - val_loss: 131.9419 - val_accuracy: 0.0588\n",
      "Epoch 7541/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.8511 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 19.3900 - accuracy: 0.0000e+00 - val_loss: 129.5257 - val_accuracy: 0.1176\n",
      "Epoch 7542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0052 - accuracy: 0.0000e+00 - val_loss: 127.5619 - val_accuracy: 0.1176\n",
      "Epoch 7543/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 14.4653 - accuracy: 0.0000e+00 - val_loss: 129.8257 - val_accuracy: 0.0588\n",
      "Epoch 7544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3439 - accuracy: 0.0312 - val_loss: 132.4097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0653 - accuracy: 0.0156 - val_loss: 136.3554 - val_accuracy: 0.0000e+00\n",
      "Epoch 7546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2222 - accuracy: 0.0156 - val_loss: 136.7317 - val_accuracy: 0.0588\n",
      "Epoch 7547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5510 - accuracy: 0.0469 - val_loss: 123.8940 - val_accuracy: 0.0588\n",
      "Epoch 7548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9628 - accuracy: 0.0000e+00 - val_loss: 120.3576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5202 - accuracy: 0.0156 - val_loss: 120.7338 - val_accuracy: 0.0000e+00\n",
      "Epoch 7550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4604 - accuracy: 0.0000e+00 - val_loss: 127.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 7551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6875 - accuracy: 0.0156 - val_loss: 142.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 7552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7784 - accuracy: 0.0469 - val_loss: 147.3374 - val_accuracy: 0.0588\n",
      "Epoch 7553/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2777 - accuracy: 0.0156 - val_loss: 146.6376 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7554/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 27.4067 - accuracy: 0.0000e+00 - val_loss: 141.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 7555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4540 - accuracy: 0.0000e+00 - val_loss: 137.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 7556/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0892 - accuracy: 0.0000e+00 - val_loss: 127.7966 - val_accuracy: 0.0588\n",
      "Epoch 7557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0619 - accuracy: 0.0312 - val_loss: 123.3729 - val_accuracy: 0.0588\n",
      "Epoch 7558/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0359 - accuracy: 0.0156 - val_loss: 128.1567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6347 - accuracy: 0.0000e+00 - val_loss: 127.0387 - val_accuracy: 0.0588\n",
      "Epoch 7560/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3987 - accuracy: 0.0312 - val_loss: 121.5226 - val_accuracy: 0.0588\n",
      "Epoch 7561/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 28.0245 - accuracy: 0.0312 - val_loss: 118.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 7562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0886 - accuracy: 0.0312 - val_loss: 121.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1381 - accuracy: 0.0156 - val_loss: 125.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 7564/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.3293 - accuracy: 0.0000e+00 - val_loss: 131.6722 - val_accuracy: 0.0588\n",
      "Epoch 7565/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 23.8187 - accuracy: 0.0000e+00 - val_loss: 132.7325 - val_accuracy: 0.0588\n",
      "Epoch 7566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6484 - accuracy: 0.0000e+00 - val_loss: 132.0180 - val_accuracy: 0.0588\n",
      "Epoch 7567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7010 - accuracy: 0.0000e+00 - val_loss: 130.6007 - val_accuracy: 0.0588\n",
      "Epoch 7568/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 18.8113 - accuracy: 0.0000e+00 - val_loss: 132.2492 - val_accuracy: 0.0588\n",
      "Epoch 7569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3292 - accuracy: 0.0000e+00 - val_loss: 129.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 7570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5394 - accuracy: 0.0000e+00 - val_loss: 122.6100 - val_accuracy: 0.0000e+00\n",
      "Epoch 7571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2555 - accuracy: 0.0000e+00 - val_loss: 116.5378 - val_accuracy: 0.0000e+00\n",
      "Epoch 7572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9539 - accuracy: 0.0156 - val_loss: 116.9500 - val_accuracy: 0.0588\n",
      "Epoch 7573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0531 - accuracy: 0.0156 - val_loss: 124.9346 - val_accuracy: 0.0588\n",
      "Epoch 7574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6149 - accuracy: 0.0000e+00 - val_loss: 127.5537 - val_accuracy: 0.0588\n",
      "Epoch 7575/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 18.4759 - accuracy: 0.0000e+00 - val_loss: 123.4854 - val_accuracy: 0.1176\n",
      "Epoch 7576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2712 - accuracy: 0.0156 - val_loss: 123.9950 - val_accuracy: 0.0588\n",
      "Epoch 7577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4599 - accuracy: 0.0000e+00 - val_loss: 120.7340 - val_accuracy: 0.1176\n",
      "Epoch 7578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7466 - accuracy: 0.0156 - val_loss: 121.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 7579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4110 - accuracy: 0.0156 - val_loss: 125.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8249 - accuracy: 0.0156 - val_loss: 130.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 7581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4170 - accuracy: 0.0156 - val_loss: 139.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 7582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7443 - accuracy: 0.0000e+00 - val_loss: 144.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 7583/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 24.2451 - accuracy: 0.0156 - val_loss: 147.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7584/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7194 - accuracy: 0.0000e+00 - val_loss: 146.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 7585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7899 - accuracy: 0.0000e+00 - val_loss: 136.5057 - val_accuracy: 0.0588\n",
      "Epoch 7586/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 20.1952 - accuracy: 0.0000e+00 - val_loss: 123.8135 - val_accuracy: 0.0588\n",
      "Epoch 7587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2523 - accuracy: 0.0000e+00 - val_loss: 124.6369 - val_accuracy: 0.0588\n",
      "Epoch 7588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7159 - accuracy: 0.0000e+00 - val_loss: 132.6094 - val_accuracy: 0.0588\n",
      "Epoch 7589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5133 - accuracy: 0.0156 - val_loss: 134.4375 - val_accuracy: 0.0588\n",
      "Epoch 7590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9525 - accuracy: 0.0312 - val_loss: 136.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 7591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9406 - accuracy: 0.0156 - val_loss: 135.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 7592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.1268 - accuracy: 0.0156 - val_loss: 129.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 7593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5723 - accuracy: 0.0156 - val_loss: 126.0417 - val_accuracy: 0.0000e+00\n",
      "Epoch 7594/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9628 - accuracy: 0.0156 - val_loss: 129.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 7595/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7801 - accuracy: 0.0000e+00 - val_loss: 134.2578 - val_accuracy: 0.0000e+00\n",
      "Epoch 7596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8393 - accuracy: 0.0156 - val_loss: 139.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 7597/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 12.5627 - accuracy: 0.0156 - val_loss: 136.0885 - val_accuracy: 0.0588\n",
      "Epoch 7598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1042 - accuracy: 0.0156 - val_loss: 136.2254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5616 - accuracy: 0.0156 - val_loss: 141.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 7600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0632 - accuracy: 0.0156 - val_loss: 143.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 7601/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9201 - accuracy: 0.0312 - val_loss: 143.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 7602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7996 - accuracy: 0.0000e+00 - val_loss: 137.2654 - val_accuracy: 0.0588\n",
      "Epoch 7603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0672 - accuracy: 0.0312 - val_loss: 132.0300 - val_accuracy: 0.0588\n",
      "Epoch 7604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5196 - accuracy: 0.0156 - val_loss: 133.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0939 - accuracy: 0.0156 - val_loss: 131.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7606/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 31.2527 - accuracy: 0.0000e+00 - val_loss: 127.5874 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1650 - accuracy: 0.0000e+00 - val_loss: 135.2606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9654 - accuracy: 0.0156 - val_loss: 138.2066 - val_accuracy: 0.0588\n",
      "Epoch 7609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1140 - accuracy: 0.0312 - val_loss: 132.8301 - val_accuracy: 0.0588\n",
      "Epoch 7610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0388 - accuracy: 0.0000e+00 - val_loss: 132.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 7611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8087 - accuracy: 0.0000e+00 - val_loss: 133.6935 - val_accuracy: 0.0000e+00\n",
      "Epoch 7612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6811 - accuracy: 0.0156 - val_loss: 135.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 7613/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3960 - accuracy: 0.0156 - val_loss: 138.6674 - val_accuracy: 0.0588\n",
      "Epoch 7614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4215 - accuracy: 0.0000e+00 - val_loss: 137.5787 - val_accuracy: 0.0588\n",
      "Epoch 7615/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.6516 - accuracy: 0.0000e+00 - val_loss: 128.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 7616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0320 - accuracy: 0.0156 - val_loss: 120.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 7617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6685 - accuracy: 0.0000e+00 - val_loss: 121.0244 - val_accuracy: 0.0588\n",
      "Epoch 7618/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 19.4414 - accuracy: 0.0156 - val_loss: 130.3279 - val_accuracy: 0.0588\n",
      "Epoch 7619/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 35.6733 - accuracy: 0.0000e+00 - val_loss: 129.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 7620/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.1384 - accuracy: 0.0000e+00 - val_loss: 133.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7621/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.9667 - accuracy: 0.0156 - val_loss: 132.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 7622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1206 - accuracy: 0.0000e+00 - val_loss: 130.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1128 - accuracy: 0.0156 - val_loss: 127.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 7624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1652 - accuracy: 0.0000e+00 - val_loss: 125.9560 - val_accuracy: 0.0000e+00\n",
      "Epoch 7625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0225 - accuracy: 0.0156 - val_loss: 131.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1644 - accuracy: 0.0000e+00 - val_loss: 139.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 7627/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8930 - accuracy: 0.0312 - val_loss: 142.8732 - val_accuracy: 0.0000e+00\n",
      "Epoch 7628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8244 - accuracy: 0.0156 - val_loss: 147.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7629/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 21.1812 - accuracy: 0.0000e+00 - val_loss: 144.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7630/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5951 - accuracy: 0.0156 - val_loss: 138.7742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7631/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2570 - accuracy: 0.0000e+00 - val_loss: 135.6471 - val_accuracy: 0.0000e+00\n",
      "Epoch 7632/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 27.9247 - accuracy: 0.0000e+00 - val_loss: 133.3420 - val_accuracy: 0.0000e+00\n",
      "Epoch 7633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9772 - accuracy: 0.0312 - val_loss: 135.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4594 - accuracy: 0.0156 - val_loss: 142.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 7635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1656 - accuracy: 0.0312 - val_loss: 144.8197 - val_accuracy: 0.0000e+00\n",
      "Epoch 7636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7089 - accuracy: 0.0000e+00 - val_loss: 140.4934 - val_accuracy: 0.0588\n",
      "Epoch 7637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9702 - accuracy: 0.0156 - val_loss: 136.3060 - val_accuracy: 0.0000e+00\n",
      "Epoch 7638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2827 - accuracy: 0.0000e+00 - val_loss: 130.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 7639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9273 - accuracy: 0.0156 - val_loss: 122.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7640/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 22.2903 - accuracy: 0.0000e+00 - val_loss: 118.3062 - val_accuracy: 0.0000e+00\n",
      "Epoch 7641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8874 - accuracy: 0.0000e+00 - val_loss: 122.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 7642/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3263 - accuracy: 0.0156 - val_loss: 129.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 7643/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 14.7791 - accuracy: 0.0156 - val_loss: 134.5099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7644/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 22.3463 - accuracy: 0.0000e+00 - val_loss: 132.9721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7429 - accuracy: 0.0000e+00 - val_loss: 128.6324 - val_accuracy: 0.0000e+00\n",
      "Epoch 7646/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.2074 - accuracy: 0.0156 - val_loss: 124.9250 - val_accuracy: 0.0000e+00\n",
      "Epoch 7647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4056 - accuracy: 0.0000e+00 - val_loss: 128.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 7648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4406 - accuracy: 0.0156 - val_loss: 135.1781 - val_accuracy: 0.0000e+00\n",
      "Epoch 7649/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.9122 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 20.9459 - accuracy: 0.0000e+00 - val_loss: 135.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 7650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2655 - accuracy: 0.0000e+00 - val_loss: 138.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7651/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 20.7113 - accuracy: 0.0000e+00 - val_loss: 138.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 7652/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 28.1805 - accuracy: 0.0000e+00 - val_loss: 138.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 7653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0624 - accuracy: 0.0312 - val_loss: 134.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 7654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8743 - accuracy: 0.0000e+00 - val_loss: 126.2639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3819 - accuracy: 0.0312 - val_loss: 122.2580 - val_accuracy: 0.0588\n",
      "Epoch 7656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7725 - accuracy: 0.0156 - val_loss: 125.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 7657/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6008 - accuracy: 0.0156 - val_loss: 128.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 7658/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6073 - accuracy: 0.0000e+00 - val_loss: 134.2833 - val_accuracy: 0.0000e+00\n",
      "Epoch 7659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3246 - accuracy: 0.0000e+00 - val_loss: 138.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 7660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2381 - accuracy: 0.0000e+00 - val_loss: 138.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 7661/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3349 - accuracy: 0.0156 - val_loss: 133.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 7662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9916 - accuracy: 0.0156 - val_loss: 131.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 7663/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 31.6826 - accuracy: 0.0000e+00 - val_loss: 132.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 7664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5310 - accuracy: 0.0000e+00 - val_loss: 126.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 7665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3706 - accuracy: 0.0156 - val_loss: 120.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 7666/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 14.9137 - accuracy: 0.0156 - val_loss: 116.5810 - val_accuracy: 0.0588\n",
      "Epoch 7667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7518 - accuracy: 0.0156 - val_loss: 123.7784 - val_accuracy: 0.0000e+00\n",
      "Epoch 7668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9353 - accuracy: 0.0312 - val_loss: 127.2518 - val_accuracy: 0.0000e+00\n",
      "Epoch 7669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3731 - accuracy: 0.0000e+00 - val_loss: 130.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 7670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7816 - accuracy: 0.0312 - val_loss: 129.5264 - val_accuracy: 0.0588\n",
      "Epoch 7671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0780 - accuracy: 0.0469 - val_loss: 129.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 7672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8352 - accuracy: 0.0000e+00 - val_loss: 125.7224 - val_accuracy: 0.0000e+00\n",
      "Epoch 7673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7271 - accuracy: 0.0000e+00 - val_loss: 124.7987 - val_accuracy: 0.0000e+00\n",
      "Epoch 7674/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 34.8053 - accuracy: 0.0312 - val_loss: 124.3568 - val_accuracy: 0.0000e+00\n",
      "Epoch 7675/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0528 - accuracy: 0.0156 - val_loss: 137.9252 - val_accuracy: 0.0000e+00\n",
      "Epoch 7676/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 20.9167 - accuracy: 0.0469 - val_loss: 144.9504 - val_accuracy: 0.0000e+00\n",
      "Epoch 7677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3655 - accuracy: 0.0000e+00 - val_loss: 142.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7989 - accuracy: 0.0312 - val_loss: 137.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 7679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8731 - accuracy: 0.0312 - val_loss: 127.6807 - val_accuracy: 0.0000e+00\n",
      "Epoch 7680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3776 - accuracy: 0.0000e+00 - val_loss: 122.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 7681/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3155 - accuracy: 0.0156 - val_loss: 127.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 7682/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7821 - accuracy: 0.0000e+00 - val_loss: 141.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 7683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8615 - accuracy: 0.0000e+00 - val_loss: 149.6787 - val_accuracy: 0.0588\n",
      "Epoch 7684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8599 - accuracy: 0.0156 - val_loss: 144.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 7685/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 18.0180 - accuracy: 0.0156 - val_loss: 137.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 7686/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 21.3886 - accuracy: 0.0156 - val_loss: 130.6049 - val_accuracy: 0.0588\n",
      "Epoch 7687/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.0511 - accuracy: 0.0000e+00 - val_loss: 136.9610 - val_accuracy: 0.0000e+00\n",
      "Epoch 7688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0159 - accuracy: 0.0000e+00 - val_loss: 147.4497 - val_accuracy: 0.0000e+00\n",
      "Epoch 7689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8498 - accuracy: 0.0000e+00 - val_loss: 146.2481 - val_accuracy: 0.0000e+00\n",
      "Epoch 7690/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0084 - accuracy: 0.0156 - val_loss: 133.2592 - val_accuracy: 0.0000e+00\n",
      "Epoch 7691/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9593 - accuracy: 0.0000e+00 - val_loss: 125.1299 - val_accuracy: 0.0000e+00\n",
      "Epoch 7692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9741 - accuracy: 0.0000e+00 - val_loss: 125.2701 - val_accuracy: 0.0000e+00\n",
      "Epoch 7693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9817 - accuracy: 0.0156 - val_loss: 126.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9879 - accuracy: 0.0000e+00 - val_loss: 131.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 7695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8689 - accuracy: 0.0156 - val_loss: 137.2183 - val_accuracy: 0.0588\n",
      "Epoch 7696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0673 - accuracy: 0.0000e+00 - val_loss: 136.1819 - val_accuracy: 0.0588\n",
      "Epoch 7697/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 16.0599 - accuracy: 0.0000e+00 - val_loss: 132.0769 - val_accuracy: 0.0588\n",
      "Epoch 7698/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.2801 - accuracy: 0.0312 - val_loss: 127.4968 - val_accuracy: 0.0588\n",
      "Epoch 7699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6339 - accuracy: 0.0312 - val_loss: 122.1803 - val_accuracy: 0.0588\n",
      "Epoch 7700/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.6411 - accuracy: 0.0156 - val_loss: 119.0727 - val_accuracy: 0.0588\n",
      "Epoch 7701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9799 - accuracy: 0.0000e+00 - val_loss: 117.2563 - val_accuracy: 0.0588\n",
      "Epoch 7702/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 30.8880 - accuracy: 0.0000e+00 - val_loss: 115.3174 - val_accuracy: 0.0588\n",
      "Epoch 7703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0315 - accuracy: 0.0312 - val_loss: 115.5506 - val_accuracy: 0.0588\n",
      "Epoch 7704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7626 - accuracy: 0.0000e+00 - val_loss: 119.8397 - val_accuracy: 0.0588\n",
      "Epoch 7705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0395 - accuracy: 0.0156 - val_loss: 126.9718 - val_accuracy: 0.0588\n",
      "Epoch 7706/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6597 - accuracy: 0.0000e+00 - val_loss: 129.8381 - val_accuracy: 0.1176\n",
      "Epoch 7707/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 27.8680 - accuracy: 0.0156 - val_loss: 131.1337 - val_accuracy: 0.0588\n",
      "Epoch 7708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0020 - accuracy: 0.0000e+00 - val_loss: 132.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 7709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9860 - accuracy: 0.0156 - val_loss: 132.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 7710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9982 - accuracy: 0.0000e+00 - val_loss: 130.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 7711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9971 - accuracy: 0.0312 - val_loss: 128.6378 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5876 - accuracy: 0.0000e+00 - val_loss: 131.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2393 - accuracy: 0.0000e+00 - val_loss: 125.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2670 - accuracy: 0.0000e+00 - val_loss: 121.1875 - val_accuracy: 0.0588\n",
      "Epoch 7715/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 16.4822 - accuracy: 0.0000e+00 - val_loss: 122.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 7716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4524 - accuracy: 0.0312 - val_loss: 127.5237 - val_accuracy: 0.0000e+00\n",
      "Epoch 7717/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7701 - accuracy: 0.0156 - val_loss: 136.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7718/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 24.2804 - accuracy: 0.0156 - val_loss: 142.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 7719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1149 - accuracy: 0.0156 - val_loss: 142.8681 - val_accuracy: 0.0000e+00\n",
      "Epoch 7720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6459 - accuracy: 0.0156 - val_loss: 143.4025 - val_accuracy: 0.0000e+00\n",
      "Epoch 7721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1138 - accuracy: 0.0000e+00 - val_loss: 140.5051 - val_accuracy: 0.0588\n",
      "Epoch 7722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2695 - accuracy: 0.0156 - val_loss: 132.9763 - val_accuracy: 0.0588\n",
      "Epoch 7723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1470 - accuracy: 0.0000e+00 - val_loss: 124.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 7724/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 25.8622 - accuracy: 0.0000e+00 - val_loss: 118.9552 - val_accuracy: 0.1176\n",
      "Epoch 7725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7718 - accuracy: 0.0156 - val_loss: 120.0736 - val_accuracy: 0.1176\n",
      "Epoch 7726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7513 - accuracy: 0.0156 - val_loss: 119.5877 - val_accuracy: 0.1176\n",
      "Epoch 7727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1754 - accuracy: 0.0000e+00 - val_loss: 119.1161 - val_accuracy: 0.1176\n",
      "Epoch 7728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4403 - accuracy: 0.0156 - val_loss: 117.9242 - val_accuracy: 0.0588\n",
      "Epoch 7729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8816 - accuracy: 0.0156 - val_loss: 120.8505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0120 - accuracy: 0.0000e+00 - val_loss: 125.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 7731/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3855 - accuracy: 0.0000e+00 - val_loss: 126.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 7732/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.5707 - accuracy: 0.0156 - val_loss: 130.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7733/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 24.1055 - accuracy: 0.0000e+00 - val_loss: 130.0468 - val_accuracy: 0.0588\n",
      "Epoch 7734/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4281 - accuracy: 0.0000e+00 - val_loss: 129.1826 - val_accuracy: 0.0588\n",
      "Epoch 7735/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 30.2872 - accuracy: 0.0000e+00 - val_loss: 128.3141 - val_accuracy: 0.0000e+00\n",
      "Epoch 7736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2572 - accuracy: 0.0000e+00 - val_loss: 132.9339 - val_accuracy: 0.0000e+00\n",
      "Epoch 7737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8007 - accuracy: 0.0000e+00 - val_loss: 131.9854 - val_accuracy: 0.0588\n",
      "Epoch 7738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8109 - accuracy: 0.0000e+00 - val_loss: 126.6087 - val_accuracy: 0.1176\n",
      "Epoch 7739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5971 - accuracy: 0.0000e+00 - val_loss: 124.8099 - val_accuracy: 0.0588\n",
      "Epoch 7740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9760 - accuracy: 0.0000e+00 - val_loss: 122.4703 - val_accuracy: 0.0588\n",
      "Epoch 7741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6742 - accuracy: 0.0156 - val_loss: 120.4758 - val_accuracy: 0.0588\n",
      "Epoch 7742/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 21.0229 - accuracy: 0.0000e+00 - val_loss: 131.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 7743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8565 - accuracy: 0.0000e+00 - val_loss: 139.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8850 - accuracy: 0.0000e+00 - val_loss: 142.5606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7745/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5682 - accuracy: 0.0000e+00 - val_loss: 131.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 7746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2419 - accuracy: 0.0000e+00 - val_loss: 130.7866 - val_accuracy: 0.0588\n",
      "Epoch 7747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4010 - accuracy: 0.0000e+00 - val_loss: 135.3981 - val_accuracy: 0.0000e+00\n",
      "Epoch 7748/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9024 - accuracy: 0.0000e+00 - val_loss: 141.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6372 - accuracy: 0.0000e+00 - val_loss: 140.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5629 - accuracy: 0.0156 - val_loss: 136.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 7751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5116 - accuracy: 0.0000e+00 - val_loss: 137.7450 - val_accuracy: 0.1176\n",
      "Epoch 7752/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6610 - accuracy: 0.0156 - val_loss: 138.4792 - val_accuracy: 0.1176\n",
      "Epoch 7753/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3309 - accuracy: 0.0156 - val_loss: 137.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 7754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2504 - accuracy: 0.0000e+00 - val_loss: 130.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 7755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5711 - accuracy: 0.0000e+00 - val_loss: 123.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 7756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8711 - accuracy: 0.0000e+00 - val_loss: 121.3451 - val_accuracy: 0.0000e+00\n",
      "Epoch 7757/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.6189 - accuracy: 0.0000e+00 - val_loss: 126.3297 - val_accuracy: 0.0000e+00\n",
      "Epoch 7758/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0731 - accuracy: 0.0156 - val_loss: 134.2978 - val_accuracy: 0.0000e+00\n",
      "Epoch 7759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1491 - accuracy: 0.0000e+00 - val_loss: 132.8777 - val_accuracy: 0.0000e+00\n",
      "Epoch 7760/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 27.1110 - accuracy: 0.0312 - val_loss: 126.9730 - val_accuracy: 0.0588\n",
      "Epoch 7761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1878 - accuracy: 0.0156 - val_loss: 120.4391 - val_accuracy: 0.0588\n",
      "Epoch 7762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4059 - accuracy: 0.0000e+00 - val_loss: 118.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 7763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9113 - accuracy: 0.0000e+00 - val_loss: 124.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 7764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 10.4137 - accuracy: 0.0156 - val_loss: 127.0435 - val_accuracy: 0.0000e+00\n",
      "Epoch 7765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4341 - accuracy: 0.0000e+00 - val_loss: 122.7606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9723 - accuracy: 0.0156 - val_loss: 118.2956 - val_accuracy: 0.0588\n",
      "Epoch 7767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8446 - accuracy: 0.0156 - val_loss: 120.6988 - val_accuracy: 0.0000e+00\n",
      "Epoch 7768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6833 - accuracy: 0.0000e+00 - val_loss: 135.9572 - val_accuracy: 0.0000e+00\n",
      "Epoch 7769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8394 - accuracy: 0.0000e+00 - val_loss: 146.4430 - val_accuracy: 0.0588\n",
      "Epoch 7770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2714 - accuracy: 0.0156 - val_loss: 145.5447 - val_accuracy: 0.0000e+00\n",
      "Epoch 7771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9336 - accuracy: 0.0000e+00 - val_loss: 140.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7772/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.2533 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 25.8703 - accuracy: 0.0000e+00 - val_loss: 137.8840 - val_accuracy: 0.0000e+00\n",
      "Epoch 7773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9990 - accuracy: 0.0156 - val_loss: 145.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 7774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9372 - accuracy: 0.0312 - val_loss: 150.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 7775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5300 - accuracy: 0.0000e+00 - val_loss: 148.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 7776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1814 - accuracy: 0.0156 - val_loss: 139.9393 - val_accuracy: 0.0000e+00\n",
      "Epoch 7777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8994 - accuracy: 0.0312 - val_loss: 131.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 7778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8786 - accuracy: 0.0469 - val_loss: 122.7259 - val_accuracy: 0.0000e+00\n",
      "Epoch 7779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3819 - accuracy: 0.0156 - val_loss: 119.7780 - val_accuracy: 0.1176\n",
      "Epoch 7780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0609 - accuracy: 0.0156 - val_loss: 122.3996 - val_accuracy: 0.0588\n",
      "Epoch 7781/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1267 - accuracy: 0.0156 - val_loss: 126.8604 - val_accuracy: 0.0588\n",
      "Epoch 7782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1251 - accuracy: 0.0000e+00 - val_loss: 127.4227 - val_accuracy: 0.0588\n",
      "Epoch 7783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6901 - accuracy: 0.0312 - val_loss: 128.6490 - val_accuracy: 0.0588\n",
      "Epoch 7784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5655 - accuracy: 0.0312 - val_loss: 131.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2574 - accuracy: 0.0156 - val_loss: 132.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 7786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1020 - accuracy: 0.0000e+00 - val_loss: 125.5396 - val_accuracy: 0.0000e+00\n",
      "Epoch 7787/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9445 - accuracy: 0.0156 - val_loss: 126.5539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6596 - accuracy: 0.0312 - val_loss: 132.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 7789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3560 - accuracy: 0.0156 - val_loss: 136.7409 - val_accuracy: 0.0000e+00\n",
      "Epoch 7790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9230 - accuracy: 0.0156 - val_loss: 138.6192 - val_accuracy: 0.0588\n",
      "Epoch 7791/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5313 - accuracy: 0.0156 - val_loss: 137.7467 - val_accuracy: 0.0588\n",
      "Epoch 7792/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 23.5031 - accuracy: 0.0312 - val_loss: 139.0343 - val_accuracy: 0.0588\n",
      "Epoch 7793/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7334 - accuracy: 0.0156 - val_loss: 137.9882 - val_accuracy: 0.0000e+00\n",
      "Epoch 7794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6504 - accuracy: 0.0156 - val_loss: 135.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 7795/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 32.3318 - accuracy: 0.0000e+00 - val_loss: 131.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0078 - accuracy: 0.0156 - val_loss: 129.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 7797/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2220 - accuracy: 0.0000e+00 - val_loss: 131.8597 - val_accuracy: 0.0000e+00\n",
      "Epoch 7798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6639 - accuracy: 0.0000e+00 - val_loss: 134.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 7799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9839 - accuracy: 0.0156 - val_loss: 131.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1028 - accuracy: 0.0000e+00 - val_loss: 127.9020 - val_accuracy: 0.0588\n",
      "Epoch 7801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1583 - accuracy: 0.0000e+00 - val_loss: 124.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7802/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0109 - accuracy: 0.0000e+00 - val_loss: 122.5314 - val_accuracy: 0.0588\n",
      "Epoch 7803/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 14.0632 - accuracy: 0.0000e+00 - val_loss: 126.4432 - val_accuracy: 0.0588\n",
      "Epoch 7804/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3998 - accuracy: 0.0000e+00 - val_loss: 139.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7805/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6230 - accuracy: 0.0156 - val_loss: 140.9879 - val_accuracy: 0.0588\n",
      "Epoch 7806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6163 - accuracy: 0.0000e+00 - val_loss: 135.2906 - val_accuracy: 0.0000e+00\n",
      "Epoch 7807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3493 - accuracy: 0.0000e+00 - val_loss: 129.3188 - val_accuracy: 0.0588\n",
      "Epoch 7808/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6603 - accuracy: 0.0156 - val_loss: 125.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 7809/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7276 - accuracy: 0.0156 - val_loss: 126.1737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9649 - accuracy: 0.0000e+00 - val_loss: 132.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 7811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.7921 - accuracy: 0.0312 - val_loss: 138.1174 - val_accuracy: 0.0000e+00\n",
      "Epoch 7812/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2606 - accuracy: 0.0000e+00 - val_loss: 142.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 7813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5678 - accuracy: 0.0000e+00 - val_loss: 145.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 7814/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 25.8649 - accuracy: 0.0000e+00 - val_loss: 139.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7815/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7723 - accuracy: 0.0000e+00 - val_loss: 127.7237 - val_accuracy: 0.0588\n",
      "Epoch 7816/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 14.7230 - accuracy: 0.0000e+00 - val_loss: 116.9482 - val_accuracy: 0.0588\n",
      "Epoch 7817/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.6442 - accuracy: 0.0000e+00 - val_loss: 121.1736 - val_accuracy: 0.0588\n",
      "Epoch 7818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6319 - accuracy: 0.0156 - val_loss: 129.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 7819/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.6416 - accuracy: 0.0469 - val_loss: 138.8090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0554 - accuracy: 0.0000e+00 - val_loss: 149.4746 - val_accuracy: 0.0000e+00\n",
      "Epoch 7821/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.2785 - accuracy: 0.0156 - val_loss: 155.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 7822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7586 - accuracy: 0.0000e+00 - val_loss: 153.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 7823/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.1716 - accuracy: 0.0156 - val_loss: 141.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 7824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2005 - accuracy: 0.0000e+00 - val_loss: 130.6474 - val_accuracy: 0.0000e+00\n",
      "Epoch 7825/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 29.1444 - accuracy: 0.0000e+00 - val_loss: 129.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 7826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2725 - accuracy: 0.0156 - val_loss: 136.7706 - val_accuracy: 0.0588\n",
      "Epoch 7827/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 16.6471 - accuracy: 0.0156 - val_loss: 141.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 7828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9119 - accuracy: 0.0000e+00 - val_loss: 137.1317 - val_accuracy: 0.0588\n",
      "Epoch 7829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4995 - accuracy: 0.0156 - val_loss: 136.3486 - val_accuracy: 0.0588\n",
      "Epoch 7830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8855 - accuracy: 0.0156 - val_loss: 145.2835 - val_accuracy: 0.0588\n",
      "Epoch 7831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8821 - accuracy: 0.0156 - val_loss: 145.4057 - val_accuracy: 0.0588\n",
      "Epoch 7832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2315 - accuracy: 0.0469 - val_loss: 143.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 7833/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4488 - accuracy: 0.0156 - val_loss: 134.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7404 - accuracy: 0.0312 - val_loss: 124.9603 - val_accuracy: 0.0000e+00\n",
      "Epoch 7835/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 26.0375 - accuracy: 0.0000e+00 - val_loss: 119.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7836/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 19.8594 - accuracy: 0.0000e+00 - val_loss: 124.0797 - val_accuracy: 0.0588\n",
      "Epoch 7837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3321 - accuracy: 0.0000e+00 - val_loss: 140.2124 - val_accuracy: 0.0588\n",
      "Epoch 7838/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0844 - accuracy: 0.0156 - val_loss: 151.6080 - val_accuracy: 0.0000e+00\n",
      "Epoch 7839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0691 - accuracy: 0.0000e+00 - val_loss: 145.2211 - val_accuracy: 0.0000e+00\n",
      "Epoch 7840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1784 - accuracy: 0.0000e+00 - val_loss: 132.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 7841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2253 - accuracy: 0.0000e+00 - val_loss: 117.4859 - val_accuracy: 0.0000e+00\n",
      "Epoch 7842/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.8502 - accuracy: 0.0000e+00 - val_loss: 123.2964 - val_accuracy: 0.0000e+00\n",
      "Epoch 7843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9373 - accuracy: 0.0000e+00 - val_loss: 134.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 7844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6731 - accuracy: 0.0156 - val_loss: 146.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 7845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6539 - accuracy: 0.0000e+00 - val_loss: 148.8816 - val_accuracy: 0.0000e+00\n",
      "Epoch 7846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9614 - accuracy: 0.0156 - val_loss: 141.1213 - val_accuracy: 0.0588\n",
      "Epoch 7847/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 26.6013 - accuracy: 0.0000e+00 - val_loss: 133.0667 - val_accuracy: 0.0588\n",
      "Epoch 7848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5283 - accuracy: 0.0000e+00 - val_loss: 132.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 7849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2456 - accuracy: 0.0156 - val_loss: 131.5782 - val_accuracy: 0.0588\n",
      "Epoch 7850/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 35.9671 - accuracy: 0.0156 - val_loss: 141.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 7851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7381 - accuracy: 0.0000e+00 - val_loss: 148.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7852/10000\n",
      "64/64 [==============================] - 0s 175us/step - loss: 22.1787 - accuracy: 0.0000e+00 - val_loss: 147.3785 - val_accuracy: 0.0000e+00\n",
      "Epoch 7853/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 37.3082 - accuracy: 0.0000e+00 - val_loss: 139.6540 - val_accuracy: 0.0000e+00\n",
      "Epoch 7854/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 26.7191 - accuracy: 0.0156 - val_loss: 129.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 7855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3664 - accuracy: 0.0000e+00 - val_loss: 122.8626 - val_accuracy: 0.0000e+00\n",
      "Epoch 7856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2440 - accuracy: 0.0000e+00 - val_loss: 123.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 7857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3756 - accuracy: 0.0000e+00 - val_loss: 123.3765 - val_accuracy: 0.0000e+00\n",
      "Epoch 7858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1142 - accuracy: 0.0000e+00 - val_loss: 125.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 7859/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.9376 - accuracy: 0.0000e+00 - val_loss: 130.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5806 - accuracy: 0.0156 - val_loss: 134.7997 - val_accuracy: 0.0588\n",
      "Epoch 7861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5301 - accuracy: 0.0156 - val_loss: 134.8031 - val_accuracy: 0.0588\n",
      "Epoch 7862/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5264 - accuracy: 0.0312 - val_loss: 131.2845 - val_accuracy: 0.0588\n",
      "Epoch 7863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0190 - accuracy: 0.0156 - val_loss: 127.8012 - val_accuracy: 0.0000e+00\n",
      "Epoch 7864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7110 - accuracy: 0.0000e+00 - val_loss: 125.0037 - val_accuracy: 0.0588\n",
      "Epoch 7865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.6297 - accuracy: 0.0000e+00 - val_loss: 130.2318 - val_accuracy: 0.0588\n",
      "Epoch 7866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3974 - accuracy: 0.0312 - val_loss: 133.1580 - val_accuracy: 0.0588\n",
      "Epoch 7867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4167 - accuracy: 0.0156 - val_loss: 132.2073 - val_accuracy: 0.0588\n",
      "Epoch 7868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4422 - accuracy: 0.0312 - val_loss: 126.8641 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8777 - accuracy: 0.0000e+00 - val_loss: 129.2098 - val_accuracy: 0.0000e+00\n",
      "Epoch 7870/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.9187 - accuracy: 0.0000e+0 - 0s 47us/step - loss: 17.6636 - accuracy: 0.0000e+00 - val_loss: 138.2540 - val_accuracy: 0.0000e+00\n",
      "Epoch 7871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1908 - accuracy: 0.0156 - val_loss: 145.3363 - val_accuracy: 0.0000e+00\n",
      "Epoch 7872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2884 - accuracy: 0.0000e+00 - val_loss: 145.4384 - val_accuracy: 0.0000e+00\n",
      "Epoch 7873/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 23.2122 - accuracy: 0.0000e+00 - val_loss: 146.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 7874/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8759 - accuracy: 0.0156 - val_loss: 144.2943 - val_accuracy: 0.0588\n",
      "Epoch 7875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3212 - accuracy: 0.0156 - val_loss: 137.9061 - val_accuracy: 0.0588\n",
      "Epoch 7876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5896 - accuracy: 0.0000e+00 - val_loss: 131.1099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5586 - accuracy: 0.0312 - val_loss: 123.8585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7119 - accuracy: 0.0000e+00 - val_loss: 122.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 7879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6825 - accuracy: 0.0000e+00 - val_loss: 130.2701 - val_accuracy: 0.0588\n",
      "Epoch 7880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9336 - accuracy: 0.0156 - val_loss: 131.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 7881/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 18.6455 - accuracy: 0.0312 - val_loss: 126.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 7882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8660 - accuracy: 0.0000e+00 - val_loss: 125.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7883/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 41.7641 - accuracy: 0.0000e+00 - val_loss: 125.8612 - val_accuracy: 0.0000e+00\n",
      "Epoch 7884/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.5544 - accuracy: 0.0000e+00 - val_loss: 123.0790 - val_accuracy: 0.0000e+00\n",
      "Epoch 7885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4247 - accuracy: 0.0156 - val_loss: 125.7306 - val_accuracy: 0.0000e+00\n",
      "Epoch 7886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0152 - accuracy: 0.0312 - val_loss: 130.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 7887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2843 - accuracy: 0.0156 - val_loss: 127.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7888/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 20.1449 - accuracy: 0.0156 - val_loss: 123.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1924 - accuracy: 0.0312 - val_loss: 121.5861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.9393 - accuracy: 0.0000e+00 - val_loss: 120.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 7891/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 27.6363 - accuracy: 0.0156 - val_loss: 130.4427 - val_accuracy: 0.0000e+00\n",
      "Epoch 7892/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5838 - accuracy: 0.0000e+00 - val_loss: 133.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 7893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0995 - accuracy: 0.0000e+00 - val_loss: 134.9293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0040 - accuracy: 0.0156 - val_loss: 135.5564 - val_accuracy: 0.0000e+00\n",
      "Epoch 7895/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.1121 - accuracy: 0.0156 - val_loss: 130.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 7896/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5684 - accuracy: 0.0156 - val_loss: 122.8519 - val_accuracy: 0.0000e+00\n",
      "Epoch 7897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8934 - accuracy: 0.0156 - val_loss: 122.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 7898/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 11.0857 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 19.6675 - accuracy: 0.0000e+00 - val_loss: 123.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 7899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2418 - accuracy: 0.0156 - val_loss: 125.3663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7900/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.4357 - accuracy: 0.0000e+00 - val_loss: 131.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 7901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4767 - accuracy: 0.0000e+00 - val_loss: 138.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3077 - accuracy: 0.0156 - val_loss: 140.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 7903/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2729 - accuracy: 0.0000e+00 - val_loss: 140.7663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7904/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2759 - accuracy: 0.0156 - val_loss: 139.7571 - val_accuracy: 0.0000e+00\n",
      "Epoch 7905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3674 - accuracy: 0.0000e+00 - val_loss: 137.8468 - val_accuracy: 0.0000e+00\n",
      "Epoch 7906/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.6941 - accuracy: 0.0000e+00 - val_loss: 134.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 7907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6091 - accuracy: 0.0000e+00 - val_loss: 128.3146 - val_accuracy: 0.0000e+00\n",
      "Epoch 7908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5353 - accuracy: 0.0000e+00 - val_loss: 127.5419 - val_accuracy: 0.0000e+00\n",
      "Epoch 7909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7543 - accuracy: 0.0156 - val_loss: 129.8636 - val_accuracy: 0.0000e+00\n",
      "Epoch 7910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5818 - accuracy: 0.0000e+00 - val_loss: 130.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 7911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3453 - accuracy: 0.0156 - val_loss: 135.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 7912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3690 - accuracy: 0.0312 - val_loss: 133.7392 - val_accuracy: 0.0000e+00\n",
      "Epoch 7913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2661 - accuracy: 0.0000e+00 - val_loss: 121.4089 - val_accuracy: 0.0000e+00\n",
      "Epoch 7914/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 28.3778 - accuracy: 0.0156 - val_loss: 112.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 7915/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5541 - accuracy: 0.0000e+00 - val_loss: 110.9593 - val_accuracy: 0.0000e+00\n",
      "Epoch 7916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9254 - accuracy: 0.0156 - val_loss: 115.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 7917/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 17.5554 - accuracy: 0.0156 - val_loss: 124.6043 - val_accuracy: 0.0000e+00\n",
      "Epoch 7918/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 28.9611 - accuracy: 0.0000e+00 - val_loss: 129.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 7919/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.2116 - accuracy: 0.0000e+00 - val_loss: 125.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7920/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9042 - accuracy: 0.0000e+00 - val_loss: 120.6790 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9848 - accuracy: 0.0156 - val_loss: 121.1234 - val_accuracy: 0.0000e+00\n",
      "Epoch 7922/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0855 - accuracy: 0.0000e+00 - val_loss: 129.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 7923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6069 - accuracy: 0.0156 - val_loss: 130.0414 - val_accuracy: 0.0000e+00\n",
      "Epoch 7924/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 24.6348 - accuracy: 0.0156 - val_loss: 133.4024 - val_accuracy: 0.0000e+00\n",
      "Epoch 7925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4966 - accuracy: 0.0156 - val_loss: 143.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 7926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3087 - accuracy: 0.0000e+00 - val_loss: 146.3213 - val_accuracy: 0.0000e+00\n",
      "Epoch 7927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0063 - accuracy: 0.0156 - val_loss: 143.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 7928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0620 - accuracy: 0.0312 - val_loss: 139.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 7929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0742 - accuracy: 0.0000e+00 - val_loss: 142.5186 - val_accuracy: 0.0000e+00\n",
      "Epoch 7930/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 27.5427 - accuracy: 0.0000e+00 - val_loss: 145.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0595 - accuracy: 0.0156 - val_loss: 143.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 7932/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6592 - accuracy: 0.0000e+00 - val_loss: 141.7246 - val_accuracy: 0.0000e+00\n",
      "Epoch 7933/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 29.2823 - accuracy: 0.0156 - val_loss: 139.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 7934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3175 - accuracy: 0.0156 - val_loss: 145.2850 - val_accuracy: 0.0000e+00\n",
      "Epoch 7935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9924 - accuracy: 0.0156 - val_loss: 149.4287 - val_accuracy: 0.0588\n",
      "Epoch 7936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2557 - accuracy: 0.0156 - val_loss: 148.5125 - val_accuracy: 0.0588\n",
      "Epoch 7937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0945 - accuracy: 0.0156 - val_loss: 143.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 7938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2191 - accuracy: 0.0000e+00 - val_loss: 137.8531 - val_accuracy: 0.0000e+00\n",
      "Epoch 7939/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 23.3478 - accuracy: 0.0000e+00 - val_loss: 133.1862 - val_accuracy: 0.0588\n",
      "Epoch 7940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.1235 - accuracy: 0.0312 - val_loss: 137.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3454 - accuracy: 0.0312 - val_loss: 140.3490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7942/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 21.4876 - accuracy: 0.0000e+00 - val_loss: 139.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7943/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 20.1493 - accuracy: 0.0156 - val_loss: 143.5884 - val_accuracy: 0.0000e+00\n",
      "Epoch 7944/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.4719 - accuracy: 0.0312 - val_loss: 149.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 7945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7740 - accuracy: 0.0000e+00 - val_loss: 152.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 7946/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6096 - accuracy: 0.0000e+00 - val_loss: 151.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 7947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4463 - accuracy: 0.0000e+00 - val_loss: 138.8718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7948/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4197 - accuracy: 0.0000e+00 - val_loss: 125.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 7949/10000\n",
      "64/64 [==============================] - 0s 106us/step - loss: 33.8928 - accuracy: 0.0000e+00 - val_loss: 119.7625 - val_accuracy: 0.0000e+00\n",
      "Epoch 7950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6140 - accuracy: 0.0000e+00 - val_loss: 121.8573 - val_accuracy: 0.0000e+00\n",
      "Epoch 7951/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5195 - accuracy: 0.0000e+00 - val_loss: 128.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 7952/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 15.8632 - accuracy: 0.0312 - val_loss: 127.2609 - val_accuracy: 0.0000e+00\n",
      "Epoch 7953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7070 - accuracy: 0.0000e+00 - val_loss: 128.5621 - val_accuracy: 0.0588\n",
      "Epoch 7954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8138 - accuracy: 0.0156 - val_loss: 132.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 7955/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 26.3017 - accuracy: 0.0156 - val_loss: 135.1796 - val_accuracy: 0.0588\n",
      "Epoch 7956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2604 - accuracy: 0.0156 - val_loss: 136.6535 - val_accuracy: 0.0000e+00\n",
      "Epoch 7957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8178 - accuracy: 0.0000e+00 - val_loss: 139.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7958/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7253 - accuracy: 0.0000e+00 - val_loss: 137.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 7959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3708 - accuracy: 0.0312 - val_loss: 133.1631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7960/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 25.6451 - accuracy: 0.0000e+00 - val_loss: 130.0496 - val_accuracy: 0.0000e+00\n",
      "Epoch 7961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6625 - accuracy: 0.0156 - val_loss: 130.7780 - val_accuracy: 0.0000e+00\n",
      "Epoch 7962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8500 - accuracy: 0.0156 - val_loss: 133.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 7963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2334 - accuracy: 0.0312 - val_loss: 133.8849 - val_accuracy: 0.0000e+00\n",
      "Epoch 7964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6647 - accuracy: 0.0000e+00 - val_loss: 134.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 7965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5237 - accuracy: 0.0312 - val_loss: 130.7523 - val_accuracy: 0.0588\n",
      "Epoch 7966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6289 - accuracy: 0.0156 - val_loss: 117.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 7967/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0307 - accuracy: 0.0000e+00 - val_loss: 114.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 7968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6566 - accuracy: 0.0000e+00 - val_loss: 121.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 7969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6848 - accuracy: 0.0312 - val_loss: 135.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 7970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0448 - accuracy: 0.0000e+00 - val_loss: 144.9384 - val_accuracy: 0.0588\n",
      "Epoch 7971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7111 - accuracy: 0.0000e+00 - val_loss: 129.1178 - val_accuracy: 0.0588\n",
      "Epoch 7972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2599 - accuracy: 0.0000e+00 - val_loss: 121.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 7973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4025 - accuracy: 0.0000e+00 - val_loss: 116.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 7974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3881 - accuracy: 0.0000e+00 - val_loss: 116.5235 - val_accuracy: 0.0588\n",
      "Epoch 7975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2825 - accuracy: 0.0000e+00 - val_loss: 120.6908 - val_accuracy: 0.0000e+00\n",
      "Epoch 7976/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4769 - accuracy: 0.0000e+00 - val_loss: 127.1940 - val_accuracy: 0.0588\n",
      "Epoch 7977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9245 - accuracy: 0.0000e+00 - val_loss: 135.1560 - val_accuracy: 0.0588\n",
      "Epoch 7978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6436 - accuracy: 0.0156 - val_loss: 138.5932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7979/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2198 - accuracy: 0.0000e+00 - val_loss: 141.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 7980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4096 - accuracy: 0.0000e+00 - val_loss: 134.1758 - val_accuracy: 0.0588\n",
      "Epoch 7981/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0184 - accuracy: 0.0000e+00 - val_loss: 126.9815 - val_accuracy: 0.0000e+00\n",
      "Epoch 7982/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 23.1338 - accuracy: 0.0156 - val_loss: 125.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 7983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5580 - accuracy: 0.0156 - val_loss: 127.8200 - val_accuracy: 0.0588\n",
      "Epoch 7984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8595 - accuracy: 0.0000e+00 - val_loss: 136.0896 - val_accuracy: 0.0000e+00\n",
      "Epoch 7985/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.5717 - accuracy: 0.0000e+00 - val_loss: 136.5115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2117 - accuracy: 0.0000e+00 - val_loss: 134.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 7987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3797 - accuracy: 0.0000e+00 - val_loss: 128.2178 - val_accuracy: 0.0000e+00\n",
      "Epoch 7988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9875 - accuracy: 0.0156 - val_loss: 119.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 7989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6115 - accuracy: 0.0000e+00 - val_loss: 123.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 7990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5512 - accuracy: 0.0000e+00 - val_loss: 127.5932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5135 - accuracy: 0.0000e+00 - val_loss: 133.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 7992/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 38.9008 - accuracy: 0.0000e+00 - val_loss: 136.0573 - val_accuracy: 0.0000e+00\n",
      "Epoch 7993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3950 - accuracy: 0.0000e+00 - val_loss: 129.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 7994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1369 - accuracy: 0.0156 - val_loss: 125.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 7995/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 29.6700 - accuracy: 0.0000e+00 - val_loss: 124.2244 - val_accuracy: 0.0588\n",
      "Epoch 7996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1278 - accuracy: 0.0000e+00 - val_loss: 119.5724 - val_accuracy: 0.0588\n",
      "Epoch 7997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2560 - accuracy: 0.0000e+00 - val_loss: 126.2813 - val_accuracy: 0.0000e+00\n",
      "Epoch 7998/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3548 - accuracy: 0.0000e+00 - val_loss: 137.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6356 - accuracy: 0.0469 - val_loss: 138.2327 - val_accuracy: 0.0588\n",
      "Epoch 8000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0155 - accuracy: 0.0000e+00 - val_loss: 133.6268 - val_accuracy: 0.0588\n",
      "Epoch 8001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3039 - accuracy: 0.0156 - val_loss: 131.1145 - val_accuracy: 0.0588\n",
      "Epoch 8002/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 19.2528 - accuracy: 0.0156 - val_loss: 126.8932 - val_accuracy: 0.0588\n",
      "Epoch 8003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2566 - accuracy: 0.0156 - val_loss: 124.0796 - val_accuracy: 0.0588\n",
      "Epoch 8004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2649 - accuracy: 0.0000e+00 - val_loss: 121.6044 - val_accuracy: 0.0000e+00\n",
      "Epoch 8005/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9717 - accuracy: 0.0000e+00 - val_loss: 122.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 8006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4025 - accuracy: 0.0000e+00 - val_loss: 130.0540 - val_accuracy: 0.0588\n",
      "Epoch 8007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5779 - accuracy: 0.0000e+00 - val_loss: 144.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 8008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6076 - accuracy: 0.0156 - val_loss: 152.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 8009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9467 - accuracy: 0.0156 - val_loss: 148.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 8010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6331 - accuracy: 0.0156 - val_loss: 141.2101 - val_accuracy: 0.0000e+00\n",
      "Epoch 8011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4589 - accuracy: 0.0156 - val_loss: 136.4166 - val_accuracy: 0.0588\n",
      "Epoch 8012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6959 - accuracy: 0.0156 - val_loss: 132.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 8013/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 16.5308 - accuracy: 0.0000e+00 - val_loss: 132.1164 - val_accuracy: 0.0000e+00\n",
      "Epoch 8014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2675 - accuracy: 0.0000e+00 - val_loss: 126.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 8015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0218 - accuracy: 0.0312 - val_loss: 115.3909 - val_accuracy: 0.0000e+00\n",
      "Epoch 8016/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 15.7750 - accuracy: 0.0000e+00 - val_loss: 112.3229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9049 - accuracy: 0.0156 - val_loss: 115.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 8018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6306 - accuracy: 0.0156 - val_loss: 122.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 8019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2676 - accuracy: 0.0312 - val_loss: 133.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 8020/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.9915 - accuracy: 0.0000e+00 - val_loss: 142.7721 - val_accuracy: 0.0000e+00\n",
      "Epoch 8021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8366 - accuracy: 0.0000e+00 - val_loss: 145.3417 - val_accuracy: 0.0000e+00\n",
      "Epoch 8022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4814 - accuracy: 0.0156 - val_loss: 141.3204 - val_accuracy: 0.0588\n",
      "Epoch 8023/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 17.0274 - accuracy: 0.0156 - val_loss: 134.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6201 - accuracy: 0.0156 - val_loss: 129.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8025/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 30.2305 - accuracy: 0.0000e+00 - val_loss: 129.7186 - val_accuracy: 0.0588\n",
      "Epoch 8026/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 15.0709 - accuracy: 0.0312 - val_loss: 134.9476 - val_accuracy: 0.0588\n",
      "Epoch 8027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6820 - accuracy: 0.0000e+00 - val_loss: 141.2839 - val_accuracy: 0.0588\n",
      "Epoch 8028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6089 - accuracy: 0.0312 - val_loss: 144.3545 - val_accuracy: 0.0588\n",
      "Epoch 8029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7776 - accuracy: 0.0156 - val_loss: 143.7567 - val_accuracy: 0.0000e+00\n",
      "Epoch 8030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1970 - accuracy: 0.0000e+00 - val_loss: 132.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 8031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8316 - accuracy: 0.0156 - val_loss: 129.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0570 - accuracy: 0.0156 - val_loss: 135.9605 - val_accuracy: 0.0000e+00\n",
      "Epoch 8033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5699 - accuracy: 0.0000e+00 - val_loss: 142.5357 - val_accuracy: 0.0000e+00\n",
      "Epoch 8034/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.5493 - accuracy: 0.0156 - val_loss: 148.0538 - val_accuracy: 0.0000e+00\n",
      "Epoch 8035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8692 - accuracy: 0.0156 - val_loss: 147.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 8036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5413 - accuracy: 0.0156 - val_loss: 142.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 8037/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.0215 - accuracy: 0.0000e+00 - val_loss: 134.6181 - val_accuracy: 0.0588\n",
      "Epoch 8038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1872 - accuracy: 0.0000e+00 - val_loss: 128.8249 - val_accuracy: 0.0588\n",
      "Epoch 8039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9664 - accuracy: 0.0312 - val_loss: 127.8803 - val_accuracy: 0.0588\n",
      "Epoch 8040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3359 - accuracy: 0.0000e+00 - val_loss: 129.0348 - val_accuracy: 0.0588\n",
      "Epoch 8041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6170 - accuracy: 0.0156 - val_loss: 132.1544 - val_accuracy: 0.0588\n",
      "Epoch 8042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2825 - accuracy: 0.0000e+00 - val_loss: 138.9065 - val_accuracy: 0.1176\n",
      "Epoch 8043/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 22.4236 - accuracy: 0.0156 - val_loss: 139.0911 - val_accuracy: 0.0588\n",
      "Epoch 8044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5712 - accuracy: 0.0156 - val_loss: 135.9112 - val_accuracy: 0.0588\n",
      "Epoch 8045/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1260 - accuracy: 0.0156 - val_loss: 135.1454 - val_accuracy: 0.0588\n",
      "Epoch 8046/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.8646 - accuracy: 0.0000e+00 - val_loss: 135.4805 - val_accuracy: 0.0588\n",
      "Epoch 8047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1198 - accuracy: 0.0000e+00 - val_loss: 127.8204 - val_accuracy: 0.0588\n",
      "Epoch 8048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3872 - accuracy: 0.0000e+00 - val_loss: 119.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 8049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9054 - accuracy: 0.0000e+00 - val_loss: 112.7897 - val_accuracy: 0.0588\n",
      "Epoch 8050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9534 - accuracy: 0.0156 - val_loss: 114.6679 - val_accuracy: 0.0000e+00\n",
      "Epoch 8051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4050 - accuracy: 0.0156 - val_loss: 118.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 8052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1200 - accuracy: 0.0312 - val_loss: 128.0298 - val_accuracy: 0.0000e+00\n",
      "Epoch 8053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4835 - accuracy: 0.0156 - val_loss: 140.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 8054/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 20.4623 - accuracy: 0.0000e+00 - val_loss: 147.2569 - val_accuracy: 0.0588\n",
      "Epoch 8055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2261 - accuracy: 0.0000e+00 - val_loss: 141.5887 - val_accuracy: 0.0588\n",
      "Epoch 8056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3378 - accuracy: 0.0000e+00 - val_loss: 133.4997 - val_accuracy: 0.0588\n",
      "Epoch 8057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5349 - accuracy: 0.0156 - val_loss: 128.1055 - val_accuracy: 0.0588\n",
      "Epoch 8058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5146 - accuracy: 0.0156 - val_loss: 128.8963 - val_accuracy: 0.1176\n",
      "Epoch 8059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8432 - accuracy: 0.0156 - val_loss: 132.4471 - val_accuracy: 0.0588\n",
      "Epoch 8060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1832 - accuracy: 0.0000e+00 - val_loss: 138.2439 - val_accuracy: 0.0588\n",
      "Epoch 8061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8554 - accuracy: 0.0156 - val_loss: 137.7037 - val_accuracy: 0.0588\n",
      "Epoch 8062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3400 - accuracy: 0.0156 - val_loss: 125.8591 - val_accuracy: 0.0588\n",
      "Epoch 8063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8819 - accuracy: 0.0000e+00 - val_loss: 115.4102 - val_accuracy: 0.0000e+00\n",
      "Epoch 8064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2821 - accuracy: 0.0000e+00 - val_loss: 110.3170 - val_accuracy: 0.0000e+00\n",
      "Epoch 8065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0662 - accuracy: 0.0156 - val_loss: 115.5511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8066/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 24.4718 - accuracy: 0.0156 - val_loss: 128.3402 - val_accuracy: 0.0588\n",
      "Epoch 8067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8592 - accuracy: 0.0000e+00 - val_loss: 133.4659 - val_accuracy: 0.0588\n",
      "Epoch 8068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8543 - accuracy: 0.0156 - val_loss: 134.6457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9464 - accuracy: 0.0156 - val_loss: 133.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 8070/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.6257 - accuracy: 0.0000e+00 - val_loss: 132.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1168 - accuracy: 0.0000e+00 - val_loss: 131.9641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1902 - accuracy: 0.0156 - val_loss: 125.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 8073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4148 - accuracy: 0.0156 - val_loss: 117.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1938 - accuracy: 0.0469 - val_loss: 113.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 8075/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 19.9247 - accuracy: 0.0469 - val_loss: 113.6546 - val_accuracy: 0.0000e+00\n",
      "Epoch 8076/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 35.8761 - accuracy: 0.0000e+00 - val_loss: 112.0616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8077/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6712 - accuracy: 0.0000e+00 - val_loss: 113.3612 - val_accuracy: 0.0000e+00\n",
      "Epoch 8078/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2660 - accuracy: 0.0156 - val_loss: 121.8580 - val_accuracy: 0.0000e+00\n",
      "Epoch 8079/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.1176 - accuracy: 0.0312 - val_loss: 134.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 8080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9921 - accuracy: 0.0000e+00 - val_loss: 135.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 8081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2061 - accuracy: 0.0000e+00 - val_loss: 138.7575 - val_accuracy: 0.0000e+00\n",
      "Epoch 8082/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4503 - accuracy: 0.0000e+00 - val_loss: 137.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3864 - accuracy: 0.0156 - val_loss: 143.0452 - val_accuracy: 0.0000e+00\n",
      "Epoch 8084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6019 - accuracy: 0.0000e+00 - val_loss: 153.5452 - val_accuracy: 0.0000e+00\n",
      "Epoch 8085/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.9528 - accuracy: 0.0156 - val_loss: 156.6583 - val_accuracy: 0.0000e+00\n",
      "Epoch 8086/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1287 - accuracy: 0.0312 - val_loss: 156.9809 - val_accuracy: 0.0000e+00\n",
      "Epoch 8087/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 17.9052 - accuracy: 0.0000e+00 - val_loss: 149.8464 - val_accuracy: 0.0588\n",
      "Epoch 8088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1810 - accuracy: 0.0000e+00 - val_loss: 137.5305 - val_accuracy: 0.0000e+00\n",
      "Epoch 8089/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 33.0358 - accuracy: 0.0156 - val_loss: 130.6081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2257 - accuracy: 0.0000e+00 - val_loss: 120.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9958 - accuracy: 0.0156 - val_loss: 117.5621 - val_accuracy: 0.0000e+00\n",
      "Epoch 8092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7739 - accuracy: 0.0000e+00 - val_loss: 119.6204 - val_accuracy: 0.0588\n",
      "Epoch 8093/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 32.4608 - accuracy: 0.0000e+00 - val_loss: 125.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 8094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8995 - accuracy: 0.0000e+00 - val_loss: 136.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9022 - accuracy: 0.0156 - val_loss: 143.3573 - val_accuracy: 0.0000e+00\n",
      "Epoch 8096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5842 - accuracy: 0.0312 - val_loss: 140.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 8097/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9179 - accuracy: 0.0000e+00 - val_loss: 128.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 8098/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 29.6694 - accuracy: 0.0000e+00 - val_loss: 118.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 8099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4445 - accuracy: 0.0000e+00 - val_loss: 116.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 8100/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0514 - accuracy: 0.0156 - val_loss: 133.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 8101/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.6922 - accuracy: 0.0156 - val_loss: 141.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 8102/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 37.7757 - accuracy: 0.0000e+00 - val_loss: 132.3711 - val_accuracy: 0.0000e+00\n",
      "Epoch 8103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3835 - accuracy: 0.0156 - val_loss: 125.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 8104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0129 - accuracy: 0.0000e+00 - val_loss: 128.3712 - val_accuracy: 0.0000e+00\n",
      "Epoch 8105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4821 - accuracy: 0.0156 - val_loss: 130.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 8106/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9274 - accuracy: 0.0156 - val_loss: 129.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 8107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7041 - accuracy: 0.0000e+00 - val_loss: 130.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1612 - accuracy: 0.0000e+00 - val_loss: 131.7025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8024 - accuracy: 0.0156 - val_loss: 129.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 8110/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 26.6001 - accuracy: 0.0000e+00 - val_loss: 129.1040 - val_accuracy: 0.0000e+00\n",
      "Epoch 8111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0075 - accuracy: 0.0156 - val_loss: 127.2849 - val_accuracy: 0.0000e+00\n",
      "Epoch 8112/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.6074 - accuracy: 0.0156 - val_loss: 126.9700 - val_accuracy: 0.0000e+00\n",
      "Epoch 8113/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0065 - accuracy: 0.0000e+00 - val_loss: 128.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 8114/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4654 - accuracy: 0.0000e+00 - val_loss: 130.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 8115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8244 - accuracy: 0.0000e+00 - val_loss: 128.8226 - val_accuracy: 0.0000e+00\n",
      "Epoch 8116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6650 - accuracy: 0.0000e+00 - val_loss: 125.0702 - val_accuracy: 0.0588\n",
      "Epoch 8117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8587 - accuracy: 0.0156 - val_loss: 128.0864 - val_accuracy: 0.0588\n",
      "Epoch 8118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7404 - accuracy: 0.0000e+00 - val_loss: 133.2192 - val_accuracy: 0.0588\n",
      "Epoch 8119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4299 - accuracy: 0.0156 - val_loss: 139.6636 - val_accuracy: 0.0588\n",
      "Epoch 8120/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9166 - accuracy: 0.0000e+00 - val_loss: 146.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 8121/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 34.1030 - accuracy: 0.0469 - val_loss: 145.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 8122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5043 - accuracy: 0.0000e+00 - val_loss: 148.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 8123/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 28.3621 - accuracy: 0.0156 - val_loss: 144.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 8124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0171 - accuracy: 0.0000e+00 - val_loss: 135.5973 - val_accuracy: 0.0000e+00\n",
      "Epoch 8125/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9796 - accuracy: 0.0000e+00 - val_loss: 122.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 8126/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8308 - accuracy: 0.0156 - val_loss: 112.6558 - val_accuracy: 0.0000e+00\n",
      "Epoch 8127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2183 - accuracy: 0.0312 - val_loss: 115.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 8128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2346 - accuracy: 0.0312 - val_loss: 121.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 8129/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2567 - accuracy: 0.0000e+00 - val_loss: 126.8963 - val_accuracy: 0.0000e+00\n",
      "Epoch 8130/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 16.5914 - accuracy: 0.0156 - val_loss: 127.0653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3391 - accuracy: 0.0000e+00 - val_loss: 125.3202 - val_accuracy: 0.0000e+00\n",
      "Epoch 8132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3222 - accuracy: 0.0312 - val_loss: 122.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1376 - accuracy: 0.0000e+00 - val_loss: 114.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8134/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 32.5811 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 31.3810 - accuracy: 0.0000e+00 - val_loss: 113.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 8135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0440 - accuracy: 0.0000e+00 - val_loss: 122.4095 - val_accuracy: 0.0000e+00\n",
      "Epoch 8136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8822 - accuracy: 0.0156 - val_loss: 128.6882 - val_accuracy: 0.0000e+00\n",
      "Epoch 8137/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1995 - accuracy: 0.0000e+00 - val_loss: 130.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8138/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 29.3170 - accuracy: 0.0000e+00 - val_loss: 138.9952 - val_accuracy: 0.0000e+00\n",
      "Epoch 8139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1245 - accuracy: 0.0312 - val_loss: 145.2332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8140/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.2663 - accuracy: 0.0312 - val_loss: 148.5895 - val_accuracy: 0.0000e+00\n",
      "Epoch 8141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2523 - accuracy: 0.0000e+00 - val_loss: 146.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 8142/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1854 - accuracy: 0.0156 - val_loss: 143.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 8143/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 20.9614 - accuracy: 0.0000e+00 - val_loss: 139.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 8144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0579 - accuracy: 0.0469 - val_loss: 134.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 8145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5503 - accuracy: 0.0000e+00 - val_loss: 128.2942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8146/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6682 - accuracy: 0.0156 - val_loss: 127.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8147/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2501 - accuracy: 0.0000e+00 - val_loss: 131.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 8148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0621 - accuracy: 0.0156 - val_loss: 141.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3135 - accuracy: 0.0000e+00 - val_loss: 146.5615 - val_accuracy: 0.0000e+00\n",
      "Epoch 8150/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 21.2350 - accuracy: 0.0312 - val_loss: 147.3136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4585 - accuracy: 0.0000e+00 - val_loss: 142.5892 - val_accuracy: 0.0000e+00\n",
      "Epoch 8152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4586 - accuracy: 0.0312 - val_loss: 138.0342 - val_accuracy: 0.0000e+00\n",
      "Epoch 8153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2776 - accuracy: 0.0156 - val_loss: 133.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 8154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7714 - accuracy: 0.0000e+00 - val_loss: 129.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 8155/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 21.3771 - accuracy: 0.0156 - val_loss: 127.3148 - val_accuracy: 0.0000e+00\n",
      "Epoch 8156/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4775 - accuracy: 0.0312 - val_loss: 122.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 8157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1460 - accuracy: 0.0000e+00 - val_loss: 116.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 8158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1934 - accuracy: 0.0000e+00 - val_loss: 116.9937 - val_accuracy: 0.0000e+00\n",
      "Epoch 8159/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 26.7247 - accuracy: 0.0000e+00 - val_loss: 120.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 8160/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9625 - accuracy: 0.0469 - val_loss: 120.2041 - val_accuracy: 0.0000e+00\n",
      "Epoch 8161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7981 - accuracy: 0.0000e+00 - val_loss: 119.4923 - val_accuracy: 0.0000e+00\n",
      "Epoch 8162/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.4193 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 22.4592 - accuracy: 0.0156 - val_loss: 118.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1966 - accuracy: 0.0000e+00 - val_loss: 118.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 8164/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.8243 - accuracy: 0.0000e+00 - val_loss: 123.7038 - val_accuracy: 0.0000e+00\n",
      "Epoch 8165/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 29.4367 - accuracy: 0.0000e+00 - val_loss: 131.5560 - val_accuracy: 0.0000e+00\n",
      "Epoch 8166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2220 - accuracy: 0.0000e+00 - val_loss: 129.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 8167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3466 - accuracy: 0.0156 - val_loss: 131.4439 - val_accuracy: 0.0000e+00\n",
      "Epoch 8168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5465 - accuracy: 0.0156 - val_loss: 136.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 8169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5682 - accuracy: 0.0000e+00 - val_loss: 145.3962 - val_accuracy: 0.0000e+00\n",
      "Epoch 8170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0393 - accuracy: 0.0156 - val_loss: 151.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 8171/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.3103 - accuracy: 0.0156 - val_loss: 155.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 8172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7719 - accuracy: 0.0156 - val_loss: 145.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7389 - accuracy: 0.0000e+00 - val_loss: 127.3682 - val_accuracy: 0.0000e+00\n",
      "Epoch 8174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3068 - accuracy: 0.0156 - val_loss: 111.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5490 - accuracy: 0.0156 - val_loss: 119.3935 - val_accuracy: 0.0588\n",
      "Epoch 8176/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 23.0669 - accuracy: 0.0000e+00 - val_loss: 137.5108 - val_accuracy: 0.0588\n",
      "Epoch 8177/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 32.1166 - accuracy: 0.0156 - val_loss: 137.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 8178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1459 - accuracy: 0.0000e+00 - val_loss: 134.3807 - val_accuracy: 0.0000e+00\n",
      "Epoch 8179/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 24.3933 - accuracy: 0.0000e+00 - val_loss: 131.7127 - val_accuracy: 0.0000e+00\n",
      "Epoch 8180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7578 - accuracy: 0.0312 - val_loss: 129.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 8181/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.9035 - accuracy: 0.0000e+00 - val_loss: 126.1540 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9610 - accuracy: 0.0469 - val_loss: 120.2696 - val_accuracy: 0.0588\n",
      "Epoch 8183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0305 - accuracy: 0.0000e+00 - val_loss: 120.1808 - val_accuracy: 0.0588\n",
      "Epoch 8184/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 34.6301 - accuracy: 0.0156 - val_loss: 126.8793 - val_accuracy: 0.0588\n",
      "Epoch 8185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5348 - accuracy: 0.0000e+00 - val_loss: 140.4358 - val_accuracy: 0.0588\n",
      "Epoch 8186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6207 - accuracy: 0.0000e+00 - val_loss: 141.4872 - val_accuracy: 0.0588\n",
      "Epoch 8187/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 19.6996 - accuracy: 0.0156 - val_loss: 133.2211 - val_accuracy: 0.0588\n",
      "Epoch 8188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4164 - accuracy: 0.0000e+00 - val_loss: 132.6646 - val_accuracy: 0.0588\n",
      "Epoch 8189/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 26.6073 - accuracy: 0.0156 - val_loss: 132.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 8190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3125 - accuracy: 0.0156 - val_loss: 139.2701 - val_accuracy: 0.0588\n",
      "Epoch 8191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7049 - accuracy: 0.0156 - val_loss: 144.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 8192/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3525 - accuracy: 0.0156 - val_loss: 145.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 8193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4370 - accuracy: 0.0156 - val_loss: 144.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 8194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1110 - accuracy: 0.0000e+00 - val_loss: 140.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 8195/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.5604 - accuracy: 0.0156 - val_loss: 131.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 8196/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.8901 - accuracy: 0.0000e+00 - val_loss: 125.6533 - val_accuracy: 0.0000e+00\n",
      "Epoch 8197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9816 - accuracy: 0.0156 - val_loss: 123.6492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5055 - accuracy: 0.0156 - val_loss: 124.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8987 - accuracy: 0.0000e+00 - val_loss: 125.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 8200/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 23.8512 - accuracy: 0.0156 - val_loss: 131.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 8201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1372 - accuracy: 0.0000e+00 - val_loss: 127.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7260 - accuracy: 0.0000e+00 - val_loss: 122.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 8203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8674 - accuracy: 0.0156 - val_loss: 121.8596 - val_accuracy: 0.0000e+00\n",
      "Epoch 8204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4810 - accuracy: 0.0156 - val_loss: 122.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 8205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3005 - accuracy: 0.0000e+00 - val_loss: 120.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 8206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0792 - accuracy: 0.0000e+00 - val_loss: 119.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 8207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3254 - accuracy: 0.0156 - val_loss: 116.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5172 - accuracy: 0.0156 - val_loss: 122.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 8209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1240 - accuracy: 0.0000e+00 - val_loss: 128.5661 - val_accuracy: 0.0588\n",
      "Epoch 8210/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 25.0301 - accuracy: 0.0156 - val_loss: 131.4492 - val_accuracy: 0.1176\n",
      "Epoch 8211/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5249 - accuracy: 0.0000e+00 - val_loss: 134.3666 - val_accuracy: 0.1176\n",
      "Epoch 8212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1417 - accuracy: 0.0312 - val_loss: 135.5399 - val_accuracy: 0.0000e+00\n",
      "Epoch 8213/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.6156 - accuracy: 0.0156 - val_loss: 135.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 8214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8050 - accuracy: 0.0312 - val_loss: 137.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 8215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4925 - accuracy: 0.0312 - val_loss: 131.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 8216/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2657 - accuracy: 0.0000e+00 - val_loss: 125.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 8217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7592 - accuracy: 0.0156 - val_loss: 123.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7799 - accuracy: 0.0000e+00 - val_loss: 127.5458 - val_accuracy: 0.0588\n",
      "Epoch 8219/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8780 - accuracy: 0.0000e+00 - val_loss: 132.2310 - val_accuracy: 0.0588\n",
      "Epoch 8220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6326 - accuracy: 0.0000e+00 - val_loss: 131.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8221/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 29.6969 - accuracy: 0.0000e+00 - val_loss: 133.8585 - val_accuracy: 0.0000e+00\n",
      "Epoch 8222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4698 - accuracy: 0.0156 - val_loss: 135.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 8223/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 33.6620 - accuracy: 0.0000e+00 - val_loss: 128.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8224/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8417 - accuracy: 0.0156 - val_loss: 125.0305 - val_accuracy: 0.0588\n",
      "Epoch 8225/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5433 - accuracy: 0.0156 - val_loss: 129.7547 - val_accuracy: 0.0588\n",
      "Epoch 8226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4845 - accuracy: 0.0156 - val_loss: 133.5921 - val_accuracy: 0.0588\n",
      "Epoch 8227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7830 - accuracy: 0.0000e+00 - val_loss: 134.0925 - val_accuracy: 0.0588\n",
      "Epoch 8228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3389 - accuracy: 0.0156 - val_loss: 137.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 8229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7903 - accuracy: 0.0312 - val_loss: 135.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 8230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1952 - accuracy: 0.0000e+00 - val_loss: 138.4277 - val_accuracy: 0.0588\n",
      "Epoch 8231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9602 - accuracy: 0.0156 - val_loss: 144.6999 - val_accuracy: 0.0588\n",
      "Epoch 8232/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 18.0993 - accuracy: 0.0000e+00 - val_loss: 147.4980 - val_accuracy: 0.0588\n",
      "Epoch 8233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3794 - accuracy: 0.0312 - val_loss: 136.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 8234/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8554 - accuracy: 0.0156 - val_loss: 128.8441 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7214 - accuracy: 0.0000e+00 - val_loss: 124.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 8236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5659 - accuracy: 0.0000e+00 - val_loss: 127.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 8237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8588 - accuracy: 0.0000e+00 - val_loss: 125.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5131 - accuracy: 0.0156 - val_loss: 127.8751 - val_accuracy: 0.0588\n",
      "Epoch 8239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0026 - accuracy: 0.0156 - val_loss: 137.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 8240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7607 - accuracy: 0.0312 - val_loss: 137.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 8241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4629 - accuracy: 0.0156 - val_loss: 131.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 8242/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 24.4651 - accuracy: 0.0000e+00 - val_loss: 123.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 8243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5321 - accuracy: 0.0000e+00 - val_loss: 119.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 8244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9078 - accuracy: 0.0156 - val_loss: 117.7677 - val_accuracy: 0.0000e+00\n",
      "Epoch 8245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5950 - accuracy: 0.0000e+00 - val_loss: 119.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 8246/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9959 - accuracy: 0.0156 - val_loss: 125.5255 - val_accuracy: 0.0000e+00\n",
      "Epoch 8247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4714 - accuracy: 0.0156 - val_loss: 128.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 8248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9404 - accuracy: 0.0000e+00 - val_loss: 127.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 8249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5784 - accuracy: 0.0000e+00 - val_loss: 132.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 8250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2602 - accuracy: 0.0156 - val_loss: 133.8422 - val_accuracy: 0.0588\n",
      "Epoch 8251/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6554 - accuracy: 0.0000e+00 - val_loss: 137.1711 - val_accuracy: 0.0588\n",
      "Epoch 8252/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.5756 - accuracy: 0.0156 - val_loss: 143.6627 - val_accuracy: 0.0588\n",
      "Epoch 8253/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2509 - accuracy: 0.0000e+00 - val_loss: 148.6903 - val_accuracy: 0.0000e+00\n",
      "Epoch 8254/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0194 - accuracy: 0.0312 - val_loss: 142.7686 - val_accuracy: 0.0000e+00\n",
      "Epoch 8255/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 22.3884 - accuracy: 0.0156 - val_loss: 135.6438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0118 - accuracy: 0.0000e+00 - val_loss: 130.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2180 - accuracy: 0.0156 - val_loss: 124.9416 - val_accuracy: 0.0000e+00\n",
      "Epoch 8258/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 23.1661 - accuracy: 0.0156 - val_loss: 122.9641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1803 - accuracy: 0.0000e+00 - val_loss: 124.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 8260/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0901 - accuracy: 0.0312 - val_loss: 122.5712 - val_accuracy: 0.0588\n",
      "Epoch 8261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9005 - accuracy: 0.0000e+00 - val_loss: 120.9287 - val_accuracy: 0.0588\n",
      "Epoch 8262/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.5849 - accuracy: 0.0156 - val_loss: 123.2206 - val_accuracy: 0.0588\n",
      "Epoch 8263/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 30.9678 - accuracy: 0.0000e+00 - val_loss: 125.3510 - val_accuracy: 0.0000e+00\n",
      "Epoch 8264/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 43.5665 - accuracy: 0.0000e+00 - val_loss: 129.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 8265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8203 - accuracy: 0.0156 - val_loss: 138.1008 - val_accuracy: 0.0000e+00\n",
      "Epoch 8266/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 22.7728 - accuracy: 0.0000e+00 - val_loss: 131.5202 - val_accuracy: 0.0000e+00\n",
      "Epoch 8267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5017 - accuracy: 0.0000e+00 - val_loss: 124.7472 - val_accuracy: 0.0000e+00\n",
      "Epoch 8268/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4310 - accuracy: 0.0000e+00 - val_loss: 122.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1251 - accuracy: 0.0156 - val_loss: 123.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4135 - accuracy: 0.0469 - val_loss: 129.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 8271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6181 - accuracy: 0.0156 - val_loss: 137.2623 - val_accuracy: 0.0000e+00\n",
      "Epoch 8272/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 24.4044 - accuracy: 0.0156 - val_loss: 147.3434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8145 - accuracy: 0.0000e+00 - val_loss: 148.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 8274/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1011 - accuracy: 0.0000e+00 - val_loss: 145.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 8275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3916 - accuracy: 0.0156 - val_loss: 138.4772 - val_accuracy: 0.0000e+00\n",
      "Epoch 8276/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 21.2132 - accuracy: 0.0156 - val_loss: 135.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 8277/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3044 - accuracy: 0.0000e+00 - val_loss: 136.9909 - val_accuracy: 0.0000e+00\n",
      "Epoch 8278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6731 - accuracy: 0.0156 - val_loss: 138.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9345 - accuracy: 0.0000e+00 - val_loss: 134.0334 - val_accuracy: 0.0588\n",
      "Epoch 8280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6743 - accuracy: 0.0156 - val_loss: 127.0599 - val_accuracy: 0.1176\n",
      "Epoch 8281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1193 - accuracy: 0.0156 - val_loss: 120.0609 - val_accuracy: 0.1176\n",
      "Epoch 8282/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6396 - accuracy: 0.0000e+00 - val_loss: 113.4569 - val_accuracy: 0.0588\n",
      "Epoch 8283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4193 - accuracy: 0.0312 - val_loss: 112.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 8284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4844 - accuracy: 0.0000e+00 - val_loss: 126.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7803 - accuracy: 0.0156 - val_loss: 132.4483 - val_accuracy: 0.0588\n",
      "Epoch 8286/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 31.8278 - accuracy: 0.0000e+00 - val_loss: 133.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 8287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8661 - accuracy: 0.0312 - val_loss: 133.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 8288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7688 - accuracy: 0.0000e+00 - val_loss: 134.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 8289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6783 - accuracy: 0.0000e+00 - val_loss: 135.9989 - val_accuracy: 0.0000e+00\n",
      "Epoch 8290/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6971 - accuracy: 0.0156 - val_loss: 135.6490 - val_accuracy: 0.0000e+00\n",
      "Epoch 8291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2434 - accuracy: 0.0000e+00 - val_loss: 133.8580 - val_accuracy: 0.0000e+00\n",
      "Epoch 8292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7556 - accuracy: 0.0156 - val_loss: 129.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 8293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2855 - accuracy: 0.0156 - val_loss: 125.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 8294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7445 - accuracy: 0.0156 - val_loss: 123.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6982 - accuracy: 0.0000e+00 - val_loss: 124.8835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4276 - accuracy: 0.0156 - val_loss: 131.2554 - val_accuracy: 0.0588\n",
      "Epoch 8297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6185 - accuracy: 0.0156 - val_loss: 137.0592 - val_accuracy: 0.0588\n",
      "Epoch 8298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0278 - accuracy: 0.0312 - val_loss: 137.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 8299/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.9591 - accuracy: 0.0000e+00 - val_loss: 134.8768 - val_accuracy: 0.0000e+00\n",
      "Epoch 8300/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 30.1112 - accuracy: 0.0156 - val_loss: 132.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 8301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5739 - accuracy: 0.0156 - val_loss: 125.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 8302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8068 - accuracy: 0.0156 - val_loss: 123.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 8303/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.7167 - accuracy: 0.0000e+00 - val_loss: 129.6683 - val_accuracy: 0.0000e+00\n",
      "Epoch 8304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7949 - accuracy: 0.0000e+00 - val_loss: 134.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8305/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 31.6003 - accuracy: 0.0156 - val_loss: 134.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 8306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9751 - accuracy: 0.0000e+00 - val_loss: 141.4308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6467 - accuracy: 0.0000e+00 - val_loss: 144.2601 - val_accuracy: 0.0588\n",
      "Epoch 8308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6690 - accuracy: 0.0000e+00 - val_loss: 146.9203 - val_accuracy: 0.0588\n",
      "Epoch 8309/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6967 - accuracy: 0.0156 - val_loss: 144.6562 - val_accuracy: 0.0588\n",
      "Epoch 8310/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9691 - accuracy: 0.0000e+00 - val_loss: 140.1926 - val_accuracy: 0.0588\n",
      "Epoch 8311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5001 - accuracy: 0.0000e+00 - val_loss: 133.9948 - val_accuracy: 0.0588\n",
      "Epoch 8312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2872 - accuracy: 0.0156 - val_loss: 134.9868 - val_accuracy: 0.0588\n",
      "Epoch 8313/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0970 - accuracy: 0.0312 - val_loss: 140.9217 - val_accuracy: 0.0588\n",
      "Epoch 8314/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 21.9085 - accuracy: 0.0000e+00 - val_loss: 148.0471 - val_accuracy: 0.0588\n",
      "Epoch 8315/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 25.3732 - accuracy: 0.0000e+00 - val_loss: 151.0943 - val_accuracy: 0.0588\n",
      "Epoch 8316/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6518 - accuracy: 0.0156 - val_loss: 152.6766 - val_accuracy: 0.0588\n",
      "Epoch 8317/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.2358 - accuracy: 0.0156 - val_loss: 147.1584 - val_accuracy: 0.0588\n",
      "Epoch 8318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0082 - accuracy: 0.0000e+00 - val_loss: 142.3229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0225 - accuracy: 0.0156 - val_loss: 131.7352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4200 - accuracy: 0.0156 - val_loss: 131.3104 - val_accuracy: 0.0000e+00\n",
      "Epoch 8321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7067 - accuracy: 0.0000e+00 - val_loss: 133.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 8322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7013 - accuracy: 0.0000e+00 - val_loss: 136.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5182 - accuracy: 0.0000e+00 - val_loss: 135.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 8324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5022 - accuracy: 0.0000e+00 - val_loss: 130.3238 - val_accuracy: 0.0000e+00\n",
      "Epoch 8325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9556 - accuracy: 0.0000e+00 - val_loss: 125.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1288 - accuracy: 0.0312 - val_loss: 123.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 8327/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 30.0061 - accuracy: 0.0156 - val_loss: 125.1369 - val_accuracy: 0.0000e+00\n",
      "Epoch 8328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4079 - accuracy: 0.0000e+00 - val_loss: 127.2494 - val_accuracy: 0.0588\n",
      "Epoch 8329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1768 - accuracy: 0.0000e+00 - val_loss: 132.4237 - val_accuracy: 0.0000e+00\n",
      "Epoch 8330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4580 - accuracy: 0.0000e+00 - val_loss: 132.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 8331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0953 - accuracy: 0.0156 - val_loss: 129.6478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1382 - accuracy: 0.0312 - val_loss: 118.2100 - val_accuracy: 0.0000e+00\n",
      "Epoch 8333/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6969 - accuracy: 0.0156 - val_loss: 116.3074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6876 - accuracy: 0.0156 - val_loss: 115.3918 - val_accuracy: 0.0588\n",
      "Epoch 8335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7305 - accuracy: 0.0312 - val_loss: 119.3998 - val_accuracy: 0.0588\n",
      "Epoch 8336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1400 - accuracy: 0.0000e+00 - val_loss: 120.7653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5378 - accuracy: 0.0156 - val_loss: 125.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 8338/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 25.5045 - accuracy: 0.0000e+00 - val_loss: 126.8967 - val_accuracy: 0.0000e+00\n",
      "Epoch 8339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.5016 - accuracy: 0.0156 - val_loss: 134.4140 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8340/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 29.2488 - accuracy: 0.0156 - val_loss: 134.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 8341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5142 - accuracy: 0.0000e+00 - val_loss: 134.5444 - val_accuracy: 0.0588\n",
      "Epoch 8342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9201 - accuracy: 0.0156 - val_loss: 136.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9346 - accuracy: 0.0000e+00 - val_loss: 136.6522 - val_accuracy: 0.0588\n",
      "Epoch 8344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1007 - accuracy: 0.0156 - val_loss: 133.5279 - val_accuracy: 0.1176\n",
      "Epoch 8345/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 25.3550 - accuracy: 0.0000e+00 - val_loss: 130.0521 - val_accuracy: 0.1176\n",
      "Epoch 8346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2870 - accuracy: 0.0312 - val_loss: 125.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 8347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0669 - accuracy: 0.0156 - val_loss: 128.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5126 - accuracy: 0.0156 - val_loss: 127.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 8349/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7101 - accuracy: 0.0000e+00 - val_loss: 128.3931 - val_accuracy: 0.0000e+00\n",
      "Epoch 8350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8682 - accuracy: 0.0156 - val_loss: 135.0911 - val_accuracy: 0.0000e+00\n",
      "Epoch 8351/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 29.7596 - accuracy: 0.031 - 0s 62us/step - loss: 23.6664 - accuracy: 0.0156 - val_loss: 141.8448 - val_accuracy: 0.0000e+00\n",
      "Epoch 8352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5298 - accuracy: 0.0156 - val_loss: 138.8520 - val_accuracy: 0.0588\n",
      "Epoch 8353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4754 - accuracy: 0.0000e+00 - val_loss: 129.4762 - val_accuracy: 0.0588\n",
      "Epoch 8354/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5853 - accuracy: 0.0156 - val_loss: 122.1749 - val_accuracy: 0.0588\n",
      "Epoch 8355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9036 - accuracy: 0.0312 - val_loss: 123.4582 - val_accuracy: 0.0588\n",
      "Epoch 8356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6016 - accuracy: 0.0156 - val_loss: 135.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 8357/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.9336 - accuracy: 0.0312 - val_loss: 132.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 8358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9600 - accuracy: 0.0156 - val_loss: 122.2609 - val_accuracy: 0.0588\n",
      "Epoch 8359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4377 - accuracy: 0.0156 - val_loss: 113.9007 - val_accuracy: 0.0588\n",
      "Epoch 8360/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7265 - accuracy: 0.0156 - val_loss: 105.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8361/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 26.8772 - accuracy: 0.0000e+00 - val_loss: 104.0629 - val_accuracy: 0.0588\n",
      "Epoch 8362/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1373 - accuracy: 0.0156 - val_loss: 104.0481 - val_accuracy: 0.0588\n",
      "Epoch 8363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7790 - accuracy: 0.0312 - val_loss: 100.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 8364/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 24.1145 - accuracy: 0.0156 - val_loss: 99.9373 - val_accuracy: 0.0000e+00\n",
      "Epoch 8365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5976 - accuracy: 0.0156 - val_loss: 103.1873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1254 - accuracy: 0.0000e+00 - val_loss: 109.7180 - val_accuracy: 0.0000e+00\n",
      "Epoch 8367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7353 - accuracy: 0.0312 - val_loss: 120.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 8368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0386 - accuracy: 0.0000e+00 - val_loss: 129.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 8369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9684 - accuracy: 0.0000e+00 - val_loss: 134.6049 - val_accuracy: 0.0000e+00\n",
      "Epoch 8370/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 32.7949 - accuracy: 0.0000e+00 - val_loss: 135.1669 - val_accuracy: 0.0000e+00\n",
      "Epoch 8371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4037 - accuracy: 0.0000e+00 - val_loss: 129.0761 - val_accuracy: 0.0588\n",
      "Epoch 8372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7210 - accuracy: 0.0156 - val_loss: 114.5990 - val_accuracy: 0.0588\n",
      "Epoch 8373/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 30.0909 - accuracy: 0.0156 - val_loss: 103.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 8374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3763 - accuracy: 0.0312 - val_loss: 111.0512 - val_accuracy: 0.0588\n",
      "Epoch 8375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2699 - accuracy: 0.0156 - val_loss: 126.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6932 - accuracy: 0.0000e+00 - val_loss: 132.2475 - val_accuracy: 0.0000e+00\n",
      "Epoch 8377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1507 - accuracy: 0.0000e+00 - val_loss: 129.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 8378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4214 - accuracy: 0.0000e+00 - val_loss: 123.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 8379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5811 - accuracy: 0.0000e+00 - val_loss: 117.6255 - val_accuracy: 0.0588\n",
      "Epoch 8380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9070 - accuracy: 0.0000e+00 - val_loss: 115.6555 - val_accuracy: 0.0588\n",
      "Epoch 8381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2439 - accuracy: 0.0000e+00 - val_loss: 116.9468 - val_accuracy: 0.0588\n",
      "Epoch 8382/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 24.3449 - accuracy: 0.0000e+00 - val_loss: 126.7488 - val_accuracy: 0.0588\n",
      "Epoch 8383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0531 - accuracy: 0.0000e+00 - val_loss: 135.1676 - val_accuracy: 0.0588\n",
      "Epoch 8384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2228 - accuracy: 0.0156 - val_loss: 136.2586 - val_accuracy: 0.0588\n",
      "Epoch 8385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1944 - accuracy: 0.0000e+00 - val_loss: 135.7839 - val_accuracy: 0.0588\n",
      "Epoch 8386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5537 - accuracy: 0.0156 - val_loss: 141.2764 - val_accuracy: 0.0588\n",
      "Epoch 8387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9399 - accuracy: 0.0312 - val_loss: 138.6645 - val_accuracy: 0.0000e+00\n",
      "Epoch 8388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9322 - accuracy: 0.0156 - val_loss: 134.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8389/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 19.3936 - accuracy: 0.0000e+00 - val_loss: 128.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 8390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0613 - accuracy: 0.0156 - val_loss: 127.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5215 - accuracy: 0.0156 - val_loss: 129.5474 - val_accuracy: 0.0000e+00\n",
      "Epoch 8392/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 15.5082 - accuracy: 0.0156 - val_loss: 134.8898 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8393/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 28.4920 - accuracy: 0.0000e+00 - val_loss: 135.5686 - val_accuracy: 0.0000e+00\n",
      "Epoch 8394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8325 - accuracy: 0.0000e+00 - val_loss: 135.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3399 - accuracy: 0.0000e+00 - val_loss: 135.4798 - val_accuracy: 0.0000e+00\n",
      "Epoch 8396/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 11.1325 - accuracy: 0.0156 - val_loss: 133.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 8397/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4296 - accuracy: 0.0156 - val_loss: 130.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 8398/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 34.9553 - accuracy: 0.0156 - val_loss: 129.8371 - val_accuracy: 0.0000e+00\n",
      "Epoch 8399/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 29.4201 - accuracy: 0.0000e+00 - val_loss: 130.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6787 - accuracy: 0.0156 - val_loss: 130.5138 - val_accuracy: 0.0000e+00\n",
      "Epoch 8401/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.3637 - accuracy: 0.0156 - val_loss: 126.6936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8402/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 19.7300 - accuracy: 0.0000e+00 - val_loss: 122.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 8403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4142 - accuracy: 0.0000e+00 - val_loss: 123.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 8404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3108 - accuracy: 0.0000e+00 - val_loss: 122.9437 - val_accuracy: 0.0000e+00\n",
      "Epoch 8405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3578 - accuracy: 0.0000e+00 - val_loss: 120.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3250 - accuracy: 0.0000e+00 - val_loss: 119.9821 - val_accuracy: 0.0000e+00\n",
      "Epoch 8407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0880 - accuracy: 0.0000e+00 - val_loss: 124.5423 - val_accuracy: 0.0000e+00\n",
      "Epoch 8408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5883 - accuracy: 0.0000e+00 - val_loss: 122.5565 - val_accuracy: 0.0000e+00\n",
      "Epoch 8409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4939 - accuracy: 0.0312 - val_loss: 120.4609 - val_accuracy: 0.0588\n",
      "Epoch 8410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8182 - accuracy: 0.0156 - val_loss: 123.0713 - val_accuracy: 0.0588\n",
      "Epoch 8411/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 18.8442 - accuracy: 0.0156 - val_loss: 126.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 8412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4662 - accuracy: 0.0156 - val_loss: 133.0777 - val_accuracy: 0.0588\n",
      "Epoch 8413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1833 - accuracy: 0.0000e+00 - val_loss: 144.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 8414/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.3571 - accuracy: 0.0000e+00 - val_loss: 147.6112 - val_accuracy: 0.0588\n",
      "Epoch 8415/10000\n",
      "64/64 [==============================] - 0s 477us/step - loss: 29.1587 - accuracy: 0.0312 - val_loss: 151.0843 - val_accuracy: 0.0588\n",
      "Epoch 8416/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 24.8909 - accuracy: 0.0000e+00 - val_loss: 151.2998 - val_accuracy: 0.0588\n",
      "Epoch 8417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9319 - accuracy: 0.0156 - val_loss: 145.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 8418/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5081 - accuracy: 0.0312 - val_loss: 133.7799 - val_accuracy: 0.0000e+00\n",
      "Epoch 8419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5444 - accuracy: 0.0156 - val_loss: 130.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 8420/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 29.3943 - accuracy: 0.0156 - val_loss: 128.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 8421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4690 - accuracy: 0.0156 - val_loss: 125.4088 - val_accuracy: 0.0588\n",
      "Epoch 8422/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 28.4507 - accuracy: 0.0000e+00 - val_loss: 123.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5356 - accuracy: 0.0156 - val_loss: 121.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 8424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2147 - accuracy: 0.0312 - val_loss: 121.5346 - val_accuracy: 0.0588\n",
      "Epoch 8425/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 19.9044 - accuracy: 0.0000e+00 - val_loss: 126.2662 - val_accuracy: 0.0000e+00\n",
      "Epoch 8426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2278 - accuracy: 0.0000e+00 - val_loss: 138.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 8427/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.2719 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 32.7255 - accuracy: 0.0000e+00 - val_loss: 145.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 8428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3827 - accuracy: 0.0000e+00 - val_loss: 144.1520 - val_accuracy: 0.0000e+00\n",
      "Epoch 8429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7019 - accuracy: 0.0312 - val_loss: 134.8864 - val_accuracy: 0.0000e+00\n",
      "Epoch 8430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8186 - accuracy: 0.0156 - val_loss: 120.9584 - val_accuracy: 0.0000e+00\n",
      "Epoch 8431/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 21.3320 - accuracy: 0.0000e+00 - val_loss: 111.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 8432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0292 - accuracy: 0.0000e+00 - val_loss: 114.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 8433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8669 - accuracy: 0.0156 - val_loss: 129.9834 - val_accuracy: 0.0588\n",
      "Epoch 8434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1976 - accuracy: 0.0156 - val_loss: 139.1856 - val_accuracy: 0.0588\n",
      "Epoch 8435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8647 - accuracy: 0.0156 - val_loss: 138.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 8436/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.2747 - accuracy: 0.0156 - val_loss: 132.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 8437/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6119 - accuracy: 0.0156 - val_loss: 133.3292 - val_accuracy: 0.0000e+00\n",
      "Epoch 8438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8025 - accuracy: 0.0625 - val_loss: 138.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 8439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5117 - accuracy: 0.0156 - val_loss: 143.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 8440/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.0701 - accuracy: 0.0000e+00 - val_loss: 143.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 8441/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 21.2535 - accuracy: 0.0156 - val_loss: 145.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 8442/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 36.1746 - accuracy: 0.0000e+00 - val_loss: 136.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0294 - accuracy: 0.0000e+00 - val_loss: 128.8541 - val_accuracy: 0.0000e+00\n",
      "Epoch 8444/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 20.5040 - accuracy: 0.0156 - val_loss: 128.8535 - val_accuracy: 0.0588\n",
      "Epoch 8445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0630 - accuracy: 0.0000e+00 - val_loss: 137.0651 - val_accuracy: 0.0000e+00\n",
      "Epoch 8446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3201 - accuracy: 0.0000e+00 - val_loss: 136.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 8447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9132 - accuracy: 0.0000e+00 - val_loss: 132.3843 - val_accuracy: 0.0000e+00\n",
      "Epoch 8448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9212 - accuracy: 0.0000e+00 - val_loss: 130.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 8449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7097 - accuracy: 0.0000e+00 - val_loss: 136.6994 - val_accuracy: 0.0588\n",
      "Epoch 8450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8011 - accuracy: 0.0312 - val_loss: 146.6873 - val_accuracy: 0.1176\n",
      "Epoch 8451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1988 - accuracy: 0.0156 - val_loss: 154.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 8452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9207 - accuracy: 0.0312 - val_loss: 156.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8453/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 26.3451 - accuracy: 0.0000e+00 - val_loss: 157.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 8454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0646 - accuracy: 0.0000e+00 - val_loss: 155.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 8455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9113 - accuracy: 0.0000e+00 - val_loss: 148.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 8456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5311 - accuracy: 0.0312 - val_loss: 139.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 8457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.3059 - accuracy: 0.0000e+00 - val_loss: 132.2153 - val_accuracy: 0.0588\n",
      "Epoch 8458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3367 - accuracy: 0.0156 - val_loss: 129.9041 - val_accuracy: 0.0588\n",
      "Epoch 8459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5002 - accuracy: 0.0156 - val_loss: 134.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1648 - accuracy: 0.0000e+00 - val_loss: 140.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 8461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0229 - accuracy: 0.0156 - val_loss: 139.4382 - val_accuracy: 0.0588\n",
      "Epoch 8462/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3943 - accuracy: 0.0000e+00 - val_loss: 129.8354 - val_accuracy: 0.0588\n",
      "Epoch 8463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0338 - accuracy: 0.0000e+00 - val_loss: 120.7807 - val_accuracy: 0.0000e+00\n",
      "Epoch 8464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2547 - accuracy: 0.0312 - val_loss: 120.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 8465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7877 - accuracy: 0.0000e+00 - val_loss: 125.8036 - val_accuracy: 0.0588\n",
      "Epoch 8466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7804 - accuracy: 0.0156 - val_loss: 132.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 8467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7928 - accuracy: 0.0312 - val_loss: 139.6425 - val_accuracy: 0.0000e+00\n",
      "Epoch 8468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7166 - accuracy: 0.0156 - val_loss: 149.5081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8469/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.3596 - accuracy: 0.0156 - val_loss: 149.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 8470/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6005 - accuracy: 0.0156 - val_loss: 142.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0013 - accuracy: 0.0469 - val_loss: 136.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 8472/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 27.0797 - accuracy: 0.0156 - val_loss: 133.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 8473/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.2199 - accuracy: 0.0000e+00 - val_loss: 126.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 8474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.8801 - accuracy: 0.0156 - val_loss: 120.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 8475/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 15.8593 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 25.5756 - accuracy: 0.0156 - val_loss: 117.0903 - val_accuracy: 0.0588\n",
      "Epoch 8476/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.7639 - accuracy: 0.0000e+00 - val_loss: 123.6816 - val_accuracy: 0.0588\n",
      "Epoch 8477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3391 - accuracy: 0.0000e+00 - val_loss: 140.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 8478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0778 - accuracy: 0.0000e+00 - val_loss: 149.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 8479/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.5313 - accuracy: 0.0000e+00 - val_loss: 143.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 8480/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 25.0434 - accuracy: 0.0156 - val_loss: 134.2882 - val_accuracy: 0.0000e+00\n",
      "Epoch 8481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3631 - accuracy: 0.0156 - val_loss: 133.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 8482/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.5871 - accuracy: 0.0156 - val_loss: 140.7979 - val_accuracy: 0.0588\n",
      "Epoch 8483/10000\n",
      "64/64 [==============================] - 0s 212us/step - loss: 30.7372 - accuracy: 0.0000e+00 - val_loss: 144.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 8484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2193 - accuracy: 0.0000e+00 - val_loss: 141.3229 - val_accuracy: 0.0588\n",
      "Epoch 8485/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 34.7517 - accuracy: 0.0000e+00 - val_loss: 135.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 8486/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.8446 - accuracy: 0.0000e+00 - val_loss: 131.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7538 - accuracy: 0.0000e+00 - val_loss: 128.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 8488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6073 - accuracy: 0.0000e+00 - val_loss: 122.7222 - val_accuracy: 0.0000e+00\n",
      "Epoch 8489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.5617 - accuracy: 0.0000e+00 - val_loss: 122.0771 - val_accuracy: 0.0000e+00\n",
      "Epoch 8490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1819 - accuracy: 0.0000e+00 - val_loss: 131.2930 - val_accuracy: 0.0000e+00\n",
      "Epoch 8491/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4535 - accuracy: 0.0000e+00 - val_loss: 140.6105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9185 - accuracy: 0.0156 - val_loss: 139.9179 - val_accuracy: 0.0588\n",
      "Epoch 8493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6077 - accuracy: 0.0156 - val_loss: 130.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8494/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.5558 - accuracy: 0.0156 - val_loss: 129.5628 - val_accuracy: 0.0588\n",
      "Epoch 8495/10000\n",
      "64/64 [==============================] - 0s 201us/step - loss: 21.9112 - accuracy: 0.0156 - val_loss: 131.5475 - val_accuracy: 0.0000e+00\n",
      "Epoch 8496/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 28.1128 - accuracy: 0.0000e+00 - val_loss: 132.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8497/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 27.9848 - accuracy: 0.0156 - val_loss: 133.8027 - val_accuracy: 0.0588\n",
      "Epoch 8498/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7265 - accuracy: 0.0156 - val_loss: 134.6494 - val_accuracy: 0.0588\n",
      "Epoch 8499/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.3004 - accuracy: 0.0000e+00 - val_loss: 130.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 8500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8469 - accuracy: 0.0156 - val_loss: 119.2444 - val_accuracy: 0.0000e+00\n",
      "Epoch 8501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5198 - accuracy: 0.0000e+00 - val_loss: 111.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 8502/10000\n",
      "64/64 [==============================] - 0s 198us/step - loss: 35.8221 - accuracy: 0.0156 - val_loss: 112.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 8503/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 13.5095 - accuracy: 0.0156 - val_loss: 119.9064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8504/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 25.4848 - accuracy: 0.0156 - val_loss: 124.7833 - val_accuracy: 0.0000e+00\n",
      "Epoch 8505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4764 - accuracy: 0.0000e+00 - val_loss: 118.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1837 - accuracy: 0.0156 - val_loss: 110.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 8507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0731 - accuracy: 0.0000e+00 - val_loss: 112.8332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4652 - accuracy: 0.0156 - val_loss: 120.2784 - val_accuracy: 0.0000e+00\n",
      "Epoch 8509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3390 - accuracy: 0.0000e+00 - val_loss: 122.2912 - val_accuracy: 0.0000e+00\n",
      "Epoch 8510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9229 - accuracy: 0.0156 - val_loss: 119.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 8511/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 23.9400 - accuracy: 0.0000e+00 - val_loss: 125.0230 - val_accuracy: 0.0588\n",
      "Epoch 8512/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 20.0503 - accuracy: 0.0000e+00 - val_loss: 130.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8513/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.1240 - accuracy: 0.0000e+00 - val_loss: 133.1808 - val_accuracy: 0.0588\n",
      "Epoch 8514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5053 - accuracy: 0.0000e+00 - val_loss: 133.8731 - val_accuracy: 0.0000e+00\n",
      "Epoch 8515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1516 - accuracy: 0.0000e+00 - val_loss: 131.2835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0984 - accuracy: 0.0000e+00 - val_loss: 135.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 8517/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.9252 - accuracy: 0.0000e+00 - val_loss: 149.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 8518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4558 - accuracy: 0.0000e+00 - val_loss: 159.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 8519/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 28.9109 - accuracy: 0.0000e+00 - val_loss: 157.6199 - val_accuracy: 0.0000e+00\n",
      "Epoch 8520/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1227 - accuracy: 0.0156 - val_loss: 147.0440 - val_accuracy: 0.0000e+00\n",
      "Epoch 8521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9141 - accuracy: 0.0000e+00 - val_loss: 136.1498 - val_accuracy: 0.0588\n",
      "Epoch 8522/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.2503 - accuracy: 0.0625 - val_loss: 133.2535 - val_accuracy: 0.0588\n",
      "Epoch 8523/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 20.7698 - accuracy: 0.0000e+00 - val_loss: 133.1210 - val_accuracy: 0.0588\n",
      "Epoch 8524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5059 - accuracy: 0.0156 - val_loss: 137.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 8525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0933 - accuracy: 0.0000e+00 - val_loss: 145.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4508 - accuracy: 0.0312 - val_loss: 146.9997 - val_accuracy: 0.0000e+00\n",
      "Epoch 8527/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 24.9419 - accuracy: 0.0000e+00 - val_loss: 142.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 8528/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.1746 - accuracy: 0.0312 - val_loss: 132.0279 - val_accuracy: 0.0000e+00\n",
      "Epoch 8529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2733 - accuracy: 0.0000e+00 - val_loss: 120.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 8530/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 21.6585 - accuracy: 0.0156 - val_loss: 113.2213 - val_accuracy: 0.0588\n",
      "Epoch 8531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2492 - accuracy: 0.0156 - val_loss: 123.7102 - val_accuracy: 0.0588\n",
      "Epoch 8532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3383 - accuracy: 0.0312 - val_loss: 142.5366 - val_accuracy: 0.0000e+00\n",
      "Epoch 8533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9447 - accuracy: 0.0000e+00 - val_loss: 153.6822 - val_accuracy: 0.0000e+00\n",
      "Epoch 8534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3889 - accuracy: 0.0000e+00 - val_loss: 156.3328 - val_accuracy: 0.0588\n",
      "Epoch 8535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4775 - accuracy: 0.0000e+00 - val_loss: 151.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 8536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3236 - accuracy: 0.0000e+00 - val_loss: 141.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8492 - accuracy: 0.0156 - val_loss: 126.0437 - val_accuracy: 0.0588\n",
      "Epoch 8538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4241 - accuracy: 0.0312 - val_loss: 119.7297 - val_accuracy: 0.0588\n",
      "Epoch 8539/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.3790 - accuracy: 0.0156 - val_loss: 119.1422 - val_accuracy: 0.0000e+00\n",
      "Epoch 8540/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7079 - accuracy: 0.0312 - val_loss: 135.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 8541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1655 - accuracy: 0.0000e+00 - val_loss: 147.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 8542/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.1838 - accuracy: 0.0156 - val_loss: 150.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5283 - accuracy: 0.0000e+00 - val_loss: 145.3720 - val_accuracy: 0.0000e+00\n",
      "Epoch 8544/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7143 - accuracy: 0.0156 - val_loss: 143.1974 - val_accuracy: 0.0000e+00\n",
      "Epoch 8545/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.8520 - accuracy: 0.0000e+00 - val_loss: 137.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 8546/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 24.2876 - accuracy: 0.0156 - val_loss: 134.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 8547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5209 - accuracy: 0.0312 - val_loss: 135.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 8548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0385 - accuracy: 0.0000e+00 - val_loss: 141.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 8549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3353 - accuracy: 0.0000e+00 - val_loss: 138.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 8550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7517 - accuracy: 0.0000e+00 - val_loss: 134.6033 - val_accuracy: 0.0588\n",
      "Epoch 8551/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 22.3305 - accuracy: 0.0156 - val_loss: 130.0751 - val_accuracy: 0.0588\n",
      "Epoch 8552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6799 - accuracy: 0.0000e+00 - val_loss: 129.6581 - val_accuracy: 0.0000e+00\n",
      "Epoch 8553/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 21.5306 - accuracy: 0.0312 - val_loss: 134.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 8554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9107 - accuracy: 0.0156 - val_loss: 134.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 8555/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 24.8108 - accuracy: 0.0000e+00 - val_loss: 134.9852 - val_accuracy: 0.0000e+00\n",
      "Epoch 8556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6109 - accuracy: 0.0000e+00 - val_loss: 135.9120 - val_accuracy: 0.0588\n",
      "Epoch 8557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6391 - accuracy: 0.0156 - val_loss: 137.8425 - val_accuracy: 0.0588\n",
      "Epoch 8558/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.6362 - accuracy: 0.0156 - val_loss: 139.2053 - val_accuracy: 0.0588\n",
      "Epoch 8559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0105 - accuracy: 0.0000e+00 - val_loss: 142.0268 - val_accuracy: 0.0000e+00\n",
      "Epoch 8560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9594 - accuracy: 0.0000e+00 - val_loss: 139.4691 - val_accuracy: 0.0000e+00\n",
      "Epoch 8561/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 30.5507 - accuracy: 0.0156 - val_loss: 142.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 8562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5382 - accuracy: 0.0000e+00 - val_loss: 145.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 8563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2582 - accuracy: 0.0156 - val_loss: 144.4389 - val_accuracy: 0.0000e+00\n",
      "Epoch 8564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9143 - accuracy: 0.0000e+00 - val_loss: 141.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8565/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.0602 - accuracy: 0.0312 - val_loss: 131.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 8566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1485 - accuracy: 0.0312 - val_loss: 127.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 8567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3263 - accuracy: 0.0000e+00 - val_loss: 125.6748 - val_accuracy: 0.0588\n",
      "Epoch 8568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5909 - accuracy: 0.0156 - val_loss: 132.5171 - val_accuracy: 0.0588\n",
      "Epoch 8569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0851 - accuracy: 0.0000e+00 - val_loss: 135.0329 - val_accuracy: 0.0588\n",
      "Epoch 8570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0804 - accuracy: 0.0000e+00 - val_loss: 133.6737 - val_accuracy: 0.0588\n",
      "Epoch 8571/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.7967 - accuracy: 0.0156 - val_loss: 127.1555 - val_accuracy: 0.0588\n",
      "Epoch 8572/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.6265 - accuracy: 0.0000e+00 - val_loss: 117.4742 - val_accuracy: 0.1176\n",
      "Epoch 8573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2119 - accuracy: 0.0469 - val_loss: 112.6777 - val_accuracy: 0.1176\n",
      "Epoch 8574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7263 - accuracy: 0.0000e+00 - val_loss: 124.0824 - val_accuracy: 0.0588\n",
      "Epoch 8575/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 28.1138 - accuracy: 0.0156 - val_loss: 145.9511 - val_accuracy: 0.0588\n",
      "Epoch 8576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5675 - accuracy: 0.0156 - val_loss: 153.3263 - val_accuracy: 0.0588\n",
      "Epoch 8577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8956 - accuracy: 0.0000e+00 - val_loss: 157.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 8578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7959 - accuracy: 0.0312 - val_loss: 149.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6709 - accuracy: 0.0156 - val_loss: 141.3620 - val_accuracy: 0.0000e+00\n",
      "Epoch 8580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0022 - accuracy: 0.0469 - val_loss: 134.4942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9043 - accuracy: 0.0156 - val_loss: 136.9785 - val_accuracy: 0.0000e+00\n",
      "Epoch 8582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7646 - accuracy: 0.0156 - val_loss: 139.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 8583/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 20.4849 - accuracy: 0.0156 - val_loss: 144.9263 - val_accuracy: 0.0000e+00\n",
      "Epoch 8584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3296 - accuracy: 0.0312 - val_loss: 148.7828 - val_accuracy: 0.0000e+00\n",
      "Epoch 8585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3367 - accuracy: 0.0000e+00 - val_loss: 154.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 8586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5461 - accuracy: 0.0156 - val_loss: 152.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5467 - accuracy: 0.0000e+00 - val_loss: 148.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8588/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.1005 - accuracy: 0.0312 - val_loss: 138.9019 - val_accuracy: 0.0000e+00\n",
      "Epoch 8589/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 18.0842 - accuracy: 0.0156 - val_loss: 129.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 8590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7777 - accuracy: 0.0469 - val_loss: 126.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 8591/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 22.6644 - accuracy: 0.0156 - val_loss: 127.3098 - val_accuracy: 0.0000e+00\n",
      "Epoch 8592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2018 - accuracy: 0.0000e+00 - val_loss: 132.5517 - val_accuracy: 0.0000e+00\n",
      "Epoch 8593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2163 - accuracy: 0.0000e+00 - val_loss: 130.1732 - val_accuracy: 0.0000e+00\n",
      "Epoch 8594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5298 - accuracy: 0.0000e+00 - val_loss: 126.3528 - val_accuracy: 0.0588\n",
      "Epoch 8595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6290 - accuracy: 0.0000e+00 - val_loss: 123.1542 - val_accuracy: 0.1176\n",
      "Epoch 8596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9694 - accuracy: 0.0000e+00 - val_loss: 128.8551 - val_accuracy: 0.0588\n",
      "Epoch 8597/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 33.9293 - accuracy: 0.0156 - val_loss: 136.1162 - val_accuracy: 0.0588\n",
      "Epoch 8598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0231 - accuracy: 0.0000e+00 - val_loss: 141.6163 - val_accuracy: 0.0000e+00\n",
      "Epoch 8599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7327 - accuracy: 0.0000e+00 - val_loss: 139.4685 - val_accuracy: 0.0000e+00\n",
      "Epoch 8600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5669 - accuracy: 0.0000e+00 - val_loss: 138.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 8601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4362 - accuracy: 0.0000e+00 - val_loss: 136.1606 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8602/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.8675 - accuracy: 0.0469 - val_loss: 130.1568 - val_accuracy: 0.0588\n",
      "Epoch 8603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4166 - accuracy: 0.0156 - val_loss: 123.2701 - val_accuracy: 0.0588\n",
      "Epoch 8604/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 15.1304 - accuracy: 0.0000e+00 - val_loss: 117.8004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6851 - accuracy: 0.0156 - val_loss: 122.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 8606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5843 - accuracy: 0.0312 - val_loss: 125.6028 - val_accuracy: 0.0588\n",
      "Epoch 8607/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.2577 - accuracy: 0.0000e+00 - val_loss: 129.1986 - val_accuracy: 0.0588\n",
      "Epoch 8608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2340 - accuracy: 0.0156 - val_loss: 131.0905 - val_accuracy: 0.0000e+00\n",
      "Epoch 8609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3732 - accuracy: 0.0000e+00 - val_loss: 130.2159 - val_accuracy: 0.0588\n",
      "Epoch 8610/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 30.2065 - accuracy: 0.0000e+00 - val_loss: 130.7097 - val_accuracy: 0.0588\n",
      "Epoch 8611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6297 - accuracy: 0.0156 - val_loss: 133.7406 - val_accuracy: 0.0588\n",
      "Epoch 8612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4038 - accuracy: 0.0000e+00 - val_loss: 140.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 8613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8115 - accuracy: 0.0000e+00 - val_loss: 145.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 8614/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7487 - accuracy: 0.0000e+00 - val_loss: 146.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0094 - accuracy: 0.0312 - val_loss: 140.6861 - val_accuracy: 0.0588\n",
      "Epoch 8616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5011 - accuracy: 0.0000e+00 - val_loss: 129.2950 - val_accuracy: 0.0588\n",
      "Epoch 8617/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3687 - accuracy: 0.0000e+00 - val_loss: 125.4460 - val_accuracy: 0.0000e+00\n",
      "Epoch 8618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8835 - accuracy: 0.0156 - val_loss: 124.7813 - val_accuracy: 0.0588\n",
      "Epoch 8619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5883 - accuracy: 0.0469 - val_loss: 130.2189 - val_accuracy: 0.0588\n",
      "Epoch 8620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9243 - accuracy: 0.0156 - val_loss: 141.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 8621/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 18.9248 - accuracy: 0.0156 - val_loss: 151.1914 - val_accuracy: 0.0588\n",
      "Epoch 8622/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.1422 - accuracy: 0.0156 - val_loss: 159.5931 - val_accuracy: 0.0588\n",
      "Epoch 8623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6433 - accuracy: 0.0156 - val_loss: 158.1790 - val_accuracy: 0.0588\n",
      "Epoch 8624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6735 - accuracy: 0.0000e+00 - val_loss: 149.2209 - val_accuracy: 0.0588\n",
      "Epoch 8625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0868 - accuracy: 0.0156 - val_loss: 139.6569 - val_accuracy: 0.0588\n",
      "Epoch 8626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2166 - accuracy: 0.0000e+00 - val_loss: 131.6922 - val_accuracy: 0.0588\n",
      "Epoch 8627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3237 - accuracy: 0.0000e+00 - val_loss: 136.1004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6667 - accuracy: 0.0312 - val_loss: 136.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 8629/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.6837 - accuracy: 0.0312 - val_loss: 136.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 8630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1688 - accuracy: 0.0000e+00 - val_loss: 134.8158 - val_accuracy: 0.0588\n",
      "Epoch 8631/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 31.2545 - accuracy: 0.0156 - val_loss: 134.4783 - val_accuracy: 0.0588\n",
      "Epoch 8632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8738 - accuracy: 0.0156 - val_loss: 138.3328 - val_accuracy: 0.0588\n",
      "Epoch 8633/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 37.0401 - accuracy: 0.0156 - val_loss: 145.4804 - val_accuracy: 0.1176\n",
      "Epoch 8634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6928 - accuracy: 0.0000e+00 - val_loss: 152.8580 - val_accuracy: 0.0588\n",
      "Epoch 8635/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0432 - accuracy: 0.0312 - val_loss: 149.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 8636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7488 - accuracy: 0.0000e+00 - val_loss: 131.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 8637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8295 - accuracy: 0.0000e+00 - val_loss: 117.3058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0023 - accuracy: 0.0000e+00 - val_loss: 111.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8639/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9967 - accuracy: 0.0156 - val_loss: 111.7924 - val_accuracy: 0.0000e+00\n",
      "Epoch 8640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1824 - accuracy: 0.0000e+00 - val_loss: 114.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 8641/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3838 - accuracy: 0.0312 - val_loss: 125.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8642/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 20.9028 - accuracy: 0.0000e+00 - val_loss: 135.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 8643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6100 - accuracy: 0.0000e+00 - val_loss: 140.0495 - val_accuracy: 0.0588\n",
      "Epoch 8644/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3248 - accuracy: 0.0000e+00 - val_loss: 147.4998 - val_accuracy: 0.0588\n",
      "Epoch 8645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9249 - accuracy: 0.0156 - val_loss: 156.1166 - val_accuracy: 0.0588\n",
      "Epoch 8646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7105 - accuracy: 0.0000e+00 - val_loss: 161.2301 - val_accuracy: 0.0588\n",
      "Epoch 8647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9787 - accuracy: 0.0156 - val_loss: 158.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 8648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1163 - accuracy: 0.0156 - val_loss: 152.8078 - val_accuracy: 0.0588\n",
      "Epoch 8649/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7517 - accuracy: 0.0000e+00 - val_loss: 146.8436 - val_accuracy: 0.0000e+00\n",
      "Epoch 8650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0530 - accuracy: 0.0156 - val_loss: 140.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8651/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5535 - accuracy: 0.0156 - val_loss: 142.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 8652/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3361 - accuracy: 0.0156 - val_loss: 147.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2609 - accuracy: 0.0312 - val_loss: 147.7338 - val_accuracy: 0.0000e+00\n",
      "Epoch 8654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0699 - accuracy: 0.0156 - val_loss: 143.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 8655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 18.1576 - accuracy: 0.0000e+00 - val_loss: 140.4397 - val_accuracy: 0.0000e+00\n",
      "Epoch 8656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4912 - accuracy: 0.0000e+00 - val_loss: 140.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 8657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0449 - accuracy: 0.0000e+00 - val_loss: 142.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 8658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8320 - accuracy: 0.0312 - val_loss: 144.3802 - val_accuracy: 0.0000e+00\n",
      "Epoch 8659/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.6855 - accuracy: 0.0000e+00 - val_loss: 147.6747 - val_accuracy: 0.0000e+00\n",
      "Epoch 8660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4117 - accuracy: 0.0156 - val_loss: 143.7433 - val_accuracy: 0.0000e+00\n",
      "Epoch 8661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9907 - accuracy: 0.0000e+00 - val_loss: 141.6425 - val_accuracy: 0.0000e+00\n",
      "Epoch 8662/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 21.9947 - accuracy: 0.0156 - val_loss: 137.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7097 - accuracy: 0.0156 - val_loss: 132.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 8664/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.3849 - accuracy: 0.031 - 0s 62us/step - loss: 34.9425 - accuracy: 0.0156 - val_loss: 128.2574 - val_accuracy: 0.0588\n",
      "Epoch 8665/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 23.6356 - accuracy: 0.0000e+00 - val_loss: 125.5525 - val_accuracy: 0.0588\n",
      "Epoch 8666/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9084 - accuracy: 0.0000e+00 - val_loss: 123.9304 - val_accuracy: 0.0588\n",
      "Epoch 8667/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0426 - accuracy: 0.0000e+00 - val_loss: 131.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 8668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7855 - accuracy: 0.0156 - val_loss: 137.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 8669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6226 - accuracy: 0.0000e+00 - val_loss: 142.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 8670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7087 - accuracy: 0.0000e+00 - val_loss: 150.8423 - val_accuracy: 0.0588\n",
      "Epoch 8671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7268 - accuracy: 0.0000e+00 - val_loss: 154.4152 - val_accuracy: 0.0588\n",
      "Epoch 8672/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7322 - accuracy: 0.0000e+00 - val_loss: 147.9850 - val_accuracy: 0.0588\n",
      "Epoch 8673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2087 - accuracy: 0.0000e+00 - val_loss: 143.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5168 - accuracy: 0.0156 - val_loss: 139.2256 - val_accuracy: 0.0000e+00\n",
      "Epoch 8675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8423 - accuracy: 0.0156 - val_loss: 133.2484 - val_accuracy: 0.0588\n",
      "Epoch 8676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5178 - accuracy: 0.0312 - val_loss: 125.9989 - val_accuracy: 0.0588\n",
      "Epoch 8677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8534 - accuracy: 0.0156 - val_loss: 121.7419 - val_accuracy: 0.0588\n",
      "Epoch 8678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2869 - accuracy: 0.0000e+00 - val_loss: 124.5009 - val_accuracy: 0.0588\n",
      "Epoch 8679/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.6718 - accuracy: 0.0156 - val_loss: 130.9110 - val_accuracy: 0.0588\n",
      "Epoch 8680/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8939 - accuracy: 0.0312 - val_loss: 133.7025 - val_accuracy: 0.0588\n",
      "Epoch 8681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3199 - accuracy: 0.0000e+00 - val_loss: 132.7806 - val_accuracy: 0.0588\n",
      "Epoch 8682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4542 - accuracy: 0.0312 - val_loss: 129.8474 - val_accuracy: 0.1176\n",
      "Epoch 8683/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 27.4500 - accuracy: 0.0156 - val_loss: 132.0428 - val_accuracy: 0.1176\n",
      "Epoch 8684/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.6050 - accuracy: 0.0156 - val_loss: 139.5507 - val_accuracy: 0.0588\n",
      "Epoch 8685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5318 - accuracy: 0.0000e+00 - val_loss: 151.6051 - val_accuracy: 0.0588\n",
      "Epoch 8686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4382 - accuracy: 0.0156 - val_loss: 154.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 8687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1659 - accuracy: 0.0000e+00 - val_loss: 148.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8688/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 18.2183 - accuracy: 0.0156 - val_loss: 142.0968 - val_accuracy: 0.0000e+00\n",
      "Epoch 8689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2997 - accuracy: 0.0156 - val_loss: 130.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 8690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7299 - accuracy: 0.0312 - val_loss: 133.6916 - val_accuracy: 0.0588\n",
      "Epoch 8691/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 19.7056 - accuracy: 0.0156 - val_loss: 144.8931 - val_accuracy: 0.0588\n",
      "Epoch 8692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6802 - accuracy: 0.0312 - val_loss: 151.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8693/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7124 - accuracy: 0.0000e+00 - val_loss: 152.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 8694/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.3375 - accuracy: 0.0312 - val_loss: 146.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 8695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2832 - accuracy: 0.0312 - val_loss: 143.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 8696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1593 - accuracy: 0.0156 - val_loss: 143.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 8697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9134 - accuracy: 0.0156 - val_loss: 147.3367 - val_accuracy: 0.0000e+00\n",
      "Epoch 8698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4845 - accuracy: 0.0000e+00 - val_loss: 149.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 8699/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3116 - accuracy: 0.0000e+00 - val_loss: 150.6127 - val_accuracy: 0.0000e+00\n",
      "Epoch 8700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8897 - accuracy: 0.0312 - val_loss: 147.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 8701/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 19.5614 - accuracy: 0.0000e+00 - val_loss: 141.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 8702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6718 - accuracy: 0.0000e+00 - val_loss: 133.8483 - val_accuracy: 0.0000e+00\n",
      "Epoch 8703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0782 - accuracy: 0.0312 - val_loss: 126.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 8704/10000\n",
      "64/64 [==============================] - 0s 57us/step - loss: 18.9748 - accuracy: 0.0000e+00 - val_loss: 124.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 8705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5145 - accuracy: 0.0000e+00 - val_loss: 124.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 8706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5904 - accuracy: 0.0156 - val_loss: 132.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8707/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 18.7033 - accuracy: 0.0000e+00 - val_loss: 137.7858 - val_accuracy: 0.0000e+00\n",
      "Epoch 8708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.2397 - accuracy: 0.0000e+00 - val_loss: 141.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 8709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7407 - accuracy: 0.0000e+00 - val_loss: 144.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 8710/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.4842 - accuracy: 0.0156 - val_loss: 145.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 8711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6136 - accuracy: 0.0156 - val_loss: 142.3328 - val_accuracy: 0.0000e+00\n",
      "Epoch 8712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9705 - accuracy: 0.0000e+00 - val_loss: 134.8318 - val_accuracy: 0.0000e+00\n",
      "Epoch 8713/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7093 - accuracy: 0.0156 - val_loss: 127.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8714/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 30.9959 - accuracy: 0.0156 - val_loss: 127.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 8715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9139 - accuracy: 0.0156 - val_loss: 128.6513 - val_accuracy: 0.0588\n",
      "Epoch 8716/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2934 - accuracy: 0.0000e+00 - val_loss: 133.8286 - val_accuracy: 0.0588\n",
      "Epoch 8717/10000\n",
      "64/64 [==============================] - 0s 108us/step - loss: 23.9649 - accuracy: 0.0000e+00 - val_loss: 142.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 8718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4841 - accuracy: 0.0000e+00 - val_loss: 138.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 8719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2117 - accuracy: 0.0000e+00 - val_loss: 134.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 8720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1229 - accuracy: 0.0000e+00 - val_loss: 132.2957 - val_accuracy: 0.0588\n",
      "Epoch 8721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9954 - accuracy: 0.0000e+00 - val_loss: 137.2720 - val_accuracy: 0.0588\n",
      "Epoch 8722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5510 - accuracy: 0.0312 - val_loss: 142.9331 - val_accuracy: 0.0000e+00\n",
      "Epoch 8723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.2153 - accuracy: 0.0156 - val_loss: 146.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 8724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2125 - accuracy: 0.0312 - val_loss: 149.6530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8725/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 18.3872 - accuracy: 0.0000e+00 - val_loss: 147.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 8726/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6861 - accuracy: 0.0156 - val_loss: 141.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 8727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1581 - accuracy: 0.0156 - val_loss: 137.3744 - val_accuracy: 0.0000e+00\n",
      "Epoch 8728/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2329 - accuracy: 0.0312 - val_loss: 128.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0677 - accuracy: 0.0000e+00 - val_loss: 126.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 8730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2314 - accuracy: 0.0000e+00 - val_loss: 132.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 8731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0104 - accuracy: 0.0000e+00 - val_loss: 133.5973 - val_accuracy: 0.0000e+00\n",
      "Epoch 8732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5146 - accuracy: 0.0000e+00 - val_loss: 133.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 8733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6409 - accuracy: 0.0000e+00 - val_loss: 138.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6884 - accuracy: 0.0156 - val_loss: 139.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8735/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3743 - accuracy: 0.0000e+00 - val_loss: 135.6380 - val_accuracy: 0.0588\n",
      "Epoch 8736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1409 - accuracy: 0.0000e+00 - val_loss: 134.2275 - val_accuracy: 0.0588\n",
      "Epoch 8737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5427 - accuracy: 0.0156 - val_loss: 138.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 8738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1001 - accuracy: 0.0000e+00 - val_loss: 143.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8739/10000\n",
      "64/64 [==============================] - 0s 51us/step - loss: 20.7250 - accuracy: 0.0000e+00 - val_loss: 143.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 8740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8280 - accuracy: 0.0156 - val_loss: 136.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 8741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1614 - accuracy: 0.0000e+00 - val_loss: 133.3780 - val_accuracy: 0.0000e+00\n",
      "Epoch 8742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.2214 - accuracy: 0.0156 - val_loss: 135.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 8743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5908 - accuracy: 0.0156 - val_loss: 140.7955 - val_accuracy: 0.0000e+00\n",
      "Epoch 8744/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 24.6073 - accuracy: 0.0000e+00 - val_loss: 143.5998 - val_accuracy: 0.0588\n",
      "Epoch 8745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0244 - accuracy: 0.0000e+00 - val_loss: 145.6035 - val_accuracy: 0.0588\n",
      "Epoch 8746/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.4606 - accuracy: 0.0000e+00 - val_loss: 145.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 8747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0436 - accuracy: 0.0156 - val_loss: 139.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 8748/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5448 - accuracy: 0.0156 - val_loss: 134.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 8749/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6056 - accuracy: 0.0000e+00 - val_loss: 135.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 8750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9742 - accuracy: 0.0156 - val_loss: 132.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 8751/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.1211 - accuracy: 0.0312 - val_loss: 130.9894 - val_accuracy: 0.0000e+00\n",
      "Epoch 8752/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.4775 - accuracy: 0.0156 - val_loss: 129.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 8753/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3827 - accuracy: 0.0000e+00 - val_loss: 125.6117 - val_accuracy: 0.0000e+00\n",
      "Epoch 8754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7983 - accuracy: 0.0312 - val_loss: 124.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1073 - accuracy: 0.0000e+00 - val_loss: 123.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 8756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0856 - accuracy: 0.0156 - val_loss: 123.7493 - val_accuracy: 0.0000e+00\n",
      "Epoch 8757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5011 - accuracy: 0.0000e+00 - val_loss: 121.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 8758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4223 - accuracy: 0.0000e+00 - val_loss: 114.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 8759/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 14.7593 - accuracy: 0.0000e+00 - val_loss: 108.4144 - val_accuracy: 0.0000e+00\n",
      "Epoch 8760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4709 - accuracy: 0.0000e+00 - val_loss: 114.2739 - val_accuracy: 0.0000e+00\n",
      "Epoch 8761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8954 - accuracy: 0.0000e+00 - val_loss: 129.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 8762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4476 - accuracy: 0.0156 - val_loss: 140.1415 - val_accuracy: 0.0000e+00\n",
      "Epoch 8763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8612 - accuracy: 0.0312 - val_loss: 147.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1012 - accuracy: 0.0156 - val_loss: 150.9262 - val_accuracy: 0.0000e+00\n",
      "Epoch 8765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3370 - accuracy: 0.0156 - val_loss: 151.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 8766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9940 - accuracy: 0.0000e+00 - val_loss: 152.2395 - val_accuracy: 0.0588\n",
      "Epoch 8767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0791 - accuracy: 0.0156 - val_loss: 150.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 8768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2437 - accuracy: 0.0000e+00 - val_loss: 146.5699 - val_accuracy: 0.0000e+00\n",
      "Epoch 8769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1730 - accuracy: 0.0156 - val_loss: 137.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 8770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3285 - accuracy: 0.0000e+00 - val_loss: 137.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 8771/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4944 - accuracy: 0.0156 - val_loss: 139.9362 - val_accuracy: 0.0588\n",
      "Epoch 8772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1061 - accuracy: 0.0000e+00 - val_loss: 140.2988 - val_accuracy: 0.0588\n",
      "Epoch 8773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2021 - accuracy: 0.0156 - val_loss: 144.2534 - val_accuracy: 0.0588\n",
      "Epoch 8774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2173 - accuracy: 0.0000e+00 - val_loss: 142.6398 - val_accuracy: 0.0588\n",
      "Epoch 8775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8955 - accuracy: 0.0000e+00 - val_loss: 134.8418 - val_accuracy: 0.0588\n",
      "Epoch 8776/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1993 - accuracy: 0.0000e+00 - val_loss: 127.3033 - val_accuracy: 0.0588\n",
      "Epoch 8777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8370 - accuracy: 0.0000e+00 - val_loss: 126.4538 - val_accuracy: 0.0588\n",
      "Epoch 8778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0826 - accuracy: 0.0000e+00 - val_loss: 134.6451 - val_accuracy: 0.0588\n",
      "Epoch 8779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2655 - accuracy: 0.0156 - val_loss: 138.9734 - val_accuracy: 0.0588\n",
      "Epoch 8780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6437 - accuracy: 0.0156 - val_loss: 143.6518 - val_accuracy: 0.0000e+00\n",
      "Epoch 8781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7397 - accuracy: 0.0000e+00 - val_loss: 143.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2513 - accuracy: 0.0156 - val_loss: 140.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8783/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 15.4646 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 15.8493 - accuracy: 0.0000e+00 - val_loss: 135.5559 - val_accuracy: 0.0588\n",
      "Epoch 8784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5907 - accuracy: 0.0312 - val_loss: 131.7301 - val_accuracy: 0.0588\n",
      "Epoch 8785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0046 - accuracy: 0.0156 - val_loss: 131.2042 - val_accuracy: 0.0000e+00\n",
      "Epoch 8786/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.8430 - accuracy: 0.0000e+00 - val_loss: 128.5295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6289 - accuracy: 0.0312 - val_loss: 130.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 8788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1169 - accuracy: 0.0156 - val_loss: 129.2793 - val_accuracy: 0.0000e+00\n",
      "Epoch 8789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9688 - accuracy: 0.0000e+00 - val_loss: 128.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4332 - accuracy: 0.0000e+00 - val_loss: 124.3208 - val_accuracy: 0.0588\n",
      "Epoch 8791/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6948 - accuracy: 0.0000e+00 - val_loss: 129.3971 - val_accuracy: 0.0000e+00\n",
      "Epoch 8792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1448 - accuracy: 0.0156 - val_loss: 137.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 8793/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 19.4860 - accuracy: 0.0000e+00 - val_loss: 142.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 8794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9871 - accuracy: 0.0312 - val_loss: 143.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1219 - accuracy: 0.0000e+00 - val_loss: 150.7048 - val_accuracy: 0.0588\n",
      "Epoch 8796/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 14.4373 - accuracy: 0.0156 - val_loss: 150.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 8797/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8456 - accuracy: 0.0312 - val_loss: 148.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 8798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2902 - accuracy: 0.0469 - val_loss: 147.6505 - val_accuracy: 0.0588\n",
      "Epoch 8799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5728 - accuracy: 0.0156 - val_loss: 146.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7045 - accuracy: 0.0000e+00 - val_loss: 146.9356 - val_accuracy: 0.0000e+00\n",
      "Epoch 8801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3208 - accuracy: 0.0000e+00 - val_loss: 152.8539 - val_accuracy: 0.0588\n",
      "Epoch 8802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1414 - accuracy: 0.0156 - val_loss: 150.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 8803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.0799 - accuracy: 0.0156 - val_loss: 144.2081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8804/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.3688 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 22.1512 - accuracy: 0.0000e+00 - val_loss: 137.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 8805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4476 - accuracy: 0.0156 - val_loss: 131.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 8806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6627 - accuracy: 0.0000e+00 - val_loss: 122.9221 - val_accuracy: 0.0588\n",
      "Epoch 8807/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8526 - accuracy: 0.0312 - val_loss: 120.6670 - val_accuracy: 0.0588\n",
      "Epoch 8808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1585 - accuracy: 0.0000e+00 - val_loss: 123.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 8809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4143 - accuracy: 0.0312 - val_loss: 124.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 8810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7240 - accuracy: 0.0469 - val_loss: 128.6539 - val_accuracy: 0.0000e+00\n",
      "Epoch 8811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.3341 - accuracy: 0.0469 - val_loss: 138.5213 - val_accuracy: 0.0000e+00\n",
      "Epoch 8812/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 22.0315 - accuracy: 0.0312 - val_loss: 149.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 8813/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 20.4366 - accuracy: 0.0312 - val_loss: 144.3914 - val_accuracy: 0.0000e+00\n",
      "Epoch 8814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2889 - accuracy: 0.0312 - val_loss: 133.5616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8815/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4395 - accuracy: 0.0156 - val_loss: 126.6192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5573 - accuracy: 0.0312 - val_loss: 121.3169 - val_accuracy: 0.0588\n",
      "Epoch 8817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7619 - accuracy: 0.0156 - val_loss: 127.8314 - val_accuracy: 0.0588\n",
      "Epoch 8818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4448 - accuracy: 0.0156 - val_loss: 141.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 8819/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8507 - accuracy: 0.0156 - val_loss: 145.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 8820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8933 - accuracy: 0.0000e+00 - val_loss: 131.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 8821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7300 - accuracy: 0.0000e+00 - val_loss: 127.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7168 - accuracy: 0.0000e+00 - val_loss: 127.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 8823/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8517 - accuracy: 0.0000e+00 - val_loss: 130.3436 - val_accuracy: 0.0000e+00\n",
      "Epoch 8824/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5187 - accuracy: 0.0000e+00 - val_loss: 129.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 8825/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 24.2059 - accuracy: 0.0000e+00 - val_loss: 134.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9926 - accuracy: 0.0156 - val_loss: 132.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 8827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2290 - accuracy: 0.0312 - val_loss: 134.0011 - val_accuracy: 0.0588\n",
      "Epoch 8828/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9447 - accuracy: 0.0000e+00 - val_loss: 139.9222 - val_accuracy: 0.0588\n",
      "Epoch 8829/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.1819 - accuracy: 0.0312 - val_loss: 146.7084 - val_accuracy: 0.0588\n",
      "Epoch 8830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7033 - accuracy: 0.0000e+00 - val_loss: 148.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 8831/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.2357 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 15.9500 - accuracy: 0.0000e+00 - val_loss: 152.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 8832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2837 - accuracy: 0.0000e+00 - val_loss: 149.7266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8833/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.6450 - accuracy: 0.0000e+00 - val_loss: 139.8057 - val_accuracy: 0.0000e+00\n",
      "Epoch 8834/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 22.3431 - accuracy: 0.0156 - val_loss: 131.3194 - val_accuracy: 0.0588\n",
      "Epoch 8835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6860 - accuracy: 0.0000e+00 - val_loss: 127.7590 - val_accuracy: 0.1176\n",
      "Epoch 8836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5044 - accuracy: 0.0000e+00 - val_loss: 127.4060 - val_accuracy: 0.0588\n",
      "Epoch 8837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2797 - accuracy: 0.0156 - val_loss: 129.2534 - val_accuracy: 0.0000e+00\n",
      "Epoch 8838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9858 - accuracy: 0.0000e+00 - val_loss: 135.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 8839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2110 - accuracy: 0.0000e+00 - val_loss: 135.0910 - val_accuracy: 0.0588\n",
      "Epoch 8840/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0553 - accuracy: 0.0000e+00 - val_loss: 128.8745 - val_accuracy: 0.0000e+00\n",
      "Epoch 8841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8099 - accuracy: 0.0000e+00 - val_loss: 121.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 8842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6030 - accuracy: 0.0156 - val_loss: 118.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 8843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4409 - accuracy: 0.0312 - val_loss: 121.9478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0272 - accuracy: 0.0000e+00 - val_loss: 129.3598 - val_accuracy: 0.0000e+00\n",
      "Epoch 8845/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 14.6913 - accuracy: 0.0000e+00 - val_loss: 130.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 8846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9187 - accuracy: 0.0156 - val_loss: 128.3500 - val_accuracy: 0.0000e+00\n",
      "Epoch 8847/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.7741 - accuracy: 0.0156 - val_loss: 129.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6523 - accuracy: 0.0000e+00 - val_loss: 130.4498 - val_accuracy: 0.0588\n",
      "Epoch 8849/10000\n",
      "64/64 [==============================] - 0s 173us/step - loss: 18.0407 - accuracy: 0.0312 - val_loss: 134.2806 - val_accuracy: 0.0000e+00\n",
      "Epoch 8850/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 18.9879 - accuracy: 0.0000e+00 - val_loss: 137.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 8851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5896 - accuracy: 0.0156 - val_loss: 130.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 8852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2857 - accuracy: 0.0156 - val_loss: 125.6912 - val_accuracy: 0.0000e+00\n",
      "Epoch 8853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8206 - accuracy: 0.0156 - val_loss: 123.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 8854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5848 - accuracy: 0.0000e+00 - val_loss: 128.2538 - val_accuracy: 0.0588\n",
      "Epoch 8855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4376 - accuracy: 0.0000e+00 - val_loss: 135.0170 - val_accuracy: 0.0588\n",
      "Epoch 8856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7623 - accuracy: 0.0156 - val_loss: 137.5561 - val_accuracy: 0.0588\n",
      "Epoch 8857/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5357 - accuracy: 0.0156 - val_loss: 142.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 8858/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 13.8121 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 18.0569 - accuracy: 0.0000e+00 - val_loss: 146.6063 - val_accuracy: 0.0000e+00\n",
      "Epoch 8859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1379 - accuracy: 0.0156 - val_loss: 152.2328 - val_accuracy: 0.0000e+00\n",
      "Epoch 8860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0567 - accuracy: 0.0000e+00 - val_loss: 151.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 8861/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 25.3644 - accuracy: 0.0000e+00 - val_loss: 141.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 8862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.8251 - accuracy: 0.0000e+00 - val_loss: 131.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 8863/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 20.3887 - accuracy: 0.0000e+00 - val_loss: 126.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 8864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8255 - accuracy: 0.0312 - val_loss: 128.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 8865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1267 - accuracy: 0.0000e+00 - val_loss: 133.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 8866/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.5766 - accuracy: 0.0000e+00 - val_loss: 144.0611 - val_accuracy: 0.0588\n",
      "Epoch 8867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5726 - accuracy: 0.0000e+00 - val_loss: 154.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 8868/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 20.9742 - accuracy: 0.0000e+00 - val_loss: 153.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 8869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9639 - accuracy: 0.0000e+00 - val_loss: 144.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 8870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3708 - accuracy: 0.0312 - val_loss: 135.7619 - val_accuracy: 0.0588\n",
      "Epoch 8871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4321 - accuracy: 0.0156 - val_loss: 130.2551 - val_accuracy: 0.0588\n",
      "Epoch 8872/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.6723 - accuracy: 0.0156 - val_loss: 134.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4789 - accuracy: 0.0156 - val_loss: 138.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 8874/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.7967 - accuracy: 0.0312 - val_loss: 144.4636 - val_accuracy: 0.0000e+00\n",
      "Epoch 8875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2510 - accuracy: 0.0156 - val_loss: 152.1429 - val_accuracy: 0.0588\n",
      "Epoch 8876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2104 - accuracy: 0.0312 - val_loss: 154.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4076 - accuracy: 0.0625 - val_loss: 150.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 8878/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 18.6508 - accuracy: 0.0000e+00 - val_loss: 143.1058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8879/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9552 - accuracy: 0.0000e+00 - val_loss: 136.8464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7646 - accuracy: 0.0000e+00 - val_loss: 136.5346 - val_accuracy: 0.0000e+00\n",
      "Epoch 8881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0606 - accuracy: 0.0156 - val_loss: 136.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 8882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9116 - accuracy: 0.0000e+00 - val_loss: 140.6062 - val_accuracy: 0.0000e+00\n",
      "Epoch 8883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4877 - accuracy: 0.0000e+00 - val_loss: 130.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 8884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4675 - accuracy: 0.0000e+00 - val_loss: 130.9667 - val_accuracy: 0.0588\n",
      "Epoch 8885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7898 - accuracy: 0.0156 - val_loss: 131.9460 - val_accuracy: 0.0588\n",
      "Epoch 8886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4329 - accuracy: 0.0000e+00 - val_loss: 144.1266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8887/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.3875 - accuracy: 0.0312 - val_loss: 152.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3275 - accuracy: 0.0000e+00 - val_loss: 153.2636 - val_accuracy: 0.0000e+00\n",
      "Epoch 8889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4645 - accuracy: 0.0156 - val_loss: 151.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 8890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2829 - accuracy: 0.0000e+00 - val_loss: 142.1028 - val_accuracy: 0.0588\n",
      "Epoch 8891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3299 - accuracy: 0.0156 - val_loss: 132.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 8892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1552 - accuracy: 0.0312 - val_loss: 132.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 8893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9308 - accuracy: 0.0156 - val_loss: 138.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4805 - accuracy: 0.0312 - val_loss: 142.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 8895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7445 - accuracy: 0.0000e+00 - val_loss: 143.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 8896/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.7024 - accuracy: 0.0312 - val_loss: 141.7299 - val_accuracy: 0.0000e+00\n",
      "Epoch 8897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2616 - accuracy: 0.0156 - val_loss: 137.8324 - val_accuracy: 0.0000e+00\n",
      "Epoch 8898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0217 - accuracy: 0.0156 - val_loss: 135.3669 - val_accuracy: 0.0000e+00\n",
      "Epoch 8899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3970 - accuracy: 0.0000e+00 - val_loss: 135.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 8900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4955 - accuracy: 0.0156 - val_loss: 141.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8901/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.3322 - accuracy: 0.0156 - val_loss: 140.1265 - val_accuracy: 0.0000e+00\n",
      "Epoch 8902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1424 - accuracy: 0.0000e+00 - val_loss: 138.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7282 - accuracy: 0.0000e+00 - val_loss: 131.5370 - val_accuracy: 0.0000e+00\n",
      "Epoch 8904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1647 - accuracy: 0.0000e+00 - val_loss: 125.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 8905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0969 - accuracy: 0.0000e+00 - val_loss: 121.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 8906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4179 - accuracy: 0.0156 - val_loss: 126.2774 - val_accuracy: 0.0000e+00\n",
      "Epoch 8907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8817 - accuracy: 0.0156 - val_loss: 124.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 8908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2997 - accuracy: 0.0000e+00 - val_loss: 122.2124 - val_accuracy: 0.0588\n",
      "Epoch 8909/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9133 - accuracy: 0.0156 - val_loss: 135.1053 - val_accuracy: 0.0588\n",
      "Epoch 8910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2096 - accuracy: 0.0000e+00 - val_loss: 146.7531 - val_accuracy: 0.0588\n",
      "Epoch 8911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5717 - accuracy: 0.0312 - val_loss: 147.1231 - val_accuracy: 0.0588\n",
      "Epoch 8912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8292 - accuracy: 0.0156 - val_loss: 141.5193 - val_accuracy: 0.0588\n",
      "Epoch 8913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4189 - accuracy: 0.0312 - val_loss: 132.0590 - val_accuracy: 0.0588\n",
      "Epoch 8914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.0142 - accuracy: 0.0312 - val_loss: 130.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3170 - accuracy: 0.0000e+00 - val_loss: 141.4066 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3963 - accuracy: 0.0156 - val_loss: 147.8392 - val_accuracy: 0.0000e+00\n",
      "Epoch 8917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2927 - accuracy: 0.0156 - val_loss: 148.0003 - val_accuracy: 0.0000e+00\n",
      "Epoch 8918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7820 - accuracy: 0.0000e+00 - val_loss: 140.5433 - val_accuracy: 0.0588\n",
      "Epoch 8919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6207 - accuracy: 0.0000e+00 - val_loss: 133.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 8920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1840 - accuracy: 0.0156 - val_loss: 125.3458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7093 - accuracy: 0.0156 - val_loss: 124.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 8922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0568 - accuracy: 0.0000e+00 - val_loss: 127.9586 - val_accuracy: 0.0000e+00\n",
      "Epoch 8923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4182 - accuracy: 0.0000e+00 - val_loss: 133.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 8924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6655 - accuracy: 0.0156 - val_loss: 134.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 8925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0788 - accuracy: 0.0000e+00 - val_loss: 133.4406 - val_accuracy: 0.0000e+00\n",
      "Epoch 8926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8707 - accuracy: 0.0156 - val_loss: 127.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2133 - accuracy: 0.0156 - val_loss: 121.5307 - val_accuracy: 0.0000e+00\n",
      "Epoch 8928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0166 - accuracy: 0.0312 - val_loss: 124.9939 - val_accuracy: 0.0000e+00\n",
      "Epoch 8929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.8764 - accuracy: 0.0156 - val_loss: 136.7416 - val_accuracy: 0.0000e+00\n",
      "Epoch 8930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2696 - accuracy: 0.0156 - val_loss: 138.3273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8931/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5208 - accuracy: 0.0000e+00 - val_loss: 139.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 8932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9736 - accuracy: 0.0156 - val_loss: 145.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8369 - accuracy: 0.0000e+00 - val_loss: 141.5670 - val_accuracy: 0.0588\n",
      "Epoch 8934/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9325 - accuracy: 0.0156 - val_loss: 136.4327 - val_accuracy: 0.1176\n",
      "Epoch 8935/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 14.0982 - accuracy: 0.0156 - val_loss: 130.7528 - val_accuracy: 0.0000e+00\n",
      "Epoch 8936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2098 - accuracy: 0.0000e+00 - val_loss: 133.4066 - val_accuracy: 0.0588\n",
      "Epoch 8937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9925 - accuracy: 0.0312 - val_loss: 140.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 8938/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.1861 - accuracy: 0.0156 - val_loss: 146.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 8939/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.5373 - accuracy: 0.0156 - val_loss: 149.0652 - val_accuracy: 0.0588\n",
      "Epoch 8940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0602 - accuracy: 0.0156 - val_loss: 146.8297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8941/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3713 - accuracy: 0.0000e+00 - val_loss: 142.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 8942/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.9367 - accuracy: 0.0469 - val_loss: 140.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 8943/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.2033 - accuracy: 0.0000e+00 - val_loss: 140.0783 - val_accuracy: 0.0000e+00\n",
      "Epoch 8944/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 17.9846 - accuracy: 0.0156 - val_loss: 141.9552 - val_accuracy: 0.0000e+00\n",
      "Epoch 8945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8777 - accuracy: 0.0000e+00 - val_loss: 142.1947 - val_accuracy: 0.0000e+00\n",
      "Epoch 8946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2123 - accuracy: 0.0000e+00 - val_loss: 141.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 8947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0184 - accuracy: 0.0000e+00 - val_loss: 140.7250 - val_accuracy: 0.0000e+00\n",
      "Epoch 8948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5554 - accuracy: 0.0000e+00 - val_loss: 140.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 8949/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.0597 - accuracy: 0.0000e+00 - val_loss: 140.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 8950/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3370 - accuracy: 0.0156 - val_loss: 142.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7497 - accuracy: 0.0469 - val_loss: 142.8139 - val_accuracy: 0.0000e+00\n",
      "Epoch 8952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9317 - accuracy: 0.0156 - val_loss: 141.6998 - val_accuracy: 0.0588\n",
      "Epoch 8953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9560 - accuracy: 0.0000e+00 - val_loss: 142.4237 - val_accuracy: 0.0588\n",
      "Epoch 8954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2277 - accuracy: 0.0156 - val_loss: 143.8878 - val_accuracy: 0.0588\n",
      "Epoch 8955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7790 - accuracy: 0.0156 - val_loss: 147.9512 - val_accuracy: 0.0588\n",
      "Epoch 8956/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 13.2005 - accuracy: 0.0156 - val_loss: 148.8628 - val_accuracy: 0.0588\n",
      "Epoch 8957/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 24.1836 - accuracy: 0.0156 - val_loss: 144.6646 - val_accuracy: 0.0588\n",
      "Epoch 8958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5944 - accuracy: 0.0000e+00 - val_loss: 138.2923 - val_accuracy: 0.0000e+00\n",
      "Epoch 8959/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.0487 - accuracy: 0.0156 - val_loss: 137.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8960/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 24.9088 - accuracy: 0.0156 - val_loss: 135.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 8961/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.0677 - accuracy: 0.0156 - val_loss: 133.8566 - val_accuracy: 0.0000e+00\n",
      "Epoch 8962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.5256 - accuracy: 0.0156 - val_loss: 132.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 8963/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.6067 - accuracy: 0.0625 - val_loss: 133.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8964/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.1865 - accuracy: 0.0000e+00 - val_loss: 136.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0546 - accuracy: 0.0000e+00 - val_loss: 134.7499 - val_accuracy: 0.0000e+00\n",
      "Epoch 8966/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.7897 - accuracy: 0.0000e+00 - val_loss: 132.3030 - val_accuracy: 0.0000e+00\n",
      "Epoch 8967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4402 - accuracy: 0.0000e+00 - val_loss: 130.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 8968/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.3876 - accuracy: 0.0000e+00 - val_loss: 127.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 8969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6264 - accuracy: 0.0000e+00 - val_loss: 131.0553 - val_accuracy: 0.0000e+00\n",
      "Epoch 8970/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.9527 - accuracy: 0.0156 - val_loss: 129.8499 - val_accuracy: 0.0000e+00\n",
      "Epoch 8971/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 19.5209 - accuracy: 0.0156 - val_loss: 130.3101 - val_accuracy: 0.0000e+00\n",
      "Epoch 8972/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8949 - accuracy: 0.0156 - val_loss: 130.2718 - val_accuracy: 0.0000e+00\n",
      "Epoch 8973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6964 - accuracy: 0.0000e+00 - val_loss: 129.9048 - val_accuracy: 0.0000e+00\n",
      "Epoch 8974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0620 - accuracy: 0.0000e+00 - val_loss: 124.0451 - val_accuracy: 0.0000e+00\n",
      "Epoch 8975/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.6295 - accuracy: 0.0156 - val_loss: 118.7846 - val_accuracy: 0.0000e+00\n",
      "Epoch 8976/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.3306 - accuracy: 0.0000e+00 - val_loss: 118.2905 - val_accuracy: 0.0000e+00\n",
      "Epoch 8977/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7306 - accuracy: 0.0156 - val_loss: 120.3235 - val_accuracy: 0.0588\n",
      "Epoch 8978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2782 - accuracy: 0.0156 - val_loss: 130.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8979/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.4717 - accuracy: 0.0156 - val_loss: 127.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 8980/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 17.9339 - accuracy: 0.0000e+00 - val_loss: 121.3886 - val_accuracy: 0.0000e+00\n",
      "Epoch 8981/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 17.3842 - accuracy: 0.0000e+00 - val_loss: 120.9884 - val_accuracy: 0.0588\n",
      "Epoch 8982/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7609 - accuracy: 0.0000e+00 - val_loss: 122.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 8983/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 21.5189 - accuracy: 0.0469 - val_loss: 126.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 8984/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 30.6548 - accuracy: 0.0156 - val_loss: 127.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 8985/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.7010 - accuracy: 0.0000e+00 - val_loss: 122.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8986/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 26.5777 - accuracy: 0.0156 - val_loss: 118.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8987/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.4758 - accuracy: 0.0000e+00 - val_loss: 111.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 8988/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 23.6619 - accuracy: 0.0000e+00 - val_loss: 101.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 8989/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 18.3265 - accuracy: 0.0156 - val_loss: 94.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3493 - accuracy: 0.0312 - val_loss: 95.4963 - val_accuracy: 0.0000e+00\n",
      "Epoch 8991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9844 - accuracy: 0.0000e+00 - val_loss: 112.8972 - val_accuracy: 0.0000e+00\n",
      "Epoch 8992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0206 - accuracy: 0.0156 - val_loss: 126.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 8993/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.0627 - accuracy: 0.0312 - val_loss: 127.9537 - val_accuracy: 0.0000e+00\n",
      "Epoch 8994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5796 - accuracy: 0.0156 - val_loss: 129.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 8995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2339 - accuracy: 0.0156 - val_loss: 133.5199 - val_accuracy: 0.0000e+00\n",
      "Epoch 8996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3927 - accuracy: 0.0000e+00 - val_loss: 130.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 8997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1095 - accuracy: 0.0312 - val_loss: 126.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 8998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0965 - accuracy: 0.0625 - val_loss: 124.6653 - val_accuracy: 0.0588\n",
      "Epoch 8999/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 28.1769 - accuracy: 0.0156 - val_loss: 123.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1892 - accuracy: 0.0000e+00 - val_loss: 123.4982 - val_accuracy: 0.0000e+00\n",
      "Epoch 9001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5693 - accuracy: 0.0000e+00 - val_loss: 128.3625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9002/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0579 - accuracy: 0.0000e+00 - val_loss: 133.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5617 - accuracy: 0.0000e+00 - val_loss: 137.7401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6348 - accuracy: 0.0312 - val_loss: 142.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3505 - accuracy: 0.0000e+00 - val_loss: 140.2296 - val_accuracy: 0.0000e+00\n",
      "Epoch 9006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0033 - accuracy: 0.0156 - val_loss: 136.9540 - val_accuracy: 0.0000e+00\n",
      "Epoch 9007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4103 - accuracy: 0.0000e+00 - val_loss: 139.4661 - val_accuracy: 0.0588\n",
      "Epoch 9008/10000\n",
      "64/64 [==============================] - 0s 180us/step - loss: 30.3362 - accuracy: 0.0000e+00 - val_loss: 142.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 9009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2796 - accuracy: 0.0156 - val_loss: 143.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 9010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1502 - accuracy: 0.0000e+00 - val_loss: 143.9660 - val_accuracy: 0.0000e+00\n",
      "Epoch 9011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9642 - accuracy: 0.0000e+00 - val_loss: 141.3200 - val_accuracy: 0.0588\n",
      "Epoch 9012/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 24.0164 - accuracy: 0.0000e+00 - val_loss: 140.3463 - val_accuracy: 0.0588\n",
      "Epoch 9013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3833 - accuracy: 0.0156 - val_loss: 135.7683 - val_accuracy: 0.0588\n",
      "Epoch 9014/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 14.3271 - accuracy: 0.0156 - val_loss: 132.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 9015/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.0966 - accuracy: 0.0000e+00 - val_loss: 130.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 9016/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.7380 - accuracy: 0.0000e+00 - val_loss: 129.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 9017/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 19.9014 - accuracy: 0.0156 - val_loss: 124.5891 - val_accuracy: 0.0000e+00\n",
      "Epoch 9018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7285 - accuracy: 0.0156 - val_loss: 119.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 9019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6837 - accuracy: 0.0156 - val_loss: 116.1132 - val_accuracy: 0.0000e+00\n",
      "Epoch 9020/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 25.9831 - accuracy: 0.0312 - val_loss: 119.0554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9021/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.8489 - accuracy: 0.0000e+00 - val_loss: 121.7586 - val_accuracy: 0.0000e+00\n",
      "Epoch 9022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8347 - accuracy: 0.0312 - val_loss: 129.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 9023/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.4531 - accuracy: 0.062 - 0s 63us/step - loss: 18.6684 - accuracy: 0.0312 - val_loss: 133.8648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3616 - accuracy: 0.0000e+00 - val_loss: 137.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7385 - accuracy: 0.0469 - val_loss: 133.9392 - val_accuracy: 0.0000e+00\n",
      "Epoch 9026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8045 - accuracy: 0.0156 - val_loss: 131.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 9027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1884 - accuracy: 0.0156 - val_loss: 135.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 9028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3074 - accuracy: 0.0156 - val_loss: 142.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9029/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9325 - accuracy: 0.0156 - val_loss: 150.2265 - val_accuracy: 0.0588\n",
      "Epoch 9030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1468 - accuracy: 0.0156 - val_loss: 152.5682 - val_accuracy: 0.0588\n",
      "Epoch 9031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3751 - accuracy: 0.0000e+00 - val_loss: 147.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9032/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0839 - accuracy: 0.0156 - val_loss: 140.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 9033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4561 - accuracy: 0.0156 - val_loss: 134.5242 - val_accuracy: 0.0000e+00\n",
      "Epoch 9034/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 25.3349 - accuracy: 0.0000e+00 - val_loss: 135.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 9035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1845 - accuracy: 0.0312 - val_loss: 134.3582 - val_accuracy: 0.0000e+00\n",
      "Epoch 9036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9644 - accuracy: 0.0156 - val_loss: 134.6169 - val_accuracy: 0.0588\n",
      "Epoch 9037/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.0445 - accuracy: 0.0156 - val_loss: 133.5201 - val_accuracy: 0.0588\n",
      "Epoch 9038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1755 - accuracy: 0.0156 - val_loss: 135.3144 - val_accuracy: 0.0588\n",
      "Epoch 9039/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.9708 - accuracy: 0.0156 - val_loss: 139.7181 - val_accuracy: 0.0588\n",
      "Epoch 9040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.8985 - accuracy: 0.0312 - val_loss: 145.9954 - val_accuracy: 0.0588\n",
      "Epoch 9041/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.2676 - accuracy: 0.0000e+00 - val_loss: 152.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 9042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7518 - accuracy: 0.0000e+00 - val_loss: 155.7883 - val_accuracy: 0.0000e+00\n",
      "Epoch 9043/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.9156 - accuracy: 0.0000e+00 - val_loss: 149.9744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8512 - accuracy: 0.0000e+00 - val_loss: 140.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9045/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1515 - accuracy: 0.0000e+00 - val_loss: 134.5240 - val_accuracy: 0.0000e+00\n",
      "Epoch 9046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9668 - accuracy: 0.0000e+00 - val_loss: 129.0334 - val_accuracy: 0.0000e+00\n",
      "Epoch 9047/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7917 - accuracy: 0.0156 - val_loss: 125.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 9048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9530 - accuracy: 0.0156 - val_loss: 125.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 9049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3506 - accuracy: 0.0312 - val_loss: 122.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 9050/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1353 - accuracy: 0.0000e+00 - val_loss: 118.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9051/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 21.8791 - accuracy: 0.0000e+00 - val_loss: 113.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5944 - accuracy: 0.0156 - val_loss: 109.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 9053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4874 - accuracy: 0.0156 - val_loss: 112.8452 - val_accuracy: 0.0000e+00\n",
      "Epoch 9054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9814 - accuracy: 0.0312 - val_loss: 123.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 9055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3479 - accuracy: 0.0312 - val_loss: 134.7316 - val_accuracy: 0.0000e+00\n",
      "Epoch 9056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1587 - accuracy: 0.0000e+00 - val_loss: 141.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 9057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1521 - accuracy: 0.0000e+00 - val_loss: 142.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 9058/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.0974 - accuracy: 0.0000e+00 - val_loss: 137.7370 - val_accuracy: 0.0588\n",
      "Epoch 9059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5347 - accuracy: 0.0000e+00 - val_loss: 129.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 9060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0491 - accuracy: 0.0000e+00 - val_loss: 120.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 9061/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 15.6772 - accuracy: 0.0469 - val_loss: 115.8161 - val_accuracy: 0.0588\n",
      "Epoch 9062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8669 - accuracy: 0.0312 - val_loss: 114.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2332 - accuracy: 0.0000e+00 - val_loss: 118.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2783 - accuracy: 0.0000e+00 - val_loss: 121.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 9065/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.9512 - accuracy: 0.0312 - val_loss: 125.1168 - val_accuracy: 0.0000e+00\n",
      "Epoch 9066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1266 - accuracy: 0.0156 - val_loss: 127.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 9067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6401 - accuracy: 0.0000e+00 - val_loss: 131.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 9068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4298 - accuracy: 0.0156 - val_loss: 134.6613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9062 - accuracy: 0.0312 - val_loss: 133.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 9070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5058 - accuracy: 0.0000e+00 - val_loss: 130.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 9071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8501 - accuracy: 0.0000e+00 - val_loss: 126.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 9072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9209 - accuracy: 0.0000e+00 - val_loss: 122.9018 - val_accuracy: 0.0000e+00\n",
      "Epoch 9073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7246 - accuracy: 0.0156 - val_loss: 119.3527 - val_accuracy: 0.0000e+00\n",
      "Epoch 9074/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7760 - accuracy: 0.0000e+00 - val_loss: 119.5246 - val_accuracy: 0.0000e+00\n",
      "Epoch 9075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0778 - accuracy: 0.0156 - val_loss: 117.7117 - val_accuracy: 0.0000e+00\n",
      "Epoch 9076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8017 - accuracy: 0.0000e+00 - val_loss: 119.9610 - val_accuracy: 0.0000e+00\n",
      "Epoch 9077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9683 - accuracy: 0.0312 - val_loss: 123.8727 - val_accuracy: 0.0000e+00\n",
      "Epoch 9078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3442 - accuracy: 0.0156 - val_loss: 122.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5844 - accuracy: 0.0312 - val_loss: 118.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 9080/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7807 - accuracy: 0.0156 - val_loss: 123.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 9081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5575 - accuracy: 0.0156 - val_loss: 134.6869 - val_accuracy: 0.0588\n",
      "Epoch 9082/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 20.6194 - accuracy: 0.0156 - val_loss: 145.6139 - val_accuracy: 0.0588\n",
      "Epoch 9083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0932 - accuracy: 0.0156 - val_loss: 149.5190 - val_accuracy: 0.0588\n",
      "Epoch 9084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5277 - accuracy: 0.0312 - val_loss: 150.7205 - val_accuracy: 0.0588\n",
      "Epoch 9085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7659 - accuracy: 0.0156 - val_loss: 151.9962 - val_accuracy: 0.0588\n",
      "Epoch 9086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1633 - accuracy: 0.0312 - val_loss: 149.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 9087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2934 - accuracy: 0.0000e+00 - val_loss: 137.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2497 - accuracy: 0.0156 - val_loss: 129.0469 - val_accuracy: 0.0588\n",
      "Epoch 9089/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.2633 - accuracy: 0.0000e+00 - val_loss: 130.1326 - val_accuracy: 0.0588\n",
      "Epoch 9090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0686 - accuracy: 0.0000e+00 - val_loss: 134.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8629 - accuracy: 0.0156 - val_loss: 134.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9092/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 18.3699 - accuracy: 0.0000e+00 - val_loss: 129.5869 - val_accuracy: 0.0588\n",
      "Epoch 9093/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 16.4292 - accuracy: 0.0000e+00 - val_loss: 125.0244 - val_accuracy: 0.0588\n",
      "Epoch 9094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3378 - accuracy: 0.0312 - val_loss: 123.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 9095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8432 - accuracy: 0.0156 - val_loss: 124.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 9096/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 20.0608 - accuracy: 0.0156 - val_loss: 136.5533 - val_accuracy: 0.0000e+00\n",
      "Epoch 9097/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 12.5297 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 18.8978 - accuracy: 0.0156 - val_loss: 146.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 9098/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5897 - accuracy: 0.0000e+00 - val_loss: 153.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 9099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6926 - accuracy: 0.0000e+00 - val_loss: 148.2803 - val_accuracy: 0.0000e+00\n",
      "Epoch 9100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0580 - accuracy: 0.0156 - val_loss: 136.2826 - val_accuracy: 0.0000e+00\n",
      "Epoch 9101/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.0137 - accuracy: 0.0156 - val_loss: 130.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 9102/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 16.0262 - accuracy: 0.0312 - val_loss: 126.6494 - val_accuracy: 0.0000e+00\n",
      "Epoch 9103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4908 - accuracy: 0.0000e+00 - val_loss: 131.2306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9734 - accuracy: 0.0000e+00 - val_loss: 140.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9105/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4809 - accuracy: 0.0000e+00 - val_loss: 149.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 9106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9863 - accuracy: 0.0000e+00 - val_loss: 152.8192 - val_accuracy: 0.0000e+00\n",
      "Epoch 9107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7456 - accuracy: 0.0156 - val_loss: 148.3455 - val_accuracy: 0.0000e+00\n",
      "Epoch 9108/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.3034 - accuracy: 0.0156 - val_loss: 138.9714 - val_accuracy: 0.0000e+00\n",
      "Epoch 9109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3013 - accuracy: 0.0000e+00 - val_loss: 130.1015 - val_accuracy: 0.0000e+00\n",
      "Epoch 9110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2398 - accuracy: 0.0156 - val_loss: 119.6441 - val_accuracy: 0.0588\n",
      "Epoch 9111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8428 - accuracy: 0.0000e+00 - val_loss: 120.7127 - val_accuracy: 0.0588\n",
      "Epoch 9112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6085 - accuracy: 0.0156 - val_loss: 134.5656 - val_accuracy: 0.0588\n",
      "Epoch 9113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9952 - accuracy: 0.0156 - val_loss: 148.2208 - val_accuracy: 0.0000e+00\n",
      "Epoch 9114/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 23.6682 - accuracy: 0.0156 - val_loss: 157.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 9115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1108 - accuracy: 0.0156 - val_loss: 155.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 9116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9859 - accuracy: 0.0000e+00 - val_loss: 145.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 9117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6658 - accuracy: 0.0312 - val_loss: 130.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8892 - accuracy: 0.0000e+00 - val_loss: 122.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 9119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3818 - accuracy: 0.0000e+00 - val_loss: 124.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 9120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0891 - accuracy: 0.0156 - val_loss: 128.5236 - val_accuracy: 0.0588\n",
      "Epoch 9121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0110 - accuracy: 0.0156 - val_loss: 131.2062 - val_accuracy: 0.0588\n",
      "Epoch 9122/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 24.6775 - accuracy: 0.0156 - val_loss: 132.9313 - val_accuracy: 0.0588\n",
      "Epoch 9123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8594 - accuracy: 0.0156 - val_loss: 133.8504 - val_accuracy: 0.0588\n",
      "Epoch 9124/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 33.4386 - accuracy: 0.0156 - val_loss: 129.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 9125/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 14.4002 - accuracy: 0.0000e+00 - val_loss: 125.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4334 - accuracy: 0.0312 - val_loss: 131.5337 - val_accuracy: 0.0000e+00\n",
      "Epoch 9127/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 12.9735 - accuracy: 0.0000e+00 - val_loss: 136.6682 - val_accuracy: 0.0000e+00\n",
      "Epoch 9128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1460 - accuracy: 0.0000e+00 - val_loss: 146.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 9129/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4290 - accuracy: 0.0156 - val_loss: 154.4544 - val_accuracy: 0.0000e+00\n",
      "Epoch 9130/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8479 - accuracy: 0.0156 - val_loss: 150.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 9131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3230 - accuracy: 0.0156 - val_loss: 144.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1351 - accuracy: 0.0000e+00 - val_loss: 130.7664 - val_accuracy: 0.0000e+00\n",
      "Epoch 9133/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 21.1832 - accuracy: 0.0000e+00 - val_loss: 126.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9134/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 25.9946 - accuracy: 0.0469 - val_loss: 126.7924 - val_accuracy: 0.1176\n",
      "Epoch 9135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3589 - accuracy: 0.0000e+00 - val_loss: 135.9055 - val_accuracy: 0.0588\n",
      "Epoch 9136/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4183 - accuracy: 0.0156 - val_loss: 141.8177 - val_accuracy: 0.0588\n",
      "Epoch 9137/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8786 - accuracy: 0.0156 - val_loss: 146.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7636 - accuracy: 0.0156 - val_loss: 149.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 9139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3411 - accuracy: 0.0312 - val_loss: 144.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3231 - accuracy: 0.0312 - val_loss: 138.3936 - val_accuracy: 0.0588\n",
      "Epoch 9141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.8814 - accuracy: 0.0156 - val_loss: 133.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 9142/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 17.8955 - accuracy: 0.0000e+00 - val_loss: 127.9374 - val_accuracy: 0.0000e+00\n",
      "Epoch 9143/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7067 - accuracy: 0.0156 - val_loss: 126.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 9144/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 27.1850 - accuracy: 0.0000e+00 - val_loss: 129.3273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9145/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0602 - accuracy: 0.0000e+00 - val_loss: 132.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 9146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.0793 - accuracy: 0.0469 - val_loss: 133.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9147/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 25.7463 - accuracy: 0.0156 - val_loss: 132.5675 - val_accuracy: 0.0000e+00\n",
      "Epoch 9148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7931 - accuracy: 0.0000e+00 - val_loss: 126.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 9149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9821 - accuracy: 0.0156 - val_loss: 124.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 9150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2737 - accuracy: 0.0000e+00 - val_loss: 124.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 9151/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.2914 - accuracy: 0.0156 - val_loss: 128.0143 - val_accuracy: 0.0588\n",
      "Epoch 9152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0717 - accuracy: 0.0000e+00 - val_loss: 133.6858 - val_accuracy: 0.0588\n",
      "Epoch 9153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6253 - accuracy: 0.0000e+00 - val_loss: 142.4562 - val_accuracy: 0.0588\n",
      "Epoch 9154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0641 - accuracy: 0.0156 - val_loss: 141.1298 - val_accuracy: 0.0588\n",
      "Epoch 9155/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 22.3120 - accuracy: 0.0312 - val_loss: 141.0293 - val_accuracy: 0.0588\n",
      "Epoch 9156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9985 - accuracy: 0.0156 - val_loss: 139.3384 - val_accuracy: 0.0588\n",
      "Epoch 9157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3281 - accuracy: 0.0000e+00 - val_loss: 140.0095 - val_accuracy: 0.0588\n",
      "Epoch 9158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3373 - accuracy: 0.0156 - val_loss: 138.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 9159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5527 - accuracy: 0.0156 - val_loss: 130.6087 - val_accuracy: 0.0000e+00\n",
      "Epoch 9160/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8649 - accuracy: 0.0156 - val_loss: 126.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3651 - accuracy: 0.0000e+00 - val_loss: 127.6725 - val_accuracy: 0.0588\n",
      "Epoch 9162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5077 - accuracy: 0.0156 - val_loss: 127.1030 - val_accuracy: 0.1176\n",
      "Epoch 9163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8297 - accuracy: 0.0000e+00 - val_loss: 129.7136 - val_accuracy: 0.1176\n",
      "Epoch 9164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0253 - accuracy: 0.0000e+00 - val_loss: 130.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 9165/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 14.7069 - accuracy: 0.0000e+00 - val_loss: 130.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 9166/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 20.2370 - accuracy: 0.0000e+00 - val_loss: 128.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9167/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 26.5539 - accuracy: 0.0156 - val_loss: 124.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 9168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9507 - accuracy: 0.0000e+00 - val_loss: 126.3337 - val_accuracy: 0.0000e+00\n",
      "Epoch 9169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7139 - accuracy: 0.0000e+00 - val_loss: 128.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 9170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7940 - accuracy: 0.0156 - val_loss: 134.7429 - val_accuracy: 0.0000e+00\n",
      "Epoch 9171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4653 - accuracy: 0.0000e+00 - val_loss: 136.9218 - val_accuracy: 0.0000e+00\n",
      "Epoch 9172/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8848 - accuracy: 0.0469 - val_loss: 130.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 9173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8457 - accuracy: 0.0000e+00 - val_loss: 126.6491 - val_accuracy: 0.0000e+00\n",
      "Epoch 9174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.1757 - accuracy: 0.0156 - val_loss: 120.4876 - val_accuracy: 0.0588\n",
      "Epoch 9175/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 31.1509 - accuracy: 0.0156 - val_loss: 125.8832 - val_accuracy: 0.0588\n",
      "Epoch 9176/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 21.9804 - accuracy: 0.0000e+00 - val_loss: 141.5550 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1682 - accuracy: 0.0469 - val_loss: 151.5954 - val_accuracy: 0.0588\n",
      "Epoch 9178/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4260 - accuracy: 0.0156 - val_loss: 144.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 9179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0349 - accuracy: 0.0000e+00 - val_loss: 137.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 9180/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 16.6327 - accuracy: 0.0312 - val_loss: 131.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5044 - accuracy: 0.0156 - val_loss: 127.2671 - val_accuracy: 0.0000e+00\n",
      "Epoch 9182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6849 - accuracy: 0.0000e+00 - val_loss: 124.3121 - val_accuracy: 0.0588\n",
      "Epoch 9183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9499 - accuracy: 0.0156 - val_loss: 123.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9184/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 24.5223 - accuracy: 0.0000e+00 - val_loss: 127.1378 - val_accuracy: 0.0588\n",
      "Epoch 9185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1005 - accuracy: 0.0156 - val_loss: 133.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 9186/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 26.7530 - accuracy: 0.0156 - val_loss: 133.9252 - val_accuracy: 0.0000e+00\n",
      "Epoch 9187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4530 - accuracy: 0.0156 - val_loss: 135.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 9188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0676 - accuracy: 0.0156 - val_loss: 146.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 9189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8362 - accuracy: 0.0156 - val_loss: 149.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 9190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4324 - accuracy: 0.0000e+00 - val_loss: 147.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0610 - accuracy: 0.0000e+00 - val_loss: 145.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 9192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4840 - accuracy: 0.0156 - val_loss: 142.5187 - val_accuracy: 0.0588\n",
      "Epoch 9193/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9893 - accuracy: 0.0000e+00 - val_loss: 139.2512 - val_accuracy: 0.0000e+00\n",
      "Epoch 9194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6297 - accuracy: 0.0312 - val_loss: 137.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 9195/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 12.9513 - accuracy: 0.0000e+00 - val_loss: 132.9748 - val_accuracy: 0.0000e+00\n",
      "Epoch 9196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9118 - accuracy: 0.0000e+00 - val_loss: 131.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 9197/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3398 - accuracy: 0.0312 - val_loss: 133.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 9198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9515 - accuracy: 0.0312 - val_loss: 137.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9199/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 18.0855 - accuracy: 0.0156 - val_loss: 140.7933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9242 - accuracy: 0.0312 - val_loss: 134.6614 - val_accuracy: 0.0000e+00\n",
      "Epoch 9201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6915 - accuracy: 0.0312 - val_loss: 129.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 9202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4953 - accuracy: 0.0156 - val_loss: 131.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 9203/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.4476 - accuracy: 0.0156 - val_loss: 135.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 9204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3328 - accuracy: 0.0000e+00 - val_loss: 137.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 9205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1680 - accuracy: 0.0000e+00 - val_loss: 137.1648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1798 - accuracy: 0.0312 - val_loss: 134.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9207/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 15.9435 - accuracy: 0.0469 - val_loss: 134.7041 - val_accuracy: 0.0588\n",
      "Epoch 9208/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 23.5633 - accuracy: 0.0156 - val_loss: 144.3926 - val_accuracy: 0.0588\n",
      "Epoch 9209/10000\n",
      "64/64 [==============================] - 0s 166us/step - loss: 19.9002 - accuracy: 0.0000e+00 - val_loss: 149.3098 - val_accuracy: 0.0588\n",
      "Epoch 9210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6231 - accuracy: 0.0156 - val_loss: 155.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2310 - accuracy: 0.0312 - val_loss: 155.9866 - val_accuracy: 0.0588\n",
      "Epoch 9212/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 14.4216 - accuracy: 0.0000e+00 - val_loss: 151.3376 - val_accuracy: 0.0588\n",
      "Epoch 9213/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6087 - accuracy: 0.0000e+00 - val_loss: 143.7478 - val_accuracy: 0.0588\n",
      "Epoch 9214/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5390 - accuracy: 0.0000e+00 - val_loss: 132.1662 - val_accuracy: 0.0588\n",
      "Epoch 9215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9869 - accuracy: 0.0312 - val_loss: 127.6480 - val_accuracy: 0.0588\n",
      "Epoch 9216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7862 - accuracy: 0.0000e+00 - val_loss: 124.1202 - val_accuracy: 0.0588\n",
      "Epoch 9217/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6047 - accuracy: 0.0156 - val_loss: 123.0459 - val_accuracy: 0.0588\n",
      "Epoch 9218/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 19.8817 - accuracy: 0.0000e+00 - val_loss: 129.0116 - val_accuracy: 0.0588\n",
      "Epoch 9219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4076 - accuracy: 0.0156 - val_loss: 139.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 9220/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 27.7329 - accuracy: 0.0000e+00 - val_loss: 147.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9221/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4378 - accuracy: 0.0000e+00 - val_loss: 145.6846 - val_accuracy: 0.0000e+00\n",
      "Epoch 9222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0617 - accuracy: 0.0312 - val_loss: 140.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 9223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3511 - accuracy: 0.0000e+00 - val_loss: 137.7987 - val_accuracy: 0.0588\n",
      "Epoch 9224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0390 - accuracy: 0.0156 - val_loss: 131.2242 - val_accuracy: 0.0588\n",
      "Epoch 9225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4772 - accuracy: 0.0156 - val_loss: 127.2546 - val_accuracy: 0.0000e+00\n",
      "Epoch 9226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2982 - accuracy: 0.0000e+00 - val_loss: 127.7402 - val_accuracy: 0.0000e+00\n",
      "Epoch 9227/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6526 - accuracy: 0.0000e+00 - val_loss: 133.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 9228/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 25.2141 - accuracy: 0.0312 - val_loss: 144.2707 - val_accuracy: 0.0000e+00\n",
      "Epoch 9229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3099 - accuracy: 0.0000e+00 - val_loss: 150.6537 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5929 - accuracy: 0.0000e+00 - val_loss: 145.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6695 - accuracy: 0.0156 - val_loss: 134.7723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9232/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9261 - accuracy: 0.0156 - val_loss: 125.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 9233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2886 - accuracy: 0.0469 - val_loss: 126.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 9234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5485 - accuracy: 0.0000e+00 - val_loss: 129.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 9235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1997 - accuracy: 0.0312 - val_loss: 135.4061 - val_accuracy: 0.0000e+00\n",
      "Epoch 9236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5230 - accuracy: 0.0156 - val_loss: 139.8877 - val_accuracy: 0.0588\n",
      "Epoch 9237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2994 - accuracy: 0.0156 - val_loss: 140.5093 - val_accuracy: 0.0588\n",
      "Epoch 9238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9849 - accuracy: 0.0000e+00 - val_loss: 134.3092 - val_accuracy: 0.0588\n",
      "Epoch 9239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4609 - accuracy: 0.0000e+00 - val_loss: 134.7108 - val_accuracy: 0.0588\n",
      "Epoch 9240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7448 - accuracy: 0.0000e+00 - val_loss: 139.9256 - val_accuracy: 0.0588\n",
      "Epoch 9241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6835 - accuracy: 0.0312 - val_loss: 141.8622 - val_accuracy: 0.0588\n",
      "Epoch 9242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6253 - accuracy: 0.0156 - val_loss: 136.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 9243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3987 - accuracy: 0.0156 - val_loss: 132.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5877 - accuracy: 0.0000e+00 - val_loss: 128.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 9245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8461 - accuracy: 0.0000e+00 - val_loss: 127.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 9246/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5694 - accuracy: 0.0000e+00 - val_loss: 130.6687 - val_accuracy: 0.0000e+00\n",
      "Epoch 9247/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.2539 - accuracy: 0.0156 - val_loss: 131.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 9248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8560 - accuracy: 0.0312 - val_loss: 131.6948 - val_accuracy: 0.0000e+00\n",
      "Epoch 9249/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 22.8497 - accuracy: 0.0156 - val_loss: 133.7538 - val_accuracy: 0.0000e+00\n",
      "Epoch 9250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8280 - accuracy: 0.0000e+00 - val_loss: 133.8980 - val_accuracy: 0.0000e+00\n",
      "Epoch 9251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5564 - accuracy: 0.0000e+00 - val_loss: 133.0392 - val_accuracy: 0.0588\n",
      "Epoch 9252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4896 - accuracy: 0.0156 - val_loss: 130.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 9253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0719 - accuracy: 0.0156 - val_loss: 134.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 9254/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.5588 - accuracy: 0.0156 - val_loss: 143.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 9255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4412 - accuracy: 0.0156 - val_loss: 145.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 9256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4431 - accuracy: 0.0156 - val_loss: 146.2359 - val_accuracy: 0.0000e+00\n",
      "Epoch 9257/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 15.6547 - accuracy: 0.0156 - val_loss: 146.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 9258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7768 - accuracy: 0.0156 - val_loss: 149.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 9259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1616 - accuracy: 0.0156 - val_loss: 146.4200 - val_accuracy: 0.0000e+00\n",
      "Epoch 9260/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1279 - accuracy: 0.0156 - val_loss: 142.1179 - val_accuracy: 0.0588\n",
      "Epoch 9261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5415 - accuracy: 0.0000e+00 - val_loss: 133.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 9262/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 21.5273 - accuracy: 0.0156 - val_loss: 130.1397 - val_accuracy: 0.0000e+00\n",
      "Epoch 9263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2368 - accuracy: 0.0156 - val_loss: 136.3976 - val_accuracy: 0.0000e+00\n",
      "Epoch 9264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4945 - accuracy: 0.0000e+00 - val_loss: 134.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4166 - accuracy: 0.0000e+00 - val_loss: 136.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 9266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1722 - accuracy: 0.0156 - val_loss: 136.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9267/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.0369 - accuracy: 0.0000e+00 - val_loss: 141.3219 - val_accuracy: 0.0000e+00\n",
      "Epoch 9268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.1164 - accuracy: 0.0156 - val_loss: 138.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 9269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8552 - accuracy: 0.0000e+00 - val_loss: 133.9910 - val_accuracy: 0.0000e+00\n",
      "Epoch 9270/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7188 - accuracy: 0.0000e+00 - val_loss: 133.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 9271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4849 - accuracy: 0.0156 - val_loss: 137.6694 - val_accuracy: 0.0000e+00\n",
      "Epoch 9272/10000\n",
      "64/64 [==============================] - 0s 60us/step - loss: 21.3812 - accuracy: 0.0000e+00 - val_loss: 139.5682 - val_accuracy: 0.0588\n",
      "Epoch 9273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5357 - accuracy: 0.0156 - val_loss: 141.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9274/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 27.5842 - accuracy: 0.0000e+00 - val_loss: 140.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6857 - accuracy: 0.0156 - val_loss: 133.0458 - val_accuracy: 0.0588\n",
      "Epoch 9276/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.9960 - accuracy: 0.0156 - val_loss: 124.5813 - val_accuracy: 0.0588\n",
      "Epoch 9277/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 20.1041 - accuracy: 0.0156 - val_loss: 116.2811 - val_accuracy: 0.0000e+00\n",
      "Epoch 9278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0002 - accuracy: 0.0156 - val_loss: 117.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9279/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.9804 - accuracy: 0.0000e+00 - val_loss: 121.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4982 - accuracy: 0.0156 - val_loss: 133.1554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8442 - accuracy: 0.0156 - val_loss: 137.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0729 - accuracy: 0.0156 - val_loss: 137.7648 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9283/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.4669 - accuracy: 0.0156 - val_loss: 140.9382 - val_accuracy: 0.0588\n",
      "Epoch 9284/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.0557 - accuracy: 0.0156 - val_loss: 141.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 9285/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 13.8390 - accuracy: 0.0156 - val_loss: 135.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9117 - accuracy: 0.0312 - val_loss: 132.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 9287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9844 - accuracy: 0.0156 - val_loss: 137.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 9288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6971 - accuracy: 0.0000e+00 - val_loss: 145.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 9289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6290 - accuracy: 0.0156 - val_loss: 146.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 9290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8432 - accuracy: 0.0156 - val_loss: 147.5135 - val_accuracy: 0.0000e+00\n",
      "Epoch 9291/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8914 - accuracy: 0.0000e+00 - val_loss: 145.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9292/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4170 - accuracy: 0.0000e+00 - val_loss: 132.7137 - val_accuracy: 0.0588\n",
      "Epoch 9293/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 14.6661 - accuracy: 0.0000e+00 - val_loss: 122.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.9409 - accuracy: 0.0000e+00 - val_loss: 118.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 9295/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 17.5498 - accuracy: 0.0156 - val_loss: 122.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 9296/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.4773 - accuracy: 0.0156 - val_loss: 132.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 9297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3158 - accuracy: 0.0000e+00 - val_loss: 134.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 9298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1557 - accuracy: 0.0156 - val_loss: 128.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 9299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7550 - accuracy: 0.0156 - val_loss: 128.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5214 - accuracy: 0.0156 - val_loss: 127.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 9301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3678 - accuracy: 0.0000e+00 - val_loss: 125.9696 - val_accuracy: 0.0000e+00\n",
      "Epoch 9302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2214 - accuracy: 0.0156 - val_loss: 122.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 9303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3036 - accuracy: 0.0000e+00 - val_loss: 118.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 9304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2848 - accuracy: 0.0000e+00 - val_loss: 127.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 9305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2162 - accuracy: 0.0312 - val_loss: 128.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 9306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2564 - accuracy: 0.0156 - val_loss: 131.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 9307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1243 - accuracy: 0.0312 - val_loss: 143.6978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1769 - accuracy: 0.0000e+00 - val_loss: 148.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 9309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.7089 - accuracy: 0.0000e+00 - val_loss: 146.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 9310/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4909 - accuracy: 0.0000e+00 - val_loss: 140.5234 - val_accuracy: 0.0588\n",
      "Epoch 9311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.7386 - accuracy: 0.0000e+00 - val_loss: 131.1979 - val_accuracy: 0.0588\n",
      "Epoch 9312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2037 - accuracy: 0.0156 - val_loss: 122.9029 - val_accuracy: 0.0000e+00\n",
      "Epoch 9313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0990 - accuracy: 0.0312 - val_loss: 125.4957 - val_accuracy: 0.0000e+00\n",
      "Epoch 9314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5873 - accuracy: 0.0000e+00 - val_loss: 130.4785 - val_accuracy: 0.0588\n",
      "Epoch 9315/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 16.8633 - accuracy: 0.0156 - val_loss: 131.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 9316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0986 - accuracy: 0.0156 - val_loss: 132.5880 - val_accuracy: 0.0000e+00\n",
      "Epoch 9317/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.7248 - accuracy: 0.0312 - val_loss: 128.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1816 - accuracy: 0.0000e+00 - val_loss: 130.5328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0095 - accuracy: 0.0312 - val_loss: 134.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 9320/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.1502 - accuracy: 0.0156 - val_loss: 136.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 9321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7689 - accuracy: 0.0000e+00 - val_loss: 138.8687 - val_accuracy: 0.0588\n",
      "Epoch 9322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9209 - accuracy: 0.0000e+00 - val_loss: 140.5061 - val_accuracy: 0.0588\n",
      "Epoch 9323/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5677 - accuracy: 0.0156 - val_loss: 133.5380 - val_accuracy: 0.0588\n",
      "Epoch 9324/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.5481 - accuracy: 0.0000e+00 - val_loss: 127.2532 - val_accuracy: 0.0588\n",
      "Epoch 9325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7306 - accuracy: 0.0312 - val_loss: 122.8853 - val_accuracy: 0.0588\n",
      "Epoch 9326/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 22.2307 - accuracy: 0.0000e+00 - val_loss: 121.6036 - val_accuracy: 0.1176\n",
      "Epoch 9327/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 25.2439 - accuracy: 0.0000e+00 - val_loss: 120.5629 - val_accuracy: 0.0588\n",
      "Epoch 9328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2529 - accuracy: 0.0000e+00 - val_loss: 121.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 9329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5329 - accuracy: 0.0156 - val_loss: 125.3728 - val_accuracy: 0.0588\n",
      "Epoch 9330/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 18.7231 - accuracy: 0.0000e+00 - val_loss: 127.6390 - val_accuracy: 0.0588\n",
      "Epoch 9331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3904 - accuracy: 0.0000e+00 - val_loss: 135.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 9332/10000\n",
      "64/64 [==============================] - 0s 233us/step - loss: 27.7643 - accuracy: 0.0000e+00 - val_loss: 138.2907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9333/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.8034 - accuracy: 0.0156 - val_loss: 139.7840 - val_accuracy: 0.0588\n",
      "Epoch 9334/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3650 - accuracy: 0.0000e+00 - val_loss: 139.9325 - val_accuracy: 0.0588\n",
      "Epoch 9335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3023 - accuracy: 0.0156 - val_loss: 137.6187 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9336/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 22.5096 - accuracy: 0.0000e+00 - val_loss: 137.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 9337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0367 - accuracy: 0.0000e+00 - val_loss: 132.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 9338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4101 - accuracy: 0.0156 - val_loss: 130.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9300 - accuracy: 0.0156 - val_loss: 131.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 9340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8174 - accuracy: 0.0156 - val_loss: 140.7480 - val_accuracy: 0.0588\n",
      "Epoch 9341/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4987 - accuracy: 0.0000e+00 - val_loss: 149.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 9342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3550 - accuracy: 0.0156 - val_loss: 157.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 9343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3311 - accuracy: 0.0312 - val_loss: 155.5928 - val_accuracy: 0.0000e+00\n",
      "Epoch 9344/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8287 - accuracy: 0.0469 - val_loss: 153.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 9345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.4024 - accuracy: 0.0156 - val_loss: 148.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 9346/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6133 - accuracy: 0.0312 - val_loss: 148.1778 - val_accuracy: 0.0588\n",
      "Epoch 9347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1211 - accuracy: 0.0156 - val_loss: 147.2075 - val_accuracy: 0.0588\n",
      "Epoch 9348/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 16.4060 - accuracy: 0.0000e+00 - val_loss: 142.8625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9349/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8895 - accuracy: 0.0000e+00 - val_loss: 135.4067 - val_accuracy: 0.0000e+00\n",
      "Epoch 9350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0260 - accuracy: 0.0469 - val_loss: 130.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 9351/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 21.9426 - accuracy: 0.0156 - val_loss: 130.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0145 - accuracy: 0.0000e+00 - val_loss: 131.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3313 - accuracy: 0.0312 - val_loss: 131.4951 - val_accuracy: 0.0588\n",
      "Epoch 9354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1274 - accuracy: 0.0000e+00 - val_loss: 128.3429 - val_accuracy: 0.0588\n",
      "Epoch 9355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0287 - accuracy: 0.0156 - val_loss: 130.8170 - val_accuracy: 0.0588\n",
      "Epoch 9356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0188 - accuracy: 0.0156 - val_loss: 136.9536 - val_accuracy: 0.0000e+00\n",
      "Epoch 9357/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 20.0650 - accuracy: 0.0000e+00 - val_loss: 141.0828 - val_accuracy: 0.0588\n",
      "Epoch 9358/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 13.9443 - accuracy: 0.0156 - val_loss: 153.4769 - val_accuracy: 0.0588\n",
      "Epoch 9359/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.0992 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 23.9378 - accuracy: 0.0000e+00 - val_loss: 159.9492 - val_accuracy: 0.0588\n",
      "Epoch 9360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0730 - accuracy: 0.0156 - val_loss: 163.8134 - val_accuracy: 0.0588\n",
      "Epoch 9361/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3728 - accuracy: 0.0312 - val_loss: 161.5114 - val_accuracy: 0.0588\n",
      "Epoch 9362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3394 - accuracy: 0.0469 - val_loss: 151.7744 - val_accuracy: 0.0588\n",
      "Epoch 9363/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.2960 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 17.0336 - accuracy: 0.0000e+00 - val_loss: 140.6897 - val_accuracy: 0.0588\n",
      "Epoch 9364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8954 - accuracy: 0.0156 - val_loss: 129.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 9365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6937 - accuracy: 0.0000e+00 - val_loss: 124.2651 - val_accuracy: 0.0000e+00\n",
      "Epoch 9366/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7129 - accuracy: 0.0312 - val_loss: 119.5273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9367/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 21.5105 - accuracy: 0.0000e+00 - val_loss: 123.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 9368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6598 - accuracy: 0.0156 - val_loss: 131.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 9369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 12.3053 - accuracy: 0.0156 - val_loss: 139.8755 - val_accuracy: 0.0000e+00\n",
      "Epoch 9370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1474 - accuracy: 0.0156 - val_loss: 142.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 9371/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.2360 - accuracy: 0.0000e+00 - val_loss: 139.2971 - val_accuracy: 0.0588\n",
      "Epoch 9372/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.7868 - accuracy: 0.0156 - val_loss: 137.1468 - val_accuracy: 0.0588\n",
      "Epoch 9373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3837 - accuracy: 0.0000e+00 - val_loss: 139.9532 - val_accuracy: 0.0588\n",
      "Epoch 9374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4467 - accuracy: 0.0312 - val_loss: 137.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 9375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3074 - accuracy: 0.0000e+00 - val_loss: 139.6114 - val_accuracy: 0.0588\n",
      "Epoch 9376/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 15.6816 - accuracy: 0.0000e+00 - val_loss: 137.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 9377/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 23.1563 - accuracy: 0.0156 - val_loss: 131.5168 - val_accuracy: 0.0588\n",
      "Epoch 9378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4397 - accuracy: 0.0156 - val_loss: 123.7218 - val_accuracy: 0.0588\n",
      "Epoch 9379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3422 - accuracy: 0.0000e+00 - val_loss: 114.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0297 - accuracy: 0.0000e+00 - val_loss: 116.1890 - val_accuracy: 0.0588\n",
      "Epoch 9381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2273 - accuracy: 0.0000e+00 - val_loss: 122.8354 - val_accuracy: 0.0000e+00\n",
      "Epoch 9382/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.9947 - accuracy: 0.0312 - val_loss: 127.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 9383/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 21.9994 - accuracy: 0.0000e+00 - val_loss: 131.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 9384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2972 - accuracy: 0.0156 - val_loss: 135.8981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7622 - accuracy: 0.0000e+00 - val_loss: 130.0345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2152 - accuracy: 0.0312 - val_loss: 126.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 9387/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0687 - accuracy: 0.0156 - val_loss: 123.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 9388/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 15.0774 - accuracy: 0.0156 - val_loss: 125.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 9389/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5156 - accuracy: 0.0312 - val_loss: 125.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 9390/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 23.0308 - accuracy: 0.0000e+00 - val_loss: 123.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 9391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8328 - accuracy: 0.0000e+00 - val_loss: 126.4999 - val_accuracy: 0.0588\n",
      "Epoch 9392/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 16.6992 - accuracy: 0.0156 - val_loss: 135.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8679 - accuracy: 0.0156 - val_loss: 147.3156 - val_accuracy: 0.0588\n",
      "Epoch 9394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8059 - accuracy: 0.0156 - val_loss: 151.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9395/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.3152 - accuracy: 0.0000e+00 - val_loss: 140.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 9396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9172 - accuracy: 0.0312 - val_loss: 130.1905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5762 - accuracy: 0.0156 - val_loss: 127.3525 - val_accuracy: 0.0588\n",
      "Epoch 9398/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.9456 - accuracy: 0.0312 - val_loss: 126.8088 - val_accuracy: 0.0000e+00\n",
      "Epoch 9399/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 23.7574 - accuracy: 0.0000e+00 - val_loss: 134.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 9400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0877 - accuracy: 0.0000e+00 - val_loss: 146.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7165 - accuracy: 0.0000e+00 - val_loss: 154.5640 - val_accuracy: 0.0588\n",
      "Epoch 9402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1146 - accuracy: 0.0156 - val_loss: 154.2675 - val_accuracy: 0.0000e+00\n",
      "Epoch 9403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9901 - accuracy: 0.0312 - val_loss: 146.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9404/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 21.2143 - accuracy: 0.0000e+00 - val_loss: 132.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 9405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3410 - accuracy: 0.0000e+00 - val_loss: 121.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 9406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6460 - accuracy: 0.0312 - val_loss: 119.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 9407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2022 - accuracy: 0.0000e+00 - val_loss: 127.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9804 - accuracy: 0.0000e+00 - val_loss: 135.7816 - val_accuracy: 0.0000e+00\n",
      "Epoch 9409/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6419 - accuracy: 0.0312 - val_loss: 139.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 9410/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 29.7215 - accuracy: 0.0156 - val_loss: 140.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.0198 - accuracy: 0.0156 - val_loss: 138.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9412/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 9.6533 - accuracy: 0.0156 - val_loss: 132.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9413/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.6010 - accuracy: 0.0156 - val_loss: 126.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 9414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8646 - accuracy: 0.0312 - val_loss: 123.1452 - val_accuracy: 0.0588\n",
      "Epoch 9415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7029 - accuracy: 0.0000e+00 - val_loss: 125.5091 - val_accuracy: 0.0000e+00\n",
      "Epoch 9416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8068 - accuracy: 0.0156 - val_loss: 124.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 9417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7689 - accuracy: 0.0000e+00 - val_loss: 122.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1728 - accuracy: 0.0000e+00 - val_loss: 121.8331 - val_accuracy: 0.0000e+00\n",
      "Epoch 9419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0318 - accuracy: 0.0156 - val_loss: 130.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 9420/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7703 - accuracy: 0.0000e+00 - val_loss: 136.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 9421/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 18.2746 - accuracy: 0.0312 - val_loss: 137.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 9422/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0922 - accuracy: 0.0000e+00 - val_loss: 136.8799 - val_accuracy: 0.0000e+00\n",
      "Epoch 9423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.3054 - accuracy: 0.0469 - val_loss: 135.3462 - val_accuracy: 0.0000e+00\n",
      "Epoch 9424/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 23.4953 - accuracy: 0.0000e+00 - val_loss: 135.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9425/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.0700 - accuracy: 0.0000e+00 - val_loss: 136.5094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3777 - accuracy: 0.0312 - val_loss: 137.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 9427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2486 - accuracy: 0.0000e+00 - val_loss: 140.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 9428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.2902 - accuracy: 0.0000e+00 - val_loss: 140.5871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9429/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 19.6532 - accuracy: 0.0000e+00 - val_loss: 138.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 9430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7853 - accuracy: 0.0312 - val_loss: 133.9632 - val_accuracy: 0.0000e+00\n",
      "Epoch 9431/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6777 - accuracy: 0.0625 - val_loss: 137.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9432/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8746 - accuracy: 0.0156 - val_loss: 141.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 9433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3528 - accuracy: 0.0312 - val_loss: 142.2772 - val_accuracy: 0.0000e+00\n",
      "Epoch 9434/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 22.8482 - accuracy: 0.0156 - val_loss: 144.9271 - val_accuracy: 0.0000e+00\n",
      "Epoch 9435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6097 - accuracy: 0.0156 - val_loss: 146.9514 - val_accuracy: 0.0000e+00\n",
      "Epoch 9436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2103 - accuracy: 0.0156 - val_loss: 147.0387 - val_accuracy: 0.0000e+00\n",
      "Epoch 9437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1616 - accuracy: 0.0000e+00 - val_loss: 147.5978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8523 - accuracy: 0.0156 - val_loss: 145.0462 - val_accuracy: 0.0000e+00\n",
      "Epoch 9439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4907 - accuracy: 0.0156 - val_loss: 137.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 9440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 16.8635 - accuracy: 0.0000e+00 - val_loss: 133.3889 - val_accuracy: 0.0000e+00\n",
      "Epoch 9441/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4686 - accuracy: 0.0000e+00 - val_loss: 130.4378 - val_accuracy: 0.0000e+00\n",
      "Epoch 9442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4807 - accuracy: 0.0156 - val_loss: 135.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9443/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 18.3356 - accuracy: 0.0156 - val_loss: 140.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 9444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9929 - accuracy: 0.0000e+00 - val_loss: 140.3377 - val_accuracy: 0.0000e+00\n",
      "Epoch 9445/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3042 - accuracy: 0.0000e+00 - val_loss: 138.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 9446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3018 - accuracy: 0.0312 - val_loss: 133.4695 - val_accuracy: 0.0588\n",
      "Epoch 9447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7344 - accuracy: 0.0000e+00 - val_loss: 127.3745 - val_accuracy: 0.0588\n",
      "Epoch 9448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3065 - accuracy: 0.0469 - val_loss: 120.5393 - val_accuracy: 0.0588\n",
      "Epoch 9449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5625 - accuracy: 0.0156 - val_loss: 125.5748 - val_accuracy: 0.0588\n",
      "Epoch 9450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7201 - accuracy: 0.0156 - val_loss: 133.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 9451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7005 - accuracy: 0.0000e+00 - val_loss: 135.2346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9452/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 14.7913 - accuracy: 0.0000e+00 - val_loss: 130.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 9453/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 17.7862 - accuracy: 0.0156 - val_loss: 128.5539 - val_accuracy: 0.0000e+00\n",
      "Epoch 9454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4494 - accuracy: 0.0156 - val_loss: 126.5886 - val_accuracy: 0.0000e+00\n",
      "Epoch 9455/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.5622 - accuracy: 0.0156 - val_loss: 126.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 9456/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5061 - accuracy: 0.0000e+00 - val_loss: 135.4645 - val_accuracy: 0.0000e+00\n",
      "Epoch 9457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4091 - accuracy: 0.0312 - val_loss: 149.1889 - val_accuracy: 0.0588\n",
      "Epoch 9458/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.0781 - accuracy: 0.0469 - val_loss: 158.1911 - val_accuracy: 0.0588\n",
      "Epoch 9459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0278 - accuracy: 0.0000e+00 - val_loss: 159.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 9460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2484 - accuracy: 0.0000e+00 - val_loss: 154.7843 - val_accuracy: 0.0000e+00\n",
      "Epoch 9461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3486 - accuracy: 0.0312 - val_loss: 147.1745 - val_accuracy: 0.0000e+00\n",
      "Epoch 9462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0717 - accuracy: 0.0000e+00 - val_loss: 149.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 9463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5827 - accuracy: 0.0312 - val_loss: 152.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9464/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 26.6131 - accuracy: 0.0000e+00 - val_loss: 152.7184 - val_accuracy: 0.0000e+00\n",
      "Epoch 9465/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2820 - accuracy: 0.0000e+00 - val_loss: 149.0857 - val_accuracy: 0.0588\n",
      "Epoch 9466/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 22.7049 - accuracy: 0.0000e+00 - val_loss: 146.8370 - val_accuracy: 0.0588\n",
      "Epoch 9467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4760 - accuracy: 0.0000e+00 - val_loss: 142.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 9468/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7115 - accuracy: 0.0156 - val_loss: 137.3424 - val_accuracy: 0.0588\n",
      "Epoch 9469/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 26.2676 - accuracy: 0.0000e+00 - val_loss: 137.2892 - val_accuracy: 0.0588\n",
      "Epoch 9470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0132 - accuracy: 0.0156 - val_loss: 138.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7258 - accuracy: 0.0000e+00 - val_loss: 135.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 9472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1905 - accuracy: 0.0156 - val_loss: 130.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 9473/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.4749 - accuracy: 0.0156 - val_loss: 125.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 9474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1087 - accuracy: 0.0156 - val_loss: 123.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 9475/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3429 - accuracy: 0.0156 - val_loss: 121.3980 - val_accuracy: 0.0000e+00\n",
      "Epoch 9476/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 18.0451 - accuracy: 0.0156 - val_loss: 125.4302 - val_accuracy: 0.1176\n",
      "Epoch 9477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9323 - accuracy: 0.0312 - val_loss: 135.3080 - val_accuracy: 0.0000e+00\n",
      "Epoch 9478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5920 - accuracy: 0.0156 - val_loss: 141.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 9479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6693 - accuracy: 0.0156 - val_loss: 143.6064 - val_accuracy: 0.0000e+00\n",
      "Epoch 9480/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 20.4002 - accuracy: 0.0156 - val_loss: 139.1672 - val_accuracy: 0.0000e+00\n",
      "Epoch 9481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6724 - accuracy: 0.0000e+00 - val_loss: 135.4747 - val_accuracy: 0.0000e+00\n",
      "Epoch 9482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2758 - accuracy: 0.0000e+00 - val_loss: 133.4862 - val_accuracy: 0.0588\n",
      "Epoch 9483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2894 - accuracy: 0.0000e+00 - val_loss: 131.3665 - val_accuracy: 0.0588\n",
      "Epoch 9484/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6264 - accuracy: 0.0000e+00 - val_loss: 132.5137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9014 - accuracy: 0.0000e+00 - val_loss: 130.2893 - val_accuracy: 0.0000e+00\n",
      "Epoch 9486/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 21.3754 - accuracy: 0.0000e+00 - val_loss: 123.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 9487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6568 - accuracy: 0.0156 - val_loss: 122.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 9488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.4133 - accuracy: 0.0156 - val_loss: 138.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9489/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7353 - accuracy: 0.0000e+00 - val_loss: 152.5535 - val_accuracy: 0.0588\n",
      "Epoch 9490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2581 - accuracy: 0.0000e+00 - val_loss: 156.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 9491/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7499 - accuracy: 0.0000e+00 - val_loss: 143.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 9492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4358 - accuracy: 0.0156 - val_loss: 129.2463 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2718 - accuracy: 0.0156 - val_loss: 116.3912 - val_accuracy: 0.0588\n",
      "Epoch 9494/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2589 - accuracy: 0.0000e+00 - val_loss: 110.8985 - val_accuracy: 0.0588\n",
      "Epoch 9495/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6970 - accuracy: 0.0156 - val_loss: 114.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7797 - accuracy: 0.0000e+00 - val_loss: 120.7313 - val_accuracy: 0.0588\n",
      "Epoch 9497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7725 - accuracy: 0.0000e+00 - val_loss: 127.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9498/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 28.9039 - accuracy: 0.0156 - val_loss: 133.6115 - val_accuracy: 0.0000e+00\n",
      "Epoch 9499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6696 - accuracy: 0.0156 - val_loss: 131.5528 - val_accuracy: 0.0000e+00\n",
      "Epoch 9500/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 22.4007 - accuracy: 0.0000e+00 - val_loss: 127.8988 - val_accuracy: 0.0588\n",
      "Epoch 9501/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7867 - accuracy: 0.0000e+00 - val_loss: 129.7372 - val_accuracy: 0.0000e+00\n",
      "Epoch 9502/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6406 - accuracy: 0.0312 - val_loss: 135.0619 - val_accuracy: 0.0000e+00\n",
      "Epoch 9503/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6508 - accuracy: 0.0156 - val_loss: 142.7416 - val_accuracy: 0.0588\n",
      "Epoch 9504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3412 - accuracy: 0.0000e+00 - val_loss: 147.3536 - val_accuracy: 0.0000e+00\n",
      "Epoch 9505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2266 - accuracy: 0.0000e+00 - val_loss: 148.3519 - val_accuracy: 0.0588\n",
      "Epoch 9506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3063 - accuracy: 0.0312 - val_loss: 142.2272 - val_accuracy: 0.0000e+00\n",
      "Epoch 9507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8626 - accuracy: 0.0000e+00 - val_loss: 133.3988 - val_accuracy: 0.0000e+00\n",
      "Epoch 9508/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 21.9391 - accuracy: 0.0000e+00 - val_loss: 129.8163 - val_accuracy: 0.0000e+00\n",
      "Epoch 9509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4616 - accuracy: 0.0156 - val_loss: 130.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 9510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2892 - accuracy: 0.0000e+00 - val_loss: 129.1019 - val_accuracy: 0.0000e+00\n",
      "Epoch 9511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.1778 - accuracy: 0.0156 - val_loss: 129.5300 - val_accuracy: 0.0588\n",
      "Epoch 9512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2730 - accuracy: 0.0312 - val_loss: 131.4408 - val_accuracy: 0.0588\n",
      "Epoch 9513/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3327 - accuracy: 0.0000e+00 - val_loss: 137.0064 - val_accuracy: 0.0588\n",
      "Epoch 9514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2967 - accuracy: 0.0000e+00 - val_loss: 138.9029 - val_accuracy: 0.0588\n",
      "Epoch 9515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6597 - accuracy: 0.0156 - val_loss: 136.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 9516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6897 - accuracy: 0.0000e+00 - val_loss: 132.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 9517/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8454 - accuracy: 0.0000e+00 - val_loss: 131.8742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5088 - accuracy: 0.0000e+00 - val_loss: 130.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 9519/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6760 - accuracy: 0.0000e+00 - val_loss: 125.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 9520/10000\n",
      "64/64 [==============================] - 0s 39us/step - loss: 21.3464 - accuracy: 0.0156 - val_loss: 121.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9787 - accuracy: 0.0312 - val_loss: 124.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9522/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 13.7618 - accuracy: 0.0156 - val_loss: 134.2997 - val_accuracy: 0.0000e+00\n",
      "Epoch 9523/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4234 - accuracy: 0.0156 - val_loss: 149.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7666 - accuracy: 0.0156 - val_loss: 156.0423 - val_accuracy: 0.0000e+00\n",
      "Epoch 9525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4585 - accuracy: 0.0156 - val_loss: 155.7731 - val_accuracy: 0.0000e+00\n",
      "Epoch 9526/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9478 - accuracy: 0.0156 - val_loss: 153.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0338 - accuracy: 0.0000e+00 - val_loss: 146.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9139 - accuracy: 0.0000e+00 - val_loss: 133.9011 - val_accuracy: 0.0588\n",
      "Epoch 9529/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6671 - accuracy: 0.0156 - val_loss: 131.2085 - val_accuracy: 0.0588\n",
      "Epoch 9530/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 19.1761 - accuracy: 0.0312 - val_loss: 135.8431 - val_accuracy: 0.0000e+00\n",
      "Epoch 9531/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 18.3526 - accuracy: 0.0156 - val_loss: 137.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 9532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0078 - accuracy: 0.0000e+00 - val_loss: 139.2318 - val_accuracy: 0.0000e+00\n",
      "Epoch 9533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3722 - accuracy: 0.0156 - val_loss: 140.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 9534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1562 - accuracy: 0.0000e+00 - val_loss: 142.6502 - val_accuracy: 0.0000e+00\n",
      "Epoch 9535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0500 - accuracy: 0.0000e+00 - val_loss: 146.3104 - val_accuracy: 0.0000e+00\n",
      "Epoch 9536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1636 - accuracy: 0.0000e+00 - val_loss: 149.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 9537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7290 - accuracy: 0.0000e+00 - val_loss: 152.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6532 - accuracy: 0.0000e+00 - val_loss: 146.9951 - val_accuracy: 0.0000e+00\n",
      "Epoch 9539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5881 - accuracy: 0.0000e+00 - val_loss: 148.4937 - val_accuracy: 0.0000e+00\n",
      "Epoch 9540/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 16.0123 - accuracy: 0.0156 - val_loss: 152.5758 - val_accuracy: 0.0000e+00\n",
      "Epoch 9541/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 23.5204 - accuracy: 0.0000e+00 - val_loss: 153.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 9542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7447 - accuracy: 0.0000e+00 - val_loss: 149.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 9543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6566 - accuracy: 0.0000e+00 - val_loss: 147.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 9544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3152 - accuracy: 0.0000e+00 - val_loss: 141.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 9545/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.2559 - accuracy: 0.0000e+00 - val_loss: 135.8235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9546/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 15.9037 - accuracy: 0.0000e+00 - val_loss: 132.1097 - val_accuracy: 0.0588\n",
      "Epoch 9547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9970 - accuracy: 0.0000e+00 - val_loss: 132.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9162 - accuracy: 0.0312 - val_loss: 130.5340 - val_accuracy: 0.0000e+00\n",
      "Epoch 9549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8587 - accuracy: 0.0156 - val_loss: 129.7221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8984 - accuracy: 0.0000e+00 - val_loss: 131.9940 - val_accuracy: 0.0000e+00\n",
      "Epoch 9551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3144 - accuracy: 0.0312 - val_loss: 134.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 9552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5007 - accuracy: 0.0312 - val_loss: 138.9328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8644 - accuracy: 0.0000e+00 - val_loss: 147.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9554/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 24.6905 - accuracy: 0.0312 - val_loss: 151.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7712 - accuracy: 0.0000e+00 - val_loss: 149.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 9556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9321 - accuracy: 0.0000e+00 - val_loss: 141.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 9557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3005 - accuracy: 0.0312 - val_loss: 138.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 9558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7253 - accuracy: 0.0156 - val_loss: 144.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8256 - accuracy: 0.0000e+00 - val_loss: 152.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 9560/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 19.6770 - accuracy: 0.0000e+00 - val_loss: 155.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7074 - accuracy: 0.0156 - val_loss: 150.5550 - val_accuracy: 0.0000e+00\n",
      "Epoch 9562/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.9723 - accuracy: 0.0156 - val_loss: 136.6975 - val_accuracy: 0.0588\n",
      "Epoch 9563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4877 - accuracy: 0.0625 - val_loss: 122.9612 - val_accuracy: 0.0588\n",
      "Epoch 9564/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 21.8946 - accuracy: 0.0156 - val_loss: 113.5810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6170 - accuracy: 0.0156 - val_loss: 111.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 9566/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0944 - accuracy: 0.0156 - val_loss: 117.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 9567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8545 - accuracy: 0.0156 - val_loss: 121.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 9568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1221 - accuracy: 0.0000e+00 - val_loss: 116.9240 - val_accuracy: 0.0000e+00\n",
      "Epoch 9569/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.9518 - accuracy: 0.0000e+00 - val_loss: 121.7171 - val_accuracy: 0.0588\n",
      "Epoch 9570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8263 - accuracy: 0.0156 - val_loss: 129.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 9571/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3203 - accuracy: 0.0000e+00 - val_loss: 138.1782 - val_accuracy: 0.0000e+00\n",
      "Epoch 9572/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 19.5814 - accuracy: 0.0000e+00 - val_loss: 148.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 9573/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.2748 - accuracy: 0.0156 - val_loss: 151.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 9574/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2159 - accuracy: 0.0000e+00 - val_loss: 153.2411 - val_accuracy: 0.0000e+00\n",
      "Epoch 9575/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 34.8425 - accuracy: 0.0156 - val_loss: 151.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7267 - accuracy: 0.0000e+00 - val_loss: 140.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 9577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6857 - accuracy: 0.0000e+00 - val_loss: 123.5456 - val_accuracy: 0.0000e+00\n",
      "Epoch 9578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7130 - accuracy: 0.0156 - val_loss: 113.8012 - val_accuracy: 0.0000e+00\n",
      "Epoch 9579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2546 - accuracy: 0.0156 - val_loss: 115.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9580/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8775 - accuracy: 0.0000e+00 - val_loss: 117.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9581/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 15.2289 - accuracy: 0.0156 - val_loss: 117.0606 - val_accuracy: 0.0000e+00\n",
      "Epoch 9582/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 23.5066 - accuracy: 0.0156 - val_loss: 114.7731 - val_accuracy: 0.0000e+00\n",
      "Epoch 9583/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 34.5634 - accuracy: 0.0156 - val_loss: 114.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 9584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0638 - accuracy: 0.0312 - val_loss: 127.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 9585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.7439 - accuracy: 0.0156 - val_loss: 135.9445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8260 - accuracy: 0.0000e+00 - val_loss: 145.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 9587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0336 - accuracy: 0.0000e+00 - val_loss: 144.8216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2820 - accuracy: 0.0000e+00 - val_loss: 140.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 9589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5298 - accuracy: 0.0156 - val_loss: 137.2800 - val_accuracy: 0.0000e+00\n",
      "Epoch 9590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8461 - accuracy: 0.0156 - val_loss: 132.5208 - val_accuracy: 0.0000e+00\n",
      "Epoch 9591/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3019 - accuracy: 0.0469 - val_loss: 129.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 9592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0007 - accuracy: 0.0156 - val_loss: 136.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 9593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0619 - accuracy: 0.0000e+00 - val_loss: 144.0520 - val_accuracy: 0.0000e+00\n",
      "Epoch 9594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7199 - accuracy: 0.0000e+00 - val_loss: 147.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9595/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8043 - accuracy: 0.0000e+00 - val_loss: 142.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 9596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8713 - accuracy: 0.0156 - val_loss: 128.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 9597/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 138us/step - loss: 13.0742 - accuracy: 0.0156 - val_loss: 121.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6758 - accuracy: 0.0312 - val_loss: 121.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 9599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9288 - accuracy: 0.0312 - val_loss: 132.3999 - val_accuracy: 0.0000e+00\n",
      "Epoch 9600/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 18.8370 - accuracy: 0.0000e+00 - val_loss: 139.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 9601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5790 - accuracy: 0.0156 - val_loss: 139.5142 - val_accuracy: 0.0588\n",
      "Epoch 9602/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.6186 - accuracy: 0.0156 - val_loss: 136.5188 - val_accuracy: 0.0588\n",
      "Epoch 9603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0275 - accuracy: 0.0312 - val_loss: 129.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 9604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3730 - accuracy: 0.0156 - val_loss: 128.7367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5070 - accuracy: 0.0000e+00 - val_loss: 131.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 9606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5758 - accuracy: 0.0000e+00 - val_loss: 141.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 9607/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9255 - accuracy: 0.0469 - val_loss: 143.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 9608/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3474 - accuracy: 0.0312 - val_loss: 140.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9609/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 21.1425 - accuracy: 0.0000e+00 - val_loss: 137.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8142 - accuracy: 0.0000e+00 - val_loss: 138.0760 - val_accuracy: 0.0588\n",
      "Epoch 9611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7628 - accuracy: 0.0000e+00 - val_loss: 140.7047 - val_accuracy: 0.0000e+00\n",
      "Epoch 9612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7696 - accuracy: 0.0156 - val_loss: 142.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 9613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2798 - accuracy: 0.0156 - val_loss: 143.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 9614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3040 - accuracy: 0.0156 - val_loss: 135.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 9615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4195 - accuracy: 0.0156 - val_loss: 126.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 9616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5545 - accuracy: 0.0156 - val_loss: 121.9031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9617/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5081 - accuracy: 0.0000e+00 - val_loss: 122.2594 - val_accuracy: 0.0000e+00\n",
      "Epoch 9618/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9956 - accuracy: 0.0469 - val_loss: 126.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5616 - accuracy: 0.0312 - val_loss: 129.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9620/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 23.9332 - accuracy: 0.0312 - val_loss: 134.4330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3451 - accuracy: 0.0000e+00 - val_loss: 137.5805 - val_accuracy: 0.0000e+00\n",
      "Epoch 9622/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 17.5234 - accuracy: 0.0156 - val_loss: 139.9554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1663 - accuracy: 0.0469 - val_loss: 135.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 9624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2881 - accuracy: 0.0000e+00 - val_loss: 130.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 9625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5524 - accuracy: 0.0156 - val_loss: 129.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 9626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0116 - accuracy: 0.0156 - val_loss: 132.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 9627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3288 - accuracy: 0.0156 - val_loss: 136.3149 - val_accuracy: 0.0000e+00\n",
      "Epoch 9628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7623 - accuracy: 0.0000e+00 - val_loss: 140.3665 - val_accuracy: 0.0000e+00\n",
      "Epoch 9629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6475 - accuracy: 0.0156 - val_loss: 145.9146 - val_accuracy: 0.0588\n",
      "Epoch 9630/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4489 - accuracy: 0.0000e+00 - val_loss: 145.0930 - val_accuracy: 0.0588\n",
      "Epoch 9631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7339 - accuracy: 0.0156 - val_loss: 139.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 9632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0607 - accuracy: 0.0000e+00 - val_loss: 137.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 9633/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.5461 - accuracy: 0.0312 - val_loss: 140.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 9634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4738 - accuracy: 0.0156 - val_loss: 141.9952 - val_accuracy: 0.0000e+00\n",
      "Epoch 9635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4474 - accuracy: 0.0000e+00 - val_loss: 140.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 9636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6460 - accuracy: 0.0000e+00 - val_loss: 134.6365 - val_accuracy: 0.0588\n",
      "Epoch 9637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9493 - accuracy: 0.0312 - val_loss: 138.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 9638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9025 - accuracy: 0.0156 - val_loss: 140.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 9639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2751 - accuracy: 0.0156 - val_loss: 141.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 9640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2451 - accuracy: 0.0000e+00 - val_loss: 141.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 9641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7740 - accuracy: 0.0000e+00 - val_loss: 142.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 9642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3405 - accuracy: 0.0000e+00 - val_loss: 146.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 9643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.5372 - accuracy: 0.0000e+00 - val_loss: 149.3615 - val_accuracy: 0.0000e+00\n",
      "Epoch 9644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3600 - accuracy: 0.0000e+00 - val_loss: 151.3454 - val_accuracy: 0.0588\n",
      "Epoch 9645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6208 - accuracy: 0.0000e+00 - val_loss: 148.7870 - val_accuracy: 0.0588\n",
      "Epoch 9646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6997 - accuracy: 0.0312 - val_loss: 137.8399 - val_accuracy: 0.0000e+00\n",
      "Epoch 9647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6328 - accuracy: 0.0000e+00 - val_loss: 128.9281 - val_accuracy: 0.0000e+00\n",
      "Epoch 9648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7658 - accuracy: 0.0000e+00 - val_loss: 128.2541 - val_accuracy: 0.0000e+00\n",
      "Epoch 9649/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 22.2431 - accuracy: 0.0156 - val_loss: 131.7681 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9650/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 18.3781 - accuracy: 0.0156 - val_loss: 142.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2184 - accuracy: 0.0000e+00 - val_loss: 148.1580 - val_accuracy: 0.0588\n",
      "Epoch 9652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5934 - accuracy: 0.0156 - val_loss: 144.1215 - val_accuracy: 0.0588\n",
      "Epoch 9653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3485 - accuracy: 0.0000e+00 - val_loss: 143.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 9654/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9469 - accuracy: 0.0000e+00 - val_loss: 141.1400 - val_accuracy: 0.0000e+00\n",
      "Epoch 9655/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 20.8715 - accuracy: 0.0156 - val_loss: 141.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9656/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 12.7063 - accuracy: 0.0312 - val_loss: 142.5567 - val_accuracy: 0.0000e+00\n",
      "Epoch 9657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2150 - accuracy: 0.0000e+00 - val_loss: 142.5790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0658 - accuracy: 0.0156 - val_loss: 141.2871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6056 - accuracy: 0.0156 - val_loss: 143.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 9660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6400 - accuracy: 0.0000e+00 - val_loss: 152.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 9661/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 16.6307 - accuracy: 0.0156 - val_loss: 152.2770 - val_accuracy: 0.0000e+00\n",
      "Epoch 9662/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 31.2009 - accuracy: 0.0312 - val_loss: 144.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 9663/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 18.8838 - accuracy: 0.0000e+00 - val_loss: 136.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 9664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8392 - accuracy: 0.0156 - val_loss: 133.6360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9665/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9445 - accuracy: 0.0156 - val_loss: 138.3361 - val_accuracy: 0.0000e+00\n",
      "Epoch 9666/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 23.0397 - accuracy: 0.0156 - val_loss: 150.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9667/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.9288 - accuracy: 0.0000e+00 - val_loss: 152.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 9668/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 15.0433 - accuracy: 0.0156 - val_loss: 150.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 9669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6672 - accuracy: 0.0000e+00 - val_loss: 147.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 9670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8997 - accuracy: 0.0156 - val_loss: 144.8831 - val_accuracy: 0.0000e+00\n",
      "Epoch 9671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8011 - accuracy: 0.0156 - val_loss: 143.9780 - val_accuracy: 0.0000e+00\n",
      "Epoch 9672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2516 - accuracy: 0.0156 - val_loss: 141.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4006 - accuracy: 0.0000e+00 - val_loss: 136.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 9674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3955 - accuracy: 0.0000e+00 - val_loss: 128.9431 - val_accuracy: 0.0000e+00\n",
      "Epoch 9675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3822 - accuracy: 0.0156 - val_loss: 123.8230 - val_accuracy: 0.0000e+00\n",
      "Epoch 9676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5445 - accuracy: 0.0156 - val_loss: 121.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 9677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7936 - accuracy: 0.0156 - val_loss: 122.0554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2756 - accuracy: 0.0000e+00 - val_loss: 126.5868 - val_accuracy: 0.0000e+00\n",
      "Epoch 9679/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.5181 - accuracy: 0.0156 - val_loss: 132.3695 - val_accuracy: 0.0000e+00\n",
      "Epoch 9680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4693 - accuracy: 0.0000e+00 - val_loss: 133.2804 - val_accuracy: 0.0000e+00\n",
      "Epoch 9681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2150 - accuracy: 0.0312 - val_loss: 134.6925 - val_accuracy: 0.0588\n",
      "Epoch 9682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1108 - accuracy: 0.0000e+00 - val_loss: 132.3401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9683/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 15.9856 - accuracy: 0.0000e+00 - val_loss: 126.3709 - val_accuracy: 0.0000e+00\n",
      "Epoch 9684/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3519 - accuracy: 0.0156 - val_loss: 122.2169 - val_accuracy: 0.0000e+00\n",
      "Epoch 9685/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 13.1301 - accuracy: 0.0000e+00 - val_loss: 117.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 9686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4877 - accuracy: 0.0312 - val_loss: 121.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 9687/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6399 - accuracy: 0.0000e+00 - val_loss: 130.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 9688/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 20.6241 - accuracy: 0.0156 - val_loss: 143.8158 - val_accuracy: 0.0000e+00\n",
      "Epoch 9689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8647 - accuracy: 0.0156 - val_loss: 145.8802 - val_accuracy: 0.0000e+00\n",
      "Epoch 9690/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6140 - accuracy: 0.0312 - val_loss: 141.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 9691/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.5033 - accuracy: 0.0156 - val_loss: 127.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 9692/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 19.8250 - accuracy: 0.0156 - val_loss: 115.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 9693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1409 - accuracy: 0.0000e+00 - val_loss: 121.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 9694/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.4123 - accuracy: 0.0000e+00 - val_loss: 136.0654 - val_accuracy: 0.0000e+00\n",
      "Epoch 9695/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 14.0940 - accuracy: 0.0156 - val_loss: 145.9960 - val_accuracy: 0.0000e+00\n",
      "Epoch 9696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2360 - accuracy: 0.0156 - val_loss: 142.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5166 - accuracy: 0.0156 - val_loss: 131.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 9698/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.1915 - accuracy: 0.0469 - val_loss: 128.7970 - val_accuracy: 0.0000e+00\n",
      "Epoch 9699/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0266 - accuracy: 0.0000e+00 - val_loss: 138.8201 - val_accuracy: 0.0588\n",
      "Epoch 9700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4714 - accuracy: 0.0000e+00 - val_loss: 147.8474 - val_accuracy: 0.0588\n",
      "Epoch 9701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3434 - accuracy: 0.0312 - val_loss: 152.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.2210 - accuracy: 0.0000e+00 - val_loss: 154.7635 - val_accuracy: 0.0000e+00\n",
      "Epoch 9703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1815 - accuracy: 0.0000e+00 - val_loss: 148.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0750 - accuracy: 0.0312 - val_loss: 147.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 9705/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2921 - accuracy: 0.0000e+00 - val_loss: 142.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7425 - accuracy: 0.0156 - val_loss: 141.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2352 - accuracy: 0.0156 - val_loss: 142.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 9708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4580 - accuracy: 0.0156 - val_loss: 138.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 9709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9332 - accuracy: 0.0156 - val_loss: 133.2899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5134 - accuracy: 0.0156 - val_loss: 130.5070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4467 - accuracy: 0.0156 - val_loss: 131.0331 - val_accuracy: 0.0588\n",
      "Epoch 9712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0413 - accuracy: 0.0000e+00 - val_loss: 131.3262 - val_accuracy: 0.0588\n",
      "Epoch 9713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6306 - accuracy: 0.0156 - val_loss: 136.9874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9714/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6265 - accuracy: 0.0000e+00 - val_loss: 136.3996 - val_accuracy: 0.0588\n",
      "Epoch 9715/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 27.8397 - accuracy: 0.0156 - val_loss: 131.1520 - val_accuracy: 0.0588\n",
      "Epoch 9716/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 19.5523 - accuracy: 0.0000e+00 - val_loss: 125.9970 - val_accuracy: 0.0588\n",
      "Epoch 9717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3287 - accuracy: 0.0312 - val_loss: 122.0187 - val_accuracy: 0.0588\n",
      "Epoch 9718/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.3565 - accuracy: 0.0000e+00 - val_loss: 120.8518 - val_accuracy: 0.0588\n",
      "Epoch 9719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2208 - accuracy: 0.0156 - val_loss: 122.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 9720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7707 - accuracy: 0.0000e+00 - val_loss: 129.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 9721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0736 - accuracy: 0.0469 - val_loss: 138.2783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1067 - accuracy: 0.0000e+00 - val_loss: 143.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5284 - accuracy: 0.0312 - val_loss: 140.7862 - val_accuracy: 0.0000e+00\n",
      "Epoch 9724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5651 - accuracy: 0.0156 - val_loss: 134.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 9725/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 13.3886 - accuracy: 0.0000e+00 - val_loss: 128.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 9726/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.6885 - accuracy: 0.0156 - val_loss: 131.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 9727/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 25.2282 - accuracy: 0.0156 - val_loss: 143.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0165 - accuracy: 0.0156 - val_loss: 154.8995 - val_accuracy: 0.0000e+00\n",
      "Epoch 9729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5825 - accuracy: 0.0000e+00 - val_loss: 159.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 9730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1521 - accuracy: 0.0156 - val_loss: 155.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 9731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3507 - accuracy: 0.0000e+00 - val_loss: 146.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 9732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6017 - accuracy: 0.0156 - val_loss: 142.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5762 - accuracy: 0.0156 - val_loss: 142.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8523 - accuracy: 0.0156 - val_loss: 138.5165 - val_accuracy: 0.0000e+00\n",
      "Epoch 9735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9875 - accuracy: 0.0156 - val_loss: 129.4872 - val_accuracy: 0.0588\n",
      "Epoch 9736/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 19.2322 - accuracy: 0.0312 - val_loss: 126.1917 - val_accuracy: 0.0588\n",
      "Epoch 9737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6551 - accuracy: 0.0156 - val_loss: 130.8052 - val_accuracy: 0.0588\n",
      "Epoch 9738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2896 - accuracy: 0.0156 - val_loss: 136.0577 - val_accuracy: 0.0588\n",
      "Epoch 9739/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 16.2396 - accuracy: 0.0156 - val_loss: 136.9598 - val_accuracy: 0.0588\n",
      "Epoch 9740/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 12.7105 - accuracy: 0.0156 - val_loss: 141.0604 - val_accuracy: 0.0588\n",
      "Epoch 9741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2622 - accuracy: 0.0156 - val_loss: 140.5823 - val_accuracy: 0.0588\n",
      "Epoch 9742/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 19.3747 - accuracy: 0.0156 - val_loss: 138.4856 - val_accuracy: 0.0588\n",
      "Epoch 9743/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 23.8729 - accuracy: 0.0156 - val_loss: 132.8997 - val_accuracy: 0.0588\n",
      "Epoch 9744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6813 - accuracy: 0.0312 - val_loss: 127.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2201 - accuracy: 0.0156 - val_loss: 114.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5964 - accuracy: 0.0000e+00 - val_loss: 106.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 9747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0348 - accuracy: 0.0000e+00 - val_loss: 108.2062 - val_accuracy: 0.0000e+00\n",
      "Epoch 9748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2951 - accuracy: 0.0312 - val_loss: 109.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 9749/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 20.4518 - accuracy: 0.0156 - val_loss: 112.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 9750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7600 - accuracy: 0.0000e+00 - val_loss: 114.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 9751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7644 - accuracy: 0.0000e+00 - val_loss: 119.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9752/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.1006 - accuracy: 0.0156 - val_loss: 130.6314 - val_accuracy: 0.0000e+00\n",
      "Epoch 9753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7530 - accuracy: 0.0156 - val_loss: 141.1164 - val_accuracy: 0.0000e+00\n",
      "Epoch 9754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9197 - accuracy: 0.0000e+00 - val_loss: 142.9347 - val_accuracy: 0.0588\n",
      "Epoch 9755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 146us/step - loss: 25.4191 - accuracy: 0.0156 - val_loss: 144.0330 - val_accuracy: 0.0588\n",
      "Epoch 9756/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 20.7748 - accuracy: 0.0000e+00 - val_loss: 147.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 9757/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 12.1885 - accuracy: 0.0000e+00 - val_loss: 151.3453 - val_accuracy: 0.0000e+00\n",
      "Epoch 9758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1946 - accuracy: 0.0312 - val_loss: 148.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9759/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.8838 - accuracy: 0.0156 - val_loss: 142.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9760/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.0210 - accuracy: 0.0312 - val_loss: 144.5968 - val_accuracy: 0.0588\n",
      "Epoch 9761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4783 - accuracy: 0.0156 - val_loss: 146.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 9762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2981 - accuracy: 0.0156 - val_loss: 139.4444 - val_accuracy: 0.0588\n",
      "Epoch 9763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8252 - accuracy: 0.0000e+00 - val_loss: 132.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 9764/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8942 - accuracy: 0.0000e+00 - val_loss: 130.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0345 - accuracy: 0.0156 - val_loss: 133.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 9766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4321 - accuracy: 0.0156 - val_loss: 140.2267 - val_accuracy: 0.0000e+00\n",
      "Epoch 9767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2799 - accuracy: 0.0000e+00 - val_loss: 143.9220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1345 - accuracy: 0.0156 - val_loss: 141.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4129 - accuracy: 0.0156 - val_loss: 142.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 9770/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4136 - accuracy: 0.0156 - val_loss: 143.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3914 - accuracy: 0.0156 - val_loss: 139.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 9772/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 26.0125 - accuracy: 0.0156 - val_loss: 130.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9773/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5652 - accuracy: 0.0000e+00 - val_loss: 128.3191 - val_accuracy: 0.0588\n",
      "Epoch 9774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9943 - accuracy: 0.0312 - val_loss: 133.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 9775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3976 - accuracy: 0.0156 - val_loss: 135.4029 - val_accuracy: 0.0000e+00\n",
      "Epoch 9776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3497 - accuracy: 0.0000e+00 - val_loss: 135.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 9777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9721 - accuracy: 0.0156 - val_loss: 140.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5376 - accuracy: 0.0312 - val_loss: 140.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 9779/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3276 - accuracy: 0.0156 - val_loss: 142.9469 - val_accuracy: 0.0588\n",
      "Epoch 9780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2765 - accuracy: 0.0312 - val_loss: 140.9481 - val_accuracy: 0.0000e+00\n",
      "Epoch 9781/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 18.1214 - accuracy: 0.0000e+00 - val_loss: 136.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 9782/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 18.1388 - accuracy: 0.0156 - val_loss: 129.2142 - val_accuracy: 0.0588\n",
      "Epoch 9783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5156 - accuracy: 0.0156 - val_loss: 129.8000 - val_accuracy: 0.0588\n",
      "Epoch 9784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5142 - accuracy: 0.0000e+00 - val_loss: 128.9942 - val_accuracy: 0.0588\n",
      "Epoch 9785/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3642 - accuracy: 0.0156 - val_loss: 137.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 9786/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0383 - accuracy: 0.0000e+00 - val_loss: 138.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 9787/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4812 - accuracy: 0.0312 - val_loss: 138.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3973 - accuracy: 0.0000e+00 - val_loss: 140.8858 - val_accuracy: 0.0000e+00\n",
      "Epoch 9789/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 18.3977 - accuracy: 0.0000e+00 - val_loss: 143.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 9790/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 22.7707 - accuracy: 0.0156 - val_loss: 143.7171 - val_accuracy: 0.0000e+00\n",
      "Epoch 9791/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0416 - accuracy: 0.0625 - val_loss: 138.7841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.6097 - accuracy: 0.0000e+00 - val_loss: 134.2821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9793/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 26.9096 - accuracy: 0.0000e+00 - val_loss: 131.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 9794/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.6334 - accuracy: 0.0156 - val_loss: 133.9877 - val_accuracy: 0.0000e+00\n",
      "Epoch 9795/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 25.6606 - accuracy: 0.0000e+00 - val_loss: 136.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 9796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2363 - accuracy: 0.0156 - val_loss: 131.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 9797/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 17.1662 - accuracy: 0.0156 - val_loss: 120.3871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9689 - accuracy: 0.0000e+00 - val_loss: 115.0418 - val_accuracy: 0.0000e+00\n",
      "Epoch 9799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0221 - accuracy: 0.0156 - val_loss: 119.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 9800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6919 - accuracy: 0.0156 - val_loss: 126.2330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5802 - accuracy: 0.0000e+00 - val_loss: 130.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 9802/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.8178 - accuracy: 0.0156 - val_loss: 133.8249 - val_accuracy: 0.0000e+00\n",
      "Epoch 9803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8571 - accuracy: 0.0312 - val_loss: 135.2689 - val_accuracy: 0.0588\n",
      "Epoch 9804/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 17.8366 - accuracy: 0.0156 - val_loss: 140.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 9805/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 26.1940 - accuracy: 0.0000e+00 - val_loss: 140.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 9806/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 27.1492 - accuracy: 0.0312 - val_loss: 136.7094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8840 - accuracy: 0.0312 - val_loss: 136.4389 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9808/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8019 - accuracy: 0.0156 - val_loss: 134.3683 - val_accuracy: 0.0588\n",
      "Epoch 9809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0171 - accuracy: 0.0469 - val_loss: 135.9400 - val_accuracy: 0.0588\n",
      "Epoch 9810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5297 - accuracy: 0.0156 - val_loss: 142.9810 - val_accuracy: 0.0588\n",
      "Epoch 9811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3681 - accuracy: 0.0000e+00 - val_loss: 148.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2550 - accuracy: 0.0156 - val_loss: 150.5835 - val_accuracy: 0.0588\n",
      "Epoch 9813/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.7702 - accuracy: 0.0312 - val_loss: 155.8535 - val_accuracy: 0.0588\n",
      "Epoch 9814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5540 - accuracy: 0.0156 - val_loss: 154.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 9815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3417 - accuracy: 0.0000e+00 - val_loss: 147.3181 - val_accuracy: 0.0000e+00\n",
      "Epoch 9816/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 25.4319 - accuracy: 0.0000e+00 - val_loss: 134.2848 - val_accuracy: 0.0588\n",
      "Epoch 9817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5004 - accuracy: 0.0156 - val_loss: 126.2099 - val_accuracy: 0.0588\n",
      "Epoch 9818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9409 - accuracy: 0.0469 - val_loss: 116.9361 - val_accuracy: 0.0588\n",
      "Epoch 9819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8694 - accuracy: 0.0000e+00 - val_loss: 114.7518 - val_accuracy: 0.0000e+00\n",
      "Epoch 9820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4985 - accuracy: 0.0156 - val_loss: 117.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 9821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2681 - accuracy: 0.0000e+00 - val_loss: 123.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 12.6758 - accuracy: 0.0156 - val_loss: 130.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 9823/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0121 - accuracy: 0.0156 - val_loss: 131.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 9824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7783 - accuracy: 0.0156 - val_loss: 133.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 9825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7341 - accuracy: 0.0156 - val_loss: 131.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 9826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7697 - accuracy: 0.0000e+00 - val_loss: 132.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 9827/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2829 - accuracy: 0.0000e+00 - val_loss: 143.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 9828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0121 - accuracy: 0.0156 - val_loss: 147.5552 - val_accuracy: 0.0000e+00\n",
      "Epoch 9829/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8841 - accuracy: 0.0156 - val_loss: 149.3094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0945 - accuracy: 0.0000e+00 - val_loss: 148.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7508 - accuracy: 0.0156 - val_loss: 144.5554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9832/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5929 - accuracy: 0.0000e+00 - val_loss: 143.9288 - val_accuracy: 0.0588\n",
      "Epoch 9833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0692 - accuracy: 0.0156 - val_loss: 140.9749 - val_accuracy: 0.0000e+00\n",
      "Epoch 9834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0479 - accuracy: 0.0000e+00 - val_loss: 142.5473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7787 - accuracy: 0.0156 - val_loss: 149.8914 - val_accuracy: 0.0000e+00\n",
      "Epoch 9836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6600 - accuracy: 0.0312 - val_loss: 155.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 9837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0483 - accuracy: 0.0000e+00 - val_loss: 158.3677 - val_accuracy: 0.0000e+00\n",
      "Epoch 9838/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7951 - accuracy: 0.0156 - val_loss: 148.7723 - val_accuracy: 0.0588\n",
      "Epoch 9839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6540 - accuracy: 0.0312 - val_loss: 130.4104 - val_accuracy: 0.0588\n",
      "Epoch 9840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4118 - accuracy: 0.0000e+00 - val_loss: 119.8856 - val_accuracy: 0.0588\n",
      "Epoch 9841/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0032 - accuracy: 0.0000e+00 - val_loss: 116.3536 - val_accuracy: 0.0588\n",
      "Epoch 9842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0724 - accuracy: 0.0000e+00 - val_loss: 121.2258 - val_accuracy: 0.0588\n",
      "Epoch 9843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6853 - accuracy: 0.0156 - val_loss: 124.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 9844/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5005 - accuracy: 0.0000e+00 - val_loss: 127.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 9845/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4078 - accuracy: 0.0156 - val_loss: 128.8052 - val_accuracy: 0.0000e+00\n",
      "Epoch 9846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7386 - accuracy: 0.0312 - val_loss: 130.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 9847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6525 - accuracy: 0.0312 - val_loss: 133.2626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2516 - accuracy: 0.0000e+00 - val_loss: 136.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5584 - accuracy: 0.0156 - val_loss: 140.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.1224 - accuracy: 0.0156 - val_loss: 138.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 9851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7589 - accuracy: 0.0156 - val_loss: 137.1912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9852/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4931 - accuracy: 0.0156 - val_loss: 136.6196 - val_accuracy: 0.0000e+00\n",
      "Epoch 9853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8562 - accuracy: 0.0312 - val_loss: 134.5401 - val_accuracy: 0.0588\n",
      "Epoch 9854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9951 - accuracy: 0.0312 - val_loss: 137.4819 - val_accuracy: 0.0588\n",
      "Epoch 9855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5575 - accuracy: 0.0156 - val_loss: 139.9357 - val_accuracy: 0.0588\n",
      "Epoch 9856/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 19.7628 - accuracy: 0.0000e+00 - val_loss: 138.9469 - val_accuracy: 0.0588\n",
      "Epoch 9857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8903 - accuracy: 0.0156 - val_loss: 136.4161 - val_accuracy: 0.0588\n",
      "Epoch 9858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5661 - accuracy: 0.0156 - val_loss: 128.9901 - val_accuracy: 0.0588\n",
      "Epoch 9859/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8383 - accuracy: 0.0156 - val_loss: 121.7066 - val_accuracy: 0.0588\n",
      "Epoch 9860/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2846 - accuracy: 0.0000e+00 - val_loss: 123.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 9861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 20.5489 - accuracy: 0.0156 - val_loss: 126.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 9862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5741 - accuracy: 0.0000e+00 - val_loss: 134.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3115 - accuracy: 0.0156 - val_loss: 137.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 9864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1069 - accuracy: 0.0312 - val_loss: 134.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0676 - accuracy: 0.0000e+00 - val_loss: 131.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 9866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2168 - accuracy: 0.0312 - val_loss: 129.2646 - val_accuracy: 0.0000e+00\n",
      "Epoch 9867/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 17.7584 - accuracy: 0.0000e+00 - val_loss: 122.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 9868/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 13.8331 - accuracy: 0.0312 - val_loss: 119.9726 - val_accuracy: 0.0000e+00\n",
      "Epoch 9869/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 24.3767 - accuracy: 0.0156 - val_loss: 126.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 9870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0840 - accuracy: 0.0000e+00 - val_loss: 130.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 9871/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0388 - accuracy: 0.0000e+00 - val_loss: 137.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 9872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9835 - accuracy: 0.0156 - val_loss: 138.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 9873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0819 - accuracy: 0.0000e+00 - val_loss: 138.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3286 - accuracy: 0.0000e+00 - val_loss: 137.4057 - val_accuracy: 0.0000e+00\n",
      "Epoch 9875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2267 - accuracy: 0.0000e+00 - val_loss: 132.9675 - val_accuracy: 0.0588\n",
      "Epoch 9876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6101 - accuracy: 0.0312 - val_loss: 128.0565 - val_accuracy: 0.0588\n",
      "Epoch 9877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9025 - accuracy: 0.0000e+00 - val_loss: 123.6505 - val_accuracy: 0.0000e+00\n",
      "Epoch 9878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6745 - accuracy: 0.0000e+00 - val_loss: 121.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 9879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6294 - accuracy: 0.0469 - val_loss: 118.0145 - val_accuracy: 0.0588\n",
      "Epoch 9880/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 11.6311 - accuracy: 0.0469 - val_loss: 119.2055 - val_accuracy: 0.0588\n",
      "Epoch 9881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5938 - accuracy: 0.0156 - val_loss: 128.1972 - val_accuracy: 0.0588\n",
      "Epoch 9882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5170 - accuracy: 0.0312 - val_loss: 137.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 9883/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0622 - accuracy: 0.0000e+00 - val_loss: 142.8014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9884/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 18.7405 - accuracy: 0.0312 - val_loss: 147.1757 - val_accuracy: 0.0588\n",
      "Epoch 9885/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.3695 - accuracy: 0.0156 - val_loss: 149.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 9886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4821 - accuracy: 0.0312 - val_loss: 143.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 9887/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7226 - accuracy: 0.0156 - val_loss: 137.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 9888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2852 - accuracy: 0.0156 - val_loss: 132.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 9889/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.9024 - accuracy: 0.0000e+00 - val_loss: 132.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.0202 - accuracy: 0.0156 - val_loss: 136.5415 - val_accuracy: 0.0588\n",
      "Epoch 9891/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 19.9693 - accuracy: 0.0156 - val_loss: 141.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 9892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9216 - accuracy: 0.0156 - val_loss: 143.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 9893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0354 - accuracy: 0.0156 - val_loss: 140.8451 - val_accuracy: 0.0000e+00\n",
      "Epoch 9894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4093 - accuracy: 0.0156 - val_loss: 140.2601 - val_accuracy: 0.0000e+00\n",
      "Epoch 9895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2776 - accuracy: 0.0312 - val_loss: 136.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 9896/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0587 - accuracy: 0.0000e+00 - val_loss: 135.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 9897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7326 - accuracy: 0.0156 - val_loss: 136.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3747 - accuracy: 0.0312 - val_loss: 133.9438 - val_accuracy: 0.0000e+00\n",
      "Epoch 9899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3149 - accuracy: 0.0000e+00 - val_loss: 130.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 9900/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8423 - accuracy: 0.0156 - val_loss: 129.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 9901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8991 - accuracy: 0.0000e+00 - val_loss: 130.5184 - val_accuracy: 0.0000e+00\n",
      "Epoch 9902/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3263 - accuracy: 0.0469 - val_loss: 132.6555 - val_accuracy: 0.0000e+00\n",
      "Epoch 9903/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.3696 - accuracy: 0.0000e+00 - val_loss: 138.7850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2420 - accuracy: 0.0156 - val_loss: 144.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 9905/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9009 - accuracy: 0.0000e+00 - val_loss: 141.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 9906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0441 - accuracy: 0.0156 - val_loss: 139.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 9907/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 17.7673 - accuracy: 0.0000e+00 - val_loss: 135.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 9908/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.1774 - accuracy: 0.0000e+00 - val_loss: 127.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9909/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 28.2023 - accuracy: 0.0000e+00 - val_loss: 134.7958 - val_accuracy: 0.0588\n",
      "Epoch 9910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9527 - accuracy: 0.0156 - val_loss: 142.7298 - val_accuracy: 0.0000e+00\n",
      "Epoch 9911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4083 - accuracy: 0.0000e+00 - val_loss: 145.3673 - val_accuracy: 0.0000e+00\n",
      "Epoch 9912/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 19.7469 - accuracy: 0.0000e+00 - val_loss: 136.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 9913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1333 - accuracy: 0.0156 - val_loss: 127.5220 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9914/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 21.5244 - accuracy: 0.0156 - val_loss: 118.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7651 - accuracy: 0.0000e+00 - val_loss: 118.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 9916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3594 - accuracy: 0.0156 - val_loss: 122.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8850 - accuracy: 0.0000e+00 - val_loss: 131.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8709 - accuracy: 0.0156 - val_loss: 145.3707 - val_accuracy: 0.0000e+00\n",
      "Epoch 9919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2574 - accuracy: 0.0000e+00 - val_loss: 157.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9920/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.0027 - accuracy: 0.0000e+00 - val_loss: 161.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 9921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8416 - accuracy: 0.0000e+00 - val_loss: 161.3845 - val_accuracy: 0.0588\n",
      "Epoch 9922/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7491 - accuracy: 0.0000e+00 - val_loss: 158.4932 - val_accuracy: 0.0588\n",
      "Epoch 9923/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.5067 - accuracy: 0.0156 - val_loss: 150.7121 - val_accuracy: 0.0588\n",
      "Epoch 9924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5500 - accuracy: 0.0156 - val_loss: 142.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 9925/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 16.4700 - accuracy: 0.0156 - val_loss: 137.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 9926/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3697 - accuracy: 0.0312 - val_loss: 140.4536 - val_accuracy: 0.0588\n",
      "Epoch 9927/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 18.5994 - accuracy: 0.0156 - val_loss: 150.6473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9928/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 34.8550 - accuracy: 0.0000e+00 - val_loss: 145.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9929/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7432 - accuracy: 0.0000e+00 - val_loss: 134.8129 - val_accuracy: 0.0000e+00\n",
      "Epoch 9930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5265 - accuracy: 0.0312 - val_loss: 138.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2614 - accuracy: 0.0156 - val_loss: 140.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4695 - accuracy: 0.0312 - val_loss: 137.1681 - val_accuracy: 0.0588\n",
      "Epoch 9933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5590 - accuracy: 0.0312 - val_loss: 133.5997 - val_accuracy: 0.0588\n",
      "Epoch 9934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.8961 - accuracy: 0.0000e+00 - val_loss: 133.8285 - val_accuracy: 0.0000e+00\n",
      "Epoch 9935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3694 - accuracy: 0.0000e+00 - val_loss: 129.2549 - val_accuracy: 0.0000e+00\n",
      "Epoch 9936/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 20.6409 - accuracy: 0.0000e+00 - val_loss: 126.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 9937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4960 - accuracy: 0.0156 - val_loss: 124.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 9938/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 13.9020 - accuracy: 0.0312 - val_loss: 127.3492 - val_accuracy: 0.0000e+00\n",
      "Epoch 9939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2015 - accuracy: 0.0156 - val_loss: 133.3389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2568 - accuracy: 0.0000e+00 - val_loss: 137.6930 - val_accuracy: 0.0000e+00\n",
      "Epoch 9941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0052 - accuracy: 0.0000e+00 - val_loss: 141.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 9942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1345 - accuracy: 0.0000e+00 - val_loss: 143.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 9943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7143 - accuracy: 0.0156 - val_loss: 142.5836 - val_accuracy: 0.0000e+00\n",
      "Epoch 9944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0583 - accuracy: 0.0156 - val_loss: 140.3309 - val_accuracy: 0.0000e+00\n",
      "Epoch 9945/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8896 - accuracy: 0.0312 - val_loss: 138.8116 - val_accuracy: 0.0588\n",
      "Epoch 9946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0064 - accuracy: 0.0312 - val_loss: 135.3931 - val_accuracy: 0.0588\n",
      "Epoch 9947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.7425 - accuracy: 0.0000e+00 - val_loss: 134.7969 - val_accuracy: 0.0588\n",
      "Epoch 9948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5458 - accuracy: 0.0000e+00 - val_loss: 138.7638 - val_accuracy: 0.0588\n",
      "Epoch 9949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0550 - accuracy: 0.0000e+00 - val_loss: 147.5381 - val_accuracy: 0.0588\n",
      "Epoch 9950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8965 - accuracy: 0.0000e+00 - val_loss: 157.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 9951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9413 - accuracy: 0.0156 - val_loss: 159.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 9952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9299 - accuracy: 0.0156 - val_loss: 153.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6821 - accuracy: 0.0000e+00 - val_loss: 147.0964 - val_accuracy: 0.0000e+00\n",
      "Epoch 9954/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.9601 - accuracy: 0.0469 - val_loss: 140.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5633 - accuracy: 0.0000e+00 - val_loss: 140.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.2776 - accuracy: 0.0156 - val_loss: 146.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 9957/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 16.2912 - accuracy: 0.0156 - val_loss: 150.1909 - val_accuracy: 0.0000e+00\n",
      "Epoch 9958/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5315 - accuracy: 0.0156 - val_loss: 151.0567 - val_accuracy: 0.0000e+00\n",
      "Epoch 9959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8898 - accuracy: 0.0000e+00 - val_loss: 144.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 9960/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 19.4253 - accuracy: 0.0156 - val_loss: 138.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 9961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1945 - accuracy: 0.0156 - val_loss: 134.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 9962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4369 - accuracy: 0.0000e+00 - val_loss: 132.9970 - val_accuracy: 0.0000e+00\n",
      "Epoch 9963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.6507 - accuracy: 0.0469 - val_loss: 129.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.1365 - accuracy: 0.0156 - val_loss: 127.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 9965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1047 - accuracy: 0.0156 - val_loss: 133.4317 - val_accuracy: 0.0588\n",
      "Epoch 9966/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2456 - accuracy: 0.0000e+00 - val_loss: 145.9754 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9967/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 18.2778 - accuracy: 0.0156 - val_loss: 156.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 9968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8304 - accuracy: 0.0000e+00 - val_loss: 165.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 9969/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 26.9529 - accuracy: 0.0156 - val_loss: 165.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 9970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1319 - accuracy: 0.0000e+00 - val_loss: 155.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.5019 - accuracy: 0.0156 - val_loss: 140.1994 - val_accuracy: 0.0000e+00\n",
      "Epoch 9972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0858 - accuracy: 0.0000e+00 - val_loss: 137.1344 - val_accuracy: 0.0588\n",
      "Epoch 9973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9209 - accuracy: 0.0000e+00 - val_loss: 142.1771 - val_accuracy: 0.0000e+00\n",
      "Epoch 9974/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 13.9946 - accuracy: 0.0156 - val_loss: 145.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 9975/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 15.8515 - accuracy: 0.0156 - val_loss: 149.1477 - val_accuracy: 0.0000e+00\n",
      "Epoch 9976/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8100 - accuracy: 0.0000e+00 - val_loss: 156.3189 - val_accuracy: 0.0588\n",
      "Epoch 9977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2784 - accuracy: 0.0000e+00 - val_loss: 159.5592 - val_accuracy: 0.0000e+00\n",
      "Epoch 9978/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 15.4704 - accuracy: 0.0000e+00 - val_loss: 147.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 9979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0433 - accuracy: 0.0156 - val_loss: 139.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9980/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7576 - accuracy: 0.0312 - val_loss: 123.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 9981/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 18.6951 - accuracy: 0.0156 - val_loss: 130.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 9982/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9880 - accuracy: 0.0000e+00 - val_loss: 138.0385 - val_accuracy: 0.0588\n",
      "Epoch 9983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9351 - accuracy: 0.0156 - val_loss: 136.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 9984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1129 - accuracy: 0.0156 - val_loss: 135.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 9985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2055 - accuracy: 0.0000e+00 - val_loss: 132.7384 - val_accuracy: 0.0000e+00\n",
      "Epoch 9986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1778 - accuracy: 0.0156 - val_loss: 131.2520 - val_accuracy: 0.0000e+00\n",
      "Epoch 9987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7390 - accuracy: 0.0000e+00 - val_loss: 130.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 9988/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 15.5808 - accuracy: 0.0000e+00 - val_loss: 130.2360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7069 - accuracy: 0.0156 - val_loss: 135.5590 - val_accuracy: 0.0588\n",
      "Epoch 9990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3631 - accuracy: 0.0000e+00 - val_loss: 135.1702 - val_accuracy: 0.1176\n",
      "Epoch 9991/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0321 - accuracy: 0.0156 - val_loss: 131.2747 - val_accuracy: 0.1176\n",
      "Epoch 9992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4510 - accuracy: 0.0000e+00 - val_loss: 121.9860 - val_accuracy: 0.0000e+00\n",
      "Epoch 9993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1156 - accuracy: 0.0000e+00 - val_loss: 123.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 9994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6018 - accuracy: 0.0156 - val_loss: 128.0817 - val_accuracy: 0.0000e+00\n",
      "Epoch 9995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7382 - accuracy: 0.0156 - val_loss: 130.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 9996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7135 - accuracy: 0.0312 - val_loss: 132.3255 - val_accuracy: 0.0000e+00\n",
      "Epoch 9997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2128 - accuracy: 0.0000e+00 - val_loss: 132.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 9998/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6554 - accuracy: 0.0156 - val_loss: 131.8360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9999/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7084 - accuracy: 0.0156 - val_loss: 132.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 10000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9720 - accuracy: 0.0469 - val_loss: 137.9646 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = model.fit(test_data_x, test_data_y, epochs=10000, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red')\n",
    "plt.plot(data_history['loss'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.044183</td>\n",
       "      <td>0.066405</td>\n",
       "      <td>0.121921</td>\n",
       "      <td>0.206038</td>\n",
       "      <td>0.288564</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.503240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421101</td>\n",
       "      <td>0.581313</td>\n",
       "      <td>0.674222</td>\n",
       "      <td>0.707964</td>\n",
       "      <td>0.704825</td>\n",
       "      <td>0.634228</td>\n",
       "      <td>0.577624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>0.065548</td>\n",
       "      <td>0.062322</td>\n",
       "      <td>0.060254</td>\n",
       "      <td>0.065530</td>\n",
       "      <td>0.092613</td>\n",
       "      <td>0.145811</td>\n",
       "      <td>0.205864</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>0.328832</td>\n",
       "      <td>0.435089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334879</td>\n",
       "      <td>0.437199</td>\n",
       "      <td>0.497421</td>\n",
       "      <td>0.531572</td>\n",
       "      <td>0.544168</td>\n",
       "      <td>0.511745</td>\n",
       "      <td>0.573746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.043313</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.075615</td>\n",
       "      <td>0.120446</td>\n",
       "      <td>0.184025</td>\n",
       "      <td>0.261701</td>\n",
       "      <td>0.369852</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466931</td>\n",
       "      <td>0.615784</td>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.753730</td>\n",
       "      <td>0.754293</td>\n",
       "      <td>0.637584</td>\n",
       "      <td>0.472356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.122190</td>\n",
       "      <td>0.193307</td>\n",
       "      <td>0.259890</td>\n",
       "      <td>0.326314</td>\n",
       "      <td>0.414541</td>\n",
       "      <td>0.542426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479133</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.751051</td>\n",
       "      <td>0.801043</td>\n",
       "      <td>0.817695</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.591887</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.060565</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>0.064028</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.247979</td>\n",
       "      <td>0.311369</td>\n",
       "      <td>0.376568</td>\n",
       "      <td>0.480816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459529</td>\n",
       "      <td>0.553023</td>\n",
       "      <td>0.597067</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.585570</td>\n",
       "      <td>0.669323</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "6    0.028796  0.031857  0.035953  0.044183  0.066405  0.121921  0.206038   \n",
       "677  0.065548  0.062322  0.060254  0.065530  0.092613  0.145811  0.205864   \n",
       "364  0.045745  0.043313  0.042787  0.050618  0.075615  0.120446  0.184025   \n",
       "255  0.051508  0.052033  0.054948  0.071690  0.122190  0.193307  0.259890   \n",
       "683  0.063436  0.060565  0.058813  0.064028  0.093407  0.162574  0.247979   \n",
       "\n",
       "           f8        f9       f10  ...       f56       f57       f58  \\\n",
       "6    0.288564  0.381148  0.503240  ...  0.421101  0.581313  0.674222   \n",
       "677  0.259082  0.328832  0.435089  ...  0.334879  0.437199  0.497421   \n",
       "364  0.261701  0.369852  0.525703  ...  0.466931  0.615784  0.709372   \n",
       "255  0.326314  0.414541  0.542426  ...  0.479133  0.648237  0.751051   \n",
       "683  0.311369  0.376568  0.480816  ...  0.459529  0.553023  0.597067   \n",
       "\n",
       "          f59       f60       f61       f62  f63  f64    target  \n",
       "6    0.707964  0.704825  0.634228  0.577624    0    1  0.347541  \n",
       "677  0.531572  0.544168  0.511745  0.573746    1    0  0.388197  \n",
       "364  0.753730  0.754293  0.637584  0.472356    0    1  0.344918  \n",
       "255  0.801043  0.817695  0.570470  0.591887    0    1  0.327869  \n",
       "683  0.612529  0.606061  0.585570  0.669323    1    0  0.411148  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy_dataframe = pd.read_excel('X.xlsx')\n",
    "canopy_dataframe = canopy_dataframe.reindex(np.random.permutation(canopy_dataframe.index))\n",
    "canopy_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the data :  (805, 65)\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows and columns in the data : ', canopy_dataframe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = canopy_dataframe['target'].values\n",
    "x_train = canopy_dataframe[canopy_dataframe.columns[canopy_dataframe.columns!='target']].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563,)\n",
      "(563, 64)\n",
      "(242, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 8,585\n",
      "Trainable params: 8,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "default_model = build_medium_regression_model(64)\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "default_model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "default_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 113 samples\n",
      "Epoch 1/10000\n",
      "450/450 [==============================] - 0s 642us/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0491 - accuracy: 0.0000e+00 - val_loss: 0.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0336 - accuracy: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "450/450 [==============================] - 0s 71us/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/10000\n",
      "450/450 [==============================] - 0s 71us/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/10000\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/10000\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/10000\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/10000\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/10000\n",
      "450/450 [==============================] - 0s 67us/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/10000\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/10000\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/10000\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 00067: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = default_model.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red')\n",
    "plt.plot(data_history['loss'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "x_train = x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prn.CreateNN([32, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  25.4806223918662 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  0.13294383152426648 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  0.12767144260074254 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  3 \t\tError:  0.12408018035644208 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  4 \t\tError:  0.12293902009681015 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  5 \t\tError:  0.12180346807176798 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  6 \t\tError:  0.12059951225562018 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  7 \t\tError:  0.11937903852261858 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  8 \t\tError:  0.11826617387809281 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  9 \t\tError:  0.11733334914155179 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  10 \t\tError:  0.11657992729455262 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  11 \t\tError:  0.11597090958837045 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  12 \t\tError:  0.1154683835228018 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  13 \t\tError:  0.1150426266011995 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  14 \t\tError:  0.11472753945816182 \tscale factor:  0.001016105268505817\n",
      "Iteration:  15 \t\tError:  0.11283943425146734 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  16 \t\tError:  0.1098880331944816 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  17 \t\tError:  0.10799964990700504 \tscale factor:  0.001016105268505817\n",
      "Iteration:  18 \t\tError:  0.10670817163820753 \tscale factor:  0.001016105268505817\n",
      "Iteration:  19 \t\tError:  0.1055299228484931 \tscale factor:  0.001016105268505817\n",
      "Iteration:  20 \t\tError:  0.10421029217173036 \tscale factor:  0.001016105268505817\n",
      "Iteration:  21 \t\tError:  0.10276304219374216 \tscale factor:  0.001016105268505817\n",
      "Iteration:  22 \t\tError:  0.10119388283918573 \tscale factor:  0.001016105268505817\n",
      "Iteration:  23 \t\tError:  0.09952177666967658 \tscale factor:  0.001016105268505817\n",
      "Iteration:  24 \t\tError:  0.09777596612240622 \tscale factor:  0.001016105268505817\n",
      "Iteration:  25 \t\tError:  0.09599202329221579 \tscale factor:  0.001016105268505817\n",
      "Iteration:  26 \t\tError:  0.09420714908610925 \tscale factor:  0.001016105268505817\n",
      "Iteration:  27 \t\tError:  0.09349214117551445 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  28 \t\tError:  0.08741713527439453 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  29 \t\tError:  0.08392092129476365 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  30 \t\tError:  0.0814196816195614 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  31 \t\tError:  0.08119703777677217 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  32 \t\tError:  0.07742708848139301 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  33 \t\tError:  0.0760962488041549 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  34 \t\tError:  0.07575053536815804 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  35 \t\tError:  0.07552114457431396 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  36 \t\tError:  0.07534479764442714 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  37 \t\tError:  0.07519928877944962 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  38 \t\tError:  0.07505549834834711 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  39 \t\tError:  0.07488754572419626 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  40 \t\tError:  0.0746786433041662 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  41 \t\tError:  0.07442224138247662 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  42 \t\tError:  0.07412115531925415 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  43 \t\tError:  0.073786662411297 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  44 \t\tError:  0.07343552510377521 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  45 \t\tError:  0.07308357702256886 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  46 \t\tError:  0.0727391430048602 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  47 \t\tError:  0.07240141993418639 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  48 \t\tError:  0.07180058392417828 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  49 \t\tError:  0.07086043112769577 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  50 \t\tError:  0.06988153550087198 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  51 \t\tError:  0.06966336517755108 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  52 \t\tError:  0.06842368034740051 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  53 \t\tError:  0.06775608044100236 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  54 \t\tError:  0.0677226086006471 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  55 \t\tError:  0.06600875091240364 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  56 \t\tError:  0.06564383017383169 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  57 \t\tError:  0.06521879818474474 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  58 \t\tError:  0.06478488137709788 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  59 \t\tError:  0.06437798320459988 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  60 \t\tError:  0.0639469399290861 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  61 \t\tError:  0.0635384846433919 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  62 \t\tError:  0.06315987820620787 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  63 \t\tError:  0.06288050334355239 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  64 \t\tError:  0.06287905784851316 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  65 \t\tError:  0.06217425116239683 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  66 \t\tError:  0.06192401988245038 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  67 \t\tError:  0.061845113728651355 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  68 \t\tError:  0.06124193751010584 \tscale factor:  0.001016105268505817\n",
      "Iteration:  69 \t\tError:  0.06104634596012106 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  70 \t\tError:  0.06086740070368087 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  71 \t\tError:  0.06041389917280958 \tscale factor:  0.001016105268505817\n",
      "Iteration:  72 \t\tError:  0.060218345450520606 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  73 \t\tError:  0.059986263608602514 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  74 \t\tError:  0.059626215386758934 \tscale factor:  0.001016105268505817\n",
      "Iteration:  75 \t\tError:  0.05943591452137713 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  76 \t\tError:  0.05917138310308272 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  77 \t\tError:  0.05888117271241339 \tscale factor:  0.001016105268505817\n",
      "Iteration:  78 \t\tError:  0.05869925772032837 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  79 \t\tError:  0.05841109997477 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  80 \t\tError:  0.058180251898138025 \tscale factor:  0.001016105268505817\n",
      "Iteration:  81 \t\tError:  0.05800882562150304 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  82 \t\tError:  0.05770008809632095 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  83 \t\tError:  0.057523792614353926 \tscale factor:  0.001016105268505817\n",
      "Iteration:  84 \t\tError:  0.057364087600864644 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  85 \t\tError:  0.05703705720360215 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  86 \t\tError:  0.05691102398368945 \tscale factor:  0.001016105268505817\n",
      "Iteration:  87 \t\tError:  0.056763321938660585 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  88 \t\tError:  0.05642426825499583 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  89 \t\tError:  0.05634024022489172 \tscale factor:  0.001016105268505817\n",
      "Iteration:  90 \t\tError:  0.05620385690458262 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  91 \t\tError:  0.05586504537045278 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  92 \t\tError:  0.05580888136948105 \tscale factor:  0.001016105268505817\n",
      "Iteration:  93 \t\tError:  0.05568243814303946 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  94 \t\tError:  0.05535809376727381 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  95 \t\tError:  0.05529429670387385 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  96 \t\tError:  0.055100805664034316 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  97 \t\tError:  0.054903672922301285 \tscale factor:  0.001016105268505817\n",
      "Iteration:  98 \t\tError:  0.05479789421067231 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  99 \t\tError:  0.054512124528546944 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  100 \t\tError:  0.054501105504996525 \tscale factor:  0.00037633528463178407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  101 \t\tError:  0.05428051609448088 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  102 \t\tError:  0.0540817801309882 \tscale factor:  0.001016105268505817\n",
      "Iteration:  103 \t\tError:  0.05398995417111241 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  104 \t\tError:  0.053717577427860916 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  105 \t\tError:  0.053640098675879655 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  106 \t\tError:  0.0533701868549085 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  107 \t\tError:  0.05328734430897948 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  108 \t\tError:  0.053030146735875014 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  109 \t\tError:  0.052976072913881816 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  110 \t\tError:  0.05279727422054804 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  111 \t\tError:  0.05247744932035972 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  112 \t\tError:  0.052358971947997435 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  113 \t\tError:  0.052200642489724884 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  114 \t\tError:  0.05194027328072506 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  115 \t\tError:  0.05157464960491345 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  116 \t\tError:  0.05140555499806197 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  117 \t\tError:  0.05110483536780355 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  118 \t\tError:  0.05059466062615564 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  119 \t\tError:  0.05037497853843018 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  120 \t\tError:  0.05013518620571414 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  121 \t\tError:  0.04987008352968256 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  122 \t\tError:  0.04945944563866814 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  123 \t\tError:  0.04939327061595338 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  124 \t\tError:  0.04923781625482667 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  125 \t\tError:  0.04889301572482003 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  126 \t\tError:  0.048762115844158294 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  127 \t\tError:  0.04846375989270482 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  128 \t\tError:  0.04839619112056537 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  129 \t\tError:  0.0481306054424281 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  130 \t\tError:  0.04811779525476933 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  131 \t\tError:  0.04785104490467992 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  132 \t\tError:  0.047805689941328486 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  133 \t\tError:  0.04762676829912233 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  134 \t\tError:  0.04749913298763038 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  135 \t\tError:  0.0474335792044481 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  136 \t\tError:  0.04736073879582535 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  137 \t\tError:  0.04724165257950198 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  138 \t\tError:  0.04705626432022667 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  139 \t\tError:  0.047032731153225024 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  140 \t\tError:  0.04696171554318977 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  141 \t\tError:  0.0469063624155376 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  142 \t\tError:  0.046794106107783895 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  143 \t\tError:  0.04672970084426725 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  144 \t\tError:  0.04666275482857083 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  145 \t\tError:  0.04665516263440556 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  146 \t\tError:  0.04653846049430575 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  147 \t\tError:  0.04649641335311615 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  148 \t\tError:  0.04647364899012274 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  149 \t\tError:  0.04645264194803975 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  150 \t\tError:  0.046432734141010616 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  151 \t\tError:  0.04641386338652638 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  152 \t\tError:  0.04639602747199514 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  153 \t\tError:  0.04637926190539117 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  154 \t\tError:  0.046363636839244285 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  155 \t\tError:  0.046349254510767504 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  156 \t\tError:  0.04633624708843416 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  157 \t\tError:  0.04632477001578962 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  158 \t\tError:  0.04631498899571118 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  159 \t\tError:  0.04630705639003714 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  160 \t\tError:  0.04630107298177327 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  161 \t\tError:  0.046297030007233675 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  162 \t\tError:  0.046294727451370477 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  163 \t\tError:  0.046293669000414005 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  164 \t\tError:  0.046292937021777884 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  165 \t\tError:  0.046291063372469576 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  166 \t\tError:  0.0462859201202223 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  167 \t\tError:  0.04627469687788044 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  168 \t\tError:  0.046254033055197014 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  169 \t\tError:  0.04622041409600903 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  170 \t\tError:  0.04617101507303513 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  171 \t\tError:  0.04610521228177464 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  172 \t\tError:  0.04594867858100511 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  173 \t\tError:  0.04591739548998639 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  174 \t\tError:  0.04586165060998368 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  175 \t\tError:  0.04584325936675515 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  176 \t\tError:  0.04582447005317079 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  177 \t\tError:  0.04580755632823823 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  178 \t\tError:  0.04578990130393671 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  179 \t\tError:  0.045771229794064366 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  180 \t\tError:  0.04575115213448658 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  181 \t\tError:  0.04572913067373827 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  182 \t\tError:  0.04570454119572445 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  183 \t\tError:  0.04567680058129227 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  184 \t\tError:  0.045645525515548686 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  185 \t\tError:  0.04561067380982638 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  186 \t\tError:  0.045572622762012904 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  187 \t\tError:  0.04553215983132172 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  188 \t\tError:  0.04549038322349589 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  189 \t\tError:  0.045448520384084576 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  190 \t\tError:  0.04537053208552837 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  191 \t\tError:  0.045322191494351 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  192 \t\tError:  0.04527402999317199 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  193 \t\tError:  0.04523861863551921 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  194 \t\tError:  0.04520391700583741 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  195 \t\tError:  0.04516901817968125 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  196 \t\tError:  0.045133160279019174 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  197 \t\tError:  0.0450959703206264 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  198 \t\tError:  0.0450573427445045 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  199 \t\tError:  0.04501730402485285 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  200 \t\tError:  0.04497591943255336 \tscale factor:  0.0001393834387525126\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=200, E_stop=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prn.NNOut(x_train, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_train_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.093109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.047459</td>\n",
       "      <td>0.035673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051703</td>\n",
       "      <td>0.044996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.030793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070224</td>\n",
       "      <td>0.066673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_train  y_train_pred\n",
       "0  0.114210      0.093109\n",
       "1  0.047459      0.035673\n",
       "2  0.051703      0.044996\n",
       "3  0.045144      0.030793\n",
       "4  0.070224      0.066673"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': y.flatten()})\n",
    "acc_sc_chk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.6891513783874852 / 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score_1 = r2_score(acc_sc_chk.y_train, acc_sc_chk.y_train_pred)\n",
    "print('r2 score = ', r2_score_1, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prn.NNOut(x_test, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.019727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.037801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>0.065511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>0.008591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_test_pred\n",
       "0  0.018135     0.019727\n",
       "1  0.002701     0.016599\n",
       "2  0.002701     0.037801\n",
       "3  0.089130     0.065511\n",
       "4  0.033569     0.008591"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk_2 = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': y_pred.flatten()})\n",
    "acc_sc_chk_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.3547752701549468 / 1.0\n"
     ]
    }
   ],
   "source": [
    " r2_score = r2_score(acc_sc_chk_2.y_test, acc_sc_chk_2.y_test_pred)\n",
    "print('r2 score = ', r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[           id  CC160323  CC160328  CC160329  CC160331  CC160414  CC160419  \\\n",
      "0    0.000349  0.002941  0.005263  0.006426  0.006561  0.010057  0.010712   \n",
      "1    0.000697  0.001944  0.004398  0.005121  0.006285  0.010145  0.009603   \n",
      "2    0.001046  0.001727  0.003102  0.004388  0.004193  0.008887  0.009074   \n",
      "3    0.001394  0.001319  0.002720  0.004339  0.003934  0.007248  0.007119   \n",
      "4    0.001743  0.003098  0.005202  0.005608  0.006448  0.008060  0.007821   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.083313  0.000000  0.000000  0.000000  0.000000  0.001720  0.002330   \n",
      "239  0.083662  0.000000  0.000000  0.000000  0.000000  0.001812  0.002173   \n",
      "240  0.084010  0.000000  0.000000  0.000000  0.000000  0.001230  0.001899   \n",
      "241  0.084359  0.000000  0.000000  0.000000  0.000000  0.001490  0.002664   \n",
      "242  0.084707  0.000000  0.000000  0.000000  0.000001  0.001482  0.002940   \n",
      "\n",
      "     CC160421  CC160425  CC160504  CC160510  CC160512  CC160516  CC160523  \\\n",
      "0    0.011305  0.011080  0.008448  0.009489  0.012636  0.011800  0.010251   \n",
      "1    0.010816  0.009170  0.009070  0.007931  0.011137  0.008938  0.008315   \n",
      "2    0.010235  0.009133  0.007139  0.008947  0.012485  0.011081  0.008663   \n",
      "3    0.008914  0.008639  0.007002  0.008612  0.012974  0.011293  0.009483   \n",
      "4    0.009087  0.008080  0.008852  0.007366  0.010697  0.009211  0.007997   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.004043  0.005293  0.005727  0.011309  0.013580  0.018191  0.009292   \n",
      "239  0.004108  0.005331  0.004309  0.011551  0.013644  0.015621  0.014607   \n",
      "240  0.003310  0.004341  0.005157  0.009925  0.012135  0.011794  0.010537   \n",
      "241  0.004283  0.005703  0.005466  0.008806  0.010194  0.013427  0.012113   \n",
      "242  0.004285  0.005069  0.004730  0.010760  0.012306  0.014803  0.013732   \n",
      "\n",
      "     CC160524  CC160525  CC160609  CC160616  CC160622  \n",
      "0    0.011200  0.011306  0.009176  0.013678  0.008847  \n",
      "1    0.008664  0.010572  0.007429  0.010679  0.015020  \n",
      "2    0.010304  0.010882  0.009008  0.018495  0.023976  \n",
      "3    0.010331  0.009867  0.010559  0.017769  0.024659  \n",
      "4    0.008861  0.009668  0.006515  0.007789  0.011669  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.009236  0.008577  0.007939  0.008867  0.012720  \n",
      "239  0.014683  0.013160  0.012560  0.014917  0.012712  \n",
      "240  0.009572  0.006973  0.008734  0.009413  0.008558  \n",
      "241  0.012910  0.010324  0.010369  0.009800  0.009256  \n",
      "242  0.012615  0.012939  0.011703  0.011915  0.009943  \n",
      "\n",
      "[243 rows x 19 columns],            id  CV160323  CV160328  CV160329  CV160331  CV160414  CV160419  \\\n",
      "0    0.000456  0.000025  0.000241  0.000039 -0.000555  0.000303  0.000506   \n",
      "1    0.000911 -0.000007  0.000144 -0.000058 -0.000761  0.000123  0.000359   \n",
      "2    0.001367  0.000026  0.000162 -0.000018 -0.000698  0.000148  0.000367   \n",
      "3    0.001822  0.000020  0.000175 -0.000022 -0.000684  0.000160  0.000342   \n",
      "4    0.002278  0.000062  0.000197 -0.000005 -0.000691  0.000163  0.000318   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.108887  0.000011  0.000009 -0.000057 -0.000326 -0.000038  0.000033   \n",
      "239  0.109342  0.000023  0.000024 -0.000032 -0.000252 -0.000037  0.000048   \n",
      "240  0.109798  0.000020  0.000016 -0.000037 -0.000203 -0.000059  0.000038   \n",
      "241  0.110254  0.000017  0.000017 -0.000025 -0.000149 -0.000093  0.000054   \n",
      "242  0.110709  0.000072  0.000083  0.000051 -0.000041 -0.000103  0.000109   \n",
      "\n",
      "     CV160421  CV160425  CV160504  CV160510  CV160512  CV160516  CV160523  \\\n",
      "0    0.000528  0.000572  0.000589  0.000483  0.000570  0.000552  0.000549   \n",
      "1    0.000381  0.000426  0.000429  0.000391  0.000435  0.000420  0.000365   \n",
      "2    0.000371  0.000381  0.000445  0.000345  0.000424  0.000407  0.000360   \n",
      "3    0.000378  0.000391  0.000533  0.000390  0.000536  0.000454  0.000398   \n",
      "4    0.000331  0.000389  0.000434  0.000382  0.000463  0.000434  0.000392   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.000110  0.000096  0.000256  0.000240  0.000341  0.000265  0.000243   \n",
      "239  0.000122  0.000098  0.000288  0.000353  0.000542  0.000455  0.000537   \n",
      "240  0.000092  0.000061  0.000205  0.000308  0.000401  0.000306  0.000333   \n",
      "241  0.000102  0.000086  0.000232  0.000300  0.000344  0.000346  0.000387   \n",
      "242  0.000175  0.000124  0.000252  0.000369  0.000444  0.000436  0.000437   \n",
      "\n",
      "     CV160524  CV160525  CV160609  CV160616  CV160622  \n",
      "0    0.000591  0.000611  0.000564  0.000425  0.000464  \n",
      "1    0.000432  0.000391  0.000287  0.000283  0.000357  \n",
      "2    0.000403  0.000385  0.000255  0.000202  0.000382  \n",
      "3    0.000399  0.000406  0.000295  0.000267  0.000451  \n",
      "4    0.000412  0.000416  0.000286  0.000265  0.000326  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.000261  0.000289  0.000277  0.000185  0.000373  \n",
      "239  0.000580  0.000656  0.000488  0.000347  0.000510  \n",
      "240  0.000333  0.000385  0.000344  0.000242  0.000382  \n",
      "241  0.000416  0.000458  0.000381  0.000262  0.000355  \n",
      "242  0.000481  0.000500  0.000552  0.000337  0.000452  \n",
      "\n",
      "[243 rows x 19 columns],            id  CH160323  CH160328  CH160329  CH160331  CH160414  CH160419  \\\n",
      "0    0.000456  0.000062  0.000116  0.000099  0.000114  0.000220  0.000247   \n",
      "1    0.000912  0.000040  0.000073  0.000098  0.000088  0.000191  0.000206   \n",
      "2    0.001367  0.000042  0.000082  0.000075  0.000051  0.000192  0.000204   \n",
      "3    0.001823  0.000032  0.000078  0.000078  0.000053  0.000165  0.000171   \n",
      "4    0.002279  0.000036  0.000071  0.000088  0.000088  0.000156  0.000164   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.108935  0.000024  0.000024  0.000000  0.000000  0.000035  0.000053   \n",
      "239  0.109391  0.000025  0.000023  0.000024  0.000000  0.000037  0.000058   \n",
      "240  0.109847  0.000025  0.000024  0.000000  0.000000  0.000000  0.000046   \n",
      "241  0.110302  0.000025  0.000024  0.000000  0.000029  0.000028  0.000050   \n",
      "242  0.110758  0.000054  0.000052  0.000060  0.000035  0.000039  0.000065   \n",
      "\n",
      "     CH160421  CH160425  CH160504  CH160510  CH160512  CH160516  CH160523  \\\n",
      "0    0.000262  0.000266  0.000271  0.000251  0.000260  0.000233  0.000240   \n",
      "1    0.000225  0.000239  0.000256  0.000245  0.000247  0.000206  0.000255   \n",
      "2    0.000221  0.000222  0.000227  0.000239  0.000230  0.000209  0.000213   \n",
      "3    0.000200  0.000204  0.000246  0.000250  0.000215  0.000184  0.000200   \n",
      "4    0.000186  0.000187  0.000234  0.000208  0.000199  0.000151  0.000201   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.000076  0.000097  0.000163  0.000149  0.000141  0.000156  0.000203   \n",
      "239  0.000085  0.000113  0.000167  0.000214  0.000233  0.000272  0.000279   \n",
      "240  0.000056  0.000087  0.000158  0.000215  0.000214  0.000238  0.000246   \n",
      "241  0.000068  0.000102  0.000158  0.000211  0.000214  0.000254  0.000264   \n",
      "242  0.000089  0.000107  0.000156  0.000205  0.000207  0.000259  0.000254   \n",
      "\n",
      "     CH160524  CH160525  CH160609  CH160616  CH160622  \n",
      "0    0.000249  0.000258  0.000226  0.000175  0.000144  \n",
      "1    0.000202  0.000244  0.000250  0.000189  0.000113  \n",
      "2    0.000197  0.000216  0.000194  0.000169  0.000139  \n",
      "3    0.000171  0.000208  0.000170  0.000166  0.000140  \n",
      "4    0.000155  0.000197  0.000167  0.000129  0.000092  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.000199  0.000190  0.000193  0.000190  0.000097  \n",
      "239  0.000291  0.000279  0.000201  0.000188  0.000124  \n",
      "240  0.000257  0.000246  0.000195  0.000174  0.000107  \n",
      "241  0.000274  0.000272  0.000222  0.000195  0.000097  \n",
      "242  0.000262  0.000266  0.000230  0.000188  0.000111  \n",
      "\n",
      "[243 rows x 19 columns],            id  ExG160317  ExG160323  ExG160328  ExG160329  ExG160331  \\\n",
      "0    0.000456   0.000084   0.000097   0.000122   0.000126   0.000114   \n",
      "1    0.000912   0.000053   0.000104   0.000130   0.000123   0.000115   \n",
      "2    0.001367   0.000093   0.000100   0.000112   0.000123   0.000110   \n",
      "3    0.001823   0.000082   0.000091   0.000092   0.000107   0.000104   \n",
      "4    0.002279   0.000075   0.000101   0.000139   0.000145   0.000123   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "238  0.108943   0.000000   0.000000   0.000000   0.000000   0.000062   \n",
      "239  0.109399   0.000000   0.000000   0.000000   0.000000   0.000061   \n",
      "240  0.109855   0.000000   0.000000   0.000000   0.000000   0.000068   \n",
      "241  0.110311   0.000000   0.000000   0.000000   0.000000   0.000073   \n",
      "242  0.110766   0.000000   0.000054   0.000000   0.000000   0.000479   \n",
      "\n",
      "     ExG160414  ExG160419  ExG160421  ExG160425  ExG160504  ExG160510  \\\n",
      "0     0.000133   0.000109   0.000108   0.000130   0.000122   0.000089   \n",
      "1     0.000132   0.000109   0.000109   0.000128   0.000136   0.000089   \n",
      "2     0.000134   0.000113   0.000110   0.000128   0.000128   0.000089   \n",
      "3     0.000105   0.000092   0.000092   0.000115   0.000133   0.000093   \n",
      "4     0.000129   0.000120   0.000110   0.000141   0.000146   0.000098   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "238   0.000076   0.000100   0.000099   0.000122   0.000119   0.000110   \n",
      "239   0.000068   0.000086   0.000086   0.000101   0.000106   0.000109   \n",
      "240   0.000067   0.000082   0.000089   0.000123   0.000128   0.000132   \n",
      "241   0.000066   0.000095   0.000086   0.000123   0.000122   0.000118   \n",
      "242   0.000059   0.000088   0.000080   0.000120   0.000117   0.000117   \n",
      "\n",
      "     ExG160512  ExG160516  ExG160523  ExG160524  ExG160525  ExG160609  \\\n",
      "0     0.000108   0.000090   0.000081   0.000083   0.000094   0.000091   \n",
      "1     0.000116   0.000104   0.000082   0.000091   0.000106   0.000086   \n",
      "2     0.000107   0.000097   0.000079   0.000089   0.000093   0.000083   \n",
      "3     0.000112   0.000099   0.000090   0.000093   0.000098   0.000098   \n",
      "4     0.000124   0.000104   0.000086   0.000102   0.000107   0.000083   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "238   0.000118   0.000110   0.000125   0.000124   0.000120   0.000102   \n",
      "239   0.000119   0.000118   0.000127   0.000127   0.000136   0.000141   \n",
      "240   0.000141   0.000134   0.000121   0.000128   0.000132   0.000123   \n",
      "241   0.000143   0.000124   0.000123   0.000124   0.000130   0.000110   \n",
      "242   0.000144   0.000135   0.000128   0.000115   0.000132   0.000141   \n",
      "\n",
      "     ExG160616  ExG160622  \n",
      "0     0.000084   0.000110  \n",
      "1     0.000079   0.000102  \n",
      "2     0.000085   0.000115  \n",
      "3     0.000072   0.000112  \n",
      "4     0.000073   0.000076  \n",
      "..         ...        ...  \n",
      "238   0.000083   0.000092  \n",
      "239   0.000117   0.000103  \n",
      "240   0.000092   0.000088  \n",
      "241   0.000089   0.000100  \n",
      "242   0.000110   0.000090  \n",
      "\n",
      "[243 rows x 20 columns]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (i, parameter) in enumerate(parameters):\n",
    "    test[i] = test[i]/np.linalg.norm(test[i])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bd83531fa4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in 4:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
