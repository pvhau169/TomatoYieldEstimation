{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from neupy import algorithms\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import pyrenn as prn\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constant \n",
    "path = '2016_spring/2016_spring{}.csv'\n",
    "yield_path = '2016_spring/2016_spring.csv'\n",
    "parameters = ['CC', 'CV', 'CH', 'ExG']\n",
    "data_type = \"CC\"\n",
    "limit_day = 80\n",
    "interval_day = 10\n",
    "x_pred = range(interval_day, limit_day+1, interval_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id    CC160323    CC160328    CC160329    CC160331    CC160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    1.779190    4.260457    5.343076    5.519863   16.668472   \n",
      "std     70.292247    2.702540    5.568591    6.607118    6.401390   10.776966   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.022717   \n",
      "25%     61.500000    0.000000    0.000000    0.000000    0.077062    5.043572   \n",
      "50%    122.000000    0.000000    1.006531    1.703657    2.849220   18.146174   \n",
      "75%    182.500000    3.539496    8.860301   11.834021   11.154441   24.911321   \n",
      "max    243.000000   10.094508   18.670866   22.237157   21.618151   46.901408   \n",
      "\n",
      "         CC160419    CC160421    CC160425    CC160504    CC160510    CC160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean    19.428900   22.604212   24.042545   25.209774   31.745804   35.118721   \n",
      "std     10.698871   10.495013    9.047723    9.244777   10.168303    9.193573   \n",
      "min      1.370548    2.348012    4.478416    1.124346    3.753984    9.872068   \n",
      "25%      7.091002   11.761658   15.771608   18.444575   25.246675   28.907828   \n",
      "50%     22.985194   25.513733   24.698005   25.490427   31.354081   35.029461   \n",
      "75%     27.815988   30.735162   30.749257   31.510117   37.680059   41.482717   \n",
      "max     40.299648   43.896321   45.503766   46.619828   68.101868   63.510101   \n",
      "\n",
      "         CC160516    CC160523    CC160524    CC160525    CC160609    CC160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean    35.458836   33.087046   35.329070   35.005474   31.574042   33.209143   \n",
      "std      8.931532    9.351277    9.539150    9.669084    8.983270   10.696622   \n",
      "min      7.653061    6.359917    7.650765    8.963321    7.236125    7.098944   \n",
      "25%     29.057810   27.323628   28.902265   28.885636   25.075075   25.219030   \n",
      "50%     34.964923   32.403659   34.929118   35.320062   31.673776   32.690701   \n",
      "75%     41.618178   39.581977   41.076032   42.053084   37.487278   40.549022   \n",
      "max     64.986500   68.607416   66.424389   64.055425   55.018662   62.065420   \n",
      "\n",
      "         CC160622  \n",
      "count  243.000000  \n",
      "mean    29.855072  \n",
      "std     13.559514  \n",
      "min      3.122053  \n",
      "25%     21.090568  \n",
      "50%     28.897902  \n",
      "75%     36.906560  \n",
      "max     70.738119  \n",
      "               id    CV160323    CV160328    CV160329    CV160331    CV160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.025504    0.162589   -0.120347   -1.275453    0.455756   \n",
      "std     70.292247    0.054609    0.121064    0.095629    0.526068    0.405926   \n",
      "min      1.000000   -0.241641   -0.134953   -0.372370   -1.988806   -0.351105   \n",
      "25%     61.500000   -0.000407    0.079524   -0.187198   -1.669335    0.184268   \n",
      "50%    122.000000    0.018088    0.154566   -0.124536   -1.421133    0.422573   \n",
      "75%    182.500000    0.048915    0.250237   -0.062527   -0.979031    0.742030   \n",
      "max    243.000000    0.339361    0.528110    0.268199    0.251432    2.023506   \n",
      "\n",
      "         CV160419    CV160421    CV160425    CV160504    CV160510    CV160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.537714    0.708608    0.733255    1.184895    1.106869    1.360369   \n",
      "std      0.336711    0.377674    0.379954    0.489754    0.442903    0.411224   \n",
      "min     -0.099054    0.056110    0.050718    0.225353    0.194038    0.374577   \n",
      "25%      0.257365    0.370449    0.380842    0.801605    0.784589    1.083015   \n",
      "50%      0.534366    0.746013    0.757832    1.087891    1.020255    1.310624   \n",
      "75%      0.755954    0.971196    0.992019    1.502699    1.378449    1.651033   \n",
      "max      1.383204    1.573283    1.613604    2.881781    2.784953    2.683436   \n",
      "\n",
      "         CV160516    CV160523    CV160524    CV160525    CV160609    CV160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     1.245839    1.345457    1.282874    1.486181    1.225371    0.947739   \n",
      "std      0.402119    0.470097    0.449471    0.496881    0.444273    0.351954   \n",
      "min      0.390300    0.339928    0.328364    0.423053    0.135786    0.133531   \n",
      "25%      0.959590    1.034972    0.930971    1.121043    0.882057    0.691438   \n",
      "50%      1.200863    1.309832    1.272195    1.456835    1.260330    0.929283   \n",
      "75%      1.493418    1.625070    1.541857    1.783188    1.526492    1.201803   \n",
      "max      2.515981    2.793169    2.619310    3.033122    2.981787    1.797718   \n",
      "\n",
      "         CV160622  \n",
      "count  243.000000  \n",
      "mean     1.208259  \n",
      "std      0.323304  \n",
      "min      0.514999  \n",
      "25%      0.948969  \n",
      "50%      1.198723  \n",
      "75%      1.445859  \n",
      "max      2.179391  \n",
      "               id    CH160323    CH160328    CH160329    CH160331    CH160414  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.076246    0.106770    0.110527    0.110976    0.238481   \n",
      "std     70.292247    0.051069    0.048342    0.079658    0.132101    0.152020   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%     61.500000    0.057907    0.065751    0.070746    0.000000    0.104721   \n",
      "50%    122.000000    0.068730    0.090834    0.089447    0.093469    0.207002   \n",
      "75%    182.500000    0.082941    0.150629    0.153059    0.184821    0.331964   \n",
      "max    243.000000    0.760147    0.254143    0.969861    1.076819    0.763881   \n",
      "\n",
      "         CH160419    CH160421    CH160425    CH160504    CH160510    CH160512  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.326765    0.380316    0.434813    0.555992    0.581738    0.553074   \n",
      "std      0.159808    0.172381    0.175906    0.159174    0.128924    0.135876   \n",
      "min      0.062200    0.089616    0.099268    0.195958    0.250065    0.230499   \n",
      "25%      0.159139    0.201092    0.242200    0.421301    0.474530    0.452727   \n",
      "50%      0.346280    0.415334    0.472981    0.541967    0.569039    0.533580   \n",
      "75%      0.455055    0.496061    0.567771    0.665200    0.679777    0.639246   \n",
      "max      0.700948    0.773985    0.866399    1.016903    0.874122    0.955869   \n",
      "\n",
      "         CH160516    CH160523    CH160524    CH160525    CH160609    CH160616  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.562553    0.622173    0.643549    0.648695    0.547599    0.476690   \n",
      "std      0.133658    0.135163    0.140558    0.146192    0.106029    0.110016   \n",
      "min      0.222351    0.264048    0.323193    0.259544    0.272005    0.201900   \n",
      "25%      0.466641    0.518361    0.539487    0.534388    0.477356    0.401076   \n",
      "50%      0.542644    0.607084    0.645303    0.632763    0.542530    0.467899   \n",
      "75%      0.655245    0.711207    0.743766    0.746891    0.619767    0.548069   \n",
      "max      0.892660    0.923697    0.969956    0.990879    0.811504    0.779979   \n",
      "\n",
      "         CH160622  \n",
      "count  243.000000  \n",
      "mean     0.336080  \n",
      "std      0.087689  \n",
      "min      0.157737  \n",
      "25%      0.275544  \n",
      "50%      0.324984  \n",
      "75%      0.394074  \n",
      "max      0.596945  \n",
      "               id   ExG160317   ExG160323   ExG160328   ExG160329   ExG160331  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean   122.000000    0.065331    0.096702    0.135541    0.144645    0.211936   \n",
      "std     70.292247    0.071743    0.079134    0.098548    0.097907    0.080964   \n",
      "min      1.000000    0.000000    0.000000    0.000000    0.000000    0.104701   \n",
      "25%     61.500000    0.000000    0.000000    0.000000    0.093325    0.156305   \n",
      "50%    122.000000    0.000000    0.114337    0.161547    0.158173    0.204603   \n",
      "75%    182.500000    0.128573    0.167559    0.217595    0.237995    0.251572   \n",
      "max    243.000000    0.208723    0.250075    0.319363    0.319114    1.050000   \n",
      "\n",
      "        ExG160414   ExG160419   ExG160421   ExG160425   ExG160504   ExG160510  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.223494    0.252478    0.223410    0.266880    0.272247    0.234704   \n",
      "std      0.060474    0.053447    0.034973    0.034144    0.033235    0.031493   \n",
      "min      0.106751    0.132074    0.148127    0.182493    0.177950    0.143914   \n",
      "25%      0.160492    0.208172    0.198456    0.242295    0.255126    0.213842   \n",
      "50%      0.241370    0.262620    0.226973    0.269579    0.273329    0.238325   \n",
      "75%      0.272044    0.295827    0.247310    0.291451    0.293501    0.256113   \n",
      "max      0.337627    0.345226    0.311434    0.360905    0.374617    0.312947   \n",
      "\n",
      "        ExG160512   ExG160516   ExG160523   ExG160524   ExG160525   ExG160609  \\\n",
      "count  243.000000  243.000000  243.000000  243.000000  243.000000  243.000000   \n",
      "mean     0.264808    0.258221    0.239454    0.237113    0.263938    0.264946   \n",
      "std      0.037053    0.040075    0.037964    0.040119    0.041691    0.054771   \n",
      "min      0.166548    0.155537    0.138684    0.129689    0.165107    0.157211   \n",
      "25%      0.238292    0.231425    0.214118    0.206064    0.234373    0.220702   \n",
      "50%      0.264688    0.260281    0.242203    0.242705    0.270033    0.265563   \n",
      "75%      0.292520    0.286816    0.264560    0.267872    0.294405    0.311555   \n",
      "max      0.361511    0.366541    0.319069    0.328575    0.351662    0.384207   \n",
      "\n",
      "        ExG160616   ExG160622  \n",
      "count  243.000000  243.000000  \n",
      "mean     0.213018    0.202651  \n",
      "std      0.043176    0.035695  \n",
      "min      0.127558    0.130875  \n",
      "25%      0.178086    0.176415  \n",
      "50%      0.209619    0.200414  \n",
      "75%      0.243025    0.223618  \n",
      "max      0.349283    0.355599  \n"
     ]
    }
   ],
   "source": [
    "#read files\n",
    "data = []\n",
    "yield_data = pd.read_csv(path.format(''))\n",
    "for i in range(len(parameters)):\n",
    "    temp = pd.read_csv(path.format('_'+parameters[i]))\n",
    "#     print(column_name for column_name in temp.columns if parameter[i] in column_name)\n",
    "    temp = temp[['id']+[x for x in temp.columns if parameters[i] in x and len(x) == len(parameters[i]) + 6]]\n",
    "    data.append(temp)\n",
    "    print(temp.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count date function\n",
    "def count_days(date_planting, date_key):\n",
    "#     print(date_planting, date_key)\n",
    "    f_date_array = date_planting.split('-')\n",
    "    f_date = date(int(f_date_array[2]), int(f_date_array[0]), int(f_date_array[1]))\n",
    "    l_date = ''.join(s for s in date_key if s.isdigit())\n",
    "    #print(int('20'+l_date[:2]), int(l_date[2:4]), int(l_date[4:6]))\n",
    "    l_date = date(int('20'+l_date[:2]), int(l_date[2:4]), int(l_date[4:6]))\n",
    "    return(abs((l_date-f_date).days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process function\n",
    "def convert_day_after_planting(data, yield_data, parameter_type, normalization, std):\n",
    "    x_pred = range(interval_day, limit_day+1, interval_day)\n",
    "    my_list = np.empty((0, len(x_pred)))\n",
    "    for i in range(len(data)):\n",
    "        date_plant = yield_data['plantDate'].iloc[i]\n",
    "        data_extract = data.iloc[i]\n",
    "        grnn = algorithms.GRNN(std = std)\n",
    "        x = np.array([count_days(date_plant, i) for i in data.columns])\n",
    "        mask = (x<=limit_day) & (data_extract >=0) &(x>=0)\n",
    "        x = x[mask]\n",
    "        x = np.append([0], x)\n",
    "        data_extract = np.append([0],data_extract[mask].values)\n",
    "        grnn.train(x, data_extract)\n",
    "        pred = np.transpose(grnn.predict(x_pred))\n",
    "        my_list = np.append(my_list, pred, axis=0)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(normalization, std):\n",
    "    preprocessed_data = []\n",
    "    for i in range(len(parameters)):\n",
    "        passed_data = data[i].copy()\n",
    "        print(normalization)\n",
    "        if normalization:\n",
    "            passed_data = passed_data/np.linalg.norm(passed_data)\n",
    "        preprocessed_data.append(convert_day_after_planting(passed_data[passed_data.columns[1:]], yield_data, parameters[i], normalization, std))\n",
    "    preprocessed_data = np.array(preprocessed_data)\n",
    "    preprocessed_data = preprocessed_data.swapaxes(0,1)\n",
    "\n",
    "    #train data has shape (number_of_observes, number_of_day_observed * number_of_parameter)\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_GRNN_example(observation, std, normalization):\n",
    "    plant_date = yield_data['plantDate'][observation]\n",
    "    grnn = algorithms.GRNN(std = std)\n",
    "    x_test= np.array(range(1, limit_day + 1))\n",
    "    x_preprocessed = np.array(range(10, limit_day+1, 10))\n",
    "    fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(8, 6))\n",
    "    fig.suptitle('Observation id:{}, Yield:{}\\n'.format(yield_data['id'][observation], yield_data['Yield'][observation])+'reps: {} variety: {} plantDate: {} Mulching: {}'.format(yield_data['reps'][observation], yield_data['variety'][observation], yield_data['plantDate'][observation], yield_data['Mulching'][observation]), fontsize=16)\n",
    "#     fig.suptitle('Observation id:{} reps: {} variety: {} plantDate: {} Mulching: {}'.format(yield_data['id'][observation], yield_data['reps'][observation], yield_data['variety'][observation], yield_data['plantDate'][observation], yield_data['Mulching'][observation]), fontsize=16)\n",
    "    for i, parameter in enumerate(parameters):\n",
    "        plant_date = yield_data['plantDate'][observation]\n",
    "        value_data = data[i].copy()\n",
    "\n",
    "        value_data = value_data[[column for column in value_data.columns if parameter in column]][observation:observation+1]\n",
    "        x_original = np.array([count_days(plant_date, column) for column in value_data.columns])\n",
    "        \n",
    "        \n",
    "#         value_data = value_data[value_data.columns[mask]]\n",
    "        y_original = np.array(value_data.values)\n",
    "        y_original = y_original[0]\n",
    "        mask = (x_original<=limit_day) & (x_original>=0) & (y_original>=0)\n",
    "#         print (len(mask))\n",
    "        x_original = x_original[mask]\n",
    "        \n",
    "        y_original = y_original[mask]\n",
    "        print(len(y_original))\n",
    "        x_original = np.append([0], x_original)\n",
    "        y_original = np.append([0], y_original)\n",
    "#         if normalization:\n",
    "#              y_original = y_original / np.linalg.norm(y_original)\n",
    "        grnn.train(x_original, y_original)\n",
    "        y_test = np.transpose(grnn.predict(x_test))\n",
    "        y_test = y_test[0]\n",
    "        y_preprocessed = x_train[observation:observation+1]\n",
    "        y_preprocessed = y_preprocessed[0]\n",
    "        y_preprocessed = y_preprocessed[i:i+1,:]\n",
    "       \n",
    "        axs[i//2, i%2].plot(x_test, y_test)\n",
    "        axs[i//2, i%2].scatter(x_original, y_original, color='red', label ='original')\n",
    "        axs[i//2, i%2].scatter(x_preprocessed, y_preprocessed, color='blue', label='predicted')\n",
    "        axs[i//2, i%2].legend()\n",
    "        axs[i//2, i%2].set_ylabel(parameter+' values')\n",
    "        axs[i//2, i%2].set_xlabel('Days after planting')\n",
    "        axs[i//2, i%2].set_title(parameter)\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "\n",
    "std = 10\n",
    "observation = 15\n",
    "normalization = False\n",
    "# x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "# print(x_train[observation:observation+1])\n",
    "y_train = yield_data['Yield'].values\n",
    "show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "std = 10\n",
    "observation = 4\n",
    "normalization = False\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "# y_original = y_original / np.linalg.norm(y_original)\n",
    "y_train = y_train/np.linalg.norm(y_train)\n",
    "# show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "12\n",
      "15\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "12\n",
      "15\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "13\n",
      "15\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "13\n",
      "15\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "13\n",
      "15\n",
      "16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(157, 162):\n",
    "    show_GRNN_example(i, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "10\n",
      "12\n",
      "13\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAG4CAYAAAC+ZBgrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3xUVfbAvycJEBKaFAslCYJKEwRBuoJrwYqy6qroiopY97fKrrsqVpS1d3EVGyqgK+7asaJgRUBEpQsSQq+SBEIIIef3x30ThpeZyaROyvl+PvNJ5r5bzntz33nn3XPuvaKqGIZhGIZhGPuIi7UAhmEYhmEYVQ0zkAzDMAzDMHyYgWQYhmEYhuHDDCTDMAzDMAwfZiAZhmEYhmH4MAPJMAzDMAzDhxlIRo1BRE4SkQ9FZKuI5IrIMhG5X0QOCJFXReSeWMhZkYjIWSIyOkT6IO+cB1WyPBNFJD2KfCM8+dKKyddaRJ4Uke9EJCdcGRFJFZF3RGSViOwSkS0iMkNETinFOXQXkT0i8q8wx6eLSIaINCzLdRaRdBGZGEW+aK/pDSIyJ+h+WC4iD4tIM1++Oz2Z/Z+3o5S7jYi8KSKZIpIlIv8TkZRoyhpGVcYMJKNGICK3AB8DucBI4GTgGWAEMEdE2sROukrlLKCIgQTMA/p6fyuTu4Gzy7G+9sB5wO/AVxHyNQC2ALcCpwKXAzuAaSIyrCQNquqPwP3AjSLSLfiYiIwEjgdGqWo2sbvOoWgK/A93DwwBxgOXAZ+KSCjdPwAne+Dzj+IaEJEk4HOgA3AJcDFwGPCFiCSX/RQMI3YkxFoAwygrIjIYuAd4TFVvCDo0U0TeAn4AXgEGx0K+cIhIPVXdXRltqWoWMKsy2vK1u6Kcq/xSVQ+CQuPkpDDtLsQZRYWIyAfASuBSnOFQEsbiDL0XRKS3qu4VkUOAB4GJqvqR125MrnMoVPU2X9IMEcnBvTh0x90XwXyvqvklbOYK4FDgCFVdDiAiPwO/AlcCj5RYcMOoItgIklET+AewDbjZf0BVVwL3AYNEpLfvsIjIGBFZ47lhvhSRo3wZThaRbzz3wQ4RWSoit/vydBORd0Xkd6+eb0RkoC/PRK+dviLyrYjsAh4QkWki4n9QISKHiEi+iFzvfW8hIs96bsMcEVktIlNEpFVwG7i3+FZBbpJ071gR1484bvDOKU9E1ovIUyLSyCeLisg9IvJ/IrJSRLJFZKaIdA7ze/jPO92XdqiIfOCdx2YReRyoV1xdAKpaEE2+MGXzgUxgTynK5uEMq6OAv3nJ44FdQKFRHs7FJiLDRGSWd87bRWRqNG4oEfmDiMzzXGQrROTKksruY6v3t8TXIAxnArMCxhEU3nPfAEPLqQ3DiAlmIBnVGhFJAI4DPlXV3DDZ3vX+Hu9L/zPO/XIdzg1xEDBdRJp6dR/qlU0H/oR7GDwCFLoORKQH8C3OnXEF8EfcQ+gzETna115j4HXgNeAUYApuZKuHiHTy5b3Q+/ua97cpzn14M85dciPOlfGNiCR6ee4GpgGb2ecmieTeGuedz6fAGcAD3nX4IIQL5iLgNOCvOEMhBXjHu/5RIyJ1vfa6A9d67bXFucL8eQOxMWklacNXR5yIJIjIwSJyG3A4zrApMao6G3gMuFNEbsJd26tVdXsxMlwF/BdYBJyDG1npghvhbBihXEfc77kLOB+4Bbge+EOIvDP8hmjQsQQRSRKRPsBdwHRV/TlE1tUisldc3Nb9IlI/0nl5dAYWhEhfCPj7tGFUL1TVPvapth+cUaPAvRHyJHp5ng5KU1yMSnJQWhruzfpu7/s5Xr5GEeqeDiwG6galxXtpbwelTfTqGuorXx83qnGvL30+MC1Cu/FAG6/Os33trAmRf5CXd5D3PWBwTfTlu8jLd6bvWv0K1AlKC1ybfsX8PhOB9KDvV3jl+gSlxeEeqAqkBaXfDuQDqWHqHukvEyLPQ14eBbKBYWXsb/WBZV59r0VxnRt4v++LvnxpQB5wfVBaevDvAUwO0UfbeOXSffVNB5aHkKdB0Pkr8BHQMMRv/k+cu/JEnNswD/fSUdz1yAPuC5F+D5BflmttH/vE+mMjSEZ1R8pQdpqq7gx8UdV0XPxIXy9pPs5gel1EzhGRA/dr2L1hHwdMBQq8N/UET6bPgGN97eUD7wcnqOou3OjCcBERr94jgW640aXg9q4WkZ9EZIdXV4Z36IhSnHsfnFtrki/9da/u43zpn6pqsFvmF+9vSWcr9QVWq2phnI46t9kb/oyqOlZVE1R1VQnbCOYxoBduhOxDYIqInF7ayrzf6yHv691RFOkLNAImB/qH10fWAEso2kf8Zf19dDXOfeWX6w+q2j5EHTm48x8I/B/ORfhe8Mifqk5S1ftV9RNV/VRVb8SNUJ4gIidEcY6hdjwvy31pGFUCM5CM6s4WnAsiLUKewLHVvvSNIfJuBFoBqIurOBl3n7wKbBCR70UkYDw0xY3k3IYzpII/1wEH+FxVm1R1b4g2X8GNDAzyvl+MG+14J5BBRP4CPI0zvIYBx+CMHHAjZCWlqfd3fXCiujidrUHHA2zzfQ8El5e07UMIf93LHVVdo6pzVfV9VT0PZwA/VFy5Ysjz/Y1EwKj+jKJ95EigWZhyUA7XSlULvPP/WlWfxLnqjsONAEYi4NrtVUy+3ynaVwAO8I4ZRrXFZrEZ1RpVzReRL4ETRSRRQ8chnen9/dyXflCIvAcBa4Pq/wI3Zbke0B83m+kDLy5mO1CAi2l5pUhNFAkqDvWmDTATNxp0kYjMBC4A3vRGKwKcj4sdCQQIIyJtw9QXDQGD52CceytQZwLuob01VKFyYD0ubsVPqN+iIpiLi+OpLALXcQRB1zmI7Ahl1xO+j5aWud7fUKNNoQjXZwMsJPTv2QkXc2UY1RYbQTJqAg/iHupFFvLzjIh/4qaHf+87fKoErdXiGT19gO/89ajqblX9HBfInAy09VwfX+HcYfO8N/X9PtEIr6qKizc5Bxc03pqiBlcSRWceXRqiut24OJnimOXlPd+X/ifci9PMKOooDd8BbbyAYcAFUuPWNqpQvHYGAOW99EAkvsUZQe1D9Q9VXRqh7HcU7aNtcIZ6aQmMfhZ3DYZ7f/33jJ93gT7ehAag8D7qz77JEYZRLbERJKPao6rTxU29H+sp51dww/s9gJtwQbIXhyi6C/hERB7ExePcBWQBj0Lh7KNjcTOJVgPNcbPI1rFv5s5o4EvgYxF5AffW39xrO15Vb4ryNF7x6n7Ga8tvoHwE/FPcgpizcTPyQrlJFgFNReRq3GhBrqr+4s+kqttE5BHgZhHZ6Z1jR1xw7dfAB1HKXVJexv0m//POZRNwFS5OZz+83/R2oF1wHJKIBM47MEvwFBHZDGxW1Zlenjtxrp9vgA24kbLLca7JwAzBQH3puKDnQeVyhkGoapaI3AiMF5EWuDioTJwb9zhghqpOCVP8HuBc9vXRurg+WsTFJiLTccHs7b3vjXF9ZjIuwF5x5z4a+ImgdaBE5Edc/1vq5TsR+AvwkTeCGsj3Z+BF4A+B6ww8h3MnvyMit3rl78b14Wejv1KGUfUwA8moEajq3SIyB7cmzUu4EZcMnOK/V1X9MTR4x3YCT+GMmjnA+UF5f8JNx78XF0uyDWc8DA+4v1R1noj0Au4AnsBN5d+MW0n5mRLIv0RE5gI9PXn9ro2xQBPv/BJxBtTJwG++fM/jRsH+5eVfRfj4rDGerFcB1+DcQa8AN2sZ1huKhKrmiciJuGv+NO76T8EZZP7rFYeL8fIH/E71fX/a+zuTfXFc83CutPNxv8kG3O85UFX9Qc7J3vEKQVWfFZHVuMDnC4E6ODful7iJAOHKLRaRU3EjpP/xytyPC94e5Msez/76PBc3k/L/cMZYPm6W3MPAE7r/AqVLcUbOIV49K3D97QFfG0V+D1XdKSLH414qXvWOTcfNztsR7twMozogRfWwYRhG7UBEDscZCL3VrXNkGIYBWAySYRi1m8Aio2YcGYaxHzaCZBiGYRiG4cNGkAzDMAzDMHyYgWQYhmEYhuHDDCTDMAzDMAwfZiCVEBG5T0R+FpHtIpIjIktE5DYRSYq1bAFEZGK4nb2LKXeUt4N6qK0DyhURWePt1K4iUuBdz09EpF+YvM+Xc/v9ReQNEVkrInkikikis0XkLhE5uDzbKisico+I5Meg3a9F5LMKrP9Qr7+lhWk70D/2isjvIvKjiDwhIqXeJV5ELhOREWUQO9p2Wnm64gevb20Wkc9EZECU5Tt45/qLiOwQkXUi8ra3T58/b7KI3C0iy0Rkl4hkiMjLIpJa3nKKyB/F7QeYKyLpInKL7L+dDiJyrKeDFni/3fJiZDhDRL7yzjNLRObIvu18wpVpH9Q/LgtxvKGI7PSO31ncdYhQ/0UlLLdGRCZGkW9ScdelshC3P6D6PtvFbav0J1/eUl2XEspxZ3nXXVrMQCo5jXDr7FyI2wBzMm49mdciFapk7gbOLkW5o3Dr+VS4geQxDbemywDcmjWHAx+KiH8D1DMIsUp2aRGRf+BWwD4AuAU4Abe9x2fA1bjF74yK51Bcf0sLc/xHXP/oj1vhexLut5ovIleWss3LcNt+VDS9cIs8vgX8Ebfq+R5gpoicEkX5IbgZdi/h+n9gnaLvReQoX96XcAtATsCtxH4HMBj4LIoXt6jlFJHTcGtQfYdbH+wpry3/pr0n4O7pBbgNecMiItfgFq2cDZyFW1H9f7i1qaIhm9CLwJ4LhNr3sKpwB8Xvh1fZvIC73/rinm+rcBt1nxVTqWKJqlaZD1Av1jKUUu57cSvINq/O1w/34FDctggVLesaYKIv7Tiv/b9XYLsnem08FOZ4A+CSYuqoizcDtJJ+13uA/MpqL6jdr4HPKrD+E7zfYlCYtmeEufZv4RY+7FHKcypSbwWc2wFAgi+tDrAc+DyK8s39fQy38Gcm8GJQWgOcITDWl/d079r+obzkBH7B7QcYnDYWtyhli6C0uKD/XweWh2n7UK/sdaW4vu2985uI2w8xxXd8Bs5wVODOMtR/UQnLFdFrVf2DW2C0yHXCDaCsBSaX9bqURY5YfmI2guQNrauIdBGRj0VkB/BG0PFhIjJLnBtru4hM9Y8seEO8k0TkChFZ7g37zhORwb58vUTkUxHZ6tX3m4g8TfkR2JDSv1dWsAxPi8hGcZuBBqfX89wHj3nfE0XkUW94eoeIbBCR90Skg6/cCO/6Hetdm+14+yZJCBebiCSJyP0islKcS2mliIwJDI+Lczu85GX/NWioNU3cMP9bIc5pkJfn5JJcrAjM8/76f+ciLjYR6SMi071rtMP7fXtG0cY/casm3xzqoKruUNWXg9oJDClfKSIPi8h6nFJvICIHicgEEfnV61cZXn9s6ZP1Hq+OdiLyoTf0ny4it0pR98TR4txLud55j6HoStKB4egxIrJURHaLcxU+KG5T3bAEDWPfJc41vNZra6aEcN/4ytYXkcdFZKF3DutF5F0ROcKXb6TXRi8ReU2c22SdiDwWkE9ETgA+9Yp8EdTfIrqgVDUPN8pXgNsOI9Dm4d61TxfnZlohIuNFpElQnq9xo1HHBbX3WdDxQz15NwfpkjMpBar6u6rm+9L24FbzbhVF+S3qPTWC0rbjDJfg8nVwD7IsXxXbvb8RdXy0corb07ALbhQvmFdx2/QMCSof7SrsI4E83MhXaQls9BzYOw5xrsVjCbGBtIRxV0uULi8RGSzOBZnl3QM/SQiXrYgMFxd+sVOcy7Cf7/h+7QXpmZGejOvFPRfeCaFPkkXkWRHZJiLZIvJfERkg5ez68n7Hnbg+FhYR6e3JsMa795Z655AYIu85IvKtd12yxLnxTo9Qd7KnM9cWp58qgqrgYnsH18nPZP89sP6L21fqHOBK3M05U0Qa+sofhxteHoPbVmA3zk1zhFdXA+Bj3FvWCNwQ9Fh826x4nWtitEJ7D5oGnqIfjXury4xQ5BXcdhUn+dJPx70Zvup9rwc0xI0anIZ7GCQCsyR0bMxkYCXuOoXc90ucUfYxTiE9jhsefx64DbeNAbitHu7x/j+XfUOt64F/A6f7b1Tc77IS+MRrJ3CT3xruIhRDmvc34kaaItId94bYCPebjsC5Bb8UkS4RytUFBgKfeA+BknC7J98VwDCcYm8G5OCMriHe347AV15bft7CGQVDgfdxrolgxX4g8Dnurf7POAPgdO9/P6/hjLxXcf3kAWAUIR4KYbgM1xevxblVWgKfBxsUIajvfcbi7qNrca6Q7zzZ/UzGrVI9DLcv1/8B//COzfa+49UT6G8/FSe4qm7Aud+CN21thXMJ/BW3Bcs47+/7QXlGAT+zz3XXF8/IEhcH9T1uZ/rrcb/RL8Db4lxLePlK3cc947APbguQEiMizYFOweVV9XdcX7heRI7zdNKRuP4wD/giZGUll7Oz93eBL/tynM4tTVzYAK+Niz2DNl/cy8ZVJahDcUZbsJvtYty2Kl+XQqawiMgfcW74eFxfGop7qfTHeg3G9e3AM6ku8L6IFNlvMAS3evVdinuuDGTfsyHAC8AluG1nhuH0pd9wRUROKKHRFOc91xJE5EARuQk4DLfNTSRScX3tKtyz5QmcnvS/1F6Pc9Guw/1G5+Ke/yFj5bz+/jnQFuinIfaUrHBiOKx3J65z/9WX3gDfMLKXnoZ7KF0flJbupaUEpTXE7Zn1qve9p9dO12LkyQdeiFL2Ll6dgc/LuI1Jiyu3DHjNl/Y2sChCmXjcvmLZwA1B6SO8th8NUWYibvPNwPeLvbzH+vKN8a7fgb462/vyNcS9od4WlNYcpxhvCkpr513HW6K4Fmu865aAUyCdcXFBS4AmIfI+77tm24BGQWlNcG/Nb0Ros5V3fneHOJYQ/AlKDwwpz47inBJwN7MCZwSl3+OlXezLvxiYFvT9fu+atgrRn/OD0gZ79V3oq+8SL/3IYmRU3CaxSSF+uzuC0iK62Ly+mYwzEv8SlD7Sa+M2X/6Pgvs6pXCxBR2fCmQXc56D/NcjXL1eX9wAHOBL/xyYW5o+HqKNB3Avav1KWtYr/x/cG33bEOf6LPvrpG+BZqVsp4icOCO9iG7wjm0Ang1TVyQX23KcXtmE20j4+KDzuLYYGQP35Qhc7KICPb1jS3Gb+hZx2RDGXY0zMJaHqP8i73scbgPeWQS5EEPUswbnUWgclNbHq+u8KNrzuzBv8tIDOrozbvR0tC/f08HyemnHe331wnDyBvUfDfHZ6+/n/usSoi7x6hvhlW/ipTfx+m4k/Vz4e+Ge90txLy0xC12pCiNIftdNX9zIwOQgazYB1/GW4IZOg5mlqhmBL6qajRsN6esl/Yp7cD4rIheJSJtQQqhqgqpeHqXMy3HBjYNwQb5nE92b+yRgaGAUTNxssVP8ZUXkPG/ocTuug+/EGY5HUJQirq8QDMG9XX/ru6af4IZP+0Qq7F3TScBI2ecSuhR3M7wUlG+Fdx2jDaj+M84tuRv3ZtoRZ1hsj1jK9YF3VbXQreCVeR83ohiOIq4qABFp7ckR/PHzdohyIiLXipvVuMMrF9g8NtRv9YHv+wL2dyf2Bb5R1bWBhKD+HMwQnJvvrRC/J7i3zuJ4X1VzgtpZgdust2/4IiAi54ub7ZeJ65s7cKNK0ZzvL/jcp2VAcMo0IFc9cS7LJSKyC/dbBEZPQsnmZwhO3uwQ17SHiCRDqfp4QL6LcZvV3qmq3walB7+1J4jP5RqU7zZcAPPVqrrSd/heXBD7aFz/vwQ4CJgmIvVL2E5IOdl372jRUqHvqyiIw70AjFTVF1T1c1W9EjdKc0u0lajqMtyD9GIR6YMzmPyjLmWlE9Aa96JWnAvxG93fmxAY+Yim74e6Z4LL9sZdb/+GzW/6K/KuZ4KqTomiXXCTU3p5n+NxE2PuEpEbIhUSkSbi3Pu/4XT5HtxzIQ5nUIEbLUwiOndqF5yB/xtwvKpuiVL+cqcqGEjrfd8DQ/WfUfShdSTOrRHMxhB1bsTzn3sddTBuWO9pIENcfM8fSyuwquaq6lxVnamq9+KGUy/0bs5IvIpzlwVmL5yPM1AmBzKIyBm4N8XFuJkEvXEddrNX1o//+oXiQNwwpv96Bvaf8l/TUDyNu0lPFRHBDTG/paqhrn+0vI87t/445Z4M/FeKiaPBvY2EOu8NRJ6BtwlvxNGXvpF9iuHFMGVDtXc9bibPxzgj+Rj2uX2K/Faqus2XtNuX7xDC9+dgDvTK5bD/77nOOx7N7xnxvgmFiJyNc+cswM36C/TNbYTum8Wdb1low/6/yQM4N+grOJfjMbghfKJsswXO7ei/R+7FPZBKPbNT3CygF4FnVNU/4+sVX3tFHiAich3OrXmTqvpfproBf8eNxD+qql96eU7HXYPAFPixvnY+wUcxcgZ+y6a+MgI0puhvHQ2B2E3/UhKfAC3DuG3D8QquT14OfKuq5T2FPnBPrYkib6h+D9H1w+LKHuL93eTLVxY9HGCd91ybq6pfqOptuP4wTkQaRyj3Ms6l9hhuEkwv9rnPA3KX5PoNwp3n86q6s4TnUK4kFJ+lwvG/kQRumhHAwhD5s33fDwqR5yBc9L1rQHU+8EfvjbAnLnbjDRHppqp+n3ppmOv9bY8bgg2Jqq4UkW+Ai3AW9kW44f7VQdnOxw29jggkiEgdwivoUG90frbiYoXOC3M8vbgKVHWBiHyFizvKxZ1raadaF8qlqoFr962IZOPeYq7Bi0cLw3YgVDzWwezrP0VQ1TxxgboniUgd9eKQvL9zAcQFYYcsHiLtfOBjVb0xkCAih0WQuzjWE74/B7MVZxyFGy1bFyY9Up2BtLUh0gOcDyxR1cJ1Z8QFYkaKWyp3ROQQoDv7jxKcj3PL/ysoX0nk2oZ7UD8U5nipHkAichLuhWcqLtbKz224B0uAzb7yl+JiOu5X1ftDlA8Ers4JTlTVxd6oZkcv6Wn2HwXdL6g7CjkDurizr612uLjJRSHKFMdC4OgQ6YERqWiDvcG58h7FGYTXRMiXixdro/sHpxf3UhEYxSg2wL6CCeinA3EuvwCh7ufyYCFuhLg98IP/oLhlJE4HxqjqE0Hp3X1Zg69fxKUfgPG483tNRM5T1SKj95VFVRhB8vMtzghqH2TNBn+W+vL3CXabee6r03BrdeyHquar6iycUopjn/IoK4EHVcTgYo9XgUEiMgjnzvC75pJwrotgLsbFe5SWj3Bv3DvCXNNA5w28rdQPU8/TOJfgncAyVf28DDKF4gVcEO0/A66BMMzEBY0XrpXiveGc5h2LxAM4Q6o81lVKoqg77tIy1Pcd0F9EgmcPBfpzMB95bSeH+T2jMZBOl6A1ckSkHe7Nr8h9E0SovvlnSq9HiutvRfBeFp722nwi6FB9ovstdodp7yOgG7AgzDXNi1bGIFkH4FzgHwN/DuWaUdWVvnZWBZU/B/fC8IyqhpyAgRs1BTdaFNx2J5xbfq3XzjpfO8tKKOdvuIflcN+hi3Cjsh+HvRDheQtnDPknrpyMi6GM2rXijc7eB7xL5KDiVV6bhUHlXqhDcaP/i3EGyUhv1CxWfI97WTvXl+7/Xl509f5uDnM8EXcvFt573vUZ4cv3De6lblQUbSrOyJ2AG8gYVgJ5y5WqMIK0H6qaJSI3AuNFpAXwIS5ouxXOEJnh86luBD4Rt/rmbtxMomS8xcvETSEchXt7Wukd+z+cEVb4MBA39fPlSHFIItIV94Y5FecfrYeLh/kr8KGqRnq4BHgDp9gnAbtws/WC+Qg4S0QexbmgjvbkLS4uJxKTcQ+L6SLyMG6mUF3c29+ZwFlePErgLfBaEXkZ1+l/Dno4/Bf3ttsf+Ju/Ee8huxS4vaQxGgCqqiJyO+63GoWbcReKsbjf7jMReRCn8G7C/R5+14C/jY/FTZ0fJ27BvVdx/aI+0AGnaHZEKfJHwGhxsz3m4oKOy3IzP4ybCfKJiNyFe/D8ExeDVjgDRlU/E5GpuBikR9jnKk3DzS77mxdTFIndwMci8hDu3O8Gfif8NQd3vk95ZT7EGVTXUnSKebQsxQVyXi4iWZ5MS1Q1cP0bBbmtG+KU9WW4mTVXqWrwjLePgctEZBHuReVcfEaDxyLcQ+5c3O+e5RkLt+Ku40wRGY97kB6AG6FJUdUrIPo+7hko7+P008NAz6Dnqqrq95EujLilSibjZty96nPf53qj4uBmcy4AHhORZrjZRKm4l8DtFBMbWUI5bwbeEbdEyhs43XQz8Iiqbgqq80D2xYq2BpI9Yw+cARoYQXgXNzHjeRE5CPd7/AkX/xJq5mZEVPWOKLJ9gNP9z3v3WH3cPRaxD6tqgeybhfWZiDyLGxXpjAvsH1tSeUuDqi4UkTeAf3kekR9xeiewqGehcSsix+PclX+OMg6pte9+Ox5n6LyrQXG+Pnm2ichc4B8ishGnQ0biG9FS1e2e3n3UM6Bew+nZ7rgX96d9+RW4TkT2Av8RkQtUtUicVYWjMYoOZ98stoQwx0/FBVlm4QyJ5Th/aKegPOl4wcM4pbgb12GOD8pzBO6NYiVueHUzbgXn3r72lGIW+ML96FO8unbhXB1zcA+JqBdpxN1kCkwJcSwON9NiHc7inonrROnB8hFhUUd8s9i8tETvmi/xrtM2T/Y72X/W1h24t869Xv1pvnqe9a5jkRky7JvhcGsU1yDsgmq4t6S1gWuKbxabl9YXN8NoJ+5G+wxvFkuUv8FA9k053YMzwmd71+PgEOc0IkQdyd712IxTuu+Gugbe76khyu83k8VL64l728r1zvsWQsy8wY0o3oAbccvFPQzn42bCNYpw3oGZInfhHqJrvfIz8c30xDeLzWvzX0F98wvcqIt/lmFgFpu/74Q6j2tw91O+V2ZAUNvBs2kyvfN7AugY4rxa4B7a23FK+lVcjJR/Zk9LnKGX7R0LPr8UnI5ZizNO1+EeMBcG5Ymqjwddg1CfYhf9ZN/Mx1Aff59pjnMv/YrTSxm4B9BhUbRTIjlxhufPOB2SgTMs43x5TohQ562+vI1xy4hs8uqcD/wpCrnD3pch+vqdvvRjce6iHJw+vIBiZrH5zm0G+/TOfIIWliX0ArgBOYJ1Qrj2RoRor/C+8NIa4PTO754M716XbhQAACAASURBVOBedBU4LUTZiIs6EnoW2w6c4X0TUD/SdcEt+Bm4pzbh7tGAPAN8bf0Jp2d34e7pWcCpxfxeD+N09HmRzqMiPuIJUC0Rtxji16pa7vvCGEXx3liWA1+paqjl/Y0qjvcb7gHuUtU7YyyOYRjlgIjcjFv7q7VG52I3oqDKudiMqoe4Bc664GbVtcFZ9IZhGEYlI2519w7sW1T1WFzIwxQzjsoXM5CMaOiBc6dswk0nnl9MfsMwDKNi2IHbWPgW3MSJtTgX650xlKlGUq1dbIZhGIZhGBVBVZzmbxiGYRiGEVPMQDIMwzAMw/BhBpJhGIZhGIYPM5AMwzAMwzB8mIFkGIZhGIbhwwwkwzAMwzAMH2YgGYZhGIZh+DADyTAMwzAMw4cZSIZhGIZhGD7MQDIMwzAMw/BhBpJhGIZhGIYPM5AMwzAMwzB8mIFkxAwRuVBE5orIDhFZLyIfisgA79jhIjJVRLaISKaI/Cwio0UkPtZyG4ZRswiji24TkXQREV/eBBHZJCKnx0peo3IwA8mICSIyGngM+BdwEJACPA0MFZF2wPfAauBIVW0MnAv0BBrGRmLDMGoiEXRRI6AJcJyvyBBAgY8qUUwjBoiqxloGo5YhIo2BtcClqjo1xPFJwAGqelqlC2cYRq0hCl00AUhQ1cuC0t4A1qjq6MqT1IgFNoJkxIK+QCLwVpjjJwBvVp44hmHUUorTRS8D54hIfSg0qM4AXqkc8YxYYgaSEQuaAVtUNT/C8fWVKI9hGLWTiLpIVb8BNgJne0nnActUdX4lyWfEEDOQjFiwFWguIgkRjh9SifIYhlE7KU4XgRst+rP3/8W4USWjFmAGkhELvgNygbPCHP8M+GPliWMYRi2lOF0EzkD6g4j0BfoAUypDMCP2mIFkVDqqmgncDowXkbNEJElE6ojIKSLyAHAH0E9EHhSRgwFEpL2ITBKRJrGU3TCMmkMUughVXQV8DbwGfKqqG2IoslGJmIFkxARVfQQYDdwKbMZN6b8OeFtVV+CCJ9OAhSKSCfwXmAtkx0RgwzBqJJF0UVC2l4FULDi7VmHT/A3DMAzDMHzYCJJhGIZhGIYPM5AMwzAMwzB8mIFkGIZhGIbhwwwkwzAMwzAMH5EWx6qSNG/eXNPS0mIthmEYZeCHH37YoqotYi1HWTBdZBjVn0i6qNoZSGlpacydOzfWYhiGUQZEZFWsZSgrposMo/oTSReZi80wDMMwDMOHGUiGYRiGYRg+zEAyDMMwDMPwUe1ikEKxZ88e1qxZQ25ubqxFqfYkJibSunVr6tSpE2tRDKPaYbqo/DBdZMSaGmEgrVmzhoYNG5KWloaIxFqcaouqsnXrVtasWUPbtm1jLY5RkUyeDGPGQEYGpKTAuHEwfHispar2mC4qH0wX1SKqsC6qES623NxcmjVrZgqpjIgIzZo1s7ffms7kyTBqFKxaBaru76hRLt0oE6aLygfTRbWEKq6LaoSBBJhCKifsOtYCxoyBnJz903JyXLpRZuweKh/sOtYCqrguqjEGkmEYUZKRUbJ0wzCMiqCK6yIzkCqZU089le3bt0fMc/vtt/PZZ5+Vqv4ZM2Zw+umnl6qsUUtISSlZulHjMD1kVAmquC4yA6mSUFUKCgqYNm0aTZo0iZh37NixnHDCCZUkmVHrGDcOkpL2T0tKculGjcb0kFFqJk+GtDSIi3N/yyNOqIrrotppIFXEDw088sgjdOnShS5duvDYY4+Rnp5Ox44dueaaa+jRowerV68mLS2NLVu2AHD33XfToUMHTjzxRC644AIeeughAEaMGMGbb74JuO0M7rjjDnr06MGRRx7JkiVLAJg9ezb9+vWje/fu9OvXj6VLl5bLORi1gOHDYcIESE0FEfd3woQqM3OkVlEBusj0kFHuVFQwdVXXRaparT5HH320+lm0aFGRtLBMmqSalKTqfmb3SUpy6WVg7ty52qVLF92xY4dmZ2drp06ddN68eSoi+t133xXmS01N1c2bN+ucOXO0W7dumpOTo1lZWdq+fXt98MEHVVX1kksu0alTpxbmf+KJJ1RVdfz48Xr55ZerqmpmZqbu2bNHVVU//fRTHTZsmKqqfvHFF3raaaeV6VxKdD2NGsXevQW6dcdu3Zi1Szdk7tLcVyappqaqiri/3n0yKXRy1ABztQrok7J8qqIuqkl6SNV0USzZkLlLv1m+WT9fslE/6neGfpPSVRc3T9Xt9ZL39dfU1FiLWWYi6aIasQ5SiYgUNV8Gq/Xrr7/m7LPPJjk5GYBhw4bx1VdfkZqaSp8+fULmHzp0KPXr1wfgjDPOCFv3sGHDADj66KP53//+B0BmZiaXXHIJv/76KyLCnj17Si27YWzMyuWNOat5fc5q1m7fVZgeV9CI1iffStrv62iTuZE2z7zPb98fwoRPj2TX7jpI/fqsWlWPUaNc/qry4lctqABdZHrIKAuqymeLN/Ha7AxmLN1EgXoHBl5ZmEe0gKPXLubkZbMYungmB8ZG1EqhQg0kERkCPA7EA8+r6n1h8p0DTAV6qWrFbo9dQVHzzhAtSkBRRZs/FPXq1QMgPj6e/Px8AG677TYGDx7MW2+9RXp6OoMGDSqZwIaB64f/nrmCRz5ZRn6B0r99My7tn0a9OvHEjRnDxjxl5QGtSD+gJb8c3J7fkxoDu2gydDZNgMzvD2X7jI7l8Y5R+6gAXWR6yCgLL36Tzt3vL6JFw3pcdVw7BhzWnPp14qlz5hlkb8tiW1IjljdrwyeH9WHc8ZfzTL/zeGVdJp1bNo616BVChcUgiUg8MB44BegEXCAinULkawj8H/B9RcmyHxUUNX/sscfy9ttvk5OTw86dO3nrrbcYOHBg2PwDBgzgvffeIzc3lx07dvDBBx+UqL3MzExatWoFwMSJE8siulFLycrdw6hXf+CBj5ZycueDmXnjICaP7MPIgYdycZ9Uhn8xhdFfT+HJ9x7kvVdu4Mcnh/PLo+ey7rmBbJjUl01v9mTnglaF9VWRmbnVhwrQRaaHjNKSl1/AhC9X0LttU7676Xj+MaQD/do1p3vKAXS58Wr6bl3BaUu/4a/fvs4HL1/PR1P+Rr2GyZw/YRY/rNoWa/ErhIoM0j4GWK6qv6lqHvA6MDREvruBB4DKWTK1gqLme/TowYgRIzjmmGPo3bs3I0eO5IADDgibv1evXpx55pl069aNYcOG0bNnTxo3jt4K/8c//sHNN99M//792bt3b5lkN2of6zN3cdb4b/hiySZuP70TT13YndRmvlGGEA/qhnm7aJmZxe61Tdm14iD2bGkUKbsRiQrQRaaHjNLyzvy1bMzazdWD2pEQ7zMNQgRTd7j3Nqb+7QSaN6jHRc/PZl7G77ERvCIJF5xU1g9wDs6tFvh+MfCUL0934L/e/zOAnmHqGgXMBeampKQUCbIqcSBfWSNMy4ns7GxVVd25c6ceffTR+sMPP8REDj8WGFmzydi6UwfcP1273P6RzlqxJXzGMEHEk67+qsyxxViQtqMK6KKqqodUTRdVFnv3FuiJj8zQkx+dqQUFBSUquykrV/vdO11PfnSm7snfW+K2CwoK9LsVW/S5L1foLf/7Wf8x9SfN2LqzxPWUlki6qCJjkEKtE1/o8BaROOBRYERxFanqBGACQM+ePaN3modj+PAqESwxatQoFi1aRG5uLpdccgk9evSItUhGDWfV1p1c+Nz3ZOfuYdLI3nRrE2EtnMA94ttIcvjwAdC/yu4vWb2oArrI9JAxY9kmlm3cwSPndSvxFi8tGtbj1tM6cvXkeUz+PoNL+qVFXXZ7Th5j3l7ABz+vB6BRYgJ79irv/byOm0/pwPDeqcTFxW7LmYo0kNYAbYK+twbWBX1vCHQBZng/yMHAuyJyplZ0oHYVYcqUKbEWwahFrPk9hwuf+56deflMuaIPXVpF4UoJ8wCvAs91o5wwPWQ8O/M3WjZO5IxuLUtVfkiXg+nfvhkPf7KU07seQrMG9Yot8+2KLYz+z09s2bGbG08+gguOSeGApDqsy8zlpv/+zG3vLOSrX7fw9PAeRV1+lURFtjoHOExE2opIXeB84N3AQVXNVNXmqpqmqmnALKDWGEeGUZlsyMzdN3J0ee/ojKMahIgMEZGlIrJcRG6KkO8cEVER6VmZ8hlGrFi7fRffr9zGxX3TqFNKQ0REuPOMzuTk7eXBj4tfLPT12Rlc/MJskuvF89Y1/bl2cHuaJtdFRGjVpD6vXHYMt5zagU8WbeTO9xaWaLZleVJhBpKq5gPXAR8Di4E3VHWhiIwVkTMrql3DMPZny47dXPj8LLbtzOPly46pjcZR1ZxRaxhVgHmrXHD1gPbNy1TPYQc15JJ+afxn7mo+XrghZB5V5cGPl3DT/36hf/vmvH1tf45sXVQfiQijjm3HlcceyqRZGTz/1coyyVZaKnTcSlWnqerhqtpOVcd5aber6rsh8g6y0SPDKF927s7nsolzWLd9Fy+O6EX3lPAzmmowVXNGrWFUAX7M2E5inTg6HNKwzHXdePIRdG3dhOsmzSete+Z+O+hszt7NZRPnMP6LFZzfqw0vXNKThol1Itb3zyEdOPXIgxk3bTHvzF9bZvlKSu1bSdswagl79hZwzeR5LFibybMX9+SYtk1jLVKsaAWsDvq+BugdnEFEugNtVPV9Efl7uIpEZBRuVi0ptq6BUQP4cfXvdG3VpNTutWAS68RzSvLRzMv8Fu03h4R1vViXI/zloWwOWbSIfMln7NDOXNwnNapg8Lg44ZHzjmLrjtnc8J/5FKhydvfWZZYzWmrnZrXVgAYNGgCwbt06zjnnnIh5H3vsMXL8WxYUw4wZMzj99NNLLZ9R9Rnz1i/MXLaZcWcfyYmdDoq1OLEk2hm1fyuuIlWdoKo9VbVnixYtylHEqovpoprL7vy9LFybRfeUCLNZS8h9dyaycWpP4urupeWlX9Pysq9odPJ8dm5J5P2/DODPfdNKNFMusU48L13aiz6HNmP0Gz8xde7q4guVE2YgVSKlWUitZcuWhTtqh6M0Ssmo2bz/8zremLuGawe344Jjav1IR0lm1KYDfXAzamtsoLbpIgNg4bos8vYWlKuBlJEBe7Y0Yv2r/dgyrSub3urBhil9yHihP4cdVDo3XlLdBF5IXEH/9Yu58c2fuebCu1n90muAc9+lpbGfO6+8qJUGUkVc0PT0dDp06MAll1xC165dOeecc8jJySEtLY2xY8cyYMAApk6dyooVKxgyZAhHH300AwcOZMmSJQCsXLmSvn370qtXL2677bb96u3SpQvglNrf//53jjzySLp27cqTTz7JE088wbp16xg8eDCDBw8G4JNPPqFv37706NGDc889lx07dgDw0Ucf0aFDBwYMGFC42aRRcwj064QGu7nupQW0qt+YG044PNZiVQWq7Ixa00Wmi2LJjxnbAco1NjHgec7f2pCdv7Rh17JD2L26GSmty2BuTJ5M/atG8fykWxj91SS+OLgTf1iYyLmjP+W6ezeSsT4fVVi1CkaNKkcjKdwKklX1U9bVa8MsDlzmBWxXrlypgH799deqqnrppZfqgw8+qKmpqXr//fcX5jv++ON12bJlqqo6a9YsHTx4sKqqnnHGGfryyy+rqupTTz2lycnJhfV27txZVVWffvppHTZsmO7Zs0dVVbdu3aqqqqmpqbp582ZVVd28ebMOHDhQd+zYoaqq9913n9511126a9cubd26tS5btkwLCgr03HPP1dNOOy3kudjqtdWPff26QFucNUdT/jZNG7bKitUi8cVCJa+kDZwKLANWAGO8tLE4Q8ifdwZhVvUP/pguMl1U3bl28g/a91+flWudFdKvU1P3q3Bdw2Z6w6k3aOroaZr6z/c15e8faINu6YVZUlOjrzqSLoq5wVPST1mVku86l+qChmLlypXapk2bwu/Tp0/XoUOHampqqqanp6uqW9I/MTFRu3XrVvjp0KGDqqo2bdpU8/LyVFU1MzMzpFIaNmyYfvLJJyHOaZ9Seu+997RZs2aF9Xfs2FEvu+wy/fHHH3XgwIGFZd555x1TSjWIQL9O6rBWU//5vjbqvdz162bZMd/KIhSVbSBVxMd0kemi6k6/e6frNZPLf2uZct9BRyTkzSLxeZqYslmbHLdY6x78e+EhkeirjqSLat0stnA7jpfHTuT+wLPA9+RktwloQUEBTZo0Yf78+VGV96OqUeU58cQTee211/ZLnz9/fomXkDeqDxkZgChNBi5l94ZGZM1u69K3JsHWVS5TYPwZbBnsKoDpIiOWbMrKZe32XVzaP63c6w650v7kyaXfnyglxekvfzIbWZXRmtyM5kWylwe1LgYp3IUrjwuakZHBd999B8Brr73GgAED9jveqFEj2rZty9SpUwGnQH766ScA+vfvz+uvvw7A5DAO1JNOOolnnnmG/Px8ALZt2wZAw4YNyc7OBqBPnz588803LF++HICcnByWLVtGhw4dWLlyJStWrCiUz6g5pKRA0uEbqNM0h6zv2oO6WzsF39M2J8cpKSPmmC4yXRRL5lVA/FFYJk92L2erVrlBnpIGC40bB0lJ+6clJTFuVHqoZMaNKx+xa52BFOY6l8sF7dixIy+//DJdu3Zl27ZtXH311UXyTJ48mRdeeIFu3brRuXNn3nnnHQAef/xxxo8fT69evcjMzAxZ/8iRI0lJSaFr165069atcA+lUaNGccoppzB48GBatGjBxIkTueCCC+jatSt9+vRhyZIlJCYmMmHCBE477TQGDBhAampq2U/YqDLcc4/SpO8K9mxLJufXgwFIYifjuKVo5vIYojDKjOki00Wx5MfVv1MnXujcslHFNzZmjHs5C6YkL2vDh8OECZCaCiLu74QJDH96QKjk8hsgD+d7q6qfsvr9VSvAP6r7++erO+b3r3588+tmTf3n+5p6/Kp9/brZXyomyKUcwGKQVNV0UXGYLqoYCgoK9ORHZ+pZ47+unAbDxBCVKFiogoiki2pdDBLYTuRGzePfM1fQvEE9vv6oFYWr90/uDaNe2P/NrTzHn40yY7rIiAXfrtjKkg3Z3P/HIyunwTAxROUWLFRB1DoXW0WRlpbGggULYi2GUQtZsDaTr37dwqX900isE7/vQJhhaXsi12xMFxnFMeHL32jeoB5Dj2pVOQ1WpD+5AqkxBpIbKTPKil3H6sejny6jUWICF/UJEcsxfDikp0NBgftrxlGFY/dQ+WDXsXwJLEpa78BsZi7bzFHJqfu/UFUk1fRlrUYYSImJiWzdutVuqDKiqmzdupXExMRYi1J9qMh17qNgXsbvTF+yiSuPa0fj+pF3xjYqHtNF5YPpolIQQRcFTyJr2Os3CvLief2e1MpVV9XwZa1GxCC1bt2aNWvWsHnz5liLUu1JTEykdevK2y25yhLNmh0BrROI8QmxzlBZlv6Ihoc/WUqz5LqM6JdWfpUapcZ0UflhuqgEFKOLApPI4hvlkNxpLdk/prJzW13GjKkWdkrMqBEGUp06dWjbtm2sxTBqClEYPkDh1NXchLqsa9ic7HrJ7Kxbn9ynplDQ/QS+mKmMfyKeXXsSiG9Sh1Wrkhk1SopUU1q+XbGFb5Zv5dbTOpJcr0bcytUe00VGTIg0jX74cNZuz+GAP6ykQbcMtEDInustJGsrfkREqttQcM+ePXXu3ArfQ9KozaSlhZ5xkZpKwW8rWbQ+i69+3cK3/36NZc1T2NiwWVTV5m+vz85lB9N4a2vSfyrb2iO78vZy/oTv2Ji1mxk3Dqq8WIJyQkR+UNWesZajLJguMqoMcXFu4rxHvsTxWfvefNG+F3OOP5vftuxE9wo7F7Uic1Y78rc1AFwoUHp6jGSuIkTSRfbaaRh+QrxWbU5qwtRDjuH1h2aQsc29qXU44EAGps8j9fcNtMraRKPcnSTn7aJ+8wOIf/ddevYE4guIq5dPQqNd1D9sA42OTkdlJQ9+3I6//uFw6iYUEwYYwke3deg5XP7yXH5em8nj53evdsaRYRjljDeNPrtufV7qOZQpRw1hQ8PmNN69k57NkzksoQ1T7m3Jjk31C4tUg0lkMccMJMPwE7Rmx+IWaTzX62ze63Qse+Lr0LtxIn85vj3HHd6CA9/7L4x6rug6Q/dOgNaNOSRx/4GoHT+lEJeYR5szFjP+ixV8vmQzN53SgX7tmlEnPoSh5HP15Wes5sc7HubGpQ1ZX1CHfw8/miFdDq7IK2EYRnVg3DhW3ng7V5z6d5Y3T2HgynncPfMFjr/pSuIv6gXAsS0qNh6yJlKhBpKIDAEeB+KB51X1Pt/xq4Brgb3ADmCUqi6qSJkMozj0nnF8e/cTPHPU6XzVtgdJebsY/sunXHzeANpddtq+jAHtEkbrjBu3fygTQGJcXcYN7caB3Q/m5v/9wiUvzqZx/ToMPqIFBzVOpGG9BOolxFOgyt5JM9h59B/JTGzA+kYtmN26E9mJDTggewdTrh/I0amVsIeSYRhVni97ncR1IxoRvyuHKa+PoR/bi1hAtihpyamwGCQRiQeWAScCa4A5wAXBBpCINFLVLO//M4FrVHVIpHrN729UFHsLlGm/rOeZmStYuC6L5ruyuHTO2wzf8gtN7ijddI9Is9hy9+zlq1+38OEv6/lq+RYyd+0hL79gv/JxBXtpkruDpjmZ9FqziP6r5jMwfT6Nd2WXxynHDItBMozy4dvlW7j4xdkcdmADnvtzT9o0TSq+kFFIrGKQjgGWq+pvnhCvA0OBQgMpYBx5JAPVK2LcqLbsZ7ikFnDW6DXMz11B+tYcDm2ezH3DjuSs7q1IrHNBmdqJ9NaWWCeeEzsdxImdDipM252/l935BcSLENepI4m/LUf8BW1zT8MwgNXbcrh2yjzaNk9m6lV9aZhoa6GVJxVpILUCVgd9XwP09mcSkWuB0UBd4PhQFYnIKGAUQEoV37vFqPrsC+1R6h+2kT3HLeHttTtpWb8x/x7eg5M6H0x8XBGzpFKolxBPvQQv6HrsnUV9dBZZaRgGkJOXzxWvzGVvgfLcn3uacVQBFLuStog8ICKNRKSOiEwXkS0iclEUdYd6whQZIVLV8araDvgncGuoilR1gqr2VNWeLVq0iKJpwwjPmDGwO34XB53/PQcO+wGATW/2ZN3dqZzy8+cxM46KUE2X568oyqCLEJEhIrJURJaLyE0hjl8lIr+IyHwR+VpEOpX/GRhG+aCq3PjmzyzbmM2TF/agbfPkWItUI4lmq5GTPFfY6bhRoMOBG6MotwZoE/S9NbAuQv7XgbOiqNcwysTmxPUcctmX1D04k60fd2HdC8eya8VBZOxt5UZsKnm7kIhUw+X5K5BS6SIvHnI8cArQCbgghAE0RVWPVNWjgAeAR8pVcsMoR17+Np0Pfl7P308+guMOt0GDiiIaAykwbncq8Jqqbouy7jnAYSLSVkTqAucD7wZnEJHDgr6eBvwaZd2GUWLy8gu49e1faHHWPPK3NWD9xAHsmJ8K6m6DFDL2rT5rVEVKq4sK4yFVNQ/3MjY0OIPFQxpVFt8eaz8+9zrjpi3mDx0O5Kpj28VauhpNNDFI74nIEmAXcI2ItAByiyukqvkich3wMW6a/4uqulBExgJzVfVd4DoROQHYA/wOXFLaEzGMSGzIzOXqyT/wY8Z2BjY/lP+NP4L8HfveD5LYyThucV9s/f2qSql0EeUYD2kYlYpvLbTfN27juh9zObBZMg+f1424qhIOUEMpdgRJVW8C+gI9VXUPkIPv7StC2WmqeriqtlPVcV7a7Z5xhKr+VVU7q+pRqjpYVReW/lSMWk+I3awLCpS3f1zL6U9+zdIN2Tw9vAev/r0jE56JIzV+DUIBqaQzgSsYzmuuHpsIUCUpgy4qt3hIERklInNFZK5tSGtUOEF7rO2oW58R597J5qQmPP3BgzRJqhtj4Wo+xY4giUgSbjHHFNxMspbAEcD7FSuaYZQA35tW1vrNfHvfczzxawMW5SbQuWUjHv1Tbw4/qCHgTb9nps0Sq0aUQReVJh7y36EOqOoEYAK4dZCiEtwwSos3mr0roR6X/fF2Fhzcnn+/9S+6rZgdY8FqB9G42F4CfgD6ed/XAFMxA8koZ/ZfVFG5ekwmXfvsIm9vAfl7lQJvUVMFCgqUAoU9ewvIyy8gd/JXbOs7nK1JjVnRtDWLD2xLQVw8rbds4fGRJ3BG15ZFh6OLWQnbqHKUVhcVxkMCa3HxkBcGZxCRw1Q1EANp8ZBG1SAlhZ3rNnL1WTczp01nHnvvIU5a/r2thVZJRGMgtVPVP4nIBQCquktEzPFplCv7rU3UbhO5fVbw7xW/w4ooK+h6Bg1259AsZzutMzfxl2//wzFrFtJrzSLqPpUXvpytv1+dKJUusnhIo7qy4vZ7uXJWFr81OYT7P3ySoYu/tFHuSiQaAylPROrj+exFpB2wu0KlMmodAVd7477LaXLsMvIz67Pt0840zW/K9M/iSIgT4oKehfHe9zrxQt2EOOp16kDdlb8VrdjetGoSpdZFqjoNmOZLuz3o/7+Wo5yGUWY+WrCBv69qSt0WDZj06ZP0W/CZ02c2yl1pRGMg3QF8BLQRkclAf2BERQpl1D4CE8cSD93M7nWN2TC5HxTEsUOgXTTLfNw91uKJaj6mi4waT+6evdzzwSImzcqga+vG/PuiY2k17oxYi1UrKdZAUtVPRWQe0Ac3G+SvqrqlwiUzahUpKbBqlVL3wCx2/NwGCuIK06PC4olqPKaLjJrOyi07uerVH1i6MZsrBrblxpM7UDchmuUKjYogmllsx3r/BrYP7yQiqOqXFSeWUdsYNw6uvjGHuLp7ydvUCCjFAJDFE9VoTBcZNZHA5JT1O7M55MLvSWpQwMRLezHoiANjLVqtJxoXW/BS/om4VWl/wBZSM8qR4cPhl+2ZvL4a9mxqZK52IxSmi4waRWByyp4GmRx0wWzy84U1zx7F2mfvgcd72thczwAAIABJREFUmwKMMdG42PZzfopIG9xeRYZRrjRtl0XCWiFrTQPqRWO6G7UK00VGTSOwcfYh53+P5iWw8fXe5G9PZgyjGT6qs8tkRlLMKI1zcw3QpbwFMYxF67Nof2AD6iXEx1oUo3pgusio1mRkKE1PWoDEFxQaRwAZpNi+kFWAaGKQnmTfsvxxwFHATxUplFE7Wbgui2MPs52pjdCYLjJqGikD1kH7TWyb3rHQOAJv42ywfSFjTDSOjLlB/+fjdtH+poLkMWopm7Jz2Zy9m04tG8VaFKPqYrrIqDFs25lH0sBFZK5tQvYPbQvT99s42/aFjCnRxCC9XBmCGLWbxevdxKROh5iBZITGdJFRk/jXtMXsYQ9/G9iVJ97fScbWJFLIYBy3uI2zbR23mBPWQBKRXwix4zVu/RFV1a4VJpVR61i0LgvARpCMIpguMmoav27M5r/z1nDFwEMZfWpDRl+ObzNKm8ZbFYg0gnR6pUlh1HoWrsuk9QH1aVy/TqxFMaoepouMGsVj038lqU48Vx3Xbl+ireNW5QhrIKnqqsoUxKjdLFqfZe41IySmi4yaxOL1WXzw83quG9yepsl1Yy2OEYFip/mLSB8RmSMiO0QkT0T2ikhWZQhn1A5y8vJZuWWnudeMiJguMmoCj366jIaJCVwx8NBYi2IUQzTrID0FXAD8CtQHRgJPVqRQRu1i8fpsVC1A2ygW00VGtean1dv5ZNFGRg44lMZJFk5Q1YlqoUhVXQ7Eq+peVX0JGBxNOREZIiJLRWS5iNwU4vhoEVkkIj+LyHQRSS2Z+EZNYNG6TAA6t2ocY0mMqk5pdZFhxJrd+Xv5x5s/06JhPS4bkBZrcYwoiGYdpBwRqQvMF5EHgPVAcjFlEJF4YDxwIm7F2zki8q6qLgrK9iPQU1VzRORq3LYBfyrpSRjVm4XrsjggqQ4tGyfGWhSjalMqXWQYVYFHPl3G0o3ZvDSiFw0TbfSoOhDNCNLFXr7rgJ1AG+CPUZQ7Bliuqr+pah7wOjA0OIOqfqGqOd7XWUDraAU3ag4L1mXSuWVjRCTWohhVm9LqIsOIKXPStzHhy9+44JgUBnc4MNbiGFESjYHUA7fWSJaq3qWqo71h7uJoBawO+r7GSwvH5cCHUdRr1CDy8gtYtmEHnVtZ/JFRLKXVRebuN2LGkg1Z3PCf+bQ+oD5jTusYa3GMEhCNgXQmsExEXhWR00Qk2n3WQw0HhFrsDRG5COgJPBjm+CgRmSsiczdv3hxl80Z14NdN2eTtLaBzS4s/MoqlVLooyN1/CtAJuEBEOvmyBdz9XYE3ce5+o5YyeTKkpUFcnPs7eXLJK8hveyhP9z2PMx7+gtzsnTxxfnca1Iv28WlUBaLZauRSEamDUy4XAk+LyKeqOrKYomtwQ+ABWgPr/JlE5ARgDHCcqu4OI8MEYAJAz549QxpZRvVkobeCdheb4m8UQxl0UaG7H0BEAu7+wnhIVf0iKP8s4KJyFd6oNkyeDKNGQY4X/LFqFYwapajChRe6t/wCVQpUyd+r5OUXsDu/gO278ti2I4+MD79g9vSf+O6U21nfqAWnLP2Ge758kWYdH7aFIKsZUZmzqrpHRD7E9Y36OOVSnFKaAxwmIm2BtcD5OKVWiIh0B54FhqjqphLKbtQAFq7NJLluPGnNLNbWKJ5S6qJQ7v7eEfKbu7+W8sWSTYyZtYBmo/bQPGEvEr/vffzWBXDrLdHUkkSzNt3ovXoBt09/jiHLvnXulDFjzECqZhRrIInIEJxxMxiYATwPnFdcOVXNF5HrgI+BeOBFVV0oImOBuar6Ls6l1gCY6gXoZqjqmaU8F6MasnBdFp1aNiIuzgK0jciUVhdROnf/cWGOjwJGAaTYTus1inXbd3H9f+azZ1c9dqUfhO6JRwvi9uspd94JghAfByJCQpxQNyGOuglxNK5fh2bJ9TjomG603ba2aKfLyKjEszHKg2hGkEbgZqBdGc4FFg5VnQZM86XdHvT/CSWpz6hZ7C1QFq3P4ryebYrPbBil10Xm7jcisrdAuf71+eTvLaDOrJ6sW1h0RDs1Fa6P5onVMAG2hUg3g7raUWyQtqqer6pvl9Q4MoziSN+6k5y8vXS2+CMjCsqgiwrd/d46SucD7wZnCHL3n2nu/trHU58vZ3b6Nu4+qwvjbk4mKWn/40lJMG5clJWNG0fZKjCqClGtpG0YFcGCtd4K2jaDzahAVDUft3bSx8Bi4I2Au19EAi79YHf/fBF5N0x1Rg0jO3cPT3z+6/+zd9/hUVXpA8e/bzoh9N6SIEV6DQICKooNVBRFxeiiuy6rq7uurmtD8acuq67dFdfNWnAlNrBjwV4QRUBAEBApSQg1BAjpbd7fH3cCYUhC2rTk/TzPPJm5c+fe985Mzrz3nHPP4bzBnZkyrCuJiZCU5NQYiTh/k5Jq0H2ozhswgcKuOTR+s27HQSJCQ+jVIcbfoZgGzpr7TWW27cun1KWcPaDjoWWJiXXMZ+q8ARMIKq1BEpF2FYwVgoj0F5F23g3LBLw6DxTidNA+vmMzwkOtItNUTkRuFhHrqGa8Ytt+53r+rq2ij7GmaWyq+mX6F1BRItQVeMI74ZigUDZQSGoqqJYNFFLtJCkju5DZ769j6dZMBna15jVzTF2AJSLytYhcKyJt/R2QaTjS9+cD0LVVEz9HYgJNVU1sA1X1K8+FqrpIRB7xYkwm0M2ceXgUtTJ5eUeN83Egr4jNGTmk7M0jbV8eu7IK2JGVz7KUfRSVuDh/aBdunNDbx8GbYKOqN4rITcBJOB2s7xKR1cArwFuqmu3XAE1QS9+fR0xkGC2jbQJZc6SqEqSqvi32TWoskpOdxCctzblMdfbsSsfz2L0vh89/SOO7zZmsTj9AaubhJEoE2sVE0qlFFBcM7cKMk3rQva0NDmmqR1UV+Ar4yj2+2gTgAeAZwNpGTK1t25dP11ZNbLJsc5SqEqRfRWSiu3PjISJyNrDFu2GZgFDxmPvQujVkZgKwr0lz3up/Cm/3G8+aTr3gzTV0aB7J0G6tuGREN/p0bEZcm6Z0axVNRJj1NTJ1IyIDcWqRLgEygWqNbWxMZdL351nzmqlQVQnSjcBCEbkYWOFelgCMBs7xdmAmAFTWlNakCau6D+S5AWexqPeJFIWFM3D3Zv7WIZ8J086kd4cYOxsz9UZEegHTcBKjUpzBIs8om1vNmNpSVbbvz2fUcW38HYoJQJUmSKq60X22dhkwwL34K5xRbAt8EZzxs7Q0kpnGTP5BGrHEksoVx81hw6j2LOvWn2ZFeSSu+oBLMtbS55brIPEif0dsGqZFOP2NLlHVNf4OxjQcWfnFZBeWWA2SqVClCZKI9AQ6qOoLHsvHicgOVd3s9eiMXyW3vp4ZmfeTRzRNeuyhcMx2Xuo0npbZ+cw6px8Xj+hGTORUf4dpGr4zccqiI5IjERkHWFlkau3wFWzWjc0crapOIY8DFV0dku9+zjRwM/kHxe1L6DDte9pftJyQqGL2fjCIA6+fwW/Hdicm0sYZNT7xGHCwguVWFpk6ST80BpLVIJmjVfULF6+qP3kuVNXlIhLvtYhMQCgqcZE9NIVOw1Jx5UeQ+dEAcn7qBhpCnnUvMr5lZZHxim37nBqkbq2tBskcraoEKaqK5yzdbsCy8oq5Zt4Kmg3P5ODyeA4s7o0WHh7ZwSalNj5mZZHxivT9eTSLCqNFExu5xhytqia2ZSLye8+FIvI7Dl/VZhqYbfvymPLvb1mRup+pXYdQ+F3/I5Ijm5Ta+IGVRcYr0vfnW/8jU6mqapD+ArwlIokceZl/BHCBtwMzvldS6uLa5BVkZBfyv9gsRt0/hiF5Y5gZ+iBppV2IjRNmz7Y5GI3PWVlkvGLb/jzi29iAtaZiVV3mvxs4UUTGc/gy//dV9XOfRGZ87vlvt7J2+0HmxOYy6qbfQV4eiaSSWPqyu+ooybIj43NWFhlvUFXS9+cztqfNvW4qdszLkFT1C+ALH8Ri/Cg1M5dHP9nI6f06MHHWRdWaa80YX7KyyNSn/XnF5BWV2hVsplI294NBVbn9zTWEh4Rw3+QBSCVzrVU2B5sxxgSbbfvsEn9TNa8mSCJyloj8IiKbROS2Cp4/SUR+FJESEbFhmP3k43W7WbI5k9sm9qFji6jKL1Ozy9eMMQ1E2SCRdom/qYzXEiQRCQXmAGcD/YBpItLPY7U04ErgZW/FYY7tucVb6dqqCZeOcCdAs2c7fY7Ks8vXjDENSNkgkV2sBslUwps1SCcAm1R1i6oW4UwwObn8Cqqa4h4AzuXFOEwV1m7P4oet+7jyxHhCQ9wjQCYmQlISxMWBiPM3yTpom+BltdnG07b9ebRoEk7zKBsDyVTMm3NFdAG2lXucDoz04v5MLTz/7VaaRoRy8YhuRz6RmGgJkWkQytVmn45TDi0TkXdVdV251cpqs2/2fYTG14pLXSxP2U+sNa+ZKnizBqmiCSm0VhsSmSEiy0VkeUZGRh3DMmX2ZBfw3uodTE3oZmdRpiGz2uxglpwM8fEQEuL8TU6u8yYf/3QjG3ZlM+Ok4+q8LdNweTNBSgfKV0t0BXbUZkOqmqSqCaqa0K6djVlRX+Z9n0aJS5l+Yry/QzHGmyqqze5Smw3ZyZqPJSfDjBmQmkqyXkp86peEXD6N+LY5tc6Tlmzay9NfbuaShG6cO7hz/cZrGhRvNrEtA3qJSHdgO3ApcJkX92dqILewhHnfp3Lq8e3p3tZGkjUNWr3VZqtqEpAEkJCQUKttmBqYORPy8khmGjP4L3k4ZVVaVhOu+Vsu2/KKOPlUFwUlpZSWKqWquFyKAqqg7o9ZFQpLXBQUl/LkZ7/SvW1T7j7P85ohY47ktQRJVUtE5HpgERAKPK+qP4vIvcByVX1XREYAbwGtgHNF5B5V7e+tmMxhc5eksC+3iOtO7envUIzxtnqrzTY+5h57bWbkfUiP/bTtvYGobvsIjS4C4JnNzq0mmkWF8cJVI4iO8Gb9gGkIvPoNUdUPgA88ls0qd38ZTmFlfCi7oJikr7cw/vh2DItt5e9wjPE2q80OVrGxfBjZBdfEX2kbWUpJdiT5m9pTfCCa0uwmuPLD+XRRKJFhoYSHCiEihIYIIiCU/XVEhoUSFR5C8ybhRIWH+vWwTHCwFLoRen5xCln5xdx0+vH+DsUYr7Pa7ODkcimP//kRntwTRciOCHZ+NpSiHS0p32IaFwcn9vBfjKZhswSpkcnKK+bZxVs4o18HBnZt4e9wjPEJq80OPne+s5aX90RxUatCBrzwCdftGUlRueTIxq413mZzsTUiqso/PlhPdkEJN57e29/hGGNMhZZuyeTlpWn8bmx3HrrlAq7c/ThJ85ra2LXGp6wGqZFwuZS73lnLa8u3ce0pPejbqbm/QzLGmKMUl7qY9c7PdGnZhJvPOB4Rp9bIxq41vmY1SEGq2mOnJSeT16M3d0y6geSlaVzbroBbzrS+R8aYwPS/71L5ZXc2s87tR5MI60xt/MdqkIJQ2dhpec5ci6SmOo8Bpk1TDhYUs/1APtveXsTHi1az6LzZ5EZG86clr3LTijeRjgV2KmaMCTh7Dhbw2CcbOeX4dpzRr4O/wzGNnCVIPrbwpx08/cVmCktKKSp14arFxAbbtyutpkMrURAQUQhRZq4sZeaa8htsSrPuwzl3wzdMWfs5J6T/7CyeOdMSJGNMwHnmqy0UFJdy97n9DzWtGeMvliD52JwvNrMvt5CEuNZEhIUQUoNCoGzVud8ACqrijAesgroESkK5845QmkeF0aVlEzqdeQp99mwlqrT4yA25B18zxphAkZVXzKvL0jh3cGcb3d8EBEuQfGhzRg7rdx5k1jn9+O3Y7rXezoK/Oc1qnuLi4KbTyy2IKATP5AggNrbW+zbGGG+YtzSVvKJSfj/OJpA1gcE6afvQwtU7EYFJgzrVaTuzZztjgJRX4Zgg1V7RGGP8p7CklLlLUhjXqy39OtsVtiYwWILkQwt/2sGI+NZ0aB5Vp+0kJjpjgBxzTJBqr2iMMf7zzsodZGQXMuMkqz0ygcOa2Hzkl13Z/Lonh/sm18/sBdUeE8QGDzHGBLBSl5L0zRb6dWrO2J5t/R2OMYdYDZKPLPxpByECZw2oW/OaMcY0JK8t28amPTn8cXwPu3LNBBRLkHxAVXn/p52MOq4N7ZpF+jscY4wJCPtyi/jnog2M7N6aSQPt5NEEFkuQfGDdzoNs2ZvLOYM6+zsUY4wJGA8t2kB2QQn3nT/Aao9MwLEEyQcW/rST0BDhrAEd/R2KMcYEhFXbDvDqsm1cdWI8vTs083c4xhzFEiQvU1UW/rSDMT3b0rpphL/DMcYYv1uTnsUf562gXUwkN0zo5e9wjKmQJUhe9lN6Ftv25XNOHcc+MsaYQFSTibOJj+ed/uO56PHPkbw8XrhqBM2iwn0YrTHVZ5f5e9nCn3YQHiqc2c+a14wxDUtVE2cnJjo16Fn5xWx7+U2+eulDPj75Bn7q1JsTtq3l6UWP07bPwzYMiQlYXk2QROQs4AkgFHhWVR/weD4S+B8wHMgELlHVFG/G5Esul3P12km92tEi2s6SjPGXxl4WedqTXcB/vtrCmu1ZqOox1y+/Svm1V6xQmk+B5uJ+JkSREGXmklL+lepif14RhSUuoBmMnsaQHRuY+flzTF/xHhGuEps42wQ0rzWxiUgoMAc4G+gHTBORfh6r/Q7Yr6o9gceAB70STLXrgOt3Nw88u58dWQWcM9ia14zxl4Api3xUDlW1q8ycQv7xwXpO+ucXzF2SgqoSFhJCeGjVt4iwECLDnVtUeAhNwkNpEh5Kfk4YrqIwXIVhuPIjKM2JouRANLnbWnJy73b8ZnQcd53Tj6ffvp+lc37D2y/dzO+XveUkR2ATZ5uA5s0apBOATaq6BUBEXgUmA+vKrTMZ+D/3/QXAUyIiWp1TmuryqAN2paahf/iDcxp02WX1tpuXX4ZrrnHvRpS0nS6eeHsHzQaHMKFvh3rbjzGmxvxfFlXQFlXqhXIIPMoilNRt8Ic/F/Pxrq0sy0qhoLiU84d04c+n9SK+bdM67Sv+75VPnP3gReUWFKRDzr6jV7SJs00A82aC1AXYVu5xOjCysnVUtUREsoA2wN56i2LmzMOFEnDPhBm8OPxcWAvc8UG97Qag3fVHLyvZ1sE6IRrjX/4vizzKIYA/nHkjn65tWe/lEFRcFn2VAecM6sRfJvSmZ/uYetnP7NlH5n1QxcTZ1VrRmMDhzQSpolG/PM/GqrMOIjIDmAEQW9MzDo8q3PGbl9EmL8t5cO+9NdtWFWbNOnxfFSgNQUtCyd9ktUfG+Jn/y6IKmpImr/uKQbs21Ws5BEeWReAuj1xCwZb2PLWneb3uq6z70MyZziHGxjo5T4UTZ1drRWMCh9Rna9YRGxYZDfyfqp7pfnw7gKreX26dRe51vhORMGAX0K6qau2EhARdvnx59QOJj6+8DjglpfrbCYzdGNMgiMgKVU3w0b78Xxb5sICwssiY6quqLPLmOEjLgF4i0l1EIoBLgXc91nkXmO6+fxHweb32PwLnLCU6+shlXqja9dFujDE15/+yyIcFhJVFxtQPryVIqloCXA8sAtYDr6vqzyJyr4ic517tOaCNiGwCbgJuq/dAEhMhKck5fRJx/iYl1XvVro92Y4ypoYAoi3xYQFhZZEz98FoTm7fUuInNGBNwfNnE5i1WFhkT/PzVxGaMMcYYE5QsQTLGGGOM8WAJkjHGGGOMB0uQjDHGGGM8BF0nbRHJACoY5aNa2lKfo3QHBjum4NAQjwlqf1xxqtquvoPxpTqURfZdCB52TMGj3suioEuQ6kJElgf7lTOe7JiCQ0M8Jmi4x+VNDfU9a4jHZccUPLxxXNbEZowxxhjjwRIkY4wxxhgPjS1BSvJ3AF5gxxQcGuIxQcM9Lm9qqO9ZQzwuO6bgUe/H1aj6IBljjDHGVEdjq0EyxhhjjDmmRpEgichZIvKLiGwSkfqfENcHRKSbiHwhIutF5GcRucG9vLWIfCIiv7r/tvJ3rDUlIqEislJEFrofdxeRpe5jes09A3tQEZGWIrJARDa4P7PRwf5ZiciN7u/eWhF5RUSiGsJn5UtWFgU2K4uCg6/KogafIIlIKDAHOBvoB0wTkX7+japWSoC/qmpfYBRwnfs4bgM+U9VewGfU9yzkvnEDzizrZR4EHnMf037gd36Jqm6eAD5S1T7AYJzjC9rPSkS6AH8GElR1ABAKXErD+Kx8wsqioGBlUYDzZVnU4BMk4ARgk6puUdUi4FVgsp9jqjFV3amqP7rvZ+N8ybvgHMuL7tVeBM73T4S1IyJdgUnAs+7HApwKLHCvEozH1Bw4CXgOQFWLVPUAQf5ZAWFAExEJA6KBnQT5Z+VjVhYFMCuLgopPyqLGkCB1AbaVe5zuXha0RCQeGAosBTqo6k5wCi6gvf8iq5XHgVsAl/txG+CAqpa4Hwfj53UckAG84K6uf1ZEmhLEn5WqbgceBtJwCqMsYAXB/1n5kpVFgc3KoiDgy7KoMSRIUsGyoL10T0RigDeAv6jqQX/HUxcicg6wR1VXlF9cwarB9nmFAcOAf6vqUCCXIKrCroi7j8JkoDvQGWiK01TkKdg+K19qCN/tQ6wsCgpWFtVBY0iQ0oFu5R53BXb4KZY6EZFwnAIpWVXfdC/eLSKd3M93Avb4K75aGAOcJyIpOM0Np+KcxbV0V51CcH5e6UC6qi51P16AU0gF82c1AdiqqhmqWgy8CZxI8H9WvmRlUeCysih4+KwsagwJ0jKgl7uHewROZ653/RxTjbnbw58D1qvqo+WeeheY7r4/HXjH17HVlqrerqpdVTUe53P5XFUTgS+Ai9yrBdUxAajqLmCbiBzvXnQasI4g/qxwqrNHiUi0+7tYdkxB/Vn5mJVFAcrKoqA6Lp+VRY1ioEgRmYhzNhAKPK+qs/0cUo2JyFjgG2ANh9vI78Bp+38diMX54kxV1X1+CbIOROQU4GZVPUdEjsM5i2sNrAQuV9VCf8ZXUyIyBKezZwSwBbgK54QkaD8rEbkHuATnKqaVwNU47fxB/Vn5kpVFgc/KosDnq7KoUSRIxhhjjDE10Ria2IwxxhhjasQSJGOMMcYYD5YgGWOMMcZ4sATJGGOMMcaDJUjGGGOMMR4sQWqgRKRURFa5ZzxeLSI3iYjPP28RGeeOYZWI9BWRy7y4r7kictGx16zwtUPcl2CXPT5PgnS2dWMCiZVFNX6tlUUBwhKkhitfVYeoan/gdGAicLcf4kgEHlbVIUAHoEaFknsGdF8YgvMeAaCq76rqAz7atzENmZVFNWNlUYCwBKkRUNU9wAzgenHEi8g3IvKj+3YigIi8JCKHZhcXkWT32Ut/EfnBfeb1k4j08tyHiPxbRJa7z9DucS+7GrgYmCUiycADwDj3dm4UkVAReUhElrm3+wf3604RkS9E5GWcweg895UjIo+4Y/9MRNpVsM4s93bXikiSe8RVRORLEXnQfTwb3WeVEcC9wCXu2C4RkStF5Cn3a+aKyJMiskREtpSdGYpIiIg87T7mhSLyQW3PGo1pDKwssrIoqKiq3RrgDcipYNl+nDOnaCDKvawXsNx9/2Tgbff9FsBWnMkO/wUkupdHAE0q2HZr999Q4EtgkPvxXOAi9/1TgIXlXjMDuNN9PxJYjjMB4Sk4kyp2r+TYtFw8s4CnKthX63LrvwSc677/JfCI+/5E4FP3/SvLtuP52L3d+TgnFP2ATe7lFwEfuJd3dL+/F/n7s7eb3QLpZmWRlUXBerMapMalbHbqcOC/IrIG55+tH4CqfgX0FJH2wDTgDVUtAb4D7hCRW4E4Vc2vYNsXi8iPOEO89y/b5jGcAfxGRFbhTFPQBqeQBPhBVbdW8joX8Jr7/jxgbAXrjBeRpe5jPNUdU5myyTVXAPHViBOcwtqlqutwCnbc+53vXr4LZy4gY8yxWVnksLIogFmC1EiIM6dQKc6szTcCu4HBQALOmViZl3Da6q8CXgBQ1ZeB84B8YJGInOqx7e7AzcBpqjoIeB+Iqk5YwJ/U6Z8wRFW7q+rH7udya3B4R8yXIyJRwNM4Z1ADgf96xFM2P08pzllpdZSf00c8/hpjqsnKIiuLgoUlSI2Au138GZxqWsWpst6pqi7gCpyq6DJzgb8AqOrP7tcfB2xR1SdxZoEe5LGL5jiFSJaIdADOriSUbKBZuceLgGtFJNy9n94i0rQahxTC4VmbLwMWezxfVgDtFZGYcutWxTO26lgMXOhu/++AUx1vjKmElUVWFgWT6masJvg0cVcXh+PMePwS8Kj7uaeBN0RkKk5V7KEzJFXdLSLrgbfLbesS4HIRKQZ24XQipNxrVovISuBnnNmiv60kpp+AEhFZjVP4PYFTrfyju+NiBnB+NY4tF+gvIiuALHd85eM5ICL/xelUmQIsq8Y2vwBuc79n91djfYA3gNOAtcBGnKr5rGq+1pjGwsoiK4uCkjhJvDEOEYnG+WcepqoB+Q8mIjmqGuPvOABEJEZVc0SkDfADMMbdB8AYUwdWFtWMlUX1z2qQzCEiMgF4Hng0UAukALRQRFri9J24zwokY+rOyqJasbKonlkNkjHGGGOMB+ukbYwxxhjjwRIkY4wxxhgPliAZY4wxxniwBMkYY4wxxoMlSMYYY4wxHixBMsYYY4zxYAmSMcYYY4wHS5CMMcYYYzxYgmSMMcYY48ESJGOMMcYYD5YgGWOMMcZ4sATJ+I2IXCYiy0UkR0R2isiHIjJWRP5PROZVsL6KSE9/xGqMaRhEJEVE8t3lTtntqWq8rpmIPOp+fa6IpInIAhE5wRdxG98L83cApnESkZuA24BrgEVAEXAWMBnI9WNoxpiG71xV/bS6K4tIJPA5cAA4B1gPRAFnAxOBH7wRpPEvq0EyPiciLYB7getU9U1VzVXVYlV9T1X/5u/4jDGNj4hbrmVDAAAgAElEQVT8W0QWlHv8oIh8JiICXAF0Bc5X1bWqWuoutxao6v/5K2bjXVaDZPxhNM7Z11v+DsQYY9z+CqwSkSuBzcDvgCGqqiIyAVikqla73YhYDZLxhzbAXlUtqWKdi0XkQPmbr4IzxjR4b3uUL79X1TzgcuBRYB7wJ1VNd6/fFthV9mIRGeJ+3UER+cX34RtfsATJ+EMm0FZEqqrBfF1VW5a/+So4Y0yDd75H+fJfAFX9AdgCCPB6ufUzgU5lD1R1lbtMmgJE+jBu40OWIBl/+A4oAM73dyDGGFNGRK7DSXh2ALeUe+oz4AwRaeqXwIxfWIJkfE5Vs4BZwBwROV9EokUkXETOFpF/+js+Y0zjIyK9gb/jNLNdAdwiIkPcT/8P2Am8JSIDRCRURKKABP9Ea3zBOmkbv1DVR0VkN3AnkAxkAyuA2cAZ/ozNGNPgvScipeUefwJ0AR5U1dUAInIH8JKIJKhqgYiMB+4B3sfpk7QXWA5c7NvQja+Iqvo7BmOMMcaYgGJNbMYYY4wxHixBMsYYY4zxYAmSMcYYY4wHS5CMMcYYYzwE3VVsbdu21fj4eH+HYYypgxUrVuxV1Xb+jqMurCwyJvhVVRYFXYIUHx/P8uXL/R2GMaYORCTV3zHUlZVFxgS/qsoia2IzxhhjjPFgCZIxxhhjjAdLkIwxxhhjPHi1D5KInAU8AYQCz6rqA5WsdxEwHxihqjVu1C8uLiY9PZ2CgoI6xWsgKiqKrl27Eh4e7u9QjDHGGL/xWoIkIqHAHOB0IB1YJiLvquo6j/WaAX8GltZ2X+np6TRr1oz4+HhEpC5hN2qqSmZmJunp6XTv3t3f4RiA5GSYORPS0iA2FmbPhsREf0dljKlv9r8ecLzZxHYCsElVt6hqEfAqMLmC9e4D/gnUuvqnoKCANm3aWHJURyJCmzZtrCYuUCQnw4wZkJoKqs7fGTOc5caYhsP+1wOSN5vYugDbyj1OB0aWX0FEhgLdVHWhiNxc2YZEZAYwAyA2Nraydeoar8HeR18rdSlrtmexInU/2QXF5BWVUlTiAkAW/EjkiKlEFxfSrDCX7vu203tvGp1mzkTszNKYhmPmTMjLO3JZXp6z3P7X/cabCVJFv7R66EmREOAx4MpjbUhVk4AkgISEBD3G6sb4zjGqxSt7eseBfB77ZCOfrN/NgbziQ+s3CQ8lPNT519H4kRT2iKAo7Mj+YF0P7OYvK9K5YGgXQkMsoTUm6KWl1Wy58QlvJkjpQLdyj7sCO8o9bgYMAL5011p0BN4VkfNq01E7WEycOJGXX36Zli1bVrrOrFmzOOmkk5gwYUKNt//ll1/y8MMPs3DhwrqEaaqjrFq87MyvrFocIDGx4qf/WMoXe7aweN8mVGHSoE6c3Lsdo3u0oU3TyCMTnvh4SE2lREI40KQZm1t3ZWO7OF5PmMTN81eT9PVmHrxwEENjW/n0sI0JKA2h705srFNAVLS8uhrC+xBoVNUrN5zkawvQHYgAVgP9q1j/SyDhWNsdPny4elq3bt1RywKNy+XS0tJSr+/niy++0EmTJtVpG8HwfgaEuDhVp8fAkbe4OPfTLg2NydeIzvs0ZlCqtrtgmXa78UONu3WhXvPSct22L7fq7c+bpxodfeS2o6PV9dI8ff+nHXri/Z/pgLs/0nU7srx+qPUNWK5eKnt8dauoLDI+Vsn/iM6bV+fNxsWpijh/a7y5mm6grsdRjdfX+Zi8xc+BVVUWebUAASYCG4HNwEz3snuB8ypY13cJkpc+kEceeUT79++v/fv318cee0y3bt2qffr00WuvvVaHDBmiKSkpGhcXpxkZGaqqeu+99+rxxx+vEyZM0EsvvVQfeughVVWdPn26zp8/X1VV4+LidNasWTp06FAdMGCArl+/XlVVly5dqqNHj9YhQ4bo6NGjdcOGDapqCZJPiRxRIBWEhum7fcbp387+s577r2+0200faNytCw/dulz7qbY+fY1Gdc2s/j6q+K5u25erI2d/qiP+/ommZR4j2QowliCZenGMk5TaqHPOVW4DLtD9UTG6NravfjjnNf3v15v1gQ/X6zNfbtL5y7fphp0HD/+L49K40G06j8tq/rt0jPfBS3lk3QVAYFWVRV4dB0lVPwA+8Fg2q5J1T/FmLIcco1mktlasWMELL7zA0qVLUVVGjhzJySefzC+//MILL7zA008/fcT6y5cv54033mDlypWUlJQwbNgwhg8fXuG227Zty48//sjTTz/Nww8/zLPPPkufPn34+uuvCQsL49NPP+WOO+7gjTfeqHX8phbc1eJZkU15evTFzB84gX3RLWhdkE3fqDBCtsSRmRpNaVYTirOiKcmMAYS4uBrsIzGx0u9l11bR/O93JzD1me+44rmlLLj2RNrGRNbLoRkTFOrQd6eguJQNu7LZuDubTXty2JtdyIH8Yj7/uoSYc0JoWhKCutwXeqsw831YAujhrrSogksVl0JJqYviUqXwu73kXPwAOZHR7I1uSX5ElDsmIG09oSFCqevwNopS27Ffj0NpQ2ppV2ZEJ0NNW8cqON61HXqwpMNgNry2ije/yqHZBSE0zY2geH8MWUt6kpcX5v8+4AHeOT3oJqutMy99IIsXL+aCCy6gadOmAEyZMoVvvvmGuLg4Ro0aVeH6kydPpkmTJgCce+65lW57ypQpAAwfPpw333wTgKysLKZPn86vv/6KiFBcXFzp642XzJ7N5lvu5vcT/0Zqq06c8ev3TFv/BWPvvJ6Qy0eR3MTJvfPLfd2io52uAfWld4dmPH/lCBKf/Z7zHv6BHfNGkbYl3LogmMahhn13Nu3J4f2fdrJk815Wph2gqNS5YjQiLIR2MZG0ahpOQWEYElFCSBMXEuoCARGlWIVfdjvbKespKAIhIogI4aFCWIgQkZ9Hl8I8mhXm0Sr/IJ0PZtA5ey/dsnbTbfPPtGgSTm5RKRnZhYy/YiehPVLoMG0peRs7kPnRIPLyImr+c+R+H4pDQlnYZxwvDj+HVZ37ANBh817ys5ohIUpY6zya9NpNZNd9ZCwYQVqanwcEDvDO6Y0vQfLSB+LU1B2tLGGq7voViYx0agVCQ0MpKSkB4K677mL8+PG89dZbpKSkcMopp9QsYFNnXyaczp+mtyA8L4eXX53JyJDsI7KSsgLO2/0mh8e14uIuw3lx83IKR6xAU0aQmhrqVIx+u5jEDy5v9B03jzWqv4hcA1wHlAI5wAz1GNTWBKDZs49sEYCjzkKKSly8vXI7ryxLY2XaAUSgf+fmXDkmnmGxrTi+YzNiW0cfukAi/pGKc664OPj02WrE9M/EyjcQHQFATGQYMZFhpC3qiYZ0p/nwFFqO20inq74m84PBpKW2q8m7ALNnk3rzXfz59OtZ3fl4jsvcxt1fvcC510yh7fTLyq73cN6e3jtpe+4qOlz2HRFLTgCiarav+lQfndO9qPHNxVbZG1/HD+Skk07i7bffJi8vj9zcXN566y3GjRtX6fpjx47lvffeo6CggJycHN5///0a7S8rK4suXboAMHfu3LqEbmph1bYD/P5/y+naoQXv3n0eI9PWQErKUclHYqKz2OWq8Ol6878H2pP5wSCi4jJpP2UFoTEFTsXoM7GNfvC5cqP6nw30A6aJSD+P1V5W1YGqOgRn4NpHfRymqY3EREhKcpIPEedvUhIkJuJyKe+s2s6ER7/iljd+IqeghDsm9mHpHaex8E/juGNiX84a0JHubZsecfXo7NlOjlVejWp+a7CB2FigNJSDP/Rg5//G4CoMp8MlPxB7zgZK3LVb1fFGn5OZeNWTbG3bjSff/SefffIAV11/AW2nX3ZUSHkbO7FnwQjCW+bRddqKGp2s17s6v9ne1fgSJC99IMOGDePKK6/khBNOYOTIkVx99dW0alX55dcjRozgvPPOY/DgwUyZMoWEhARatGhR7f3dcsst3H777YwZM4bS0tI6xW5qZn9uEdcl/0j7ZlG88vuRdG0VfewXeVlaGuSu60rmRwOIis2k8++/pPkJm0kL6XTkimXNyY3LMUf1V9WD5R42pdyYbSbAVXAWsjkjhyn/XsINr66iaWQYL1w5go9vPIkZJ/WgfbOqa0yqyLmqH081N1D+56g4ozm7XhxL/tpu0G8zlz+3lD3ZVc9qUFzq4q631/LX+avpH9eGj2adw3nrvkI8zsY8Q+pAW6Z070d6/gG++GVPNQ/MC+r8ZnuX+DV7rIWEhARdvvzIYZLWr19P3759q7+RABkvIicnh5iYGPLy8jjppJNISkpi2LBhPo/DU43fz0ak1KVcNXcZ32/OZMG1oxnUtfLxrHypfBV6WIs8Wp32M9G99kBBCFM3LuKcDd9wYupqwl2lTkHkqv7ZqTeIyApVTfDRvi4CzlLVq92PrwBGqur1HutdB9yEMyzJqar6a1XbragsMv7lcikvfpfCAx9uoElEKLPO6cf5Q7oQEsADqlb0cxTZJ507315DVHgot5/dh6nDux11DPtyi/hj8gq+37KPP5x0HLec1adGA8cWl7o49ZEvaRUdwTvXjWm0syhUVRY1vj5IUOWVQb40Y8YM1q1bR0FBAdOnTw+I5Mi4VZJE//vLTXy9MYO/nz8gYJIjOLIrRklWNBlvjqBFXDrj+7/Fh8ePYf6g02lekMOEX5dyzr5fOHleMqF3+v8kwUeqHNX/0ALVOcAcEbkMuBOYftSGqjHtkfGP7IJibnxtNZ+u383449vx4IWDaN/cj/1rqqnin6OuDOnWgjveXMutb6zh9eXpXJzQlf6dWxAZFkLy0jQWrEinqNTFY5cM5oKhXWu83/DQEK4f35Nb31jDl79kML5P+3o5noakcSZIAeLll1/2dwimIpUMBbE2P5THtzTnnEGdSBwZWD+OFXYIn5hC4ou3UbComK+7D2NR79F82msUb0adRuy3u/hNuyFcunMPMfU01EUAO9ao/p5eBf5d0RNq0x4FpM0ZOcz433JSMvOYdU4/rhoTH/Q1Ij3bN+O1P4xiwYp0HvzoF259Y82h58JDhUkDO3HNKT3o07F5rfcxZVhX/vX5Jh7/dCOnHN8u6N+z+mYJkjGeKhgKorCwiL8uP0irbm35+/kDArIgOfpMdCyMSSJq5kzO2PwDZxTvonhaAov+8xxz40bx99N+z/MjJjN70RzGb1kRMGOPeMEyoJeIdAe2A5cCl5VfQUR6lWtSmwRU2bxmAscXv+zhzy+vJCIshOSrRzLquDb+DqneiAhTE7px4bCupO3LY+2OLDJzijh7YMdj9qWqjrJapNveXMM7q3Zw/tAu9RB1w9H4OmkbcywVDPnwxJjL+KVlFx68cCAt3ZfqBgWPDqzhlydyzrdvsyD5VhbM+xtNi/K5auo93DTpJnJ3+rGzphepaglwPbAIWA+8rqo/i8i9InKee7XrReRnEVmF0w/pqOY1E1hUlWe/2cLv5i6jW+to3v3T2AaVHJUXEiLEt23KOYM6M/3E+HpJjspcOLwrQ2Nb8tf5q3lvdRUVq8nJTmfHkBDnbyO4GtZqkIzx5DE2x/IufXlm5IVcvGUJp/aZ5MfA6on7+BK2r2fh3BuYM/oS5oy+mI2de/J8dkG9Fr6B4lij+qvqDT4PytTIEd0C40sZ/oefWbF/G2f278BjlwwhOsJ+zmojPDSEl343kt++sIwbXl1JbmEJ5w/tQlR46OGVvDQDRXlZ+cU8+80Wvt6YQe8OzRjcrSXj+7SnS8sm9bL92micV7GZKjX697NcYZAR3ZJJVz5Bk9Ji3jsxiua/aQBNUJ6FHfBF3zFcd/5ttGoezYu/HUHP9s28GoIvr2LzFruKzXfKf2VDYwpod8EKIjsf4JR2PXn+xt4BfZVasMgrKuHqF5ezZHMmoSFCj3ZN6dYqmujIMJq+OZ+WGTtok3eQjtl7GbltDe1zDziX5aek1Gm/pS7lma8288xXm8kuKGFobEtSM/PYl1tEdEQo900ewIXDa94JvbrsKrYgFBMTQ05ODjt27ODPf/4zCxYsqHTdxx9/nBkzZhDtOb5TFb788ksefvhhFi5cWB/hNizuM6KSO+/iT6N/z8EmzXixTwHNfzPNz4HVkwp6dI+feS2vnTyOq+YuY8rTS3jmiuGc2KOtf+M0xq2sW2Bkl320O/9HJKKEPW8N48vCToT81d/RNQzREWG8cNUIPl+/h593HGT9zoPsOlhAflEpOR36cCDuBIrCDk9N0nf3Fi5e8ylXqta6T2ZJqYub56/m7VU7mNC3Azed3pt+nZujqmzOyOWOt9bw1/mrWbxpL/dO7k+zKN9OjWI1SD5UWlpKaGjosVfkcIJUHfHx8Sxfvpy2bav/g1ZVghQs76e33f/Bev7z9RYemTrYq2cwgWTbvjx+O3cZKZm53D9lEBd56bitBsnUREgINB2YRusz1lKS1YSMtxIo3tssEIb08r5AGLcvPh5NTSU7IpqU1p1ZHDeET3uN5McufTl7QEcemjqYmMia1bcUlbi44dWVfLh2F38783iuG9/zqHVKXcpTn2/iic820qVVEx6/ZCjD4yofgLk2qiqLGmUnbW/0NUtJSaFPnz5Mnz6dQYMGcdFFF5GXl0d8fDz33nsvY8eOZf78+WzevJmzzjqL4cOHM27cODZs2ADA1q1bGT16NCNGjOCuu+46YrsDBgwAnATr5ptvZuDAgQwaNIh//etfPPnkk+zYsYPx48czfvx4AD7++GNGjx7NsGHDmDp16qFE66OPPqJPnz6MHTv20KS3pmLPLd7Kf77eQuLI2EaTHAF0ax3NgmtP5ITurbl5/mpmvrWG/blF/g7LNGKuecnEnraUNmevoSCtDbv+N5bivU4TcIMfiqqsbdHf0wXNno1ER9O8KI9Buzbxx6ULeOPNu5nZMZ+P1+3m/Dnfsm1f3rG341ZS6uL6l3/kw7W7uHNS3wqTI4DQEOGGCb14/Q+j0ewcLp7zDY+cdAUHe/U59B54te+4qgbVbfjw4epp3bp1Ry2rzLx5qtHRqs63zblFRzvL62Lr1q0K6OLFi1VV9aqrrtKHHnpI4+Li9MEHHzy03qmnnqobN25UVdXvv/9ex48fr6qq5557rr744ouqqvrUU09p06ZND223f//+qqr69NNP65QpU7S4uFhVVTMzM1VVNS4uTjMyMlRVNSMjQ8eNG6c5OTmqqvrAAw/oPffco/n5+dq1a1fduHGjulwunTp1qk6aNKnCY6nJ+9kQJX+fqnG3LtRrXlquxSWl/g7HLwqLS/Xe937W4259Twf95TV9fvh5eqBnn0P/KPPmqcbFqYo4f2v6/wMs1wAoT+pyq6gsMvVs3jx96NSrNO7WhdrutJWKlB4ut8nRedd+4+8IvSsu7sgfq7JbXJzvY6nkn/7bTRk68O6P9Jwnv9GC4pJjbqa01KU3vrZS425dqC8s3lLtfWe1bKM3TrpJ425dqP3+8rrefdZ1+uB1X2p0TGmdfs+rKov8XsjU9FbXBMlb37etW7dqt27dDj3+7LPPdPLkyRoXF6cpKSmqqpqdna1RUVE6ePDgQ7c+ffqoqmrr1q21qKhIVVWzsrIqTJCmTJmiH3/8cQXHdDhBeu+997RNmzaHtt+3b1/97W9/qytXrtRx48Ydes0777xjCVIFFizfpvG3LdQrn1+qhcWNMzk6ZN483dD1eJ12yWyNu3WhHve3d/TixAf1qhs+0VZD0jWyS6aGRBXWe6EULDdLkLzvtVMu0bhbF+qtZ/1JX2KaxrFVhVKNY6vOY5p/EgVfEqn4B0vE35Ed4aO1OzXu1oV6z7s/V7mey+XSu99Zq3G3LtQnP91Y/R2U++H+qUMPvXHSTdrz5rc07taF2u2mD7TDZd9qkx67avV7XlVZ1Og6aVcwxE2Vy2vCs6Na2eOmTZsC4HK5aNmyJatWrarW6z2pHrsznKpy+umn88orrxyxfNWqVQE5uGEgeeHbrdzz3jrG9GzDvy8fTkRYo2yBPmzmTI5PTyX5tZms6tSbz3qewKc9R7I0qpDmZ66iOZD1Q3cOfNHv0By4DXOcSeMPSzbv5Y6EaYxNWcl9Hz9NOKVczpHlGmkNvEzzGHLkiOUB5Mz+HbnyxHie/3YrJ/Zow4R+HY5ax+VS/vHBeuYuSeF3Y7tz/akVN6tVqNwP9MDdm3n0/Ue5/Yvn6R63hohOB4novB9CtKLV66TR/QJU9r2qj+9bWloa3333HQCvvPIKY8eOPeL55s2b0717d+bPnw84yczq1asBGDNmDK+++ioAyZU0op5xxhk888wzlJSUALBv3z4AmjVrRnZ2NgCjRo3i22+/ZdOmTQDk5eWxceNG+vTpw9atW9m8efOh+IxDVXn0k43c8946zujXgeemjzhyDJDGyl3KCDB050Zu/mYeH73wJ9IePoPt/z2Z3fNHkLu2q+fqxtRZqUu54801xObu5em37ncmWa5IgCUK9W72bPC8Ojk62lkeYG6f2If+nZvz1/mrmZ2074h+QS++5OKm11fx7OKtTB8dx8yJfWt2wl7B59wu7wBtN8L+z/uxe94Y8n/tWNXqtdLoEiRvft/69u3Liy++yKBBg9i3bx/XXnvtUeskJyfz3HPPMXjwYPr3788777wDwBNPPMGcOXMYMWIEWVlZFW7/6quvJjY2lkGDBjF48OBDc7nNmDGDs88+m/Hjx9OuXTvmzp3LtGnTGDRoEKNGjWLDhg1ERUWRlJTEpEmTGDt2LHFxcXU/4CB2uGOf0n3Kep787FemDu/K04nDLDkqU0kpE8tuSvbFULClPcUZzY+1ujE19sm6XaRk5vHXAc1oXlk7R4AmCvUqMRGSkpzxhkScv0lJAVlVGxkWyr8ThxNWGkHSr9+T2SoVQkvZE7ab2xct5e1VO/jbmcfzf+f1r/m4VZX8cM+ekeLd/LGytrdAvdW1D5Jq3TuYVqR8X6Fg19D7IB3uqO/S1mf85HQAPXOtvvSSy9+hBZZKrmiYd+03db7QAeuDZCrhcrl08lOLddyDn2tJqetwgQ2qoaGHO5nUR8Ft6l1czyJtd9FSjbt1ocb+9QOnn9ANH2ncKWl123AlP9zevGCk0fVBgoom9TSNiTPonNJm4k/EDEwn67seHPj6eO7cIFx+ub+jCyAVDCjJ7NkkJo6FMf4fmsU0TMtS9rNq2wHum9yf0BCxAjvIpG0ORzeNoNmIrYS1yCN/UwcK0togWscGq0q+B978eng1QRKRs4AngFDgWVV9wOP5a4DrgFIgB5ihquu8GZO3xMfHs3btWn+HYaohLQ1anryBmIHpHFjci6xvex9abjz4oVAyjVvS15tp3TSCi4Z383cophacfuVC9rLjjlwehL06vNYHSURCgTnA2UA/YJqI9PNY7WVVHaiqQ4B/Ao/Wdn9OTZmpq8bwPsaelkKLUVvI/jGOrG97HV4ekt4oZqg2JlBt2pPDp+v3cMWoOJpEWF/AYBRE/cqPyZudtE8ANqnqFlUtAl4FJpdfQVUPlnvYFKjVr3NUVBSZmZmN4sfdm1SVzMxMoqIa3mzuZT5auwsZ/jOFWzqw79P+ONdoQTS5zC69xT+j1BpjAHhn1XZCQ4QrRgdhdYMBgqpf+TF5s4mtC7Ct3ON0YKTnSiJyHXATEAGcWpsdde3alfT0dDIyMmrzclNOVFQUXbs2zKk1fkzbzw2vrmRwt5ZM7j+Ue97cTlppZ2JJYzZ3kMgrkIcN6GOMn3y2fg/D41rRNibS36GYOmgoTfDeTJAquo7vqCoeVZ0DzBGRy4A7gelHbUhkBjADILaCa4nDw8Pp3r17XeM1DVhqZi5Xv7icDs2jeHZ6Am1jQrlqeiwVVlpaZyRjfG5nVj7rdh7k9rP7+DsU4w2BMOluDXmziS0dKN/Lriuwo4r1XwXOr+gJVU1S1QRVTWjXrl09hmgag90HC7jqhWW4VJl71YjDZ6feHDXUGFMjn2/YA8Bpfdv7ORJT7wJl0t0a8maCtAzoJSLdRSQCuBR4t/wKItKr3MNJwK9ejMc0dBVM6/zVxgwmPvENO7MK+O9vEjiuXczh9RtSb0Jjgtzn6/cQ2zqaHuX/R03D4IytcuSysvmJApjXmthUtURErgcW4Vzm/7yq/iwi9+IMzPQucL2ITACKgf1U0LxmTLWUnaHk5aHA+rwQXn9pCXPXtOT4Ds2YkziUnu2bHfmaSsb5CfRqX2MamvyiUhZv2su0E2JtzsiGyJuToHqRV8dBUtUPgA88ls0qd/8Gb+7fBLd9uUWk788jr6iUguJSnLGvFVfZX5dSVOoiv6iUvBc/YfeIi9nVrC2rOvcmtVVnRF1M27yYWff+vfJLhhtKb8JGRkRCgBiPK2FNkFqyeS+FJS5rXmuogmTSXU+NciRtE5iO6MM3cjcR41dSVNkklZ6GTSWipJiO2XvpmbmNa79fwIRNS2mbfxDm3+/dwI1PiMjLwDU4A8uuAFqIyKOq+pB/IzN19dmGPTSNCOWE7q39HYrxhtmzD9XwHxIE3RksQTIBoVwLGTFDUtFxa8nd1ZyrRvRm4umhRIaHEhoiCBAiQkiI8zciLISo8FCiT0ig5a/rjr50spFPytvA9FPVgyKSiFMzfStOomQJUhBTVT5fv4dxvdoRGWaDQzZIQdqd4ZgJkoiMAVapaq6IXA4MA55Q1Qrqy4ypnbI+fDGD02hz5lryNrVn77tDmfd5GH+/thobuPuOoDxDMTUSLiLhOFe7PqWqxSJio8MGudXpWew6WGDNaw1dEHZnqM5VbP8G8kRkMHALkAr8z6tRmUanrK9eVPcMig80IePN4WhxWPX78DWk4VtNZf4DpOCMuv+1iMQB1gcpyL3/0w7CQ4Uz+nX0dyjGHKE6CVKJOnN4TMapOXoCaHaM1xhTI2V99UJjCig5EA3umZ9r1IcvMRFSUsDlcv5actSgqOqTqtpFVSeqIxUY7++4TO2pKh+s2cW4Xu1oER3u73CMOUJ1Eji9HRAAACAASURBVKRsEbkduAJ43z0JrX2TTb0qG5IoLKaQ0hxnLjhrITPliUgHEXlORD50P+6HDQ0S1FZtO8D2A/lMHNjJ36EYc5TqJEiXAIXAb1V1F84ca9Yp0tSrxET4z3+UsJgCSnOirIXMVGQuzrhqnd2PNwJ/8Vs0ps7e/2kn4aHC6f06+DsUY45yzATJnRS9AZTNHrgXeMubQZnG6ezziyBUeWx2pLWQmYq0VdXXARc4g9HiXPJvgpDTvLaTk3q1o0UTa5QwgeeYCZKI/B5YgNNBEpwapLe9GZRpnHYfLASgQ/MoP0diAlSuiLTBPcOwiIwCsqrzQhE5S0R+EZFNInJbBc/fJCLrROQnEfnM3QHceNHKbQfYkVXApEHWvGYCU3Wa2K4DxuC+WkRVfwXsekxT73ZnFwDQ3hIkU7GbcOZz7CEi3+JcTfunY73I3W9yDnA20A+Y5u6/VN5KIEFVB+GcEP6zPgM3R3tv9Q4iQkOYYM1rJkBVZ6DIQlUtKpsfR0TCcJ/BGVOfdmc5CVKH5pHHWNM0Rqr6o4icDBwPCPCLqhZX46UnAJtUdQuAiLyKc1XuunLb/qLc+t8Dl9db4OYomzNySF6axsSBHWkeZc1rJjBVJ0H6SkTuAJqIyOnAH4H3vBuWaYzKmtjaN7MaJHM0EfmNx6JhIoKqHmtcti7AtnKP04GRVaz/O+DDWoRoqsHlUm5/Yw1RYSHcMamvv8MxplLVSZBuwykw1gB/wBni/1lvBmUap93ZBbRpGkFEWHVafk0jNKLc/SjgNOBHjj1wbUXTw1dYC+6eLSABOLmS52cAMwBiA3yizUD1yrI0fkjZxz8vHGQnQyagHTNBUlUX8F/3zRiv2Z1VYP2PTKVU9Yj+RiLSAnipGi9NB7qVe9wV2OG5kohMAGYCJ6tqYSUxJAFJAAkJCdbVoCaSk9l6/+M8cPrfOPFAOlN/OQAj7FJVE7iqMxfbVio421LV47wSkWm0dmcX0NH6H5nqywN6VWO9ZUAvEekObAcuBS4rv4KIDMW5UvcsVd1T34E2dq55ybw45y3+ecZthLtKuP/th5DXDzp1ezaehwlQ1WliSyh3PwqYCrT2TjimMdt9sJABnVv4OwwToETkPQ6frIXgXJH2+rFep6olInI9ziCTocDzqvqziNwLLFfVd3EGv40B5rsvSElT1fO8cBiNisulfPVrBv/6ch8/nnwVp2xezj8WPUXn7L3OCjNnWoJkAlZ1mtgyPRY9LiKLgVneCck0RiWlLvbmFFoTm6nKw+XulwCpqppenReq6gc4/SfLL5tV7v6EeonQAE5i9M7q7cz5YjOb9uTQIbIFD73/GBet/ezIDmHVno3aGN+rThPbsHIPQ3BqlGyyWlOvMnIKUbVL/E3lVPUrf8dgjpac7FQEpaU5k0v/YeZ+lhatY9W2A/Tt1JzHLhnMpAtPJmLrlqNfbB3dTQCrThPbI+XulwApwMVeicY0WmWX+He0GiTjQUSyqfiqMwFUVZv7OKTGyTMTmj2bZBKZMQPy8iCsVS65g3/hP5t30iwskkemDuaCoV0ICRG4714OrVjGZqM2Aa46TWzjfRGIadx2HywbJNISJHMkVbUa6xqqIJepW1ef5OQjE5zUVJgxg5ktJ6JdCmnTczdN+29HS0M4sKQn7OjBhX8v9/NStvN6DcoY76o0QRKRm6p6oao+Wv/hmMaqLEFqb01s5hhEpD3OBSMAqKp1ZCnHM5fZnpXLX55L553tRfTo6UwSW5XyTyuKS0Hf3UDJqX+kODSM/PBI9jVpwd6mLdDmS2gv4CoKJWd1LAeW9MSVG8XBikaeSky0hMgElapqkOp81iYiZwFP4Fw58qyqPuDx/E3A1ThNdxnAb1U1ta77NcFn98ECQkOEtk0tQTIVE5HzcJr8OwN7gDhgPdDfn3EFmpkz3U1ebbJpdcoGmvTYAyr8sCOcrcWCAFJRAlOOlOtKHSIgrY8jvEUJEaXFRJYU0Sr/IMftS2f7/gHsSu1J4c6W4Do8wKt1LTINQaUJkqreU5cNl5sg8nScgdqWici7qrqu3GplE0Tmici1OBNEXlKX/ZrgtPtgIe2bRTr9FYyp2H3AKOBTVR0qIuOBaX6OKeCUXRjW6pQNRHXbR9aSXuSsisWVG0WKq5YbjY93mtU8JLQpZkb+k1Buu9a1yDQUx5zTQUSiROQ6EXlaRJ4vu1Vj24cmiFTVIqBsgshDVPULVS3rtfc9zgi3phHafdBG0TbHVOwediRERELcE8wO8XdQgaas9iY0poCCba3JWtyb0pyoutXqzJ7tZD7lRUeT+MRIkpIgLs6plYqLg6Qka0kzDUN1Jr16CegInAl8hZPEZFfjdRVNENmlivVtgshGbPfBAjo0s+Y1U6UDIhIDfA0ki8gTOM3zppyyXCa0aRGuvAigHmp1EhOpLBNKTISUFHC5nL+WHJmGojoJUk9VvQvIVdUXgUnAwGq8rjYTRD5UyfMzRGS5iCzPyMioxq5NsNl9sJCOLawGyVRpMs70IjcCHwGbgXP9GlEASkyE//xHCYsupDQvsv5qdSwTMo1MdRKkYvffAyIyAGgBxFfjdTWdIPK8qiaIVNUEVU1o165dNXZtgklBcSlZ+cV2ib85lhlAZ1UtUdUXVfXJCkb6N8C5F5ZAqPLQfRGWyxhTS9VJkJJEpBVwF/AusA54sBqvOzRBpIhE4EwQ+W75FcpNEHmeTRDZeB26xN+a2EzVmgOLROQbd7/IDv4OKFBl5jjnmm1j7H/KmNqqzkjaL6hqKU7/o+Oqu2GbINJUV9ko2laDZKrivrL2HhH5//buPLyq6lz8+PdNSAgkjAGlDEnwSguCYQqWIVLR4nVArV6oYrTgowbx9udU61Wp9oryu+3vKnWoto1a4ZE4Y6/joxSFFqwiYZBKBC9KgAhBkkAgZE7e3x97Bw+HJJzkzDnv53nOk7P32Xufd2eHl7XXWnutTJynXf8mIsU2j9qJyo/WAdA3OTHMkRgTvXwpIO0UkfeAl4EP9WSjjHmwCSKNL0rcGiTrg2R89C1QApQBp4Q5lohUWukUkFJTrIBkTEf50sT2A2Al8O9AkYj8XkSygxuWiSX7K2yaEXNyIjJfRFYDHwD9gBtVNTO8UUWmsqPWxGaMv3yZi60aeAV4xe2L9BhOc1t8kGMzMaLkcA3dEuLpmeRLhaaJYenAbaq6OdyBRLoytwapT3erQTKmo3z6H0lEfoTT5n8hTufrnwYzKBNbSg7XMKBXEnKy+Q9MTFPVu8MdQ7Qoq6ylV7cEErv40khgjGnJSQtIIrIT2IxTi/RLVT0a9KhMTNlfUcOpNkmtMQFTerTO+h8Z4ydfapBGq+rhoEdiYlbJ4Rqy0vuEOwxjOo2yylpS7Qk2Y/xy0vpXKxyZYGpqUmeaEXuCzZiAKausIzXZamWN8Yc1UJuwKq+qo75RGWBPsJlWiMj1IvJLj+VvROSwiBwRkfnhjC1SlVsTmzF+swKSCasS9xF/KyCZNtwE/Nlj+VtV7Qn0B2aHJ6TI1diklFfVkWqP+Bvjl1b7IInIHW3tqKqLAx+OiTXN04xYE5tpQ5zXnGuvAqhqjYh0C1NMEetgVR2q0M9qkIzxS1s1SD08Xnd6LfcIfmgmFhwbRdtqkEzrenkuqOr/BRCROCA1LBFFsOYxkKwPkjH+abUGyZ33CAAR+YnnsjGBsr+iBhHobxPVmtatEJGHVPVXXusXAivCEVAka56o1vogGeMfX4cu9nn+NWPao+RwDf1SupIQb93hTKt+CTwjIjuAz9x1o4EC4MawRRWhSo821yBZAckYf9jcDiasSg7X8j3rf2Ta4A5OO1tETgNGuqsLVfWrMIYVsb6rQbJaWWP80VYn7X/yXc3R6SKypfkjQG2SSBMI+ytqSEvtHu4wTHSYpqrPNi+ISDzwK2v+P15ZZR1xAr27JYQ7FGOiWls1SDNCFoWJWSWHazhraN9wh2Giw3ki8m/A9Tids5/DmTjbeCg7Wkff5K7Exdnchsb4o62OHwnAYFXd5fkC0rCmORMANfWNVFTXM8Ca2IwPVPVqYCnwT+Bd4DZVvdOXfUXkAhHZLiI7ROSESW9FZKqIbBSRBhGZGdjIQ6usstYe8TcmANoqID0KHGlhfbX7mTF+aR4k8lR7xN/4QESGAbcCy4Ei4FoROWn7rNsU9yRwIXAGTn+mM7w22w3MBV4IYMhhUWajaBsTEG0VkDJUdYv3SlUtADKCFpGJGTYGkmmnt4D7VHUe8CPgf4H1Pux3FrBDVb9W1TrgJeAyzw1UtcjNd00Bjjnkyipr6WtjIBnjt7aaytr6X8tGrzV+ax5Fe0AvS+bGJ2c1T56tqgo8IiJv+rDfIGCPx3Ix8MMgxBcRnIlqrQbJGH+1VYO0XkROGGNERK4HNgQvJBMrrInN+EJE7gJQ1cMiMsvr4+t8OUQL6zo0tpuI5IpIgYgUHDhwoCOHCKqa+kaO1DZYHyRjAqCtAtJtwHUislpEHnFffwNuwOkHYIxfSg7XkJwYT48kexzZtOkqj/f3eH12gQ/7FwNDPJYHA3s7Eoiq5qlqlqpm9e/fvyOHCKry5kEibQwkY/zWagFJVfer6mTgAZwOkUXAA6o6SVVLQhOeCZv8fMjIgLg452d+fsC/Yv/hGpuk1vhCWnnf0nJL1gPDRGSoiCTiFLh8aZqLOt/Nw2Y1SMb466TzO6jqKlV9wn192J6Dx9KjtZ1Kfj7k5sKuXeTrVWTsWk3cNbPJiN9D/s1rA/Y1+ypqrIO28YW28r6l5RN3Vm0Afg68D3wBvKKqW0VkoYhcCiAiE0SkGJgF/ElEtgYm9NAqPWqjaBsTKEEbz8jj0drpOFXc60XkTVUt9Nis+dFan8YyMSGyYAFUVZHPbHJ5miqSAdjVNITcP/QF1pIzZZez3e7dkJYGixZBTo7PX1FT30jxwWrOPr1fkE7CdCKjReQwTm1RN/c97rJPJWxVfRdn7CTPdfd7vF+P0/QW1cqtBsmYgAnmgI/HHq0FEJHmR2uPFZBUtcj9LOofre1MjpQcYP1pWSxIu4Vu3XbQzW3EaKrtQlN1IgvWpdBvzdP0r0+if4/+9P9mH0m5uc5GPhSS9h6q5qZlGzhwpJZzhp8SxDMxnYGqxoc7hmhRdqwGyQpIxvgrmAWkgD1aKyK5QC5AWlqa/5GZFtU2NLLwrUJeuuVFGuPi0YZykqq6gjolpLikeuK6NgAwj18et2+P2qP0/riaPgfX0qtbAj2SupCc2IXuifEkJcbTtUs8qkp9o/JqwR5qG5rIu3Y8548cEPLzNKazKqusI7FLHCldbbIDY/wVzH9FAXu0VlXzgDyArKysDh3DtO3bIzXMX7aRDbsOktOvgYuffYirv36JbxpOO37DuCbSu3/F28kX8m1yH0qT+3AguTelyb051K0nB8eP4FBVPSUVNRypaaC6vpHq+kbqGpqIE4iPE04/pQdPzB7L6aekhOdkjemkSivr6JeciIjNw2aMv4JZQArYo7UmuPaUV/HTP33Moap6fn/1WGZkDoRB1Sya9xtyG353rA8SQPemahbpfzNq/1cnHig9Hd56uMXvUFVL2sYEWdnRWuug3cnU19dTXFxMTU1NuEOJaklJSQwePJiEBN+HlQlmAenYo7XANziP1l4dxO8zHdDYpNzxymYqaxp4bf4kRg7s5XyQk0NOTg7cvJYFeRnsbhxIWvxeFuUWkTPlR5CbD1VV3x2oe3eno3YrrHBkTPCVVdo8bJ1NcXExPXr0ICMjw/JoB6kqZWVlFBcXM3ToUJ/3O+lj/n4EFDOP1kazZ9Z8zfqigzxw2cjvCkcecp7KpqhhME0aR1HDYHKeynY6YuflOTVGIs7PvLx2PcVmjAm8sspaUm0etk6lpqaG1NRUKxz5QURITU1tdy1cUHvyxcqjtdHqi32HeWTFl1w4agCXjx3Uvp1zcqxAZEwEUVVKj9bZNCOdkBWO/NeR32HQapBMZKupb+T2lzfTs1sCiy4/0/4BGhPljtY5D0NYE5sJh4suuohDhw61uc3999/PypUrO3T81atXM2PGjA7t21H2LGiMeuidQraVHOG56ybQ1waVMybqlVU6YyD1tSY2E0Kqiqry7rvvnnTbhQsXhiCiwLEapBj0zpZ9LPtkN/Omnsa0H9hAjcZ0BqXNo2hbDVJsC8I8mosXL2bUqFGMGjWKRx99lKKiIkaMGMHNN9/MuHHj2LNnDxkZGZSWlgLw4IMPMnz4cKZPn87s2bN5+GHn6ea5c+fy2muvAZCRkcGvf/1rxo0bx5lnnsm2bdsA+PTTT5k8eTJjx45l8uTJbN++3e/4O8oKSDFmV9lR7l6+hbFpvbnzX38Q7nCMMQHSXIPUz2qQYpfHPJqoOj9zc/0qJG3YsIHnnnuOdevW8cknn/D0009z8OBBtm/fzs9+9jM2bdpEenr6se0LCgpYvnw5mzZt4vXXX6egoKDVY/fr14+NGzcyf/78Y4Wo4cOH8/e//51NmzaxcOFC7r333g7H7i8rIEUpn28SPDZcOXkGVyz+EBF4/KqxJMTb5Temsyg7ajVIMc+dR/M4VVXO+g5au3Ytl19+OcnJyaSkpHDFFVewZs0a0tPTmThxYovbX3bZZXTr1o0ePXpwySWXtHrsK664AoDx48dTVFQEQEVFBbNmzWLUqFHcfvvtbN0avofb7X/IKOTzTUJ+PpqbyxdVwj3n38wNU+dzaskulg8pZ0jf7mGJ3RgTHN/1QbICUszavbt9632g2vLkFcnJyS2ub237lnTt6tR2xsfH09DgTGN13333MW3aND7//HPeeuutsA6QaZ20Q6yytoFNuw9SW99EbUMTTW38MbX2yYI/KaRDsgCizqQuoix4roma9CYqaxoorazl23eL2HDdnyhN6YNoE/PWLeeONc/T9YNBcP3sYJyeMSZMSivr6NG1C0kJNrdvzEpLc+6YW1rfQVOnTmXu3LncfffdqCp/+ctfeP7558nLy2tx++zsbObNm8c999xDQ0MD77zzDjfeeKPP31dRUcGgQc6wM0uWLOlw3IFgBaQQe/CtQl4u2HPyDdsyGfq3dvy3nZ+9uyfQr1tfJu/+jOyizZxdtInvHSlzPvTjbsIYE5nKjtoo2jFv0SKnOaEdsxyczLhx45g7dy5nnXUWADfccAN9+vRpdfsJEyZw6aWXMnr0aNLT08nKyqJXrxMHIW7NXXfdxZw5c1i8eDHnnntuh+MOBGlPdVgkyMrK0rY6fUWyhsYmJixayfj0Ptx63vdJ7BLHybsBnTg+0Y/Pg2/24lQxqYAKqjB4QDyfbY6jW0I8iV3czkkt3U2kp4Pb3mtMOIjIBlXNCncc/oi0XJTzzCfU1DexfP7kcIdiAuiLL75gxIgRvu+Qn+/0Odq926k5WrQo5IP6VlZWkpKSQlVVFVOnTiUvL49x48aFNIaWtPS7bCsXWQ1SCBXsOsjBqnquGDeYMwf7XqL2tujuVm4S7ode3Tw3DPzdhDEmMpVV1pFmfQtNBMxykJubS2FhITU1NcyZMyciCkcdYQWkEPpr4X4Su8Qx9futNZD5pvlv/6Q3CT5vaIyJdqWVdYxN6x3uMIzhhRdeCHcIAWEFpBBRVVYUljDlX1JJ6er/r93nm4QIuJswxgRXU5NSftQmqjUmkOwx/xDZVnKEPeXVnD9yQLhDMcZ0Moeq62lSGwPJmECyAlKIrNi6HxE4b4RN7WGMCazmMZBSU6wGyZhAsQJSiKwoLGFcWh9O6ZEU7lCMMZ1M8zxs/WyQSGMCxgpIIfDNoWq27j3M9DNODXcoxphOqOyo1SCZ6JCSkgLA3r17mTlzZpvbPvroo1R5T51yEqtXr2bGjBkdjs+TFZBC4K9bSwCsgGSMCYpym4fNhFFjY2O79xk4cCCvvfZam9t0pIAUSFZACoEVhfs5/ZQU/qV/SrhDMcZ0QqWVdYhAn+5WQIp1Pk9k7qOioiKGDx/OnDlzyMzMZObMmVRVVZGRkcHChQvJzs7m1Vdf5auvvuKCCy5g/PjxnH322Wzbtg2AnTt3MmnSJCZMmMB999133HFHjRoFOAWsO++8kzPPPJPMzEyeeOIJHn/8cfbu3cu0adOYNm0aACtWrGDSpEmMGzeOWbNmUVlZCcB7773H8OHDyc7O5vXXX/fvhD1YASnIDlXVsW5nOedb7ZExJkjKKmvp0z2R+LgTR943scPniczbafv27eTm5rJlyxZ69uzJU089BUBSUhJr167lqquuIjc3lyeeeIINGzbw8MMPc/PNNwNw6623Mn/+fNavX8+AAS0/xZ2Xl8fOnTvZtGkTW7ZsIScnh1tuuYWBAweyatUqVq1aRWlpKQ899BArV65k48aNZGVlsXjxYmpqarjxxht56623WLNmDSUlJf6drAcrIAXZqu3f0tik9ni/MSZoyirrSLUO2jFvwYLjJ04AZ3nBAv+OO2TIEKZMmQLANddcw9q1awG48sorAWdqkX/84x/MmjWLMWPGMG/ePPbt2wfARx99xOzZzuTo1157bYvHX7lyJTfddBNdujhjBPbt2/eEbT755BMKCwuZMmUKY8aMYenSpezatYtt27YxdOhQhg0bhohwzTXX+HeyHmygyCBbsXU/p/ToSuagjk8tYowxbSk7Wmv9j0yr85D7Oz+5iLS4nJycDEBTUxO9e/dm8+bNPu3vTVV92mb69Om8+OKLx63fvHnzSfftqKDWIInIBSKyXUR2iMjdLXzeVURedj9fJyIZwYwn1GrqG/nblweYfsapxFnVtzFh09lzUVllnT3BZkhLa996X+3evZuPP/4YgBdffJHs7OzjPu/ZsydDhw7l1VdfBZzCzGeffQbAlClTeOmllwDIb6Wt7/zzz+ePf/wjDQ0NAJSXlwPQo0cPjhw5AsDEiRP56KOP2LFjBwBVVVV8+eWXDB8+nJ07d/LVV18diy9QglZAEpF44EngQuAMYLaInOG12fXAQVU9Hfgd8NugBBPoXms+fs2iZ0qpqmu05jVjwihiclEQ81BpZa2NgWRYtMiZj9xTIOYnHzFiBEuXLiUzM5Py8nLmz59/wjb5+fk8++yzjB49mpEjR/LGG28A8Nhjj/Hkk08yYcIEKioqWjz+DTfcQFpaGpmZmYwePfrYXG65ublceOGFTJs2jf79+7NkyRJmz55NZmYmEydOZNu2bSQlJZGXl8fFF19MdnY26enp/p2sJ1UNyguYBLzvsXwPcI/XNu8Dk9z3XYBSQNo67vjx47Vdli1T7d5d1emzptVdEvVwr1Q9vHSZHq6uC9jrmaV1mtyrTiWxTuO61ml8crWeetkm/f4972ltfWP7YjamkwMKNEi5x/sVEbnIKw8pOMvLlnXgt/ednQcq9T/f/FzT/+NtfeKDL/06lolMhYWF7dp+2TLV9HRVEeenn39iunPnTh05cqR/B4kQLf0u28pFweyDNAjY47FcDPywtW1UtUFEKoBUNzkFhlevtf865zqWjr8ECoH/XBGwrwHod9OJ62p3DiSxi/WFNyaMwp+LWug9uyB7Lh9/VAv7Vp90d/V8r0qTQmOTsreimngRLhszkJwfBvDO2UQtm588cIJZQGqp0412YBtEJBfIBUhrb2OqV++0f/3yY4ZU7HcWHnmkfcdqwy9+4RG4ClofhzbGU1PUL2DfYYzpkPDnohZ6yaYf2sfhb7bB2WN9OoRngPFxggAZ/ZK5asIQTulpUxiZ4MjIyODzzz8PdxhhEcwCUjEwxGN5MLC3lW2KRaQL0Aso9z6QquYBeQBZWVknJK02paU5g0G4Ju/ewuTdWyA9Hc4+rV2HastD3x73NccEsjnUGNMh4c9FXnkIIPfTvzgJ4o3/5/NhjDGhE8y2n/XAMBEZKiKJwFXAm17bvAnMcd/PBD502wQDJ1i91sLzNcaY9gt/LrIEYfwQ6P8WY1FHfodBKyCpagPwc5zOj18Ar6jqVhFZKCKXups9C6SKyA7gDuCEx2/9lpMDeXnOnZqI8zMvL+CNtCH6GmNMO0VELrIEYTooKSmJsrIyKyT5QVUpKysjKal9TdESbb/0rKwsLSgoCHcYxhg/iMgGVc0Kdxz+sFxkQqG+vp7i4mJqamrCHUpUS0pKYvDgwSQkJBy3vq1cZCNpG2OMMREqISGBoUOHhjuMmGTPnxtjjDHGeLECkjHGGGOMFysgGWOMMcZ4ibpO2iJyAGhhxCGf9COQo3RHBjun6NAZzwk6fl7pqto/0MGEkh+5yP4WooedU/QIeC6KugKSP0SkINqfnPFm5xQdOuM5Qec9r2DqrL+zznhedk7RIxjnZU1sxhhjjDFerIBkjDHGGOMl1gpIeeEOIAjsnKJDZzwn6LznFUyd9XfWGc/Lzil6BPy8YqoPkjHGGGOML2KtBskYY4wx5qRiooAkIheIyHYR2SEigZ8QNwREZIiIrBKRL0Rkq4jc6q7vKyJ/FZH/dX/2CXes7SUi8SKySUTedpeHisg695xedmdgjyoi0ltEXhORbe41mxTt10pEbnf/9j4XkRdFJKkzXKtQslwU2SwXRYdQ5aJOX0ASkXjgSeBC4AxgtoicEd6oOqQB+IWqjgAmAv/unsfdwAeqOgz4gEDPQh4at+LMst7st8Dv3HM6CFwflqj88xjwnqoOB0bjnF/UXisRGQTcAmSp6iggHriKznGtQsJyUVSwXBThQpmLOn0BCTgL2KGqX6tqHfAScFmYY2o3Vd2nqhvd90dw/sgH4ZzLUnezpcBPwhNhx4jIYOBi4Bl3WYBzgdfcTaLxnHoCU4FnAVS1TlUPEeXXCmdy624i0gXoDuwjyq9ViFkuimCWi6JKSHJRLBSQBgF7PJaL3XVRS0QygLHAOuBUVd0HTuICTglfZB3yKHAX0OQupwKHVLXBXY7G63UacAB4zq2uf0ZEkonia6Wq3wAPA7txklEFsIHov1ahZLkoslkuNRvOswAABkpJREFUigKhzEWxUECSFtZF7aN7IpICLAduU9XD4Y7HHyIyA/hWVTd4rm5h02i7Xl2AccAfVHUscJQoqsJuidtH4TJgKDAQSMZpKvIWbdcqlDrD3/YxlouiguUiP8RCAakYGOKxPBjYG6ZY/CIiCTgJKV9VX3dX7xeR77mffw/4NlzxdcAU4FIRKcJpbjgX5y6ut1t1CtF5vYqBYlVd5y6/hpOkovla/RjYqaoHVLUeeB2YTPRfq1CyXBS5LBdFj5DlolgoIK0Hhrk93BNxOnO9GeaY2s1tD38W+EJVF3t89CYwx30/B3gj1LF1lKreo6qDVTUD57p8qKo5wCpgprtZVJ0TgKqWAHtE5AfuqvOAQqL4WuFUZ08Uke7u32LzOUX1tQoxy0URynJRVJ1XyHJRTAwUKSIX4dwNxAN/VtVFYQ6p3UQkG1gD/JPv2sjvxWn7fwVIw/nDmaWq5WEJ0g8icg5wp6rOEJHTcO7i+gKbgGtUtTac8bWXiIzB6eyZCHwNXIdzQxK110pEHgCuxHmKaRNwA047f1Rfq1CyXBT5LBdFvlDlopgoIBljjDHGtEcsNLEZY4wxxrSLFZCMMcYYY7xYAckYY4wxxosVkIwxxhhjvFgByRhjjDHGixWQOikRaRSRze6Mx5+JyB0iEvLrLSJnuzFsFpERInJ1EL9riYjMPPmWLe47xn0Eu3n5UonS2daNiSSWi9q9r+WiCGEFpM6rWlXHqOpIYDpwEfDrMMSRAzysqmOAU4F2JSV3BvRQGIPzOwJAVd9U1d+E6LuN6cwsF7WP5aIIYQWkGKCq3wK5wM/FkSEia0Rko/uaDCAiz4vIsdnFRSTfvXsZKSKfundeW0RkmPd3iMgfRKTAvUN7wF13A/BT4H4RyQd+A5ztHud2EYkXkf8WkfXucee5+50jIqtE5AWcwei8v6tSRB5xY/9ARPq3sM397nE/F5E8d8RVRGS1iPzWPZ8v3bvKRGAhcKUb25UiMldEfu/us0REHheRf4jI1813hiISJyJPuef8toi829G7RmNigeUiy0VRRVXt1QlfQGUL6w7i3Dl1B5LcdcOAAvf9j4D/cd/3AnbiTHb4BJDjrk8EurVw7L7uz3hgNZDpLi8BZrrvzwHe9tgnF/iV+74rUIAzAeE5OJMqDm3l3NQjnvuB37fwXX09tn8euMR9vxp4xH1/EbDSfT+3+Tjey+5xX8W5oTgD2OGunwm8664f4P5+Z4b72tvLXpH0slxkuShaX1aDFFuaZ6dOAJ4WkX/i/GM7A0BV/wacLiKnALOB5araAHwM3Csi/wGkq2p1C8f+qYhsxBnifWTzMU/ifOBnIrIZZ5qCVJwkCfCpqu5sZb8m4GX3/TIgu4VtponIOvccz3VjatY8ueYGIMOHOMFJ1k2qWoiT2HG/91V3fQnOXEDGmJOzXOSwXBTBrIAUI8SZU6gRZ9bm24H9wGggC+dOrNnzOG311wHPAajqC8ClQDXwvoic63XsocCdwHmqmgm8AyT5Ehbwf9TpnzBGVYeq6gr3s6PtOL3j5ssRkSTgKZw7qDOBp73iaZ6fpxHnrtQXnnP6iNdPY4yPLBdZLooWVkCKAW67+B9xqmkVp8p6n6o2AdfiVEU3WwLcBqCqW939TwO+VtXHcWaBzvT6ip44SaRCRE4FLmwllCNAD4/l94H5IpLgfs/3RSTZh1OK47tZm68G1np93pyASkUkxWPbtnjH5ou1wL+57f+n4lTHG2NaYbnIclE08bXEaqJPN7e6OAFnxuPngcXuZ08By0VkFk5V7LE7JFXdLyJfAP/jcawrgWtEpB4owelEiMc+n4nIJmArzmzRH7US0xagQUQ+w0l+j+FUK290Oy4eAH7iw7kdBUaKyAagwo3PM55DIvI0TqfKImC9D8dcBdzt/s7+y4ftAZYD5wGfA1/iVM1X+LivMbHCcpHloqgkTiHeGIeIdMf5xzxOVSPyH5iIVKpqSrjjABCRFFWtFJFU4FNgitsHwBjjB8tF7WO5KPCsBskcIyI/Bv4MLI7UhBSB3haR3jh9Jx60hGSM/ywXdYjlogCzGiRjjDHGGC/WSdsYY4wxxosVkIwxxhhjvFgByRhjjDHGixWQjDHGGGO8WAHJGGOMMcaLFZCMMcYYY7z8f8E7b83EG7CuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show graph examples of specific observation with no normalization\n",
    "\n",
    "std = 3\n",
    "observation = 13\n",
    "normalization = True\n",
    "# x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "show_GRNN_example(observation-1, std, normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_medium_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(64, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_default_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    \n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(10, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "#     model.add(keras.layers.Dense(4, activation = 'relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_small_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(16, activation='relu', input_shape=[input_shape], kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(16, activation = 'relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.Dense(1, activation ='relu'))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model that have 2 hidden layers (64, 64)\n",
    "def build_tiny_regression_model(input_shape):\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     #     layers.Dropout(0.25),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "#     model = keras.Sequential([\n",
    "#     layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "#     layers.Dense(64, activation='relu'),\n",
    "#     layers.Dense(1)\n",
    "#     ])\n",
    "    # Define a Keras sequential model\n",
    "    model = keras.Sequential()\n",
    "    # Define the first dense layer\n",
    "    model.add(keras.layers.Dense(10, activation='relu', input_shape=[input_shape],kernel_regularizer=regularizers.l2(0.001),\n",
    "                activity_regularizer=regularizers.l1(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    # Define the second dense layer\n",
    "    model.add(keras.layers.Dense(1, activation ='relu'))\n",
    "\n",
    "#     # Print the model architecture\n",
    "#     optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 6,537\n",
      "Trainable params: 6,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_medium_regression_model(len(parameters) * len(x_pred))\n",
    "# optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "optimizer = keras.optimizers.RMSprop(0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "# model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile and train model\n",
    "\n",
    "std = 10\n",
    "observation = 4\n",
    "normalization = True\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "y_train = y_train / np.linalg.norm(y_train)\n",
    "x_train = x_train.reshape(len(yield_data), len(x_pred) * len(parameters))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 34 samples\n",
      "Epoch 1/10000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0021 - mae: 0.0373 - mse: 0.0021 - val_loss: 9.2062e-04 - val_mae: 0.0249 - val_mse: 9.2062e-04\n",
      "Epoch 2/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 9.1963e-04 - mae: 0.0240 - mse: 9.1963e-04 - val_loss: 8.1035e-04 - val_mae: 0.0243 - val_mse: 8.1035e-04\n",
      "Epoch 3/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.5892e-04 - mae: 0.0235 - mse: 8.5892e-04 - val_loss: 8.1775e-04 - val_mae: 0.0243 - val_mse: 8.1775e-04\n",
      "Epoch 4/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.3583e-04 - mae: 0.0226 - mse: 8.3583e-04 - val_loss: 0.0011 - val_mae: 0.0265 - val_mse: 0.0011\n",
      "Epoch 5/10000\n",
      "136/136 [==============================] - 0s 66us/step - loss: 9.2969e-04 - mae: 0.0239 - mse: 9.2969e-04 - val_loss: 7.5789e-04 - val_mae: 0.0240 - val_mse: 7.5789e-04\n",
      "Epoch 6/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 9.1771e-04 - mae: 0.0233 - mse: 9.1771e-04 - val_loss: 9.0952e-04 - val_mae: 0.0248 - val_mse: 9.0952e-04\n",
      "Epoch 7/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.7684e-04 - mae: 0.0233 - mse: 8.7684e-04 - val_loss: 8.0131e-04 - val_mae: 0.0242 - val_mse: 8.0131e-04\n",
      "Epoch 8/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.6320e-04 - mae: 0.0233 - mse: 8.6320e-04 - val_loss: 9.8954e-04 - val_mae: 0.0256 - val_mse: 9.8954e-04\n",
      "Epoch 9/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.6529e-04 - mae: 0.0235 - mse: 8.6529e-04 - val_loss: 7.4537e-04 - val_mae: 0.0238 - val_mse: 7.4537e-04\n",
      "Epoch 10/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 9.0987e-04 - mae: 0.0238 - mse: 9.0987e-04 - val_loss: 7.5583e-04 - val_mae: 0.0239 - val_mse: 7.5583e-04\n",
      "Epoch 11/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.9692e-04 - mae: 0.0239 - mse: 8.9692e-04 - val_loss: 8.7098e-04 - val_mae: 0.0245 - val_mse: 8.7098e-04\n",
      "Epoch 12/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.7881e-04 - mae: 0.0238 - mse: 8.7881e-04 - val_loss: 7.4657e-04 - val_mae: 0.0238 - val_mse: 7.4657e-04\n",
      "Epoch 13/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.9856e-04 - mae: 0.0238 - mse: 8.9856e-04 - val_loss: 9.6709e-04 - val_mae: 0.0254 - val_mse: 9.6709e-04\n",
      "Epoch 14/10000\n",
      "136/136 [==============================] - 0s 74us/step - loss: 8.9623e-04 - mae: 0.0242 - mse: 8.9623e-04 - val_loss: 8.3793e-04 - val_mae: 0.0243 - val_mse: 8.3793e-04\n",
      "Epoch 15/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.2984e-04 - mae: 0.0227 - mse: 8.2984e-04 - val_loss: 0.0011 - val_mae: 0.0263 - val_mse: 0.0011\n",
      "Epoch 16/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 9.4092e-04 - mae: 0.0246 - mse: 9.4092e-04 - val_loss: 7.7770e-04 - val_mae: 0.0239 - val_mse: 7.7770e-04\n",
      "Epoch 17/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 8.3854e-04 - mae: 0.0229 - mse: 8.3854e-04 - val_loss: 8.4462e-04 - val_mae: 0.0244 - val_mse: 8.4462e-04\n",
      "Epoch 18/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 9.0041e-04 - mae: 0.0234 - mse: 9.0041e-04 - val_loss: 0.0010 - val_mae: 0.0257 - val_mse: 0.0010\n",
      "Epoch 19/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.8301e-04 - mae: 0.0239 - mse: 8.8301e-04 - val_loss: 0.0013 - val_mae: 0.0299 - val_mse: 0.0013\n",
      "Epoch 20/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 9.3765e-04 - mae: 0.0237 - mse: 9.3765e-04 - val_loss: 0.0011 - val_mae: 0.0265 - val_mse: 0.0011\n",
      "Epoch 21/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.5173e-04 - mae: 0.0233 - mse: 8.5173e-04 - val_loss: 7.4703e-04 - val_mae: 0.0238 - val_mse: 7.4703e-04\n",
      "Epoch 22/10000\n",
      "136/136 [==============================] - 0s 73us/step - loss: 8.2387e-04 - mae: 0.0226 - mse: 8.2387e-04 - val_loss: 9.0914e-04 - val_mae: 0.0248 - val_mse: 9.0914e-04\n",
      "Epoch 23/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 8.3834e-04 - mae: 0.0232 - mse: 8.3834e-04 - val_loss: 7.8710e-04 - val_mae: 0.0240 - val_mse: 7.8710e-04\n",
      "Epoch 24/10000\n",
      "136/136 [==============================] - 0s 81us/step - loss: 8.1910e-04 - mae: 0.0226 - mse: 8.1910e-04 - val_loss: 7.6028e-04 - val_mae: 0.0239 - val_mse: 7.6028e-04\n",
      "Epoch 25/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.2354e-04 - mae: 0.0227 - mse: 8.2354e-04 - val_loss: 0.0012 - val_mae: 0.0280 - val_mse: 0.0012\n",
      "Epoch 26/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.5587e-04 - mae: 0.0232 - mse: 8.5587e-04 - val_loss: 0.0011 - val_mae: 0.0262 - val_mse: 0.0011\n",
      "Epoch 27/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.4377e-04 - mae: 0.0232 - mse: 8.4377e-04 - val_loss: 7.3053e-04 - val_mae: 0.0235 - val_mse: 7.3053e-04\n",
      "Epoch 28/10000\n",
      "136/136 [==============================] - 0s 88us/step - loss: 8.4226e-04 - mae: 0.0226 - mse: 8.4226e-04 - val_loss: 7.3149e-04 - val_mae: 0.0234 - val_mse: 7.3149e-04\n",
      "Epoch 29/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 8.6141e-04 - mae: 0.0234 - mse: 8.6141e-04 - val_loss: 7.7774e-04 - val_mae: 0.0235 - val_mse: 7.7774e-04\n",
      "Epoch 30/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 8.4608e-04 - mae: 0.0229 - mse: 8.4608e-04 - val_loss: 8.4095e-04 - val_mae: 0.0242 - val_mse: 8.4095e-04\n",
      "Epoch 31/10000\n",
      "136/136 [==============================] - 0s 99us/step - loss: 8.4208e-04 - mae: 0.0230 - mse: 8.4208e-04 - val_loss: 7.2376e-04 - val_mae: 0.0233 - val_mse: 7.2376e-04\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=30, mode=\"min\", verbose=1)\n",
    "history = model.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])\n",
    "# history = model.fit(x_train, y_train, epochs= 10000, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 68us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0007446734115085883, 0.022263439372181892, 0.0007446734234690666]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mae', 'val_mse', 'loss', 'mae', 'mse'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['mse'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['val_mse'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using default network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrenn as prn\n",
    "net = prn.CreateNN([32, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  6.574105877473802 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  3.92758178419609 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  2.842927263696396 \tscale factor:  0.02\n",
      "Iteration:  3 \t\tError:  2.6579319932618244 \tscale factor:  0.1458\n",
      "Iteration:  4 \t\tError:  2.5283194976270194 \tscale factor:  0.054\n",
      "Iteration:  5 \t\tError:  2.4595635923532795 \tscale factor:  0.019999999999999997\n",
      "Iteration:  6 \t\tError:  2.384437987231993 \tscale factor:  0.007407407407407406\n",
      "Iteration:  7 \t\tError:  1.6970042068163227 \tscale factor:  0.007407407407407406\n",
      "Iteration:  8 \t\tError:  1.3518058576324674 \tscale factor:  0.019999999999999997\n",
      "Iteration:  9 \t\tError:  1.0821591659533865 \tscale factor:  0.007407407407407406\n",
      "Iteration:  10 \t\tError:  0.9396936505418847 \tscale factor:  0.007407407407407406\n",
      "Iteration:  11 \t\tError:  0.7782720390782079 \tscale factor:  0.002743484224965706\n",
      "Iteration:  12 \t\tError:  0.6608469459210028 \tscale factor:  0.007407407407407406\n",
      "Iteration:  13 \t\tError:  0.5716945735925149 \tscale factor:  0.007407407407407406\n",
      "Iteration:  14 \t\tError:  0.5146104326880458 \tscale factor:  0.007407407407407406\n",
      "Iteration:  15 \t\tError:  0.4932748182012767 \tscale factor:  0.002743484224965706\n",
      "Iteration:  16 \t\tError:  0.3941332785992945 \tscale factor:  0.007407407407407406\n",
      "Iteration:  17 \t\tError:  0.3781555266617259 \tscale factor:  0.007407407407407406\n",
      "Iteration:  18 \t\tError:  0.3299007164510469 \tscale factor:  0.007407407407407406\n",
      "Iteration:  19 \t\tError:  0.2762793355310798 \tscale factor:  0.007407407407407406\n",
      "Iteration:  20 \t\tError:  0.2393301974602186 \tscale factor:  0.007407407407407406\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=20, E_stop=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prn.NNOut(x_train, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_train_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>59.2</td>\n",
       "      <td>57.441457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.392380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>26.8</td>\n",
       "      <td>24.081672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.983642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>35.587038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_train  y_train_pred\n",
       "0     59.2     57.441457\n",
       "1     24.6     25.392380\n",
       "2     26.8     24.081672\n",
       "3     23.4     23.983642\n",
       "4     36.4     35.587038"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': y.flatten()})\n",
    "acc_sc_chk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.9611871773202583 / 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score_1 = r2_score(acc_sc_chk.y_train, acc_sc_chk.y_train_pred)\n",
    "print('r2 score = ', r2_score_1, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction test data\n",
    "y_pred = prn.NNOut(x_test, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>25.507260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>22.314717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>29.390475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>46.2</td>\n",
       "      <td>30.507028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>14.127041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_test_pred\n",
       "0     9.4    25.507260\n",
       "1     1.4    22.314717\n",
       "2     1.4    29.390475\n",
       "3    46.2    30.507028\n",
       "4    17.4    14.127041"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk_2 = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': y_pred.flatten()})\n",
    "acc_sc_chk_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-4efaa3864a71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mr2_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_sc_chk_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_sc_chk_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r2 score = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/ 1.0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "r2_score = r2_score(acc_sc_chk_2.y_test, acc_sc_chk_2.y_test_pred)\n",
    "print('r2 score = ', r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"normalizationWeight.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(129, 32)\n",
      "(129,)\n"
     ]
    }
   ],
   "source": [
    "#compile and train model\n",
    "\n",
    "std = 2\n",
    "observation = 4\n",
    "normalization = False\n",
    "x_pred = range(10, limit_day+1, 10)\n",
    "\n",
    "\n",
    "x_train = process(normalization, std)\n",
    "y_train = yield_data['Yield'].values\n",
    "x_train = x_train.reshape(len(yield_data), len(x_pred) * len(parameters))\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.33, random_state=42)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-d853d70ac43a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRMSprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = build_model(len(parameters) * len(x_pred))\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 34 samples\n",
      "Epoch 1/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 22.0235 - accuracy: 0.0294 - val_loss: 330.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 22.0566 - accuracy: 0.0294 - val_loss: 304.6982 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "136/136 [==============================] - 0s 125us/step - loss: 16.2596 - accuracy: 0.0441 - val_loss: 302.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 20.9351 - accuracy: 0.0221 - val_loss: 297.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 20.3262 - accuracy: 0.0294 - val_loss: 292.8714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 19.4125 - accuracy: 0.0147 - val_loss: 318.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 16.2981 - accuracy: 0.0074 - val_loss: 277.9302 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 26.9520 - accuracy: 0.0000e+00 - val_loss: 277.6325 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 17.2630 - accuracy: 0.0147 - val_loss: 331.4875 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 24.1353 - accuracy: 0.0294 - val_loss: 289.0898 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 27.6881 - accuracy: 0.0147 - val_loss: 225.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 31.5064 - accuracy: 0.0000e+00 - val_loss: 245.7843 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 27.9803 - accuracy: 0.0074 - val_loss: 277.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "136/136 [==============================] - 0s 154us/step - loss: 23.5792 - accuracy: 0.0294 - val_loss: 295.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 21.3009 - accuracy: 0.0294 - val_loss: 297.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 22.5863 - accuracy: 0.0294 - val_loss: 287.1923 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "136/136 [==============================] - 0s 118us/step - loss: 24.0893 - accuracy: 0.0221 - val_loss: 293.1207 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "136/136 [==============================] - 0s 132us/step - loss: 19.0059 - accuracy: 0.0074 - val_loss: 304.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "136/136 [==============================] - 0s 110us/step - loss: 14.6915 - accuracy: 0.0441 - val_loss: 296.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/10000\n",
      "136/136 [==============================] - 0s 96us/step - loss: 19.9271 - accuracy: 0.0074 - val_loss: 309.7323 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 23.0918 - accuracy: 0.0074 - val_loss: 312.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 20.0033 - accuracy: 0.0147 - val_loss: 304.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 20.5833 - accuracy: 0.0294 - val_loss: 294.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 20.4638 - accuracy: 0.0294 - val_loss: 305.2590 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 15.8400 - accuracy: 0.0221 - val_loss: 328.9878 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 21.7599 - accuracy: 0.0074 - val_loss: 309.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/10000\n",
      "136/136 [==============================] - 0s 147us/step - loss: 16.2800 - accuracy: 0.0147 - val_loss: 318.8981 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "136/136 [==============================] - 0s 154us/step - loss: 20.0312 - accuracy: 0.0147 - val_loss: 314.4065 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "136/136 [==============================] - 0s 125us/step - loss: 22.1290 - accuracy: 0.0000e+00 - val_loss: 283.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "136/136 [==============================] - 0s 103us/step - loss: 22.1368 - accuracy: 0.0221 - val_loss: 300.0958 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "136/136 [==============================] - 0s 140us/step - loss: 20.5637 - accuracy: 0.0221 - val_loss: 319.8900 - val_accuracy: 0.0000e+00\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = model.fit(x_train, y_train, epochs=10000, validation_data=(x_valid, y_valid), callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 62us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[152.62903189953462, 0.012345679104328156]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"UnnormalizationWeight.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test connection of input and output\n",
    "# Output using: plants planted on 2/28/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "test = data\n",
    "print(type(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 12)\n",
      "(81, 9)\n",
      "(81, 12)\n",
      "(81, 12)\n",
      "(81, 45)\n"
     ]
    }
   ],
   "source": [
    "plantDate = '2-28-2016'\n",
    "mask_yield = yield_data['plantDate'] == plantDate\n",
    "test_data = np.empty((81, 0))\n",
    "for i in range(len(data)):\n",
    "    test = data[i].copy()\n",
    "    test = test[mask_yield]\n",
    "    for column in test.columns:\n",
    "        temp_mask = test[column].values<=0\n",
    "        if sum(temp_mask) != 0:\n",
    "            test = test.drop(column, axis = 1)\n",
    "#     print(test.columns)\n",
    "    test = test[test.columns[test.columns != 'id' ]]\n",
    "    day_after_planting = np.array([count_days(plantDate, x) for x in test.columns])\n",
    "    \n",
    "    mask = (day_after_planting>20) & (day_after_planting <=limit_day)\n",
    "#     print(day_after_planting[mask])\n",
    "    value = test[test.columns[mask]].values\n",
    "    print(value.shape)\n",
    "    value = value/np.linalg.norm(value)\n",
    "    test_data = np.append(test_data, value, axis = 1)\n",
    "    \n",
    "# test_data=np.array(test_data)\n",
    "# test_data = test_data.swapaxes(0,1)\n",
    "print(test_data.shape)\n",
    "#     print(type(test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data= test_data.reshape(81, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 45)\n",
      "(64,)\n"
     ]
    }
   ],
   "source": [
    "test_data_x = test_data\n",
    "test_data_y = yield_data['Yield'][mask_yield].values\n",
    "test_data_y /= np.linalg.norm(test_data_y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(test_data_x, test_data_y, test_size = 0.2)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>612</td>\n",
       "      <td>0.076548</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>0.064414</td>\n",
       "      <td>0.062494</td>\n",
       "      <td>0.077544</td>\n",
       "      <td>0.122361</td>\n",
       "      <td>0.185421</td>\n",
       "      <td>0.246436</td>\n",
       "      <td>0.325305</td>\n",
       "      <td>0.450840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383785</td>\n",
       "      <td>0.512663</td>\n",
       "      <td>0.580496</td>\n",
       "      <td>0.605675</td>\n",
       "      <td>0.596939</td>\n",
       "      <td>0.662752</td>\n",
       "      <td>0.730180</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.609836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.036692</td>\n",
       "      <td>0.040188</td>\n",
       "      <td>0.044507</td>\n",
       "      <td>0.054816</td>\n",
       "      <td>0.088630</td>\n",
       "      <td>0.170701</td>\n",
       "      <td>0.287965</td>\n",
       "      <td>0.397261</td>\n",
       "      <td>0.510692</td>\n",
       "      <td>0.642437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.474338</td>\n",
       "      <td>0.631576</td>\n",
       "      <td>0.724246</td>\n",
       "      <td>0.760365</td>\n",
       "      <td>0.762104</td>\n",
       "      <td>0.555369</td>\n",
       "      <td>0.322262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>0.057990</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.053455</td>\n",
       "      <td>0.059006</td>\n",
       "      <td>0.086824</td>\n",
       "      <td>0.156805</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>0.351107</td>\n",
       "      <td>0.458857</td>\n",
       "      <td>0.604437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.639595</td>\n",
       "      <td>0.760024</td>\n",
       "      <td>0.822052</td>\n",
       "      <td>0.839582</td>\n",
       "      <td>0.816573</td>\n",
       "      <td>0.607383</td>\n",
       "      <td>0.636550</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.648787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>609</td>\n",
       "      <td>0.072349</td>\n",
       "      <td>0.067886</td>\n",
       "      <td>0.064455</td>\n",
       "      <td>0.068856</td>\n",
       "      <td>0.100332</td>\n",
       "      <td>0.175779</td>\n",
       "      <td>0.274623</td>\n",
       "      <td>0.360292</td>\n",
       "      <td>0.453749</td>\n",
       "      <td>0.582514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.599032</td>\n",
       "      <td>0.735785</td>\n",
       "      <td>0.798537</td>\n",
       "      <td>0.812896</td>\n",
       "      <td>0.789501</td>\n",
       "      <td>0.815436</td>\n",
       "      <td>0.924938</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.706230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.031597</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>0.050084</td>\n",
       "      <td>0.086425</td>\n",
       "      <td>0.139599</td>\n",
       "      <td>0.197102</td>\n",
       "      <td>0.257314</td>\n",
       "      <td>0.337184</td>\n",
       "      <td>0.455256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393861</td>\n",
       "      <td>0.549271</td>\n",
       "      <td>0.650403</td>\n",
       "      <td>0.698242</td>\n",
       "      <td>0.709303</td>\n",
       "      <td>0.622483</td>\n",
       "      <td>0.594256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.364590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "612  0.076548  0.070373  0.064414  0.062494  0.077544  0.122361  0.185421   \n",
       "27   0.036692  0.040188  0.044507  0.054816  0.088630  0.170701  0.287965   \n",
       "568  0.057990  0.055000  0.053455  0.059006  0.086824  0.156805  0.257027   \n",
       "609  0.072349  0.067886  0.064455  0.068856  0.100332  0.175779  0.274623   \n",
       "238  0.031597  0.032631  0.036055  0.050084  0.086425  0.139599  0.197102   \n",
       "\n",
       "           f8        f9       f10  ...       f56       f57       f58  \\\n",
       "612  0.246436  0.325305  0.450840  ...  0.383785  0.512663  0.580496   \n",
       "27   0.397261  0.510692  0.642437  ...  0.474338  0.631576  0.724246   \n",
       "568  0.351107  0.458857  0.604437  ...  0.639595  0.760024  0.822052   \n",
       "609  0.360292  0.453749  0.582514  ...  0.599032  0.735785  0.798537   \n",
       "238  0.257314  0.337184  0.455256  ...  0.393861  0.549271  0.650403   \n",
       "\n",
       "          f59       f60       f61       f62  f63  f64    target  \n",
       "612  0.605675  0.596939  0.662752  0.730180    1    0  0.609836  \n",
       "27   0.760365  0.762104  0.555369  0.322262    0    1  0.152262  \n",
       "568  0.839582  0.816573  0.607383  0.636550    1    0  0.648787  \n",
       "609  0.812896  0.789501  0.815436  0.924938    1    0  0.706230  \n",
       "238  0.698242  0.709303  0.622483  0.594256    0    1  0.364590  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy_dataframe = pd.read_excel('X.xlsx')\n",
    "canopy_dataframe = canopy_dataframe.reindex(np.random.permutation(canopy_dataframe.index))\n",
    "canopy_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805, 64)\n"
     ]
    }
   ],
   "source": [
    "X = canopy_dataframe.loc[:, canopy_dataframe.columns != 'target' ].values\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805,)\n"
     ]
    }
   ],
   "source": [
    "y = canopy_dataframe['target'].values\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "history ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_198 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_94 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,385\n",
      "Trainable params: 8,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.9375 - mae: 0.3789 - mse: 0.2098 - val_loss: 0.7624 - val_mae: 0.2977 - val_mse: 0.1229\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.8203 - mae: 0.3049 - mse: 0.1440 - val_loss: 0.6674 - val_mae: 0.2114 - val_mse: 0.0708\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.7315 - mae: 0.2543 - mse: 0.0986 - val_loss: 0.6028 - val_mae: 0.1682 - val_mse: 0.0466\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.6716 - mae: 0.2294 - mse: 0.0818 - val_loss: 0.5522 - val_mae: 0.1460 - val_mse: 0.0355\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.6221 - mae: 0.2182 - mse: 0.0745 - val_loss: 0.5086 - val_mae: 0.1383 - val_mse: 0.0315\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.5671 - mae: 0.1990 - mse: 0.0621 - val_loss: 0.4692 - val_mae: 0.1264 - val_mse: 0.0261\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.5259 - mae: 0.1854 - mse: 0.0563 - val_loss: 0.4359 - val_mae: 0.1228 - val_mse: 0.0245\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.4896 - mae: 0.1797 - mse: 0.0529 - val_loss: 0.4077 - val_mae: 0.1276 - val_mse: 0.0256\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.4544 - mae: 0.1746 - mse: 0.0492 - val_loss: 0.3811 - val_mae: 0.1299 - val_mse: 0.0259\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.4210 - mae: 0.1639 - mse: 0.0443 - val_loss: 0.3574 - val_mae: 0.1361 - val_mse: 0.0279\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.3896 - mae: 0.1657 - mse: 0.0416 - val_loss: 0.3362 - val_mae: 0.1391 - val_mse: 0.0291\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.3666 - mae: 0.1625 - mse: 0.0434 - val_loss: 0.3166 - val_mae: 0.1477 - val_mse: 0.0325\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.3410 - mae: 0.1638 - mse: 0.0433 - val_loss: 0.2969 - val_mae: 0.1438 - val_mse: 0.0313\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.3196 - mae: 0.1647 - mse: 0.0429 - val_loss: 0.2787 - val_mae: 0.1452 - val_mse: 0.0320\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2932 - mae: 0.1540 - mse: 0.0368 - val_loss: 0.2621 - val_mae: 0.1511 - val_mse: 0.0343\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2735 - mae: 0.1536 - mse: 0.0376 - val_loss: 0.2463 - val_mae: 0.1493 - val_mse: 0.0335\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.2562 - mae: 0.1550 - mse: 0.0382 - val_loss: 0.2319 - val_mae: 0.1512 - val_mse: 0.0341\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2415 - mae: 0.1611 - mse: 0.0390 - val_loss: 0.2201 - val_mae: 0.1545 - val_mse: 0.0353\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.2287 - mae: 0.1626 - mse: 0.0403 - val_loss: 0.2083 - val_mae: 0.1538 - val_mse: 0.0349\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.2163 - mae: 0.1603 - mse: 0.0409 - val_loss: 0.1974 - val_mae: 0.1523 - val_mse: 0.0342\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2051 - mae: 0.1578 - mse: 0.0390 - val_loss: 0.1904 - val_mae: 0.1593 - val_mse: 0.0367\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1974 - mae: 0.1647 - mse: 0.0415 - val_loss: 0.1831 - val_mae: 0.1559 - val_mse: 0.0353\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1896 - mae: 0.1624 - mse: 0.0398 - val_loss: 0.1758 - val_mae: 0.1470 - val_mse: 0.0318\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1855 - mae: 0.1627 - mse: 0.0412 - val_loss: 0.1704 - val_mae: 0.1466 - val_mse: 0.0317\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1779 - mae: 0.1577 - mse: 0.0384 - val_loss: 0.1649 - val_mae: 0.1394 - val_mse: 0.0290\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1723 - mae: 0.1548 - mse: 0.0360 - val_loss: 0.1603 - val_mae: 0.1388 - val_mse: 0.0288\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1697 - mae: 0.1573 - mse: 0.0390 - val_loss: 0.1560 - val_mae: 0.1364 - val_mse: 0.0280\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1610 - mae: 0.1445 - mse: 0.0323 - val_loss: 0.1515 - val_mae: 0.1306 - val_mse: 0.0260\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1590 - mae: 0.1453 - mse: 0.0331 - val_loss: 0.1485 - val_mae: 0.1369 - val_mse: 0.0280\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1544 - mae: 0.1472 - mse: 0.0328 - val_loss: 0.1444 - val_mae: 0.1287 - val_mse: 0.0252\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1516 - mae: 0.1452 - mse: 0.0327 - val_loss: 0.1406 - val_mae: 0.1196 - val_mse: 0.0223\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1475 - mae: 0.1380 - mse: 0.0299 - val_loss: 0.1378 - val_mae: 0.1220 - val_mse: 0.0230\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.1449 - mae: 0.1394 - mse: 0.0302 - val_loss: 0.1350 - val_mae: 0.1219 - val_mse: 0.0229\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.1417 - mae: 0.1425 - mse: 0.0307 - val_loss: 0.1315 - val_mae: 0.1138 - val_mse: 0.0204\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.1386 - mae: 0.1363 - mse: 0.0285 - val_loss: 0.1288 - val_mae: 0.1160 - val_mse: 0.0210\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1349 - mae: 0.1331 - mse: 0.0277 - val_loss: 0.1260 - val_mae: 0.1132 - val_mse: 0.0202\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1308 - mae: 0.1261 - mse: 0.0252 - val_loss: 0.1231 - val_mae: 0.1109 - val_mse: 0.0194\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1284 - mae: 0.1258 - mse: 0.0252 - val_loss: 0.1203 - val_mae: 0.1086 - val_mse: 0.0187\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.1253 - mae: 0.1242 - mse: 0.0240 - val_loss: 0.1177 - val_mae: 0.1056 - val_mse: 0.0178\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1229 - mae: 0.1243 - mse: 0.0243 - val_loss: 0.1153 - val_mae: 0.1052 - val_mse: 0.0178\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1201 - mae: 0.1202 - mse: 0.0231 - val_loss: 0.1129 - val_mae: 0.1046 - val_mse: 0.0177\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.1189 - mae: 0.1224 - mse: 0.0244 - val_loss: 0.1108 - val_mae: 0.1052 - val_mse: 0.0178\n",
      "Epoch 43/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.1146 - mae: 0.1159 - mse: 0.0216 - val_loss: 0.1082 - val_mae: 0.0978 - val_mse: 0.0156\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1134 - mae: 0.1170 - mse: 0.0218 - val_loss: 0.1063 - val_mae: 0.1005 - val_mse: 0.0164\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1103 - mae: 0.1132 - mse: 0.0203 - val_loss: 0.1041 - val_mae: 0.0982 - val_mse: 0.0156\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1092 - mae: 0.1154 - mse: 0.0213 - val_loss: 0.1022 - val_mae: 0.0976 - val_mse: 0.0155\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1078 - mae: 0.1172 - mse: 0.0220 - val_loss: 0.1004 - val_mae: 0.0983 - val_mse: 0.0157\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1052 - mae: 0.1134 - mse: 0.0204 - val_loss: 0.0986 - val_mae: 0.0989 - val_mse: 0.0158\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1028 - mae: 0.1135 - mse: 0.0201 - val_loss: 0.0967 - val_mae: 0.0948 - val_mse: 0.0146\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1009 - mae: 0.1094 - mse: 0.0188 - val_loss: 0.0950 - val_mae: 0.0963 - val_mse: 0.0150\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0988 - mae: 0.1072 - mse: 0.0187 - val_loss: 0.0932 - val_mae: 0.0958 - val_mse: 0.0149\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0973 - mae: 0.1079 - mse: 0.0187 - val_loss: 0.0915 - val_mae: 0.0931 - val_mse: 0.0141\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0963 - mae: 0.1073 - mse: 0.0187 - val_loss: 0.0899 - val_mae: 0.0947 - val_mse: 0.0146\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0945 - mae: 0.1094 - mse: 0.0190 - val_loss: 0.0881 - val_mae: 0.0896 - val_mse: 0.0131\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0940 - mae: 0.1095 - mse: 0.0196 - val_loss: 0.0866 - val_mae: 0.0903 - val_mse: 0.0133\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0912 - mae: 0.1064 - mse: 0.0180 - val_loss: 0.0850 - val_mae: 0.0885 - val_mse: 0.0128\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0901 - mae: 0.1059 - mse: 0.0184 - val_loss: 0.0835 - val_mae: 0.0857 - val_mse: 0.0121\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0875 - mae: 0.1028 - mse: 0.0167 - val_loss: 0.0823 - val_mae: 0.0905 - val_mse: 0.0136\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0872 - mae: 0.1059 - mse: 0.0184 - val_loss: 0.0808 - val_mae: 0.0897 - val_mse: 0.0134\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0855 - mae: 0.1047 - mse: 0.0179 - val_loss: 0.0794 - val_mae: 0.0884 - val_mse: 0.0130\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0841 - mae: 0.1029 - mse: 0.0177 - val_loss: 0.0778 - val_mae: 0.0856 - val_mse: 0.0122\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0828 - mae: 0.1041 - mse: 0.0172 - val_loss: 0.0764 - val_mae: 0.0840 - val_mse: 0.0117\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 209us/step - loss: 0.0812 - mae: 0.1003 - mse: 0.0164 - val_loss: 0.0753 - val_mae: 0.0871 - val_mse: 0.0127\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0804 - mae: 0.1050 - mse: 0.0178 - val_loss: 0.0740 - val_mae: 0.0865 - val_mse: 0.0125\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0790 - mae: 0.1028 - mse: 0.0174 - val_loss: 0.0726 - val_mae: 0.0837 - val_mse: 0.0117\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0766 - mae: 0.0996 - mse: 0.0158 - val_loss: 0.0712 - val_mae: 0.0829 - val_mse: 0.0114\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0753 - mae: 0.0980 - mse: 0.0154 - val_loss: 0.0702 - val_mae: 0.0844 - val_mse: 0.0119\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0752 - mae: 0.1008 - mse: 0.0169 - val_loss: 0.0690 - val_mae: 0.0825 - val_mse: 0.0114\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0741 - mae: 0.0990 - mse: 0.0161 - val_loss: 0.0680 - val_mae: 0.0821 - val_mse: 0.0113\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0728 - mae: 0.0993 - mse: 0.0165 - val_loss: 0.0668 - val_mae: 0.0795 - val_mse: 0.0106\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0716 - mae: 0.0961 - mse: 0.0154 - val_loss: 0.0658 - val_mae: 0.0808 - val_mse: 0.0110\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0709 - mae: 0.0988 - mse: 0.0160 - val_loss: 0.0649 - val_mae: 0.0837 - val_mse: 0.0119\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0697 - mae: 0.1003 - mse: 0.0167 - val_loss: 0.0638 - val_mae: 0.0829 - val_mse: 0.0117\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0669 - mae: 0.0926 - mse: 0.0147 - val_loss: 0.0626 - val_mae: 0.0806 - val_mse: 0.0111\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0662 - mae: 0.0932 - mse: 0.0146 - val_loss: 0.0616 - val_mae: 0.0808 - val_mse: 0.0112\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0661 - mae: 0.0954 - mse: 0.0156 - val_loss: 0.0607 - val_mae: 0.0821 - val_mse: 0.0116\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 185us/step - loss: 0.0652 - mae: 0.0963 - mse: 0.0156 - val_loss: 0.0599 - val_mae: 0.0842 - val_mse: 0.0122\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0643 - mae: 0.0979 - mse: 0.0159 - val_loss: 0.0585 - val_mae: 0.0800 - val_mse: 0.0109\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0629 - mae: 0.0954 - mse: 0.0152 - val_loss: 0.0576 - val_mae: 0.0799 - val_mse: 0.0110\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0622 - mae: 0.0952 - mse: 0.0157 - val_loss: 0.0568 - val_mae: 0.0807 - val_mse: 0.0113\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0604 - mae: 0.0910 - mse: 0.0142 - val_loss: 0.0561 - val_mae: 0.0819 - val_mse: 0.0117\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0588 - mae: 0.0903 - mse: 0.0136 - val_loss: 0.0546 - val_mae: 0.0747 - val_mse: 0.0097\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0589 - mae: 0.0908 - mse: 0.0140 - val_loss: 0.0543 - val_mae: 0.0804 - val_mse: 0.0113\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0581 - mae: 0.0926 - mse: 0.0144 - val_loss: 0.0532 - val_mae: 0.0755 - val_mse: 0.0100\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0578 - mae: 0.0911 - mse: 0.0144 - val_loss: 0.0524 - val_mae: 0.0756 - val_mse: 0.0100\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0575 - mae: 0.0924 - mse: 0.0147 - val_loss: 0.0517 - val_mae: 0.0752 - val_mse: 0.0100\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0562 - mae: 0.0927 - mse: 0.0143 - val_loss: 0.0510 - val_mae: 0.0760 - val_mse: 0.0102\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0539 - mae: 0.0880 - mse: 0.0128 - val_loss: 0.0501 - val_mae: 0.0732 - val_mse: 0.0094\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0540 - mae: 0.0885 - mse: 0.0131 - val_loss: 0.0496 - val_mae: 0.0761 - val_mse: 0.0101\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0535 - mae: 0.0906 - mse: 0.0143 - val_loss: 0.0488 - val_mae: 0.0729 - val_mse: 0.0093\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0529 - mae: 0.0890 - mse: 0.0137 - val_loss: 0.0482 - val_mae: 0.0761 - val_mse: 0.0102\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0530 - mae: 0.0919 - mse: 0.0144 - val_loss: 0.0476 - val_mae: 0.0756 - val_mse: 0.0101\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0515 - mae: 0.0888 - mse: 0.0135 - val_loss: 0.0466 - val_mae: 0.0716 - val_mse: 0.0089\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0490 - mae: 0.0820 - mse: 0.0111 - val_loss: 0.0461 - val_mae: 0.0738 - val_mse: 0.0096\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0500 - mae: 0.0870 - mse: 0.0132 - val_loss: 0.0455 - val_mae: 0.0714 - val_mse: 0.0092\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0494 - mae: 0.0868 - mse: 0.0130 - val_loss: 0.0453 - val_mae: 0.0762 - val_mse: 0.0104\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0490 - mae: 0.0906 - mse: 0.0138 - val_loss: 0.0443 - val_mae: 0.0709 - val_mse: 0.0089\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0492 - mae: 0.0892 - mse: 0.0138 - val_loss: 0.0438 - val_mae: 0.0729 - val_mse: 0.0094\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 127us/step - loss: 0.0468 - mae: 0.0837 - mse: 0.0123 - val_loss: 0.0432 - val_mae: 0.0724 - val_mse: 0.0093\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0472 - mae: 0.0867 - mse: 0.0128 - val_loss: 0.0425 - val_mae: 0.0700 - val_mse: 0.0088\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0465 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0421 - val_mae: 0.0719 - val_mse: 0.0093\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0467 - mae: 0.0889 - mse: 0.0136 - val_loss: 0.0416 - val_mae: 0.0708 - val_mse: 0.0090\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0459 - mae: 0.0883 - mse: 0.0133 - val_loss: 0.0413 - val_mae: 0.0736 - val_mse: 0.0098\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0444 - mae: 0.0852 - mse: 0.0125 - val_loss: 0.0406 - val_mae: 0.0688 - val_mse: 0.0083\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0445 - mae: 0.0861 - mse: 0.0122 - val_loss: 0.0401 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0437 - mae: 0.0843 - mse: 0.0121 - val_loss: 0.0397 - val_mae: 0.0707 - val_mse: 0.0091\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0435 - mae: 0.0869 - mse: 0.0125 - val_loss: 0.0392 - val_mae: 0.0678 - val_mse: 0.0081\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0431 - mae: 0.0851 - mse: 0.0122 - val_loss: 0.0389 - val_mae: 0.0702 - val_mse: 0.0089\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0437 - mae: 0.0890 - mse: 0.0136 - val_loss: 0.0385 - val_mae: 0.0713 - val_mse: 0.0091\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0428 - mae: 0.0852 - mse: 0.0131 - val_loss: 0.0382 - val_mae: 0.0722 - val_mse: 0.0092\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0448 - mae: 0.0924 - mse: 0.0154 - val_loss: 0.0379 - val_mae: 0.0726 - val_mse: 0.0093\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0420 - mae: 0.0845 - mse: 0.0128 - val_loss: 0.0373 - val_mae: 0.0701 - val_mse: 0.0089\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0415 - mae: 0.0879 - mse: 0.0128 - val_loss: 0.0371 - val_mae: 0.0704 - val_mse: 0.0086\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mae: 0.0853 - mse: 0.0126 - val_loss: 0.0368 - val_mae: 0.0725 - val_mse: 0.0095\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0406 - mae: 0.0858 - mse: 0.0127 - val_loss: 0.0363 - val_mae: 0.0674 - val_mse: 0.0081\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0406 - mae: 0.0841 - mse: 0.0124 - val_loss: 0.0359 - val_mae: 0.0689 - val_mse: 0.0087\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0399 - mae: 0.0841 - mse: 0.0123 - val_loss: 0.0356 - val_mae: 0.0691 - val_mse: 0.0087\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0398 - mae: 0.0870 - mse: 0.0128 - val_loss: 0.0354 - val_mae: 0.0663 - val_mse: 0.0078\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0401 - mae: 0.0836 - mse: 0.0124 - val_loss: 0.0350 - val_mae: 0.0674 - val_mse: 0.0079\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0388 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0346 - val_mae: 0.0696 - val_mse: 0.0087\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0385 - mae: 0.0842 - mse: 0.0121 - val_loss: 0.0346 - val_mae: 0.0719 - val_mse: 0.0093\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0380 - mae: 0.0819 - mse: 0.0121 - val_loss: 0.0342 - val_mae: 0.0694 - val_mse: 0.0086\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0382 - mae: 0.0850 - mse: 0.0123 - val_loss: 0.0339 - val_mae: 0.0696 - val_mse: 0.0084\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0380 - mae: 0.0857 - mse: 0.0123 - val_loss: 0.0335 - val_mae: 0.0690 - val_mse: 0.0085\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0371 - mae: 0.0817 - mse: 0.0119 - val_loss: 0.0333 - val_mae: 0.0691 - val_mse: 0.0084\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0379 - mae: 0.0869 - mse: 0.0129 - val_loss: 0.0332 - val_mae: 0.0703 - val_mse: 0.0089\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0364 - mae: 0.0831 - mse: 0.0118 - val_loss: 0.0332 - val_mae: 0.0720 - val_mse: 0.0093\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0368 - mae: 0.0847 - mse: 0.0125 - val_loss: 0.0329 - val_mae: 0.0713 - val_mse: 0.0093\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0366 - mae: 0.0849 - mse: 0.0123 - val_loss: 0.0324 - val_mae: 0.0691 - val_mse: 0.0087\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0366 - mae: 0.0843 - mse: 0.0124 - val_loss: 0.0324 - val_mae: 0.0700 - val_mse: 0.0086\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0363 - mae: 0.0842 - mse: 0.0122 - val_loss: 0.0321 - val_mae: 0.0695 - val_mse: 0.0087\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0359 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0318 - val_mae: 0.0705 - val_mse: 0.0091\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0346 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0318 - val_mae: 0.0723 - val_mse: 0.0095\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0363 - mae: 0.0900 - mse: 0.0135 - val_loss: 0.0314 - val_mae: 0.0685 - val_mse: 0.0084\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0350 - mae: 0.0825 - mse: 0.0115 - val_loss: 0.0314 - val_mae: 0.0716 - val_mse: 0.0093\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0335 - mae: 0.0785 - mse: 0.0106 - val_loss: 0.0312 - val_mae: 0.0706 - val_mse: 0.0090\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0338 - mae: 0.0805 - mse: 0.0109 - val_loss: 0.0310 - val_mae: 0.0709 - val_mse: 0.0090\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0344 - mae: 0.0819 - mse: 0.0117 - val_loss: 0.0304 - val_mae: 0.0666 - val_mse: 0.0080\n",
      "Epoch 139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.0334 - mae: 0.0792 - mse: 0.0107 - val_loss: 0.0302 - val_mae: 0.0660 - val_mse: 0.0077\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0341 - mae: 0.0825 - mse: 0.0114 - val_loss: 0.0303 - val_mae: 0.0697 - val_mse: 0.0084\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0338 - mae: 0.0815 - mse: 0.0118 - val_loss: 0.0302 - val_mae: 0.0703 - val_mse: 0.0085\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0333 - mae: 0.0802 - mse: 0.0110 - val_loss: 0.0297 - val_mae: 0.0677 - val_mse: 0.0082\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0331 - mae: 0.0812 - mse: 0.0111 - val_loss: 0.0296 - val_mae: 0.0676 - val_mse: 0.0080\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0331 - mae: 0.0817 - mse: 0.0114 - val_loss: 0.0293 - val_mae: 0.0661 - val_mse: 0.0077\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0339 - mae: 0.0823 - mse: 0.0122 - val_loss: 0.0292 - val_mae: 0.0673 - val_mse: 0.0080\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0332 - mae: 0.0823 - mse: 0.0116 - val_loss: 0.0290 - val_mae: 0.0668 - val_mse: 0.0079\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0323 - mae: 0.0789 - mse: 0.0108 - val_loss: 0.0288 - val_mae: 0.0669 - val_mse: 0.0079\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0329 - mae: 0.0823 - mse: 0.0117 - val_loss: 0.0288 - val_mae: 0.0692 - val_mse: 0.0085\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0326 - mae: 0.0833 - mse: 0.0117 - val_loss: 0.0286 - val_mae: 0.0679 - val_mse: 0.0081\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0325 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0284 - val_mae: 0.0678 - val_mse: 0.0081\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0325 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0286 - val_mae: 0.0704 - val_mse: 0.0088\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0318 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0283 - val_mae: 0.0690 - val_mse: 0.0085\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0315 - mae: 0.0805 - mse: 0.0113 - val_loss: 0.0282 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0311 - mae: 0.0815 - mse: 0.0111 - val_loss: 0.0277 - val_mae: 0.0656 - val_mse: 0.0076\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0306 - mae: 0.0774 - mse: 0.0101 - val_loss: 0.0276 - val_mae: 0.0680 - val_mse: 0.0079\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0313 - mae: 0.0805 - mse: 0.0111 - val_loss: 0.0277 - val_mae: 0.0700 - val_mse: 0.0085\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0316 - mae: 0.0840 - mse: 0.0118 - val_loss: 0.0277 - val_mae: 0.0693 - val_mse: 0.0081\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0312 - mae: 0.0798 - mse: 0.0115 - val_loss: 0.0273 - val_mae: 0.0674 - val_mse: 0.0078\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0312 - mae: 0.0789 - mse: 0.0114 - val_loss: 0.0275 - val_mae: 0.0714 - val_mse: 0.0087\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0311 - mae: 0.0826 - mse: 0.0119 - val_loss: 0.0275 - val_mae: 0.0722 - val_mse: 0.0091\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0306 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0271 - val_mae: 0.0691 - val_mse: 0.0083\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0306 - mae: 0.0819 - mse: 0.0116 - val_loss: 0.0270 - val_mae: 0.0708 - val_mse: 0.0089\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0299 - mae: 0.0792 - mse: 0.0110 - val_loss: 0.0268 - val_mae: 0.0692 - val_mse: 0.0085\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0309 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0266 - val_mae: 0.0694 - val_mse: 0.0086\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0301 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0264 - val_mae: 0.0673 - val_mse: 0.0080\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0297 - mae: 0.0782 - mse: 0.0109 - val_loss: 0.0263 - val_mae: 0.0665 - val_mse: 0.0078\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0292 - mae: 0.0770 - mse: 0.0101 - val_loss: 0.0262 - val_mae: 0.0698 - val_mse: 0.0086\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0293 - mae: 0.0803 - mse: 0.0110 - val_loss: 0.0261 - val_mae: 0.0667 - val_mse: 0.0077\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0302 - mae: 0.0812 - mse: 0.0118 - val_loss: 0.0260 - val_mae: 0.0701 - val_mse: 0.0087\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0295 - mae: 0.0817 - mse: 0.0116 - val_loss: 0.0257 - val_mae: 0.0661 - val_mse: 0.0077\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0284 - mae: 0.0753 - mse: 0.0098 - val_loss: 0.0255 - val_mae: 0.0649 - val_mse: 0.0074\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0291 - mae: 0.0792 - mse: 0.0107 - val_loss: 0.0254 - val_mae: 0.0669 - val_mse: 0.0078\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0282 - mae: 0.0776 - mse: 0.0103 - val_loss: 0.0254 - val_mae: 0.0690 - val_mse: 0.0083\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0288 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0252 - val_mae: 0.0671 - val_mse: 0.0077\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0280 - mae: 0.0771 - mse: 0.0103 - val_loss: 0.0250 - val_mae: 0.0676 - val_mse: 0.0078\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0287 - mae: 0.0814 - mse: 0.0111 - val_loss: 0.0248 - val_mae: 0.0676 - val_mse: 0.0078\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0290 - mae: 0.0803 - mse: 0.0117 - val_loss: 0.0250 - val_mae: 0.0700 - val_mse: 0.0084\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0274 - mae: 0.0777 - mse: 0.0103 - val_loss: 0.0246 - val_mae: 0.0671 - val_mse: 0.0079\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0275 - mae: 0.0782 - mse: 0.0101 - val_loss: 0.0245 - val_mae: 0.0679 - val_mse: 0.0081\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0279 - mae: 0.0789 - mse: 0.0107 - val_loss: 0.0244 - val_mae: 0.0675 - val_mse: 0.0079\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0294 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0245 - val_mae: 0.0688 - val_mse: 0.0083\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0276 - mae: 0.0777 - mse: 0.0108 - val_loss: 0.0243 - val_mae: 0.0692 - val_mse: 0.0083\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0274 - mae: 0.0794 - mse: 0.0110 - val_loss: 0.0241 - val_mae: 0.0689 - val_mse: 0.0081\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0281 - mae: 0.0832 - mse: 0.0118 - val_loss: 0.0240 - val_mae: 0.0676 - val_mse: 0.0080\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0270 - mae: 0.0783 - mse: 0.0104 - val_loss: 0.0237 - val_mae: 0.0661 - val_mse: 0.0075\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0276 - mae: 0.0799 - mse: 0.0109 - val_loss: 0.0238 - val_mae: 0.0676 - val_mse: 0.0079\n",
      "Epoch 187/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0271 - mae: 0.0793 - mse: 0.0106 - val_loss: 0.0238 - val_mae: 0.0689 - val_mse: 0.0080\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0272 - mae: 0.0803 - mse: 0.0113 - val_loss: 0.0237 - val_mae: 0.0687 - val_mse: 0.0079\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0270 - mae: 0.0802 - mse: 0.0109 - val_loss: 0.0236 - val_mae: 0.0693 - val_mse: 0.0080\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0273 - mae: 0.0805 - mse: 0.0110 - val_loss: 0.0234 - val_mae: 0.0688 - val_mse: 0.0081\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0270 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0232 - val_mae: 0.0642 - val_mse: 0.0071\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0275 - mae: 0.0820 - mse: 0.0111 - val_loss: 0.0229 - val_mae: 0.0655 - val_mse: 0.0074\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0268 - mae: 0.0802 - mse: 0.0109 - val_loss: 0.0230 - val_mae: 0.0652 - val_mse: 0.0072\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0268 - mae: 0.0784 - mse: 0.0107 - val_loss: 0.0229 - val_mae: 0.0683 - val_mse: 0.0079\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0271 - mae: 0.0841 - mse: 0.0116 - val_loss: 0.0231 - val_mae: 0.0718 - val_mse: 0.0088\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0271 - mae: 0.0839 - mse: 0.0120 - val_loss: 0.0228 - val_mae: 0.0676 - val_mse: 0.0075\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0783 - mse: 0.0106 - val_loss: 0.0228 - val_mae: 0.0691 - val_mse: 0.0079\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0801 - mse: 0.0111 - val_loss: 0.0226 - val_mae: 0.0683 - val_mse: 0.0077\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0266 - mae: 0.0815 - mse: 0.0113 - val_loss: 0.0224 - val_mae: 0.0667 - val_mse: 0.0074\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0259 - mae: 0.0786 - mse: 0.0105 - val_loss: 0.0225 - val_mae: 0.0675 - val_mse: 0.0077\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0268 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0223 - val_mae: 0.0686 - val_mse: 0.0079\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0259 - mae: 0.0791 - mse: 0.0109 - val_loss: 0.0222 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0253 - mae: 0.0773 - mse: 0.0103 - val_loss: 0.0221 - val_mae: 0.0642 - val_mse: 0.0069\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0256 - mae: 0.0792 - mse: 0.0103 - val_loss: 0.0221 - val_mae: 0.0685 - val_mse: 0.0078\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0264 - mae: 0.0830 - mse: 0.0117 - val_loss: 0.0219 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0258 - mae: 0.0786 - mse: 0.0110 - val_loss: 0.0218 - val_mae: 0.0659 - val_mse: 0.0072\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0259 - mae: 0.0811 - mse: 0.0113 - val_loss: 0.0218 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0261 - mae: 0.0829 - mse: 0.0116 - val_loss: 0.0218 - val_mae: 0.0682 - val_mse: 0.0076\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0260 - mae: 0.0827 - mse: 0.0116 - val_loss: 0.0216 - val_mae: 0.0669 - val_mse: 0.0073\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0254 - mae: 0.0794 - mse: 0.0108 - val_loss: 0.0215 - val_mae: 0.0669 - val_mse: 0.0074\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0257 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0214 - val_mae: 0.0684 - val_mse: 0.0078\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0250 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0214 - val_mae: 0.0688 - val_mse: 0.0080\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0257 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0210 - val_mae: 0.0647 - val_mse: 0.0071\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0253 - mae: 0.0784 - mse: 0.0113 - val_loss: 0.0211 - val_mae: 0.0676 - val_mse: 0.0077\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0255 - mae: 0.0810 - mse: 0.0116 - val_loss: 0.0215 - val_mae: 0.0721 - val_mse: 0.0089\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0247 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0210 - val_mae: 0.0692 - val_mse: 0.0080\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0252 - mae: 0.0804 - mse: 0.0114 - val_loss: 0.0210 - val_mae: 0.0688 - val_mse: 0.0080\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0250 - mae: 0.0805 - mse: 0.0113 - val_loss: 0.0208 - val_mae: 0.0671 - val_mse: 0.0075\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0240 - mae: 0.0774 - mse: 0.0100 - val_loss: 0.0208 - val_mae: 0.0681 - val_mse: 0.0076\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0250 - mae: 0.0809 - mse: 0.0113 - val_loss: 0.0207 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0242 - mae: 0.0766 - mse: 0.0104 - val_loss: 0.0209 - val_mae: 0.0695 - val_mse: 0.0081\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0239 - mae: 0.0782 - mse: 0.0105 - val_loss: 0.0207 - val_mae: 0.0693 - val_mse: 0.0079\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0249 - mae: 0.0817 - mse: 0.0116 - val_loss: 0.0204 - val_mae: 0.0679 - val_mse: 0.0076\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0246 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0204 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0247 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0204 - val_mae: 0.0687 - val_mse: 0.0078\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0242 - mae: 0.0808 - mse: 0.0112 - val_loss: 0.0203 - val_mae: 0.0670 - val_mse: 0.0074\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0238 - mae: 0.0783 - mse: 0.0105 - val_loss: 0.0203 - val_mae: 0.0695 - val_mse: 0.0080\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0242 - mae: 0.0812 - mse: 0.0111 - val_loss: 0.0199 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0240 - mae: 0.0802 - mse: 0.0108 - val_loss: 0.0200 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0239 - mae: 0.0783 - mse: 0.0110 - val_loss: 0.0200 - val_mae: 0.0676 - val_mse: 0.0075\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0236 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0201 - val_mae: 0.0704 - val_mse: 0.0083\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0237 - mae: 0.0803 - mse: 0.0112 - val_loss: 0.0197 - val_mae: 0.0668 - val_mse: 0.0074\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0240 - mae: 0.0819 - mse: 0.0114 - val_loss: 0.0197 - val_mae: 0.0685 - val_mse: 0.0077\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0241 - mae: 0.0822 - mse: 0.0114 - val_loss: 0.0198 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 235/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 124us/step - loss: 0.0235 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0194 - val_mae: 0.0659 - val_mse: 0.0072\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0238 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0195 - val_mae: 0.0667 - val_mse: 0.0073\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0235 - mae: 0.0783 - mse: 0.0109 - val_loss: 0.0193 - val_mae: 0.0662 - val_mse: 0.0073\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0244 - mae: 0.0824 - mse: 0.0121 - val_loss: 0.0196 - val_mae: 0.0693 - val_mse: 0.0078\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0231 - mae: 0.0785 - mse: 0.0107 - val_loss: 0.0193 - val_mae: 0.0682 - val_mse: 0.0077\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0232 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0192 - val_mae: 0.0673 - val_mse: 0.0076\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0240 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0195 - val_mae: 0.0704 - val_mse: 0.0082\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0236 - mae: 0.0835 - mse: 0.0115 - val_loss: 0.0193 - val_mae: 0.0671 - val_mse: 0.0073\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0236 - mae: 0.0821 - mse: 0.0113 - val_loss: 0.0195 - val_mae: 0.0711 - val_mse: 0.0083\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0227 - mae: 0.0796 - mse: 0.0107 - val_loss: 0.0192 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0227 - mae: 0.0797 - mse: 0.0107 - val_loss: 0.0190 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0222 - mae: 0.0758 - mse: 0.0101 - val_loss: 0.0190 - val_mae: 0.0675 - val_mse: 0.0076\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0233 - mae: 0.0820 - mse: 0.0115 - val_loss: 0.0189 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0231 - mae: 0.0816 - mse: 0.0113 - val_loss: 0.0189 - val_mae: 0.0695 - val_mse: 0.0080\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 132us/step - loss: 0.0230 - mae: 0.0811 - mse: 0.0114 - val_loss: 0.0190 - val_mae: 0.0705 - val_mse: 0.0082\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0230 - mae: 0.0830 - mse: 0.0115 - val_loss: 0.0187 - val_mae: 0.0660 - val_mse: 0.0071\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0233 - mae: 0.0819 - mse: 0.0116 - val_loss: 0.0192 - val_mae: 0.0731 - val_mse: 0.0088\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0234 - mae: 0.0845 - mse: 0.0124 - val_loss: 0.0188 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0230 - mae: 0.0813 - mse: 0.0114 - val_loss: 0.0187 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0227 - mae: 0.0811 - mse: 0.0111 - val_loss: 0.0188 - val_mae: 0.0692 - val_mse: 0.0076\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0230 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0188 - val_mae: 0.0711 - val_mse: 0.0081\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0236 - mae: 0.0839 - mse: 0.0123 - val_loss: 0.0186 - val_mae: 0.0703 - val_mse: 0.0081\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0222 - mae: 0.0804 - mse: 0.0111 - val_loss: 0.0187 - val_mae: 0.0715 - val_mse: 0.0085\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0233 - mae: 0.0835 - mse: 0.0123 - val_loss: 0.0185 - val_mae: 0.0706 - val_mse: 0.0083\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0223 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0184 - val_mae: 0.0685 - val_mse: 0.0077\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0222 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0184 - val_mae: 0.0684 - val_mse: 0.0077\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0225 - mae: 0.0798 - mse: 0.0114 - val_loss: 0.0186 - val_mae: 0.0716 - val_mse: 0.0084\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0218 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0183 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0229 - mae: 0.0818 - mse: 0.0117 - val_loss: 0.0183 - val_mae: 0.0684 - val_mse: 0.0077\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0224 - mae: 0.0819 - mse: 0.0115 - val_loss: 0.0185 - val_mae: 0.0717 - val_mse: 0.0084\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0225 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0184 - val_mae: 0.0703 - val_mse: 0.0080\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0229 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0187 - val_mae: 0.0735 - val_mse: 0.0088\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0225 - mae: 0.0832 - mse: 0.0119 - val_loss: 0.0181 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0222 - mae: 0.0796 - mse: 0.0111 - val_loss: 0.0183 - val_mae: 0.0702 - val_mse: 0.0080\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0224 - mae: 0.0798 - mse: 0.0116 - val_loss: 0.0181 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0217 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0180 - val_mae: 0.0678 - val_mse: 0.0077\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0224 - mae: 0.0806 - mse: 0.0117 - val_loss: 0.0181 - val_mae: 0.0698 - val_mse: 0.0080\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0225 - mae: 0.0828 - mse: 0.0119 - val_loss: 0.0178 - val_mae: 0.0680 - val_mse: 0.0077\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0228 - mae: 0.0838 - mse: 0.0122 - val_loss: 0.0180 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0225 - mae: 0.0822 - mse: 0.0119 - val_loss: 0.0179 - val_mae: 0.0686 - val_mse: 0.0077\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0220 - mae: 0.0813 - mse: 0.0114 - val_loss: 0.0177 - val_mae: 0.0676 - val_mse: 0.0076\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0219 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0180 - val_mae: 0.0704 - val_mse: 0.0082\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0223 - mae: 0.0818 - mse: 0.0120 - val_loss: 0.0179 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0229 - mae: 0.0848 - mse: 0.0123 - val_loss: 0.0179 - val_mae: 0.0702 - val_mse: 0.0082\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0225 - mae: 0.0839 - mse: 0.0124 - val_loss: 0.0180 - val_mae: 0.0711 - val_mse: 0.0082\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0222 - mae: 0.0830 - mse: 0.0119 - val_loss: 0.0176 - val_mae: 0.0690 - val_mse: 0.0079\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0218 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0175 - val_mae: 0.0661 - val_mse: 0.0072\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0219 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0174 - val_mae: 0.0674 - val_mse: 0.0075\n",
      "Epoch 283/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 120us/step - loss: 0.0224 - mae: 0.0831 - mse: 0.0119 - val_loss: 0.0178 - val_mae: 0.0706 - val_mse: 0.0080\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0220 - mae: 0.0820 - mse: 0.0116 - val_loss: 0.0176 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0218 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0175 - val_mae: 0.0674 - val_mse: 0.0074\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0222 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0175 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0217 - mae: 0.0797 - mse: 0.0111 - val_loss: 0.0177 - val_mae: 0.0709 - val_mse: 0.0082\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0176 - val_mae: 0.0702 - val_mse: 0.0080\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0223 - mae: 0.0829 - mse: 0.0121 - val_loss: 0.0175 - val_mae: 0.0709 - val_mse: 0.0083\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0223 - mae: 0.0834 - mse: 0.0123 - val_loss: 0.0178 - val_mae: 0.0727 - val_mse: 0.0084\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0222 - mae: 0.0835 - mse: 0.0122 - val_loss: 0.0175 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0213 - mae: 0.0799 - mse: 0.0110 - val_loss: 0.0175 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0818 - mse: 0.0113 - val_loss: 0.0174 - val_mae: 0.0698 - val_mse: 0.0078\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0223 - mae: 0.0856 - mse: 0.0124 - val_loss: 0.0173 - val_mae: 0.0694 - val_mse: 0.0078\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0216 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0174 - val_mae: 0.0705 - val_mse: 0.0081\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0225 - mae: 0.0854 - mse: 0.0127 - val_loss: 0.0174 - val_mae: 0.0695 - val_mse: 0.0077\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0223 - mae: 0.0836 - mse: 0.0123 - val_loss: 0.0175 - val_mae: 0.0725 - val_mse: 0.0086\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0811 - mse: 0.0113 - val_loss: 0.0173 - val_mae: 0.0686 - val_mse: 0.0075\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0220 - mae: 0.0823 - mse: 0.0119 - val_loss: 0.0175 - val_mae: 0.0720 - val_mse: 0.0085\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0171 - val_mae: 0.0671 - val_mse: 0.0074\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0226 - mae: 0.0852 - mse: 0.0128 - val_loss: 0.0172 - val_mae: 0.0695 - val_mse: 0.0079\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0220 - mae: 0.0840 - mse: 0.0121 - val_loss: 0.0172 - val_mae: 0.0697 - val_mse: 0.0078\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0216 - mae: 0.0828 - mse: 0.0117 - val_loss: 0.0172 - val_mae: 0.0712 - val_mse: 0.0082\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0210 - mae: 0.0806 - mse: 0.0112 - val_loss: 0.0169 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0214 - mae: 0.0818 - mse: 0.0118 - val_loss: 0.0171 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0219 - mae: 0.0832 - mse: 0.0122 - val_loss: 0.0169 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0225 - mae: 0.0852 - mse: 0.0128 - val_loss: 0.0172 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0825 - mse: 0.0119 - val_loss: 0.0170 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0213 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0169 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0218 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0167 - val_mae: 0.0666 - val_mse: 0.0072\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0220 - mae: 0.0847 - mse: 0.0124 - val_loss: 0.0171 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0214 - mae: 0.0826 - mse: 0.0117 - val_loss: 0.0168 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0217 - mae: 0.0835 - mse: 0.0120 - val_loss: 0.0170 - val_mae: 0.0709 - val_mse: 0.0081\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0218 - mae: 0.0838 - mse: 0.0125 - val_loss: 0.0173 - val_mae: 0.0732 - val_mse: 0.0087\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0829 - mse: 0.0118 - val_loss: 0.0170 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0216 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0169 - val_mae: 0.0714 - val_mse: 0.0083\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0210 - mae: 0.0817 - mse: 0.0117 - val_loss: 0.0172 - val_mae: 0.0730 - val_mse: 0.0086\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0211 - mae: 0.0811 - mse: 0.0117 - val_loss: 0.0170 - val_mae: 0.0721 - val_mse: 0.0083\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0215 - mae: 0.0839 - mse: 0.0123 - val_loss: 0.0170 - val_mae: 0.0725 - val_mse: 0.0085\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0213 - mae: 0.0847 - mse: 0.0123 - val_loss: 0.0168 - val_mae: 0.0699 - val_mse: 0.0079\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0220 - mae: 0.0858 - mse: 0.0126 - val_loss: 0.0166 - val_mae: 0.0681 - val_mse: 0.0075\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0219 - mae: 0.0852 - mse: 0.0125 - val_loss: 0.0171 - val_mae: 0.0725 - val_mse: 0.0083\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0824 - mse: 0.0117 - val_loss: 0.0167 - val_mae: 0.0710 - val_mse: 0.0080\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0808 - mse: 0.0112 - val_loss: 0.0166 - val_mae: 0.0697 - val_mse: 0.0077\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0219 - mae: 0.0863 - mse: 0.0129 - val_loss: 0.0167 - val_mae: 0.0715 - val_mse: 0.0082\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0210 - mae: 0.0826 - mse: 0.0118 - val_loss: 0.0167 - val_mae: 0.0702 - val_mse: 0.0079\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0207 - mae: 0.0817 - mse: 0.0114 - val_loss: 0.0164 - val_mae: 0.0652 - val_mse: 0.0070\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0166 - val_mae: 0.0704 - val_mse: 0.0080\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0220 - mae: 0.0857 - mse: 0.0130 - val_loss: 0.0167 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0842 - mse: 0.0123 - val_loss: 0.0166 - val_mae: 0.0713 - val_mse: 0.0082\n",
      "Epoch 331/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 110us/step - loss: 0.0229 - mae: 0.0894 - mse: 0.0140 - val_loss: 0.0170 - val_mae: 0.0744 - val_mse: 0.0090\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0865 - mse: 0.0129 - val_loss: 0.0167 - val_mae: 0.0714 - val_mse: 0.0083\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0841 - mse: 0.0120 - val_loss: 0.0166 - val_mae: 0.0717 - val_mse: 0.0082\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0207 - mae: 0.0820 - mse: 0.0116 - val_loss: 0.0165 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0828 - mse: 0.0121 - val_loss: 0.0166 - val_mae: 0.0715 - val_mse: 0.0081\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0212 - mae: 0.0841 - mse: 0.0122 - val_loss: 0.0170 - val_mae: 0.0744 - val_mse: 0.0090\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0221 - mae: 0.0867 - mse: 0.0134 - val_loss: 0.0167 - val_mae: 0.0718 - val_mse: 0.0082\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0211 - mae: 0.0839 - mse: 0.0121 - val_loss: 0.0164 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mae: 0.0821 - mse: 0.0115 - val_loss: 0.0165 - val_mae: 0.0705 - val_mse: 0.0080\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0217 - mae: 0.0858 - mse: 0.0128 - val_loss: 0.0162 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0214 - mae: 0.0834 - mse: 0.0121 - val_loss: 0.0162 - val_mae: 0.0681 - val_mse: 0.0077\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0208 - mae: 0.0822 - mse: 0.0118 - val_loss: 0.0162 - val_mae: 0.0689 - val_mse: 0.0078\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0214 - mae: 0.0849 - mse: 0.0126 - val_loss: 0.0162 - val_mae: 0.0663 - val_mse: 0.0071\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0215 - mae: 0.0838 - mse: 0.0123 - val_loss: 0.0164 - val_mae: 0.0701 - val_mse: 0.0080\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0210 - mae: 0.0850 - mse: 0.0124 - val_loss: 0.0163 - val_mae: 0.0691 - val_mse: 0.0078\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0212 - mae: 0.0846 - mse: 0.0123 - val_loss: 0.0167 - val_mae: 0.0735 - val_mse: 0.0086\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0211 - mae: 0.0831 - mse: 0.0123 - val_loss: 0.0164 - val_mae: 0.0716 - val_mse: 0.0082\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mae: 0.0849 - mse: 0.0125 - val_loss: 0.0164 - val_mae: 0.0708 - val_mse: 0.0081\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0835 - mse: 0.0121 - val_loss: 0.0164 - val_mae: 0.0713 - val_mse: 0.0081\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0217 - mae: 0.0857 - mse: 0.0129 - val_loss: 0.0164 - val_mae: 0.0709 - val_mse: 0.0081\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0210 - mae: 0.0841 - mse: 0.0122 - val_loss: 0.0162 - val_mae: 0.0699 - val_mse: 0.0078\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0210 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0651 - val_mse: 0.0068\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0207 - mae: 0.0808 - mse: 0.0114 - val_loss: 0.0160 - val_mae: 0.0681 - val_mse: 0.0074\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0220 - mae: 0.0864 - mse: 0.0133 - val_loss: 0.0164 - val_mae: 0.0711 - val_mse: 0.0080\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0207 - mae: 0.0829 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0689 - val_mse: 0.0075\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0211 - mae: 0.0833 - mse: 0.0120 - val_loss: 0.0164 - val_mae: 0.0721 - val_mse: 0.0084\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0214 - mae: 0.0866 - mse: 0.0129 - val_loss: 0.0161 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0209 - mae: 0.0827 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0831 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0666 - val_mse: 0.0072\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0212 - mae: 0.0852 - mse: 0.0122 - val_loss: 0.0159 - val_mae: 0.0662 - val_mse: 0.0071\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0210 - mae: 0.0830 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0206 - mae: 0.0810 - mse: 0.0115 - val_loss: 0.0159 - val_mae: 0.0675 - val_mse: 0.0073\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0207 - mae: 0.0832 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0210 - mae: 0.0835 - mse: 0.0121 - val_loss: 0.0161 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0852 - mse: 0.0126 - val_loss: 0.0162 - val_mae: 0.0715 - val_mse: 0.0083\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0826 - mse: 0.0115 - val_loss: 0.0161 - val_mae: 0.0683 - val_mse: 0.0075\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0201 - mae: 0.0807 - mse: 0.0112 - val_loss: 0.0159 - val_mae: 0.0687 - val_mse: 0.0076\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0159 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0833 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0199 - mae: 0.0801 - mse: 0.0110 - val_loss: 0.0160 - val_mae: 0.0698 - val_mse: 0.0079\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0200 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0162 - val_mae: 0.0726 - val_mse: 0.0085\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0204 - mae: 0.0850 - mse: 0.0121 - val_loss: 0.0159 - val_mae: 0.0696 - val_mse: 0.0078\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0840 - mse: 0.0120 - val_loss: 0.0157 - val_mae: 0.0674 - val_mse: 0.0074\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0807 - mse: 0.0117 - val_loss: 0.0158 - val_mae: 0.0681 - val_mse: 0.0075\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0206 - mae: 0.0834 - mse: 0.0120 - val_loss: 0.0159 - val_mae: 0.0696 - val_mse: 0.0078\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0838 - mse: 0.0120 - val_loss: 0.0161 - val_mae: 0.0709 - val_mse: 0.0080\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0203 - mae: 0.0834 - mse: 0.0117 - val_loss: 0.0160 - val_mae: 0.0714 - val_mse: 0.0081\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0206 - mae: 0.0827 - mse: 0.0120 - val_loss: 0.0156 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0834 - mse: 0.0119 - val_loss: 0.0159 - val_mae: 0.0700 - val_mse: 0.0077\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0216 - mae: 0.0863 - mse: 0.0131 - val_loss: 0.0159 - val_mae: 0.0693 - val_mse: 0.0076\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0207 - mae: 0.0834 - mse: 0.0120 - val_loss: 0.0155 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0801 - mse: 0.0115 - val_loss: 0.0158 - val_mae: 0.0699 - val_mse: 0.0079\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0827 - mse: 0.0117 - val_loss: 0.0155 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0816 - mse: 0.0116 - val_loss: 0.0156 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0201 - mae: 0.0817 - mse: 0.0115 - val_loss: 0.0156 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0214 - mae: 0.0859 - mse: 0.0129 - val_loss: 0.0157 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0206 - mae: 0.0825 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0680 - val_mse: 0.0075\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0822 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0648 - val_mse: 0.0069\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0207 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0155 - val_mae: 0.0664 - val_mse: 0.0072\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0805 - mse: 0.0114 - val_loss: 0.0156 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0208 - mae: 0.0849 - mse: 0.0124 - val_loss: 0.0155 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0205 - mae: 0.0823 - mse: 0.0119 - val_loss: 0.0159 - val_mae: 0.0706 - val_mse: 0.0078\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0203 - mae: 0.0830 - mse: 0.0120 - val_loss: 0.0156 - val_mae: 0.0683 - val_mse: 0.0075\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0211 - mae: 0.0849 - mse: 0.0128 - val_loss: 0.0158 - val_mae: 0.0715 - val_mse: 0.0082\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0202 - mae: 0.0825 - mse: 0.0119 - val_loss: 0.0154 - val_mae: 0.0662 - val_mse: 0.0071\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0204 - mae: 0.0821 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0708 - val_mse: 0.0081\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0833 - mse: 0.0118 - val_loss: 0.0156 - val_mae: 0.0697 - val_mse: 0.0078\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0830 - mse: 0.0117 - val_loss: 0.0157 - val_mae: 0.0707 - val_mse: 0.0081\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0200 - mae: 0.0837 - mse: 0.0117 - val_loss: 0.0155 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0825 - mse: 0.0122 - val_loss: 0.0153 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0823 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0709 - val_mse: 0.0080\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0848 - mse: 0.0124 - val_loss: 0.0156 - val_mae: 0.0697 - val_mse: 0.0077\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0206 - mae: 0.0850 - mse: 0.0124 - val_loss: 0.0154 - val_mae: 0.0676 - val_mse: 0.0074\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0207 - mae: 0.0836 - mse: 0.0124 - val_loss: 0.0155 - val_mae: 0.0679 - val_mse: 0.0074\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0201 - mae: 0.0812 - mse: 0.0117 - val_loss: 0.0158 - val_mae: 0.0708 - val_mse: 0.0079\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0198 - mae: 0.0819 - mse: 0.0114 - val_loss: 0.0156 - val_mae: 0.0701 - val_mse: 0.0078\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0812 - mse: 0.0113 - val_loss: 0.0155 - val_mae: 0.0701 - val_mse: 0.0079\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0797 - mse: 0.0107 - val_loss: 0.0155 - val_mae: 0.0689 - val_mse: 0.0076\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0200 - mae: 0.0807 - mse: 0.0117 - val_loss: 0.0153 - val_mae: 0.0667 - val_mse: 0.0071\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0196 - mae: 0.0814 - mse: 0.0111 - val_loss: 0.0153 - val_mae: 0.0664 - val_mse: 0.0071\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0810 - mse: 0.0115 - val_loss: 0.0153 - val_mae: 0.0678 - val_mse: 0.0074\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0202 - mae: 0.0823 - mse: 0.0120 - val_loss: 0.0155 - val_mae: 0.0700 - val_mse: 0.0080\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0198 - mae: 0.0813 - mse: 0.0116 - val_loss: 0.0154 - val_mae: 0.0695 - val_mse: 0.0078\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0204 - mae: 0.0848 - mse: 0.0123 - val_loss: 0.0158 - val_mae: 0.0724 - val_mse: 0.0083\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0201 - mae: 0.0841 - mse: 0.0121 - val_loss: 0.0153 - val_mae: 0.0683 - val_mse: 0.0076\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0806 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0811 - mse: 0.0112 - val_loss: 0.0150 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0199 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0152 - val_mae: 0.0665 - val_mse: 0.0072\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0205 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0152 - val_mae: 0.0655 - val_mse: 0.0070\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0196 - mae: 0.0800 - mse: 0.0111 - val_loss: 0.0153 - val_mae: 0.0688 - val_mse: 0.0076\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0206 - mae: 0.0855 - mse: 0.0126 - val_loss: 0.0159 - val_mae: 0.0740 - val_mse: 0.0086\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0210 - mae: 0.0870 - mse: 0.0134 - val_loss: 0.0157 - val_mae: 0.0722 - val_mse: 0.0083\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0205 - mae: 0.0849 - mse: 0.0127 - val_loss: 0.0154 - val_mae: 0.0691 - val_mse: 0.0076\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0835 - mse: 0.0122 - val_loss: 0.0155 - val_mae: 0.0699 - val_mse: 0.0077\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0838 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0676 - val_mse: 0.0073\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0201 - mae: 0.0815 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0735 - val_mse: 0.0085\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0198 - mae: 0.0820 - mse: 0.0118 - val_loss: 0.0152 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0204 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0153 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0803 - mse: 0.0115 - val_loss: 0.0152 - val_mae: 0.0679 - val_mse: 0.0073\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0826 - mse: 0.0117 - val_loss: 0.0156 - val_mae: 0.0721 - val_mse: 0.0084\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0199 - mae: 0.0834 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0691 - val_mse: 0.0077\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0198 - mae: 0.0808 - mse: 0.0116 - val_loss: 0.0154 - val_mae: 0.0706 - val_mse: 0.0079\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0837 - mse: 0.0119 - val_loss: 0.0153 - val_mae: 0.0689 - val_mse: 0.0077\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0211 - mae: 0.0871 - mse: 0.0131 - val_loss: 0.0152 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0785 - mse: 0.0104 - val_loss: 0.0153 - val_mae: 0.0691 - val_mse: 0.0077\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0198 - mae: 0.0832 - mse: 0.0117 - val_loss: 0.0153 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0200 - mae: 0.0829 - mse: 0.0120 - val_loss: 0.0152 - val_mae: 0.0688 - val_mse: 0.0076\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0201 - mae: 0.0828 - mse: 0.0119 - val_loss: 0.0152 - val_mae: 0.0689 - val_mse: 0.0076\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0819 - mse: 0.0118 - val_loss: 0.0151 - val_mae: 0.0678 - val_mse: 0.0075\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0195 - mae: 0.0808 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0639 - val_mse: 0.0067\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0826 - mse: 0.0119 - val_loss: 0.0151 - val_mae: 0.0653 - val_mse: 0.0067\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0818 - mse: 0.0117 - val_loss: 0.0152 - val_mae: 0.0687 - val_mse: 0.0075\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0196 - mae: 0.0823 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0198 - mae: 0.0809 - mse: 0.0116 - val_loss: 0.0150 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0837 - mse: 0.0121 - val_loss: 0.0151 - val_mae: 0.0686 - val_mse: 0.0075\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0207 - mae: 0.0854 - mse: 0.0127 - val_loss: 0.0150 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0203 - mae: 0.0829 - mse: 0.0120 - val_loss: 0.0153 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0849 - mse: 0.0124 - val_loss: 0.0151 - val_mae: 0.0686 - val_mse: 0.0076\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0203 - mae: 0.0853 - mse: 0.0123 - val_loss: 0.0151 - val_mae: 0.0683 - val_mse: 0.0074\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0202 - mae: 0.0833 - mse: 0.0121 - val_loss: 0.0149 - val_mae: 0.0668 - val_mse: 0.0072\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0195 - mae: 0.0804 - mse: 0.0114 - val_loss: 0.0148 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0203 - mae: 0.0837 - mse: 0.0122 - val_loss: 0.0151 - val_mae: 0.0675 - val_mse: 0.0072\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0810 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0673 - val_mse: 0.0073\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0199 - mae: 0.0827 - mse: 0.0119 - val_loss: 0.0149 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0853 - mse: 0.0132 - val_loss: 0.0151 - val_mae: 0.0682 - val_mse: 0.0074\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0195 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0673 - val_mse: 0.0072\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0200 - mae: 0.0820 - mse: 0.0119 - val_loss: 0.0147 - val_mae: 0.0657 - val_mse: 0.0069\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0646 - val_mse: 0.0068\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0193 - mae: 0.0799 - mse: 0.0110 - val_loss: 0.0149 - val_mae: 0.0670 - val_mse: 0.0074\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0655 - val_mse: 0.0070\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0202 - mae: 0.0835 - mse: 0.0123 - val_loss: 0.0150 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0814 - mse: 0.0118 - val_loss: 0.0148 - val_mae: 0.0649 - val_mse: 0.0068\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0812 - mse: 0.0113 - val_loss: 0.0150 - val_mae: 0.0685 - val_mse: 0.0074\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0202 - mae: 0.0848 - mse: 0.0124 - val_loss: 0.0149 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0830 - mse: 0.0118 - val_loss: 0.0151 - val_mae: 0.0685 - val_mse: 0.0076\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0195 - mae: 0.0812 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0674 - val_mse: 0.0072\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0203 - mae: 0.0853 - mse: 0.0124 - val_loss: 0.0149 - val_mae: 0.0659 - val_mse: 0.0069\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0826 - mse: 0.0115 - val_loss: 0.0148 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0197 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0149 - val_mae: 0.0648 - val_mse: 0.0066\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0808 - mse: 0.0110 - val_loss: 0.0147 - val_mae: 0.0654 - val_mse: 0.0069\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0192 - mae: 0.0799 - mse: 0.0111 - val_loss: 0.0148 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0837 - mse: 0.0120 - val_loss: 0.0150 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0195 - mae: 0.0820 - mse: 0.0117 - val_loss: 0.0148 - val_mae: 0.0660 - val_mse: 0.0070\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0191 - mae: 0.0802 - mse: 0.0110 - val_loss: 0.0148 - val_mae: 0.0670 - val_mse: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0206 - mae: 0.0847 - mse: 0.0128 - val_loss: 0.0149 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0202 - mae: 0.0834 - mse: 0.0124 - val_loss: 0.0148 - val_mae: 0.0666 - val_mse: 0.0071\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0799 - mse: 0.0112 - val_loss: 0.0149 - val_mae: 0.0680 - val_mse: 0.0073\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0194 - mae: 0.0831 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0629 - val_mse: 0.0065\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0816 - mse: 0.0112 - val_loss: 0.0148 - val_mae: 0.0685 - val_mse: 0.0076\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0815 - mse: 0.0114 - val_loss: 0.0146 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0802 - mse: 0.0116 - val_loss: 0.0145 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0198 - mae: 0.0838 - mse: 0.0120 - val_loss: 0.0148 - val_mae: 0.0655 - val_mse: 0.0067\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0146 - val_mae: 0.0649 - val_mse: 0.0067\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0819 - mse: 0.0118 - val_loss: 0.0147 - val_mae: 0.0674 - val_mse: 0.0072\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0193 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0147 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0823 - mse: 0.0115 - val_loss: 0.0146 - val_mae: 0.0658 - val_mse: 0.0069\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0151 - val_mae: 0.0704 - val_mse: 0.0079\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0198 - mae: 0.0825 - mse: 0.0120 - val_loss: 0.0145 - val_mae: 0.0649 - val_mse: 0.0068\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mae: 0.0834 - mse: 0.0122 - val_loss: 0.0146 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0832 - mse: 0.0121 - val_loss: 0.0146 - val_mae: 0.0650 - val_mse: 0.0070\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0188 - mae: 0.0777 - mse: 0.0107 - val_loss: 0.0146 - val_mae: 0.0661 - val_mse: 0.0071\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0194 - mae: 0.0824 - mse: 0.0115 - val_loss: 0.0146 - val_mae: 0.0660 - val_mse: 0.0071\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0145 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0812 - mse: 0.0115 - val_loss: 0.0145 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0190 - mae: 0.0784 - mse: 0.0109 - val_loss: 0.0150 - val_mae: 0.0697 - val_mse: 0.0079\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0188 - mae: 0.0802 - mse: 0.0111 - val_loss: 0.0144 - val_mae: 0.0642 - val_mse: 0.0067\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0197 - mae: 0.0819 - mse: 0.0117 - val_loss: 0.0144 - val_mae: 0.0647 - val_mse: 0.0068\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0188 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0146 - val_mae: 0.0668 - val_mse: 0.0073\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0774 - mse: 0.0102 - val_loss: 0.0144 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0199 - mae: 0.0818 - mse: 0.0120 - val_loss: 0.0149 - val_mae: 0.0687 - val_mse: 0.0075\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0192 - mae: 0.0800 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0648 - val_mse: 0.0069\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0194 - mae: 0.0805 - mse: 0.0117 - val_loss: 0.0146 - val_mae: 0.0667 - val_mse: 0.0073\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0190 - mae: 0.0801 - mse: 0.0112 - val_loss: 0.0144 - val_mae: 0.0634 - val_mse: 0.0066\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0786 - mse: 0.0109 - val_loss: 0.0145 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0204 - mae: 0.0855 - mse: 0.0127 - val_loss: 0.0146 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0790 - mse: 0.0108 - val_loss: 0.0146 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0798 - mse: 0.0113 - val_loss: 0.0146 - val_mae: 0.0670 - val_mse: 0.0072\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0814 - mse: 0.0116 - val_loss: 0.0144 - val_mae: 0.0640 - val_mse: 0.0067\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0194 - mae: 0.0802 - mse: 0.0113 - val_loss: 0.0145 - val_mae: 0.0657 - val_mse: 0.0070\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0192 - mae: 0.0815 - mse: 0.0113 - val_loss: 0.0145 - val_mae: 0.0652 - val_mse: 0.0068\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0792 - mse: 0.0106 - val_loss: 0.0142 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0814 - mse: 0.0113 - val_loss: 0.0144 - val_mae: 0.0632 - val_mse: 0.0066\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0144 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0194 - mae: 0.0801 - mse: 0.0117 - val_loss: 0.0145 - val_mae: 0.0662 - val_mse: 0.0070\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0801 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0654 - val_mse: 0.0070\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0782 - mse: 0.0106 - val_loss: 0.0149 - val_mae: 0.0701 - val_mse: 0.0080\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0191 - mae: 0.0808 - mse: 0.0116 - val_loss: 0.0145 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0183 - mae: 0.0780 - mse: 0.0104 - val_loss: 0.0142 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0801 - mse: 0.0112 - val_loss: 0.0146 - val_mae: 0.0679 - val_mse: 0.0075\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0793 - mse: 0.0109 - val_loss: 0.0142 - val_mae: 0.0627 - val_mse: 0.0065\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0190 - mae: 0.0803 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0634 - val_mse: 0.0065\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0192 - mae: 0.0800 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0684 - val_mse: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0193 - mae: 0.0825 - mse: 0.0116 - val_loss: 0.0142 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0792 - mse: 0.0109 - val_loss: 0.0144 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0796 - mse: 0.0111 - val_loss: 0.0140 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0184 - mae: 0.0775 - mse: 0.0105 - val_loss: 0.0143 - val_mae: 0.0658 - val_mse: 0.0071\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0197 - mae: 0.0817 - mse: 0.0119 - val_loss: 0.0148 - val_mae: 0.0706 - val_mse: 0.0079\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0200 - mae: 0.0843 - mse: 0.0125 - val_loss: 0.0146 - val_mae: 0.0679 - val_mse: 0.0073\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0800 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0804 - mse: 0.0113 - val_loss: 0.0141 - val_mae: 0.0614 - val_mse: 0.0062\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0193 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0640 - val_mse: 0.0068\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0846 - mse: 0.0126 - val_loss: 0.0142 - val_mae: 0.0651 - val_mse: 0.0070\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0191 - mae: 0.0811 - mse: 0.0115 - val_loss: 0.0142 - val_mae: 0.0642 - val_mse: 0.0067\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0793 - mse: 0.0107 - val_loss: 0.0142 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0806 - mse: 0.0115 - val_loss: 0.0141 - val_mae: 0.0627 - val_mse: 0.0065\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0144 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0809 - mse: 0.0113 - val_loss: 0.0143 - val_mae: 0.0650 - val_mse: 0.0066\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0808 - mse: 0.0114 - val_loss: 0.0142 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0190 - mae: 0.0807 - mse: 0.0113 - val_loss: 0.0142 - val_mae: 0.0639 - val_mse: 0.0065\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0191 - mae: 0.0799 - mse: 0.0113 - val_loss: 0.0147 - val_mae: 0.0688 - val_mse: 0.0078\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0843 - mse: 0.0122 - val_loss: 0.0143 - val_mae: 0.0652 - val_mse: 0.0067\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0199 - mae: 0.0836 - mse: 0.0122 - val_loss: 0.0144 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0195 - mae: 0.0814 - mse: 0.0119 - val_loss: 0.0141 - val_mae: 0.0639 - val_mse: 0.0066\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0189 - mae: 0.0795 - mse: 0.0111 - val_loss: 0.0143 - val_mae: 0.0667 - val_mse: 0.0072\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0141 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0795 - mse: 0.0113 - val_loss: 0.0140 - val_mae: 0.0639 - val_mse: 0.0065\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0192 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0636 - val_mse: 0.0065\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0801 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0197 - mae: 0.0817 - mse: 0.0120 - val_loss: 0.0143 - val_mae: 0.0673 - val_mse: 0.0072\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0809 - mse: 0.0115 - val_loss: 0.0140 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0807 - mse: 0.0115 - val_loss: 0.0143 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0788 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0636 - val_mse: 0.0065\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0200 - mae: 0.0843 - mse: 0.0124 - val_loss: 0.0142 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mae: 0.0799 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0643 - val_mse: 0.0065\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0198 - mae: 0.0825 - mse: 0.0121 - val_loss: 0.0142 - val_mae: 0.0657 - val_mse: 0.0071\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0786 - mse: 0.0111 - val_loss: 0.0139 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0187 - mae: 0.0803 - mse: 0.0110 - val_loss: 0.0144 - val_mae: 0.0676 - val_mse: 0.0074\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0773 - mse: 0.0104 - val_loss: 0.0139 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0790 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0183 - mae: 0.0791 - mse: 0.0107 - val_loss: 0.0143 - val_mae: 0.0663 - val_mse: 0.0072\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0794 - mse: 0.0107 - val_loss: 0.0139 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0139 - val_mae: 0.0636 - val_mse: 0.0066\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0194 - mae: 0.0828 - mse: 0.0118 - val_loss: 0.0141 - val_mae: 0.0656 - val_mse: 0.0069\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0794 - mse: 0.0109 - val_loss: 0.0140 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0193 - mae: 0.0824 - mse: 0.0116 - val_loss: 0.0143 - val_mae: 0.0672 - val_mse: 0.0074\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0791 - mse: 0.0110 - val_loss: 0.0138 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0187 - mae: 0.0780 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0644 - val_mse: 0.0068\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0190 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0141 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0783 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0785 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0184 - mae: 0.0789 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0649 - val_mse: 0.0069\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0110 - val_loss: 0.0140 - val_mae: 0.0630 - val_mse: 0.0062\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0783 - mse: 0.0107 - val_loss: 0.0139 - val_mae: 0.0640 - val_mse: 0.0066\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mae: 0.0790 - mse: 0.0113 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0792 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0626 - val_mse: 0.0064\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0796 - mse: 0.0109 - val_loss: 0.0137 - val_mae: 0.0600 - val_mse: 0.0060\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0784 - mse: 0.0107 - val_loss: 0.0140 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0809 - mse: 0.0116 - val_loss: 0.0138 - val_mae: 0.0620 - val_mse: 0.0063\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0771 - mse: 0.0104 - val_loss: 0.0140 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0782 - mse: 0.0103 - val_loss: 0.0139 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0194 - mae: 0.0813 - mse: 0.0118 - val_loss: 0.0143 - val_mae: 0.0673 - val_mse: 0.0074\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0768 - mse: 0.0105 - val_loss: 0.0141 - val_mae: 0.0658 - val_mse: 0.0069\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0188 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0139 - val_mae: 0.0638 - val_mse: 0.0067\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0790 - mse: 0.0112 - val_loss: 0.0141 - val_mae: 0.0658 - val_mse: 0.0068\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0183 - mae: 0.0777 - mse: 0.0106 - val_loss: 0.0139 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0785 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0637 - val_mse: 0.0067\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0790 - mse: 0.0107 - val_loss: 0.0142 - val_mae: 0.0665 - val_mse: 0.0071\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0761 - mse: 0.0101 - val_loss: 0.0139 - val_mae: 0.0638 - val_mse: 0.0067\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0189 - mae: 0.0800 - mse: 0.0114 - val_loss: 0.0140 - val_mae: 0.0651 - val_mse: 0.0069\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0807 - mse: 0.0111 - val_loss: 0.0139 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0810 - mse: 0.0117 - val_loss: 0.0141 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0812 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0643 - val_mse: 0.0067\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0792 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0611 - val_mse: 0.0062\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0780 - mse: 0.0108 - val_loss: 0.0138 - val_mae: 0.0626 - val_mse: 0.0063\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0786 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0782 - mse: 0.0108 - val_loss: 0.0140 - val_mae: 0.0644 - val_mse: 0.0065\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0187 - mae: 0.0802 - mse: 0.0111 - val_loss: 0.0140 - val_mae: 0.0655 - val_mse: 0.0069\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0188 - mae: 0.0810 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0621 - val_mse: 0.0061\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0648 - val_mse: 0.0068\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0193 - mae: 0.0817 - mse: 0.0118 - val_loss: 0.0137 - val_mae: 0.0604 - val_mse: 0.0059\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0783 - mse: 0.0109 - val_loss: 0.0141 - val_mae: 0.0654 - val_mse: 0.0070\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0112 - val_loss: 0.0139 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0764 - mse: 0.0103 - val_loss: 0.0137 - val_mae: 0.0624 - val_mse: 0.0064\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0757 - mse: 0.0096 - val_loss: 0.0135 - val_mae: 0.0595 - val_mse: 0.0058\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0189 - mae: 0.0794 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0182 - mae: 0.0765 - mse: 0.0105 - val_loss: 0.0138 - val_mae: 0.0638 - val_mse: 0.0066\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0109 - val_loss: 0.0136 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0188 - mae: 0.0796 - mse: 0.0112 - val_loss: 0.0134 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0759 - mse: 0.0103 - val_loss: 0.0136 - val_mae: 0.0616 - val_mse: 0.0063\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0176 - mae: 0.0754 - mse: 0.0100 - val_loss: 0.0134 - val_mae: 0.0591 - val_mse: 0.0058\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0762 - mse: 0.0103 - val_loss: 0.0136 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0746 - mse: 0.0100 - val_loss: 0.0135 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0782 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0780 - mse: 0.0110 - val_loss: 0.0137 - val_mae: 0.0629 - val_mse: 0.0066\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0592 - val_mse: 0.0057\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0767 - mse: 0.0101 - val_loss: 0.0138 - val_mae: 0.0648 - val_mse: 0.0067\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0764 - mse: 0.0103 - val_loss: 0.0139 - val_mae: 0.0632 - val_mse: 0.0064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0185 - mae: 0.0793 - mse: 0.0109 - val_loss: 0.0134 - val_mae: 0.0602 - val_mse: 0.0060\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0175 - mae: 0.0738 - mse: 0.0098 - val_loss: 0.0136 - val_mae: 0.0632 - val_mse: 0.0065\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0190 - mae: 0.0798 - mse: 0.0114 - val_loss: 0.0136 - val_mae: 0.0630 - val_mse: 0.0065\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0186 - mae: 0.0798 - mse: 0.0111 - val_loss: 0.0137 - val_mae: 0.0645 - val_mse: 0.0068\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0188 - mae: 0.0795 - mse: 0.0114 - val_loss: 0.0138 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0180 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0135 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0135 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0769 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0621 - val_mse: 0.0061\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0137 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0786 - mse: 0.0108 - val_loss: 0.0136 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0180 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0134 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0109 - val_loss: 0.0136 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0788 - mse: 0.0109 - val_loss: 0.0135 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0607 - val_mse: 0.0059\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0103 - val_loss: 0.0135 - val_mae: 0.0623 - val_mse: 0.0063\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0751 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0781 - mse: 0.0111 - val_loss: 0.0136 - val_mae: 0.0616 - val_mse: 0.0060\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0771 - mse: 0.0104 - val_loss: 0.0134 - val_mae: 0.0606 - val_mse: 0.0059\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0752 - mse: 0.0097 - val_loss: 0.0138 - val_mae: 0.0652 - val_mse: 0.0070\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0781 - mse: 0.0104 - val_loss: 0.0134 - val_mae: 0.0602 - val_mse: 0.0058\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0754 - mse: 0.0098 - val_loss: 0.0133 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0183 - mae: 0.0776 - mse: 0.0108 - val_loss: 0.0137 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0772 - mse: 0.0109 - val_loss: 0.0135 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0753 - mse: 0.0098 - val_loss: 0.0137 - val_mae: 0.0644 - val_mse: 0.0067\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0181 - mae: 0.0774 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0628 - val_mse: 0.0062\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0795 - mse: 0.0108 - val_loss: 0.0138 - val_mae: 0.0637 - val_mse: 0.0064\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0771 - mse: 0.0102 - val_loss: 0.0133 - val_mae: 0.0601 - val_mse: 0.0059\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0750 - mse: 0.0098 - val_loss: 0.0138 - val_mae: 0.0661 - val_mse: 0.0071\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0819 - mse: 0.0119 - val_loss: 0.0135 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0137 - val_mae: 0.0639 - val_mse: 0.0064\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0777 - mse: 0.0103 - val_loss: 0.0137 - val_mae: 0.0646 - val_mse: 0.0068\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0184 - mae: 0.0784 - mse: 0.0109 - val_loss: 0.0133 - val_mae: 0.0596 - val_mse: 0.0058\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0753 - mse: 0.0102 - val_loss: 0.0134 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0174 - mae: 0.0756 - mse: 0.0099 - val_loss: 0.0137 - val_mae: 0.0646 - val_mse: 0.0067\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0179 - mae: 0.0772 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0757 - mse: 0.0105 - val_loss: 0.0134 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0189 - mae: 0.0797 - mse: 0.0114 - val_loss: 0.0135 - val_mae: 0.0631 - val_mse: 0.0065\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0790 - mse: 0.0107 - val_loss: 0.0136 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0186 - mae: 0.0795 - mse: 0.0111 - val_loss: 0.0135 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0181 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0783 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0637 - val_mse: 0.0066\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0759 - mse: 0.0100 - val_loss: 0.0133 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0780 - mse: 0.0107 - val_loss: 0.0134 - val_mae: 0.0608 - val_mse: 0.0060\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0770 - mse: 0.0103 - val_loss: 0.0135 - val_mae: 0.0611 - val_mse: 0.0060\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0179 - mae: 0.0764 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0639 - val_mse: 0.0068\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0798 - mse: 0.0108 - val_loss: 0.0137 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0746 - mse: 0.0094 - val_loss: 0.0135 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0772 - mse: 0.0105 - val_loss: 0.0131 - val_mae: 0.0579 - val_mse: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0182 - mae: 0.0765 - mse: 0.0105 - val_loss: 0.0133 - val_mae: 0.0621 - val_mse: 0.0063\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0761 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0131 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0176 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0640 - val_mse: 0.0064\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0793 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0643 - val_mse: 0.0068\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0175 - mae: 0.0767 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0614 - val_mse: 0.0059\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0787 - mse: 0.0104 - val_loss: 0.0133 - val_mae: 0.0627 - val_mse: 0.0064\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0756 - mse: 0.0100 - val_loss: 0.0139 - val_mae: 0.0677 - val_mse: 0.0073\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0188 - mae: 0.0822 - mse: 0.0117 - val_loss: 0.0132 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0774 - mse: 0.0106 - val_loss: 0.0134 - val_mae: 0.0628 - val_mse: 0.0064\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0767 - mse: 0.0104 - val_loss: 0.0131 - val_mae: 0.0595 - val_mse: 0.0057\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0762 - mse: 0.0101 - val_loss: 0.0134 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0762 - mse: 0.0102 - val_loss: 0.0130 - val_mae: 0.0596 - val_mse: 0.0059\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0130 - val_mae: 0.0592 - val_mse: 0.0057\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0769 - mse: 0.0105 - val_loss: 0.0131 - val_mae: 0.0598 - val_mse: 0.0058\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0792 - mse: 0.0113 - val_loss: 0.0132 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0181 - mae: 0.0781 - mse: 0.0107 - val_loss: 0.0136 - val_mae: 0.0646 - val_mse: 0.0067\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0787 - mse: 0.0110 - val_loss: 0.0135 - val_mae: 0.0635 - val_mse: 0.0066\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0765 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0608 - val_mse: 0.0061\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0133 - val_mae: 0.0623 - val_mse: 0.0064\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0790 - mse: 0.0110 - val_loss: 0.0131 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0168 - mae: 0.0730 - mse: 0.0093 - val_loss: 0.0132 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0185 - mae: 0.0801 - mse: 0.0111 - val_loss: 0.0131 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0178 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0616 - val_mse: 0.0061\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0136 - val_mae: 0.0658 - val_mse: 0.0068\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0133 - val_mae: 0.0624 - val_mse: 0.0062\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0102 - val_loss: 0.0136 - val_mae: 0.0657 - val_mse: 0.0070\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0178 - mae: 0.0785 - mse: 0.0105 - val_loss: 0.0132 - val_mae: 0.0619 - val_mse: 0.0063\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0184 - mae: 0.0805 - mse: 0.0112 - val_loss: 0.0132 - val_mae: 0.0622 - val_mse: 0.0063\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0787 - mse: 0.0111 - val_loss: 0.0134 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0172 - mae: 0.0764 - mse: 0.0100 - val_loss: 0.0135 - val_mae: 0.0627 - val_mse: 0.0061\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0748 - mse: 0.0098 - val_loss: 0.0130 - val_mae: 0.0605 - val_mse: 0.0060\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0186 - mae: 0.0790 - mse: 0.0111 - val_loss: 0.0132 - val_mae: 0.0627 - val_mse: 0.0064\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0773 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0764 - mse: 0.0101 - val_loss: 0.0132 - val_mae: 0.0618 - val_mse: 0.0063\n",
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0795 - mse: 0.0110 - val_loss: 0.0130 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0172 - mae: 0.0742 - mse: 0.0097 - val_loss: 0.0133 - val_mae: 0.0641 - val_mse: 0.0067\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0177 - mae: 0.0763 - mse: 0.0104 - val_loss: 0.0133 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0750 - mse: 0.0102 - val_loss: 0.0135 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0176 - mae: 0.0781 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0575 - val_mse: 0.0055\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0174 - mae: 0.0765 - mse: 0.0098 - val_loss: 0.0131 - val_mae: 0.0623 - val_mse: 0.0063\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0133 - val_mae: 0.0634 - val_mse: 0.0066\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0765 - mse: 0.0102 - val_loss: 0.0130 - val_mae: 0.0611 - val_mse: 0.0061\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0176 - mae: 0.0780 - mse: 0.0103 - val_loss: 0.0131 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0788 - mse: 0.0106 - val_loss: 0.0133 - val_mae: 0.0617 - val_mse: 0.0060\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0810 - mse: 0.0118 - val_loss: 0.0131 - val_mae: 0.0626 - val_mse: 0.0063\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0182 - mae: 0.0779 - mse: 0.0109 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0175 - mae: 0.0771 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0625 - val_mse: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0759 - mse: 0.0101 - val_loss: 0.0131 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0185 - mae: 0.0798 - mse: 0.0113 - val_loss: 0.0133 - val_mae: 0.0635 - val_mse: 0.0065\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0177 - mae: 0.0778 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0571 - val_mse: 0.0054\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0180 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0132 - val_mae: 0.0609 - val_mse: 0.0059\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0767 - mse: 0.0104 - val_loss: 0.0130 - val_mae: 0.0600 - val_mse: 0.0057\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0179 - mae: 0.0762 - mse: 0.0104 - val_loss: 0.0132 - val_mae: 0.0626 - val_mse: 0.0064\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0749 - mse: 0.0099 - val_loss: 0.0134 - val_mae: 0.0641 - val_mse: 0.0067\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0783 - mse: 0.0104 - val_loss: 0.0128 - val_mae: 0.0568 - val_mse: 0.0053\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0756 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0584 - val_mse: 0.0056\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0759 - mse: 0.0102 - val_loss: 0.0132 - val_mae: 0.0635 - val_mse: 0.0063\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0174 - mae: 0.0776 - mse: 0.0101 - val_loss: 0.0127 - val_mae: 0.0595 - val_mse: 0.0058\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0180 - mae: 0.0775 - mse: 0.0106 - val_loss: 0.0135 - val_mae: 0.0660 - val_mse: 0.0072\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0167 - mae: 0.0755 - mse: 0.0096 - val_loss: 0.0131 - val_mae: 0.0629 - val_mse: 0.0064\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0128 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0171 - mae: 0.0755 - mse: 0.0097 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0065\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0178 - mae: 0.0782 - mse: 0.0107 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0064\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0780 - mse: 0.0106 - val_loss: 0.0129 - val_mae: 0.0615 - val_mse: 0.0061\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0172 - mae: 0.0754 - mse: 0.0100 - val_loss: 0.0130 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0168 - mae: 0.0735 - mse: 0.0096 - val_loss: 0.0129 - val_mae: 0.0612 - val_mse: 0.0061\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0783 - mse: 0.0110 - val_loss: 0.0128 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0182 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0130 - val_mae: 0.0625 - val_mse: 0.0063\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mae: 0.0759 - mse: 0.0097 - val_loss: 0.0126 - val_mae: 0.0578 - val_mse: 0.0054\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0179 - mae: 0.0782 - mse: 0.0107 - val_loss: 0.0130 - val_mae: 0.0621 - val_mse: 0.0063\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0182 - mae: 0.0780 - mse: 0.0110 - val_loss: 0.0128 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0787 - mse: 0.0110 - val_loss: 0.0130 - val_mae: 0.0624 - val_mse: 0.0063\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0757 - mse: 0.0101 - val_loss: 0.0132 - val_mae: 0.0637 - val_mse: 0.0065\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0183 - mae: 0.0795 - mse: 0.0112 - val_loss: 0.0129 - val_mae: 0.0610 - val_mse: 0.0061\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0099 - val_loss: 0.0135 - val_mae: 0.0654 - val_mse: 0.0069\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0751 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0601 - val_mse: 0.0060\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0768 - mse: 0.0102 - val_loss: 0.0128 - val_mae: 0.0603 - val_mse: 0.0060\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0167 - mae: 0.0745 - mse: 0.0094 - val_loss: 0.0129 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0184 - mae: 0.0772 - mse: 0.0109 - val_loss: 0.0127 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 121us/step - loss: 0.0177 - mae: 0.0784 - mse: 0.0104 - val_loss: 0.0131 - val_mae: 0.0609 - val_mse: 0.0058\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0171 - mae: 0.0747 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0054\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0169 - mae: 0.0752 - mse: 0.0095 - val_loss: 0.0128 - val_mae: 0.0609 - val_mse: 0.0061\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0762 - mse: 0.0100 - val_loss: 0.0130 - val_mae: 0.0628 - val_mse: 0.0065\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0177 - mae: 0.0776 - mse: 0.0106 - val_loss: 0.0128 - val_mae: 0.0597 - val_mse: 0.0058\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0759 - mse: 0.0100 - val_loss: 0.0128 - val_mae: 0.0612 - val_mse: 0.0061\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0167 - mae: 0.0730 - mse: 0.0096 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0054\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0173 - mae: 0.0750 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0623 - val_mse: 0.0061\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0180 - mae: 0.0787 - mse: 0.0108 - val_loss: 0.0129 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0126 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0757 - mse: 0.0099 - val_loss: 0.0129 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0790 - mse: 0.0108 - val_loss: 0.0126 - val_mae: 0.0594 - val_mse: 0.0058\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0132 - val_mae: 0.0629 - val_mse: 0.0061\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0778 - mse: 0.0105 - val_loss: 0.0126 - val_mae: 0.0576 - val_mse: 0.0054\n",
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.0741 - mse: 0.0098 - val_loss: 0.0126 - val_mae: 0.0596 - val_mse: 0.0057\n",
      "Epoch 762/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0184 - mae: 0.0796 - mse: 0.0113 - val_loss: 0.0127 - val_mae: 0.0604 - val_mse: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0184 - mae: 0.0806 - mse: 0.0113 - val_loss: 0.0132 - val_mae: 0.0650 - val_mse: 0.0069\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0180 - mae: 0.0792 - mse: 0.0111 - val_loss: 0.0126 - val_mae: 0.0589 - val_mse: 0.0057\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0780 - mse: 0.0105 - val_loss: 0.0129 - val_mae: 0.0616 - val_mse: 0.0062\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0170 - mae: 0.0755 - mse: 0.0099 - val_loss: 0.0126 - val_mae: 0.0600 - val_mse: 0.0059\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0773 - mse: 0.0105 - val_loss: 0.0124 - val_mae: 0.0560 - val_mse: 0.0052\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0127 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0173 - mae: 0.0775 - mse: 0.0101 - val_loss: 0.0125 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0742 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0598 - val_mse: 0.0059\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0098 - val_loss: 0.0133 - val_mae: 0.0656 - val_mse: 0.0070\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0166 - mae: 0.0738 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0601 - val_mse: 0.0058\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0760 - mse: 0.0101 - val_loss: 0.0130 - val_mae: 0.0621 - val_mse: 0.0060\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0761 - mse: 0.0103 - val_loss: 0.0126 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0172 - mae: 0.0765 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0766 - mse: 0.0102 - val_loss: 0.0128 - val_mae: 0.0614 - val_mse: 0.0059\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0750 - mse: 0.0098 - val_loss: 0.0126 - val_mae: 0.0603 - val_mse: 0.0059\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0774 - mse: 0.0103 - val_loss: 0.0126 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0160 - mae: 0.0713 - mse: 0.0088 - val_loss: 0.0126 - val_mae: 0.0605 - val_mse: 0.0060\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0175 - mae: 0.0759 - mse: 0.0104 - val_loss: 0.0126 - val_mae: 0.0601 - val_mse: 0.0059\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0759 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0613 - val_mse: 0.0058\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0174 - mae: 0.0766 - mse: 0.0102 - val_loss: 0.0126 - val_mae: 0.0594 - val_mse: 0.0058\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0733 - mse: 0.0094 - val_loss: 0.0127 - val_mae: 0.0605 - val_mse: 0.0058\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0179 - mae: 0.0774 - mse: 0.0109 - val_loss: 0.0127 - val_mae: 0.0600 - val_mse: 0.0058\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0166 - mae: 0.0742 - mse: 0.0094 - val_loss: 0.0128 - val_mae: 0.0621 - val_mse: 0.0062\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0762 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0768 - mse: 0.0102 - val_loss: 0.0131 - val_mae: 0.0641 - val_mse: 0.0065\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0794 - mse: 0.0112 - val_loss: 0.0130 - val_mae: 0.0623 - val_mse: 0.0060\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0768 - mse: 0.0105 - val_loss: 0.0128 - val_mae: 0.0604 - val_mse: 0.0058\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0171 - mae: 0.0762 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0058\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0741 - mse: 0.0094 - val_loss: 0.0125 - val_mae: 0.0595 - val_mse: 0.0056\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0174 - mae: 0.0774 - mse: 0.0103 - val_loss: 0.0128 - val_mae: 0.0617 - val_mse: 0.0062\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.0758 - mse: 0.0099 - val_loss: 0.0127 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0169 - mae: 0.0739 - mse: 0.0095 - val_loss: 0.0126 - val_mae: 0.0609 - val_mse: 0.0060\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mae: 0.0771 - mse: 0.0105 - val_loss: 0.0127 - val_mae: 0.0594 - val_mse: 0.0056\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0167 - mae: 0.0743 - mse: 0.0094 - val_loss: 0.0126 - val_mae: 0.0593 - val_mse: 0.0057\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.0758 - mse: 0.0102 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0055\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0163 - mae: 0.0737 - mse: 0.0093 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0762 - mse: 0.0101 - val_loss: 0.0128 - val_mae: 0.0620 - val_mse: 0.0061\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0165 - mae: 0.0747 - mse: 0.0096 - val_loss: 0.0127 - val_mae: 0.0621 - val_mse: 0.0062\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.0742 - mse: 0.009 - 0s 104us/step - loss: 0.0168 - mae: 0.0756 - mse: 0.0097 - val_loss: 0.0127 - val_mae: 0.0620 - val_mse: 0.0062\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0175 - mae: 0.0768 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0633 - val_mse: 0.0065\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0173 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0130 - val_mae: 0.0634 - val_mse: 0.0064\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0174 - mae: 0.0755 - mse: 0.0105 - val_loss: 0.0126 - val_mae: 0.0608 - val_mse: 0.0061\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0760 - mse: 0.0105 - val_loss: 0.0125 - val_mae: 0.0602 - val_mse: 0.0059\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0169 - mae: 0.0748 - mse: 0.0098 - val_loss: 0.0127 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0168 - mae: 0.0745 - mse: 0.0097 - val_loss: 0.0129 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0181 - mae: 0.0800 - mse: 0.0112 - val_loss: 0.0128 - val_mae: 0.0618 - val_mse: 0.0062\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0751 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 810/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0170 - mae: 0.0742 - mse: 0.0098 - val_loss: 0.0124 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0173 - mae: 0.0765 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0776 - mse: 0.0106 - val_loss: 0.0127 - val_mae: 0.0617 - val_mse: 0.0061\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0166 - mae: 0.0743 - mse: 0.0095 - val_loss: 0.0125 - val_mae: 0.0599 - val_mse: 0.0058\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0753 - mse: 0.0096 - val_loss: 0.0127 - val_mae: 0.0617 - val_mse: 0.0059\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 130us/step - loss: 0.0177 - mae: 0.0772 - mse: 0.0106 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0758 - mse: 0.0101 - val_loss: 0.0124 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0164 - mae: 0.0723 - mse: 0.0093 - val_loss: 0.0124 - val_mae: 0.0596 - val_mse: 0.0058\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0173 - mae: 0.0772 - mse: 0.0102 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0167 - mae: 0.0739 - mse: 0.0095 - val_loss: 0.0126 - val_mae: 0.0607 - val_mse: 0.0060\n",
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0173 - mae: 0.0767 - mse: 0.0103 - val_loss: 0.0120 - val_mae: 0.0558 - val_mse: 0.0051\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0173 - mae: 0.0769 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0606 - val_mse: 0.0060\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0757 - mse: 0.0098 - val_loss: 0.0120 - val_mae: 0.0558 - val_mse: 0.0050\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0779 - mse: 0.0102 - val_loss: 0.0122 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0770 - mse: 0.0108 - val_loss: 0.0123 - val_mae: 0.0584 - val_mse: 0.0056\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0163 - mae: 0.0723 - mse: 0.0093 - val_loss: 0.0127 - val_mae: 0.0614 - val_mse: 0.0061\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0769 - mse: 0.0104 - val_loss: 0.0122 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0763 - mse: 0.0101 - val_loss: 0.0123 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0161 - mae: 0.0726 - mse: 0.0091 - val_loss: 0.0123 - val_mae: 0.0574 - val_mse: 0.0053\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0773 - mse: 0.0103 - val_loss: 0.0125 - val_mae: 0.0600 - val_mse: 0.0057\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0780 - mse: 0.0105 - val_loss: 0.0125 - val_mae: 0.0600 - val_mse: 0.0059\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0174 - mae: 0.0770 - mse: 0.0104 - val_loss: 0.0129 - val_mae: 0.0637 - val_mse: 0.0065\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0167 - mae: 0.0749 - mse: 0.0096 - val_loss: 0.0122 - val_mae: 0.0576 - val_mse: 0.0054\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0763 - mse: 0.0100 - val_loss: 0.0124 - val_mae: 0.0596 - val_mse: 0.0056\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0171 - mae: 0.0766 - mse: 0.0101 - val_loss: 0.0123 - val_mae: 0.0592 - val_mse: 0.0056\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0161 - mae: 0.0732 - mse: 0.0091 - val_loss: 0.0125 - val_mae: 0.0592 - val_mse: 0.0055\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0766 - mse: 0.0103 - val_loss: 0.0122 - val_mae: 0.0583 - val_mse: 0.0055\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0770 - mse: 0.0102 - val_loss: 0.0122 - val_mae: 0.0589 - val_mse: 0.0055\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0166 - mae: 0.0755 - mse: 0.0096 - val_loss: 0.0128 - val_mae: 0.0638 - val_mse: 0.0065\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0165 - mae: 0.0735 - mse: 0.0096 - val_loss: 0.0124 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0171 - mae: 0.0757 - mse: 0.0102 - val_loss: 0.0126 - val_mae: 0.0613 - val_mse: 0.0060\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0747 - mse: 0.0099 - val_loss: 0.0122 - val_mae: 0.0584 - val_mse: 0.0054\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0164 - mae: 0.0732 - mse: 0.0092 - val_loss: 0.0122 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0169 - mae: 0.0761 - mse: 0.0098 - val_loss: 0.0124 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0168 - mae: 0.0742 - mse: 0.0096 - val_loss: 0.0128 - val_mae: 0.0629 - val_mse: 0.0063\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0168 - mae: 0.0744 - mse: 0.0101 - val_loss: 0.0126 - val_mae: 0.0608 - val_mse: 0.0059\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0170 - mae: 0.0758 - mse: 0.0100 - val_loss: 0.0124 - val_mae: 0.0591 - val_mse: 0.0057\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0167 - mae: 0.0749 - mse: 0.0097 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0776 - mse: 0.0105 - val_loss: 0.0124 - val_mae: 0.0593 - val_mse: 0.0054\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0167 - mae: 0.0742 - mse: 0.0094 - val_loss: 0.0123 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0166 - mae: 0.0729 - mse: 0.0093 - val_loss: 0.0126 - val_mae: 0.0611 - val_mse: 0.0058\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00850: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_medium = build_medium_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_medium.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "model_medium.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['medium'] = model_medium.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_201 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,821\n",
      "Trainable params: 4,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.6086 - mae: 0.1588 - mse: 0.0349 - val_loss: 0.5534 - val_mae: 0.1180 - val_mse: 0.0200\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.5555 - mae: 0.1306 - mse: 0.0242 - val_loss: 0.5133 - val_mae: 0.1022 - val_mse: 0.0154\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.5185 - mae: 0.1223 - mse: 0.0214 - val_loss: 0.4805 - val_mae: 0.1026 - val_mse: 0.0156\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.4834 - mae: 0.1224 - mse: 0.0213 - val_loss: 0.4478 - val_mae: 0.1022 - val_mse: 0.0155\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.4500 - mae: 0.1219 - mse: 0.0211 - val_loss: 0.4168 - val_mae: 0.1020 - val_mse: 0.0154\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.4186 - mae: 0.1195 - mse: 0.0204 - val_loss: 0.3884 - val_mae: 0.1000 - val_mse: 0.0149\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.3902 - mae: 0.1169 - mse: 0.0197 - val_loss: 0.3625 - val_mae: 0.1006 - val_mse: 0.0152\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.3641 - mae: 0.1158 - mse: 0.0195 - val_loss: 0.3391 - val_mae: 0.0988 - val_mse: 0.0149\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.3404 - mae: 0.1135 - mse: 0.0190 - val_loss: 0.3174 - val_mae: 0.0982 - val_mse: 0.0149\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.3189 - mae: 0.1124 - mse: 0.0189 - val_loss: 0.2977 - val_mae: 0.0961 - val_mse: 0.0145\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2993 - mae: 0.1109 - mse: 0.0186 - val_loss: 0.2800 - val_mae: 0.0969 - val_mse: 0.0149\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.2818 - mae: 0.1109 - mse: 0.0188 - val_loss: 0.2641 - val_mae: 0.0979 - val_mse: 0.0153\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.2662 - mae: 0.1113 - mse: 0.0191 - val_loss: 0.2501 - val_mae: 0.1010 - val_mse: 0.0162\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.2520 - mae: 0.1148 - mse: 0.0203 - val_loss: 0.2369 - val_mae: 0.1055 - val_mse: 0.0175\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.2389 - mae: 0.1184 - mse: 0.0214 - val_loss: 0.2253 - val_mae: 0.1087 - val_mse: 0.0183\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.2278 - mae: 0.1217 - mse: 0.0224 - val_loss: 0.2153 - val_mae: 0.1088 - val_mse: 0.0182\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2180 - mae: 0.1220 - mse: 0.0225 - val_loss: 0.2065 - val_mae: 0.1136 - val_mse: 0.0197\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2093 - mae: 0.1242 - mse: 0.0232 - val_loss: 0.1988 - val_mae: 0.1248 - val_mse: 0.0230\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.2016 - mae: 0.1287 - mse: 0.0248 - val_loss: 0.1917 - val_mae: 0.1175 - val_mse: 0.0208\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1947 - mae: 0.1261 - mse: 0.0238 - val_loss: 0.1850 - val_mae: 0.1093 - val_mse: 0.0184\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.1883 - mae: 0.1212 - mse: 0.0221 - val_loss: 0.1794 - val_mae: 0.1061 - val_mse: 0.0175\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1826 - mae: 0.1195 - mse: 0.0215 - val_loss: 0.1738 - val_mae: 0.1059 - val_mse: 0.0174\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1770 - mae: 0.1197 - mse: 0.0215 - val_loss: 0.1684 - val_mae: 0.1071 - val_mse: 0.0178\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1714 - mae: 0.1198 - mse: 0.0215 - val_loss: 0.1631 - val_mae: 0.1062 - val_mse: 0.0175\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1665 - mae: 0.1184 - mse: 0.0210 - val_loss: 0.1586 - val_mae: 0.1064 - val_mse: 0.0175\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.1617 - mae: 0.1183 - mse: 0.0209 - val_loss: 0.1538 - val_mae: 0.1086 - val_mse: 0.0181\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.1616 - mae: 0.1216 - mse: 0.024 - 0s 97us/step - loss: 0.1567 - mae: 0.1207 - mse: 0.0217 - val_loss: 0.1491 - val_mae: 0.1052 - val_mse: 0.0172\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1522 - mae: 0.1178 - mse: 0.0207 - val_loss: 0.1450 - val_mae: 0.1050 - val_mse: 0.0171\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1478 - mae: 0.1193 - mse: 0.0212 - val_loss: 0.1407 - val_mae: 0.1034 - val_mse: 0.0166\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1434 - mae: 0.1183 - mse: 0.0209 - val_loss: 0.1366 - val_mae: 0.1024 - val_mse: 0.0163\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1392 - mae: 0.1177 - mse: 0.0206 - val_loss: 0.1327 - val_mae: 0.1010 - val_mse: 0.0158\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.1356 - mae: 0.1160 - mse: 0.0200 - val_loss: 0.1296 - val_mae: 0.1125 - val_mse: 0.0190\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1324 - mae: 0.1243 - mse: 0.0226 - val_loss: 0.1266 - val_mae: 0.1040 - val_mse: 0.0165\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.1295 - mae: 0.1186 - mse: 0.0207 - val_loss: 0.1237 - val_mae: 0.1066 - val_mse: 0.0172\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 160us/step - loss: 0.1266 - mae: 0.1202 - mse: 0.0211 - val_loss: 0.1208 - val_mae: 0.1135 - val_mse: 0.0191\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1235 - mae: 0.1243 - mse: 0.0223 - val_loss: 0.1178 - val_mae: 0.1094 - val_mse: 0.0179\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.1206 - mae: 0.1237 - mse: 0.0221 - val_loss: 0.1149 - val_mae: 0.1045 - val_mse: 0.0164\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1177 - mae: 0.1188 - mse: 0.0205 - val_loss: 0.1121 - val_mae: 0.1029 - val_mse: 0.0160\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1150 - mae: 0.1188 - mse: 0.0204 - val_loss: 0.1094 - val_mae: 0.1016 - val_mse: 0.0156\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.1122 - mae: 0.1160 - mse: 0.0195 - val_loss: 0.1068 - val_mae: 0.1085 - val_mse: 0.0175\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1091 - mae: 0.1216 - mse: 0.0212 - val_loss: 0.1031 - val_mae: 0.1078 - val_mse: 0.0171\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1050 - mae: 0.1182 - mse: 0.0201 - val_loss: 0.0991 - val_mae: 0.1095 - val_mse: 0.0175\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.1013 - mae: 0.1182 - mse: 0.0201 - val_loss: 0.0959 - val_mae: 0.1022 - val_mse: 0.0155\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0985 - mae: 0.1137 - mse: 0.0188 - val_loss: 0.0931 - val_mae: 0.0972 - val_mse: 0.0143\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0957 - mae: 0.1098 - mse: 0.0177 - val_loss: 0.0907 - val_mae: 0.1012 - val_mse: 0.0153\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0933 - mae: 0.1124 - mse: 0.0185 - val_loss: 0.0882 - val_mae: 0.0948 - val_mse: 0.0137\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0910 - mae: 0.1080 - mse: 0.0173 - val_loss: 0.0861 - val_mae: 0.0944 - val_mse: 0.0136\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0886 - mae: 0.1073 - mse: 0.0171 - val_loss: 0.0837 - val_mae: 0.0929 - val_mse: 0.0132\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0865 - mae: 0.1070 - mse: 0.0169 - val_loss: 0.0815 - val_mae: 0.0930 - val_mse: 0.0132\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0842 - mae: 0.1060 - mse: 0.0167 - val_loss: 0.0793 - val_mae: 0.0901 - val_mse: 0.0125\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0822 - mae: 0.1046 - mse: 0.0163 - val_loss: 0.0776 - val_mae: 0.0889 - val_mse: 0.0122\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0805 - mae: 0.1028 - mse: 0.0158 - val_loss: 0.0759 - val_mae: 0.0888 - val_mse: 0.0122\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0787 - mae: 0.1021 - mse: 0.0157 - val_loss: 0.0742 - val_mae: 0.0885 - val_mse: 0.0122\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0770 - mae: 0.1015 - mse: 0.0155 - val_loss: 0.0726 - val_mae: 0.0895 - val_mse: 0.0125\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0754 - mae: 0.1016 - mse: 0.0156 - val_loss: 0.0712 - val_mae: 0.0891 - val_mse: 0.0124\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0740 - mae: 0.1013 - mse: 0.0155 - val_loss: 0.0697 - val_mae: 0.0846 - val_mse: 0.0113\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0727 - mae: 0.0973 - mse: 0.0145 - val_loss: 0.0685 - val_mae: 0.0844 - val_mse: 0.0113\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0714 - mae: 0.0974 - mse: 0.0146 - val_loss: 0.0673 - val_mae: 0.0830 - val_mse: 0.0109\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0702 - mae: 0.0957 - mse: 0.0141 - val_loss: 0.0661 - val_mae: 0.0824 - val_mse: 0.0108\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0689 - mae: 0.0956 - mse: 0.0141 - val_loss: 0.0649 - val_mae: 0.0805 - val_mse: 0.0103\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0678 - mae: 0.0935 - mse: 0.0137 - val_loss: 0.0637 - val_mae: 0.0815 - val_mse: 0.0106\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0665 - mae: 0.0940 - mse: 0.0138 - val_loss: 0.0626 - val_mae: 0.0841 - val_mse: 0.0113\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0653 - mae: 0.0963 - mse: 0.0144 - val_loss: 0.0613 - val_mae: 0.0802 - val_mse: 0.0103\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0642 - mae: 0.0925 - mse: 0.0134 - val_loss: 0.0603 - val_mae: 0.0810 - val_mse: 0.0106\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0631 - mae: 0.0930 - mse: 0.0136 - val_loss: 0.0592 - val_mae: 0.0796 - val_mse: 0.0102\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0620 - mae: 0.0922 - mse: 0.0133 - val_loss: 0.0582 - val_mae: 0.0782 - val_mse: 0.0099\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0610 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0572 - val_mae: 0.0776 - val_mse: 0.0098\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0601 - mae: 0.0908 - mse: 0.0130 - val_loss: 0.0562 - val_mae: 0.0785 - val_mse: 0.0099\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0590 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0552 - val_mae: 0.0783 - val_mse: 0.0099\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0580 - mae: 0.0912 - mse: 0.0131 - val_loss: 0.0542 - val_mae: 0.0791 - val_mse: 0.0101\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0570 - mae: 0.0910 - mse: 0.0130 - val_loss: 0.0532 - val_mae: 0.0796 - val_mse: 0.0102\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0559 - mae: 0.0917 - mse: 0.0131 - val_loss: 0.0521 - val_mae: 0.0775 - val_mse: 0.0097\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0550 - mae: 0.0898 - mse: 0.0127 - val_loss: 0.0513 - val_mae: 0.0774 - val_mse: 0.0097\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0541 - mae: 0.0904 - mse: 0.0128 - val_loss: 0.0505 - val_mae: 0.0753 - val_mse: 0.0092\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 98us/step - loss: 0.0533 - mae: 0.0883 - mse: 0.0122 - val_loss: 0.0497 - val_mae: 0.0762 - val_mse: 0.0094\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0524 - mae: 0.0890 - mse: 0.0124 - val_loss: 0.0489 - val_mae: 0.0797 - val_mse: 0.0102\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0516 - mae: 0.0915 - mse: 0.0130 - val_loss: 0.0480 - val_mae: 0.0770 - val_mse: 0.0095\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0508 - mae: 0.0895 - mse: 0.0125 - val_loss: 0.0472 - val_mae: 0.0757 - val_mse: 0.0092\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0500 - mae: 0.0884 - mse: 0.0122 - val_loss: 0.0464 - val_mae: 0.0754 - val_mse: 0.0092\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0491 - mae: 0.0882 - mse: 0.0122 - val_loss: 0.0457 - val_mae: 0.0747 - val_mse: 0.0090\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0483 - mae: 0.0880 - mse: 0.0121 - val_loss: 0.0448 - val_mae: 0.0750 - val_mse: 0.0090\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0476 - mae: 0.0880 - mse: 0.0121 - val_loss: 0.0441 - val_mae: 0.0758 - val_mse: 0.0092\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0467 - mae: 0.0883 - mse: 0.0121 - val_loss: 0.0433 - val_mae: 0.0777 - val_mse: 0.0096\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 191us/step - loss: 0.0460 - mae: 0.0891 - mse: 0.0123 - val_loss: 0.0427 - val_mae: 0.0788 - val_mse: 0.0098\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0453 - mae: 0.0897 - mse: 0.0124 - val_loss: 0.0420 - val_mae: 0.0779 - val_mse: 0.0096\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0446 - mae: 0.0889 - mse: 0.0122 - val_loss: 0.0412 - val_mae: 0.0756 - val_mse: 0.0091\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 203us/step - loss: 0.0438 - mae: 0.0882 - mse: 0.0121 - val_loss: 0.0405 - val_mae: 0.0734 - val_mse: 0.0086\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0432 - mae: 0.0868 - mse: 0.0117 - val_loss: 0.0399 - val_mae: 0.0757 - val_mse: 0.0091\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0426 - mae: 0.0880 - mse: 0.0120 - val_loss: 0.0392 - val_mae: 0.0749 - val_mse: 0.0089\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0419 - mae: 0.0876 - mse: 0.0119 - val_loss: 0.0386 - val_mae: 0.0730 - val_mse: 0.0084\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0413 - mae: 0.0859 - mse: 0.0115 - val_loss: 0.0380 - val_mae: 0.0738 - val_mse: 0.0086\n",
      "Epoch 92/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 164us/step - loss: 0.0406 - mae: 0.0862 - mse: 0.0115 - val_loss: 0.0374 - val_mae: 0.0731 - val_mse: 0.0085\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0401 - mae: 0.0855 - mse: 0.0114 - val_loss: 0.0368 - val_mae: 0.0753 - val_mse: 0.0089\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0395 - mae: 0.0872 - mse: 0.0117 - val_loss: 0.0362 - val_mae: 0.0718 - val_mse: 0.0082\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0390 - mae: 0.0852 - mse: 0.0113 - val_loss: 0.0357 - val_mae: 0.0715 - val_mse: 0.0081\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 199us/step - loss: 0.0383 - mae: 0.0846 - mse: 0.0111 - val_loss: 0.0352 - val_mae: 0.0705 - val_mse: 0.0079\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0378 - mae: 0.0838 - mse: 0.0109 - val_loss: 0.0347 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0373 - mae: 0.0839 - mse: 0.0110 - val_loss: 0.0342 - val_mae: 0.0741 - val_mse: 0.0087\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0368 - mae: 0.0855 - mse: 0.0113 - val_loss: 0.0337 - val_mae: 0.0717 - val_mse: 0.0082\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0363 - mae: 0.0840 - mse: 0.0110 - val_loss: 0.0332 - val_mae: 0.0712 - val_mse: 0.0081\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0359 - mae: 0.0833 - mse: 0.0108 - val_loss: 0.0327 - val_mae: 0.0703 - val_mse: 0.0079\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0355 - mae: 0.0829 - mse: 0.0107 - val_loss: 0.0324 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0351 - mae: 0.0822 - mse: 0.0106 - val_loss: 0.0320 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0347 - mae: 0.0822 - mse: 0.0106 - val_loss: 0.0316 - val_mae: 0.0684 - val_mse: 0.0075\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0342 - mae: 0.0814 - mse: 0.0104 - val_loss: 0.0311 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0339 - mae: 0.0834 - mse: 0.0109 - val_loss: 0.0308 - val_mae: 0.0710 - val_mse: 0.0080\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0334 - mae: 0.0828 - mse: 0.0108 - val_loss: 0.0304 - val_mae: 0.0682 - val_mse: 0.0075\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0331 - mae: 0.0805 - mse: 0.0103 - val_loss: 0.0301 - val_mae: 0.0685 - val_mse: 0.0075\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0328 - mae: 0.0808 - mse: 0.0103 - val_loss: 0.0297 - val_mae: 0.0690 - val_mse: 0.0076\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0324 - mae: 0.0803 - mse: 0.0102 - val_loss: 0.0294 - val_mae: 0.0708 - val_mse: 0.0080\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0321 - mae: 0.0821 - mse: 0.0106 - val_loss: 0.0291 - val_mae: 0.0677 - val_mse: 0.0074\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0319 - mae: 0.0797 - mse: 0.0101 - val_loss: 0.0288 - val_mae: 0.0694 - val_mse: 0.0077\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0315 - mae: 0.0809 - mse: 0.0104 - val_loss: 0.0284 - val_mae: 0.0681 - val_mse: 0.0074\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0312 - mae: 0.0797 - mse: 0.0101 - val_loss: 0.0282 - val_mae: 0.0693 - val_mse: 0.0077\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0309 - mae: 0.0808 - mse: 0.0103 - val_loss: 0.0280 - val_mae: 0.0670 - val_mse: 0.0072\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0307 - mae: 0.0788 - mse: 0.0099 - val_loss: 0.0276 - val_mae: 0.0692 - val_mse: 0.0077\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0303 - mae: 0.0802 - mse: 0.0102 - val_loss: 0.0273 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0300 - mae: 0.0792 - mse: 0.0100 - val_loss: 0.0270 - val_mae: 0.0671 - val_mse: 0.0072\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0298 - mae: 0.0784 - mse: 0.0099 - val_loss: 0.0268 - val_mae: 0.0677 - val_mse: 0.0073\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0295 - mae: 0.0791 - mse: 0.0100 - val_loss: 0.0264 - val_mae: 0.0684 - val_mse: 0.0075\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 166us/step - loss: 0.0293 - mae: 0.0794 - mse: 0.0101 - val_loss: 0.0263 - val_mae: 0.0668 - val_mse: 0.0072\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0290 - mae: 0.0783 - mse: 0.0099 - val_loss: 0.0261 - val_mae: 0.0676 - val_mse: 0.0073\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0288 - mae: 0.0782 - mse: 0.0098 - val_loss: 0.0258 - val_mae: 0.0669 - val_mse: 0.0072\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0285 - mae: 0.0783 - mse: 0.0098 - val_loss: 0.0256 - val_mae: 0.0657 - val_mse: 0.0069\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0283 - mae: 0.0770 - mse: 0.0096 - val_loss: 0.0253 - val_mae: 0.0672 - val_mse: 0.0072\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0281 - mae: 0.0775 - mse: 0.0097 - val_loss: 0.0250 - val_mae: 0.0698 - val_mse: 0.0077\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0279 - mae: 0.0796 - mse: 0.0101 - val_loss: 0.0249 - val_mae: 0.0659 - val_mse: 0.0070\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0277 - mae: 0.0770 - mse: 0.0096 - val_loss: 0.0248 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0275 - mae: 0.0760 - mse: 0.0093 - val_loss: 0.0247 - val_mae: 0.0645 - val_mse: 0.0067\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0274 - mae: 0.0756 - mse: 0.0093 - val_loss: 0.0245 - val_mae: 0.0650 - val_mse: 0.0068\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0271 - mae: 0.0762 - mse: 0.0094 - val_loss: 0.0244 - val_mae: 0.0642 - val_mse: 0.0066\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 162us/step - loss: 0.0269 - mae: 0.0756 - mse: 0.0092 - val_loss: 0.0242 - val_mae: 0.0638 - val_mse: 0.0065\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0268 - mae: 0.0747 - mse: 0.0090 - val_loss: 0.0239 - val_mae: 0.0662 - val_mse: 0.0070\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 153us/step - loss: 0.0266 - mae: 0.0765 - mse: 0.0094 - val_loss: 0.0238 - val_mae: 0.0651 - val_mse: 0.0068\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0265 - mae: 0.0757 - mse: 0.0093 - val_loss: 0.0237 - val_mae: 0.0666 - val_mse: 0.0070\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 185us/step - loss: 0.0263 - mae: 0.0761 - mse: 0.0093 - val_loss: 0.0235 - val_mae: 0.0655 - val_mse: 0.0068\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0262 - mae: 0.0752 - mse: 0.0092 - val_loss: 0.0233 - val_mae: 0.0652 - val_mse: 0.0068\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 180us/step - loss: 0.0260 - mae: 0.0752 - mse: 0.0091 - val_loss: 0.0233 - val_mae: 0.0641 - val_mse: 0.0065\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0258 - mae: 0.0739 - mse: 0.0089 - val_loss: 0.0231 - val_mae: 0.0641 - val_mse: 0.0066\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0257 - mae: 0.0744 - mse: 0.0090 - val_loss: 0.0230 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0256 - mae: 0.0737 - mse: 0.0088 - val_loss: 0.0228 - val_mae: 0.0643 - val_mse: 0.0066\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0254 - mae: 0.0743 - mse: 0.0089 - val_loss: 0.0228 - val_mae: 0.0623 - val_mse: 0.0062\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 193us/step - loss: 0.0253 - mae: 0.0723 - mse: 0.0085 - val_loss: 0.0227 - val_mae: 0.0633 - val_mse: 0.0064\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0251 - mae: 0.0724 - mse: 0.0085 - val_loss: 0.0224 - val_mae: 0.0640 - val_mse: 0.0065\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0249 - mae: 0.0732 - mse: 0.0087 - val_loss: 0.0224 - val_mae: 0.0627 - val_mse: 0.0063\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0248 - mae: 0.0728 - mse: 0.0086 - val_loss: 0.0224 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 174us/step - loss: 0.0247 - mae: 0.0711 - mse: 0.0082 - val_loss: 0.0221 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 153us/step - loss: 0.0245 - mae: 0.0718 - mse: 0.0084 - val_loss: 0.0219 - val_mae: 0.0635 - val_mse: 0.0064\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0244 - mae: 0.0725 - mse: 0.0085 - val_loss: 0.0220 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0242 - mae: 0.0705 - mse: 0.0081 - val_loss: 0.0218 - val_mae: 0.0613 - val_mse: 0.0060\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0241 - mae: 0.0703 - mse: 0.0080 - val_loss: 0.0216 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0240 - mae: 0.0706 - mse: 0.0081 - val_loss: 0.0217 - val_mae: 0.0630 - val_mse: 0.0063\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0239 - mae: 0.0713 - mse: 0.0082 - val_loss: 0.0214 - val_mae: 0.0612 - val_mse: 0.0060\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0237 - mae: 0.0699 - mse: 0.0080 - val_loss: 0.0213 - val_mae: 0.0622 - val_mse: 0.0062\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0236 - mae: 0.0704 - mse: 0.0081 - val_loss: 0.0211 - val_mae: 0.0628 - val_mse: 0.0063\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 218us/step - loss: 0.0235 - mae: 0.0712 - mse: 0.0082 - val_loss: 0.0211 - val_mae: 0.0618 - val_mse: 0.0061\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 285us/step - loss: 0.0234 - mae: 0.0705 - mse: 0.0081 - val_loss: 0.0209 - val_mae: 0.0627 - val_mse: 0.0063\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 183us/step - loss: 0.0233 - mae: 0.0702 - mse: 0.0081 - val_loss: 0.0209 - val_mae: 0.0632 - val_mse: 0.0064\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0231 - mae: 0.0708 - mse: 0.0082 - val_loss: 0.0208 - val_mae: 0.0603 - val_mse: 0.0058\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0230 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0208 - val_mae: 0.0604 - val_mse: 0.0058\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0230 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0206 - val_mae: 0.0610 - val_mse: 0.0060\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0229 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0205 - val_mae: 0.0605 - val_mse: 0.0059\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0228 - mae: 0.0689 - mse: 0.0077 - val_loss: 0.0205 - val_mae: 0.0620 - val_mse: 0.0061\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0227 - mae: 0.0695 - mse: 0.0078 - val_loss: 0.0204 - val_mae: 0.0600 - val_mse: 0.0058\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0226 - mae: 0.0683 - mse: 0.0076 - val_loss: 0.0203 - val_mae: 0.0611 - val_mse: 0.0060\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0225 - mae: 0.0688 - mse: 0.0077 - val_loss: 0.0203 - val_mae: 0.0599 - val_mse: 0.0057\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0677 - mse: 0.0075 - val_loss: 0.0202 - val_mae: 0.0597 - val_mse: 0.0057\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0223 - mae: 0.0673 - mse: 0.0074 - val_loss: 0.0202 - val_mae: 0.0590 - val_mse: 0.0056\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0223 - mae: 0.0674 - mse: 0.0074 - val_loss: 0.0201 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0222 - mae: 0.0677 - mse: 0.0075 - val_loss: 0.0199 - val_mae: 0.0602 - val_mse: 0.0058\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0221 - mae: 0.0683 - mse: 0.0076 - val_loss: 0.0199 - val_mae: 0.0594 - val_mse: 0.0057\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0220 - mae: 0.0671 - mse: 0.0074 - val_loss: 0.0198 - val_mae: 0.0614 - val_mse: 0.0060\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0219 - mae: 0.0682 - mse: 0.0076 - val_loss: 0.0198 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0218 - mae: 0.0671 - mse: 0.0074 - val_loss: 0.0197 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0217 - mae: 0.0659 - mse: 0.0071 - val_loss: 0.0195 - val_mae: 0.0598 - val_mse: 0.0057\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0216 - mae: 0.0673 - mse: 0.0074 - val_loss: 0.0196 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0216 - mae: 0.0660 - mse: 0.0071 - val_loss: 0.0195 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0214 - mae: 0.0670 - mse: 0.0074 - val_loss: 0.0194 - val_mae: 0.0596 - val_mse: 0.0057\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0213 - mae: 0.0672 - mse: 0.0074 - val_loss: 0.0193 - val_mae: 0.0587 - val_mse: 0.0055\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0213 - mae: 0.0665 - mse: 0.0073 - val_loss: 0.0193 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0212 - mae: 0.0657 - mse: 0.0071 - val_loss: 0.0192 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0211 - mae: 0.0662 - mse: 0.0072 - val_loss: 0.0192 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0211 - mae: 0.0650 - mse: 0.0069 - val_loss: 0.0192 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0211 - mae: 0.0651 - mse: 0.0070 - val_loss: 0.0190 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0210 - mae: 0.0656 - mse: 0.0071 - val_loss: 0.0189 - val_mae: 0.0587 - val_mse: 0.0056\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0659 - mse: 0.0072 - val_loss: 0.0188 - val_mae: 0.0590 - val_mse: 0.0056\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0208 - mae: 0.0663 - mse: 0.0073 - val_loss: 0.0189 - val_mae: 0.0575 - val_mse: 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0207 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0188 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0656 - mse: 0.0070 - val_loss: 0.0188 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 236us/step - loss: 0.0206 - mae: 0.0649 - mse: 0.0069 - val_loss: 0.0187 - val_mae: 0.0574 - val_mse: 0.0054\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 203us/step - loss: 0.0206 - mae: 0.0651 - mse: 0.0070 - val_loss: 0.0186 - val_mae: 0.0581 - val_mse: 0.0055\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0205 - mae: 0.0654 - mse: 0.0071 - val_loss: 0.0186 - val_mae: 0.0579 - val_mse: 0.0055\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 162us/step - loss: 0.0205 - mae: 0.0653 - mse: 0.0070 - val_loss: 0.0185 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0204 - mae: 0.0656 - mse: 0.0071 - val_loss: 0.0185 - val_mae: 0.0582 - val_mse: 0.0055\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0185 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0203 - mae: 0.0649 - mse: 0.0070 - val_loss: 0.0183 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0652 - mse: 0.0070 - val_loss: 0.0184 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0184 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0201 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0182 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0201 - mae: 0.0648 - mse: 0.0069 - val_loss: 0.0182 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0182 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0200 - mae: 0.0642 - mse: 0.0068 - val_loss: 0.0181 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0199 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0180 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0199 - mae: 0.0648 - mse: 0.0070 - val_loss: 0.0180 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0198 - mae: 0.0647 - mse: 0.0069 - val_loss: 0.0180 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0198 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0197 - mae: 0.0646 - mse: 0.0069 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0179 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0196 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0179 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0196 - mae: 0.0636 - mse: 0.0067 - val_loss: 0.0177 - val_mae: 0.0574 - val_mse: 0.0053\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0196 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0178 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0642 - mse: 0.0068 - val_loss: 0.0178 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0177 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0194 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0176 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0176 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mae: 0.0638 - mse: 0.0067 - val_loss: 0.0175 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0174 - val_mae: 0.0584 - val_mse: 0.0055\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0647 - mse: 0.0069 - val_loss: 0.0175 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0175 - val_mae: 0.0589 - val_mse: 0.0055\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0643 - mse: 0.0068 - val_loss: 0.0174 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0634 - mse: 0.0066 - val_loss: 0.0174 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0639 - mse: 0.0067 - val_loss: 0.0174 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0191 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0173 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0191 - mae: 0.0636 - mse: 0.0067 - val_loss: 0.0172 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0173 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0171 - val_mae: 0.0567 - val_mse: 0.0053\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0643 - mse: 0.0069 - val_loss: 0.0172 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0189 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0171 - val_mae: 0.0564 - val_mse: 0.0051\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0189 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0170 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0188 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0170 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0646 - mse: 0.0070 - val_loss: 0.0171 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0188 - mae: 0.0633 - mse: 0.0066 - val_loss: 0.0170 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0187 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0169 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0187 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0169 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0187 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0169 - val_mae: 0.0571 - val_mse: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0187 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0168 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0186 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0168 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0167 - val_mae: 0.0576 - val_mse: 0.0055\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0186 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0578 - val_mse: 0.0055\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0588 - val_mse: 0.0056\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0185 - mae: 0.0650 - mse: 0.0070 - val_loss: 0.0167 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0185 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0167 - val_mae: 0.0559 - val_mse: 0.0050\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0165 - val_mae: 0.0566 - val_mse: 0.0053\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0184 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0165 - val_mae: 0.0583 - val_mse: 0.0055\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0184 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0166 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0184 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0052\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0183 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0164 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0183 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0166 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0164 - val_mae: 0.0573 - val_mse: 0.0053\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0165 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0163 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0182 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0182 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0051\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0181 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0163 - val_mae: 0.0556 - val_mse: 0.0050\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0162 - val_mae: 0.0561 - val_mse: 0.0051\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0181 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0164 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0181 - mae: 0.0627 - mse: 0.0065 - val_loss: 0.0162 - val_mae: 0.0569 - val_mse: 0.0052\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0568 - val_mse: 0.0052\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0161 - val_mae: 0.0585 - val_mse: 0.0056\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0180 - mae: 0.0649 - mse: 0.0070 - val_loss: 0.0162 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0162 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0179 - mae: 0.0632 - mse: 0.0066 - val_loss: 0.0161 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0179 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0160 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0161 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0178 - mae: 0.0637 - mse: 0.0067 - val_loss: 0.0161 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0178 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0052\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0052\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0159 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0158 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0645 - mse: 0.0069 - val_loss: 0.0160 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0158 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0177 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0157 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0176 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0157 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0158 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0159 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0156 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0158 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0175 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0158 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0624 - mse: 0.0065 - val_loss: 0.0156 - val_mae: 0.0574 - val_mse: 0.0052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0157 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0175 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0157 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0175 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0156 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0174 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0156 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0174 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0174 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0174 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0154 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0155 - val_mae: 0.0567 - val_mse: 0.0051\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0173 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0155 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0173 - mae: 0.0625 - mse: 0.0065 - val_loss: 0.0154 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0154 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0173 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0153 - val_mae: 0.0570 - val_mse: 0.0053\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0153 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0153 - val_mae: 0.0571 - val_mse: 0.0053\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0172 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0155 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0172 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0154 - val_mae: 0.0584 - val_mse: 0.0054\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0172 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0153 - val_mae: 0.0583 - val_mse: 0.0054\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0154 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0153 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0154 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0171 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0171 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0577 - val_mse: 0.0054\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0152 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0152 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0170 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0170 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0170 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0170 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0152 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0170 - mae: 0.0635 - mse: 0.0067 - val_loss: 0.0151 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0151 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0150 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0151 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0169 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0572 - val_mse: 0.0053\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0150 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0152 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0630 - mse: 0.0066 - val_loss: 0.0151 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0150 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0168 - mae: 0.0631 - mse: 0.0066 - val_loss: 0.0150 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0168 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0150 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0177 - mae: 0.0580 - mse: 0.007 - 0s 116us/step - loss: 0.0168 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0152 - val_mae: 0.0582 - val_mse: 0.0052\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0168 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0167 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0150 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0167 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0149 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0167 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0167 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0167 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0149 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0167 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0147 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0166 - mae: 0.0645 - mse: 0.0070 - val_loss: 0.0147 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0166 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0149 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0166 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0149 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0166 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0147 - val_mae: 0.0578 - val_mse: 0.0053\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0147 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0582 - val_mse: 0.0053\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0165 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0148 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0165 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0147 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0165 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0147 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0148 - val_mae: 0.0578 - val_mse: 0.0051\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0165 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0165 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0146 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0146 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0164 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0643 - mse: 0.0069 - val_loss: 0.0146 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0144 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0145 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0163 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0144 - val_mae: 0.0580 - val_mse: 0.0054\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0144 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0163 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0163 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0162 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0162 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0144 - val_mae: 0.0580 - val_mse: 0.0051\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0162 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0162 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0161 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0142 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0161 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0161 - mae: 0.0634 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0161 - mae: 0.0629 - mse: 0.0066 - val_loss: 0.0142 - val_mae: 0.0573 - val_mse: 0.0052\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0161 - mae: 0.0640 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0161 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0160 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0569 - val_mse: 0.0049\n",
      "Epoch 379/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0160 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0160 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0160 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0160 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0160 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0160 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0159 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0142 - val_mae: 0.0580 - val_mse: 0.0051\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0159 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0159 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0159 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0158 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0587 - val_mse: 0.0055\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0158 - mae: 0.0644 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mae: 0.0641 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0157 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0139 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0157 - mae: 0.0643 - mse: 0.0070 - val_loss: 0.0140 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0157 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0141 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0157 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0585 - val_mse: 0.0055\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0157 - mae: 0.0644 - mse: 0.0070 - val_loss: 0.0139 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0157 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0157 - mae: 0.0639 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0156 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0156 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0156 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0156 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0156 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0156 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0138 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0155 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0138 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0155 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mae: 0.0646 - mse: 0.0070 - val_loss: 0.0137 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0155 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0155 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0589 - val_mse: 0.0053\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0155 - mae: 0.0638 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0155 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mae: 0.0640 - mse: 0.0069 - val_loss: 0.0138 - val_mae: 0.0584 - val_mse: 0.0053\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0154 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0154 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0136 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0154 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0154 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0154 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0154 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0138 - val_mae: 0.0583 - val_mse: 0.0052\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0154 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 184us/step - loss: 0.0154 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0153 - mae: 0.0638 - mse: 0.0069 - val_loss: 0.0137 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0153 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 427/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 68us/step - loss: 0.0153 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0135 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.0153 - mae: 0.0641 - mse: 0.0069 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0153 - mae: 0.0636 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0588 - val_mse: 0.0055\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 47us/step - loss: 0.0153 - mae: 0.0642 - mse: 0.0069 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 65us/step - loss: 0.0153 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 78us/step - loss: 0.0153 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 161us/step - loss: 0.0152 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0135 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0152 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0639 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0152 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0152 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0571 - val_mse: 0.0050\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0152 - mae: 0.0637 - mse: 0.0068 - val_loss: 0.0135 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0151 - mae: 0.0632 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0135 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0151 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0151 - mae: 0.0633 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0586 - val_mse: 0.0054\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0150 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0150 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0150 - mae: 0.0635 - mse: 0.0068 - val_loss: 0.0133 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0150 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0150 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0149 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0133 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0593 - val_mse: 0.0054\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0149 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0149 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0586 - val_mse: 0.0055\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0149 - mae: 0.0637 - mse: 0.0069 - val_loss: 0.0132 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0149 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0149 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0133 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0149 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0132 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0148 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 133us/step - loss: 0.0148 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0148 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0132 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0148 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0148 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mae: 0.0628 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0147 - mae: 0.0628 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0131 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0133 - val_mae: 0.0579 - val_mse: 0.0051\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0147 - mae: 0.0623 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mae: 0.0627 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0147 - mae: 0.0626 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0581 - val_mse: 0.0053\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0131 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0581 - val_mse: 0.0054\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0633 - mse: 0.0068 - val_loss: 0.0130 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0147 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0146 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mae: 0.0623 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0579 - val_mse: 0.0054\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mae: 0.0634 - mse: 0.0068 - val_loss: 0.0129 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0146 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0590 - val_mse: 0.0054\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0146 - mae: 0.0630 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0146 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0629 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0146 - mae: 0.0632 - mse: 0.0067 - val_loss: 0.0131 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0129 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0145 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0128 - val_mae: 0.0579 - val_mse: 0.0053\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0145 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0130 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0145 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0130 - val_mae: 0.0584 - val_mse: 0.0052\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0579 - val_mse: 0.0052\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0130 - val_mae: 0.0578 - val_mse: 0.0051\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0145 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0585 - val_mse: 0.0054\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0144 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0128 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0580 - val_mse: 0.0053\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mae: 0.0631 - mse: 0.0067 - val_loss: 0.0129 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 523/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 116us/step - loss: 0.0144 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0577 - val_mse: 0.0053\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0144 - mae: 0.0627 - mse: 0.0067 - val_loss: 0.0128 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0144 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0144 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0129 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0143 - mae: 0.0627 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0581 - val_mse: 0.0052\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0143 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0143 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0126 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0127 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mae: 0.0617 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0142 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0142 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0052\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0142 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0126 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mae: 0.0618 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mae: 0.0617 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0626 - mse: 0.0066 - val_loss: 0.0128 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0142 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0126 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0127 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0141 - mae: 0.0611 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0141 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0576 - val_mse: 0.0052\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0141 - mae: 0.0625 - mse: 0.0066 - val_loss: 0.0125 - val_mae: 0.0578 - val_mse: 0.0052\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0141 - mae: 0.0621 - mse: 0.0066 - val_loss: 0.0125 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0570 - val_mse: 0.0051\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0140 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0126 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0052\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mae: 0.0622 - mse: 0.0065 - val_loss: 0.0125 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0140 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0140 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0612 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0582 - val_mse: 0.0054\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mae: 0.0621 - mse: 0.0065 - val_loss: 0.0124 - val_mae: 0.0576 - val_mse: 0.0053\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0622 - mse: 0.0066 - val_loss: 0.0124 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0139 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0575 - val_mse: 0.0053\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mae: 0.0624 - mse: 0.0066 - val_loss: 0.0124 - val_mae: 0.0574 - val_mse: 0.0052\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0577 - val_mse: 0.0051\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0127 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0139 - mae: 0.0619 - mse: 0.0065 - val_loss: 0.0126 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0139 - mae: 0.0607 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0126 - val_mae: 0.0573 - val_mse: 0.0050\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0139 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0139 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0125 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0138 - mae: 0.0614 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0571 - val_mse: 0.0051\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0138 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0138 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mae: 0.0620 - mse: 0.0065 - val_loss: 0.0123 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0138 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0138 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0572 - val_mse: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0579 - val_mse: 0.0051\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0614 - mse: 0.0064 - val_loss: 0.0125 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0125 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0570 - val_mse: 0.0052\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mae: 0.0612 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0585 - val_mse: 0.0053\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mae: 0.0617 - mse: 0.0064 - val_loss: 0.0123 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mae: 0.0607 - mse: 0.0063 - val_loss: 0.0124 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0615 - mse: 0.0064 - val_loss: 0.0122 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0137 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0577 - val_mse: 0.0052\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0137 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0124 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0575 - val_mse: 0.0052\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0616 - mse: 0.0064 - val_loss: 0.0124 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0610 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mae: 0.0606 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0137 - mae: 0.0611 - mse: 0.0064 - val_loss: 0.0121 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mae: 0.0613 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0569 - val_mse: 0.0051\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0613 - mse: 0.0064 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0136 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0136 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0136 - mae: 0.0609 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0124 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0137 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0123 - val_mae: 0.0574 - val_mse: 0.0051\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0136 - mae: 0.0612 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mae: 0.0601 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0136 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0136 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0135 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0565 - val_mse: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0136 - mae: 0.0608 - mse: 0.0063 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0613 - mse: 0.0063 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0145 - mae: 0.0664 - mse: 0.007 - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0568 - val_mse: 0.0051\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mae: 0.0611 - mse: 0.0063 - val_loss: 0.0120 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0135 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0608 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0134 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0135 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0609 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0122 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mae: 0.0598 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0134 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0123 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0134 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0134 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mae: 0.0601 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0134 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0134 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0134 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0134 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0134 - mae: 0.0602 - mse: 0.0062 - val_loss: 0.0120 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0133 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0134 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0134 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0564 - val_mse: 0.0049\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0133 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 148us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0133 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0133 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0572 - val_mse: 0.0051\n",
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mae: 0.0608 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0133 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0576 - val_mse: 0.0051\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0133 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0123 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0133 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0121 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 136us/step - loss: 0.0133 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0133 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 140us/step - loss: 0.0133 - mae: 0.0604 - mse: 0.0062 - val_loss: 0.0121 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 134us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0132 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0570 - val_mse: 0.0050\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0132 - mae: 0.0603 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0121 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0133 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0122 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0050\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0122 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0132 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0572 - val_mse: 0.0050\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0132 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0131 - mae: 0.0598 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0131 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0567 - val_mse: 0.0050\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0132 - mae: 0.0596 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0566 - val_mse: 0.0050\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0132 - mae: 0.0601 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0597 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0131 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0120 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 762/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 119us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0119 - val_mae: 0.0575 - val_mse: 0.0051\n",
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0131 - mae: 0.0602 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0131 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0050\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0117 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0131 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0117 - val_mae: 0.0566 - val_mse: 0.0051\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0607 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0131 - mae: 0.0591 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0131 - mae: 0.0595 - mse: 0.0060 - val_loss: 0.0120 - val_mae: 0.0562 - val_mse: 0.0048\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0131 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0564 - val_mse: 0.0050\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0606 - mse: 0.0062 - val_loss: 0.0119 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0565 - val_mse: 0.0051\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0605 - mse: 0.0062 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0568 - val_mse: 0.0050\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0599 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0130 - mae: 0.0593 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0129 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0130 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0569 - val_mse: 0.0050\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0130 - mae: 0.0599 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0119 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0130 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0130 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0130 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0129 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0562 - val_mse: 0.0050\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0129 - mae: 0.0597 - mse: 0.0061 - val_loss: 0.0118 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0130 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0573 - val_mse: 0.0051\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mae: 0.0596 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0130 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0129 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0129 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0565 - val_mse: 0.0050\n",
      "Epoch 810/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0600 - mse: 0.0061 - val_loss: 0.0119 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0129 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0129 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0556 - val_mse: 0.0049\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mae: 0.0593 - mse: 0.0060 - val_loss: 0.0118 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0128 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0118 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0128 - mae: 0.0586 - mse: 0.0059 - val_loss: 0.0118 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0128 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0127 - mae: 0.0594 - mse: 0.0060 - val_loss: 0.0117 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0565 - val_mse: 0.0049\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0049\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mae: 0.0591 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mae: 0.0592 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 851/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 852/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0050\n",
      "Epoch 853/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mae: 0.0598 - mse: 0.0060 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 854/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0560 - val_mse: 0.0048\n",
      "Epoch 855/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 856/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 857/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 858/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 859/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0590 - mse: 0.0059 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 860/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 861/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 862/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 863/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0567 - val_mse: 0.0049\n",
      "Epoch 864/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 865/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0127 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 866/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 867/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 868/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 869/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0115 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 870/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0127 - mae: 0.0579 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0563 - val_mse: 0.0049\n",
      "Epoch 871/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0127 - mae: 0.0587 - mse: 0.0059 - val_loss: 0.0116 - val_mae: 0.0566 - val_mse: 0.0049\n",
      "Epoch 872/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 873/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0589 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 874/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0116 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 875/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 876/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 877/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 878/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 879/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 880/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 881/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 882/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0126 - mae: 0.0588 - mse: 0.0059 - val_loss: 0.0117 - val_mae: 0.0561 - val_mse: 0.0048\n",
      "Epoch 883/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 884/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 885/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0560 - val_mse: 0.0049\n",
      "Epoch 886/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mae: 0.0594 - mse: 0.0059 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 887/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0126 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 888/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0126 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 889/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 890/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 891/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 892/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 893/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 894/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 895/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 896/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 897/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0125 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0115 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 898/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 899/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 900/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 901/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0116 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 902/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0558 - val_mse: 0.0049\n",
      "Epoch 903/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 904/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 905/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0115 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 906/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 122us/step - loss: 0.0125 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 907/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 908/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 909/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 910/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 911/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 912/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 913/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0125 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 914/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 915/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0125 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 916/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 917/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0116 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 918/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0125 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 919/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 920/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 921/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 922/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mae: 0.0583 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 923/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 924/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0125 - mae: 0.0580 - mse: 0.0058 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 925/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 926/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 927/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 928/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 929/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0562 - val_mse: 0.0049\n",
      "Epoch 930/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mae: 0.0584 - mse: 0.0058 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 931/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 932/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0577 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 933/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0574 - mse: 0.0055 - val_loss: 0.0115 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 934/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 935/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0568 - val_mse: 0.0049\n",
      "Epoch 936/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0125 - mae: 0.0585 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 937/10000\n",
      "482/482 [==============================] - 0s 182us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 938/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 939/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 940/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 941/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 942/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 943/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 944/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 945/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0574 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 946/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 947/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0048\n",
      "Epoch 948/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 949/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 950/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 951/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 952/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 953/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 954/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 131us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0117 - val_mae: 0.0559 - val_mse: 0.0048\n",
      "Epoch 955/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0115 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 956/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0124 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0048\n",
      "Epoch 957/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0556 - val_mse: 0.0049\n",
      "Epoch 958/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0587 - mse: 0.0058 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 959/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 960/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 961/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0123 - mae: 0.0582 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0558 - val_mse: 0.0048\n",
      "Epoch 962/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0124 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 963/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 964/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 965/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 966/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 967/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 968/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 969/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0115 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 970/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0123 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 971/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0571 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 972/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 973/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0057 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 974/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0056 - val_loss: 0.0116 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 975/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 976/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0552 - val_mse: 0.0047\n",
      "Epoch 977/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0123 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0560 - val_mse: 0.0050\n",
      "Epoch 978/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0588 - mse: 0.0058 - val_loss: 0.0113 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 979/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0114 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 980/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 981/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0551 - val_mse: 0.0048\n",
      "Epoch 982/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mae: 0.0584 - mse: 0.0057 - val_loss: 0.0112 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 983/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0123 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 984/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 985/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0556 - val_mse: 0.0048\n",
      "Epoch 986/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0123 - mae: 0.0579 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 987/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 988/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 989/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0578 - mse: 0.0057 - val_loss: 0.0114 - val_mae: 0.0551 - val_mse: 0.0047\n",
      "Epoch 990/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0571 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 991/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0555 - val_mse: 0.0049\n",
      "Epoch 992/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0123 - mae: 0.0580 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 993/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 994/10000\n",
      "482/482 [==============================] - 0s 178us/step - loss: 0.0122 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 995/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 996/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0122 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 997/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0122 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 999/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1000/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1001/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0546 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1002/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1003/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0575 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0555 - val_mse: 0.0048\n",
      "Epoch 1004/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0581 - mse: 0.0057 - val_loss: 0.0111 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1005/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1006/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1007/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0576 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1008/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1009/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0572 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1010/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mae: 0.0564 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1011/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1012/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1013/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1014/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0552 - val_mse: 0.0048\n",
      "Epoch 1015/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1016/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1017/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mae: 0.0566 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1018/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1019/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1020/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0561 - val_mse: 0.0049\n",
      "Epoch 1021/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mae: 0.0586 - mse: 0.0058 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1022/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0579 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 1023/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1024/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1025/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1026/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0121 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1027/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0121 - mae: 0.0573 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0554 - val_mse: 0.0048\n",
      "Epoch 1028/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0584 - mse: 0.0057 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1029/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1030/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1031/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0121 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1032/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1033/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0577 - mse: 0.0056 - val_loss: 0.0115 - val_mae: 0.0548 - val_mse: 0.0047\n",
      "Epoch 1034/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1035/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1036/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1037/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1038/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1039/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1040/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0113 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1041/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0121 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1042/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1043/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1044/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0121 - mae: 0.0574 - mse: 0.0056 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1045/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1046/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1047/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0120 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1048/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0121 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1049/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1050/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1051/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0121 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0113 - val_mae: 0.0558 - val_mse: 0.0047\n",
      "Epoch 1052/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0121 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1053/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1054/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0557 - val_mse: 0.0048\n",
      "Epoch 1055/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0056 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1056/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1057/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1058/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0574 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1059/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1060/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1061/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1062/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1063/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0559 - val_mse: 0.0049\n",
      "Epoch 1064/10000\n",
      "482/482 [==============================] - 0s 127us/step - loss: 0.0120 - mae: 0.0578 - mse: 0.0056 - val_loss: 0.0112 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1065/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1066/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1067/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1068/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0114 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1069/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0120 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1070/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1071/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1072/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0120 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 1073/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1074/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1075/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1076/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1077/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1078/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1079/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1080/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0120 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1081/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1082/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1083/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1084/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1085/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1086/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1087/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1088/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0120 - mae: 0.0568 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1089/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1090/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1091/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0120 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1092/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1093/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0112 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1094/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1095/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1096/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1097/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1098/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1099/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1100/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0120 - mae: 0.0569 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1101/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0119 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1102/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1103/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0047\n",
      "Epoch 1104/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0113 - val_mae: 0.0554 - val_mse: 0.0047\n",
      "Epoch 1105/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1107/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1108/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1109/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1110/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1111/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1112/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1113/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0571 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1114/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1115/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 1116/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1117/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0047\n",
      "Epoch 1118/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0572 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1119/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1120/10000\n",
      "482/482 [==============================] - 0s 128us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0111 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1121/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0119 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1122/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0119 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1123/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1124/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1125/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1126/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1127/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mae: 0.0567 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1128/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0119 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1129/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1130/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1131/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1132/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1133/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1134/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1135/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1136/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1137/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0118 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1138/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1139/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1140/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1141/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1142/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0054 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1143/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0118 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1144/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1145/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0554 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1146/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0118 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1147/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1148/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0118 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1149/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1150/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1151/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0110 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1152/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1153/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0118 - mae: 0.0570 - mse: 0.0055 - val_loss: 0.0109 - val_mae: 0.0546 - val_mse: 0.0045\n",
      "Epoch 1154/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1155/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mae: 0.0566 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1156/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1157/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1159/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1160/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1161/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1162/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1163/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1164/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1165/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0547 - val_mse: 0.0046\n",
      "Epoch 1166/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1168/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1169/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0110 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1170/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1171/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1172/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1173/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1174/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1175/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1176/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1177/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0562 - mse: 0.0054 - val_loss: 0.0111 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1178/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1179/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1180/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1181/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1182/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1183/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1184/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1185/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1186/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1187/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0117 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1188/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1189/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0545 - val_mse: 0.0047\n",
      "Epoch 1191/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0569 - mse: 0.0055 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1192/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1193/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0117 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1194/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0108 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1195/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0556 - val_mse: 0.0047\n",
      "Epoch 1196/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0117 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1197/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1198/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1199/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1200/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1201/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1202/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1203/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1204/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1205/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1206/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1207/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1208/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1209/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1210/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1211/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0547 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1212/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1213/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1214/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1215/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1216/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1217/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1218/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1219/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0560 - val_mse: 0.0047\n",
      "Epoch 1220/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1221/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1222/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1223/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1224/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0047\n",
      "Epoch 1225/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0547 - val_mse: 0.0047\n",
      "Epoch 1226/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0567 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1227/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0116 - mae: 0.0565 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1228/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1229/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0107 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1230/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1231/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0109 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1232/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0549 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1233/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1234/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0116 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1235/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0550 - val_mse: 0.0046\n",
      "Epoch 1236/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1237/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1238/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1239/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1240/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1241/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0563 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1242/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1243/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0116 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1244/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1245/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0115 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1246/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0116 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1247/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1248/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1249/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mae: 0.0556 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1250/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1251/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1252/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1253/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0115 - mae: 0.0564 - mse: 0.0054 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1254/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1255/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1256/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1257/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0561 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1258/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1259/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1260/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1261/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1262/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1263/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1264/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1265/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0528 - val_mse: 0.0044\n",
      "Epoch 1266/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0107 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1267/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1269/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1270/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1271/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1272/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0053 - val_loss: 0.0108 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1273/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1274/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1275/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1276/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1278/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1279/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1280/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1281/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1282/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1283/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1284/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1285/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1286/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1287/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mae: 0.0563 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0550 - val_mse: 0.0047\n",
      "Epoch 1288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0552 - val_mse: 0.0046\n",
      "Epoch 1289/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1290/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0110 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1291/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0115 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1292/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1293/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0544 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1294/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1295/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1296/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1297/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1298/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1299/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1300/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1301/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0552 - val_mse: 0.0046\n",
      "Epoch 1302/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1303/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1304/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1305/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1306/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0046\n",
      "Epoch 1307/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0562 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1308/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1309/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1310/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mae: 0.0557 - mse: 0.0053 - val_loss: 0.0107 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1311/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1312/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1313/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0114 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1314/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1316/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0553 - val_mse: 0.0048\n",
      "Epoch 1317/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0114 - mae: 0.0568 - mse: 0.0054 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1318/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1319/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1320/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1322/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0548 - val_mse: 0.0046\n",
      "Epoch 1323/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1324/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1325/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0110 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0114 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1328/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1329/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0544 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1330/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1331/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1332/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1333/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1334/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1335/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1336/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1337/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1338/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1339/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1340/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1341/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1342/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1343/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1344/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1345/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1346/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1347/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1348/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0106 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1349/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1350/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1351/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1352/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1353/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1354/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1355/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1356/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1357/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1358/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1359/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1360/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1361/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1362/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1363/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0112 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0045\n",
      "Epoch 1364/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1365/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1366/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1367/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1368/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1369/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1370/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1371/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0113 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1372/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1373/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1374/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1375/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1376/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0556 - mse: 0.0052 - val_loss: 0.0107 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1377/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1378/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1379/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1380/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1381/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0538 - val_mse: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1382/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1383/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1384/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1385/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1386/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1387/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1388/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1389/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1390/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0539 - val_mse: 0.0046\n",
      "Epoch 1391/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0558 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1392/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1393/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1394/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1395/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1396/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1397/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1398/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1399/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1400/10000\n",
      "482/482 [==============================] - 0s 167us/step - loss: 0.0112 - mae: 0.0555 - mse: 0.0052 - val_loss: 0.0105 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1401/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1402/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1403/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1404/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1405/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1406/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1408/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1409/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1410/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1411/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1412/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1413/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mae: 0.0559 - mse: 0.0053 - val_loss: 0.0103 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1414/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0560 - mse: 0.0053 - val_loss: 0.0104 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1415/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1416/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1417/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1418/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0108 - val_mae: 0.0533 - val_mse: 0.0045\n",
      "Epoch 1419/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0109 - val_mae: 0.0553 - val_mse: 0.0047\n",
      "Epoch 1420/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0543 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1421/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1422/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1423/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1424/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0108 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1425/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1426/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1427/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1428/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1429/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0107 - val_mae: 0.0532 - val_mse: 0.0045\n",
      "Epoch 1430/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1431/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0112 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1432/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1433/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0544 - val_mse: 0.0046\n",
      "Epoch 1434/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0557 - mse: 0.0052 - val_loss: 0.0102 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1435/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0043\n",
      "Epoch 1436/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1437/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1438/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1439/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0558 - mse: 0.0052 - val_loss: 0.0104 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1440/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1441/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1442/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1443/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1444/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1445/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1446/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1447/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1448/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0111 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1449/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1450/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0552 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1451/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1452/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0124 - mae: 0.0587 - mse: 0.006 - 0s 112us/step - loss: 0.0111 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1453/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0105 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1454/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0545 - val_mse: 0.0046\n",
      "Epoch 1455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1456/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0106 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1457/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1458/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1459/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1460/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0052 - val_loss: 0.0103 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1461/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1462/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1463/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1464/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1465/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1466/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0533 - val_mse: 0.0043\n",
      "Epoch 1467/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1468/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1469/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1470/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1471/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1472/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1473/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1474/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1475/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1476/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1477/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1478/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1479/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1480/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1481/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1482/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1483/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1484/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1485/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1486/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1487/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1488/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1489/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1490/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1491/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1492/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1493/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1494/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1495/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1496/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0110 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1497/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1498/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1499/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1500/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0553 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1501/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1502/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1503/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1504/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1505/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0110 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1506/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1508/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1509/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1510/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1511/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1512/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1513/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1514/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1515/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1516/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0100 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1517/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1518/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0538 - val_mse: 0.0046\n",
      "Epoch 1519/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mae: 0.0554 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1520/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0105 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1521/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1522/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1523/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0527 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1524/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1525/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1526/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1528/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1529/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1530/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0104 - val_mae: 0.0549 - val_mse: 0.0046\n",
      "Epoch 1531/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1532/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1533/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1534/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1535/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1536/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0550 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1537/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0109 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1538/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0548 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1539/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1540/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0103 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1541/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1542/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1543/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mae: 0.0546 - mse: 0.0051 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1544/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1545/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1546/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1547/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1548/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1549/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1550/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1551/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0537 - val_mse: 0.0044\n",
      "Epoch 1552/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1553/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1554/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1555/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1556/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0109 - mae: 0.0553 - mse: 0.0052 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1557/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0545 - mse: 0.0051 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1558/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1559/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1560/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1561/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1562/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1563/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1564/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1565/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1566/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0109 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0520 - val_mse: 0.0043\n",
      "Epoch 1567/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1568/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0549 - mse: 0.0051 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1569/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1570/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1571/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0108 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1572/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1573/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1574/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1576/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1577/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1578/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1579/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1580/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0104 - val_mae: 0.0553 - val_mse: 0.0046\n",
      "Epoch 1581/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1582/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1583/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1584/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1585/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1586/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1587/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1588/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1589/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1590/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1591/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1592/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1593/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1594/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0104 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1595/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1596/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1597/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1598/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1599/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0108 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0538 - val_mse: 0.0044\n",
      "Epoch 1600/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1601/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0107 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1602/10000\n",
      "482/482 [==============================] - 0s 152us/step - loss: 0.0108 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1603/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0108 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1604/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0108 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1605/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1606/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1607/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1608/10000\n",
      "482/482 [==============================] - 0s 176us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1609/10000\n",
      "482/482 [==============================] - 0s 147us/step - loss: 0.0108 - mae: 0.0547 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1610/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1611/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1612/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0103 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1613/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1614/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1615/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1616/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1617/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1618/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1619/10000\n",
      "482/482 [==============================] - 0s 150us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1620/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0107 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1621/10000\n",
      "482/482 [==============================] - 0s 134us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1622/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0102 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1623/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1624/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1625/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1626/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0107 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1627/10000\n",
      "482/482 [==============================] - 0s 146us/step - loss: 0.0107 - mae: 0.0547 - mse: 0.0051 - val_loss: 0.0099 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1628/10000\n",
      "482/482 [==============================] - 0s 138us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1629/10000\n",
      "482/482 [==============================] - 0s 145us/step - loss: 0.0107 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1630/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1631/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1632/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0042\n",
      "Epoch 1633/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1634/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0107 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1635/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1636/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1637/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1638/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1639/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1640/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1641/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1642/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1643/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1644/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1645/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1646/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1647/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1648/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1649/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1650/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1651/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1652/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1653/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1654/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1655/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1656/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0107 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1657/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1658/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1659/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1660/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0042\n",
      "Epoch 1661/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 1662/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1663/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1664/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1665/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1666/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1667/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0103 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1668/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0107 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1669/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1670/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1671/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0521 - val_mse: 0.0043\n",
      "Epoch 1672/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1673/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1674/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0107 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1675/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1676/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1677/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0107 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1678/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1679/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1680/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1681/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1682/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1684/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1685/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1686/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1687/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1688/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1689/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1690/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1691/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1692/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1693/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0106 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0100 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1694/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1695/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1696/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1697/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1698/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1699/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1700/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1701/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0106 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1702/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1703/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0106 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1704/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1705/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1706/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1707/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1708/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0106 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1709/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0105 - val_mae: 0.0539 - val_mse: 0.0046\n",
      "Epoch 1710/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1711/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1712/10000\n",
      "482/482 [==============================] - 0s 109us/step - loss: 0.0106 - mae: 0.0543 - mse: 0.0050 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1713/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1714/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1715/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1716/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0537 - val_mse: 0.0045\n",
      "Epoch 1717/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0106 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1718/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0555 - val_mse: 0.0047\n",
      "Epoch 1719/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0544 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1720/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1721/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1722/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1723/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1724/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 1725/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1726/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1727/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0050 - val_loss: 0.0101 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1728/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1729/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1730/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1731/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1732/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1733/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0523 - val_mse: 0.0043\n",
      "Epoch 1734/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1735/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1736/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0102 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1737/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1738/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1739/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mae: 0.0551 - mse: 0.0051 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1740/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1741/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1742/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1743/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1744/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1745/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1746/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1747/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1748/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1749/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0542 - val_mse: 0.0045\n",
      "Epoch 1750/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1751/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1752/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0105 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1753/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1754/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1755/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0105 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1756/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0538 - val_mse: 0.0045\n",
      "Epoch 1757/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1758/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1759/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1760/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0545 - val_mse: 0.0045\n",
      "Epoch 1761/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0101 - val_mae: 0.0532 - val_mse: 0.0044\n",
      "Epoch 1762/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1763/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0105 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1764/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0044\n",
      "Epoch 1765/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1766/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1767/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1768/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1769/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1770/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1771/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1772/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1773/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1774/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1775/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1776/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1777/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1778/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1779/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1780/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0105 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1781/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1782/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1783/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1784/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1785/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0541 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1786/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0539 - val_mse: 0.0045\n",
      "Epoch 1787/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0105 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1788/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1789/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0105 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1790/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1791/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1792/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1793/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1794/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1795/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1796/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0542 - val_mse: 0.0046\n",
      "Epoch 1797/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0099 - val_mae: 0.0514 - val_mse: 0.0042\n",
      "Epoch 1798/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1799/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0042\n",
      "Epoch 1800/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0104 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1801/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1802/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1803/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0513 - val_mse: 0.0042\n",
      "Epoch 1804/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1805/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1806/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0536 - val_mse: 0.0044\n",
      "Epoch 1807/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1808/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1809/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1810/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1811/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1812/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1813/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1814/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1815/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1816/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0046\n",
      "Epoch 1817/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0545 - mse: 0.0050 - val_loss: 0.0099 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1818/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1819/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0527 - val_mse: 0.0044\n",
      "Epoch 1820/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1821/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1822/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1823/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0104 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1824/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1825/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1826/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1827/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1828/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0101 - val_mae: 0.0525 - val_mse: 0.0043\n",
      "Epoch 1829/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1830/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1831/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0100 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 1832/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1833/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1834/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1835/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1836/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 1838/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1839/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mae: 0.0536 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1840/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1841/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0532 - val_mse: 0.0043\n",
      "Epoch 1842/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1843/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1844/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1845/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1846/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1847/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1848/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1849/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1850/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1851/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1852/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0539 - val_mse: 0.0044\n",
      "Epoch 1853/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1854/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1855/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1856/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1857/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1858/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1859/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1860/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1861/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1862/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1863/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1864/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1865/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1866/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0104 - mae: 0.0542 - mse: 0.0050 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1867/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1868/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1869/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1870/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1871/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1872/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1873/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0081 - mae: 0.0410 - mse: 0.002 - 0s 108us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0533 - val_mse: 0.0044\n",
      "Epoch 1874/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1875/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1876/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1877/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1878/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1879/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1880/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1881/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0103 - mae: 0.0540 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1882/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1883/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0103 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1884/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0515 - val_mse: 0.0042\n",
      "Epoch 1885/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1886/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1887/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1888/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1889/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1890/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1891/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1892/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0544 - val_mse: 0.0045\n",
      "Epoch 1893/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1894/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1895/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1896/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1897/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1898/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0541 - val_mse: 0.0045\n",
      "Epoch 1899/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1900/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0536 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1901/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0536 - val_mse: 0.0045\n",
      "Epoch 1902/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0546 - mse: 0.0050 - val_loss: 0.0096 - val_mae: 0.0509 - val_mse: 0.0041\n",
      "Epoch 1903/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1904/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1905/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1906/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1907/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1908/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1909/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1910/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1911/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1912/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1913/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1914/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 1915/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 1916/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0098 - val_mae: 0.0543 - val_mse: 0.0045\n",
      "Epoch 1917/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1918/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 1919/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1920/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 1921/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0105 - mae: 0.0562 - mse: 0.005 - 0s 120us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0534 - val_mse: 0.0045\n",
      "Epoch 1922/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0103 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1923/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1924/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mae: 0.0535 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 1925/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1926/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 1927/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1928/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1929/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1930/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1931/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1932/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0508 - val_mse: 0.0041\n",
      "Epoch 1933/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1934/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0096 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1935/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1936/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0529 - val_mse: 0.0043\n",
      "Epoch 1937/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1938/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1939/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0539 - mse: 0.0049 - val_loss: 0.0097 - val_mae: 0.0531 - val_mse: 0.0043\n",
      "Epoch 1940/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1941/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0100 - val_mae: 0.0520 - val_mse: 0.0043\n",
      "Epoch 1942/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1943/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1944/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1945/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 1946/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1947/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1948/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0539 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1949/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1950/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1951/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0520 - val_mse: 0.0041\n",
      "Epoch 1952/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1953/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1954/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0102 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1955/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 1956/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0042\n",
      "Epoch 1957/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1958/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1959/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0097 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1960/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0523 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1961/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 1962/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0099 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 1963/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 1964/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1965/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0101 - mae: 0.0550 - mse: 0.004 - 0s 104us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 1966/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0040\n",
      "Epoch 1967/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0102 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 1968/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1969/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 1970/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 1971/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0106 - val_mae: 0.0546 - val_mse: 0.0048\n",
      "Epoch 1972/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 1973/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1974/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1975/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 1976/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1977/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1978/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1979/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0508 - val_mse: 0.0041\n",
      "Epoch 1980/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0523 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1981/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0042\n",
      "Epoch 1982/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 1983/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 1984/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 1985/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1986/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 1987/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 1988/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 1989/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 1990/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0102 - mae: 0.0535 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 1991/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0522 - val_mse: 0.0043\n",
      "Epoch 1992/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 1993/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 1994/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 1995/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0540 - val_mse: 0.0045\n",
      "Epoch 1996/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mae: 0.0537 - mse: 0.0049 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 1997/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 1998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 1999/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0530 - mse: 0.0048 - val_loss: 0.0095 - val_mae: 0.0525 - val_mse: 0.0042\n",
      "Epoch 2000/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2001/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0534 - val_mse: 0.0044\n",
      "Epoch 2002/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0523 - val_mse: 0.0042\n",
      "Epoch 2003/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 2004/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2005/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2006/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2007/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0509 - val_mse: 0.0040\n",
      "Epoch 2008/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 2009/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2010/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2011/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2012/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0046 - val_loss: 0.0094 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2013/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0048 - val_loss: 0.0096 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 2014/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0518 - mse: 0.0046 - val_loss: 0.0097 - val_mae: 0.0546 - val_mse: 0.0045\n",
      "Epoch 2015/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mae: 0.0538 - mse: 0.0049 - val_loss: 0.0095 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2016/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0519 - val_mse: 0.0043\n",
      "Epoch 2017/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2018/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2019/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0523 - mse: 0.0046 - val_loss: 0.0093 - val_mae: 0.0510 - val_mse: 0.0041\n",
      "Epoch 2020/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2021/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 2022/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2023/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2024/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 2025/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2026/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0532 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2027/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0516 - val_mse: 0.0042\n",
      "Epoch 2028/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0510 - val_mse: 0.0040\n",
      "Epoch 2029/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 2030/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2031/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0546 - val_mse: 0.0046\n",
      "Epoch 2032/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0537 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0527 - val_mse: 0.0043\n",
      "Epoch 2033/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 2034/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2035/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2036/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0534 - mse: 0.0049 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2037/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2038/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0099 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 2039/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mae: 0.0528 - mse: 0.0046 - val_loss: 0.0095 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 2040/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2041/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0098 - val_mae: 0.0530 - val_mse: 0.0044\n",
      "Epoch 2042/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2043/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0529 - val_mse: 0.0044\n",
      "Epoch 2044/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mae: 0.0531 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0520 - val_mse: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2045/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0048 - val_loss: 0.0093 - val_mae: 0.0520 - val_mse: 0.0042\n",
      "Epoch 2046/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 2047/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2048/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0523 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0531 - val_mse: 0.0044\n",
      "Epoch 2049/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0521 - val_mse: 0.0042\n",
      "Epoch 2050/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0533 - mse: 0.0048 - val_loss: 0.0092 - val_mae: 0.0518 - val_mse: 0.0042\n",
      "Epoch 2051/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2052/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2053/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0096 - val_mae: 0.0535 - val_mse: 0.0044\n",
      "Epoch 2054/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mae: 0.0526 - mse: 0.0048 - val_loss: 0.0094 - val_mae: 0.0530 - val_mse: 0.0043\n",
      "Epoch 2055/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0506 - val_mse: 0.0040\n",
      "Epoch 2056/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0097 - val_mae: 0.0512 - val_mse: 0.0042\n",
      "Epoch 2057/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0101 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0508 - val_mse: 0.0040\n",
      "Epoch 2058/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0046 - val_loss: 0.0095 - val_mae: 0.0513 - val_mse: 0.0041\n",
      "Epoch 2059/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0517 - mse: 0.0046 - val_loss: 0.0093 - val_mae: 0.0517 - val_mse: 0.0041\n",
      "Epoch 2060/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0516 - val_mse: 0.0041\n",
      "Epoch 2061/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0530 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0515 - val_mse: 0.0041\n",
      "Epoch 2062/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0512 - val_mse: 0.0041\n",
      "Epoch 2063/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0514 - val_mse: 0.0041\n",
      "Epoch 2064/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 2065/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 2066/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0524 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0517 - val_mse: 0.0042\n",
      "Epoch 2067/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0092 - val_mae: 0.0511 - val_mse: 0.0040\n",
      "Epoch 2068/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0525 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0524 - val_mse: 0.0043\n",
      "Epoch 2069/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0527 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0524 - val_mse: 0.0042\n",
      "Epoch 2070/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0511 - val_mse: 0.0041\n",
      "Epoch 2071/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0099 - mae: 0.0522 - mse: 0.0046 - val_loss: 0.0092 - val_mae: 0.0519 - val_mse: 0.0042\n",
      "Epoch 2072/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0099 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0522 - val_mse: 0.0042\n",
      "Epoch 2073/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0100 - mae: 0.0533 - mse: 0.0047 - val_loss: 0.0095 - val_mae: 0.0526 - val_mse: 0.0043\n",
      "Epoch 2074/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mae: 0.0529 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0518 - val_mse: 0.0041\n",
      "Epoch 2075/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mae: 0.0528 - mse: 0.0047 - val_loss: 0.0094 - val_mae: 0.0528 - val_mse: 0.0043\n",
      "Epoch 2076/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0100 - mae: 0.0526 - mse: 0.0047 - val_loss: 0.0093 - val_mae: 0.0505 - val_mse: 0.0040\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 02076: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_default = build_default_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_default.compile(loss='mse', optimizer=optimizer, metrics=['mae', 'mse'])\n",
    "model_default.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['default'] = model_default.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_204 (Dense)            (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "dropout_95 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_96 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.3553 - mae: 0.3076 - val_loss: 0.3525 - val_mae: 0.3612\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.3351 - mae: 0.2935 - val_loss: 0.3118 - val_mae: 0.3185\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.3002 - mae: 0.2552 - val_loss: 0.2708 - val_mae: 0.2673\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.2893 - mae: 0.2512 - val_loss: 0.2398 - val_mae: 0.2254\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.2711 - mae: 0.2379 - val_loss: 0.2223 - val_mae: 0.2036\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2504 - mae: 0.2172 - val_loss: 0.2046 - val_mae: 0.1781\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.2403 - mae: 0.2127 - val_loss: 0.1921 - val_mae: 0.1657\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.2246 - mae: 0.2013 - val_loss: 0.1841 - val_mae: 0.1675\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.2177 - mae: 0.2000 - val_loss: 0.1714 - val_mae: 0.1498\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.2071 - mae: 0.1986 - val_loss: 0.1615 - val_mae: 0.1385\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1975 - mae: 0.1913 - val_loss: 0.1559 - val_mae: 0.1438\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1861 - mae: 0.1794 - val_loss: 0.1512 - val_mae: 0.1474\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1756 - mae: 0.1735 - val_loss: 0.1446 - val_mae: 0.1420\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.1719 - mae: 0.1764 - val_loss: 0.1420 - val_mae: 0.1510\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1639 - mae: 0.1705 - val_loss: 0.1373 - val_mae: 0.1479\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1601 - mae: 0.1728 - val_loss: 0.1315 - val_mae: 0.1390\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.1538 - mae: 0.1693 - val_loss: 0.1279 - val_mae: 0.1422\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1448 - mae: 0.1621 - val_loss: 0.1244 - val_mae: 0.1443\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1435 - mae: 0.1678 - val_loss: 0.1201 - val_mae: 0.1402\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1355 - mae: 0.1592 - val_loss: 0.1166 - val_mae: 0.1381\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.1300 - mae: 0.1567 - val_loss: 0.1128 - val_mae: 0.1336\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1244 - mae: 0.1481 - val_loss: 0.1098 - val_mae: 0.1355\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1232 - mae: 0.1547 - val_loss: 0.1077 - val_mae: 0.1403\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1179 - mae: 0.1498 - val_loss: 0.1030 - val_mae: 0.1286\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1147 - mae: 0.1476 - val_loss: 0.1005 - val_mae: 0.1250\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1140 - mae: 0.1529 - val_loss: 0.0991 - val_mae: 0.1283\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.1153 - mae: 0.1565 - val_loss: 0.0977 - val_mae: 0.1274\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1098 - mae: 0.1475 - val_loss: 0.0966 - val_mae: 0.1266\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.1105 - mae: 0.1544 - val_loss: 0.0958 - val_mae: 0.1266\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1079 - mae: 0.1490 - val_loss: 0.0944 - val_mae: 0.1244\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1062 - mae: 0.1466 - val_loss: 0.0934 - val_mae: 0.1258\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.1042 - mae: 0.1475 - val_loss: 0.0911 - val_mae: 0.1138\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.1015 - mae: 0.1386 - val_loss: 0.0905 - val_mae: 0.1189\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0999 - mae: 0.1372 - val_loss: 0.0893 - val_mae: 0.1205\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0981 - mae: 0.1337 - val_loss: 0.0881 - val_mae: 0.1196\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0985 - mae: 0.1409 - val_loss: 0.0862 - val_mae: 0.1141\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0962 - mae: 0.1351 - val_loss: 0.0858 - val_mae: 0.1176\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0957 - mae: 0.1378 - val_loss: 0.0845 - val_mae: 0.1156\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0944 - mae: 0.1361 - val_loss: 0.0830 - val_mae: 0.1103\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0926 - mae: 0.1366 - val_loss: 0.0820 - val_mae: 0.1144\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0926 - mae: 0.1365 - val_loss: 0.0810 - val_mae: 0.1150\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0908 - mae: 0.1362 - val_loss: 0.0793 - val_mae: 0.1063\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0897 - mae: 0.1309 - val_loss: 0.0792 - val_mae: 0.1150\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0876 - mae: 0.1343 - val_loss: 0.0782 - val_mae: 0.1161\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0879 - mae: 0.1385 - val_loss: 0.0766 - val_mae: 0.1104\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0866 - mae: 0.1359 - val_loss: 0.0755 - val_mae: 0.1087\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0838 - mae: 0.1272 - val_loss: 0.0753 - val_mae: 0.1147\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0822 - mae: 0.1233 - val_loss: 0.0737 - val_mae: 0.1108\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0798 - mae: 0.1263 - val_loss: 0.0724 - val_mae: 0.1081\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0816 - mae: 0.1283 - val_loss: 0.0716 - val_mae: 0.1086\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0792 - mae: 0.1271 - val_loss: 0.0696 - val_mae: 0.0986\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0814 - mae: 0.1306 - val_loss: 0.0687 - val_mae: 0.0963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0779 - mae: 0.1200 - val_loss: 0.0685 - val_mae: 0.1039\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0778 - mae: 0.1298 - val_loss: 0.0671 - val_mae: 0.0986\n",
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0768 - mae: 0.1288 - val_loss: 0.0666 - val_mae: 0.1016\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0729 - mae: 0.1202 - val_loss: 0.0659 - val_mae: 0.1012\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0724 - mae: 0.1180 - val_loss: 0.0660 - val_mae: 0.1075\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0736 - mae: 0.1245 - val_loss: 0.0642 - val_mae: 0.0974\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0727 - mae: 0.1198 - val_loss: 0.0635 - val_mae: 0.0971\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0729 - mae: 0.1241 - val_loss: 0.0629 - val_mae: 0.0975\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0708 - mae: 0.1184 - val_loss: 0.0627 - val_mae: 0.1014\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0685 - mae: 0.1152 - val_loss: 0.0609 - val_mae: 0.0902\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0667 - mae: 0.1105 - val_loss: 0.0601 - val_mae: 0.0885\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0689 - mae: 0.1179 - val_loss: 0.0605 - val_mae: 0.0980\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0665 - mae: 0.1169 - val_loss: 0.0596 - val_mae: 0.0948\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0649 - mae: 0.1104 - val_loss: 0.0583 - val_mae: 0.0863\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0655 - mae: 0.1137 - val_loss: 0.0582 - val_mae: 0.0927\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0651 - mae: 0.1144 - val_loss: 0.0579 - val_mae: 0.0950\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0653 - mae: 0.1166 - val_loss: 0.0571 - val_mae: 0.0920\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0647 - mae: 0.1167 - val_loss: 0.0568 - val_mae: 0.0938\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0650 - mae: 0.1166 - val_loss: 0.0558 - val_mae: 0.0896\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0630 - mae: 0.1131 - val_loss: 0.0554 - val_mae: 0.0912\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0613 - mae: 0.1128 - val_loss: 0.0546 - val_mae: 0.0879\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0609 - mae: 0.1103 - val_loss: 0.0544 - val_mae: 0.0907\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0613 - mae: 0.1117 - val_loss: 0.0539 - val_mae: 0.0908\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0625 - mae: 0.1174 - val_loss: 0.0530 - val_mae: 0.0874\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0611 - mae: 0.1152 - val_loss: 0.0528 - val_mae: 0.0894\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0585 - mae: 0.1105 - val_loss: 0.0521 - val_mae: 0.0862\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0606 - mae: 0.1140 - val_loss: 0.0515 - val_mae: 0.0864\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0580 - mae: 0.1093 - val_loss: 0.0512 - val_mae: 0.0883\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0585 - mae: 0.1115 - val_loss: 0.0505 - val_mae: 0.0846\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0574 - mae: 0.1087 - val_loss: 0.0503 - val_mae: 0.0870\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0572 - mae: 0.1114 - val_loss: 0.0503 - val_mae: 0.0932\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0562 - mae: 0.1101 - val_loss: 0.0495 - val_mae: 0.0896\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0563 - mae: 0.1111 - val_loss: 0.0494 - val_mae: 0.0926\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0570 - mae: 0.1140 - val_loss: 0.0486 - val_mae: 0.0890\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0568 - mae: 0.1119 - val_loss: 0.0486 - val_mae: 0.0929\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0550 - mae: 0.1111 - val_loss: 0.0481 - val_mae: 0.0915\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0559 - mae: 0.1126 - val_loss: 0.0474 - val_mae: 0.0884\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0553 - mae: 0.1130 - val_loss: 0.0469 - val_mae: 0.0868\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0547 - mae: 0.1112 - val_loss: 0.0468 - val_mae: 0.0894\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mae: 0.1061 - val_loss: 0.0461 - val_mae: 0.0854\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0554 - mae: 0.1140 - val_loss: 0.0455 - val_mae: 0.0838\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0539 - mae: 0.1119 - val_loss: 0.0454 - val_mae: 0.0867\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0517 - mae: 0.1071 - val_loss: 0.0454 - val_mae: 0.0898\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0522 - mae: 0.1069 - val_loss: 0.0446 - val_mae: 0.0854\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0513 - mae: 0.1057 - val_loss: 0.0442 - val_mae: 0.0841\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0530 - mae: 0.1114 - val_loss: 0.0438 - val_mae: 0.0843\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0514 - mae: 0.1100 - val_loss: 0.0437 - val_mae: 0.0873\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0498 - mae: 0.1065 - val_loss: 0.0435 - val_mae: 0.0887\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0519 - mae: 0.1140 - val_loss: 0.0434 - val_mae: 0.0907\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0517 - mae: 0.1143 - val_loss: 0.0424 - val_mae: 0.0846\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mae: 0.1136 - val_loss: 0.0423 - val_mae: 0.0864\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0489 - mae: 0.1029 - val_loss: 0.0419 - val_mae: 0.0859\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0482 - mae: 0.1065 - val_loss: 0.0414 - val_mae: 0.0844\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0488 - mae: 0.1055 - val_loss: 0.0412 - val_mae: 0.0851\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0500 - mae: 0.1110 - val_loss: 0.0413 - val_mae: 0.0879\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0475 - mae: 0.1065 - val_loss: 0.0410 - val_mae: 0.0879\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0489 - mae: 0.1103 - val_loss: 0.0405 - val_mae: 0.0866\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0475 - mae: 0.1063 - val_loss: 0.0398 - val_mae: 0.0829\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0487 - mae: 0.1095 - val_loss: 0.0397 - val_mae: 0.0847\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0474 - mae: 0.1063 - val_loss: 0.0394 - val_mae: 0.0841\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0451 - mae: 0.1032 - val_loss: 0.0387 - val_mae: 0.0793\n",
      "Epoch 114/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0462 - mae: 0.093 - 0s 112us/step - loss: 0.0461 - mae: 0.1037 - val_loss: 0.0385 - val_mae: 0.0819\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0468 - mae: 0.1072 - val_loss: 0.0381 - val_mae: 0.0802\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0461 - mae: 0.1048 - val_loss: 0.0380 - val_mae: 0.0822\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0441 - mae: 0.1013 - val_loss: 0.0381 - val_mae: 0.0852\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0464 - mae: 0.1106 - val_loss: 0.0380 - val_mae: 0.0863\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0440 - mae: 0.1030 - val_loss: 0.0373 - val_mae: 0.0831\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0450 - mae: 0.1046 - val_loss: 0.0374 - val_mae: 0.0857\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0443 - mae: 0.1040 - val_loss: 0.0369 - val_mae: 0.0837\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0438 - mae: 0.1035 - val_loss: 0.0365 - val_mae: 0.0825\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0431 - mae: 0.1025 - val_loss: 0.0363 - val_mae: 0.0831\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0439 - mae: 0.1058 - val_loss: 0.0362 - val_mae: 0.0837\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0425 - mae: 0.1026 - val_loss: 0.0356 - val_mae: 0.0807\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0429 - mae: 0.1030 - val_loss: 0.0355 - val_mae: 0.0822\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0428 - mae: 0.1051 - val_loss: 0.0351 - val_mae: 0.0803\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0422 - mae: 0.1021 - val_loss: 0.0347 - val_mae: 0.0784\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0398 - mae: 0.0950 - val_loss: 0.0347 - val_mae: 0.0820\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0419 - mae: 0.1060 - val_loss: 0.0346 - val_mae: 0.0827\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0417 - mae: 0.1030 - val_loss: 0.0342 - val_mae: 0.0817\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0409 - mae: 0.1016 - val_loss: 0.0341 - val_mae: 0.0828\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0401 - mae: 0.0997 - val_loss: 0.0338 - val_mae: 0.0819\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 70us/step - loss: 0.0411 - mae: 0.1040 - val_loss: 0.0335 - val_mae: 0.0813\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0387 - mae: 0.0955 - val_loss: 0.0334 - val_mae: 0.0820\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 64us/step - loss: 0.0394 - mae: 0.0997 - val_loss: 0.0332 - val_mae: 0.0824\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0398 - mae: 0.1022 - val_loss: 0.0329 - val_mae: 0.0809\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 60us/step - loss: 0.0388 - mae: 0.1004 - val_loss: 0.0328 - val_mae: 0.0823\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0384 - mae: 0.0984 - val_loss: 0.0325 - val_mae: 0.0815\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 78us/step - loss: 0.0390 - mae: 0.1014 - val_loss: 0.0326 - val_mae: 0.0839\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 65us/step - loss: 0.0383 - mae: 0.0987 - val_loss: 0.0320 - val_mae: 0.0810\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 156us/step - loss: 0.0381 - mae: 0.1000 - val_loss: 0.0316 - val_mae: 0.0800\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0374 - mae: 0.0988 - val_loss: 0.0311 - val_mae: 0.0767\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0392 - mae: 0.1024 - val_loss: 0.0311 - val_mae: 0.0787\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0371 - mae: 0.0985 - val_loss: 0.0313 - val_mae: 0.0816\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0370 - mae: 0.0988 - val_loss: 0.0308 - val_mae: 0.0798\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0369 - mae: 0.1002 - val_loss: 0.0305 - val_mae: 0.0783\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0374 - mae: 0.0998 - val_loss: 0.0309 - val_mae: 0.0828\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0363 - mae: 0.1003 - val_loss: 0.0300 - val_mae: 0.0771\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0359 - mae: 0.0946 - val_loss: 0.0299 - val_mae: 0.0781\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0373 - mae: 0.0996 - val_loss: 0.0299 - val_mae: 0.0795\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0363 - mae: 0.0992 - val_loss: 0.0294 - val_mae: 0.0768\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0361 - mae: 0.0985 - val_loss: 0.0292 - val_mae: 0.0769\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0365 - mae: 0.1013 - val_loss: 0.0294 - val_mae: 0.0796\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0359 - mae: 0.1013 - val_loss: 0.0295 - val_mae: 0.0818\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0345 - mae: 0.0962 - val_loss: 0.0289 - val_mae: 0.0788\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0345 - mae: 0.0977 - val_loss: 0.0289 - val_mae: 0.0794\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0336 - mae: 0.0935 - val_loss: 0.0283 - val_mae: 0.0766\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0343 - mae: 0.0962 - val_loss: 0.0281 - val_mae: 0.0762\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0347 - mae: 0.0977 - val_loss: 0.0288 - val_mae: 0.0829\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0330 - mae: 0.0946 - val_loss: 0.0279 - val_mae: 0.0768\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0351 - mae: 0.0995 - val_loss: 0.0279 - val_mae: 0.0779\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0341 - mae: 0.0970 - val_loss: 0.0279 - val_mae: 0.0791\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0336 - mae: 0.0963 - val_loss: 0.0275 - val_mae: 0.0774\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0336 - mae: 0.0949 - val_loss: 0.0272 - val_mae: 0.0761\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0342 - mae: 0.0976 - val_loss: 0.0273 - val_mae: 0.0780\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0336 - mae: 0.0958 - val_loss: 0.0269 - val_mae: 0.0756\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0320 - mae: 0.0921 - val_loss: 0.0266 - val_mae: 0.0741\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0314 - mae: 0.0890 - val_loss: 0.0264 - val_mae: 0.0739\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0323 - mae: 0.0925 - val_loss: 0.0263 - val_mae: 0.0748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0321 - mae: 0.0952 - val_loss: 0.0264 - val_mae: 0.0764\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0317 - mae: 0.0936 - val_loss: 0.0261 - val_mae: 0.0757\n",
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0322 - mae: 0.0953 - val_loss: 0.0263 - val_mae: 0.0783\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0322 - mae: 0.0955 - val_loss: 0.0270 - val_mae: 0.0830\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0311 - mae: 0.0962 - val_loss: 0.0261 - val_mae: 0.0788\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0317 - mae: 0.0950 - val_loss: 0.0259 - val_mae: 0.0775\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0324 - mae: 0.0996 - val_loss: 0.0258 - val_mae: 0.0785\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0305 - mae: 0.0906 - val_loss: 0.0255 - val_mae: 0.0775\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0316 - mae: 0.0957 - val_loss: 0.0252 - val_mae: 0.0756\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0294 - mae: 0.0894 - val_loss: 0.0251 - val_mae: 0.0760\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0318 - mae: 0.0973 - val_loss: 0.0247 - val_mae: 0.0730\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0300 - mae: 0.0912 - val_loss: 0.0246 - val_mae: 0.0729\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0312 - mae: 0.0931 - val_loss: 0.0248 - val_mae: 0.0768\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0289 - mae: 0.0903 - val_loss: 0.0244 - val_mae: 0.0742\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0297 - mae: 0.0918 - val_loss: 0.0243 - val_mae: 0.0743\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0312 - mae: 0.0951 - val_loss: 0.0249 - val_mae: 0.0791\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0292 - mae: 0.0900 - val_loss: 0.0243 - val_mae: 0.0757\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0298 - mae: 0.0935 - val_loss: 0.0239 - val_mae: 0.0735\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0293 - mae: 0.0921 - val_loss: 0.0241 - val_mae: 0.0764\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0300 - mae: 0.0943 - val_loss: 0.0236 - val_mae: 0.0722\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0288 - mae: 0.0889 - val_loss: 0.0241 - val_mae: 0.0774\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0292 - mae: 0.0922 - val_loss: 0.0238 - val_mae: 0.0764\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0303 - mae: 0.0935 - val_loss: 0.0236 - val_mae: 0.0753\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0278 - mae: 0.0888 - val_loss: 0.0232 - val_mae: 0.0723\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0306 - mae: 0.102 - 0s 116us/step - loss: 0.0293 - mae: 0.0909 - val_loss: 0.0233 - val_mae: 0.0751\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0287 - mae: 0.0912 - val_loss: 0.0233 - val_mae: 0.0759\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0278 - mae: 0.0891 - val_loss: 0.0229 - val_mae: 0.0735\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0279 - mae: 0.0886 - val_loss: 0.0228 - val_mae: 0.0731\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0272 - mae: 0.0875 - val_loss: 0.0229 - val_mae: 0.0749\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0282 - mae: 0.0910 - val_loss: 0.0229 - val_mae: 0.0760\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0280 - mae: 0.0915 - val_loss: 0.0224 - val_mae: 0.0720\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0272 - mae: 0.0868 - val_loss: 0.0225 - val_mae: 0.0736\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0284 - mae: 0.0927 - val_loss: 0.0227 - val_mae: 0.0763\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0278 - mae: 0.0914 - val_loss: 0.0225 - val_mae: 0.0749\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0276 - mae: 0.0911 - val_loss: 0.0226 - val_mae: 0.0765\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0269 - mae: 0.0883 - val_loss: 0.0218 - val_mae: 0.0706\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0270 - mae: 0.0878 - val_loss: 0.0217 - val_mae: 0.0709\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0272 - mae: 0.0872 - val_loss: 0.0219 - val_mae: 0.0730\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0272 - mae: 0.0883 - val_loss: 0.0216 - val_mae: 0.0713\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0267 - mae: 0.0867 - val_loss: 0.0216 - val_mae: 0.0724\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0269 - mae: 0.0904 - val_loss: 0.0217 - val_mae: 0.0741\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0264 - mae: 0.0871 - val_loss: 0.0221 - val_mae: 0.0773\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0262 - mae: 0.0886 - val_loss: 0.0213 - val_mae: 0.0716\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0267 - mae: 0.0905 - val_loss: 0.0221 - val_mae: 0.0783\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0264 - mae: 0.0893 - val_loss: 0.0216 - val_mae: 0.0753\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0261 - mae: 0.0881 - val_loss: 0.0212 - val_mae: 0.0726\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0266 - mae: 0.0892 - val_loss: 0.0213 - val_mae: 0.0748\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0271 - mae: 0.0927 - val_loss: 0.0209 - val_mae: 0.0714\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0265 - mae: 0.0894 - val_loss: 0.0209 - val_mae: 0.0728\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0253 - mae: 0.0875 - val_loss: 0.0208 - val_mae: 0.0720\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0267 - mae: 0.0908 - val_loss: 0.0211 - val_mae: 0.0751\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0257 - mae: 0.0881 - val_loss: 0.0209 - val_mae: 0.0746\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0251 - mae: 0.0866 - val_loss: 0.0208 - val_mae: 0.0739\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0264 - mae: 0.0914 - val_loss: 0.0208 - val_mae: 0.0750\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0258 - mae: 0.0899 - val_loss: 0.0205 - val_mae: 0.0727\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0247 - mae: 0.0859 - val_loss: 0.0205 - val_mae: 0.0731\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0248 - mae: 0.0857 - val_loss: 0.0206 - val_mae: 0.0750\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0248 - mae: 0.0855 - val_loss: 0.0204 - val_mae: 0.0739\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0259 - mae: 0.0905 - val_loss: 0.0210 - val_mae: 0.0785\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0257 - mae: 0.0903 - val_loss: 0.0205 - val_mae: 0.0752\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0251 - mae: 0.0890 - val_loss: 0.0201 - val_mae: 0.0722\n",
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0246 - mae: 0.0852 - val_loss: 0.0200 - val_mae: 0.0729\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0248 - mae: 0.0873 - val_loss: 0.0202 - val_mae: 0.0746\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0246 - mae: 0.0864 - val_loss: 0.0196 - val_mae: 0.0704\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0239 - mae: 0.0842 - val_loss: 0.0195 - val_mae: 0.0698\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0247 - mae: 0.0883 - val_loss: 0.0199 - val_mae: 0.0739\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0253 - mae: 0.0905 - val_loss: 0.0195 - val_mae: 0.0709\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0245 - mae: 0.0865 - val_loss: 0.0194 - val_mae: 0.0706\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0246 - mae: 0.0881 - val_loss: 0.0196 - val_mae: 0.0732\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0253 - mae: 0.0899 - val_loss: 0.0197 - val_mae: 0.0737\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0244 - mae: 0.0882 - val_loss: 0.0199 - val_mae: 0.0761\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0253 - mae: 0.0916 - val_loss: 0.0193 - val_mae: 0.0713\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0238 - mae: 0.0850 - val_loss: 0.0195 - val_mae: 0.0737\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0246 - mae: 0.0897 - val_loss: 0.0191 - val_mae: 0.0710\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0248 - mae: 0.0899 - val_loss: 0.0192 - val_mae: 0.0719\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0240 - mae: 0.0865 - val_loss: 0.0190 - val_mae: 0.0706\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0238 - mae: 0.0871 - val_loss: 0.0192 - val_mae: 0.0731\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0258 - mae: 0.0933 - val_loss: 0.0194 - val_mae: 0.0751\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0241 - mae: 0.0874 - val_loss: 0.0193 - val_mae: 0.0748\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0235 - mae: 0.0868 - val_loss: 0.0191 - val_mae: 0.0733\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0237 - mae: 0.0884 - val_loss: 0.0192 - val_mae: 0.0747\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0235 - mae: 0.0865 - val_loss: 0.0188 - val_mae: 0.0712\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0244 - mae: 0.0881 - val_loss: 0.0188 - val_mae: 0.0716\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0243 - mae: 0.0886 - val_loss: 0.0188 - val_mae: 0.0722\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0242 - mae: 0.0891 - val_loss: 0.0188 - val_mae: 0.0733\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0236 - mae: 0.0874 - val_loss: 0.0187 - val_mae: 0.0719\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0227 - mae: 0.0826 - val_loss: 0.0187 - val_mae: 0.0723\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0228 - mae: 0.0852 - val_loss: 0.0184 - val_mae: 0.0704\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0233 - mae: 0.0850 - val_loss: 0.0186 - val_mae: 0.0727\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0236 - mae: 0.0881 - val_loss: 0.0183 - val_mae: 0.0698\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0229 - mae: 0.0837 - val_loss: 0.0185 - val_mae: 0.0721\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0236 - mae: 0.0861 - val_loss: 0.0185 - val_mae: 0.0726\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0231 - mae: 0.0855 - val_loss: 0.0185 - val_mae: 0.0729\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0231 - mae: 0.0863 - val_loss: 0.0184 - val_mae: 0.0724\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0229 - mae: 0.0856 - val_loss: 0.0183 - val_mae: 0.0718\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0232 - mae: 0.0890 - val_loss: 0.0180 - val_mae: 0.0696\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0223 - mae: 0.0831 - val_loss: 0.0185 - val_mae: 0.0745\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0238 - mae: 0.0899 - val_loss: 0.0184 - val_mae: 0.0735\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0239 - mae: 0.0893 - val_loss: 0.0181 - val_mae: 0.0722\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0233 - mae: 0.0888 - val_loss: 0.0180 - val_mae: 0.0710\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0848 - val_loss: 0.0181 - val_mae: 0.0725\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0190 - mae: 0.068 - 0s 118us/step - loss: 0.0222 - mae: 0.0863 - val_loss: 0.0180 - val_mae: 0.0723\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0235 - mae: 0.0903 - val_loss: 0.0181 - val_mae: 0.0725\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0223 - mae: 0.0851 - val_loss: 0.0180 - val_mae: 0.0722\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0224 - mae: 0.0854 - val_loss: 0.0179 - val_mae: 0.0717\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0231 - mae: 0.0887 - val_loss: 0.0180 - val_mae: 0.0725\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0229 - mae: 0.0877 - val_loss: 0.0180 - val_mae: 0.0733\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0224 - mae: 0.0864 - val_loss: 0.0181 - val_mae: 0.0740\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0280 - mae: 0.117 - 0s 112us/step - loss: 0.0230 - mae: 0.0879 - val_loss: 0.0179 - val_mae: 0.0728\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0213 - mae: 0.0831 - val_loss: 0.0177 - val_mae: 0.0719\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0222 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.0746\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0228 - mae: 0.0889 - val_loss: 0.0178 - val_mae: 0.0729\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0227 - mae: 0.0862 - val_loss: 0.0177 - val_mae: 0.0729\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0232 - mae: 0.0886 - val_loss: 0.0178 - val_mae: 0.0737\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0224 - mae: 0.0865 - val_loss: 0.0178 - val_mae: 0.0739\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0227 - mae: 0.0887 - val_loss: 0.0177 - val_mae: 0.0732\n",
      "Epoch 287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0227 - mae: 0.0879 - val_loss: 0.0176 - val_mae: 0.0717\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0218 - mae: 0.0833 - val_loss: 0.0180 - val_mae: 0.0758\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0231 - mae: 0.0909 - val_loss: 0.0175 - val_mae: 0.0720\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0230 - mae: 0.0890 - val_loss: 0.0175 - val_mae: 0.0720\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0220 - mae: 0.0845 - val_loss: 0.0176 - val_mae: 0.0733\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0229 - mae: 0.0904 - val_loss: 0.0173 - val_mae: 0.0716\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0224 - mae: 0.0875 - val_loss: 0.0174 - val_mae: 0.0719\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0225 - mae: 0.0872 - val_loss: 0.0174 - val_mae: 0.0730\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0219 - mae: 0.0849 - val_loss: 0.0177 - val_mae: 0.0747\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0219 - mae: 0.0864 - val_loss: 0.0174 - val_mae: 0.0728\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0223 - mae: 0.0887 - val_loss: 0.0178 - val_mae: 0.0760\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0228 - mae: 0.0885 - val_loss: 0.0176 - val_mae: 0.0752\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 109us/step - loss: 0.0221 - mae: 0.0875 - val_loss: 0.0175 - val_mae: 0.0745\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0218 - mae: 0.0850 - val_loss: 0.0171 - val_mae: 0.0709\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0228 - mae: 0.0884 - val_loss: 0.0174 - val_mae: 0.0740\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0219 - mae: 0.0876 - val_loss: 0.0174 - val_mae: 0.0746\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0215 - mae: 0.0864 - val_loss: 0.0174 - val_mae: 0.0742\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0215 - mae: 0.0860 - val_loss: 0.0175 - val_mae: 0.0757\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0219 - mae: 0.0884 - val_loss: 0.0174 - val_mae: 0.0751\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0218 - mae: 0.0875 - val_loss: 0.0169 - val_mae: 0.0709\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0834 - val_loss: 0.0169 - val_mae: 0.0710\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0223 - mae: 0.0888 - val_loss: 0.0171 - val_mae: 0.0726\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0216 - mae: 0.0863 - val_loss: 0.0176 - val_mae: 0.0766\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0222 - mae: 0.0892 - val_loss: 0.0171 - val_mae: 0.0735\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0216 - mae: 0.0865 - val_loss: 0.0171 - val_mae: 0.0741\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0217 - mae: 0.0862 - val_loss: 0.0169 - val_mae: 0.0726\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0213 - mae: 0.0857 - val_loss: 0.0171 - val_mae: 0.0741\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0215 - mae: 0.0871 - val_loss: 0.0173 - val_mae: 0.0755\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0214 - mae: 0.0875 - val_loss: 0.0168 - val_mae: 0.0718\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0212 - mae: 0.0846 - val_loss: 0.0166 - val_mae: 0.0706\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0225 - mae: 0.0885 - val_loss: 0.0167 - val_mae: 0.0717\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0209 - mae: 0.0824 - val_loss: 0.0166 - val_mae: 0.0707\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0218 - mae: 0.0870 - val_loss: 0.0167 - val_mae: 0.0718\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0207 - mae: 0.0846 - val_loss: 0.0166 - val_mae: 0.0715\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0228 - mae: 0.0911 - val_loss: 0.0169 - val_mae: 0.0744\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0867 - val_loss: 0.0166 - val_mae: 0.0716\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0868 - val_loss: 0.0167 - val_mae: 0.0728\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0224 - mae: 0.0897 - val_loss: 0.0166 - val_mae: 0.0720\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0216 - mae: 0.0878 - val_loss: 0.0166 - val_mae: 0.0721\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0211 - mae: 0.0847 - val_loss: 0.0167 - val_mae: 0.0731\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0851 - val_loss: 0.0168 - val_mae: 0.0741\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0211 - mae: 0.0874 - val_loss: 0.0164 - val_mae: 0.0704\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0853 - val_loss: 0.0169 - val_mae: 0.0751\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0830 - val_loss: 0.0165 - val_mae: 0.0715\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0205 - mae: 0.0845 - val_loss: 0.0167 - val_mae: 0.0737\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0214 - mae: 0.0869 - val_loss: 0.0166 - val_mae: 0.0732\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0213 - mae: 0.0848 - val_loss: 0.0166 - val_mae: 0.0728\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0862 - val_loss: 0.0164 - val_mae: 0.0714\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0218 - mae: 0.0897 - val_loss: 0.0165 - val_mae: 0.0728\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mae: 0.0869 - val_loss: 0.0165 - val_mae: 0.0728\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mae: 0.0853 - val_loss: 0.0163 - val_mae: 0.0715\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0836 - val_loss: 0.0162 - val_mae: 0.0707\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0208 - mae: 0.0833 - val_loss: 0.0164 - val_mae: 0.0720\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0862 - val_loss: 0.0165 - val_mae: 0.0736\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0846 - val_loss: 0.0163 - val_mae: 0.0722\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0215 - mae: 0.0897 - val_loss: 0.0164 - val_mae: 0.0721\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0208 - mae: 0.0846 - val_loss: 0.0164 - val_mae: 0.0722\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0208 - mae: 0.0847 - val_loss: 0.0164 - val_mae: 0.0728\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0865 - val_loss: 0.0163 - val_mae: 0.0723\n",
      "Epoch 346/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 124us/step - loss: 0.0210 - mae: 0.0859 - val_loss: 0.0165 - val_mae: 0.0741\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0207 - mae: 0.0850 - val_loss: 0.0165 - val_mae: 0.0742\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0207 - mae: 0.0855 - val_loss: 0.0163 - val_mae: 0.0734\n",
      "Epoch 349/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0205 - mae: 0.0858 - val_loss: 0.0162 - val_mae: 0.0723\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0209 - mae: 0.0861 - val_loss: 0.0161 - val_mae: 0.0718\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0202 - mae: 0.0847 - val_loss: 0.0163 - val_mae: 0.0727\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0208 - mae: 0.0863 - val_loss: 0.0161 - val_mae: 0.0713\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0213 - mae: 0.0868 - val_loss: 0.0165 - val_mae: 0.0749\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0213 - mae: 0.0871 - val_loss: 0.0165 - val_mae: 0.0744\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0207 - mae: 0.0858 - val_loss: 0.0162 - val_mae: 0.0733\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0209 - mae: 0.0845 - val_loss: 0.0161 - val_mae: 0.0724\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0209 - mae: 0.0860 - val_loss: 0.0164 - val_mae: 0.0747\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0204 - mae: 0.0850 - val_loss: 0.0164 - val_mae: 0.0750\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0210 - mae: 0.0872 - val_loss: 0.0160 - val_mae: 0.0723\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0205 - mae: 0.0850 - val_loss: 0.0160 - val_mae: 0.0720\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0209 - mae: 0.0844 - val_loss: 0.0160 - val_mae: 0.0728\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0212 - mae: 0.0900 - val_loss: 0.0162 - val_mae: 0.0735\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0206 - mae: 0.0842 - val_loss: 0.0161 - val_mae: 0.0737\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mae: 0.0871 - val_loss: 0.0159 - val_mae: 0.0718\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0206 - mae: 0.0864 - val_loss: 0.0159 - val_mae: 0.0723\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0210 - mae: 0.0869 - val_loss: 0.0157 - val_mae: 0.0701\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0204 - mae: 0.0850 - val_loss: 0.0161 - val_mae: 0.0738\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0213 - mae: 0.0897 - val_loss: 0.0162 - val_mae: 0.0752\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0205 - mae: 0.0854 - val_loss: 0.0158 - val_mae: 0.0722\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0846 - val_loss: 0.0159 - val_mae: 0.0729\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0202 - mae: 0.0852 - val_loss: 0.0159 - val_mae: 0.0723\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0202 - mae: 0.0844 - val_loss: 0.0158 - val_mae: 0.0717\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0199 - mae: 0.0841 - val_loss: 0.0158 - val_mae: 0.0714\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0849 - val_loss: 0.0155 - val_mae: 0.0692\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0206 - mae: 0.0856 - val_loss: 0.0156 - val_mae: 0.0706\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0859 - val_loss: 0.0161 - val_mae: 0.0745\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0158 - val_mae: 0.0727\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0201 - mae: 0.0858 - val_loss: 0.0154 - val_mae: 0.0690\n",
      "Epoch 379/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0204 - mae: 0.0854 - val_loss: 0.0155 - val_mae: 0.0699\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0206 - mae: 0.0864 - val_loss: 0.0161 - val_mae: 0.0746\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mae: 0.0893 - val_loss: 0.0155 - val_mae: 0.0710\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0873 - val_loss: 0.0159 - val_mae: 0.0743\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0202 - mae: 0.0862 - val_loss: 0.0157 - val_mae: 0.0729\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0208 - mae: 0.0882 - val_loss: 0.0158 - val_mae: 0.0736\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0208 - mae: 0.0878 - val_loss: 0.0156 - val_mae: 0.0720\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0208 - mae: 0.0867 - val_loss: 0.0157 - val_mae: 0.0733\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0201 - mae: 0.0859 - val_loss: 0.0160 - val_mae: 0.0745\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0205 - mae: 0.0867 - val_loss: 0.0154 - val_mae: 0.0709\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0841 - val_loss: 0.0156 - val_mae: 0.0719\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0197 - mae: 0.0851 - val_loss: 0.0155 - val_mae: 0.0719\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0206 - mae: 0.0877 - val_loss: 0.0155 - val_mae: 0.0720\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mae: 0.0889 - val_loss: 0.0156 - val_mae: 0.0729\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0205 - mae: 0.0859 - val_loss: 0.0157 - val_mae: 0.0737\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0863 - val_loss: 0.0156 - val_mae: 0.0727\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0204 - mae: 0.0861 - val_loss: 0.0158 - val_mae: 0.0744\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0828 - val_loss: 0.0156 - val_mae: 0.0734\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0204 - mae: 0.0866 - val_loss: 0.0159 - val_mae: 0.0750\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0198 - mae: 0.0857 - val_loss: 0.0155 - val_mae: 0.0721\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mae: 0.0869 - val_loss: 0.0154 - val_mae: 0.0712\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0199 - mae: 0.0848 - val_loss: 0.0152 - val_mae: 0.0695\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0841 - val_loss: 0.0155 - val_mae: 0.0729\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0202 - mae: 0.0860 - val_loss: 0.0160 - val_mae: 0.0763\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0200 - mae: 0.0851 - val_loss: 0.0155 - val_mae: 0.0723\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0707\n",
      "Epoch 405/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mae: 0.0849 - val_loss: 0.0151 - val_mae: 0.0700\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0832 - val_loss: 0.0154 - val_mae: 0.0726\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0203 - mae: 0.0856 - val_loss: 0.0158 - val_mae: 0.0755\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0200 - mae: 0.0861 - val_loss: 0.0158 - val_mae: 0.0754\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0706\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0193 - mae: 0.0830 - val_loss: 0.0153 - val_mae: 0.0713\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0199 - mae: 0.0845 - val_loss: 0.0157 - val_mae: 0.0746\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0200 - mae: 0.0844 - val_loss: 0.0155 - val_mae: 0.0732\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0201 - mae: 0.0861 - val_loss: 0.0153 - val_mae: 0.0722\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0831 - val_loss: 0.0152 - val_mae: 0.0707\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0197 - mae: 0.0838 - val_loss: 0.0155 - val_mae: 0.0730\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0202 - mae: 0.0859 - val_loss: 0.0151 - val_mae: 0.0703\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0192 - mae: 0.0828 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0151 - val_mae: 0.0707\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0200 - mae: 0.0846 - val_loss: 0.0151 - val_mae: 0.0709\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0200 - mae: 0.0846 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0201 - mae: 0.0862 - val_loss: 0.0154 - val_mae: 0.0732\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0190 - mae: 0.0835 - val_loss: 0.0153 - val_mae: 0.0724\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0853 - val_loss: 0.0152 - val_mae: 0.0719\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0195 - mae: 0.0846 - val_loss: 0.0150 - val_mae: 0.0708\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0831 - val_loss: 0.0148 - val_mae: 0.0681\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0190 - mae: 0.0835 - val_loss: 0.0153 - val_mae: 0.0730\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0208 - mae: 0.0876 - val_loss: 0.0154 - val_mae: 0.0744\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mae: 0.0878 - val_loss: 0.0151 - val_mae: 0.0724\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0199 - mae: 0.0855 - val_loss: 0.0149 - val_mae: 0.0697\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0203 - mae: 0.0856 - val_loss: 0.0151 - val_mae: 0.0718\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0842 - val_loss: 0.0150 - val_mae: 0.0712\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mae: 0.0823 - val_loss: 0.0148 - val_mae: 0.0687\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0198 - mae: 0.0838 - val_loss: 0.0152 - val_mae: 0.0721\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0192 - mae: 0.0836 - val_loss: 0.0149 - val_mae: 0.0704\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0205 - mae: 0.0881 - val_loss: 0.0149 - val_mae: 0.0706\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0194 - mae: 0.0837 - val_loss: 0.0150 - val_mae: 0.0714\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0841 - val_loss: 0.0151 - val_mae: 0.0721\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0195 - mae: 0.0841 - val_loss: 0.0152 - val_mae: 0.0729\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mae: 0.0888 - val_loss: 0.0152 - val_mae: 0.0733\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0191 - mae: 0.0833 - val_loss: 0.0152 - val_mae: 0.0731\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0194 - mae: 0.0858 - val_loss: 0.0147 - val_mae: 0.0678\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0192 - mae: 0.0831 - val_loss: 0.0151 - val_mae: 0.0719\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0197 - mae: 0.0846 - val_loss: 0.0147 - val_mae: 0.0699\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0844 - val_loss: 0.0148 - val_mae: 0.0709\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0202 - mae: 0.0866 - val_loss: 0.0150 - val_mae: 0.0721\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0202 - mae: 0.0889 - val_loss: 0.0148 - val_mae: 0.0706\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0203 - mae: 0.0886 - val_loss: 0.0148 - val_mae: 0.0711\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0192 - mae: 0.0831 - val_loss: 0.0150 - val_mae: 0.0726\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0801 - val_loss: 0.0150 - val_mae: 0.0722\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0193 - mae: 0.0843 - val_loss: 0.0151 - val_mae: 0.0729\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0193 - mae: 0.0845 - val_loss: 0.0148 - val_mae: 0.0699\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0199 - mae: 0.0850 - val_loss: 0.0149 - val_mae: 0.0718\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0189 - mae: 0.0811 - val_loss: 0.0150 - val_mae: 0.0724\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0195 - mae: 0.0859 - val_loss: 0.0149 - val_mae: 0.0717\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0186 - mae: 0.0813 - val_loss: 0.0150 - val_mae: 0.0721\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0185 - mae: 0.0807 - val_loss: 0.0145 - val_mae: 0.0680\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0197 - mae: 0.0856 - val_loss: 0.0148 - val_mae: 0.0706\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0204 - mae: 0.0884 - val_loss: 0.0146 - val_mae: 0.0694\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0191 - mae: 0.0838 - val_loss: 0.0150 - val_mae: 0.0736\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0149 - val_mae: 0.0724\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0193 - mae: 0.0842 - val_loss: 0.0149 - val_mae: 0.0719\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0190 - mae: 0.0839 - val_loss: 0.0147 - val_mae: 0.0704\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0204 - mae: 0.0870 - val_loss: 0.0153 - val_mae: 0.0751\n",
      "Epoch 464/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 108us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0145 - val_mae: 0.0677\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0789 - val_loss: 0.0144 - val_mae: 0.0666\n",
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0190 - mae: 0.0826 - val_loss: 0.0146 - val_mae: 0.0696\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0828 - val_loss: 0.0146 - val_mae: 0.0706\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0192 - mae: 0.0840 - val_loss: 0.0145 - val_mae: 0.0701\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0183 - mae: 0.0793 - val_loss: 0.0146 - val_mae: 0.0706\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0798 - val_loss: 0.0150 - val_mae: 0.0733\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0815 - val_loss: 0.0145 - val_mae: 0.0709\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0188 - mae: 0.0832 - val_loss: 0.0150 - val_mae: 0.0739\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0844 - val_loss: 0.0146 - val_mae: 0.0709\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0849 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0185 - mae: 0.0807 - val_loss: 0.0143 - val_mae: 0.0672\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0196 - mae: 0.0836 - val_loss: 0.0144 - val_mae: 0.0696\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0192 - mae: 0.0842 - val_loss: 0.0149 - val_mae: 0.0732\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0840 - val_loss: 0.0146 - val_mae: 0.0708\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0190 - mae: 0.0834 - val_loss: 0.0150 - val_mae: 0.0738\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0872 - val_loss: 0.0145 - val_mae: 0.0702\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0194 - mae: 0.0840 - val_loss: 0.0148 - val_mae: 0.0730\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0192 - mae: 0.0853 - val_loss: 0.0145 - val_mae: 0.0717\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0185 - mae: 0.0831 - val_loss: 0.0144 - val_mae: 0.0695\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0191 - mae: 0.0828 - val_loss: 0.0146 - val_mae: 0.0715\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0184 - mae: 0.0824 - val_loss: 0.0143 - val_mae: 0.0667\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0826 - val_loss: 0.0143 - val_mae: 0.0674\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0195 - mae: 0.0844 - val_loss: 0.0143 - val_mae: 0.0681\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0190 - mae: 0.0826 - val_loss: 0.0144 - val_mae: 0.0699\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0195 - mae: 0.0848 - val_loss: 0.0144 - val_mae: 0.0706\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0184 - mae: 0.0821 - val_loss: 0.0144 - val_mae: 0.0694\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0196 - mae: 0.0842 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0180 - mae: 0.0794 - val_loss: 0.0144 - val_mae: 0.0688\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0803 - val_loss: 0.0144 - val_mae: 0.0690\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0184 - mae: 0.0805 - val_loss: 0.0146 - val_mae: 0.0716\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0193 - mae: 0.0843 - val_loss: 0.0146 - val_mae: 0.0712\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0189 - mae: 0.0836 - val_loss: 0.0143 - val_mae: 0.0688\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0186 - mae: 0.0826 - val_loss: 0.0144 - val_mae: 0.0696\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0143 - val_mae: 0.0684\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0805 - val_loss: 0.0142 - val_mae: 0.0660\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0788 - val_loss: 0.0143 - val_mae: 0.0694\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0183 - mae: 0.0808 - val_loss: 0.0141 - val_mae: 0.0674\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0181 - mae: 0.0799 - val_loss: 0.0142 - val_mae: 0.0688\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mae: 0.0781 - val_loss: 0.0141 - val_mae: 0.0672\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0191 - mae: 0.0821 - val_loss: 0.0144 - val_mae: 0.0702\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0188 - mae: 0.0834 - val_loss: 0.0142 - val_mae: 0.0683\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0183 - mae: 0.0812 - val_loss: 0.0145 - val_mae: 0.0716\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0844 - val_loss: 0.0145 - val_mae: 0.0713\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0181 - mae: 0.0805 - val_loss: 0.0148 - val_mae: 0.0737\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mae: 0.0841 - val_loss: 0.0142 - val_mae: 0.0692\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0821 - val_loss: 0.0145 - val_mae: 0.0720\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0806 - val_loss: 0.0143 - val_mae: 0.0712\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0827 - val_loss: 0.0143 - val_mae: 0.0712\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0811 - val_loss: 0.0140 - val_mae: 0.0684\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0807 - val_loss: 0.0143 - val_mae: 0.0706\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0832 - val_loss: 0.0141 - val_mae: 0.0686\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0817 - val_loss: 0.0143 - val_mae: 0.0711\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0197 - mae: 0.0864 - val_loss: 0.0143 - val_mae: 0.0708\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mae: 0.0827 - val_loss: 0.0143 - val_mae: 0.0713\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0183 - mae: 0.0825 - val_loss: 0.0145 - val_mae: 0.0720\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mae: 0.0830 - val_loss: 0.0141 - val_mae: 0.0699\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0186 - mae: 0.0806 - val_loss: 0.0142 - val_mae: 0.0708\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0838 - val_loss: 0.0141 - val_mae: 0.0690\n",
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0189 - mae: 0.0837 - val_loss: 0.0140 - val_mae: 0.0683\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mae: 0.0841 - val_loss: 0.0142 - val_mae: 0.0704\n",
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0179 - mae: 0.0797 - val_loss: 0.0141 - val_mae: 0.0695\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0777 - val_loss: 0.0140 - val_mae: 0.0677\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0192 - mae: 0.0835 - val_loss: 0.0142 - val_mae: 0.0699\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0810 - val_loss: 0.0141 - val_mae: 0.0690\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.0839 - val_loss: 0.0140 - val_mae: 0.0701\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0141 - val_mae: 0.0700\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0792 - val_loss: 0.0139 - val_mae: 0.0684\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0174 - mae: 0.0767 - val_loss: 0.0138 - val_mae: 0.0674\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0802 - val_loss: 0.0139 - val_mae: 0.0686\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0187 - mae: 0.0817 - val_loss: 0.0138 - val_mae: 0.0680\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0186 - mae: 0.0818 - val_loss: 0.0140 - val_mae: 0.0699\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0815 - val_loss: 0.0137 - val_mae: 0.0661\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0190 - mae: 0.0839 - val_loss: 0.0137 - val_mae: 0.0670\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0775 - val_loss: 0.0137 - val_mae: 0.0673\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0179 - mae: 0.0801 - val_loss: 0.0144 - val_mae: 0.0733\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0817 - val_loss: 0.0140 - val_mae: 0.0697\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0188 - mae: 0.0823 - val_loss: 0.0141 - val_mae: 0.0702\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0187 - mae: 0.0823 - val_loss: 0.0140 - val_mae: 0.0698\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0139 - val_mae: 0.0695\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0176 - mae: 0.0781 - val_loss: 0.0143 - val_mae: 0.0724\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0187 - mae: 0.0839 - val_loss: 0.0144 - val_mae: 0.0730\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0822 - val_loss: 0.0136 - val_mae: 0.0660\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0171 - mae: 0.0764 - val_loss: 0.0137 - val_mae: 0.0671\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0172 - mae: 0.0782 - val_loss: 0.0139 - val_mae: 0.0698\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mae: 0.0841 - val_loss: 0.0139 - val_mae: 0.0693\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0808 - val_loss: 0.0139 - val_mae: 0.0696\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0805 - val_loss: 0.0141 - val_mae: 0.0711\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0181 - mae: 0.0808 - val_loss: 0.0140 - val_mae: 0.0700\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0189 - mae: 0.0830 - val_loss: 0.0141 - val_mae: 0.0709\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0182 - mae: 0.0805 - val_loss: 0.0141 - val_mae: 0.0711\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0187 - mae: 0.0822 - val_loss: 0.0139 - val_mae: 0.0698\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0827 - val_loss: 0.0139 - val_mae: 0.0700\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0826 - val_loss: 0.0139 - val_mae: 0.0700\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0173 - mae: 0.0780 - val_loss: 0.0138 - val_mae: 0.0691\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0171 - mae: 0.081 - 0s 108us/step - loss: 0.0181 - mae: 0.0809 - val_loss: 0.0139 - val_mae: 0.0702\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0191 - mae: 0.0839 - val_loss: 0.0141 - val_mae: 0.0719\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mae: 0.0806 - val_loss: 0.0137 - val_mae: 0.0663\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0188 - mae: 0.0829 - val_loss: 0.0138 - val_mae: 0.0694\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0175 - mae: 0.0786 - val_loss: 0.0137 - val_mae: 0.0686\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0777 - val_loss: 0.0136 - val_mae: 0.0675\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0800 - val_loss: 0.0136 - val_mae: 0.0682\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0179 - mae: 0.0797 - val_loss: 0.0138 - val_mae: 0.0700\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0183 - mae: 0.0816 - val_loss: 0.0139 - val_mae: 0.0709\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0188 - mae: 0.0856 - val_loss: 0.0138 - val_mae: 0.0703\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0184 - mae: 0.0820 - val_loss: 0.0135 - val_mae: 0.0672\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0190 - mae: 0.0855 - val_loss: 0.0136 - val_mae: 0.0686\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0812 - val_loss: 0.0136 - val_mae: 0.0694\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0185 - mae: 0.0837 - val_loss: 0.0140 - val_mae: 0.0714\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0187 - mae: 0.0833 - val_loss: 0.0137 - val_mae: 0.0699\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0830 - val_loss: 0.0137 - val_mae: 0.0697\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0179 - mae: 0.0814 - val_loss: 0.0136 - val_mae: 0.0688\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0821 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0180 - mae: 0.0811 - val_loss: 0.0134 - val_mae: 0.0670\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0175 - mae: 0.0797 - val_loss: 0.0135 - val_mae: 0.0682\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0178 - mae: 0.0805 - val_loss: 0.0137 - val_mae: 0.0700\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0170 - mae: 0.0775 - val_loss: 0.0142 - val_mae: 0.0726\n",
      "Epoch 581/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0802 - val_loss: 0.0135 - val_mae: 0.0676\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0182 - mae: 0.0811 - val_loss: 0.0134 - val_mae: 0.0659\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0178 - mae: 0.0809 - val_loss: 0.0136 - val_mae: 0.0668\n",
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0806 - val_loss: 0.0139 - val_mae: 0.0710\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0178 - mae: 0.0804 - val_loss: 0.0137 - val_mae: 0.0697\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0174 - mae: 0.0805 - val_loss: 0.0135 - val_mae: 0.0674\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0789 - val_loss: 0.0134 - val_mae: 0.0663\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0179 - mae: 0.0798 - val_loss: 0.0135 - val_mae: 0.0679\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0806 - val_loss: 0.0136 - val_mae: 0.0691\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0178 - mae: 0.0799 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0787 - val_loss: 0.0134 - val_mae: 0.0672\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0179 - mae: 0.0802 - val_loss: 0.0136 - val_mae: 0.0690\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0180 - mae: 0.0809 - val_loss: 0.0139 - val_mae: 0.0716\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mae: 0.0750 - val_loss: 0.0135 - val_mae: 0.0684\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0179 - mae: 0.0811 - val_loss: 0.0136 - val_mae: 0.0706\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0180 - mae: 0.0835 - val_loss: 0.0135 - val_mae: 0.0694\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0819 - val_loss: 0.0133 - val_mae: 0.0659\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0788 - val_loss: 0.0134 - val_mae: 0.0677\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0176 - mae: 0.0794 - val_loss: 0.0134 - val_mae: 0.0682\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0175 - mae: 0.0795 - val_loss: 0.0135 - val_mae: 0.0695\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0796 - val_loss: 0.0135 - val_mae: 0.0688\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0777 - val_loss: 0.0140 - val_mae: 0.0728\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0174 - mae: 0.0798 - val_loss: 0.0136 - val_mae: 0.0697\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0173 - mae: 0.0806 - val_loss: 0.0135 - val_mae: 0.0689\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0177 - mae: 0.0807 - val_loss: 0.0134 - val_mae: 0.0680\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0185 - mae: 0.0827 - val_loss: 0.0136 - val_mae: 0.0698\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0176 - mae: 0.0797 - val_loss: 0.0135 - val_mae: 0.0696\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0169 - mae: 0.0782 - val_loss: 0.0134 - val_mae: 0.0686\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0793 - val_loss: 0.0132 - val_mae: 0.0671\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0178 - mae: 0.0828 - val_loss: 0.0134 - val_mae: 0.0686\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0175 - mae: 0.0806 - val_loss: 0.0134 - val_mae: 0.0683\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0180 - mae: 0.0803 - val_loss: 0.0136 - val_mae: 0.0703\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mae: 0.0827 - val_loss: 0.0140 - val_mae: 0.0727\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0163 - mae: 0.0755 - val_loss: 0.0132 - val_mae: 0.0665\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0173 - mae: 0.0783 - val_loss: 0.0137 - val_mae: 0.0706\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0798 - val_loss: 0.0133 - val_mae: 0.0678\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0177 - mae: 0.0796 - val_loss: 0.0134 - val_mae: 0.0688\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0173 - mae: 0.0789 - val_loss: 0.0132 - val_mae: 0.0669\n",
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0182 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.0657\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0178 - mae: 0.0797 - val_loss: 0.0131 - val_mae: 0.0668\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0179 - mae: 0.0814 - val_loss: 0.0130 - val_mae: 0.0656\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0177 - mae: 0.0801 - val_loss: 0.0131 - val_mae: 0.0661\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0136 - val_mae: 0.0703\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0178 - mae: 0.0817 - val_loss: 0.0133 - val_mae: 0.0681\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0183 - mae: 0.0814 - val_loss: 0.0132 - val_mae: 0.0672\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0764 - val_loss: 0.0134 - val_mae: 0.0694\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0176 - mae: 0.0813 - val_loss: 0.0131 - val_mae: 0.0670\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0186 - mae: 0.0829 - val_loss: 0.0133 - val_mae: 0.0687\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0172 - mae: 0.0802 - val_loss: 0.0132 - val_mae: 0.0673\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0183 - mae: 0.0829 - val_loss: 0.0130 - val_mae: 0.0647\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0176 - mae: 0.0802 - val_loss: 0.0132 - val_mae: 0.0674\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0169 - mae: 0.0775 - val_loss: 0.0131 - val_mae: 0.0664\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0177 - mae: 0.0803 - val_loss: 0.0134 - val_mae: 0.0685\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0174 - mae: 0.0776 - val_loss: 0.0131 - val_mae: 0.0652\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0171 - mae: 0.0782 - val_loss: 0.0131 - val_mae: 0.0664\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0770 - val_loss: 0.0132 - val_mae: 0.0675\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0173 - mae: 0.0787 - val_loss: 0.0130 - val_mae: 0.0661\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0176 - mae: 0.0815 - val_loss: 0.0136 - val_mae: 0.0710\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0180 - mae: 0.0822 - val_loss: 0.0129 - val_mae: 0.0642\n",
      "Epoch 640/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0170 - mae: 0.0770 - val_loss: 0.0130 - val_mae: 0.0659\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0175 - mae: 0.0799 - val_loss: 0.0129 - val_mae: 0.0653\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0173 - mae: 0.0801 - val_loss: 0.0133 - val_mae: 0.0686\n",
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0180 - mae: 0.0837 - val_loss: 0.0132 - val_mae: 0.0686\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0170 - mae: 0.0795 - val_loss: 0.0131 - val_mae: 0.0679\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mae: 0.0817 - val_loss: 0.0130 - val_mae: 0.0656\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mae: 0.0826 - val_loss: 0.0136 - val_mae: 0.0712\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0175 - mae: 0.0808 - val_loss: 0.0134 - val_mae: 0.0693\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0177 - mae: 0.0812 - val_loss: 0.0135 - val_mae: 0.0696\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0175 - mae: 0.0790 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0165 - mae: 0.0760 - val_loss: 0.0133 - val_mae: 0.0688\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0171 - mae: 0.0787 - val_loss: 0.0132 - val_mae: 0.0681\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0175 - mae: 0.0807 - val_loss: 0.0134 - val_mae: 0.0692\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0178 - mae: 0.0804 - val_loss: 0.0133 - val_mae: 0.0694\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0168 - mae: 0.0790 - val_loss: 0.0130 - val_mae: 0.0669\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0169 - mae: 0.0781 - val_loss: 0.0132 - val_mae: 0.0686\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0176 - mae: 0.0799 - val_loss: 0.0131 - val_mae: 0.0677\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0162 - mae: 0.078 - 0s 114us/step - loss: 0.0172 - mae: 0.0790 - val_loss: 0.0131 - val_mae: 0.0681\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0169 - mae: 0.0797 - val_loss: 0.0131 - val_mae: 0.0682\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0168 - mae: 0.0783 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0181 - mae: 0.0822 - val_loss: 0.0134 - val_mae: 0.0696\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0825 - val_loss: 0.0135 - val_mae: 0.0710\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0175 - mae: 0.0817 - val_loss: 0.0131 - val_mae: 0.0657\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0182 - mae: 0.0806 - val_loss: 0.0131 - val_mae: 0.0681\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0174 - mae: 0.0803 - val_loss: 0.0132 - val_mae: 0.0683\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mae: 0.0755 - val_loss: 0.0129 - val_mae: 0.0667\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0182 - mae: 0.0823 - val_loss: 0.0130 - val_mae: 0.0674\n",
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mae: 0.0769 - val_loss: 0.0130 - val_mae: 0.0668\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0181 - mae: 0.0819 - val_loss: 0.0133 - val_mae: 0.0696\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0165 - mae: 0.0761 - val_loss: 0.0133 - val_mae: 0.0693\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00669: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_small = build_small_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_small.compile(optimizer = optimizer, loss='mse', metrics=['mae'])\n",
    "model_small.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['small'] = model_small.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_76\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_207 (Dense)            (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dropout_97 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 661\n",
      "Trainable params: 661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 482 samples, validate on 121 samples\n",
      "Epoch 1/10000\n",
      "482/482 [==============================] - 1s 2ms/step - loss: 0.2259 - mse: 0.1734 - val_loss: 0.2455 - val_mse: 0.1950\n",
      "Epoch 2/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2225 - mse: 0.1717 - val_loss: 0.2438 - val_mse: 0.1950\n",
      "Epoch 3/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2219 - mse: 0.1726 - val_loss: 0.2425 - val_mse: 0.1950\n",
      "Epoch 4/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.2149 - mse: 0.1668 - val_loss: 0.2419 - val_mse: 0.1950\n",
      "Epoch 5/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.2070 - mse: 0.1595 - val_loss: 0.2409 - val_mse: 0.1947\n",
      "Epoch 6/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.2057 - mse: 0.1590 - val_loss: 0.2384 - val_mse: 0.1934\n",
      "Epoch 7/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.1960 - mse: 0.1496 - val_loss: 0.1891 - val_mse: 0.1426\n",
      "Epoch 8/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.1679 - mse: 0.1201 - val_loss: 0.1417 - val_mse: 0.0942\n",
      "Epoch 9/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.1431 - mse: 0.0945 - val_loss: 0.1139 - val_mse: 0.0659\n",
      "Epoch 10/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.1356 - mse: 0.0868 - val_loss: 0.0960 - val_mse: 0.0481\n",
      "Epoch 11/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.1143 - mse: 0.0655 - val_loss: 0.0802 - val_mse: 0.0323\n",
      "Epoch 12/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.1154 - mse: 0.0669 - val_loss: 0.0728 - val_mse: 0.0259\n",
      "Epoch 13/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.1078 - mse: 0.0606 - val_loss: 0.0687 - val_mse: 0.0229\n",
      "Epoch 14/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.1012 - mse: 0.0552 - val_loss: 0.0665 - val_mse: 0.0219\n",
      "Epoch 15/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.1000 - mse: 0.0553 - val_loss: 0.0659 - val_mse: 0.0230\n",
      "Epoch 16/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0950 - mse: 0.0519 - val_loss: 0.0642 - val_mse: 0.0220\n",
      "Epoch 17/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0894 - mse: 0.0469 - val_loss: 0.0642 - val_mse: 0.0229\n",
      "Epoch 18/10000\n",
      "482/482 [==============================] - 0s 81us/step - loss: 0.0876 - mse: 0.0460 - val_loss: 0.0649 - val_mse: 0.0248\n",
      "Epoch 19/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0897 - mse: 0.0495 - val_loss: 0.0661 - val_mse: 0.0273\n",
      "Epoch 20/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0889 - mse: 0.0497 - val_loss: 0.0656 - val_mse: 0.0276\n",
      "Epoch 21/10000\n",
      "482/482 [==============================] - 0s 89us/step - loss: 0.0870 - mse: 0.0486 - val_loss: 0.0659 - val_mse: 0.0288\n",
      "Epoch 22/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0841 - mse: 0.0466 - val_loss: 0.0651 - val_mse: 0.0286\n",
      "Epoch 23/10000\n",
      "482/482 [==============================] - 0s 83us/step - loss: 0.0865 - mse: 0.0497 - val_loss: 0.0637 - val_mse: 0.0274\n",
      "Epoch 24/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0843 - mse: 0.0479 - val_loss: 0.0644 - val_mse: 0.0292\n",
      "Epoch 25/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0840 - mse: 0.0482 - val_loss: 0.0629 - val_mse: 0.0278\n",
      "Epoch 26/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0804 - mse: 0.0452 - val_loss: 0.0635 - val_mse: 0.0295\n",
      "Epoch 27/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0797 - mse: 0.0454 - val_loss: 0.0628 - val_mse: 0.0294\n",
      "Epoch 28/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0853 - mse: 0.0513 - val_loss: 0.0620 - val_mse: 0.0287\n",
      "Epoch 29/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0796 - mse: 0.0458 - val_loss: 0.0608 - val_mse: 0.0276\n",
      "Epoch 30/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0765 - mse: 0.0430 - val_loss: 0.0609 - val_mse: 0.0284\n",
      "Epoch 31/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0811 - mse: 0.0484 - val_loss: 0.0600 - val_mse: 0.0278\n",
      "Epoch 32/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0788 - mse: 0.0463 - val_loss: 0.0589 - val_mse: 0.0265\n",
      "Epoch 33/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0809 - mse: 0.0481 - val_loss: 0.0588 - val_mse: 0.0269\n",
      "Epoch 34/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0800 - mse: 0.0480 - val_loss: 0.0587 - val_mse: 0.0275\n",
      "Epoch 35/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0764 - mse: 0.0448 - val_loss: 0.0580 - val_mse: 0.0271\n",
      "Epoch 36/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0783 - mse: 0.0471 - val_loss: 0.0569 - val_mse: 0.0260\n",
      "Epoch 37/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0767 - mse: 0.0455 - val_loss: 0.0568 - val_mse: 0.0263\n",
      "Epoch 38/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0732 - mse: 0.0427 - val_loss: 0.0573 - val_mse: 0.0277\n",
      "Epoch 39/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0717 - mse: 0.0418 - val_loss: 0.0559 - val_mse: 0.0265\n",
      "Epoch 40/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0734 - mse: 0.0437 - val_loss: 0.0563 - val_mse: 0.0276\n",
      "Epoch 41/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0714 - mse: 0.0423 - val_loss: 0.0545 - val_mse: 0.0255\n",
      "Epoch 42/10000\n",
      "482/482 [==============================] - 0s 87us/step - loss: 0.0734 - mse: 0.0439 - val_loss: 0.0535 - val_mse: 0.0241\n",
      "Epoch 43/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0651 - mse: 0.0355 - val_loss: 0.0531 - val_mse: 0.0243\n",
      "Epoch 44/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0704 - mse: 0.0415 - val_loss: 0.0522 - val_mse: 0.0235\n",
      "Epoch 45/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0692 - mse: 0.0402 - val_loss: 0.0522 - val_mse: 0.0238\n",
      "Epoch 46/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0693 - mse: 0.0406 - val_loss: 0.0515 - val_mse: 0.0237\n",
      "Epoch 47/10000\n",
      "482/482 [==============================] - 0s 81us/step - loss: 0.0693 - mse: 0.0412 - val_loss: 0.0513 - val_mse: 0.0236\n",
      "Epoch 48/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0659 - mse: 0.0380 - val_loss: 0.0513 - val_mse: 0.0241\n",
      "Epoch 49/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0674 - mse: 0.0400 - val_loss: 0.0504 - val_mse: 0.0232\n",
      "Epoch 50/10000\n",
      "482/482 [==============================] - 0s 79us/step - loss: 0.0625 - mse: 0.0352 - val_loss: 0.0500 - val_mse: 0.0233\n",
      "Epoch 51/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0636 - mse: 0.0366 - val_loss: 0.0497 - val_mse: 0.0235\n",
      "Epoch 52/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0606 - mse: 0.0341 - val_loss: 0.0491 - val_mse: 0.0234\n",
      "Epoch 53/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0688 - mse: 0.0426 - val_loss: 0.0478 - val_mse: 0.0217\n",
      "Epoch 54/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0670 - mse: 0.0406 - val_loss: 0.0474 - val_mse: 0.0213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0613 - mse: 0.0352 - val_loss: 0.0463 - val_mse: 0.0203\n",
      "Epoch 56/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0612 - mse: 0.0352 - val_loss: 0.0466 - val_mse: 0.0214\n",
      "Epoch 57/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0677 - mse: 0.040 - 0s 110us/step - loss: 0.0588 - mse: 0.0336 - val_loss: 0.0453 - val_mse: 0.0202\n",
      "Epoch 58/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0616 - mse: 0.0364 - val_loss: 0.0445 - val_mse: 0.0193\n",
      "Epoch 59/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0573 - mse: 0.0321 - val_loss: 0.0437 - val_mse: 0.0186\n",
      "Epoch 60/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0636 - mse: 0.0386 - val_loss: 0.0438 - val_mse: 0.0189\n",
      "Epoch 61/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0561 - mse: 0.0312 - val_loss: 0.0433 - val_mse: 0.0186\n",
      "Epoch 62/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0584 - mse: 0.0338 - val_loss: 0.0432 - val_mse: 0.0190\n",
      "Epoch 63/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0587 - mse: 0.0344 - val_loss: 0.0436 - val_mse: 0.0198\n",
      "Epoch 64/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0584 - mse: 0.0343 - val_loss: 0.0432 - val_mse: 0.0195\n",
      "Epoch 65/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0585 - mse: 0.0346 - val_loss: 0.0431 - val_mse: 0.0200\n",
      "Epoch 66/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0558 - mse: 0.0324 - val_loss: 0.0411 - val_mse: 0.0179\n",
      "Epoch 67/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0590 - mse: 0.0358 - val_loss: 0.0407 - val_mse: 0.0177\n",
      "Epoch 68/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0569 - mse: 0.0341 - val_loss: 0.0400 - val_mse: 0.0170\n",
      "Epoch 69/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0530 - mse: 0.0300 - val_loss: 0.0396 - val_mse: 0.0168\n",
      "Epoch 70/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0564 - mse: 0.0336 - val_loss: 0.0402 - val_mse: 0.0181\n",
      "Epoch 71/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0532 - mse: 0.0310 - val_loss: 0.0391 - val_mse: 0.0168\n",
      "Epoch 72/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0544 - mse: 0.0321 - val_loss: 0.0393 - val_mse: 0.0176\n",
      "Epoch 73/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0504 - mse: 0.0285 - val_loss: 0.0383 - val_mse: 0.0164\n",
      "Epoch 74/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0534 - mse: 0.0316 - val_loss: 0.0386 - val_mse: 0.0173\n",
      "Epoch 75/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0516 - mse: 0.0301 - val_loss: 0.0373 - val_mse: 0.0158\n",
      "Epoch 76/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0540 - mse: 0.0326 - val_loss: 0.0368 - val_mse: 0.0151\n",
      "Epoch 77/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0549 - mse: 0.0335 - val_loss: 0.0377 - val_mse: 0.0169\n",
      "Epoch 78/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0527 - mse: 0.0320 - val_loss: 0.0365 - val_mse: 0.0156\n",
      "Epoch 79/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0503 - mse: 0.0295 - val_loss: 0.0362 - val_mse: 0.0153\n",
      "Epoch 80/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0487 - mse: 0.0280 - val_loss: 0.0359 - val_mse: 0.0152\n",
      "Epoch 81/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0472 - mse: 0.0267 - val_loss: 0.0354 - val_mse: 0.0149\n",
      "Epoch 82/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0468 - mse: 0.0264 - val_loss: 0.0356 - val_mse: 0.0154\n",
      "Epoch 83/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0497 - mse: 0.0297 - val_loss: 0.0358 - val_mse: 0.0162\n",
      "Epoch 84/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0532 - mse: 0.0334 - val_loss: 0.0362 - val_mse: 0.0171\n",
      "Epoch 85/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0478 - mse: 0.0286 - val_loss: 0.0349 - val_mse: 0.0156\n",
      "Epoch 86/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0467 - mse: 0.0274 - val_loss: 0.0336 - val_mse: 0.0141\n",
      "Epoch 87/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0487 - mse: 0.0296 - val_loss: 0.0335 - val_mse: 0.0141\n",
      "Epoch 88/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0476 - mse: 0.0283 - val_loss: 0.0338 - val_mse: 0.0148\n",
      "Epoch 89/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0459 - mse: 0.0270 - val_loss: 0.0331 - val_mse: 0.0143\n",
      "Epoch 90/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0480 - mse: 0.0291 - val_loss: 0.0327 - val_mse: 0.0138\n",
      "Epoch 91/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0477 - mse: 0.0290 - val_loss: 0.0323 - val_mse: 0.0136\n",
      "Epoch 92/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0476 - mse: 0.0290 - val_loss: 0.0319 - val_mse: 0.0133\n",
      "Epoch 93/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0442 - mse: 0.0258 - val_loss: 0.0327 - val_mse: 0.0149\n",
      "Epoch 94/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0460 - mse: 0.0281 - val_loss: 0.0313 - val_mse: 0.0131\n",
      "Epoch 95/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0453 - mse: 0.0271 - val_loss: 0.0314 - val_mse: 0.0136\n",
      "Epoch 96/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0464 - mse: 0.0288 - val_loss: 0.0318 - val_mse: 0.0147\n",
      "Epoch 97/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0430 - mse: 0.0259 - val_loss: 0.0310 - val_mse: 0.0137\n",
      "Epoch 98/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0438 - mse: 0.0265 - val_loss: 0.0308 - val_mse: 0.0137\n",
      "Epoch 99/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0430 - mse: 0.0260 - val_loss: 0.0302 - val_mse: 0.0131\n",
      "Epoch 100/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0421 - mse: 0.0252 - val_loss: 0.0302 - val_mse: 0.0133\n",
      "Epoch 101/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0438 - mse: 0.0271 - val_loss: 0.0309 - val_mse: 0.0145\n",
      "Epoch 102/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0474 - mse: 0.0307 - val_loss: 0.0297 - val_mse: 0.0122\n",
      "Epoch 103/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0429 - mse: 0.0255 - val_loss: 0.0298 - val_mse: 0.0128\n",
      "Epoch 104/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0437 - mse: 0.0266 - val_loss: 0.0293 - val_mse: 0.0120\n",
      "Epoch 105/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0424 - mse: 0.0255 - val_loss: 0.0301 - val_mse: 0.0137\n",
      "Epoch 106/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0425 - mse: 0.0262 - val_loss: 0.0291 - val_mse: 0.0126\n",
      "Epoch 107/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0445 - mse: 0.0282 - val_loss: 0.0291 - val_mse: 0.0129\n",
      "Epoch 108/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0395 - mse: 0.0233 - val_loss: 0.0278 - val_mse: 0.0116\n",
      "Epoch 109/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0401 - mse: 0.0242 - val_loss: 0.0285 - val_mse: 0.0131\n",
      "Epoch 110/10000\n",
      "482/482 [==============================] - 0s 143us/step - loss: 0.0408 - mse: 0.0253 - val_loss: 0.0288 - val_mse: 0.0138\n",
      "Epoch 111/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mse: 0.0262 - val_loss: 0.0282 - val_mse: 0.0125\n",
      "Epoch 112/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0402 - mse: 0.0248 - val_loss: 0.0284 - val_mse: 0.0131\n",
      "Epoch 113/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0397 - mse: 0.0245 - val_loss: 0.0278 - val_mse: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0406 - mse: 0.0256 - val_loss: 0.0270 - val_mse: 0.0115\n",
      "Epoch 115/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0387 - mse: 0.0234 - val_loss: 0.0273 - val_mse: 0.0120\n",
      "Epoch 116/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0399 - mse: 0.0249 - val_loss: 0.0273 - val_mse: 0.0125\n",
      "Epoch 117/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0413 - mse: 0.0267 - val_loss: 0.0272 - val_mse: 0.0121\n",
      "Epoch 118/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0351 - mse: 0.0202 - val_loss: 0.0266 - val_mse: 0.0117\n",
      "Epoch 119/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0373 - mse: 0.0225 - val_loss: 0.0260 - val_mse: 0.0107\n",
      "Epoch 120/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0380 - mse: 0.0231 - val_loss: 0.0259 - val_mse: 0.0109\n",
      "Epoch 121/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0400 - mse: 0.0254 - val_loss: 0.0256 - val_mse: 0.0106\n",
      "Epoch 122/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0387 - mse: 0.0240 - val_loss: 0.0263 - val_mse: 0.0118\n",
      "Epoch 123/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0397 - mse: 0.0253 - val_loss: 0.0255 - val_mse: 0.0104\n",
      "Epoch 124/10000\n",
      "482/482 [==============================] - 0s 168us/step - loss: 0.0349 - mse: 0.0203 - val_loss: 0.0270 - val_mse: 0.0131\n",
      "Epoch 125/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0364 - mse: 0.0225 - val_loss: 0.0257 - val_mse: 0.0114\n",
      "Epoch 126/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0349 - mse: 0.0209 - val_loss: 0.0249 - val_mse: 0.0105\n",
      "Epoch 127/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0400 - mse: 0.0259 - val_loss: 0.0248 - val_mse: 0.0102\n",
      "Epoch 128/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0373 - mse: 0.0231 - val_loss: 0.0242 - val_mse: 0.0097\n",
      "Epoch 129/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0339 - mse: 0.0200 - val_loss: 0.0243 - val_mse: 0.0108\n",
      "Epoch 130/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0359 - mse: 0.0225 - val_loss: 0.0246 - val_mse: 0.0116\n",
      "Epoch 131/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0364 - mse: 0.0234 - val_loss: 0.0240 - val_mse: 0.0106\n",
      "Epoch 132/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0352 - mse: 0.0224 - val_loss: 0.0238 - val_mse: 0.0106\n",
      "Epoch 133/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0358 - mse: 0.0230 - val_loss: 0.0242 - val_mse: 0.0112\n",
      "Epoch 134/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0336 - mse: 0.0209 - val_loss: 0.0241 - val_mse: 0.0114\n",
      "Epoch 135/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0351 - mse: 0.0226 - val_loss: 0.0238 - val_mse: 0.0109\n",
      "Epoch 136/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0344 - mse: 0.0217 - val_loss: 0.0234 - val_mse: 0.0104\n",
      "Epoch 137/10000\n",
      "482/482 [==============================] - 0s 163us/step - loss: 0.0341 - mse: 0.0216 - val_loss: 0.0236 - val_mse: 0.0113\n",
      "Epoch 138/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0336 - mse: 0.0215 - val_loss: 0.0237 - val_mse: 0.0115\n",
      "Epoch 139/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0364 - mse: 0.0243 - val_loss: 0.0232 - val_mse: 0.0105\n",
      "Epoch 140/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0325 - mse: 0.0202 - val_loss: 0.0226 - val_mse: 0.0097\n",
      "Epoch 141/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0327 - mse: 0.0202 - val_loss: 0.0227 - val_mse: 0.0100\n",
      "Epoch 142/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0337 - mse: 0.0213 - val_loss: 0.0230 - val_mse: 0.0108\n",
      "Epoch 143/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0335 - mse: 0.0213 - val_loss: 0.0225 - val_mse: 0.0099\n",
      "Epoch 144/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0313 - mse: 0.0194 - val_loss: 0.0219 - val_mse: 0.0097\n",
      "Epoch 145/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0296 - mse: 0.0181 - val_loss: 0.0222 - val_mse: 0.0106\n",
      "Epoch 146/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0333 - mse: 0.0220 - val_loss: 0.0222 - val_mse: 0.0104\n",
      "Epoch 147/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0328 - mse: 0.0213 - val_loss: 0.0220 - val_mse: 0.0102\n",
      "Epoch 148/10000\n",
      "482/482 [==============================] - 0s 128us/step - loss: 0.0312 - mse: 0.0196 - val_loss: 0.0218 - val_mse: 0.0102\n",
      "Epoch 149/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0316 - mse: 0.0204 - val_loss: 0.0218 - val_mse: 0.0106\n",
      "Epoch 150/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0302 - mse: 0.0192 - val_loss: 0.0221 - val_mse: 0.0111\n",
      "Epoch 151/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0292 - mse: 0.0184 - val_loss: 0.0210 - val_mse: 0.0100\n",
      "Epoch 152/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0285 - mse: 0.0178 - val_loss: 0.0204 - val_mse: 0.0090\n",
      "Epoch 153/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0315 - mse: 0.0205 - val_loss: 0.0208 - val_mse: 0.0094\n",
      "Epoch 154/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0286 - mse: 0.0177 - val_loss: 0.0213 - val_mse: 0.0103\n",
      "Epoch 155/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0322 - mse: 0.0214 - val_loss: 0.0210 - val_mse: 0.0096\n",
      "Epoch 156/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0282 - mse: 0.0173 - val_loss: 0.0203 - val_mse: 0.0090\n",
      "Epoch 157/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0321 - mse: 0.0212 - val_loss: 0.0206 - val_mse: 0.0097\n",
      "Epoch 158/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0255 - mse: 0.0150 - val_loss: 0.0205 - val_mse: 0.0100\n",
      "Epoch 159/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0295 - mse: 0.0192 - val_loss: 0.0207 - val_mse: 0.0102\n",
      "Epoch 160/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0299 - mse: 0.0197 - val_loss: 0.0199 - val_mse: 0.0092\n",
      "Epoch 161/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0256 - mse: 0.0155 - val_loss: 0.0196 - val_mse: 0.0090\n",
      "Epoch 162/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0285 - mse: 0.0184 - val_loss: 0.0194 - val_mse: 0.0091\n",
      "Epoch 163/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0303 - mse: 0.0204 - val_loss: 0.0193 - val_mse: 0.0088\n",
      "Epoch 164/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0274 - mse: 0.0173 - val_loss: 0.0196 - val_mse: 0.0094\n",
      "Epoch 165/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0288 - mse: 0.0190 - val_loss: 0.0195 - val_mse: 0.0093\n",
      "Epoch 166/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0285 - mse: 0.0185 - val_loss: 0.0196 - val_mse: 0.0091\n",
      "Epoch 167/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0303 - mse: 0.0202 - val_loss: 0.0193 - val_mse: 0.0089\n",
      "Epoch 168/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0298 - mse: 0.0199 - val_loss: 0.0191 - val_mse: 0.0092\n",
      "Epoch 169/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0261 - mse: 0.0166 - val_loss: 0.0192 - val_mse: 0.0094\n",
      "Epoch 170/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0253 - mse: 0.0160 - val_loss: 0.0185 - val_mse: 0.0083\n",
      "Epoch 171/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0301 - mse: 0.0203 - val_loss: 0.0188 - val_mse: 0.0089\n",
      "Epoch 172/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0268 - mse: 0.0174 - val_loss: 0.0188 - val_mse: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0267 - mse: 0.0172 - val_loss: 0.0185 - val_mse: 0.0082\n",
      "Epoch 174/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0268 - mse: 0.0171 - val_loss: 0.0184 - val_mse: 0.0081\n",
      "Epoch 175/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0281 - mse: 0.0184 - val_loss: 0.0186 - val_mse: 0.0086\n",
      "Epoch 176/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0270 - mse: 0.0174 - val_loss: 0.0185 - val_mse: 0.0084\n",
      "Epoch 177/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0257 - mse: 0.0162 - val_loss: 0.0183 - val_mse: 0.0082\n",
      "Epoch 178/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0268 - mse: 0.0173 - val_loss: 0.0182 - val_mse: 0.0078\n",
      "Epoch 179/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0266 - mse: 0.0167 - val_loss: 0.0180 - val_mse: 0.0077\n",
      "Epoch 180/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0235 - mse: 0.0137 - val_loss: 0.0178 - val_mse: 0.0079\n",
      "Epoch 181/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0241 - mse: 0.0147 - val_loss: 0.0178 - val_mse: 0.0081\n",
      "Epoch 182/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0232 - mse: 0.0139 - val_loss: 0.0174 - val_mse: 0.0079\n",
      "Epoch 183/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0243 - mse: 0.0151 - val_loss: 0.0172 - val_mse: 0.0075\n",
      "Epoch 184/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0244 - mse: 0.0150 - val_loss: 0.0176 - val_mse: 0.0085\n",
      "Epoch 185/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0240 - mse: 0.0152 - val_loss: 0.0174 - val_mse: 0.0078\n",
      "Epoch 186/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0244 - mse: 0.0152 - val_loss: 0.0178 - val_mse: 0.0087\n",
      "Epoch 187/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0236 - mse: 0.0144 - val_loss: 0.0171 - val_mse: 0.0076\n",
      "Epoch 188/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0231 - mse: 0.0137 - val_loss: 0.0172 - val_mse: 0.0079\n",
      "Epoch 189/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0222 - mse: 0.0132 - val_loss: 0.0169 - val_mse: 0.0070\n",
      "Epoch 190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0241 - mse: 0.0148 - val_loss: 0.0173 - val_mse: 0.0079\n",
      "Epoch 191/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0248 - mse: 0.0153 - val_loss: 0.0180 - val_mse: 0.0091\n",
      "Epoch 192/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0224 - mse: 0.0135 - val_loss: 0.0169 - val_mse: 0.0073\n",
      "Epoch 193/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0228 - mse: 0.0136 - val_loss: 0.0169 - val_mse: 0.0079\n",
      "Epoch 194/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0230 - mse: 0.0141 - val_loss: 0.0170 - val_mse: 0.0082\n",
      "Epoch 195/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0240 - mse: 0.0152 - val_loss: 0.0168 - val_mse: 0.0076\n",
      "Epoch 196/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0218 - mse: 0.0129 - val_loss: 0.0167 - val_mse: 0.0079\n",
      "Epoch 197/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0204 - mse: 0.0118 - val_loss: 0.0168 - val_mse: 0.0083\n",
      "Epoch 198/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0217 - mse: 0.0131 - val_loss: 0.0164 - val_mse: 0.0073\n",
      "Epoch 199/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0216 - mse: 0.0127 - val_loss: 0.0168 - val_mse: 0.0083\n",
      "Epoch 200/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0233 - mse: 0.0148 - val_loss: 0.0163 - val_mse: 0.0074\n",
      "Epoch 201/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0227 - mse: 0.0139 - val_loss: 0.0166 - val_mse: 0.0080\n",
      "Epoch 202/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0213 - mse: 0.0126 - val_loss: 0.0165 - val_mse: 0.0079\n",
      "Epoch 203/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0225 - mse: 0.0140 - val_loss: 0.0168 - val_mse: 0.0084\n",
      "Epoch 204/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0212 - mse: 0.0126 - val_loss: 0.0162 - val_mse: 0.0070\n",
      "Epoch 205/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0218 - mse: 0.0131 - val_loss: 0.0163 - val_mse: 0.0077\n",
      "Epoch 206/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0219 - mse: 0.0134 - val_loss: 0.0160 - val_mse: 0.0070\n",
      "Epoch 207/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0224 - mse: 0.0138 - val_loss: 0.0162 - val_mse: 0.0073\n",
      "Epoch 208/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0213 - mse: 0.0128 - val_loss: 0.0161 - val_mse: 0.0072\n",
      "Epoch 209/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0210 - mse: 0.0125 - val_loss: 0.0160 - val_mse: 0.0075\n",
      "Epoch 210/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0218 - mse: 0.0135 - val_loss: 0.0159 - val_mse: 0.0075\n",
      "Epoch 211/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0213 - mse: 0.0130 - val_loss: 0.0160 - val_mse: 0.0075\n",
      "Epoch 212/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0214 - mse: 0.0130 - val_loss: 0.0158 - val_mse: 0.0073\n",
      "Epoch 213/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0215 - mse: 0.0133 - val_loss: 0.0163 - val_mse: 0.0085\n",
      "Epoch 214/10000\n",
      "482/482 [==============================] - 0s 90us/step - loss: 0.0203 - mse: 0.0123 - val_loss: 0.0157 - val_mse: 0.0068\n",
      "Epoch 215/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mse: 0.0126 - val_loss: 0.0161 - val_mse: 0.0078\n",
      "Epoch 216/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0212 - mse: 0.0128 - val_loss: 0.0158 - val_mse: 0.0073\n",
      "Epoch 217/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0204 - mse: 0.0121 - val_loss: 0.0154 - val_mse: 0.0063\n",
      "Epoch 218/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0212 - mse: 0.0128 - val_loss: 0.0155 - val_mse: 0.0070\n",
      "Epoch 219/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0206 - mse: 0.0126 - val_loss: 0.0152 - val_mse: 0.0070\n",
      "Epoch 220/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0210 - mse: 0.0130 - val_loss: 0.0153 - val_mse: 0.0071\n",
      "Epoch 221/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mse: 0.0121 - val_loss: 0.0153 - val_mse: 0.0074\n",
      "Epoch 222/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0194 - mse: 0.0116 - val_loss: 0.0155 - val_mse: 0.0081\n",
      "Epoch 223/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0197 - mse: 0.0120 - val_loss: 0.0153 - val_mse: 0.0076\n",
      "Epoch 224/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0202 - mse: 0.0124 - val_loss: 0.0153 - val_mse: 0.0076\n",
      "Epoch 225/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0203 - mse: 0.0126 - val_loss: 0.0151 - val_mse: 0.0072\n",
      "Epoch 226/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0199 - mse: 0.0121 - val_loss: 0.0149 - val_mse: 0.0066\n",
      "Epoch 227/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0203 - mse: 0.0123 - val_loss: 0.0150 - val_mse: 0.0070\n",
      "Epoch 228/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0206 - mse: 0.0127 - val_loss: 0.0148 - val_mse: 0.0066\n",
      "Epoch 229/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0198 - mse: 0.0119 - val_loss: 0.0148 - val_mse: 0.0066\n",
      "Epoch 230/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0206 - mse: 0.0127 - val_loss: 0.0150 - val_mse: 0.0069\n",
      "Epoch 231/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0201 - mse: 0.0121 - val_loss: 0.0147 - val_mse: 0.0065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0196 - mse: 0.0117 - val_loss: 0.0147 - val_mse: 0.0066\n",
      "Epoch 233/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0187 - mse: 0.0110 - val_loss: 0.0146 - val_mse: 0.0067\n",
      "Epoch 234/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0203 - mse: 0.0124 - val_loss: 0.0149 - val_mse: 0.0074\n",
      "Epoch 235/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0189 - mse: 0.0112 - val_loss: 0.0145 - val_mse: 0.0060\n",
      "Epoch 236/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0189 - mse: 0.0109 - val_loss: 0.0144 - val_mse: 0.0062\n",
      "Epoch 237/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0182 - mse: 0.0104 - val_loss: 0.0144 - val_mse: 0.0069\n",
      "Epoch 238/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0186 - mse: 0.0111 - val_loss: 0.0145 - val_mse: 0.0073\n",
      "Epoch 239/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mse: 0.0112 - val_loss: 0.0143 - val_mse: 0.0066\n",
      "Epoch 240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0188 - mse: 0.0113 - val_loss: 0.0142 - val_mse: 0.0060\n",
      "Epoch 241/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0191 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0063\n",
      "Epoch 242/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0195 - mse: 0.0119 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 243/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0193 - mse: 0.0119 - val_loss: 0.0143 - val_mse: 0.0069\n",
      "Epoch 244/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0187 - mse: 0.0114 - val_loss: 0.0141 - val_mse: 0.0065\n",
      "Epoch 245/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0185 - mse: 0.0111 - val_loss: 0.0140 - val_mse: 0.0062\n",
      "Epoch 246/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0189 - mse: 0.0115 - val_loss: 0.0140 - val_mse: 0.0060\n",
      "Epoch 247/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0190 - mse: 0.0113 - val_loss: 0.0141 - val_mse: 0.0064\n",
      "Epoch 248/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0194 - mse: 0.0119 - val_loss: 0.0140 - val_mse: 0.0064\n",
      "Epoch 249/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0179 - mse: 0.0104 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 250/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0179 - mse: 0.0105 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 251/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0186 - mse: 0.0112 - val_loss: 0.0138 - val_mse: 0.0064\n",
      "Epoch 252/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0188 - mse: 0.0114 - val_loss: 0.0139 - val_mse: 0.0062\n",
      "Epoch 253/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0185 - mse: 0.0110 - val_loss: 0.0139 - val_mse: 0.0057\n",
      "Epoch 254/10000\n",
      "482/482 [==============================] - 0s 105us/step - loss: 0.0179 - mse: 0.0101 - val_loss: 0.0138 - val_mse: 0.0061\n",
      "Epoch 255/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0172 - mse: 0.0097 - val_loss: 0.0137 - val_mse: 0.0060\n",
      "Epoch 256/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0175 - mse: 0.0102 - val_loss: 0.0137 - val_mse: 0.0066\n",
      "Epoch 257/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0177 - mse: 0.0107 - val_loss: 0.0135 - val_mse: 0.0060\n",
      "Epoch 258/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0181 - mse: 0.0108 - val_loss: 0.0141 - val_mse: 0.0075\n",
      "Epoch 259/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0176 - mse: 0.0107 - val_loss: 0.0135 - val_mse: 0.0061\n",
      "Epoch 260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0172 - mse: 0.0102 - val_loss: 0.0134 - val_mse: 0.0059\n",
      "Epoch 261/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0177 - mse: 0.0106 - val_loss: 0.0134 - val_mse: 0.0065\n",
      "Epoch 262/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0172 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0059\n",
      "Epoch 263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0174 - mse: 0.0102 - val_loss: 0.0133 - val_mse: 0.0065\n",
      "Epoch 264/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0168 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0063\n",
      "Epoch 265/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0173 - mse: 0.0105 - val_loss: 0.0130 - val_mse: 0.0059\n",
      "Epoch 266/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0170 - mse: 0.0100 - val_loss: 0.0130 - val_mse: 0.0061\n",
      "Epoch 267/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0184 - mse: 0.0116 - val_loss: 0.0132 - val_mse: 0.0066\n",
      "Epoch 268/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0177 - mse: 0.0109 - val_loss: 0.0131 - val_mse: 0.0063\n",
      "Epoch 269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0176 - mse: 0.0108 - val_loss: 0.0134 - val_mse: 0.0069\n",
      "Epoch 270/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0185 - mse: 0.0117 - val_loss: 0.0133 - val_mse: 0.0065\n",
      "Epoch 271/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0168 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0061\n",
      "Epoch 272/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0175 - mse: 0.0106 - val_loss: 0.0131 - val_mse: 0.0061\n",
      "Epoch 273/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0170 - mse: 0.0099 - val_loss: 0.0130 - val_mse: 0.0058\n",
      "Epoch 274/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0169 - mse: 0.0099 - val_loss: 0.0131 - val_mse: 0.0067\n",
      "Epoch 275/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0176 - mse: 0.0108 - val_loss: 0.0131 - val_mse: 0.0067\n",
      "Epoch 276/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0173 - mse: 0.0106 - val_loss: 0.0128 - val_mse: 0.0058\n",
      "Epoch 277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0171 - mse: 0.0103 - val_loss: 0.0128 - val_mse: 0.0061\n",
      "Epoch 278/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0174 - mse: 0.011 - 0s 116us/step - loss: 0.0172 - mse: 0.0105 - val_loss: 0.0128 - val_mse: 0.0062\n",
      "Epoch 279/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0169 - mse: 0.0102 - val_loss: 0.0128 - val_mse: 0.0058\n",
      "Epoch 280/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0170 - mse: 0.0100 - val_loss: 0.0127 - val_mse: 0.0057\n",
      "Epoch 281/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0158 - mse: 0.0091 - val_loss: 0.0129 - val_mse: 0.0067\n",
      "Epoch 282/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0126 - val_mse: 0.0057\n",
      "Epoch 283/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0168 - mse: 0.0100 - val_loss: 0.0125 - val_mse: 0.0057\n",
      "Epoch 284/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0175 - mse: 0.0106 - val_loss: 0.0126 - val_mse: 0.0060\n",
      "Epoch 285/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0167 - mse: 0.0101 - val_loss: 0.0126 - val_mse: 0.0059\n",
      "Epoch 286/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0126 - val_mse: 0.0060\n",
      "Epoch 287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0171 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0058\n",
      "Epoch 288/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0162 - mse: 0.0096 - val_loss: 0.0125 - val_mse: 0.0059\n",
      "Epoch 289/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0171 - mse: 0.0106 - val_loss: 0.0125 - val_mse: 0.0059\n",
      "Epoch 290/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0165 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0055\n",
      "Epoch 291/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0166 - mse: 0.0098 - val_loss: 0.0125 - val_mse: 0.0055\n",
      "Epoch 292/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0174 - mse: 0.0107 - val_loss: 0.0124 - val_mse: 0.0060\n",
      "Epoch 293/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0061\n",
      "Epoch 294/10000\n",
      "482/482 [==============================] - 0s 125us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0123 - val_mse: 0.0057\n",
      "Epoch 295/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0161 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0059\n",
      "Epoch 296/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0161 - mse: 0.0097 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 297/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 298/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0161 - mse: 0.0093 - val_loss: 0.0123 - val_mse: 0.0055\n",
      "Epoch 299/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0160 - mse: 0.0093 - val_loss: 0.0124 - val_mse: 0.0062\n",
      "Epoch 300/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0164 - mse: 0.0100 - val_loss: 0.0124 - val_mse: 0.0060\n",
      "Epoch 301/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0166 - mse: 0.0102 - val_loss: 0.0123 - val_mse: 0.0057\n",
      "Epoch 302/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mse: 0.0101 - val_loss: 0.0123 - val_mse: 0.0059\n",
      "Epoch 303/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0152 - mse: 0.0088 - val_loss: 0.0122 - val_mse: 0.0058\n",
      "Epoch 304/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0092 - val_loss: 0.0122 - val_mse: 0.0055\n",
      "Epoch 305/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0153 - mse: 0.0087 - val_loss: 0.0122 - val_mse: 0.0060\n",
      "Epoch 306/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0163 - mse: 0.0098 - val_loss: 0.0120 - val_mse: 0.0055\n",
      "Epoch 307/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0164 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0066\n",
      "Epoch 308/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0160 - mse: 0.0097 - val_loss: 0.0121 - val_mse: 0.0057\n",
      "Epoch 309/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0159 - mse: 0.0094 - val_loss: 0.0121 - val_mse: 0.0058\n",
      "Epoch 310/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0157 - mse: 0.0092 - val_loss: 0.0121 - val_mse: 0.0059\n",
      "Epoch 311/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0163 - mse: 0.0099 - val_loss: 0.0121 - val_mse: 0.0056\n",
      "Epoch 312/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0121 - val_mse: 0.0057\n",
      "Epoch 313/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0162 - mse: 0.0097 - val_loss: 0.0120 - val_mse: 0.0058\n",
      "Epoch 314/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0159 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0063\n",
      "Epoch 315/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0159 - mse: 0.0096 - val_loss: 0.0122 - val_mse: 0.0060\n",
      "Epoch 316/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0167 - mse: 0.0102 - val_loss: 0.0122 - val_mse: 0.0061\n",
      "Epoch 317/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0158 - mse: 0.0094 - val_loss: 0.0121 - val_mse: 0.0055\n",
      "Epoch 318/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0152 - mse: 0.0087 - val_loss: 0.0120 - val_mse: 0.0057\n",
      "Epoch 319/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0157 - mse: 0.0093 - val_loss: 0.0121 - val_mse: 0.0054\n",
      "Epoch 320/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0153 - mse: 0.0086 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 321/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0086 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 322/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0156 - mse: 0.0092 - val_loss: 0.0119 - val_mse: 0.0054\n",
      "Epoch 323/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0153 - mse: 0.0088 - val_loss: 0.0120 - val_mse: 0.0057\n",
      "Epoch 324/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0119 - val_mse: 0.0054\n",
      "Epoch 325/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0164 - mse: 0.0099 - val_loss: 0.0121 - val_mse: 0.0061\n",
      "Epoch 326/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0149 - mse: 0.0086 - val_loss: 0.0118 - val_mse: 0.0054\n",
      "Epoch 327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0165 - mse: 0.0101 - val_loss: 0.0118 - val_mse: 0.0058\n",
      "Epoch 328/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0119 - val_mse: 0.0059\n",
      "Epoch 329/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0156 - mse: 0.0093 - val_loss: 0.0119 - val_mse: 0.0059\n",
      "Epoch 330/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0158 - mse: 0.0095 - val_loss: 0.0119 - val_mse: 0.0057\n",
      "Epoch 331/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0154 - mse: 0.0091 - val_loss: 0.0118 - val_mse: 0.0055\n",
      "Epoch 332/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0167 - mse: 0.0104 - val_loss: 0.0119 - val_mse: 0.0053\n",
      "Epoch 333/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0163 - mse: 0.0098 - val_loss: 0.0119 - val_mse: 0.0058\n",
      "Epoch 334/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mse: 0.0085 - val_loss: 0.0119 - val_mse: 0.0060\n",
      "Epoch 335/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0154 - mse: 0.0092 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 336/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0156 - mse: 0.0093 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 337/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0155 - mse: 0.0091 - val_loss: 0.0117 - val_mse: 0.0054\n",
      "Epoch 338/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0153 - mse: 0.0088 - val_loss: 0.0117 - val_mse: 0.0057\n",
      "Epoch 339/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0155 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0055\n",
      "Epoch 340/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 341/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0151 - mse: 0.0090 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 342/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0151 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0056\n",
      "Epoch 343/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0151 - mse: 0.0089 - val_loss: 0.0116 - val_mse: 0.0053\n",
      "Epoch 344/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0153 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 345/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0159 - mse: 0.0094 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 346/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0148 - mse: 0.0084 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 347/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0142 - mse: 0.0080 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 348/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0158 - mse: 0.0095 - val_loss: 0.0117 - val_mse: 0.0058\n",
      "Epoch 349/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 114us/step - loss: 0.0154 - mse: 0.0092 - val_loss: 0.0116 - val_mse: 0.0052\n",
      "Epoch 350/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mse: 0.0082 - val_loss: 0.0115 - val_mse: 0.0053\n",
      "Epoch 351/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0154 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 352/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0151 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0056\n",
      "Epoch 353/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0117 - val_mse: 0.0061\n",
      "Epoch 354/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0156 - mse: 0.0097 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 355/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0150 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0052\n",
      "Epoch 356/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0151 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 357/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0150 - mse: 0.0088 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 358/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0150 - mse: 0.009 - 0s 114us/step - loss: 0.0146 - mse: 0.0083 - val_loss: 0.0115 - val_mse: 0.0056\n",
      "Epoch 359/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0116 - val_mse: 0.0059\n",
      "Epoch 360/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0147 - mse: 0.0086 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 361/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 362/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 363/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0153 - mse: 0.0092 - val_loss: 0.0114 - val_mse: 0.0054\n",
      "Epoch 364/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0148 - mse: 0.0087 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 365/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 366/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0148 - mse: 0.0088 - val_loss: 0.0116 - val_mse: 0.0057\n",
      "Epoch 367/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0148 - mse: 0.0086 - val_loss: 0.0115 - val_mse: 0.0054\n",
      "Epoch 368/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0115 - val_mse: 0.0058\n",
      "Epoch 369/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0089 - val_loss: 0.0115 - val_mse: 0.0055\n",
      "Epoch 370/10000\n",
      "482/482 [==============================] - 0s 164us/step - loss: 0.0145 - mse: 0.0083 - val_loss: 0.0115 - val_mse: 0.0057\n",
      "Epoch 371/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0152 - mse: 0.0090 - val_loss: 0.0117 - val_mse: 0.0059\n",
      "Epoch 372/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0139 - mse: 0.0077 - val_loss: 0.0116 - val_mse: 0.0060\n",
      "Epoch 373/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0151 - mse: 0.0092 - val_loss: 0.0117 - val_mse: 0.0053\n",
      "Epoch 374/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0150 - mse: 0.0087 - val_loss: 0.0116 - val_mse: 0.0054\n",
      "Epoch 375/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0148 - mse: 0.0086 - val_loss: 0.0115 - val_mse: 0.0058\n",
      "Epoch 376/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0149 - mse: 0.0088 - val_loss: 0.0114 - val_mse: 0.0056\n",
      "Epoch 377/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0121 - mse: 0.006 - 0s 135us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 378/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0153 - mse: 0.0093 - val_loss: 0.0113 - val_mse: 0.0052\n",
      "Epoch 379/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0152 - mse: 0.0092 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 380/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0051\n",
      "Epoch 381/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0148 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 382/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 383/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0148 - mse: 0.0087 - val_loss: 0.0114 - val_mse: 0.0052\n",
      "Epoch 384/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0160 - mse: 0.0097 - val_loss: 0.0113 - val_mse: 0.0053\n",
      "Epoch 385/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0147 - mse: 0.0085 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 386/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0156 - mse: 0.0095 - val_loss: 0.0114 - val_mse: 0.0057\n",
      "Epoch 387/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0150 - mse: 0.0089 - val_loss: 0.0114 - val_mse: 0.0053\n",
      "Epoch 388/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0147 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 389/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0052\n",
      "Epoch 390/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0134 - mse: 0.0073 - val_loss: 0.0113 - val_mse: 0.0056\n",
      "Epoch 391/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0144 - mse: 0.0083 - val_loss: 0.0114 - val_mse: 0.0055\n",
      "Epoch 392/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0146 - mse: 0.0084 - val_loss: 0.0113 - val_mse: 0.0055\n",
      "Epoch 393/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0138 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 394/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0137 - mse: 0.0076 - val_loss: 0.0112 - val_mse: 0.0056\n",
      "Epoch 395/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 396/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0080 - val_loss: 0.0112 - val_mse: 0.0055\n",
      "Epoch 397/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 398/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0077 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 399/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 400/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0145 - mse: 0.0084 - val_loss: 0.0115 - val_mse: 0.0062\n",
      "Epoch 401/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 402/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 403/10000\n",
      "482/482 [==============================] - 0s 137us/step - loss: 0.0145 - mse: 0.0085 - val_loss: 0.0114 - val_mse: 0.0051\n",
      "Epoch 404/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0144 - mse: 0.0081 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 405/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0149 - mse: 0.0089 - val_loss: 0.0113 - val_mse: 0.0056\n",
      "Epoch 406/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0147 - mse: 0.0088 - val_loss: 0.0111 - val_mse: 0.0052\n",
      "Epoch 407/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0139 - mse: 0.0077 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 408/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0142 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0056\n",
      "Epoch 409/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0110 - val_mse: 0.0052\n",
      "Epoch 410/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0112 - val_mse: 0.0057\n",
      "Epoch 411/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0150 - mse: 0.0091 - val_loss: 0.0112 - val_mse: 0.0057\n",
      "Epoch 412/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0142 - mse: 0.0084 - val_loss: 0.0112 - val_mse: 0.0054\n",
      "Epoch 413/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0147 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 414/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0078 - val_loss: 0.0112 - val_mse: 0.0055\n",
      "Epoch 415/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 416/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0054\n",
      "Epoch 417/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0141 - mse: 0.0081 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 418/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0143 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0060\n",
      "Epoch 419/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0079 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 420/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0069 - val_loss: 0.0114 - val_mse: 0.0061\n",
      "Epoch 421/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0146 - mse: 0.0089 - val_loss: 0.0111 - val_mse: 0.0056\n",
      "Epoch 422/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0146 - mse: 0.0086 - val_loss: 0.0113 - val_mse: 0.0061\n",
      "Epoch 423/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0054\n",
      "Epoch 424/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0148 - mse: 0.0089 - val_loss: 0.0111 - val_mse: 0.0057\n",
      "Epoch 425/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0145 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 426/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mse: 0.0087 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 427/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0142 - mse: 0.0082 - val_loss: 0.0111 - val_mse: 0.0054\n",
      "Epoch 428/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 429/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0143 - mse: 0.0082 - val_loss: 0.0111 - val_mse: 0.0053\n",
      "Epoch 430/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0052\n",
      "Epoch 431/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0075 - val_loss: 0.0112 - val_mse: 0.0059\n",
      "Epoch 432/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0075 - val_loss: 0.0110 - val_mse: 0.0056\n",
      "Epoch 433/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 434/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 435/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0070 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 436/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mse: 0.0073 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 437/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0153 - mse: 0.0096 - val_loss: 0.0110 - val_mse: 0.0057\n",
      "Epoch 438/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0144 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0058\n",
      "Epoch 439/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0144 - mse: 0.0086 - val_loss: 0.0111 - val_mse: 0.0055\n",
      "Epoch 440/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0148 - mse: 0.0090 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 441/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0110 - val_mse: 0.0053\n",
      "Epoch 442/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0079 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 443/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0055\n",
      "Epoch 444/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 445/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0052\n",
      "Epoch 446/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0137 - mse: 0.0078 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 447/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0140 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0059\n",
      "Epoch 448/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0142 - mse: 0.0084 - val_loss: 0.0111 - val_mse: 0.0059\n",
      "Epoch 449/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0138 - mse: 0.0081 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 450/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0138 - mse: 0.0078 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 451/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0146 - mse: 0.0086 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 452/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0051\n",
      "Epoch 453/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0137 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 454/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0122 - mse: 0.006 - 0s 114us/step - loss: 0.0148 - mse: 0.0089 - val_loss: 0.0109 - val_mse: 0.0055\n",
      "Epoch 455/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 456/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0139 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0052\n",
      "Epoch 457/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 458/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0146 - mse: 0.0089 - val_loss: 0.0109 - val_mse: 0.0050\n",
      "Epoch 459/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0061\n",
      "Epoch 460/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0056\n",
      "Epoch 461/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0082 - val_loss: 0.0108 - val_mse: 0.0052\n",
      "Epoch 462/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0053\n",
      "Epoch 463/10000\n",
      "482/482 [==============================] - 0s 158us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0109 - val_mse: 0.0054\n",
      "Epoch 464/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0109 - val_mse: 0.0056\n",
      "Epoch 465/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0134 - mse: 0.0076 - val_loss: 0.0109 - val_mse: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/10000\n",
      "482/482 [==============================] - 0s 132us/step - loss: 0.0136 - mse: 0.0078 - val_loss: 0.0108 - val_mse: 0.0055\n",
      "Epoch 467/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 468/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0129 - mse: 0.0071 - val_loss: 0.0109 - val_mse: 0.0058\n",
      "Epoch 469/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0147 - mse: 0.0090 - val_loss: 0.0109 - val_mse: 0.0051\n",
      "Epoch 470/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0135 - mse: 0.0077 - val_loss: 0.0108 - val_mse: 0.0051\n",
      "Epoch 471/10000\n",
      "482/482 [==============================] - 0s 139us/step - loss: 0.0143 - mse: 0.0085 - val_loss: 0.0107 - val_mse: 0.0054\n",
      "Epoch 472/10000\n",
      "482/482 [==============================] - 0s 141us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0108 - val_mse: 0.0053\n",
      "Epoch 473/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 474/10000\n",
      "482/482 [==============================] - 0s 131us/step - loss: 0.0139 - mse: 0.0081 - val_loss: 0.0107 - val_mse: 0.0051\n",
      "Epoch 475/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0053\n",
      "Epoch 476/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0144 - mse: 0.0087 - val_loss: 0.0107 - val_mse: 0.0052\n",
      "Epoch 477/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 478/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0132 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0049\n",
      "Epoch 479/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 480/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0141 - mse: 0.0083 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 481/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 482/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0110 - val_mse: 0.0060\n",
      "Epoch 483/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 484/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0143 - mse: 0.0086 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 485/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 486/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0057\n",
      "Epoch 487/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 488/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0107 - val_mse: 0.0048\n",
      "Epoch 489/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0141 - mse: 0.0082 - val_loss: 0.0109 - val_mse: 0.0059\n",
      "Epoch 490/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0140 - mse: 0.0084 - val_loss: 0.0107 - val_mse: 0.0055\n",
      "Epoch 491/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0139 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 492/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0077 - val_loss: 0.0106 - val_mse: 0.0051\n",
      "Epoch 493/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0133 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 494/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0106 - val_mse: 0.0053\n",
      "Epoch 495/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 496/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0140 - mse: 0.0082 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 497/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mse: 0.0076 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 498/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 499/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0070 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 500/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0107 - val_mse: 0.0056\n",
      "Epoch 501/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0134 - mse: 0.0078 - val_loss: 0.0107 - val_mse: 0.0050\n",
      "Epoch 502/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0108 - val_mse: 0.0058\n",
      "Epoch 503/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 504/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 505/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0140 - mse: 0.0081 - val_loss: 0.0107 - val_mse: 0.0057\n",
      "Epoch 506/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0138 - mse: 0.0082 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 507/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0133 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0052\n",
      "Epoch 508/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0054\n",
      "Epoch 509/10000\n",
      "482/482 [==============================] - 0s 140us/step - loss: 0.0142 - mse: 0.0086 - val_loss: 0.0106 - val_mse: 0.0055\n",
      "Epoch 510/10000\n",
      "482/482 [==============================] - 0s 119us/step - loss: 0.0139 - mse: 0.0084 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 511/10000\n",
      "482/482 [==============================] - 0s 129us/step - loss: 0.0136 - mse: 0.0079 - val_loss: 0.0105 - val_mse: 0.0053\n",
      "Epoch 512/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0107 - val_mse: 0.0051\n",
      "Epoch 513/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0131 - mse: 0.0074 - val_loss: 0.0106 - val_mse: 0.0054\n",
      "Epoch 514/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0105 - val_mse: 0.0050\n",
      "Epoch 515/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0130 - mse: 0.0073 - val_loss: 0.0107 - val_mse: 0.0049\n",
      "Epoch 516/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0104 - val_mse: 0.0051\n",
      "Epoch 517/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 518/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0049\n",
      "Epoch 519/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0047\n",
      "Epoch 520/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0064 - val_loss: 0.0104 - val_mse: 0.0048\n",
      "Epoch 521/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 522/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0058\n",
      "Epoch 523/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0105 - val_mse: 0.0049\n",
      "Epoch 524/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0077 - val_loss: 0.0105 - val_mse: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 525/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0135 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0059\n",
      "Epoch 526/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0145 - mse: 0.0090 - val_loss: 0.0103 - val_mse: 0.0047\n",
      "Epoch 527/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0144 - mse: 0.0087 - val_loss: 0.0105 - val_mse: 0.0055\n",
      "Epoch 528/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0132 - mse: 0.0077 - val_loss: 0.0105 - val_mse: 0.0048\n",
      "Epoch 529/10000\n",
      "482/482 [==============================] - 0s 136us/step - loss: 0.0141 - mse: 0.0084 - val_loss: 0.0105 - val_mse: 0.0055\n",
      "Epoch 530/10000\n",
      "482/482 [==============================] - 0s 123us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0104 - val_mse: 0.0052\n",
      "Epoch 531/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0104 - val_mse: 0.0053\n",
      "Epoch 532/10000\n",
      "482/482 [==============================] - 0s 133us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 533/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0105 - val_mse: 0.0054\n",
      "Epoch 534/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 535/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0104 - val_mse: 0.0054\n",
      "Epoch 536/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0134 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0050\n",
      "Epoch 537/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 538/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0145 - mse: 0.0090 - val_loss: 0.0105 - val_mse: 0.0056\n",
      "Epoch 539/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0131 - mse: 0.0077 - val_loss: 0.0104 - val_mse: 0.0048\n",
      "Epoch 540/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0136 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0058\n",
      "Epoch 541/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 542/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 543/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 544/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 545/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0072 - val_loss: 0.0103 - val_mse: 0.0050\n",
      "Epoch 546/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0143 - mse: 0.0089 - val_loss: 0.0104 - val_mse: 0.0056\n",
      "Epoch 547/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 548/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0141 - mse: 0.0085 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 549/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0070 - val_loss: 0.0102 - val_mse: 0.0050\n",
      "Epoch 550/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0049\n",
      "Epoch 551/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mse: 0.0074 - val_loss: 0.0103 - val_mse: 0.0049\n",
      "Epoch 552/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0135 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0051\n",
      "Epoch 553/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 554/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0105 - val_mse: 0.0058\n",
      "Epoch 555/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0103 - val_mse: 0.0053\n",
      "Epoch 556/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0079 - val_loss: 0.0102 - val_mse: 0.0053\n",
      "Epoch 557/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0139 - mse: 0.0084 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 558/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0047\n",
      "Epoch 559/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0131 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 560/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 561/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0078 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 562/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0103 - val_mse: 0.0052\n",
      "Epoch 563/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0134 - mse: 0.0080 - val_loss: 0.0101 - val_mse: 0.0050\n",
      "Epoch 564/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0102 - val_mse: 0.0051\n",
      "Epoch 565/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0140 - mse: 0.0086 - val_loss: 0.0106 - val_mse: 0.0059\n",
      "Epoch 566/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0136 - mse: 0.0084 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 567/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0138 - mse: 0.0083 - val_loss: 0.0100 - val_mse: 0.0048\n",
      "Epoch 568/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0135 - mse: 0.0078 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 569/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0102 - val_mse: 0.0053\n",
      "Epoch 570/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0050\n",
      "Epoch 571/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 572/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0049\n",
      "Epoch 573/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0133 - mse: 0.0078 - val_loss: 0.0100 - val_mse: 0.0047\n",
      "Epoch 574/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0076 - val_loss: 0.0102 - val_mse: 0.0048\n",
      "Epoch 575/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 576/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0051\n",
      "Epoch 577/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0100 - val_mse: 0.0047\n",
      "Epoch 578/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0123 - mse: 0.0068 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 579/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0046\n",
      "Epoch 580/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 581/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 582/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0101 - val_mse: 0.0052\n",
      "Epoch 583/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0100 - val_mse: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 584/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0073 - val_loss: 0.0101 - val_mse: 0.0053\n",
      "Epoch 585/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0133 - mse: 0.0079 - val_loss: 0.0101 - val_mse: 0.0048\n",
      "Epoch 586/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0126 - mse: 0.0071 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 587/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0050\n",
      "Epoch 588/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 589/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 590/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0055\n",
      "Epoch 591/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 592/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0072 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 593/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0047\n",
      "Epoch 594/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 595/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 596/10000\n",
      "482/482 [==============================] - 0s 85us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0048\n",
      "Epoch 597/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 598/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0137 - mse: 0.0081 - val_loss: 0.0101 - val_mse: 0.0047\n",
      "Epoch 599/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0132 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0045\n",
      "Epoch 600/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0124 - mse: 0.0069 - val_loss: 0.0100 - val_mse: 0.0052\n",
      "Epoch 601/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0099 - val_mse: 0.0047\n",
      "Epoch 602/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0069 - val_loss: 0.0100 - val_mse: 0.0051\n",
      "Epoch 603/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 604/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0132 - mse: 0.0079 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 605/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 606/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0082 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 607/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0082 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 608/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0134 - mse: 0.0081 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 609/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0129 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0046\n",
      "Epoch 610/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0073 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 611/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 612/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0102 - val_mse: 0.0056\n",
      "Epoch 613/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 614/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 615/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0130 - mse: 0.0077 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 616/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0078 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 617/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0048\n",
      "Epoch 618/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0046\n",
      "Epoch 619/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0074 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 620/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0132 - mse: 0.0078 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 621/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0129 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 622/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0125 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0050\n",
      "Epoch 623/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0125 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0056\n",
      "Epoch 624/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0102 - val_mse: 0.0057\n",
      "Epoch 625/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 626/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0128 - mse: 0.0078 - val_loss: 0.0101 - val_mse: 0.0055\n",
      "Epoch 627/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 628/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0100 - val_mse: 0.0049\n",
      "Epoch 629/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 630/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0078 - val_loss: 0.0099 - val_mse: 0.0049\n",
      "Epoch 631/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0099 - val_mse: 0.0053\n",
      "Epoch 632/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0100 - val_mse: 0.0054\n",
      "Epoch 633/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 634/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 635/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0097 - val_mse: 0.0049\n",
      "Epoch 636/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0135 - mse: 0.0081 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 637/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0050\n",
      "Epoch 638/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 639/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0100 - val_mse: 0.0053\n",
      "Epoch 640/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 641/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0077 - val_loss: 0.0099 - val_mse: 0.0051\n",
      "Epoch 642/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 643/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0048\n",
      "Epoch 644/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0097 - val_mse: 0.0043\n",
      "Epoch 645/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0130 - mse: 0.0075 - val_loss: 0.0103 - val_mse: 0.0058\n",
      "Epoch 646/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0125 - mse: 0.0075 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 647/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 648/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0124 - mse: 0.0071 - val_loss: 0.0101 - val_mse: 0.0056\n",
      "Epoch 649/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 650/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 651/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0062 - val_loss: 0.0097 - val_mse: 0.0046\n",
      "Epoch 652/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 653/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 654/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 655/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0127 - mse: 0.0076 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 656/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 657/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0098 - val_mse: 0.0047\n",
      "Epoch 658/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0070 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 659/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 660/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0133 - mse: 0.0080 - val_loss: 0.0096 - val_mse: 0.0046\n",
      "Epoch 661/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 662/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 663/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 664/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 665/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0043\n",
      "Epoch 666/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0137 - mse: 0.0082 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 667/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 668/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0096 - val_mse: 0.0048\n",
      "Epoch 669/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0098 - val_mse: 0.0048\n",
      "Epoch 670/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0130 - mse: 0.0079 - val_loss: 0.0097 - val_mse: 0.0047\n",
      "Epoch 671/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0097 - val_mse: 0.0045\n",
      "Epoch 672/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0128 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0047\n",
      "Epoch 673/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0046\n",
      "Epoch 674/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0069 - val_loss: 0.0097 - val_mse: 0.0050\n",
      "Epoch 675/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0099 - val_mse: 0.0055\n",
      "Epoch 676/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 677/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 678/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0135 - mse: 0.0083 - val_loss: 0.0095 - val_mse: 0.0046\n",
      "Epoch 679/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 680/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0071 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 681/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 682/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 683/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 684/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0096 - val_mse: 0.0051\n",
      "Epoch 685/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 686/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 687/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 688/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 689/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 690/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 691/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 692/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0049\n",
      "Epoch 693/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 694/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0131 - mse: 0.0080 - val_loss: 0.0096 - val_mse: 0.0044\n",
      "Epoch 695/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0130 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 696/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mse: 0.0076 - val_loss: 0.0096 - val_mse: 0.0045\n",
      "Epoch 697/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0042\n",
      "Epoch 698/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 699/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0064 - val_loss: 0.0095 - val_mse: 0.0047\n",
      "Epoch 700/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0127 - mse: 0.0075 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 701/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0095 - val_mse: 0.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 702/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 703/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 704/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0128 - mse: 0.0077 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 705/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0131 - mse: 0.0079 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 706/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0127 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 707/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 708/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 709/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0095 - val_mse: 0.0048\n",
      "Epoch 710/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 711/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0120 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0045\n",
      "Epoch 712/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 713/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 714/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0130 - mse: 0.0078 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 715/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0096 - val_mse: 0.0050\n",
      "Epoch 716/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0076 - val_loss: 0.0095 - val_mse: 0.0044\n",
      "Epoch 717/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0073 - val_loss: 0.0096 - val_mse: 0.0044\n",
      "Epoch 718/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 719/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 720/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 721/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 722/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 723/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0123 - mse: 0.0071 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 724/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 725/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 726/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 727/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 728/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0063 - val_loss: 0.0095 - val_mse: 0.0043\n",
      "Epoch 729/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 730/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 731/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 732/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0046\n",
      "Epoch 733/10000\n",
      "482/482 [==============================] - 0s 172us/step - loss: 0.0121 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 734/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 735/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0130 - mse: 0.0080 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 736/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0070 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 737/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0095 - val_mse: 0.0050\n",
      "Epoch 738/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 739/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0126 - mse: 0.0075 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 740/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 741/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0095 - val_mse: 0.0041\n",
      "Epoch 742/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0068 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 743/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0128 - mse: 0.0075 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 744/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0094 - val_mse: 0.0044\n",
      "Epoch 745/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0120 - mse: 0.0068 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 746/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 747/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 748/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0066 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 749/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0096 - val_mse: 0.0053\n",
      "Epoch 750/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0049\n",
      "Epoch 751/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0046\n",
      "Epoch 752/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0047\n",
      "Epoch 753/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 754/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0072 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 755/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 756/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0093 - val_mse: 0.0046\n",
      "Epoch 757/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0097 - val_mse: 0.0054\n",
      "Epoch 758/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0120 - mse: 0.0070 - val_loss: 0.0094 - val_mse: 0.0043\n",
      "Epoch 759/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0129 - mse: 0.0077 - val_loss: 0.0092 - val_mse: 0.0043\n",
      "Epoch 760/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0070 - val_loss: 0.0092 - val_mse: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 761/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0045\n",
      "Epoch 762/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 763/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0044\n",
      "Epoch 764/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0125 - mse: 0.0074 - val_loss: 0.0094 - val_mse: 0.0051\n",
      "Epoch 765/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0047\n",
      "Epoch 766/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0050\n",
      "Epoch 767/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 768/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 769/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 770/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0126 - mse: 0.0076 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 771/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0065 - val_loss: 0.0093 - val_mse: 0.0044\n",
      "Epoch 772/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0093 - val_mse: 0.0048\n",
      "Epoch 773/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0123 - mse: 0.0073 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 774/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0045\n",
      "Epoch 775/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 776/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 777/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0124 - mse: 0.0074 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 778/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 779/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 780/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0093 - val_mse: 0.0043\n",
      "Epoch 781/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 782/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 783/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0122 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 784/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0041\n",
      "Epoch 785/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0062 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 786/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0115 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 787/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0094 - val_mse: 0.0045\n",
      "Epoch 788/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 789/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 790/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0092 - val_mse: 0.0048\n",
      "Epoch 791/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0126 - mse: 0.0077 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 792/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 793/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 794/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0092 - val_mse: 0.0047\n",
      "Epoch 795/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0044\n",
      "Epoch 796/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 797/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 798/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0063 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 799/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 800/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0124 - mse: 0.0073 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 801/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 802/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0091 - val_mse: 0.0045\n",
      "Epoch 803/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 804/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0116 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0041\n",
      "Epoch 805/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0062 - val_loss: 0.0090 - val_mse: 0.0046\n",
      "Epoch 806/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0072 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 807/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 808/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0125 - mse: 0.0075 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 809/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 810/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0063 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 811/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0127 - mse: 0.0078 - val_loss: 0.0091 - val_mse: 0.0046\n",
      "Epoch 812/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 813/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 814/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0093 - val_mse: 0.0050\n",
      "Epoch 815/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 816/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0066 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 817/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 818/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 819/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0060 - val_loss: 0.0089 - val_mse: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 820/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0042\n",
      "Epoch 821/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 822/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mse: 0.0064 - val_loss: 0.0092 - val_mse: 0.0051\n",
      "Epoch 823/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0120 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0049\n",
      "Epoch 824/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 825/10000\n",
      "482/482 [==============================] - 0s 95us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 826/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0043\n",
      "Epoch 827/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0091 - val_mse: 0.0047\n",
      "Epoch 828/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0093 - val_mse: 0.0042\n",
      "Epoch 829/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0072 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 830/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 831/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0090 - val_mse: 0.0042\n",
      "Epoch 832/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0068 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 833/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mse: 0.0065 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 834/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0123 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 835/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 836/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0121 - mse: 0.0071 - val_loss: 0.0091 - val_mse: 0.0048\n",
      "Epoch 837/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 838/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0065 - val_loss: 0.0096 - val_mse: 0.0055\n",
      "Epoch 839/10000\n",
      "482/482 [==============================] - 0s 111us/step - loss: 0.0126 - mse: 0.0079 - val_loss: 0.0090 - val_mse: 0.0045\n",
      "Epoch 840/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 841/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0039\n",
      "Epoch 842/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0046\n",
      "Epoch 843/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0123 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 844/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 845/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0120 - mse: 0.0071 - val_loss: 0.0090 - val_mse: 0.0044\n",
      "Epoch 846/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0074 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 847/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 848/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 849/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 850/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0065 - val_loss: 0.0090 - val_mse: 0.0047\n",
      "Epoch 851/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0089 - val_mse: 0.0043\n",
      "Epoch 852/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 853/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0062 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 854/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0124 - mse: 0.0075 - val_loss: 0.0089 - val_mse: 0.0045\n",
      "Epoch 855/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 856/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 857/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 858/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 859/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0044\n",
      "Epoch 860/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0116 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 861/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 862/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 863/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 864/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 865/10000\n",
      "482/482 [==============================] - 0s 117us/step - loss: 0.0116 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 866/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 867/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 868/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0064 - val_loss: 0.0091 - val_mse: 0.0049\n",
      "Epoch 869/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 870/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0068 - val_loss: 0.0089 - val_mse: 0.0045\n",
      "Epoch 871/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0091 - val_mse: 0.0041\n",
      "Epoch 872/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0117 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 873/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 874/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 875/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 876/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 877/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0117 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 878/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0089 - val_mse: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0060 - val_loss: 0.0090 - val_mse: 0.0043\n",
      "Epoch 880/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 881/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0119 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 882/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0068 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 883/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 884/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0117 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 885/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0039\n",
      "Epoch 886/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0122 - mse: 0.0073 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 887/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 888/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 889/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0088 - val_mse: 0.0040\n",
      "Epoch 890/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0123 - mse: 0.0074 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 891/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0090 - val_mse: 0.0048\n",
      "Epoch 892/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 893/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0119 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 894/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0044\n",
      "Epoch 895/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 896/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 897/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 898/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0070 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 899/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 900/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0074 - val_loss: 0.0087 - val_mse: 0.0041\n",
      "Epoch 901/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0052\n",
      "Epoch 902/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0115 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0045\n",
      "Epoch 903/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0115 - mse: 0.0068 - val_loss: 0.0091 - val_mse: 0.0050\n",
      "Epoch 904/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 905/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0067 - val_loss: 0.0095 - val_mse: 0.0057\n",
      "Epoch 906/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0087 - val_mse: 0.0043\n",
      "Epoch 907/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0092 - val_mse: 0.0053\n",
      "Epoch 908/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0063 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 909/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0121 - mse: 0.0076 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 910/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0069 - val_loss: 0.0089 - val_mse: 0.0047\n",
      "Epoch 911/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 912/10000\n",
      "482/482 [==============================] - 0s 115us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 913/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 914/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0039\n",
      "Epoch 915/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0121 - mse: 0.0073 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 916/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0063 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 917/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 918/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 919/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 920/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0061 - val_loss: 0.0088 - val_mse: 0.0046\n",
      "Epoch 921/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 922/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0091 - val_mse: 0.0052\n",
      "Epoch 923/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 924/10000\n",
      "482/482 [==============================] - 0s 170us/step - loss: 0.0120 - mse: 0.0073 - val_loss: 0.0092 - val_mse: 0.0052\n",
      "Epoch 925/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0038\n",
      "Epoch 926/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0057 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 927/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 928/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0119 - mse: 0.0073 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 929/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0107 - mse: 0.0062 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 930/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 931/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 932/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0089 - val_mse: 0.0049\n",
      "Epoch 933/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0096 - mse: 0.005 - 0s 110us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 934/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 935/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 936/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 937/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0039\n",
      "Epoch 938/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 939/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 940/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 941/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 942/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 943/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 944/10000\n",
      "482/482 [==============================] - 0s 113us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0087 - val_mse: 0.0045\n",
      "Epoch 945/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 946/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 947/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0061 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 948/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0087 - val_mse: 0.0046\n",
      "Epoch 949/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 950/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 951/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0122 - mse: 0.0076 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 952/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 953/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 954/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0123 - mse: 0.0078 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 955/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0120 - mse: 0.0074 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 956/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0058 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 957/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0089 - val_mse: 0.0041\n",
      "Epoch 958/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0120 - mse: 0.0072 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 959/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0088 - val_mse: 0.0048\n",
      "Epoch 960/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0043\n",
      "Epoch 961/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mse: 0.0070 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 962/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0118 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0042\n",
      "Epoch 963/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0119 - mse: 0.0073 - val_loss: 0.0085 - val_mse: 0.0039\n",
      "Epoch 964/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 965/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 966/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 967/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0071 - val_loss: 0.0088 - val_mse: 0.0041\n",
      "Epoch 968/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0046\n",
      "Epoch 969/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 970/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 971/10000\n",
      "482/482 [==============================] - 0s 151us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 972/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0066 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 973/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 974/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 975/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 976/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0117 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 977/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 978/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0040\n",
      "Epoch 979/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 980/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 981/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 982/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 983/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 984/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 985/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0117 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0044\n",
      "Epoch 986/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 987/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0115 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 988/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 989/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0116 - mse: 0.0070 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 990/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0087 - val_mse: 0.0047\n",
      "Epoch 991/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 992/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 993/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0089 - val_mse: 0.0042\n",
      "Epoch 994/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 995/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0042\n",
      "Epoch 996/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0058 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 997/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 998/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 999/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1000/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0059 - val_loss: 0.0090 - val_mse: 0.0052\n",
      "Epoch 1001/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0062 - val_loss: 0.0088 - val_mse: 0.0050\n",
      "Epoch 1002/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 1003/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1004/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1005/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 1006/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0106 - mse: 0.0061 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1007/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1008/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 1009/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1010/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 1011/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0107 - mse: 0.0061 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1012/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1013/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1014/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0044\n",
      "Epoch 1015/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1016/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0042\n",
      "Epoch 1017/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0114 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1018/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0121 - mse: 0.0076 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1019/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1020/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1021/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0086 - val_mse: 0.0045\n",
      "Epoch 1022/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1023/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1024/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1025/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1026/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1027/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0045\n",
      "Epoch 1028/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1029/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0061 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1030/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0105 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 1031/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0038\n",
      "Epoch 1032/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0060 - val_loss: 0.0084 - val_mse: 0.0039\n",
      "Epoch 1033/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0111 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1034/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1035/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1036/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1037/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0043\n",
      "Epoch 1038/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1039/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0086 - val_mse: 0.0047\n",
      "Epoch 1040/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0084 - val_mse: 0.0042\n",
      "Epoch 1041/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1042/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0046\n",
      "Epoch 1043/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1044/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1045/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0084 - val_mse: 0.0044\n",
      "Epoch 1046/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 1047/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1048/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0042\n",
      "Epoch 1049/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0039\n",
      "Epoch 1050/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0114 - mse: 0.0069 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1051/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1052/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0071 - val_loss: 0.0084 - val_mse: 0.0044\n",
      "Epoch 1053/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0046\n",
      "Epoch 1054/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1055/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1056/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1057/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1058/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1059/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1060/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0043\n",
      "Epoch 1061/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0046\n",
      "Epoch 1062/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1063/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1064/10000\n",
      "482/482 [==============================] - 0s 107us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1065/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1066/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1067/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1068/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1069/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1070/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0116 - mse: 0.0072 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1071/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0043\n",
      "Epoch 1072/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1073/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1074/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0100 - mse: 0.0057 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1075/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1076/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1077/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1078/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1079/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0118 - mse: 0.0074 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1080/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1081/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1082/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1083/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0115 - mse: 0.0073 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1084/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1085/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1086/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1087/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0084 - val_mse: 0.0047\n",
      "Epoch 1088/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1089/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1090/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1091/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mse: 0.0059 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1092/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1093/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1094/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1095/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1096/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1097/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0116 - mse: 0.0072 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1098/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1099/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1100/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0040\n",
      "Epoch 1101/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0112 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1102/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0084 - val_mse: 0.0040\n",
      "Epoch 1103/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1104/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0118 - mse: 0.0075 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1105/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0116 - mse: 0.0074 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1106/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0111 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1107/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0111 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1108/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1109/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1110/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1111/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0065 - val_loss: 0.0082 - val_mse: 0.0039\n",
      "Epoch 1112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0039\n",
      "Epoch 1113/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1114/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0047\n",
      "Epoch 1115/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1116/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0110 - mse: 0.0068 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1117/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1118/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1119/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1120/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1121/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 1122/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0114 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1123/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0063 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1124/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1125/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1126/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1127/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0110 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1128/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0038\n",
      "Epoch 1129/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1130/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0084 - mse: 0.004 - 0s 112us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0087 - val_mse: 0.0052\n",
      "Epoch 1131/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0085 - val_mse: 0.0049\n",
      "Epoch 1132/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1133/10000\n",
      "482/482 [==============================] - 0s 93us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1134/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1135/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1136/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1137/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1138/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1139/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0086 - val_mse: 0.0041\n",
      "Epoch 1140/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0044\n",
      "Epoch 1141/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1142/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0113 - mse: 0.0070 - val_loss: 0.0082 - val_mse: 0.0043\n",
      "Epoch 1143/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1144/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1145/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0085 - val_mse: 0.0048\n",
      "Epoch 1146/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0120 - mse: 0.0078 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1147/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1148/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0099 - mse: 0.0056 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1149/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1150/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1151/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0042\n",
      "Epoch 1152/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1153/10000\n",
      "482/482 [==============================] - 0s 126us/step - loss: 0.0114 - mse: 0.0071 - val_loss: 0.0082 - val_mse: 0.0044\n",
      "Epoch 1154/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1155/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0058 - val_loss: 0.0082 - val_mse: 0.0044\n",
      "Epoch 1156/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1157/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1158/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0112 - mse: 0.0069 - val_loss: 0.0083 - val_mse: 0.0045\n",
      "Epoch 1159/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1160/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1161/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1162/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0114 - mse: 0.0072 - val_loss: 0.0083 - val_mse: 0.0046\n",
      "Epoch 1163/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0059 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1164/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1165/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1166/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mse: 0.0059 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 1167/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0116 - mse: 0.0075 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1168/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0084 - val_mse: 0.0041\n",
      "Epoch 1169/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1170/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1171/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1172/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0085 - val_mse: 0.0041\n",
      "Epoch 1173/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0100 - mse: 0.0055 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1174/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1175/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1176/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0042\n",
      "Epoch 1177/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1178/10000\n",
      "482/482 [==============================] - ETA: 0s - loss: 0.0108 - mse: 0.006 - 0s 108us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1179/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1180/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0043\n",
      "Epoch 1181/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1182/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1183/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0041\n",
      "Epoch 1184/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 1185/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1186/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0066 - val_loss: 0.0082 - val_mse: 0.0040\n",
      "Epoch 1187/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1188/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0044\n",
      "Epoch 1189/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 1190/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1191/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1192/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1193/10000\n",
      "482/482 [==============================] - 0s 149us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1194/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1195/10000\n",
      "482/482 [==============================] - 0s 124us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1196/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0112 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0044\n",
      "Epoch 1197/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mse: 0.0065 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1198/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1199/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0113 - mse: 0.0072 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1200/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0084 - val_mse: 0.0049\n",
      "Epoch 1201/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1202/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1203/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1204/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0113 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0043\n",
      "Epoch 1205/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0047\n",
      "Epoch 1206/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0038\n",
      "Epoch 1207/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0115 - mse: 0.0072 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1208/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0082 - val_mse: 0.0041\n",
      "Epoch 1209/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0083 - val_mse: 0.0040\n",
      "Epoch 1210/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0062 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1211/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1212/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1213/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0109 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1214/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 1215/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1216/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0079 - val_mse: 0.0037\n",
      "Epoch 1217/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1218/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mse: 0.0060 - val_loss: 0.0083 - val_mse: 0.0048\n",
      "Epoch 1219/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0081 - val_mse: 0.0045\n",
      "Epoch 1220/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1221/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1222/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1223/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1224/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1225/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1226/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0110 - mse: 0.0070 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1227/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0085 - val_mse: 0.0051\n",
      "Epoch 1228/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1229/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0100 - mse: 0.0058 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1230/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1231/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1232/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1233/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1234/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1235/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1236/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1237/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1238/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0085 - val_mse: 0.0050\n",
      "Epoch 1239/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0043\n",
      "Epoch 1240/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0108 - mse: 0.0069 - val_loss: 0.0082 - val_mse: 0.0045\n",
      "Epoch 1241/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1242/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1243/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1244/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1245/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1246/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1247/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1248/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1249/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1250/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 1251/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1252/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1253/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1254/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0112 - mse: 0.0071 - val_loss: 0.0080 - val_mse: 0.0042\n",
      "Epoch 1255/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0115 - mse: 0.0075 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1256/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0111 - mse: 0.0070 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1257/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1258/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0039\n",
      "Epoch 1259/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1260/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1261/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1262/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1263/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1264/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0079 - val_mse: 0.0041\n",
      "Epoch 1265/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1266/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1267/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1268/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1269/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0046\n",
      "Epoch 1270/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1271/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1272/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1273/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0037\n",
      "Epoch 1274/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0036\n",
      "Epoch 1275/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0047\n",
      "Epoch 1276/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0105 - mse: 0.0065 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1277/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1278/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1279/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0106 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0038\n",
      "Epoch 1280/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Epoch 1281/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0084 - val_mse: 0.0051\n",
      "Epoch 1282/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0105 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1283/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1284/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0113 - mse: 0.0072 - val_loss: 0.0079 - val_mse: 0.0036\n",
      "Epoch 1285/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0108 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1286/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0039\n",
      "Epoch 1287/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0114 - mse: 0.0073 - val_loss: 0.0083 - val_mse: 0.0049\n",
      "Epoch 1288/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1289/10000\n",
      "482/482 [==============================] - 0s 91us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1290/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1291/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1292/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0105 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1293/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1294/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1295/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1296/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0102 - mse: 0.0061 - val_loss: 0.0082 - val_mse: 0.0048\n",
      "Epoch 1297/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1298/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0059 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1299/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1300/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1301/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1302/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1303/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1304/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0081 - val_mse: 0.0047\n",
      "Epoch 1305/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0102 - mse: 0.0062 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1306/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1307/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0109 - mse: 0.0070 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1308/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0079 - val_mse: 0.0044\n",
      "Epoch 1309/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1310/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1311/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0109 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1312/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1313/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0066 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1314/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0108 - mse: 0.0069 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1315/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1316/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0065 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1317/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1318/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1319/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1320/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1321/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0106 - mse: 0.0067 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1322/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0108 - mse: 0.0067 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1323/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0095 - mse: 0.0055 - val_loss: 0.0083 - val_mse: 0.0042\n",
      "Epoch 1324/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0080 - val_mse: 0.0040\n",
      "Epoch 1325/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1326/10000\n",
      "482/482 [==============================] - 0s 120us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1327/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0107 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1328/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1329/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0081 - val_mse: 0.0048\n",
      "Epoch 1330/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0106 - mse: 0.0067 - val_loss: 0.0082 - val_mse: 0.0049\n",
      "Epoch 1331/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0110 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1332/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0109 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1333/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0078 - val_mse: 0.0039\n",
      "Epoch 1334/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0099 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0044\n",
      "Epoch 1335/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0041\n",
      "Epoch 1336/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0099 - mse: 0.0059 - val_loss: 0.0079 - val_mse: 0.0038\n",
      "Epoch 1337/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0110 - mse: 0.0071 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1338/10000\n",
      "482/482 [==============================] - 0s 122us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1339/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1340/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0038\n",
      "Epoch 1341/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0111 - mse: 0.0071 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1342/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0097 - mse: 0.0058 - val_loss: 0.0077 - val_mse: 0.0039\n",
      "Epoch 1343/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0083 - val_mse: 0.0050\n",
      "Epoch 1344/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482/482 [==============================] - 0s 126us/step - loss: 0.0103 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1345/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1346/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0040\n",
      "Epoch 1347/10000\n",
      "482/482 [==============================] - 0s 118us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0079 - val_mse: 0.0039\n",
      "Epoch 1348/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0104 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1349/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0108 - mse: 0.0068 - val_loss: 0.0079 - val_mse: 0.0043\n",
      "Epoch 1350/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0077 - val_mse: 0.0037\n",
      "Epoch 1351/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1352/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0083 - val_mse: 0.0041\n",
      "Epoch 1353/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0106 - mse: 0.0066 - val_loss: 0.0078 - val_mse: 0.0040\n",
      "Epoch 1354/10000\n",
      "482/482 [==============================] - 0s 106us/step - loss: 0.0107 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1355/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0106 - mse: 0.0068 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1356/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0037\n",
      "Epoch 1357/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1358/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1359/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0103 - mse: 0.0065 - val_loss: 0.0081 - val_mse: 0.0040\n",
      "Epoch 1360/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1361/10000\n",
      "482/482 [==============================] - 0s 102us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1362/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0102 - mse: 0.0063 - val_loss: 0.0079 - val_mse: 0.0040\n",
      "Epoch 1363/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0041\n",
      "Epoch 1364/10000\n",
      "482/482 [==============================] - 0s 114us/step - loss: 0.0107 - mse: 0.0067 - val_loss: 0.0076 - val_mse: 0.0037\n",
      "Epoch 1365/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0109 - mse: 0.0070 - val_loss: 0.0078 - val_mse: 0.0044\n",
      "Epoch 1366/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0095 - mse: 0.0057 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1367/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0078 - val_mse: 0.0043\n",
      "Epoch 1368/10000\n",
      "482/482 [==============================] - 0s 100us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0038\n",
      "Epoch 1369/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0078 - val_mse: 0.0038\n",
      "Epoch 1370/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0100 - mse: 0.0061 - val_loss: 0.0081 - val_mse: 0.0041\n",
      "Epoch 1371/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1372/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0065 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1373/10000\n",
      "482/482 [==============================] - 0s 116us/step - loss: 0.0103 - mse: 0.0065 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1374/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0042\n",
      "Epoch 1375/10000\n",
      "482/482 [==============================] - 0s 112us/step - loss: 0.0101 - mse: 0.0062 - val_loss: 0.0077 - val_mse: 0.0043\n",
      "Epoch 1376/10000\n",
      "482/482 [==============================] - 0s 97us/step - loss: 0.0102 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1377/10000\n",
      "482/482 [==============================] - 0s 104us/step - loss: 0.0100 - mse: 0.0060 - val_loss: 0.0080 - val_mse: 0.0045\n",
      "Epoch 1378/10000\n",
      "482/482 [==============================] - 0s 110us/step - loss: 0.0103 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0040\n",
      "Epoch 1379/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0104 - mse: 0.0064 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1380/10000\n",
      "482/482 [==============================] - 0s 108us/step - loss: 0.0103 - mse: 0.0063 - val_loss: 0.0076 - val_mse: 0.0039\n",
      "Epoch 1381/10000\n",
      "482/482 [==============================] - 0s 135us/step - loss: 0.0105 - mse: 0.0066 - val_loss: 0.0079 - val_mse: 0.0042\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 01381: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_tiny = build_tiny_regression_model(64)\n",
    "optimizer = keras.optimizers.RMSprop(0.0001)\n",
    "model_tiny.compile(optimizer = optimizer, loss='mse', metrics=['mse'])\n",
    "model_tiny.summary()\n",
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.00001, patience=30, mode=\"min\", verbose=1, restore_best_weights=True)\n",
    "history['tiny'] = model_tiny.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks=[ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prn.CreateNN([64, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 603)\n",
      "(603,)\n",
      "(64, 202)\n",
      "(202,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "print(type(x_test))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  882.8162979844722 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  26.177556237542092 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  9.341793040836631 \tscale factor:  0.007407407407407407\n",
      "Iteration:  3 \t\tError:  6.71134769805921 \tscale factor:  0.3936600000000001\n",
      "Iteration:  4 \t\tError:  2.5254005292343162 \tscale factor:  0.14580000000000004\n",
      "Iteration:  5 \t\tError:  1.9236393623491903 \tscale factor:  0.14580000000000004\n",
      "Iteration:  6 \t\tError:  1.687300050809699 \tscale factor:  0.05400000000000001\n",
      "Iteration:  7 \t\tError:  1.6160548125720917 \tscale factor:  0.05400000000000001\n",
      "Iteration:  8 \t\tError:  1.5356668949939483 \tscale factor:  0.05400000000000001\n",
      "Iteration:  9 \t\tError:  1.4736452210781634 \tscale factor:  0.020000000000000004\n",
      "Iteration:  10 \t\tError:  1.4254625807512398 \tscale factor:  0.05400000000000001\n",
      "Iteration:  11 \t\tError:  1.4116778597370008 \tscale factor:  0.05400000000000001\n",
      "Iteration:  12 \t\tError:  1.365237846690635 \tscale factor:  0.05400000000000001\n",
      "Iteration:  13 \t\tError:  1.323235904443498 \tscale factor:  0.05400000000000001\n",
      "Iteration:  14 \t\tError:  1.2925159023223451 \tscale factor:  0.05400000000000001\n",
      "Iteration:  15 \t\tError:  1.2619840230417894 \tscale factor:  0.05400000000000001\n",
      "Iteration:  16 \t\tError:  1.2299898519913346 \tscale factor:  0.05400000000000001\n",
      "Iteration:  17 \t\tError:  1.1884255640132588 \tscale factor:  0.020000000000000004\n",
      "Iteration:  18 \t\tError:  1.186742445422218 \tscale factor:  0.0074074074074074086\n",
      "Iteration:  19 \t\tError:  1.0641568368274221 \tscale factor:  0.0074074074074074086\n",
      "Iteration:  20 \t\tError:  1.0288475822902372 \tscale factor:  0.0074074074074074086\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=20, E_stop=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = prn.NNOut(x_train, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = prn.NNOut(x_test, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_train  y_train_pred\n",
      "0  0.647607      0.660812\n",
      "1  0.527738      0.508704\n",
      "2  0.624918      0.571427\n",
      "3  0.158689      0.204018\n",
      "4  0.467016      0.431129\n",
      "train r2 score =  0.9225192374167468 / 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy on the training data\n",
    "train_compare = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': pred_train.flatten()})\n",
    "print(train_compare.head())\n",
    "train_r2_score = r2_score(train_compare.y_train, train_compare.y_train_pred)\n",
    "print('train r2 score = ', train_r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_test  y_test_pred\n",
      "0  0.094426     0.168700\n",
      "1  0.629770     0.598467\n",
      "2  0.498361     0.465771\n",
      "3  0.366033     0.250176\n",
      "4  0.414426     0.394646\n",
      "test r2 score =  0.8376478450635576 / 1.0\n"
     ]
    }
   ],
   "source": [
    "test_compare = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': pred_test.flatten()})\n",
    "print(test_compare.head())\n",
    "test_r2_score = r2_score(test_compare.y_test, test_compare.y_test_pred)\n",
    "print('test r2 score = ', test_r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linestyles = ['-', '--', '-.', ':']\n",
    "colors = ['red', 'blue', 'green', 'yellow']\n",
    "sizes = ['tiny', 'small', 'medium', 'default']\n",
    "plt.figure()\n",
    "for y, linestyle in enumerate(sizes):\n",
    "    data_history = history[sizes[y]].history\n",
    "    loss = data_history['loss']\n",
    "    val_loss = data_history['val_loss']\n",
    "    plt.plot(val_loss, color=colors[y], linestyle = '--', label = sizes[y] + '_val_loss')\n",
    "    plt.plot(loss, color=colors[y], linestyle = ':', label = sizes[y] +'_loss')\n",
    "    \n",
    "plt.legend(loc = 'upper left' )\n",
    "plt.xlabel = 'epochs'\n",
    "plt.ylabel = 'loss'\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['medium'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['small'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.title('small model')\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_history = history['tiny'].history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.title('tiny model')\n",
    "plt.plot(data_history['val_loss'], color='red', label = 'val_loss')\n",
    "plt.plot(data_history['loss'], color='blue', label = 'loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "y_train = y_train.T\n",
    "x_test = x_test.T\n",
    "y_test = y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model_default.predict(x_test)\n",
    "pred_train = model_default.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    y_train  y_train_pred\n",
      "0  0.647607      0.514552\n",
      "1  0.527738      0.498594\n",
      "2  0.624918      0.629943\n",
      "3  0.158689      0.218937\n",
      "4  0.467016      0.408544\n",
      "train r2 score =  0.7898080341059219 / 1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking the accuracy on the training data\n",
    "train_compare = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': pred_train.flatten()})\n",
    "print(train_compare.head())\n",
    "train_r2_score = r2_score(train_compare.y_train, train_compare.y_train_pred)\n",
    "print('train r2 score = ', train_r2_score, '/ 1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_test  y_test_pred\n",
      "0  0.094426     0.218937\n",
      "1  0.629770     0.585916\n",
      "2  0.498361     0.533952\n",
      "3  0.366033     0.339156\n",
      "4  0.414426     0.407704\n",
      "test r2 score =  0.7518127377966217 / 1.0\n"
     ]
    }
   ],
   "source": [
    "test_compare = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': pred_test.flatten()})\n",
    "print(test_compare.head())\n",
    "test_r2_score = r2_score(test_compare.y_test, test_compare.y_test_pred)\n",
    "print('test r2 score = ', test_r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.330492</td>\n",
       "      <td>0.339449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.663082</td>\n",
       "      <td>0.515690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.427934</td>\n",
       "      <td>0.275546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.346492</td>\n",
       "      <td>0.341245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.364590</td>\n",
       "      <td>0.327694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_test_pred\n",
       "0  0.330492     0.339449\n",
       "1  0.663082     0.515690\n",
       "2  0.427934     0.275546\n",
       "3  0.346492     0.341245\n",
       "4  0.364590     0.327694"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.8265397095743221 / 1.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with CH value only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_x = test_data[:,0,:]\n",
    "test_data_y = yield_data['Yield'][mask_yield].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 64)                832       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 5,257\n",
      "Trainable params: 5,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_regression_model(12)\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81, 12)\n"
     ]
    }
   ],
   "source": [
    "print(test_data_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 64 samples, validate on 17 samples\n",
      "Epoch 1/10000\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 919.0145 - accuracy: 0.0000e+00 - val_loss: 519.3804 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 656.6866 - accuracy: 0.0000e+00 - val_loss: 371.0316 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 414.0786 - accuracy: 0.0000e+00 - val_loss: 266.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 265.6183 - accuracy: 0.0000e+00 - val_loss: 212.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "64/64 [==============================] - 0s 179us/step - loss: 273.8373 - accuracy: 0.0000e+00 - val_loss: 197.5551 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 298.7087 - accuracy: 0.0000e+00 - val_loss: 200.4125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 310.8811 - accuracy: 0.0156 - val_loss: 203.4566 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 234.9682 - accuracy: 0.0000e+00 - val_loss: 200.1054 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 283.4267 - accuracy: 0.0000e+00 - val_loss: 191.4078 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 271.8621 - accuracy: 0.0000e+00 - val_loss: 184.1571 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "64/64 [==============================] - 0s 315us/step - loss: 267.7375 - accuracy: 0.0000e+00 - val_loss: 182.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 250.3867 - accuracy: 0.0000e+00 - val_loss: 188.3636 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 251.0997 - accuracy: 0.0156 - val_loss: 197.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 252.6989 - accuracy: 0.0000e+00 - val_loss: 204.9701 - val_accuracy: 0.0588\n",
      "Epoch 15/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 233.4025 - accuracy: 0.0000e+00 - val_loss: 210.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 221.7016 - accuracy: 0.0000e+00 - val_loss: 210.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 213.7828 - accuracy: 0.0000e+00 - val_loss: 207.2567 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 268.9313 - accuracy: 0.0156 - val_loss: 199.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 259.7483 - accuracy: 0.0000e+00 - val_loss: 188.6309 - val_accuracy: 0.0588\n",
      "Epoch 20/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 205.6538 - accuracy: 0.0000e+00 - val_loss: 179.5594 - val_accuracy: 0.0588\n",
      "Epoch 21/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 195.3052 - accuracy: 0.0000e+00 - val_loss: 170.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 151.9656 - accuracy: 0.0000e+00 - val_loss: 164.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 201.0114 - accuracy: 0.0156 - val_loss: 160.4981 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 203.5452 - accuracy: 0.0000e+00 - val_loss: 160.3402 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 196.0561 - accuracy: 0.0000e+00 - val_loss: 163.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 178.2034 - accuracy: 0.0000e+00 - val_loss: 167.5468 - val_accuracy: 0.0588\n",
      "Epoch 27/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 221.9117 - accuracy: 0.0156 - val_loss: 173.8404 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 222.7455 - accuracy: 0.0000e+00 - val_loss: 175.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 155.0220 - accuracy: 0.0000e+00 - val_loss: 172.7637 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 174.5987 - accuracy: 0.0000e+00 - val_loss: 167.8829 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 184.5064 - accuracy: 0.0156 - val_loss: 161.8482 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 225.6445 - accuracy: 0.0000e+00 - val_loss: 156.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 230.4330 - accuracy: 0.0156 - val_loss: 151.7428 - val_accuracy: 0.0588\n",
      "Epoch 34/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 235.5918 - accuracy: 0.0000e+00 - val_loss: 146.1258 - val_accuracy: 0.0588\n",
      "Epoch 35/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.9772 - accuracy: 0.0000e+00 - val_loss: 142.8292 - val_accuracy: 0.0588\n",
      "Epoch 36/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 191.1345 - accuracy: 0.0156 - val_loss: 139.7425 - val_accuracy: 0.0588\n",
      "Epoch 37/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 219.8819 - accuracy: 0.0000e+00 - val_loss: 140.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 159.8179 - accuracy: 0.0000e+00 - val_loss: 144.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 149.3368 - accuracy: 0.0000e+00 - val_loss: 151.1553 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.4899 - accuracy: 0.0000e+00 - val_loss: 153.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 183.8045 - accuracy: 0.0000e+00 - val_loss: 151.1885 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 158.0460 - accuracy: 0.0000e+00 - val_loss: 147.6312 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 192.7749 - accuracy: 0.0000e+00 - val_loss: 142.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 203.7605 - accuracy: 0.0000e+00 - val_loss: 132.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.5863 - accuracy: 0.0000e+00 - val_loss: 125.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 163.2003 - accuracy: 0.0000e+00 - val_loss: 121.6926 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 188.6192 - accuracy: 0.0000e+00 - val_loss: 122.1478 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 174.5193 - accuracy: 0.0000e+00 - val_loss: 131.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.4134 - accuracy: 0.0000e+00 - val_loss: 142.4991 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.0945 - accuracy: 0.0156 - val_loss: 151.0955 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 194.2966 - accuracy: 0.0000e+00 - val_loss: 152.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 171.1273 - accuracy: 0.0000e+00 - val_loss: 147.1539 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 169.1698 - accuracy: 0.0000e+00 - val_loss: 135.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 151.9541 - accuracy: 0.0000e+00 - val_loss: 122.7022 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 175.2093 - accuracy: 0.0000e+00 - val_loss: 115.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 163.7057 - accuracy: 0.0000e+ - 0s 125us/step - loss: 171.9912 - accuracy: 0.0156 - val_loss: 110.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 173.0939 - accuracy: 0.0000e+00 - val_loss: 107.5262 - val_accuracy: 0.0588\n",
      "Epoch 58/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.2368 - accuracy: 0.0000e+00 - val_loss: 109.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 160.6484 - accuracy: 0.0000e+00 - val_loss: 113.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 142.9353 - accuracy: 0.0000e+00 - val_loss: 119.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.1225 - accuracy: 0.0000e+00 - val_loss: 125.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.8518 - accuracy: 0.0000e+00 - val_loss: 136.3193 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 187.2827 - accuracy: 0.0000e+00 - val_loss: 138.3542 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 161.4770 - accuracy: 0.0000e+00 - val_loss: 132.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 142.3231 - accuracy: 0.0156 - val_loss: 126.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 154.8860 - accuracy: 0.0000e+00 - val_loss: 119.7753 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 188.1061 - accuracy: 0.0156 - val_loss: 112.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 140.7591 - accuracy: 0.0000e+00 - val_loss: 110.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 134.2978 - accuracy: 0.0000e+00 - val_loss: 108.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 162.2009 - accuracy: 0.0000e+00 - val_loss: 108.7579 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 173.6074 - accuracy: 0.0000e+00 - val_loss: 113.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 162.2045 - accuracy: 0.0000e+00 - val_loss: 117.6842 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.5753 - accuracy: 0.0000e+00 - val_loss: 123.6619 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.6151 - accuracy: 0.0000e+00 - val_loss: 126.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 167.5950 - accuracy: 0.0312 - val_loss: 126.5158 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 169.8740 - accuracy: 0.0156 - val_loss: 126.0813 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 163.6138 - accuracy: 0.0000e+00 - val_loss: 117.5957 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 170.6783 - accuracy: 0.0000e+00 - val_loss: 113.0215 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 157.0419 - accuracy: 0.0000e+00 - val_loss: 112.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 158.5028 - accuracy: 0.0000e+00 - val_loss: 115.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 137.4615 - accuracy: 0.0000e+00 - val_loss: 113.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.0983 - accuracy: 0.0312 - val_loss: 112.8232 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 122.8114 - accuracy: 0.0000e+00 - val_loss: 112.8495 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 119.7417 - accuracy: 0.0000e+00 - val_loss: 113.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.4022 - accuracy: 0.0000e+00 - val_loss: 112.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 147.7029 - accuracy: 0.0000e+00 - val_loss: 109.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.8216 - accuracy: 0.0000e+00 - val_loss: 108.8237 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 154.0785 - accuracy: 0.0156 - val_loss: 108.6925 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 139.5411 - accuracy: 0.0000e+00 - val_loss: 105.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.9461 - accuracy: 0.0000e+00 - val_loss: 102.5481 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 150.4585 - accuracy: 0.0000e+00 - val_loss: 106.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 138.8390 - accuracy: 0.0000e+00 - val_loss: 111.7747 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 133.2212 - accuracy: 0.0000e+00 - val_loss: 121.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 118.0976 - accuracy: 0.0156 - val_loss: 131.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 152.3251 - accuracy: 0.0156 - val_loss: 133.6267 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 157.6668 - accuracy: 0.0156 - val_loss: 130.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.4156 - accuracy: 0.0000e+00 - val_loss: 123.6321 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.6404 - accuracy: 0.0000e+00 - val_loss: 117.7926 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 136.1808 - accuracy: 0.0156 - val_loss: 114.3712 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.8008 - accuracy: 0.0000e+00 - val_loss: 113.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.0952 - accuracy: 0.0000e+00 - val_loss: 115.6361 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.4529 - accuracy: 0.0156 - val_loss: 118.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.8029 - accuracy: 0.0000e+00 - val_loss: 118.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.8860 - accuracy: 0.0000e+00 - val_loss: 119.1265 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 145.9311 - accuracy: 0.0000e+00 - val_loss: 117.5124 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 141.6039 - accuracy: 0.0000e+00 - val_loss: 116.0176 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 111.7204 - accuracy: 0.0000e+00 - val_loss: 111.4548 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.7446 - accuracy: 0.0156 - val_loss: 103.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.2041 - accuracy: 0.0000e+00 - val_loss: 95.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 137.0257 - accuracy: 0.0156 - val_loss: 91.8084 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 166.7494 - accuracy: 0.0000e+00 - val_loss: 94.5509 - val_accuracy: 0.0588\n",
      "Epoch 112/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 156.8771 - accuracy: 0.0000e+00 - val_loss: 105.8223 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.9853 - accuracy: 0.0000e+00 - val_loss: 119.4765 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 143.0402 - accuracy: 0.0000e+00 - val_loss: 130.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 113.2497 - accuracy: 0.0000e+00 - val_loss: 133.1805 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.2063 - accuracy: 0.0000e+00 - val_loss: 123.2787 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.4163 - accuracy: 0.0312 - val_loss: 107.3158 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.0141 - accuracy: 0.0156 - val_loss: 96.0545 - val_accuracy: 0.0588\n",
      "Epoch 119/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 128.2527 - accuracy: 0.0000e+00 - val_loss: 96.1778 - val_accuracy: 0.0588\n",
      "Epoch 120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 149.4209 - accuracy: 0.0000e+00 - val_loss: 100.2188 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 126.9805 - accuracy: 0.0000e+00 - val_loss: 107.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 137.4711 - accuracy: 0.0156 - val_loss: 116.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 133.5065 - accuracy: 0.0000e+00 - val_loss: 125.6252 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 149.3536 - accuracy: 0.0000e+00 - val_loss: 129.9661 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 121.7429 - accuracy: 0.0000e+00 - val_loss: 126.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 141.7879 - accuracy: 0.0000e+00 - val_loss: 114.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.4128 - accuracy: 0.0000e+00 - val_loss: 103.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 158.2665 - accuracy: 0.0000e+00 - val_loss: 102.3653 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 116.6244 - accuracy: 0.0000e+00 - val_loss: 99.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 136.5044 - accuracy: 0.0000e+00 - val_loss: 101.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/10000\n",
      "64/64 [==============================] - 0s 167us/step - loss: 117.5791 - accuracy: 0.0000e+00 - val_loss: 107.0120 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 138.3744 - accuracy: 0.0156 - val_loss: 116.6736 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.4452 - accuracy: 0.0000e+00 - val_loss: 119.4997 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.0111 - accuracy: 0.0156 - val_loss: 116.1543 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 129.6651 - accuracy: 0.0000e+00 - val_loss: 115.0210 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.2324 - accuracy: 0.0000e+00 - val_loss: 113.0161 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.1081 - accuracy: 0.0000e+00 - val_loss: 105.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 115.4761 - accuracy: 0.0312 - val_loss: 97.1477 - val_accuracy: 0.0588\n",
      "Epoch 139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.7672 - accuracy: 0.0000e+00 - val_loss: 92.9759 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.6531 - accuracy: 0.0000e+00 - val_loss: 93.3417 - val_accuracy: 0.0588\n",
      "Epoch 141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 166.5128 - accuracy: 0.0000e+00 - val_loss: 103.4739 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 138.1838 - accuracy: 0.0000e+00 - val_loss: 109.5036 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 127.6452 - accuracy: 0.0000e+00 - val_loss: 112.2923 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 151.0158 - accuracy: 0.0156 - val_loss: 115.7901 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.4967 - accuracy: 0.0156 - val_loss: 119.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 144.0561 - accuracy: 0.0000e+00 - val_loss: 123.7539 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.5438 - accuracy: 0.0000e+00 - val_loss: 120.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.3885 - accuracy: 0.0312 - val_loss: 109.6579 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 89.9623 - accuracy: 0.0156 - val_loss: 101.2648 - val_accuracy: 0.0588\n",
      "Epoch 150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 131.7073 - accuracy: 0.0000e+00 - val_loss: 98.7363 - val_accuracy: 0.0588\n",
      "Epoch 151/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 109.3032 - accuracy: 0.0312 - val_loss: 99.6822 - val_accuracy: 0.0588\n",
      "Epoch 152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 142.7682 - accuracy: 0.0000e+00 - val_loss: 108.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.0859 - accuracy: 0.0000e+00 - val_loss: 117.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.2467 - accuracy: 0.0156 - val_loss: 126.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 105.3410 - accuracy: 0.0000e+00 - val_loss: 123.2456 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 107.7761 - accuracy: 0.0000e+00 - val_loss: 115.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.6404 - accuracy: 0.0156 - val_loss: 108.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 143.2380 - accuracy: 0.0000e+00 - val_loss: 100.2565 - val_accuracy: 0.0588\n",
      "Epoch 159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.9077 - accuracy: 0.0156 - val_loss: 97.8493 - val_accuracy: 0.0588\n",
      "Epoch 160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.6835 - accuracy: 0.0000e+00 - val_loss: 101.2257 - val_accuracy: 0.0588\n",
      "Epoch 161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 127.7558 - accuracy: 0.0156 - val_loss: 104.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.6880 - accuracy: 0.0000e+00 - val_loss: 111.7978 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 132.9052 - accuracy: 0.0156 - val_loss: 121.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.0965 - accuracy: 0.0000e+00 - val_loss: 122.9704 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.7255 - accuracy: 0.0000e+00 - val_loss: 113.0666 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.0673 - accuracy: 0.0000e+00 - val_loss: 103.4545 - val_accuracy: 0.0588\n",
      "Epoch 167/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 128.5817 - accuracy: 0.0000e+00 - val_loss: 97.0742 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 122.1869 - accuracy: 0.0156 - val_loss: 96.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.5461 - accuracy: 0.0000e+00 - val_loss: 101.5615 - val_accuracy: 0.0588\n",
      "Epoch 170/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 107.6186 - accuracy: 0.0000e+00 - val_loss: 111.0714 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.1388 - accuracy: 0.0000e+00 - val_loss: 115.5616 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 125.4294 - accuracy: 0.0000e+00 - val_loss: 110.1922 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 128.7043 - accuracy: 0.0000e+00 - val_loss: 103.3265 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8304 - accuracy: 0.0156 - val_loss: 101.2994 - val_accuracy: 0.0588\n",
      "Epoch 175/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.6713 - accuracy: 0.0000e+00 - val_loss: 94.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2976 - accuracy: 0.0000e+00 - val_loss: 89.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.7842 - accuracy: 0.0000e+00 - val_loss: 90.8683 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.8239 - accuracy: 0.0000e+00 - val_loss: 95.1817 - val_accuracy: 0.0588\n",
      "Epoch 179/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.5889 - accuracy: 0.0000e+00 - val_loss: 107.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.4848 - accuracy: 0.0000e+00 - val_loss: 121.0960 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.6250 - accuracy: 0.0000e+00 - val_loss: 127.7294 - val_accuracy: 0.0588\n",
      "Epoch 182/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.1550 - accuracy: 0.0000e+00 - val_loss: 121.9436 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.0697 - accuracy: 0.0156 - val_loss: 107.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 114.4849 - accuracy: 0.0156 - val_loss: 91.9452 - val_accuracy: 0.0588\n",
      "Epoch 185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.6717 - accuracy: 0.0000e+00 - val_loss: 84.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.7658 - accuracy: 0.0000e+00 - val_loss: 86.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 111.1621 - accuracy: 0.0000e+00 - val_loss: 92.6738 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.3226 - accuracy: 0.0000e+00 - val_loss: 96.8399 - val_accuracy: 0.0588\n",
      "Epoch 189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 124.8146 - accuracy: 0.0156 - val_loss: 102.3237 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4722 - accuracy: 0.0000e+00 - val_loss: 108.0129 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 119.2177 - accuracy: 0.0000e+00 - val_loss: 108.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.8709 - accuracy: 0.0000e+00 - val_loss: 106.7145 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.3099 - accuracy: 0.0000e+00 - val_loss: 106.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 126.3901 - accuracy: 0.0000e+00 - val_loss: 107.8556 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.2561 - accuracy: 0.0000e+00 - val_loss: 103.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 115.9955 - accuracy: 0.0156 - val_loss: 94.6895 - val_accuracy: 0.0588\n",
      "Epoch 197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 127.0519 - accuracy: 0.0000e+00 - val_loss: 97.0042 - val_accuracy: 0.0588\n",
      "Epoch 198/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.1124 - accuracy: 0.0156 - val_loss: 99.3207 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.4393 - accuracy: 0.0000e+00 - val_loss: 96.5420 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5349 - accuracy: 0.0000e+00 - val_loss: 94.3689 - val_accuracy: 0.0588\n",
      "Epoch 201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.8088 - accuracy: 0.0000e+00 - val_loss: 97.9880 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.4753 - accuracy: 0.0000e+00 - val_loss: 104.0720 - val_accuracy: 0.0588\n",
      "Epoch 203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.0399 - accuracy: 0.0000e+00 - val_loss: 104.0496 - val_accuracy: 0.0588\n",
      "Epoch 204/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.9834 - accuracy: 0.0000e+00 - val_loss: 93.6528 - val_accuracy: 0.0588\n",
      "Epoch 205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.9764 - accuracy: 0.0000e+00 - val_loss: 88.4511 - val_accuracy: 0.1176\n",
      "Epoch 206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.1814 - accuracy: 0.0000e+00 - val_loss: 90.0319 - val_accuracy: 0.0588\n",
      "Epoch 207/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.6819 - accuracy: 0.0000e+00 - val_loss: 95.2764 - val_accuracy: 0.0588\n",
      "Epoch 208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.4941 - accuracy: 0.0156 - val_loss: 101.1636 - val_accuracy: 0.0588\n",
      "Epoch 209/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 111.8264 - accuracy: 0.0000e+00 - val_loss: 100.2464 - val_accuracy: 0.0588\n",
      "Epoch 210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.9181 - accuracy: 0.0000e+00 - val_loss: 90.9203 - val_accuracy: 0.0588\n",
      "Epoch 211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5659 - accuracy: 0.0000e+00 - val_loss: 82.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.3451 - accuracy: 0.0000e+00 - val_loss: 82.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.7654 - accuracy: 0.0156 - val_loss: 87.9866 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.2716 - accuracy: 0.0000e+00 - val_loss: 90.7559 - val_accuracy: 0.0588\n",
      "Epoch 215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2886 - accuracy: 0.0000e+00 - val_loss: 97.0595 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.8506 - accuracy: 0.0156 - val_loss: 104.4656 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.7234 - accuracy: 0.0000e+00 - val_loss: 110.3955 - val_accuracy: 0.0588\n",
      "Epoch 218/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 131.8628 - accuracy: 0.0000e+00 - val_loss: 110.8574 - val_accuracy: 0.0588\n",
      "Epoch 219/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 131.5726 - accuracy: 0.0000e+00 - val_loss: 105.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 105.7620 - accuracy: 0.0000e+00 - val_loss: 99.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.8223 - accuracy: 0.0000e+00 - val_loss: 92.8922 - val_accuracy: 0.0588\n",
      "Epoch 222/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 111.4602 - accuracy: 0.0000e+00 - val_loss: 91.0732 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.5863 - accuracy: 0.0000e+00 - val_loss: 95.7270 - val_accuracy: 0.0588\n",
      "Epoch 224/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4913 - accuracy: 0.0156 - val_loss: 99.5599 - val_accuracy: 0.0588\n",
      "Epoch 225/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 106.4728 - accuracy: 0.0000e+00 - val_loss: 107.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.2317 - accuracy: 0.0000e+00 - val_loss: 108.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.0144 - accuracy: 0.0156 - val_loss: 108.7036 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.3196 - accuracy: 0.0000e+00 - val_loss: 108.8950 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.8445 - accuracy: 0.0000e+00 - val_loss: 100.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.8861 - accuracy: 0.0312 - val_loss: 94.7652 - val_accuracy: 0.0588\n",
      "Epoch 231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.6268 - accuracy: 0.0000e+00 - val_loss: 94.9179 - val_accuracy: 0.0588\n",
      "Epoch 232/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 113.4374 - accuracy: 0.0000e+00 - val_loss: 98.9667 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 130.8697 - accuracy: 0.0000e+00 - val_loss: 102.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.0747 - accuracy: 0.0000e+00 - val_loss: 106.8406 - val_accuracy: 0.0588\n",
      "Epoch 235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.3734 - accuracy: 0.0000e+00 - val_loss: 106.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.8739 - accuracy: 0.0156 - val_loss: 104.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.9640 - accuracy: 0.0000e+00 - val_loss: 97.9894 - val_accuracy: 0.0588\n",
      "Epoch 238/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.4768 - accuracy: 0.0000e+00 - val_loss: 94.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.7573 - accuracy: 0.0000e+00 - val_loss: 98.5964 - val_accuracy: 0.0588\n",
      "Epoch 240/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.5485 - accuracy: 0.0000e+00 - val_loss: 105.6901 - val_accuracy: 0.0588\n",
      "Epoch 241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 125.9917 - accuracy: 0.0000e+00 - val_loss: 109.6110 - val_accuracy: 0.0588\n",
      "Epoch 242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.3168 - accuracy: 0.0000e+00 - val_loss: 114.4814 - val_accuracy: 0.0588\n",
      "Epoch 243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.8329 - accuracy: 0.0000e+00 - val_loss: 108.6885 - val_accuracy: 0.0588\n",
      "Epoch 244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.9922 - accuracy: 0.0156 - val_loss: 96.8548 - val_accuracy: 0.0588\n",
      "Epoch 245/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 110.1671 - accuracy: 0.0000e+00 - val_loss: 91.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.6872 - accuracy: 0.0000e+00 - val_loss: 95.3283 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.3609 - accuracy: 0.0000e+00 - val_loss: 100.0944 - val_accuracy: 0.0588\n",
      "Epoch 248/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 125.9677 - accuracy: 0.0469 - val_loss: 107.4885 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.7987 - accuracy: 0.0000e+00 - val_loss: 110.9006 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 119.9479 - accuracy: 0.0000e+00 - val_loss: 103.7780 - val_accuracy: 0.0588\n",
      "Epoch 251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.8595 - accuracy: 0.0000e+00 - val_loss: 101.3351 - val_accuracy: 0.0588\n",
      "Epoch 252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.0036 - accuracy: 0.0156 - val_loss: 97.2887 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.4315 - accuracy: 0.0000e+00 - val_loss: 91.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 134.1394 - accuracy: 0.0000e+00 - val_loss: 89.8328 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 99.6643 - accuracy: 0.0156 - val_loss: 96.8473 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 120.6935 - accuracy: 0.0000e+00 - val_loss: 102.5279 - val_accuracy: 0.0588\n",
      "Epoch 257/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.1677 - accuracy: 0.0000e+00 - val_loss: 104.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.7711 - accuracy: 0.0000e+00 - val_loss: 100.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 123.2402 - accuracy: 0.0156 - val_loss: 100.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.8149 - accuracy: 0.0000e+00 - val_loss: 100.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.8428 - accuracy: 0.0000e+00 - val_loss: 99.8558 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4534 - accuracy: 0.0000e+00 - val_loss: 106.4323 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.3966 - accuracy: 0.0000e+00 - val_loss: 108.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.6927 - accuracy: 0.0156 - val_loss: 111.5362 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 111.8311 - accuracy: 0.0156 - val_loss: 102.1447 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.9629 - accuracy: 0.0156 - val_loss: 94.2159 - val_accuracy: 0.0588\n",
      "Epoch 267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.6645 - accuracy: 0.0000e+00 - val_loss: 88.9603 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 110.4884 - accuracy: 0.0312 - val_loss: 92.0392 - val_accuracy: 0.0588\n",
      "Epoch 269/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.4273 - accuracy: 0.0000e+00 - val_loss: 92.9913 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.7567 - accuracy: 0.0000e+00 - val_loss: 94.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.8061 - accuracy: 0.0000e+00 - val_loss: 101.6894 - val_accuracy: 0.0588\n",
      "Epoch 272/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1069 - accuracy: 0.0000e+00 - val_loss: 114.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.8672 - accuracy: 0.0000e+00 - val_loss: 116.4253 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 129.5299 - accuracy: 0.0000e+00 - val_loss: 99.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.3699 - accuracy: 0.0156 - val_loss: 90.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.4674 - accuracy: 0.0000e+00 - val_loss: 85.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.1128 - accuracy: 0.0000e+00 - val_loss: 86.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 105.5016 - accuracy: 0.0156 - val_loss: 93.4024 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.4966 - accuracy: 0.0156 - val_loss: 100.5123 - val_accuracy: 0.0588\n",
      "Epoch 280/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.9574 - accuracy: 0.0000e+00 - val_loss: 102.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 93.0762 - accuracy: 0.0000e+00 - val_loss: 99.7115 - val_accuracy: 0.0588\n",
      "Epoch 282/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 85.8949 - accuracy: 0.0156 - val_loss: 98.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.6751 - accuracy: 0.0000e+00 - val_loss: 103.5083 - val_accuracy: 0.0588\n",
      "Epoch 284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 113.8426 - accuracy: 0.0000e+00 - val_loss: 107.0803 - val_accuracy: 0.0588\n",
      "Epoch 285/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 118.8223 - accuracy: 0.0000e+00 - val_loss: 105.2366 - val_accuracy: 0.0588\n",
      "Epoch 286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.8358 - accuracy: 0.0000e+00 - val_loss: 103.8737 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.0888 - accuracy: 0.0156 - val_loss: 104.8745 - val_accuracy: 0.0588\n",
      "Epoch 288/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 106.3634 - accuracy: 0.0000e+00 - val_loss: 102.9231 - val_accuracy: 0.1176\n",
      "Epoch 289/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.7796 - accuracy: 0.0000e+00 - val_loss: 95.6854 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.4865 - accuracy: 0.0000e+00 - val_loss: 94.5033 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.3967 - accuracy: 0.0000e+00 - val_loss: 105.4209 - val_accuracy: 0.1176\n",
      "Epoch 292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 114.0377 - accuracy: 0.0000e+00 - val_loss: 113.1493 - val_accuracy: 0.0588\n",
      "Epoch 293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.7438 - accuracy: 0.0156 - val_loss: 111.0640 - val_accuracy: 0.0588\n",
      "Epoch 294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.6250 - accuracy: 0.0000e+00 - val_loss: 105.2549 - val_accuracy: 0.0588\n",
      "Epoch 295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.8411 - accuracy: 0.0156 - val_loss: 97.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.8214 - accuracy: 0.0000e+00 - val_loss: 96.7206 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6435 - accuracy: 0.0000e+00 - val_loss: 98.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.4060 - accuracy: 0.0000e+00 - val_loss: 100.3378 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.1560 - accuracy: 0.0000e+00 - val_loss: 107.1931 - val_accuracy: 0.0588\n",
      "Epoch 300/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 128.2129 - accuracy: 0.0000e+00 - val_loss: 116.3856 - val_accuracy: 0.0588\n",
      "Epoch 301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0376 - accuracy: 0.0469 - val_loss: 116.5196 - val_accuracy: 0.0588\n",
      "Epoch 302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.8815 - accuracy: 0.0156 - val_loss: 107.2790 - val_accuracy: 0.0588\n",
      "Epoch 303/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 85.1174 - accuracy: 0.0000e+00 - val_loss: 100.3736 - val_accuracy: 0.1176\n",
      "Epoch 304/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.4343 - accuracy: 0.0000e+00 - val_loss: 93.1719 - val_accuracy: 0.0588\n",
      "Epoch 305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.3857 - accuracy: 0.0000e+00 - val_loss: 87.4255 - val_accuracy: 0.0588\n",
      "Epoch 306/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.1350 - accuracy: 0.0312 - val_loss: 86.1900 - val_accuracy: 0.0588\n",
      "Epoch 307/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.2286 - accuracy: 0.0000e+00 - val_loss: 86.6234 - val_accuracy: 0.0588\n",
      "Epoch 308/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 66.9708 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 106.9388 - accuracy: 0.0000e+00 - val_loss: 89.2942 - val_accuracy: 0.0588\n",
      "Epoch 309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.1429 - accuracy: 0.0000e+00 - val_loss: 97.1006 - val_accuracy: 0.1176\n",
      "Epoch 310/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4550 - accuracy: 0.0312 - val_loss: 106.9123 - val_accuracy: 0.0588\n",
      "Epoch 311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.6462 - accuracy: 0.0000e+00 - val_loss: 104.7097 - val_accuracy: 0.0588\n",
      "Epoch 312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.0392 - accuracy: 0.0000e+00 - val_loss: 102.6634 - val_accuracy: 0.1176\n",
      "Epoch 313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.4925 - accuracy: 0.0000e+00 - val_loss: 97.9159 - val_accuracy: 0.0588\n",
      "Epoch 314/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.2809 - accuracy: 0.0000e+00 - val_loss: 93.0219 - val_accuracy: 0.0588\n",
      "Epoch 315/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.4473 - accuracy: 0.0000e+00 - val_loss: 89.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.5992 - accuracy: 0.0000e+00 - val_loss: 95.4519 - val_accuracy: 0.0588\n",
      "Epoch 317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4593 - accuracy: 0.0000e+00 - val_loss: 95.0179 - val_accuracy: 0.0588\n",
      "Epoch 318/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 121.9485 - accuracy: 0.0000e+00 - val_loss: 101.1753 - val_accuracy: 0.0588\n",
      "Epoch 319/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 114.9441 - accuracy: 0.0000e+00 - val_loss: 105.7359 - val_accuracy: 0.0588\n",
      "Epoch 320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1934 - accuracy: 0.0000e+00 - val_loss: 101.0880 - val_accuracy: 0.0588\n",
      "Epoch 321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 119.3930 - accuracy: 0.0000e+00 - val_loss: 92.5855 - val_accuracy: 0.0588\n",
      "Epoch 322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.9269 - accuracy: 0.0000e+00 - val_loss: 89.0226 - val_accuracy: 0.0588\n",
      "Epoch 323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.8394 - accuracy: 0.0000e+00 - val_loss: 93.7038 - val_accuracy: 0.0588\n",
      "Epoch 324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.9217 - accuracy: 0.0000e+00 - val_loss: 101.0674 - val_accuracy: 0.0588\n",
      "Epoch 325/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.4809 - accuracy: 0.0000e+00 - val_loss: 104.2927 - val_accuracy: 0.0588\n",
      "Epoch 326/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.7246 - accuracy: 0.0000e+00 - val_loss: 103.1698 - val_accuracy: 0.0588\n",
      "Epoch 327/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 107.5280 - accuracy: 0.0000e+00 - val_loss: 99.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.4291 - accuracy: 0.0000e+00 - val_loss: 97.1858 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5582 - accuracy: 0.0156 - val_loss: 98.4851 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.3779 - accuracy: 0.0000e+00 - val_loss: 97.7955 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0440 - accuracy: 0.0000e+00 - val_loss: 97.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.0903 - accuracy: 0.0000e+00 - val_loss: 95.8167 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.3339 - accuracy: 0.0000e+00 - val_loss: 96.5624 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.6995 - accuracy: 0.0000e+00 - val_loss: 102.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.3850 - accuracy: 0.0000e+00 - val_loss: 113.5541 - val_accuracy: 0.0588\n",
      "Epoch 336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5649 - accuracy: 0.0000e+00 - val_loss: 119.0588 - val_accuracy: 0.0588\n",
      "Epoch 337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.2573 - accuracy: 0.0000e+00 - val_loss: 112.6940 - val_accuracy: 0.1176\n",
      "Epoch 338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.1340 - accuracy: 0.0000e+00 - val_loss: 101.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.9614 - accuracy: 0.0000e+00 - val_loss: 88.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.8688 - accuracy: 0.0000e+00 - val_loss: 83.9405 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7872 - accuracy: 0.0000e+00 - val_loss: 89.8272 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.4395 - accuracy: 0.0000e+00 - val_loss: 102.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.9139 - accuracy: 0.0156 - val_loss: 115.2095 - val_accuracy: 0.0588\n",
      "Epoch 344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.9786 - accuracy: 0.0000e+00 - val_loss: 114.6668 - val_accuracy: 0.0588\n",
      "Epoch 345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 101.6278 - accuracy: 0.0156 - val_loss: 101.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.1412 - accuracy: 0.0000e+00 - val_loss: 90.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.1814 - accuracy: 0.0000e+00 - val_loss: 90.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.5473 - accuracy: 0.0156 - val_loss: 96.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 97.2911 - accuracy: 0.0000e+00 - val_loss: 102.2145 - val_accuracy: 0.0588\n",
      "Epoch 350/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.3358 - accuracy: 0.0312 - val_loss: 105.9345 - val_accuracy: 0.0588\n",
      "Epoch 351/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 87.2983 - accuracy: 0.0000e+00 - val_loss: 105.8435 - val_accuracy: 0.0588\n",
      "Epoch 352/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 101.9084 - accuracy: 0.0000e+00 - val_loss: 98.9948 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3965 - accuracy: 0.0156 - val_loss: 93.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0348 - accuracy: 0.0000e+00 - val_loss: 96.4177 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.9720 - accuracy: 0.0000e+00 - val_loss: 104.1754 - val_accuracy: 0.0588\n",
      "Epoch 356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.8068 - accuracy: 0.0000e+00 - val_loss: 102.8825 - val_accuracy: 0.0588\n",
      "Epoch 357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 121.1081 - accuracy: 0.0000e+00 - val_loss: 93.1193 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 110.4866 - accuracy: 0.0156 - val_loss: 96.1037 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.3273 - accuracy: 0.0000e+00 - val_loss: 100.3488 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.0097 - accuracy: 0.0000e+00 - val_loss: 103.3388 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1317 - accuracy: 0.0000e+00 - val_loss: 98.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.4489 - accuracy: 0.0000e+00 - val_loss: 94.7724 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.1170 - accuracy: 0.0000e+00 - val_loss: 94.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 118.4706 - accuracy: 0.0000e+00 - val_loss: 95.4854 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.9878 - accuracy: 0.0000e+00 - val_loss: 96.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.7897 - accuracy: 0.0000e+00 - val_loss: 97.8365 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.4964 - accuracy: 0.0000e+00 - val_loss: 95.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 121.0691 - accuracy: 0.0000e+00 - val_loss: 100.9794 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9542 - accuracy: 0.0156 - val_loss: 107.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9391 - accuracy: 0.0000e+00 - val_loss: 105.8027 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.1508 - accuracy: 0.0000e+00 - val_loss: 100.6825 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.6349 - accuracy: 0.0000e+00 - val_loss: 94.6353 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.5249 - accuracy: 0.0156 - val_loss: 90.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.5905 - accuracy: 0.0156 - val_loss: 96.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.5214 - accuracy: 0.0000e+00 - val_loss: 101.4064 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.4019 - accuracy: 0.0000e+00 - val_loss: 107.7156 - val_accuracy: 0.0588\n",
      "Epoch 377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.0806 - accuracy: 0.0156 - val_loss: 110.1474 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.7549 - accuracy: 0.0312 - val_loss: 105.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.0675 - accuracy: 0.0000e+00 - val_loss: 99.9443 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.9889 - accuracy: 0.0000e+00 - val_loss: 99.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.5414 - accuracy: 0.0000e+00 - val_loss: 102.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 123.4270 - accuracy: 0.0156 - val_loss: 108.0455 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.7176 - accuracy: 0.0000e+00 - val_loss: 114.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2157 - accuracy: 0.0000e+00 - val_loss: 118.9841 - val_accuracy: 0.0588\n",
      "Epoch 385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.2822 - accuracy: 0.0000e+00 - val_loss: 110.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.2827 - accuracy: 0.0156 - val_loss: 98.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.9357 - accuracy: 0.0000e+00 - val_loss: 91.7346 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1381 - accuracy: 0.0000e+00 - val_loss: 92.7707 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.2133 - accuracy: 0.0000e+00 - val_loss: 102.0600 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1913 - accuracy: 0.0156 - val_loss: 108.1537 - val_accuracy: 0.0588\n",
      "Epoch 391/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.1478 - accuracy: 0.0312 - val_loss: 106.4983 - val_accuracy: 0.0588\n",
      "Epoch 392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.8614 - accuracy: 0.0000e+00 - val_loss: 102.3817 - val_accuracy: 0.0588\n",
      "Epoch 393/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.1058 - accuracy: 0.0000e+00 - val_loss: 96.1927 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0531 - accuracy: 0.0312 - val_loss: 88.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.8293 - accuracy: 0.0000e+00 - val_loss: 88.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.1947 - accuracy: 0.0000e+00 - val_loss: 91.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.0539 - accuracy: 0.0000e+00 - val_loss: 99.5058 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.3972 - accuracy: 0.0312 - val_loss: 106.4376 - val_accuracy: 0.0588\n",
      "Epoch 399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.3148 - accuracy: 0.0000e+00 - val_loss: 109.5307 - val_accuracy: 0.0588\n",
      "Epoch 400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.8643 - accuracy: 0.0156 - val_loss: 108.6847 - val_accuracy: 0.0588\n",
      "Epoch 401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.5593 - accuracy: 0.0000e+00 - val_loss: 100.5564 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.6717 - accuracy: 0.0000e+00 - val_loss: 90.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0893 - accuracy: 0.0000e+00 - val_loss: 83.0851 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 149.3524 - accuracy: 0.0000e+00 - val_loss: 86.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.9447 - accuracy: 0.0000e+00 - val_loss: 96.3531 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.0076 - accuracy: 0.0000e+00 - val_loss: 105.5387 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.6981 - accuracy: 0.0156 - val_loss: 104.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 103.8989 - accuracy: 0.0000e+00 - val_loss: 110.1064 - val_accuracy: 0.0588\n",
      "Epoch 409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.8239 - accuracy: 0.0000e+00 - val_loss: 102.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.3580 - accuracy: 0.0000e+00 - val_loss: 98.6050 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6419 - accuracy: 0.0000e+00 - val_loss: 94.7609 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.3177 - accuracy: 0.0000e+00 - val_loss: 88.4346 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.1798 - accuracy: 0.0000e+00 - val_loss: 95.2638 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.8759 - accuracy: 0.0156 - val_loss: 110.6747 - val_accuracy: 0.0588\n",
      "Epoch 415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.8944 - accuracy: 0.0000e+00 - val_loss: 112.2980 - val_accuracy: 0.0588\n",
      "Epoch 416/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 112.3970 - accuracy: 0.0000e+00 - val_loss: 102.6815 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.3350 - accuracy: 0.0000e+00 - val_loss: 90.3576 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.0271 - accuracy: 0.0000e+00 - val_loss: 89.5840 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.5609 - accuracy: 0.0156 - val_loss: 90.6043 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7626 - accuracy: 0.0000e+00 - val_loss: 93.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.6778 - accuracy: 0.0000e+00 - val_loss: 88.6712 - val_accuracy: 0.0588\n",
      "Epoch 422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.6543 - accuracy: 0.0000e+00 - val_loss: 80.0989 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.6116 - accuracy: 0.0000e+00 - val_loss: 82.6286 - val_accuracy: 0.0588\n",
      "Epoch 424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.7960 - accuracy: 0.0000e+00 - val_loss: 86.6037 - val_accuracy: 0.0588\n",
      "Epoch 425/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.9596 - accuracy: 0.0000e+00 - val_loss: 90.7660 - val_accuracy: 0.0588\n",
      "Epoch 426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.4355 - accuracy: 0.0000e+00 - val_loss: 103.9383 - val_accuracy: 0.0588\n",
      "Epoch 427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1594 - accuracy: 0.0000e+00 - val_loss: 107.7349 - val_accuracy: 0.0588\n",
      "Epoch 428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8230 - accuracy: 0.0000e+00 - val_loss: 108.9735 - val_accuracy: 0.0588\n",
      "Epoch 429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 85.9071 - accuracy: 0.0000e+00 - val_loss: 103.7849 - val_accuracy: 0.0588\n",
      "Epoch 430/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.7514 - accuracy: 0.0156 - val_loss: 94.7182 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.8796 - accuracy: 0.0000e+00 - val_loss: 82.5222 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1242 - accuracy: 0.0000e+00 - val_loss: 82.8449 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2938 - accuracy: 0.0000e+00 - val_loss: 87.5929 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.3492 - accuracy: 0.0000e+00 - val_loss: 98.3431 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4459 - accuracy: 0.0156 - val_loss: 105.4842 - val_accuracy: 0.0588\n",
      "Epoch 436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.0038 - accuracy: 0.0312 - val_loss: 107.4186 - val_accuracy: 0.0588\n",
      "Epoch 437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.8337 - accuracy: 0.0000e+00 - val_loss: 106.5220 - val_accuracy: 0.0588\n",
      "Epoch 438/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.4239 - accuracy: 0.0000e+00 - val_loss: 97.5426 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.2088 - accuracy: 0.0156 - val_loss: 87.6249 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.5145 - accuracy: 0.0000e+00 - val_loss: 87.5322 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.0136 - accuracy: 0.0000e+00 - val_loss: 93.2304 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.6534 - accuracy: 0.0156 - val_loss: 99.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.7219 - accuracy: 0.0000e+00 - val_loss: 103.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.3280 - accuracy: 0.0000e+00 - val_loss: 102.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.9420 - accuracy: 0.0000e+00 - val_loss: 97.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.4067 - accuracy: 0.0000e+00 - val_loss: 93.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.9980 - accuracy: 0.0000e+00 - val_loss: 87.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.4426 - accuracy: 0.0000e+00 - val_loss: 94.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 100.5976 - accuracy: 0.0000e+00 - val_loss: 114.7637 - val_accuracy: 0.0588\n",
      "Epoch 450/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 99.0602 - accuracy: 0.0156 - val_loss: 111.6577 - val_accuracy: 0.0588\n",
      "Epoch 451/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2468 - accuracy: 0.0000e+00 - val_loss: 99.9349 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.3709 - accuracy: 0.0000e+00 - val_loss: 85.4987 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 102.7358 - accuracy: 0.0000e+00 - val_loss: 75.7740 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.1405 - accuracy: 0.0000e+00 - val_loss: 78.0068 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3099 - accuracy: 0.0000e+00 - val_loss: 90.9544 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.7671 - accuracy: 0.0000e+00 - val_loss: 106.2811 - val_accuracy: 0.0588\n",
      "Epoch 457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.0391 - accuracy: 0.0000e+00 - val_loss: 115.6346 - val_accuracy: 0.0588\n",
      "Epoch 458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.2144 - accuracy: 0.0000e+00 - val_loss: 110.0830 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.4906 - accuracy: 0.0000e+00 - val_loss: 99.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.8363 - accuracy: 0.0156 - val_loss: 88.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.0819 - accuracy: 0.0000e+00 - val_loss: 85.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.0409 - accuracy: 0.0000e+00 - val_loss: 91.6070 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.2861 - accuracy: 0.0000e+00 - val_loss: 104.7698 - val_accuracy: 0.0588\n",
      "Epoch 464/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.5714 - accuracy: 0.0000e+00 - val_loss: 109.4923 - val_accuracy: 0.0588\n",
      "Epoch 465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.2240 - accuracy: 0.0000e+00 - val_loss: 103.5889 - val_accuracy: 0.0588\n",
      "Epoch 466/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 80.8674 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 103.3034 - accuracy: 0.0000e+00 - val_loss: 94.2656 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.9898 - accuracy: 0.0000e+00 - val_loss: 84.5723 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1101 - accuracy: 0.0156 - val_loss: 83.3144 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 108.1273 - accuracy: 0.0000e+00 - val_loss: 85.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 87.0556 - accuracy: 0.0000e+00 - val_loss: 96.0717 - val_accuracy: 0.0588\n",
      "Epoch 471/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 86.3035 - accuracy: 0.0000e+00 - val_loss: 106.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8652 - accuracy: 0.0000e+00 - val_loss: 111.4135 - val_accuracy: 0.0588\n",
      "Epoch 473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3188 - accuracy: 0.0156 - val_loss: 103.7553 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.8447 - accuracy: 0.0156 - val_loss: 92.6031 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.4036 - accuracy: 0.0000e+00 - val_loss: 89.3469 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 113.2942 - accuracy: 0.0000e+00 - val_loss: 85.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.2228 - accuracy: 0.0156 - val_loss: 86.8489 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 101.0983 - accuracy: 0.0000e+00 - val_loss: 92.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.1335 - accuracy: 0.0000e+00 - val_loss: 91.3299 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 92.4157 - accuracy: 0.0312 - val_loss: 92.9358 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.3203 - accuracy: 0.0000e+00 - val_loss: 99.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 76.6590 - accuracy: 0.0000e+00 - val_loss: 101.8712 - val_accuracy: 0.0588\n",
      "Epoch 483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 116.4034 - accuracy: 0.0000e+00 - val_loss: 101.6246 - val_accuracy: 0.0588\n",
      "Epoch 484/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.0542 - accuracy: 0.0000e+00 - val_loss: 98.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.9302 - accuracy: 0.0000e+00 - val_loss: 90.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.0947 - accuracy: 0.0000e+00 - val_loss: 84.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.6717 - accuracy: 0.0000e+00 - val_loss: 81.0594 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.8445 - accuracy: 0.0000e+00 - val_loss: 89.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.7464 - accuracy: 0.0000e+00 - val_loss: 107.6835 - val_accuracy: 0.0588\n",
      "Epoch 490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.0747 - accuracy: 0.0000e+00 - val_loss: 114.5082 - val_accuracy: 0.0588\n",
      "Epoch 491/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 92.8695 - accuracy: 0.0000e+00 - val_loss: 104.4609 - val_accuracy: 0.0588\n",
      "Epoch 492/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.6299 - accuracy: 0.0000e+00 - val_loss: 90.3733 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.8307 - accuracy: 0.0000e+00 - val_loss: 82.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.1717 - accuracy: 0.0000e+00 - val_loss: 83.7354 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8930 - accuracy: 0.0000e+00 - val_loss: 90.2950 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5622 - accuracy: 0.0000e+00 - val_loss: 97.0154 - val_accuracy: 0.1176\n",
      "Epoch 497/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1225 - accuracy: 0.0000e+00 - val_loss: 98.5227 - val_accuracy: 0.1176\n",
      "Epoch 498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4968 - accuracy: 0.0312 - val_loss: 92.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.0571 - accuracy: 0.0000e+00 - val_loss: 93.2097 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.3945 - accuracy: 0.0156 - val_loss: 93.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 107.5666 - accuracy: 0.0000e+00 - val_loss: 97.9770 - val_accuracy: 0.0000e+00\n",
      "Epoch 502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.5531 - accuracy: 0.0156 - val_loss: 98.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.2721 - accuracy: 0.0000e+00 - val_loss: 100.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 504/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 94.8595 - accuracy: 0.0000e+00 - val_loss: 97.2317 - val_accuracy: 0.0000e+00\n",
      "Epoch 505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.0490 - accuracy: 0.0000e+00 - val_loss: 100.6555 - val_accuracy: 0.0588\n",
      "Epoch 506/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.1607 - accuracy: 0.0156 - val_loss: 92.7270 - val_accuracy: 0.0000e+00\n",
      "Epoch 507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.1622 - accuracy: 0.0000e+00 - val_loss: 87.6355 - val_accuracy: 0.0000e+00\n",
      "Epoch 508/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 102.8480 - accuracy: 0.0156 - val_loss: 91.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.9334 - accuracy: 0.0000e+00 - val_loss: 92.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 510/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.7803 - accuracy: 0.0000e+00 - val_loss: 97.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5775 - accuracy: 0.0000e+00 - val_loss: 102.8419 - val_accuracy: 0.0588\n",
      "Epoch 512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.2442 - accuracy: 0.0156 - val_loss: 98.2354 - val_accuracy: 0.0588\n",
      "Epoch 513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3147 - accuracy: 0.0000e+00 - val_loss: 94.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 514/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 94.2236 - accuracy: 0.0312 - val_loss: 98.8048 - val_accuracy: 0.0588\n",
      "Epoch 515/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2980 - accuracy: 0.0156 - val_loss: 99.1891 - val_accuracy: 0.0000e+00\n",
      "Epoch 516/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.2867 - accuracy: 0.0156 - val_loss: 94.0281 - val_accuracy: 0.0000e+00\n",
      "Epoch 517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9354 - accuracy: 0.0156 - val_loss: 87.6063 - val_accuracy: 0.0000e+00\n",
      "Epoch 518/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.2452 - accuracy: 0.0000e+00 - val_loss: 80.4842 - val_accuracy: 0.0000e+00\n",
      "Epoch 519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.2174 - accuracy: 0.0156 - val_loss: 80.6125 - val_accuracy: 0.0000e+00\n",
      "Epoch 520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1960 - accuracy: 0.0000e+00 - val_loss: 87.9981 - val_accuracy: 0.0000e+00\n",
      "Epoch 521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.2042 - accuracy: 0.0156 - val_loss: 98.2087 - val_accuracy: 0.1176\n",
      "Epoch 522/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 74.5718 - accuracy: 0.0000e+00 - val_loss: 102.0065 - val_accuracy: 0.0588\n",
      "Epoch 523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 104.1666 - accuracy: 0.0000e+00 - val_loss: 102.4148 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 524/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 120.2487 - accuracy: 0.0156 - val_loss: 103.3898 - val_accuracy: 0.0588\n",
      "Epoch 525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.6894 - accuracy: 0.0000e+00 - val_loss: 102.7688 - val_accuracy: 0.0000e+00\n",
      "Epoch 526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6578 - accuracy: 0.0000e+00 - val_loss: 92.3634 - val_accuracy: 0.0000e+00\n",
      "Epoch 527/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.3423 - accuracy: 0.0000e+00 - val_loss: 86.1897 - val_accuracy: 0.0000e+00\n",
      "Epoch 528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.8764 - accuracy: 0.0000e+00 - val_loss: 81.8870 - val_accuracy: 0.0000e+00\n",
      "Epoch 529/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.7408 - accuracy: 0.0000e+00 - val_loss: 92.7986 - val_accuracy: 0.0000e+00\n",
      "Epoch 530/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.9982 - accuracy: 0.0000e+00 - val_loss: 113.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 105.0709 - accuracy: 0.0000e+00 - val_loss: 120.2298 - val_accuracy: 0.0000e+00\n",
      "Epoch 532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5803 - accuracy: 0.0000e+00 - val_loss: 110.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 533/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 96.4958 - accuracy: 0.0000e+00 - val_loss: 99.7906 - val_accuracy: 0.0588\n",
      "Epoch 534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.7730 - accuracy: 0.0000e+00 - val_loss: 86.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.7437 - accuracy: 0.0000e+00 - val_loss: 78.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 536/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.1724 - accuracy: 0.0000e+00 - val_loss: 74.6493 - val_accuracy: 0.0000e+00\n",
      "Epoch 537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1907 - accuracy: 0.0000e+00 - val_loss: 81.7761 - val_accuracy: 0.0000e+00\n",
      "Epoch 538/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2867 - accuracy: 0.0156 - val_loss: 101.8510 - val_accuracy: 0.0588\n",
      "Epoch 539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.9184 - accuracy: 0.0000e+00 - val_loss: 117.8388 - val_accuracy: 0.0588\n",
      "Epoch 540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7964 - accuracy: 0.0000e+00 - val_loss: 118.9003 - val_accuracy: 0.0588\n",
      "Epoch 541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 96.1350 - accuracy: 0.0000e+00 - val_loss: 104.4429 - val_accuracy: 0.0588\n",
      "Epoch 542/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 79.0658 - accuracy: 0.0000e+00 - val_loss: 89.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 543/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 101.6994 - accuracy: 0.0000e+00 - val_loss: 78.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 106.0951 - accuracy: 0.0000e+00 - val_loss: 80.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.6627 - accuracy: 0.0000e+00 - val_loss: 93.0401 - val_accuracy: 0.0000e+00\n",
      "Epoch 546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.0687 - accuracy: 0.0000e+00 - val_loss: 108.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 122.0341 - accuracy: 0.0000e+00 - val_loss: 117.9037 - val_accuracy: 0.0000e+00\n",
      "Epoch 548/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.4128 - accuracy: 0.0156 - val_loss: 109.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.2821 - accuracy: 0.0156 - val_loss: 91.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9104 - accuracy: 0.0156 - val_loss: 77.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.1529 - accuracy: 0.0156 - val_loss: 76.6552 - val_accuracy: 0.0000e+00\n",
      "Epoch 552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1767 - accuracy: 0.0000e+00 - val_loss: 86.5749 - val_accuracy: 0.0000e+00\n",
      "Epoch 553/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 146.4702 - accuracy: 0.03 - 0s 125us/step - loss: 107.5238 - accuracy: 0.0156 - val_loss: 98.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 554/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.7736 - accuracy: 0.0156 - val_loss: 107.8889 - val_accuracy: 0.0000e+00\n",
      "Epoch 555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8367 - accuracy: 0.0156 - val_loss: 110.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 556/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7502 - accuracy: 0.0156 - val_loss: 99.2730 - val_accuracy: 0.0588\n",
      "Epoch 557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1432 - accuracy: 0.0000e+00 - val_loss: 84.9471 - val_accuracy: 0.0000e+00\n",
      "Epoch 558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.0087 - accuracy: 0.0000e+00 - val_loss: 78.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.6155 - accuracy: 0.0000e+00 - val_loss: 78.2461 - val_accuracy: 0.0000e+00\n",
      "Epoch 560/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.4474 - accuracy: 0.0000e+00 - val_loss: 79.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 561/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.0540 - accuracy: 0.0000e+00 - val_loss: 82.8537 - val_accuracy: 0.0000e+00\n",
      "Epoch 562/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 130.6043 - accuracy: 0.0000e+00 - val_loss: 90.8324 - val_accuracy: 0.0000e+00\n",
      "Epoch 563/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.1811 - accuracy: 0.0156 - val_loss: 90.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 564/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1942 - accuracy: 0.0156 - val_loss: 93.7903 - val_accuracy: 0.0000e+00\n",
      "Epoch 565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 112.0975 - accuracy: 0.0000e+00 - val_loss: 93.0263 - val_accuracy: 0.0588\n",
      "Epoch 566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5567 - accuracy: 0.0000e+00 - val_loss: 89.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 567/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.3668 - accuracy: 0.0156 - val_loss: 92.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7803 - accuracy: 0.0000e+00 - val_loss: 94.0660 - val_accuracy: 0.0000e+00\n",
      "Epoch 569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5521 - accuracy: 0.0000e+00 - val_loss: 89.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5313 - accuracy: 0.0000e+00 - val_loss: 87.6863 - val_accuracy: 0.0000e+00\n",
      "Epoch 571/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.4861 - accuracy: 0.0156 - val_loss: 87.0284 - val_accuracy: 0.0588\n",
      "Epoch 572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.1995 - accuracy: 0.0000e+00 - val_loss: 96.2818 - val_accuracy: 0.1176\n",
      "Epoch 573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 98.6928 - accuracy: 0.0000e+00 - val_loss: 99.4517 - val_accuracy: 0.1176\n",
      "Epoch 574/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.6113 - accuracy: 0.0000e+00 - val_loss: 89.3144 - val_accuracy: 0.0588\n",
      "Epoch 575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.5279 - accuracy: 0.0000e+00 - val_loss: 75.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9480 - accuracy: 0.0000e+00 - val_loss: 74.6536 - val_accuracy: 0.0000e+00\n",
      "Epoch 577/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4657 - accuracy: 0.0000e+00 - val_loss: 79.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.9294 - accuracy: 0.0000e+00 - val_loss: 86.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.0321 - accuracy: 0.0000e+00 - val_loss: 94.9470 - val_accuracy: 0.0588\n",
      "Epoch 580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.2225 - accuracy: 0.0156 - val_loss: 105.1113 - val_accuracy: 0.0588\n",
      "Epoch 581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.7499 - accuracy: 0.0156 - val_loss: 107.7531 - val_accuracy: 0.0588\n",
      "Epoch 582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.8116 - accuracy: 0.0000e+00 - val_loss: 101.2485 - val_accuracy: 0.1176\n",
      "Epoch 583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6185 - accuracy: 0.0156 - val_loss: 97.3910 - val_accuracy: 0.0588\n",
      "Epoch 584/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 69.7025 - accuracy: 0.0000e+00 - val_loss: 90.8655 - val_accuracy: 0.0588\n",
      "Epoch 585/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.5880 - accuracy: 0.0000e+00 - val_loss: 91.7124 - val_accuracy: 0.0588\n",
      "Epoch 586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.7900 - accuracy: 0.0000e+00 - val_loss: 100.2474 - val_accuracy: 0.0588\n",
      "Epoch 587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 111.1872 - accuracy: 0.0000e+00 - val_loss: 99.0997 - val_accuracy: 0.0588\n",
      "Epoch 588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8692 - accuracy: 0.0000e+00 - val_loss: 95.5681 - val_accuracy: 0.0588\n",
      "Epoch 589/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 83.2669 - accuracy: 0.0000e+00 - val_loss: 83.7981 - val_accuracy: 0.0588\n",
      "Epoch 590/10000\n",
      "64/64 [==============================] - 0s 562us/step - loss: 77.1190 - accuracy: 0.0000e+00 - val_loss: 76.2694 - val_accuracy: 0.0588\n",
      "Epoch 591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1762 - accuracy: 0.0000e+00 - val_loss: 76.7394 - val_accuracy: 0.0588\n",
      "Epoch 592/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.5170 - accuracy: 0.0000e+00 - val_loss: 77.8290 - val_accuracy: 0.0588\n",
      "Epoch 593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.6601 - accuracy: 0.0000e+00 - val_loss: 91.7142 - val_accuracy: 0.0588\n",
      "Epoch 594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.0276 - accuracy: 0.0000e+00 - val_loss: 115.4722 - val_accuracy: 0.0588\n",
      "Epoch 595/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 117.7159 - accuracy: 0.0156 - val_loss: 122.5612 - val_accuracy: 0.1176\n",
      "Epoch 596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1852 - accuracy: 0.0000e+00 - val_loss: 111.4176 - val_accuracy: 0.0588\n",
      "Epoch 597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.1537 - accuracy: 0.0000e+00 - val_loss: 93.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.4957 - accuracy: 0.0000e+00 - val_loss: 85.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 599/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.9351 - accuracy: 0.031 - 0s 125us/step - loss: 65.2672 - accuracy: 0.0156 - val_loss: 80.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.2039 - accuracy: 0.0156 - val_loss: 79.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.1147 - accuracy: 0.0000e+00 - val_loss: 85.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 602/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 108.1198 - accuracy: 0.0156 - val_loss: 100.5730 - val_accuracy: 0.0588\n",
      "Epoch 603/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.0405 - accuracy: 0.0000e+00 - val_loss: 107.4209 - val_accuracy: 0.0588\n",
      "Epoch 604/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.3175 - accuracy: 0.0156 - val_loss: 103.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.0979 - accuracy: 0.0000e+00 - val_loss: 98.7084 - val_accuracy: 0.0588\n",
      "Epoch 606/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.9224 - accuracy: 0.0000e+00 - val_loss: 97.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 607/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.6311 - accuracy: 0.0000e+00 - val_loss: 90.4057 - val_accuracy: 0.0588\n",
      "Epoch 608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.8316 - accuracy: 0.0000e+00 - val_loss: 87.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 609/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 95.0016 - accuracy: 0.0000e+00 - val_loss: 83.9240 - val_accuracy: 0.0000e+00\n",
      "Epoch 610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5411 - accuracy: 0.0000e+00 - val_loss: 84.1563 - val_accuracy: 0.0588\n",
      "Epoch 611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7883 - accuracy: 0.0000e+00 - val_loss: 89.3763 - val_accuracy: 0.1176\n",
      "Epoch 612/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.5107 - accuracy: 0.0000e+00 - val_loss: 90.0771 - val_accuracy: 0.0588\n",
      "Epoch 613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.8371 - accuracy: 0.0000e+00 - val_loss: 85.7784 - val_accuracy: 0.0588\n",
      "Epoch 614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2205 - accuracy: 0.0000e+00 - val_loss: 79.7275 - val_accuracy: 0.0588\n",
      "Epoch 615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0507 - accuracy: 0.0000e+00 - val_loss: 80.9971 - val_accuracy: 0.0588\n",
      "Epoch 616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3793 - accuracy: 0.0000e+00 - val_loss: 85.2482 - val_accuracy: 0.0588\n",
      "Epoch 617/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 89.4485 - accuracy: 0.0000e+00 - val_loss: 95.4915 - val_accuracy: 0.0588\n",
      "Epoch 618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0994 - accuracy: 0.0000e+00 - val_loss: 105.6877 - val_accuracy: 0.1176\n",
      "Epoch 619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5345 - accuracy: 0.0156 - val_loss: 109.9327 - val_accuracy: 0.1176\n",
      "Epoch 620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7995 - accuracy: 0.0000e+00 - val_loss: 96.8790 - val_accuracy: 0.0588\n",
      "Epoch 621/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.4215 - accuracy: 0.0156 - val_loss: 82.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 622/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.1895 - accuracy: 0.0000e+00 - val_loss: 75.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0877 - accuracy: 0.0000e+00 - val_loss: 75.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1272 - accuracy: 0.0000e+00 - val_loss: 85.7094 - val_accuracy: 0.0588\n",
      "Epoch 625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5511 - accuracy: 0.0000e+00 - val_loss: 102.2882 - val_accuracy: 0.0588\n",
      "Epoch 626/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 60.1573 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 74.8618 - accuracy: 0.0156 - val_loss: 113.4802 - val_accuracy: 0.0588\n",
      "Epoch 627/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.9480 - accuracy: 0.0000e+00 - val_loss: 103.0058 - val_accuracy: 0.0588\n",
      "Epoch 628/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 103.1458 - accuracy: 0.0000e+00 - val_loss: 89.3523 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.9817 - accuracy: 0.0156 - val_loss: 80.2573 - val_accuracy: 0.0000e+00\n",
      "Epoch 630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2091 - accuracy: 0.0000e+00 - val_loss: 82.8885 - val_accuracy: 0.0000e+00\n",
      "Epoch 631/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.6840 - accuracy: 0.0156 - val_loss: 87.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 632/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.6886 - accuracy: 0.0000e+00 - val_loss: 93.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.5273 - accuracy: 0.0000e+00 - val_loss: 96.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1456 - accuracy: 0.0000e+00 - val_loss: 98.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.0475 - accuracy: 0.0000e+00 - val_loss: 99.7435 - val_accuracy: 0.0000e+00\n",
      "Epoch 636/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.9355 - accuracy: 0.0000e+00 - val_loss: 95.7678 - val_accuracy: 0.0000e+00\n",
      "Epoch 637/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5861 - accuracy: 0.0156 - val_loss: 88.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5099 - accuracy: 0.0000e+00 - val_loss: 80.0504 - val_accuracy: 0.0000e+00\n",
      "Epoch 639/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.6117 - accuracy: 0.0000e+00 - val_loss: 83.3240 - val_accuracy: 0.0000e+00\n",
      "Epoch 640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.3652 - accuracy: 0.0156 - val_loss: 93.9959 - val_accuracy: 0.0588\n",
      "Epoch 641/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.6379 - accuracy: 0.0312 - val_loss: 104.7596 - val_accuracy: 0.0588\n",
      "Epoch 642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.6462 - accuracy: 0.0000e+00 - val_loss: 98.8249 - val_accuracy: 0.0588\n",
      "Epoch 643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4493 - accuracy: 0.0000e+00 - val_loss: 90.2327 - val_accuracy: 0.0588\n",
      "Epoch 644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.2507 - accuracy: 0.0000e+00 - val_loss: 88.1547 - val_accuracy: 0.0588\n",
      "Epoch 645/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.5720 - accuracy: 0.0000e+00 - val_loss: 85.9480 - val_accuracy: 0.0588\n",
      "Epoch 646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.4569 - accuracy: 0.0000e+00 - val_loss: 80.5695 - val_accuracy: 0.0588\n",
      "Epoch 647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.1450 - accuracy: 0.0000e+00 - val_loss: 82.8173 - val_accuracy: 0.0588\n",
      "Epoch 648/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 72.2205 - accuracy: 0.0000e+00 - val_loss: 88.5950 - val_accuracy: 0.0588\n",
      "Epoch 649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.1158 - accuracy: 0.0000e+00 - val_loss: 93.8454 - val_accuracy: 0.0588\n",
      "Epoch 650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.8874 - accuracy: 0.0000e+00 - val_loss: 102.6689 - val_accuracy: 0.1176\n",
      "Epoch 651/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.5655 - accuracy: 0.0000e+00 - val_loss: 105.3781 - val_accuracy: 0.1176\n",
      "Epoch 652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.3866 - accuracy: 0.0156 - val_loss: 99.2595 - val_accuracy: 0.0588\n",
      "Epoch 653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1767 - accuracy: 0.0000e+00 - val_loss: 93.3945 - val_accuracy: 0.0588\n",
      "Epoch 654/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.1170 - accuracy: 0.0000e+00 - val_loss: 97.4342 - val_accuracy: 0.0588\n",
      "Epoch 655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5221 - accuracy: 0.0000e+00 - val_loss: 89.1843 - val_accuracy: 0.0588\n",
      "Epoch 656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.0846 - accuracy: 0.0000e+00 - val_loss: 88.0482 - val_accuracy: 0.0588\n",
      "Epoch 657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.7546 - accuracy: 0.0000e+00 - val_loss: 92.3418 - val_accuracy: 0.0588\n",
      "Epoch 658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.6275 - accuracy: 0.0000e+00 - val_loss: 103.3384 - val_accuracy: 0.1765\n",
      "Epoch 659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.6707 - accuracy: 0.0000e+00 - val_loss: 108.3470 - val_accuracy: 0.1765\n",
      "Epoch 660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.7158 - accuracy: 0.0156 - val_loss: 105.5793 - val_accuracy: 0.1765\n",
      "Epoch 661/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1873 - accuracy: 0.0000e+00 - val_loss: 92.3978 - val_accuracy: 0.0588\n",
      "Epoch 662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3111 - accuracy: 0.0156 - val_loss: 79.5756 - val_accuracy: 0.0000e+00\n",
      "Epoch 663/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.8165 - accuracy: 0.0000e+00 - val_loss: 73.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 664/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.6252 - accuracy: 0.0000e+00 - val_loss: 75.8613 - val_accuracy: 0.0000e+00\n",
      "Epoch 665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.1831 - accuracy: 0.0000e+00 - val_loss: 90.2206 - val_accuracy: 0.0588\n",
      "Epoch 666/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3755 - accuracy: 0.0000e+00 - val_loss: 105.0446 - val_accuracy: 0.0588\n",
      "Epoch 667/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.0256 - accuracy: 0.0469 - val_loss: 112.0146 - val_accuracy: 0.0588\n",
      "Epoch 668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9531 - accuracy: 0.0000e+00 - val_loss: 104.8267 - val_accuracy: 0.0588\n",
      "Epoch 669/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.8435 - accuracy: 0.0000e+00 - val_loss: 91.1916 - val_accuracy: 0.0000e+00\n",
      "Epoch 670/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.2611 - accuracy: 0.0000e+00 - val_loss: 81.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3093 - accuracy: 0.0000e+00 - val_loss: 81.8789 - val_accuracy: 0.0000e+00\n",
      "Epoch 672/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.9247 - accuracy: 0.0000e+00 - val_loss: 96.4955 - val_accuracy: 0.0588\n",
      "Epoch 673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3429 - accuracy: 0.0156 - val_loss: 108.5267 - val_accuracy: 0.0588\n",
      "Epoch 674/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 106.0328 - accuracy: 0.0000e+00 - val_loss: 100.1075 - val_accuracy: 0.1176\n",
      "Epoch 675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6599 - accuracy: 0.0156 - val_loss: 93.0429 - val_accuracy: 0.0588\n",
      "Epoch 676/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.3564 - accuracy: 0.0000e+00 - val_loss: 83.8457 - val_accuracy: 0.0588\n",
      "Epoch 677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.1358 - accuracy: 0.0000e+00 - val_loss: 78.2222 - val_accuracy: 0.0588\n",
      "Epoch 678/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.7810 - accuracy: 0.0000e+00 - val_loss: 88.8045 - val_accuracy: 0.1176\n",
      "Epoch 679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.4059 - accuracy: 0.0000e+00 - val_loss: 109.7601 - val_accuracy: 0.1176\n",
      "Epoch 680/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.2034 - accuracy: 0.0000e+00 - val_loss: 112.4618 - val_accuracy: 0.1176\n",
      "Epoch 681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.2127 - accuracy: 0.0000e+00 - val_loss: 97.9312 - val_accuracy: 0.0588\n",
      "Epoch 682/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.8469 - accuracy: 0.0000e+00 - val_loss: 89.7514 - val_accuracy: 0.0588\n",
      "Epoch 683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.2411 - accuracy: 0.0000e+00 - val_loss: 80.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.8719 - accuracy: 0.0000e+00 - val_loss: 81.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1048 - accuracy: 0.0000e+00 - val_loss: 90.7390 - val_accuracy: 0.0588\n",
      "Epoch 686/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 84.5313 - accuracy: 0.0000e+00 - val_loss: 109.8861 - val_accuracy: 0.1176\n",
      "Epoch 687/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1053 - accuracy: 0.0000e+00 - val_loss: 117.1830 - val_accuracy: 0.0588\n",
      "Epoch 688/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.2967 - accuracy: 0.0000e+00 - val_loss: 114.9679 - val_accuracy: 0.0588\n",
      "Epoch 689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5888 - accuracy: 0.0000e+00 - val_loss: 103.0563 - val_accuracy: 0.0588\n",
      "Epoch 690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 94.9350 - accuracy: 0.0000e+00 - val_loss: 89.0339 - val_accuracy: 0.1765\n",
      "Epoch 691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5447 - accuracy: 0.0000e+00 - val_loss: 80.8744 - val_accuracy: 0.0588\n",
      "Epoch 692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2350 - accuracy: 0.0000e+00 - val_loss: 89.5311 - val_accuracy: 0.1765\n",
      "Epoch 693/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.6953 - accuracy: 0.0000e+00 - val_loss: 97.8314 - val_accuracy: 0.1176\n",
      "Epoch 694/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.8447 - accuracy: 0.0000e+00 - val_loss: 95.5824 - val_accuracy: 0.0588\n",
      "Epoch 695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5097 - accuracy: 0.0000e+00 - val_loss: 98.7090 - val_accuracy: 0.0588\n",
      "Epoch 696/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.6058 - accuracy: 0.0000e+00 - val_loss: 96.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.8430 - accuracy: 0.0156 - val_loss: 96.7389 - val_accuracy: 0.0000e+00\n",
      "Epoch 698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5432 - accuracy: 0.0156 - val_loss: 96.5758 - val_accuracy: 0.0000e+00\n",
      "Epoch 699/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 98.0452 - accuracy: 0.0000e+00 - val_loss: 93.7319 - val_accuracy: 0.0000e+00\n",
      "Epoch 700/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 78.7419 - accuracy: 0.0000e+00 - val_loss: 85.2588 - val_accuracy: 0.0000e+00\n",
      "Epoch 701/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.2192 - accuracy: 0.0000e+00 - val_loss: 82.0902 - val_accuracy: 0.0000e+00\n",
      "Epoch 702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.8947 - accuracy: 0.0000e+00 - val_loss: 85.7786 - val_accuracy: 0.0588\n",
      "Epoch 703/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 81.1349 - accuracy: 0.0000e+00 - val_loss: 96.6078 - val_accuracy: 0.1176\n",
      "Epoch 704/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.0733 - accuracy: 0.0000e+00 - val_loss: 107.7002 - val_accuracy: 0.0588\n",
      "Epoch 705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.2129 - accuracy: 0.0000e+00 - val_loss: 107.6734 - val_accuracy: 0.0588\n",
      "Epoch 706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.2290 - accuracy: 0.0000e+00 - val_loss: 92.5213 - val_accuracy: 0.0588\n",
      "Epoch 707/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1856 - accuracy: 0.0000e+00 - val_loss: 88.4697 - val_accuracy: 0.0588\n",
      "Epoch 708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1386 - accuracy: 0.0000e+00 - val_loss: 91.2288 - val_accuracy: 0.0588\n",
      "Epoch 709/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.8229 - accuracy: 0.0000e+00 - val_loss: 99.0496 - val_accuracy: 0.1176\n",
      "Epoch 710/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.2555 - accuracy: 0.0000e+00 - val_loss: 97.9640 - val_accuracy: 0.1176\n",
      "Epoch 711/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.4121 - accuracy: 0.0156 - val_loss: 101.2422 - val_accuracy: 0.0588\n",
      "Epoch 712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.0713 - accuracy: 0.0000e+00 - val_loss: 100.0707 - val_accuracy: 0.1176\n",
      "Epoch 713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.2113 - accuracy: 0.0000e+00 - val_loss: 88.6242 - val_accuracy: 0.1176\n",
      "Epoch 714/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.2465 - accuracy: 0.0000e+00 - val_loss: 79.9826 - val_accuracy: 0.0588\n",
      "Epoch 715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.2148 - accuracy: 0.0000e+00 - val_loss: 78.2845 - val_accuracy: 0.1176\n",
      "Epoch 716/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.1050 - accuracy: 0.0000e+00 - val_loss: 81.0131 - val_accuracy: 0.1176\n",
      "Epoch 717/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4067 - accuracy: 0.0000e+00 - val_loss: 94.4674 - val_accuracy: 0.1176\n",
      "Epoch 718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0755 - accuracy: 0.0000e+00 - val_loss: 97.9553 - val_accuracy: 0.1176\n",
      "Epoch 719/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.7183 - accuracy: 0.0000e+00 - val_loss: 91.5066 - val_accuracy: 0.0588\n",
      "Epoch 720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6597 - accuracy: 0.0000e+00 - val_loss: 88.6956 - val_accuracy: 0.0588\n",
      "Epoch 721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.8570 - accuracy: 0.0000e+00 - val_loss: 88.7368 - val_accuracy: 0.0588\n",
      "Epoch 722/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.3525 - accuracy: 0.0156 - val_loss: 94.9402 - val_accuracy: 0.0588\n",
      "Epoch 723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.4078 - accuracy: 0.0156 - val_loss: 98.1307 - val_accuracy: 0.1176\n",
      "Epoch 724/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.5718 - accuracy: 0.0000e+00 - val_loss: 94.6790 - val_accuracy: 0.0588\n",
      "Epoch 725/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 97.0275 - accuracy: 0.0000e+00 - val_loss: 95.2803 - val_accuracy: 0.1176\n",
      "Epoch 726/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1253 - accuracy: 0.0000e+00 - val_loss: 96.4418 - val_accuracy: 0.1176\n",
      "Epoch 727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.4650 - accuracy: 0.0156 - val_loss: 89.3331 - val_accuracy: 0.1176\n",
      "Epoch 728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4502 - accuracy: 0.0156 - val_loss: 91.7219 - val_accuracy: 0.1176\n",
      "Epoch 729/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.5593 - accuracy: 0.0000e+00 - val_loss: 97.1124 - val_accuracy: 0.0588\n",
      "Epoch 730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9031 - accuracy: 0.0000e+00 - val_loss: 93.4041 - val_accuracy: 0.1176\n",
      "Epoch 731/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.3041 - accuracy: 0.0000e+00 - val_loss: 90.0112 - val_accuracy: 0.1176\n",
      "Epoch 732/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.0086 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 56.8306 - accuracy: 0.0000e+00 - val_loss: 91.3547 - val_accuracy: 0.1176\n",
      "Epoch 733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.6749 - accuracy: 0.0000e+00 - val_loss: 90.6372 - val_accuracy: 0.1176\n",
      "Epoch 734/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 93.9741 - accuracy: 0.0000e+00 - val_loss: 89.9889 - val_accuracy: 0.1176\n",
      "Epoch 735/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 86.5903 - accuracy: 0.0000e+00 - val_loss: 87.8450 - val_accuracy: 0.0588\n",
      "Epoch 736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1852 - accuracy: 0.0000e+00 - val_loss: 87.3806 - val_accuracy: 0.0588\n",
      "Epoch 737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.3927 - accuracy: 0.0000e+00 - val_loss: 97.1952 - val_accuracy: 0.1176\n",
      "Epoch 738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7562 - accuracy: 0.0000e+00 - val_loss: 107.7456 - val_accuracy: 0.1176\n",
      "Epoch 739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.5586 - accuracy: 0.0312 - val_loss: 109.9493 - val_accuracy: 0.1176\n",
      "Epoch 740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5433 - accuracy: 0.0000e+00 - val_loss: 93.2845 - val_accuracy: 0.1176\n",
      "Epoch 741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5513 - accuracy: 0.0000e+00 - val_loss: 81.2238 - val_accuracy: 0.0588\n",
      "Epoch 742/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 61.7552 - accuracy: 0.0000e+00 - val_loss: 77.1579 - val_accuracy: 0.0588\n",
      "Epoch 743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.3604 - accuracy: 0.0000e+00 - val_loss: 75.1561 - val_accuracy: 0.0588\n",
      "Epoch 744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4986 - accuracy: 0.0156 - val_loss: 81.5426 - val_accuracy: 0.0588\n",
      "Epoch 745/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.9509 - accuracy: 0.0156 - val_loss: 84.2354 - val_accuracy: 0.1176\n",
      "Epoch 746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.7383 - accuracy: 0.0000e+00 - val_loss: 88.3777 - val_accuracy: 0.1765\n",
      "Epoch 747/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.7412 - accuracy: 0.0000e+00 - val_loss: 87.8061 - val_accuracy: 0.1765\n",
      "Epoch 748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7768 - accuracy: 0.0156 - val_loss: 87.0032 - val_accuracy: 0.1176\n",
      "Epoch 749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1522 - accuracy: 0.0000e+00 - val_loss: 82.9623 - val_accuracy: 0.0588\n",
      "Epoch 750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2808 - accuracy: 0.0000e+00 - val_loss: 79.4138 - val_accuracy: 0.0588\n",
      "Epoch 751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5834 - accuracy: 0.0156 - val_loss: 80.2804 - val_accuracy: 0.0588\n",
      "Epoch 752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.7180 - accuracy: 0.0000e+00 - val_loss: 86.8056 - val_accuracy: 0.1176\n",
      "Epoch 753/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2417 - accuracy: 0.0156 - val_loss: 93.3687 - val_accuracy: 0.1176\n",
      "Epoch 754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6775 - accuracy: 0.0156 - val_loss: 97.7180 - val_accuracy: 0.1176\n",
      "Epoch 755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.3350 - accuracy: 0.0000e+00 - val_loss: 89.9036 - val_accuracy: 0.0588\n",
      "Epoch 756/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.2845 - accuracy: 0.0000e+00 - val_loss: 83.8054 - val_accuracy: 0.0588\n",
      "Epoch 757/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.3421 - accuracy: 0.0000e+00 - val_loss: 89.6279 - val_accuracy: 0.0588\n",
      "Epoch 758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0409 - accuracy: 0.0000e+00 - val_loss: 93.5340 - val_accuracy: 0.0588\n",
      "Epoch 759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4565 - accuracy: 0.0000e+00 - val_loss: 91.9497 - val_accuracy: 0.0588\n",
      "Epoch 760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.9123 - accuracy: 0.0000e+00 - val_loss: 88.0153 - val_accuracy: 0.0588\n",
      "Epoch 761/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.8936 - accuracy: 0.0000e+00 - val_loss: 82.0183 - val_accuracy: 0.0588\n",
      "Epoch 762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2901 - accuracy: 0.0312 - val_loss: 78.3799 - val_accuracy: 0.0588\n",
      "Epoch 763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.2969 - accuracy: 0.0312 - val_loss: 83.0871 - val_accuracy: 0.1176\n",
      "Epoch 764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6019 - accuracy: 0.0000e+00 - val_loss: 87.0599 - val_accuracy: 0.1765\n",
      "Epoch 765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5470 - accuracy: 0.0000e+00 - val_loss: 90.3805 - val_accuracy: 0.1765\n",
      "Epoch 766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9053 - accuracy: 0.0000e+00 - val_loss: 94.2696 - val_accuracy: 0.1765\n",
      "Epoch 767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 101.8690 - accuracy: 0.0000e+00 - val_loss: 91.3828 - val_accuracy: 0.1176\n",
      "Epoch 768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9813 - accuracy: 0.0000e+00 - val_loss: 89.5473 - val_accuracy: 0.0588\n",
      "Epoch 769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.5103 - accuracy: 0.0000e+00 - val_loss: 87.4034 - val_accuracy: 0.0588\n",
      "Epoch 770/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1102 - accuracy: 0.0156 - val_loss: 83.0198 - val_accuracy: 0.0588\n",
      "Epoch 771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.3549 - accuracy: 0.0000e+00 - val_loss: 84.0612 - val_accuracy: 0.0588\n",
      "Epoch 772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5182 - accuracy: 0.0000e+00 - val_loss: 92.4878 - val_accuracy: 0.0588\n",
      "Epoch 773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3805 - accuracy: 0.0000e+00 - val_loss: 111.2910 - val_accuracy: 0.0588\n",
      "Epoch 774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.1139 - accuracy: 0.0156 - val_loss: 113.2538 - val_accuracy: 0.0588\n",
      "Epoch 775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.9840 - accuracy: 0.0000e+00 - val_loss: 105.7541 - val_accuracy: 0.0588\n",
      "Epoch 776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.5472 - accuracy: 0.0000e+00 - val_loss: 86.2621 - val_accuracy: 0.1176\n",
      "Epoch 777/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.6528 - accuracy: 0.0156 - val_loss: 71.0884 - val_accuracy: 0.1176\n",
      "Epoch 778/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.3699 - accuracy: 0.0000e+00 - val_loss: 70.6929 - val_accuracy: 0.1176\n",
      "Epoch 779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.1315 - accuracy: 0.0000e+00 - val_loss: 69.9477 - val_accuracy: 0.1176\n",
      "Epoch 780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.6767 - accuracy: 0.0000e+00 - val_loss: 75.7931 - val_accuracy: 0.1176\n",
      "Epoch 781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.8896 - accuracy: 0.0000e+00 - val_loss: 92.8507 - val_accuracy: 0.0588\n",
      "Epoch 782/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.8924 - accuracy: 0.0000e+00 - val_loss: 109.9400 - val_accuracy: 0.0588\n",
      "Epoch 783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.0059 - accuracy: 0.0000e+00 - val_loss: 110.2918 - val_accuracy: 0.0588\n",
      "Epoch 784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5662 - accuracy: 0.0000e+00 - val_loss: 94.9252 - val_accuracy: 0.1176\n",
      "Epoch 785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.2176 - accuracy: 0.0000e+00 - val_loss: 80.0991 - val_accuracy: 0.0588\n",
      "Epoch 786/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.8047 - accuracy: 0.0000e+00 - val_loss: 73.1667 - val_accuracy: 0.0588\n",
      "Epoch 787/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 90.0304 - accuracy: 0.0156 - val_loss: 76.0281 - val_accuracy: 0.0588\n",
      "Epoch 788/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 102.9337 - accuracy: 0.0000e+00 - val_loss: 91.3037 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.3351 - accuracy: 0.0000e+00 - val_loss: 106.5365 - val_accuracy: 0.0588\n",
      "Epoch 790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 99.2717 - accuracy: 0.0000e+00 - val_loss: 109.8862 - val_accuracy: 0.0588\n",
      "Epoch 791/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 72.9747 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 67.6064 - accuracy: 0.0000e+00 - val_loss: 97.2210 - val_accuracy: 0.0588\n",
      "Epoch 792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.9569 - accuracy: 0.0000e+00 - val_loss: 80.0823 - val_accuracy: 0.1176\n",
      "Epoch 793/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2804 - accuracy: 0.0000e+00 - val_loss: 73.9175 - val_accuracy: 0.0588\n",
      "Epoch 794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7209 - accuracy: 0.0000e+00 - val_loss: 73.8210 - val_accuracy: 0.0588\n",
      "Epoch 795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 108.1383 - accuracy: 0.0000e+00 - val_loss: 79.8796 - val_accuracy: 0.0588\n",
      "Epoch 796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6487 - accuracy: 0.0000e+00 - val_loss: 81.4757 - val_accuracy: 0.0588\n",
      "Epoch 797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.5799 - accuracy: 0.0000e+00 - val_loss: 85.2486 - val_accuracy: 0.0588\n",
      "Epoch 798/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.7220 - accuracy: 0.0000e+00 - val_loss: 94.5747 - val_accuracy: 0.0588\n",
      "Epoch 799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.5328 - accuracy: 0.0000e+00 - val_loss: 92.1499 - val_accuracy: 0.0588\n",
      "Epoch 800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2660 - accuracy: 0.0000e+00 - val_loss: 83.6101 - val_accuracy: 0.0588\n",
      "Epoch 801/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.0822 - accuracy: 0.0000e+00 - val_loss: 72.5766 - val_accuracy: 0.0588\n",
      "Epoch 802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6617 - accuracy: 0.0000e+00 - val_loss: 69.7917 - val_accuracy: 0.0588\n",
      "Epoch 803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.9886 - accuracy: 0.0156 - val_loss: 82.0686 - val_accuracy: 0.1176\n",
      "Epoch 804/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8419 - accuracy: 0.0000e+00 - val_loss: 99.3820 - val_accuracy: 0.1176\n",
      "Epoch 805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.7908 - accuracy: 0.0000e+00 - val_loss: 101.0068 - val_accuracy: 0.0588\n",
      "Epoch 806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6260 - accuracy: 0.0000e+00 - val_loss: 89.1970 - val_accuracy: 0.1765\n",
      "Epoch 807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9515 - accuracy: 0.0000e+00 - val_loss: 78.8486 - val_accuracy: 0.1176\n",
      "Epoch 808/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.7450 - accuracy: 0.0000e+00 - val_loss: 73.2369 - val_accuracy: 0.1176\n",
      "Epoch 809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8215 - accuracy: 0.0156 - val_loss: 82.3763 - val_accuracy: 0.1176\n",
      "Epoch 810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3637 - accuracy: 0.0156 - val_loss: 95.2009 - val_accuracy: 0.1176\n",
      "Epoch 811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8129 - accuracy: 0.0000e+00 - val_loss: 100.8215 - val_accuracy: 0.1176\n",
      "Epoch 812/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.5490 - accuracy: 0.0000e+00 - val_loss: 97.8464 - val_accuracy: 0.1176\n",
      "Epoch 813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1753 - accuracy: 0.0312 - val_loss: 84.7844 - val_accuracy: 0.1176\n",
      "Epoch 814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.5475 - accuracy: 0.0000e+00 - val_loss: 86.7092 - val_accuracy: 0.1765\n",
      "Epoch 815/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6568 - accuracy: 0.0000e+00 - val_loss: 88.3042 - val_accuracy: 0.1765\n",
      "Epoch 816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.4332 - accuracy: 0.0000e+00 - val_loss: 85.3795 - val_accuracy: 0.1176\n",
      "Epoch 817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.2466 - accuracy: 0.0000e+00 - val_loss: 84.8018 - val_accuracy: 0.1176\n",
      "Epoch 818/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.5619 - accuracy: 0.0000e+00 - val_loss: 89.0814 - val_accuracy: 0.1765\n",
      "Epoch 819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1732 - accuracy: 0.0000e+00 - val_loss: 91.4699 - val_accuracy: 0.1176\n",
      "Epoch 820/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.6870 - accuracy: 0.0156 - val_loss: 91.6378 - val_accuracy: 0.0588\n",
      "Epoch 821/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.8919 - accuracy: 0.0000e+00 - val_loss: 93.1513 - val_accuracy: 0.0588\n",
      "Epoch 822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0094 - accuracy: 0.0156 - val_loss: 93.3946 - val_accuracy: 0.0588\n",
      "Epoch 823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4051 - accuracy: 0.0000e+00 - val_loss: 83.2904 - val_accuracy: 0.0588\n",
      "Epoch 824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.6268 - accuracy: 0.0000e+00 - val_loss: 80.0274 - val_accuracy: 0.0588\n",
      "Epoch 825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.0817 - accuracy: 0.0000e+00 - val_loss: 86.7435 - val_accuracy: 0.0588\n",
      "Epoch 826/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4557 - accuracy: 0.0000e+00 - val_loss: 90.5825 - val_accuracy: 0.0588\n",
      "Epoch 827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.8710 - accuracy: 0.0000e+00 - val_loss: 90.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.6467 - accuracy: 0.0000e+00 - val_loss: 84.2341 - val_accuracy: 0.0000e+00\n",
      "Epoch 829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.8184 - accuracy: 0.0000e+00 - val_loss: 76.7980 - val_accuracy: 0.0000e+00\n",
      "Epoch 830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.1670 - accuracy: 0.0000e+00 - val_loss: 86.8648 - val_accuracy: 0.0588\n",
      "Epoch 831/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 73.4621 - accuracy: 0.0000e+00 - val_loss: 90.9164 - val_accuracy: 0.0588\n",
      "Epoch 832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.0717 - accuracy: 0.0000e+00 - val_loss: 95.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.7205 - accuracy: 0.0000e+00 - val_loss: 91.8247 - val_accuracy: 0.1176\n",
      "Epoch 834/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.0587 - accuracy: 0.0000e+00 - val_loss: 88.9863 - val_accuracy: 0.0588\n",
      "Epoch 835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.0514 - accuracy: 0.0000e+00 - val_loss: 86.3305 - val_accuracy: 0.1176\n",
      "Epoch 836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.2940 - accuracy: 0.0156 - val_loss: 82.9861 - val_accuracy: 0.1176\n",
      "Epoch 837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.0861 - accuracy: 0.0000e+00 - val_loss: 79.9324 - val_accuracy: 0.1176\n",
      "Epoch 838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.1655 - accuracy: 0.0000e+00 - val_loss: 85.5624 - val_accuracy: 0.1176\n",
      "Epoch 839/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.7568 - accuracy: 0.0000e+00 - val_loss: 83.7519 - val_accuracy: 0.1176\n",
      "Epoch 840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3978 - accuracy: 0.0000e+00 - val_loss: 85.1310 - val_accuracy: 0.0588\n",
      "Epoch 841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.3349 - accuracy: 0.0000e+00 - val_loss: 84.5499 - val_accuracy: 0.0588\n",
      "Epoch 842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1846 - accuracy: 0.0000e+00 - val_loss: 86.7856 - val_accuracy: 0.0588\n",
      "Epoch 843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.3543 - accuracy: 0.0000e+00 - val_loss: 89.5784 - val_accuracy: 0.0588\n",
      "Epoch 844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.5390 - accuracy: 0.0000e+00 - val_loss: 94.4958 - val_accuracy: 0.0000e+00\n",
      "Epoch 845/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.9468 - accuracy: 0.0000e+00 - val_loss: 92.0399 - val_accuracy: 0.0588\n",
      "Epoch 846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5617 - accuracy: 0.0000e+00 - val_loss: 91.8799 - val_accuracy: 0.0588\n",
      "Epoch 847/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.8054 - accuracy: 0.0000e+00 - val_loss: 80.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.5538 - accuracy: 0.0000e+00 - val_loss: 77.4521 - val_accuracy: 0.0588\n",
      "Epoch 849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.8181 - accuracy: 0.0156 - val_loss: 78.1883 - val_accuracy: 0.0588\n",
      "Epoch 850/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 80.1158 - accuracy: 0.0000e+00 - val_loss: 84.6025 - val_accuracy: 0.0588\n",
      "Epoch 851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.5221 - accuracy: 0.0156 - val_loss: 88.0957 - val_accuracy: 0.0000e+00\n",
      "Epoch 852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.5074 - accuracy: 0.0000e+00 - val_loss: 81.4488 - val_accuracy: 0.0588\n",
      "Epoch 853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.5569 - accuracy: 0.0156 - val_loss: 79.4939 - val_accuracy: 0.0588\n",
      "Epoch 854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.3377 - accuracy: 0.0156 - val_loss: 83.9310 - val_accuracy: 0.0588\n",
      "Epoch 855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.4085 - accuracy: 0.0156 - val_loss: 94.5130 - val_accuracy: 0.0000e+00\n",
      "Epoch 856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.0055 - accuracy: 0.0000e+00 - val_loss: 100.0572 - val_accuracy: 0.0000e+00\n",
      "Epoch 857/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.3406 - accuracy: 0.0000e+00 - val_loss: 88.5858 - val_accuracy: 0.0588\n",
      "Epoch 858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.6327 - accuracy: 0.0000e+00 - val_loss: 80.4594 - val_accuracy: 0.1176\n",
      "Epoch 859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8318 - accuracy: 0.0156 - val_loss: 87.2023 - val_accuracy: 0.1176\n",
      "Epoch 860/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 82.1227 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 89.3502 - accuracy: 0.0156 - val_loss: 87.5084 - val_accuracy: 0.1176\n",
      "Epoch 861/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.6373 - accuracy: 0.0000e+00 - val_loss: 92.7201 - val_accuracy: 0.0588\n",
      "Epoch 862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.3614 - accuracy: 0.0000e+00 - val_loss: 96.3895 - val_accuracy: 0.0588\n",
      "Epoch 863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6056 - accuracy: 0.0000e+00 - val_loss: 100.2838 - val_accuracy: 0.0588\n",
      "Epoch 864/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.8179 - accuracy: 0.0156 - val_loss: 95.6579 - val_accuracy: 0.0588\n",
      "Epoch 865/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 84.6090 - accuracy: 0.0156 - val_loss: 92.9063 - val_accuracy: 0.0588\n",
      "Epoch 866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.6285 - accuracy: 0.0000e+00 - val_loss: 94.9568 - val_accuracy: 0.0000e+00\n",
      "Epoch 867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.1345 - accuracy: 0.0156 - val_loss: 87.5289 - val_accuracy: 0.0588\n",
      "Epoch 868/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 44.9557 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 47.2785 - accuracy: 0.0000e+00 - val_loss: 87.0650 - val_accuracy: 0.0588\n",
      "Epoch 869/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2256 - accuracy: 0.0000e+00 - val_loss: 88.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8442 - accuracy: 0.0312 - val_loss: 86.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 871/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 81.4284 - accuracy: 0.0000e+00 - val_loss: 85.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 872/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.0068 - accuracy: 0.0000e+00 - val_loss: 82.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.2571 - accuracy: 0.0000e+00 - val_loss: 83.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.5500 - accuracy: 0.0000e+00 - val_loss: 88.3376 - val_accuracy: 0.0000e+00\n",
      "Epoch 875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.2110 - accuracy: 0.0000e+00 - val_loss: 95.0949 - val_accuracy: 0.0000e+00\n",
      "Epoch 876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 96.2929 - accuracy: 0.0000e+00 - val_loss: 96.8149 - val_accuracy: 0.0000e+00\n",
      "Epoch 877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2454 - accuracy: 0.0000e+00 - val_loss: 85.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6613 - accuracy: 0.0000e+00 - val_loss: 80.6890 - val_accuracy: 0.0588\n",
      "Epoch 879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2780 - accuracy: 0.0000e+00 - val_loss: 82.3463 - val_accuracy: 0.0588\n",
      "Epoch 880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.2194 - accuracy: 0.0000e+00 - val_loss: 95.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.4523 - accuracy: 0.0000e+00 - val_loss: 104.3852 - val_accuracy: 0.0588\n",
      "Epoch 882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.4128 - accuracy: 0.0156 - val_loss: 100.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0775 - accuracy: 0.0000e+00 - val_loss: 87.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.2817 - accuracy: 0.0000e+00 - val_loss: 75.8984 - val_accuracy: 0.0588\n",
      "Epoch 885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 89.6020 - accuracy: 0.0156 - val_loss: 73.8895 - val_accuracy: 0.0588\n",
      "Epoch 886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0770 - accuracy: 0.0156 - val_loss: 86.4130 - val_accuracy: 0.0000e+00\n",
      "Epoch 887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2483 - accuracy: 0.0000e+00 - val_loss: 99.5286 - val_accuracy: 0.0000e+00\n",
      "Epoch 888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.1833 - accuracy: 0.0000e+00 - val_loss: 114.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 889/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 88.7496 - accuracy: 0.0156 - val_loss: 108.8455 - val_accuracy: 0.0000e+00\n",
      "Epoch 890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.6605 - accuracy: 0.0000e+00 - val_loss: 92.9935 - val_accuracy: 0.0588\n",
      "Epoch 891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.9112 - accuracy: 0.0000e+00 - val_loss: 77.0519 - val_accuracy: 0.0588\n",
      "Epoch 892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9150 - accuracy: 0.0156 - val_loss: 72.5828 - val_accuracy: 0.0588\n",
      "Epoch 893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 95.5936 - accuracy: 0.0000e+00 - val_loss: 79.7125 - val_accuracy: 0.1176\n",
      "Epoch 894/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 95.3224 - accuracy: 0.0156 - val_loss: 97.3790 - val_accuracy: 0.1176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.4736 - accuracy: 0.0000e+00 - val_loss: 101.3205 - val_accuracy: 0.0588\n",
      "Epoch 896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6090 - accuracy: 0.0000e+00 - val_loss: 102.1066 - val_accuracy: 0.0588\n",
      "Epoch 897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.9414 - accuracy: 0.0000e+00 - val_loss: 96.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 898/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 63.8522 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 69.6823 - accuracy: 0.0156 - val_loss: 93.3850 - val_accuracy: 0.0588\n",
      "Epoch 899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.4828 - accuracy: 0.0156 - val_loss: 93.6793 - val_accuracy: 0.0588\n",
      "Epoch 900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.4256 - accuracy: 0.0156 - val_loss: 103.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3023 - accuracy: 0.0000e+00 - val_loss: 104.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 902/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 66.2685 - accuracy: 0.0000e+00 - val_loss: 94.1982 - val_accuracy: 0.0000e+00\n",
      "Epoch 903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.7138 - accuracy: 0.0000e+00 - val_loss: 80.5755 - val_accuracy: 0.0588\n",
      "Epoch 904/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3592 - accuracy: 0.0000e+00 - val_loss: 82.1249 - val_accuracy: 0.0588\n",
      "Epoch 905/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.1127 - accuracy: 0.0312 - val_loss: 90.2459 - val_accuracy: 0.0000e+00\n",
      "Epoch 906/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 79.5332 - accuracy: 0.0000e+00 - val_loss: 96.6507 - val_accuracy: 0.0588\n",
      "Epoch 907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.3719 - accuracy: 0.0000e+00 - val_loss: 105.5345 - val_accuracy: 0.0000e+00\n",
      "Epoch 908/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2985 - accuracy: 0.0000e+00 - val_loss: 96.2249 - val_accuracy: 0.0588\n",
      "Epoch 909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4047 - accuracy: 0.0312 - val_loss: 83.9757 - val_accuracy: 0.0000e+00\n",
      "Epoch 910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 86.1566 - accuracy: 0.0000e+00 - val_loss: 83.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 911/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.3866 - accuracy: 0.0156 - val_loss: 84.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6846 - accuracy: 0.0000e+00 - val_loss: 91.4477 - val_accuracy: 0.0588\n",
      "Epoch 913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.3639 - accuracy: 0.0000e+00 - val_loss: 98.2272 - val_accuracy: 0.0000e+00\n",
      "Epoch 914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.7291 - accuracy: 0.0156 - val_loss: 89.2545 - val_accuracy: 0.0588\n",
      "Epoch 915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.1226 - accuracy: 0.0000e+00 - val_loss: 81.4773 - val_accuracy: 0.0000e+00\n",
      "Epoch 916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9419 - accuracy: 0.0000e+00 - val_loss: 80.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 917/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.5814 - accuracy: 0.0156 - val_loss: 81.7089 - val_accuracy: 0.0000e+00\n",
      "Epoch 918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.4346 - accuracy: 0.0000e+00 - val_loss: 81.0080 - val_accuracy: 0.0000e+00\n",
      "Epoch 919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8254 - accuracy: 0.0000e+00 - val_loss: 79.3895 - val_accuracy: 0.0588\n",
      "Epoch 920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1363 - accuracy: 0.0000e+00 - val_loss: 91.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.4051 - accuracy: 0.0156 - val_loss: 114.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6102 - accuracy: 0.0000e+00 - val_loss: 105.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 923/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0832 - accuracy: 0.0156 - val_loss: 83.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 924/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 77.7987 - accuracy: 0.0000e+00 - val_loss: 67.5980 - val_accuracy: 0.0000e+00\n",
      "Epoch 925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.3503 - accuracy: 0.0000e+00 - val_loss: 68.5851 - val_accuracy: 0.0588\n",
      "Epoch 926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.0057 - accuracy: 0.0000e+00 - val_loss: 82.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5922 - accuracy: 0.0000e+00 - val_loss: 94.1409 - val_accuracy: 0.0588\n",
      "Epoch 928/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 86.4203 - accuracy: 0.0000e+00 - val_loss: 101.1979 - val_accuracy: 0.0000e+00\n",
      "Epoch 929/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3386 - accuracy: 0.0000e+00 - val_loss: 93.4578 - val_accuracy: 0.0588\n",
      "Epoch 930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0175 - accuracy: 0.0000e+00 - val_loss: 79.2957 - val_accuracy: 0.0000e+00\n",
      "Epoch 931/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 67.8730 - accuracy: 0.0000e+00 - val_loss: 72.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 932/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.5883 - accuracy: 0.0000e+00 - val_loss: 81.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 933/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 67.8132 - accuracy: 0.0000e+00 - val_loss: 99.9030 - val_accuracy: 0.0588\n",
      "Epoch 934/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1214 - accuracy: 0.0000e+00 - val_loss: 112.2575 - val_accuracy: 0.0000e+00\n",
      "Epoch 935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9721 - accuracy: 0.0156 - val_loss: 105.7000 - val_accuracy: 0.0000e+00\n",
      "Epoch 936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.1123 - accuracy: 0.0156 - val_loss: 89.5496 - val_accuracy: 0.0588\n",
      "Epoch 937/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1643 - accuracy: 0.0000e+00 - val_loss: 78.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1097 - accuracy: 0.0156 - val_loss: 77.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.1734 - accuracy: 0.0000e+00 - val_loss: 84.6068 - val_accuracy: 0.0588\n",
      "Epoch 940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.5788 - accuracy: 0.0000e+00 - val_loss: 104.9441 - val_accuracy: 0.0000e+00\n",
      "Epoch 941/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 71.9351 - accuracy: 0.0156 - val_loss: 122.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5520 - accuracy: 0.0156 - val_loss: 117.2512 - val_accuracy: 0.0000e+00\n",
      "Epoch 943/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 73.2604 - accuracy: 0.0000e+00 - val_loss: 93.4369 - val_accuracy: 0.0588\n",
      "Epoch 944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5391 - accuracy: 0.0312 - val_loss: 77.0645 - val_accuracy: 0.0588\n",
      "Epoch 945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.6660 - accuracy: 0.0000e+00 - val_loss: 78.7231 - val_accuracy: 0.1176\n",
      "Epoch 946/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1650 - accuracy: 0.0000e+00 - val_loss: 83.8958 - val_accuracy: 0.0588\n",
      "Epoch 947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9674 - accuracy: 0.0156 - val_loss: 86.1006 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9111 - accuracy: 0.0156 - val_loss: 87.7073 - val_accuracy: 0.0000e+00\n",
      "Epoch 949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.5041 - accuracy: 0.0000e+00 - val_loss: 88.7067 - val_accuracy: 0.0000e+00\n",
      "Epoch 950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.8038 - accuracy: 0.0000e+00 - val_loss: 82.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2303 - accuracy: 0.0156 - val_loss: 80.1552 - val_accuracy: 0.0000e+00\n",
      "Epoch 952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 102.3356 - accuracy: 0.0000e+00 - val_loss: 85.8737 - val_accuracy: 0.0000e+00\n",
      "Epoch 953/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.3994 - accuracy: 0.0000e+00 - val_loss: 93.2180 - val_accuracy: 0.0588\n",
      "Epoch 954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2366 - accuracy: 0.0000e+00 - val_loss: 105.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 955/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.3987 - accuracy: 0.0000e+00 - val_loss: 102.8030 - val_accuracy: 0.0588\n",
      "Epoch 956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4611 - accuracy: 0.0000e+00 - val_loss: 97.7804 - val_accuracy: 0.0000e+00\n",
      "Epoch 957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.7176 - accuracy: 0.0000e+00 - val_loss: 83.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1975 - accuracy: 0.0000e+00 - val_loss: 81.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1000 - accuracy: 0.0000e+00 - val_loss: 77.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 960/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 75.1823 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 76.5193 - accuracy: 0.0000e+00 - val_loss: 80.8827 - val_accuracy: 0.0588\n",
      "Epoch 961/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 78.6519 - accuracy: 0.0000e+00 - val_loss: 92.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1171 - accuracy: 0.0000e+00 - val_loss: 100.1735 - val_accuracy: 0.0000e+00\n",
      "Epoch 963/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.5042 - accuracy: 0.0156 - val_loss: 98.7376 - val_accuracy: 0.0000e+00\n",
      "Epoch 964/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 82.8804 - accuracy: 0.031 - 0s 125us/step - loss: 81.1840 - accuracy: 0.0156 - val_loss: 91.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3417 - accuracy: 0.0156 - val_loss: 84.0604 - val_accuracy: 0.0000e+00\n",
      "Epoch 966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6045 - accuracy: 0.0000e+00 - val_loss: 89.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.6234 - accuracy: 0.0000e+00 - val_loss: 92.9058 - val_accuracy: 0.0000e+00\n",
      "Epoch 968/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.0601 - accuracy: 0.0000e+00 - val_loss: 93.2249 - val_accuracy: 0.0588\n",
      "Epoch 969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4282 - accuracy: 0.0000e+00 - val_loss: 89.1497 - val_accuracy: 0.0588\n",
      "Epoch 970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.9088 - accuracy: 0.0000e+00 - val_loss: 85.8226 - val_accuracy: 0.0588\n",
      "Epoch 971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.6018 - accuracy: 0.0000e+00 - val_loss: 88.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.7495 - accuracy: 0.0156 - val_loss: 90.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.8882 - accuracy: 0.0000e+00 - val_loss: 95.3423 - val_accuracy: 0.0000e+00\n",
      "Epoch 974/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.2697 - accuracy: 0.0156 - val_loss: 89.8899 - val_accuracy: 0.0000e+00\n",
      "Epoch 975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.6938 - accuracy: 0.0156 - val_loss: 77.9684 - val_accuracy: 0.0000e+00\n",
      "Epoch 976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.0582 - accuracy: 0.0000e+00 - val_loss: 74.8569 - val_accuracy: 0.0000e+00\n",
      "Epoch 977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.6538 - accuracy: 0.0000e+00 - val_loss: 77.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.8527 - accuracy: 0.0000e+00 - val_loss: 92.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.0206 - accuracy: 0.0000e+00 - val_loss: 105.9875 - val_accuracy: 0.0000e+00\n",
      "Epoch 980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.1946 - accuracy: 0.0000e+00 - val_loss: 101.4173 - val_accuracy: 0.0000e+00\n",
      "Epoch 981/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.7815 - accuracy: 0.0000e+00 - val_loss: 88.6355 - val_accuracy: 0.0588\n",
      "Epoch 982/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 71.4843 - accuracy: 0.031 - 0s 62us/step - loss: 77.8650 - accuracy: 0.0156 - val_loss: 82.5395 - val_accuracy: 0.0000e+00\n",
      "Epoch 983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0838 - accuracy: 0.0000e+00 - val_loss: 82.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.0161 - accuracy: 0.0156 - val_loss: 78.9983 - val_accuracy: 0.0000e+00\n",
      "Epoch 985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.8333 - accuracy: 0.0000e+00 - val_loss: 83.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 986/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.9849 - accuracy: 0.0000e+00 - val_loss: 90.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.7329 - accuracy: 0.0156 - val_loss: 96.1451 - val_accuracy: 0.0588\n",
      "Epoch 988/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1080 - accuracy: 0.0156 - val_loss: 98.0006 - val_accuracy: 0.0000e+00\n",
      "Epoch 989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9474 - accuracy: 0.0000e+00 - val_loss: 85.4630 - val_accuracy: 0.0000e+00\n",
      "Epoch 990/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1385 - accuracy: 0.0312 - val_loss: 78.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9166 - accuracy: 0.0000e+00 - val_loss: 79.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.1978 - accuracy: 0.0000e+00 - val_loss: 87.0693 - val_accuracy: 0.0588\n",
      "Epoch 993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7439 - accuracy: 0.0000e+00 - val_loss: 95.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 994/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 57.0394 - accuracy: 0.0156 - val_loss: 92.8347 - val_accuracy: 0.0000e+00\n",
      "Epoch 995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.4622 - accuracy: 0.0312 - val_loss: 87.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 996/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 98.6950 - accuracy: 0.0000e+00 - val_loss: 83.7799 - val_accuracy: 0.0000e+00\n",
      "Epoch 997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5723 - accuracy: 0.0312 - val_loss: 82.3330 - val_accuracy: 0.0588\n",
      "Epoch 998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4080 - accuracy: 0.0156 - val_loss: 80.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 90.3337 - accuracy: 0.0000e+00 - val_loss: 87.9402 - val_accuracy: 0.0588\n",
      "Epoch 1000/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 65.6156 - accuracy: 0.0000e+00 - val_loss: 100.7752 - val_accuracy: 0.0000e+00\n",
      "Epoch 1001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5239 - accuracy: 0.0000e+00 - val_loss: 100.6943 - val_accuracy: 0.0000e+00\n",
      "Epoch 1002/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.4076 - accuracy: 0.0156 - val_loss: 93.5009 - val_accuracy: 0.0588\n",
      "Epoch 1003/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 66.8657 - accuracy: 0.0156 - val_loss: 85.8623 - val_accuracy: 0.1176\n",
      "Epoch 1004/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 74.0227 - accuracy: 0.0000e+00 - val_loss: 80.6392 - val_accuracy: 0.0588\n",
      "Epoch 1005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9887 - accuracy: 0.0000e+00 - val_loss: 82.9192 - val_accuracy: 0.0588\n",
      "Epoch 1006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.8243 - accuracy: 0.0000e+00 - val_loss: 85.8060 - val_accuracy: 0.0588\n",
      "Epoch 1007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.5013 - accuracy: 0.0156 - val_loss: 82.5570 - val_accuracy: 0.0588\n",
      "Epoch 1008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.9051 - accuracy: 0.0000e+00 - val_loss: 82.3891 - val_accuracy: 0.0588\n",
      "Epoch 1009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4062 - accuracy: 0.0000e+00 - val_loss: 87.1666 - val_accuracy: 0.0588\n",
      "Epoch 1010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8547 - accuracy: 0.0000e+00 - val_loss: 90.7114 - val_accuracy: 0.0588\n",
      "Epoch 1011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1179 - accuracy: 0.0000e+00 - val_loss: 99.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8362 - accuracy: 0.0312 - val_loss: 102.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 1013/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2542 - accuracy: 0.0000e+00 - val_loss: 90.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 1014/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.1750 - accuracy: 0.0000e+00 - val_loss: 82.4478 - val_accuracy: 0.0000e+00\n",
      "Epoch 1015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.2919 - accuracy: 0.0000e+00 - val_loss: 82.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 1016/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 76.2924 - accuracy: 0.0000e+00 - val_loss: 86.1506 - val_accuracy: 0.0000e+00\n",
      "Epoch 1017/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.4001 - accuracy: 0.0156 - val_loss: 95.3649 - val_accuracy: 0.0000e+00\n",
      "Epoch 1018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6365 - accuracy: 0.0156 - val_loss: 100.6124 - val_accuracy: 0.0588\n",
      "Epoch 1019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2087 - accuracy: 0.0156 - val_loss: 94.3970 - val_accuracy: 0.0588\n",
      "Epoch 1020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2596 - accuracy: 0.0000e+00 - val_loss: 94.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 1021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.8462 - accuracy: 0.0156 - val_loss: 107.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 1022/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 59.6731 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 65.3695 - accuracy: 0.0000e+00 - val_loss: 109.4882 - val_accuracy: 0.0000e+00\n",
      "Epoch 1023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.6312 - accuracy: 0.0000e+00 - val_loss: 89.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 1024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5436 - accuracy: 0.0000e+00 - val_loss: 70.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1025/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 100.1283 - accuracy: 0.0156 - val_loss: 63.8952 - val_accuracy: 0.0000e+00\n",
      "Epoch 1026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4710 - accuracy: 0.0000e+00 - val_loss: 74.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 1027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5183 - accuracy: 0.0000e+00 - val_loss: 83.5394 - val_accuracy: 0.0588\n",
      "Epoch 1028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0907 - accuracy: 0.0000e+00 - val_loss: 87.5618 - val_accuracy: 0.0588\n",
      "Epoch 1029/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 84.3355 - accuracy: 0.0156 - val_loss: 90.2681 - val_accuracy: 0.0588\n",
      "Epoch 1030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7685 - accuracy: 0.0156 - val_loss: 102.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 1031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3626 - accuracy: 0.0312 - val_loss: 100.8685 - val_accuracy: 0.0588\n",
      "Epoch 1032/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.2588 - accuracy: 0.0000e+00 - val_loss: 87.5646 - val_accuracy: 0.0000e+00\n",
      "Epoch 1033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1427 - accuracy: 0.0000e+00 - val_loss: 80.0413 - val_accuracy: 0.0000e+00\n",
      "Epoch 1034/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2330 - accuracy: 0.0000e+00 - val_loss: 79.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 1035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.9345 - accuracy: 0.0000e+00 - val_loss: 86.3291 - val_accuracy: 0.0588\n",
      "Epoch 1036/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 92.8562 - accuracy: 0.0156 - val_loss: 101.2233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5946 - accuracy: 0.0000e+00 - val_loss: 112.8692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1038/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.5670 - accuracy: 0.0156 - val_loss: 96.7604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1039/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.9202 - accuracy: 0.0000e+00 - val_loss: 80.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.9818 - accuracy: 0.0156 - val_loss: 74.7255 - val_accuracy: 0.0000e+00\n",
      "Epoch 1041/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.3374 - accuracy: 0.0000e+00 - val_loss: 79.2295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1042/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 84.1559 - accuracy: 0.0000e+00 - val_loss: 91.9469 - val_accuracy: 0.0588\n",
      "Epoch 1043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.0239 - accuracy: 0.0156 - val_loss: 94.1342 - val_accuracy: 0.0588\n",
      "Epoch 1044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9802 - accuracy: 0.0000e+00 - val_loss: 92.0782 - val_accuracy: 0.0000e+00\n",
      "Epoch 1045/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.4952 - accuracy: 0.0156 - val_loss: 90.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 1046/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.9654 - accuracy: 0.0000e+00 - val_loss: 89.9849 - val_accuracy: 0.0000e+00\n",
      "Epoch 1047/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 94.2939 - accuracy: 0.0156 - val_loss: 93.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.8518 - accuracy: 0.0000e+00 - val_loss: 96.1182 - val_accuracy: 0.0000e+00\n",
      "Epoch 1049/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.0183 - accuracy: 0.0156 - val_loss: 94.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5713 - accuracy: 0.0000e+00 - val_loss: 91.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 1051/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.0669 - accuracy: 0.0000e+00 - val_loss: 85.2692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1052/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1572 - accuracy: 0.0000e+00 - val_loss: 81.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1053/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 66.2027 - accuracy: 0.0000e+00 - val_loss: 85.9873 - val_accuracy: 0.0000e+00\n",
      "Epoch 1054/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.4064 - accuracy: 0.0000e+00 - val_loss: 85.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 1055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1717 - accuracy: 0.0000e+00 - val_loss: 90.2604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6087 - accuracy: 0.0000e+00 - val_loss: 90.6523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8239 - accuracy: 0.0000e+00 - val_loss: 89.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1058/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0815 - accuracy: 0.0000e+00 - val_loss: 88.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 1059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5294 - accuracy: 0.0156 - val_loss: 88.2977 - val_accuracy: 0.0000e+00\n",
      "Epoch 1060/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9627 - accuracy: 0.0312 - val_loss: 87.3076 - val_accuracy: 0.0000e+00\n",
      "Epoch 1061/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1535 - accuracy: 0.0000e+00 - val_loss: 85.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 1062/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.5267 - accuracy: 0.0000e+00 - val_loss: 87.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1063/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.1130 - accuracy: 0.0156 - val_loss: 98.6041 - val_accuracy: 0.0588\n",
      "Epoch 1064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.9937 - accuracy: 0.0000e+00 - val_loss: 106.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 78.3581 - accuracy: 0.0000e+00 - val_loss: 100.5658 - val_accuracy: 0.0588\n",
      "Epoch 1066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4097 - accuracy: 0.0000e+00 - val_loss: 85.2509 - val_accuracy: 0.0000e+00\n",
      "Epoch 1067/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.8117 - accuracy: 0.0000e+00 - val_loss: 77.6864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5491 - accuracy: 0.0312 - val_loss: 75.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 1069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.3538 - accuracy: 0.0000e+00 - val_loss: 78.5375 - val_accuracy: 0.0000e+00\n",
      "Epoch 1070/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.8788 - accuracy: 0.0000e+00 - val_loss: 95.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1071/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.6539 - accuracy: 0.0000e+00 - val_loss: 112.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 1072/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.7576 - accuracy: 0.0000e+00 - val_loss: 119.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 1073/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 60.3864 - accuracy: 0.0000e+00 - val_loss: 107.6472 - val_accuracy: 0.0000e+00\n",
      "Epoch 1074/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 62.2661 - accuracy: 0.0156 - val_loss: 85.0251 - val_accuracy: 0.0000e+00\n",
      "Epoch 1075/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 71.0541 - accuracy: 0.0000e+00 - val_loss: 72.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 1076/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1974 - accuracy: 0.0000e+00 - val_loss: 73.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 1077/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.3829 - accuracy: 0.0156 - val_loss: 86.7285 - val_accuracy: 0.0000e+00\n",
      "Epoch 1078/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 66.9338 - accuracy: 0.0000e+00 - val_loss: 108.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 1079/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.6816 - accuracy: 0.0000e+00 - val_loss: 121.3207 - val_accuracy: 0.0000e+00\n",
      "Epoch 1080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.0281 - accuracy: 0.0000e+00 - val_loss: 104.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 1081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4451 - accuracy: 0.0000e+00 - val_loss: 77.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.9042 - accuracy: 0.0000e+00 - val_loss: 71.7720 - val_accuracy: 0.0000e+00\n",
      "Epoch 1083/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2032 - accuracy: 0.0312 - val_loss: 78.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 1084/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9112 - accuracy: 0.0000e+00 - val_loss: 85.4648 - val_accuracy: 0.0588\n",
      "Epoch 1085/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1236 - accuracy: 0.0000e+00 - val_loss: 96.5067 - val_accuracy: 0.0000e+00\n",
      "Epoch 1086/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.9646 - accuracy: 0.0000e+00 - val_loss: 103.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1087/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.8245 - accuracy: 0.0000e+00 - val_loss: 108.5532 - val_accuracy: 0.0000e+00\n",
      "Epoch 1088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.1689 - accuracy: 0.0000e+00 - val_loss: 98.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 1089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 93.2849 - accuracy: 0.0000e+00 - val_loss: 83.3889 - val_accuracy: 0.0588\n",
      "Epoch 1090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2370 - accuracy: 0.0000e+00 - val_loss: 74.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 1091/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.1316 - accuracy: 0.0156 - val_loss: 68.5488 - val_accuracy: 0.1176\n",
      "Epoch 1092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 87.7290 - accuracy: 0.0156 - val_loss: 70.3176 - val_accuracy: 0.1176\n",
      "Epoch 1093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4886 - accuracy: 0.0000e+00 - val_loss: 85.2199 - val_accuracy: 0.1176\n",
      "Epoch 1094/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2127 - accuracy: 0.0000e+00 - val_loss: 96.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 1095/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.3344 - accuracy: 0.0000e+00 - val_loss: 108.3552 - val_accuracy: 0.0000e+00\n",
      "Epoch 1096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5753 - accuracy: 0.0156 - val_loss: 105.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1097/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.5561 - accuracy: 0.0000e+00 - val_loss: 90.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 1098/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 64.2873 - accuracy: 0.0156 - val_loss: 82.2106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5454 - accuracy: 0.0312 - val_loss: 86.7379 - val_accuracy: 0.0588\n",
      "Epoch 1100/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.2974 - accuracy: 0.0000e+00 - val_loss: 96.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1101/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2117 - accuracy: 0.0000e+00 - val_loss: 102.6108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1102/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 69.8407 - accuracy: 0.0000e+00 - val_loss: 96.8002 - val_accuracy: 0.0000e+00\n",
      "Epoch 1103/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 72.8921 - accuracy: 0.0000e+00 - val_loss: 87.2866 - val_accuracy: 0.0000e+00\n",
      "Epoch 1104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 250us/step - loss: 56.1983 - accuracy: 0.0000e+00 - val_loss: 76.5265 - val_accuracy: 0.0588\n",
      "Epoch 1105/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 70.7474 - accuracy: 0.0000e+00 - val_loss: 85.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.6978 - accuracy: 0.0000e+00 - val_loss: 100.1880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.0665 - accuracy: 0.0000e+00 - val_loss: 110.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9461 - accuracy: 0.0000e+00 - val_loss: 109.9486 - val_accuracy: 0.0588\n",
      "Epoch 1109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.2923 - accuracy: 0.0156 - val_loss: 94.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 1110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.8911 - accuracy: 0.0000e+00 - val_loss: 77.2018 - val_accuracy: 0.0000e+00\n",
      "Epoch 1111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.6002 - accuracy: 0.0156 - val_loss: 76.0614 - val_accuracy: 0.0000e+00\n",
      "Epoch 1112/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 104.7560 - accuracy: 0.0000e+00 - val_loss: 85.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 1113/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.6427 - accuracy: 0.0000e+00 - val_loss: 100.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 1114/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0337 - accuracy: 0.0000e+00 - val_loss: 99.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1115/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.8245 - accuracy: 0.0156 - val_loss: 85.6658 - val_accuracy: 0.0000e+00\n",
      "Epoch 1116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.3536 - accuracy: 0.0156 - val_loss: 79.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 1117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1836 - accuracy: 0.0000e+00 - val_loss: 76.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.5765 - accuracy: 0.0000e+00 - val_loss: 83.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1200 - accuracy: 0.0156 - val_loss: 93.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 1120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.3826 - accuracy: 0.0000e+00 - val_loss: 93.0888 - val_accuracy: 0.0000e+00\n",
      "Epoch 1121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 83.3431 - accuracy: 0.0000e+00 - val_loss: 83.8526 - val_accuracy: 0.0000e+00\n",
      "Epoch 1122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8600 - accuracy: 0.0000e+00 - val_loss: 83.1854 - val_accuracy: 0.0000e+00\n",
      "Epoch 1123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6572 - accuracy: 0.0156 - val_loss: 92.2014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1124/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 65.3429 - accuracy: 0.0156 - val_loss: 101.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1125/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3779 - accuracy: 0.0000e+00 - val_loss: 103.6967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.2804 - accuracy: 0.0000e+00 - val_loss: 97.9419 - val_accuracy: 0.0000e+00\n",
      "Epoch 1127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 85.6528 - accuracy: 0.0156 - val_loss: 89.9959 - val_accuracy: 0.0000e+00\n",
      "Epoch 1128/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.6615 - accuracy: 0.0000e+00 - val_loss: 87.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1129/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1509 - accuracy: 0.0312 - val_loss: 77.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 1130/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 57.4943 - accuracy: 0.0000e+00 - val_loss: 74.0234 - val_accuracy: 0.0000e+00\n",
      "Epoch 1131/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6115 - accuracy: 0.0000e+00 - val_loss: 78.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6031 - accuracy: 0.0000e+00 - val_loss: 102.0894 - val_accuracy: 0.0588\n",
      "Epoch 1133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.4597 - accuracy: 0.0000e+00 - val_loss: 116.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 1134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1522 - accuracy: 0.0156 - val_loss: 104.3964 - val_accuracy: 0.0588\n",
      "Epoch 1135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6049 - accuracy: 0.0000e+00 - val_loss: 86.7921 - val_accuracy: 0.0000e+00\n",
      "Epoch 1136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4232 - accuracy: 0.0156 - val_loss: 76.8108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1137/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.1279 - accuracy: 0.0000e+00 - val_loss: 76.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 1138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7120 - accuracy: 0.0000e+00 - val_loss: 90.6188 - val_accuracy: 0.0588\n",
      "Epoch 1139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.9278 - accuracy: 0.0000e+00 - val_loss: 109.3314 - val_accuracy: 0.0000e+00\n",
      "Epoch 1140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.2685 - accuracy: 0.0000e+00 - val_loss: 118.7670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.1789 - accuracy: 0.0156 - val_loss: 114.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8274 - accuracy: 0.0000e+00 - val_loss: 90.4654 - val_accuracy: 0.0588\n",
      "Epoch 1143/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 60.0701 - accuracy: 0.0000e+00 - val_loss: 73.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1144/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 85.0098 - accuracy: 0.0000e+00 - val_loss: 65.3856 - val_accuracy: 0.0000e+00\n",
      "Epoch 1145/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 85.6104 - accuracy: 0.0000e+00 - val_loss: 75.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 1146/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 65.1287 - accuracy: 0.0000e+00 - val_loss: 111.3395 - val_accuracy: 0.0000e+00\n",
      "Epoch 1147/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 75.0300 - accuracy: 0.0000e+00 - val_loss: 130.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 1148/10000\n",
      "64/64 [==============================] - 0s 314us/step - loss: 72.3327 - accuracy: 0.0000e+00 - val_loss: 129.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1149/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 67.7412 - accuracy: 0.0000e+00 - val_loss: 101.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 1150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8440 - accuracy: 0.0000e+00 - val_loss: 73.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 1151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6603 - accuracy: 0.0312 - val_loss: 68.6095 - val_accuracy: 0.0000e+00\n",
      "Epoch 1152/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 77.8444 - accuracy: 0.0156 - val_loss: 79.7994 - val_accuracy: 0.0000e+00\n",
      "Epoch 1153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.2905 - accuracy: 0.0000e+00 - val_loss: 99.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 1154/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 81.9868 - accuracy: 0.0000e+00 - val_loss: 113.6053 - val_accuracy: 0.0000e+00\n",
      "Epoch 1155/10000\n",
      "64/64 [==============================] - 0s 249us/step - loss: 79.9141 - accuracy: 0.0000e+00 - val_loss: 113.1476 - val_accuracy: 0.0000e+00\n",
      "Epoch 1156/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 67.6676 - accuracy: 0.0156 - val_loss: 108.3634 - val_accuracy: 0.0000e+00\n",
      "Epoch 1157/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 62.2024 - accuracy: 0.0000e+00 - val_loss: 101.1818 - val_accuracy: 0.0000e+00\n",
      "Epoch 1158/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 63.8773 - accuracy: 0.0000e+00 - val_loss: 99.4615 - val_accuracy: 0.0588\n",
      "Epoch 1159/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 85.7653 - accuracy: 0.0000e+00 - val_loss: 98.5954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1160/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 58.9090 - accuracy: 0.0000e+00 - val_loss: 106.1740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1161/10000\n",
      "64/64 [==============================] - 0s 293us/step - loss: 72.0423 - accuracy: 0.0000e+00 - val_loss: 113.0543 - val_accuracy: 0.0000e+00\n",
      "Epoch 1162/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 85.8119 - accuracy: 0.0000e+00 - val_loss: 112.8627 - val_accuracy: 0.0000e+00\n",
      "Epoch 1163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.3913 - accuracy: 0.0000e+00 - val_loss: 103.0042 - val_accuracy: 0.0000e+00\n",
      "Epoch 1164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.3075 - accuracy: 0.0000e+00 - val_loss: 90.3734 - val_accuracy: 0.0000e+00\n",
      "Epoch 1165/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.1407 - accuracy: 0.0000e+00 - val_loss: 86.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 1166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 91.7307 - accuracy: 0.0000e+00 - val_loss: 103.9950 - val_accuracy: 0.0000e+00\n",
      "Epoch 1167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6548 - accuracy: 0.0000e+00 - val_loss: 114.0006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.2164 - accuracy: 0.0000e+00 - val_loss: 104.5912 - val_accuracy: 0.0000e+00\n",
      "Epoch 1169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4704 - accuracy: 0.0156 - val_loss: 82.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.3942 - accuracy: 0.0000e+00 - val_loss: 67.5669 - val_accuracy: 0.0000e+00\n",
      "Epoch 1171/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 68.5517 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 84.9446 - accuracy: 0.0000e+00 - val_loss: 66.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 1172/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 65.0749 - accuracy: 0.0156 - val_loss: 79.0672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 78.9879 - accuracy: 0.0312 - val_loss: 103.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 1174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4965 - accuracy: 0.0000e+00 - val_loss: 125.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 1175/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.2013 - accuracy: 0.0000e+00 - val_loss: 118.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 1176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5647 - accuracy: 0.0000e+00 - val_loss: 96.1552 - val_accuracy: 0.0588\n",
      "Epoch 1177/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.3363 - accuracy: 0.0156 - val_loss: 77.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 1178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1433 - accuracy: 0.0000e+00 - val_loss: 76.0850 - val_accuracy: 0.0000e+00\n",
      "Epoch 1179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.2682 - accuracy: 0.0156 - val_loss: 92.5924 - val_accuracy: 0.0000e+00\n",
      "Epoch 1180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.4760 - accuracy: 0.0000e+00 - val_loss: 121.5497 - val_accuracy: 0.0000e+00\n",
      "Epoch 1181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5576 - accuracy: 0.0000e+00 - val_loss: 116.5546 - val_accuracy: 0.0000e+00\n",
      "Epoch 1182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.6901 - accuracy: 0.0000e+00 - val_loss: 88.5926 - val_accuracy: 0.0000e+00\n",
      "Epoch 1183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.0569 - accuracy: 0.0000e+00 - val_loss: 71.2055 - val_accuracy: 0.0000e+00\n",
      "Epoch 1184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.9048 - accuracy: 0.0000e+00 - val_loss: 70.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 1185/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.5900 - accuracy: 0.0000e+00 - val_loss: 87.0996 - val_accuracy: 0.0000e+00\n",
      "Epoch 1186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 62.9155 - accuracy: 0.0156 - val_loss: 94.1659 - val_accuracy: 0.0588\n",
      "Epoch 1187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0007 - accuracy: 0.0156 - val_loss: 101.1917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1188/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 76.6757 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 68.4275 - accuracy: 0.0000e+00 - val_loss: 95.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 1189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.7056 - accuracy: 0.0156 - val_loss: 85.3995 - val_accuracy: 0.0000e+00\n",
      "Epoch 1190/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 66.9395 - accuracy: 0.0000e+00 - val_loss: 72.8280 - val_accuracy: 0.0588\n",
      "Epoch 1191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5767 - accuracy: 0.0312 - val_loss: 61.9557 - val_accuracy: 0.0000e+00\n",
      "Epoch 1192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.8136 - accuracy: 0.0156 - val_loss: 66.5691 - val_accuracy: 0.0588\n",
      "Epoch 1193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9142 - accuracy: 0.0156 - val_loss: 91.7279 - val_accuracy: 0.0000e+00\n",
      "Epoch 1194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.5057 - accuracy: 0.0000e+00 - val_loss: 124.8162 - val_accuracy: 0.0000e+00\n",
      "Epoch 1195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.0506 - accuracy: 0.0000e+00 - val_loss: 110.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 1196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 97.7805 - accuracy: 0.0000e+00 - val_loss: 82.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 1197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 97.4762 - accuracy: 0.0000e+00 - val_loss: 73.5012 - val_accuracy: 0.0588\n",
      "Epoch 1198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.8519 - accuracy: 0.0000e+00 - val_loss: 79.9813 - val_accuracy: 0.0000e+00\n",
      "Epoch 1199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.1850 - accuracy: 0.0000e+00 - val_loss: 96.5314 - val_accuracy: 0.0000e+00\n",
      "Epoch 1200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.2388 - accuracy: 0.0000e+00 - val_loss: 115.4235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.7962 - accuracy: 0.0156 - val_loss: 115.5597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2834 - accuracy: 0.0000e+00 - val_loss: 100.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 1203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 69.7873 - accuracy: 0.0000e+00 - val_loss: 81.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 1204/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.5148 - accuracy: 0.0000e+00 - val_loss: 78.6445 - val_accuracy: 0.0000e+00\n",
      "Epoch 1205/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 74.4536 - accuracy: 0.0000e+00 - val_loss: 79.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 1206/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 72.0411 - accuracy: 0.0000e+00 - val_loss: 81.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 1207/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 63.9601 - accuracy: 0.0000e+00 - val_loss: 90.1776 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1208/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 52.9248 - accuracy: 0.0000e+00 - val_loss: 101.1857 - val_accuracy: 0.0000e+00\n",
      "Epoch 1209/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 62.0300 - accuracy: 0.0000e+00 - val_loss: 104.6606 - val_accuracy: 0.0000e+00\n",
      "Epoch 1210/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 72.1090 - accuracy: 0.0000e+00 - val_loss: 98.4408 - val_accuracy: 0.0000e+00\n",
      "Epoch 1211/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 67.7989 - accuracy: 0.0469 - val_loss: 87.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 1212/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 73.1960 - accuracy: 0.0000e+00 - val_loss: 83.0257 - val_accuracy: 0.0000e+00\n",
      "Epoch 1213/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 52.9470 - accuracy: 0.0000e+00 - val_loss: 90.8031 - val_accuracy: 0.0000e+00\n",
      "Epoch 1214/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 61.7466 - accuracy: 0.0000e+00 - val_loss: 94.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 1215/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 54.4179 - accuracy: 0.0000e+00 - val_loss: 99.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1216/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 55.3773 - accuracy: 0.0156 - val_loss: 97.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1217/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 66.4427 - accuracy: 0.0000e+00 - val_loss: 91.4398 - val_accuracy: 0.0000e+00\n",
      "Epoch 1218/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 42.3595 - accuracy: 0.0000e+00 - val_loss: 85.3438 - val_accuracy: 0.0588\n",
      "Epoch 1219/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 76.5086 - accuracy: 0.0000e+00 - val_loss: 82.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 1220/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 65.0335 - accuracy: 0.0000e+00 - val_loss: 87.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1221/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 51.8629 - accuracy: 0.0156 - val_loss: 92.2534 - val_accuracy: 0.0588\n",
      "Epoch 1222/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 71.3950 - accuracy: 0.0000e+00 - val_loss: 97.0640 - val_accuracy: 0.0588\n",
      "Epoch 1223/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 60.7405 - accuracy: 0.0000e+00 - val_loss: 99.6791 - val_accuracy: 0.0588\n",
      "Epoch 1224/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 48.7190 - accuracy: 0.0000e+00 - val_loss: 99.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1225/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 73.8390 - accuracy: 0.0312 - val_loss: 92.1769 - val_accuracy: 0.0588\n",
      "Epoch 1226/10000\n",
      "64/64 [==============================] - 0s 322us/step - loss: 73.2397 - accuracy: 0.0156 - val_loss: 80.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4476 - accuracy: 0.0000e+00 - val_loss: 73.0954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1228/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.4705 - accuracy: 0.0000e+00 - val_loss: 72.0284 - val_accuracy: 0.0000e+00\n",
      "Epoch 1229/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 75.2171 - accuracy: 0.0156 - val_loss: 88.8231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1230/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 82.6309 - accuracy: 0.0000e+00 - val_loss: 107.9852 - val_accuracy: 0.0000e+00\n",
      "Epoch 1231/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 55.1576 - accuracy: 0.0000e+00 - val_loss: 112.5847 - val_accuracy: 0.0000e+00\n",
      "Epoch 1232/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 56.1247 - accuracy: 0.0000e+00 - val_loss: 98.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 1233/10000\n",
      "64/64 [==============================] - 0s 252us/step - loss: 75.5129 - accuracy: 0.0156 - val_loss: 81.6608 - val_accuracy: 0.0000e+00\n",
      "Epoch 1234/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 73.4752 - accuracy: 0.0000e+00 - val_loss: 77.0491 - val_accuracy: 0.0000e+00\n",
      "Epoch 1235/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 84.0485 - accuracy: 0.0000e+00 - val_loss: 97.3618 - val_accuracy: 0.0588\n",
      "Epoch 1236/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 60.8554 - accuracy: 0.0000e+00 - val_loss: 114.2253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.3408 - accuracy: 0.0000e+00 - val_loss: 111.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1238/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 68.1234 - accuracy: 0.0000e+00 - val_loss: 96.5917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6582 - accuracy: 0.0156 - val_loss: 84.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1240/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 57.8563 - accuracy: 0.0156 - val_loss: 78.8236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5946 - accuracy: 0.0000e+00 - val_loss: 80.0879 - val_accuracy: 0.0000e+00\n",
      "Epoch 1242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.7127 - accuracy: 0.0000e+00 - val_loss: 90.3300 - val_accuracy: 0.0000e+00\n",
      "Epoch 1243/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 76.9571 - accuracy: 0.0000e+00 - val_loss: 101.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 68.0680 - accuracy: 0.0000e+00 - val_loss: 101.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.6023 - accuracy: 0.0000e+00 - val_loss: 90.3674 - val_accuracy: 0.0588\n",
      "Epoch 1246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.5977 - accuracy: 0.0000e+00 - val_loss: 80.2353 - val_accuracy: 0.0588\n",
      "Epoch 1247/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.6523 - accuracy: 0.0156 - val_loss: 76.7981 - val_accuracy: 0.0588\n",
      "Epoch 1248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.7483 - accuracy: 0.0000e+00 - val_loss: 82.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 1249/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 69.1901 - accuracy: 0.0156 - val_loss: 91.0523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1250/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.9288 - accuracy: 0.0000e+00 - val_loss: 98.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 1251/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0454 - accuracy: 0.0000e+00 - val_loss: 102.3171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1252/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 58.9649 - accuracy: 0.0000e+00 - val_loss: 98.9925 - val_accuracy: 0.0000e+00\n",
      "Epoch 1253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2834 - accuracy: 0.0156 - val_loss: 88.8561 - val_accuracy: 0.0588\n",
      "Epoch 1254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.1454 - accuracy: 0.0000e+00 - val_loss: 81.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 1255/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 50.4857 - accuracy: 0.0000e+00 - val_loss: 90.3257 - val_accuracy: 0.0588\n",
      "Epoch 1256/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.4727 - accuracy: 0.0000e+00 - val_loss: 98.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 1257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.0660 - accuracy: 0.0000e+00 - val_loss: 91.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 1258/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.7160 - accuracy: 0.0000e+00 - val_loss: 93.0584 - val_accuracy: 0.0000e+00\n",
      "Epoch 1259/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2130 - accuracy: 0.0156 - val_loss: 88.6447 - val_accuracy: 0.0000e+00\n",
      "Epoch 1260/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7305 - accuracy: 0.0000e+00 - val_loss: 82.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 1261/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 74.2225 - accuracy: 0.031 - 0s 125us/step - loss: 65.8651 - accuracy: 0.0156 - val_loss: 81.9385 - val_accuracy: 0.0000e+00\n",
      "Epoch 1262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4780 - accuracy: 0.0000e+00 - val_loss: 90.0524 - val_accuracy: 0.0000e+00\n",
      "Epoch 1263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7433 - accuracy: 0.0000e+00 - val_loss: 104.8600 - val_accuracy: 0.0000e+00\n",
      "Epoch 1264/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.7256 - accuracy: 0.0000e+00 - val_loss: 97.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 1265/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 60.0940 - accuracy: 0.0312 - val_loss: 84.3077 - val_accuracy: 0.0000e+00\n",
      "Epoch 1266/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.0464 - accuracy: 0.0000e+00 - val_loss: 75.3254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1267/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.9889 - accuracy: 0.0000e+00 - val_loss: 80.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1268/10000\n",
      "64/64 [==============================] - 0s 244us/step - loss: 71.6806 - accuracy: 0.0156 - val_loss: 81.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.9318 - accuracy: 0.0156 - val_loss: 88.8425 - val_accuracy: 0.0000e+00\n",
      "Epoch 1270/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 78.5098 - accuracy: 0.0156 - val_loss: 98.0859 - val_accuracy: 0.0000e+00\n",
      "Epoch 1271/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.3763 - accuracy: 0.0156 - val_loss: 105.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1272/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.8978 - accuracy: 0.0156 - val_loss: 102.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 1273/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9472 - accuracy: 0.0000e+00 - val_loss: 95.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1274/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.1160 - accuracy: 0.0000e+00 - val_loss: 90.8654 - val_accuracy: 0.0588\n",
      "Epoch 1275/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 52.1998 - accuracy: 0.0000e+00 - val_loss: 90.2103 - val_accuracy: 0.0588\n",
      "Epoch 1276/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1797 - accuracy: 0.0000e+00 - val_loss: 95.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 1277/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.0828 - accuracy: 0.0000e+00 - val_loss: 103.6122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1278/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 86.3838 - accuracy: 0.0000e+00 - val_loss: 94.9758 - val_accuracy: 0.0000e+00\n",
      "Epoch 1279/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.3945 - accuracy: 0.0000e+00 - val_loss: 88.1435 - val_accuracy: 0.0000e+00\n",
      "Epoch 1280/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5943 - accuracy: 0.0000e+00 - val_loss: 90.7039 - val_accuracy: 0.0000e+00\n",
      "Epoch 1281/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.0818 - accuracy: 0.0000e+00 - val_loss: 84.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 1282/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.7033 - accuracy: 0.0000e+00 - val_loss: 84.7570 - val_accuracy: 0.0000e+00\n",
      "Epoch 1283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6348 - accuracy: 0.0000e+00 - val_loss: 90.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3825 - accuracy: 0.0000e+00 - val_loss: 97.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 1285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.9178 - accuracy: 0.0000e+00 - val_loss: 97.1744 - val_accuracy: 0.0000e+00\n",
      "Epoch 1286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.2449 - accuracy: 0.0000e+00 - val_loss: 97.2529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.7981 - accuracy: 0.0312 - val_loss: 85.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 1288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9716 - accuracy: 0.0000e+00 - val_loss: 80.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.5019 - accuracy: 0.0000e+00 - val_loss: 83.7996 - val_accuracy: 0.0000e+00\n",
      "Epoch 1290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2418 - accuracy: 0.0000e+00 - val_loss: 90.9434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2397 - accuracy: 0.0000e+00 - val_loss: 97.4587 - val_accuracy: 0.0000e+00\n",
      "Epoch 1292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0973 - accuracy: 0.0000e+00 - val_loss: 103.2108 - val_accuracy: 0.0588\n",
      "Epoch 1293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5695 - accuracy: 0.0156 - val_loss: 97.9612 - val_accuracy: 0.0588\n",
      "Epoch 1294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4733 - accuracy: 0.0000e+00 - val_loss: 82.4170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.9871 - accuracy: 0.0000e+00 - val_loss: 69.7030 - val_accuracy: 0.0000e+00\n",
      "Epoch 1296/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.6793 - accuracy: 0.0000e+00 - val_loss: 69.2864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.2593 - accuracy: 0.0000e+00 - val_loss: 78.5943 - val_accuracy: 0.0000e+00\n",
      "Epoch 1298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2868 - accuracy: 0.0000e+00 - val_loss: 92.7621 - val_accuracy: 0.0000e+00\n",
      "Epoch 1299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.8732 - accuracy: 0.0156 - val_loss: 104.9502 - val_accuracy: 0.0000e+00\n",
      "Epoch 1300/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.3077 - accuracy: 0.0156 - val_loss: 98.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1301/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 81.0408 - accuracy: 0.0000e+00 - val_loss: 84.3840 - val_accuracy: 0.0588\n",
      "Epoch 1302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7318 - accuracy: 0.0156 - val_loss: 73.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 1303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.1782 - accuracy: 0.0156 - val_loss: 79.0882 - val_accuracy: 0.0000e+00\n",
      "Epoch 1304/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.5599 - accuracy: 0.0156 - val_loss: 93.8711 - val_accuracy: 0.0000e+00\n",
      "Epoch 1305/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.6858 - accuracy: 0.0000e+00 - val_loss: 111.6860 - val_accuracy: 0.0588\n",
      "Epoch 1306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.0022 - accuracy: 0.0000e+00 - val_loss: 112.4358 - val_accuracy: 0.0588\n",
      "Epoch 1307/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3832 - accuracy: 0.0156 - val_loss: 105.9557 - val_accuracy: 0.0588\n",
      "Epoch 1308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.0148 - accuracy: 0.0156 - val_loss: 87.8294 - val_accuracy: 0.0000e+00\n",
      "Epoch 1309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.4668 - accuracy: 0.0000e+00 - val_loss: 70.8879 - val_accuracy: 0.0000e+00\n",
      "Epoch 1310/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.2374 - accuracy: 0.0000e+00 - val_loss: 71.6598 - val_accuracy: 0.0000e+00\n",
      "Epoch 1311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2429 - accuracy: 0.0000e+00 - val_loss: 84.3737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1312/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 45.4351 - accuracy: 0.0000e+00 - val_loss: 98.5283 - val_accuracy: 0.0588\n",
      "Epoch 1313/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.7249 - accuracy: 0.0000e+00 - val_loss: 101.4241 - val_accuracy: 0.0588\n",
      "Epoch 1314/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.6742 - accuracy: 0.0000e+00 - val_loss: 87.6471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1315/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1878 - accuracy: 0.0000e+00 - val_loss: 73.7876 - val_accuracy: 0.0000e+00\n",
      "Epoch 1316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3131 - accuracy: 0.0000e+00 - val_loss: 74.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9681 - accuracy: 0.0156 - val_loss: 84.4046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0518 - accuracy: 0.0000e+00 - val_loss: 90.3693 - val_accuracy: 0.0588\n",
      "Epoch 1319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.7421 - accuracy: 0.0000e+00 - val_loss: 98.2099 - val_accuracy: 0.0000e+00\n",
      "Epoch 1320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5653 - accuracy: 0.0000e+00 - val_loss: 91.0488 - val_accuracy: 0.0000e+00\n",
      "Epoch 1321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8929 - accuracy: 0.0000e+00 - val_loss: 87.8494 - val_accuracy: 0.0588\n",
      "Epoch 1322/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0058 - accuracy: 0.0000e+00 - val_loss: 79.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.0428 - accuracy: 0.0000e+00 - val_loss: 78.7512 - val_accuracy: 0.0000e+00\n",
      "Epoch 1324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.8397 - accuracy: 0.0312 - val_loss: 81.0691 - val_accuracy: 0.0000e+00\n",
      "Epoch 1325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.2816 - accuracy: 0.0000e+00 - val_loss: 84.1581 - val_accuracy: 0.0588\n",
      "Epoch 1326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.4589 - accuracy: 0.0156 - val_loss: 87.2961 - val_accuracy: 0.0588\n",
      "Epoch 1327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0849 - accuracy: 0.0000e+00 - val_loss: 84.9297 - val_accuracy: 0.0588\n",
      "Epoch 1328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.9184 - accuracy: 0.0000e+00 - val_loss: 82.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8639 - accuracy: 0.0000e+00 - val_loss: 86.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 1330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.4037 - accuracy: 0.0156 - val_loss: 95.3284 - val_accuracy: 0.0588\n",
      "Epoch 1331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 82.9607 - accuracy: 0.0000e+00 - val_loss: 100.2414 - val_accuracy: 0.0588\n",
      "Epoch 1332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9988 - accuracy: 0.0000e+00 - val_loss: 99.9313 - val_accuracy: 0.0588\n",
      "Epoch 1333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 88.4161 - accuracy: 0.0000e+00 - val_loss: 91.3012 - val_accuracy: 0.0000e+00\n",
      "Epoch 1334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.3824 - accuracy: 0.0000e+00 - val_loss: 84.5952 - val_accuracy: 0.0000e+00\n",
      "Epoch 1335/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.0746 - accuracy: 0.0000e+00 - val_loss: 83.4072 - val_accuracy: 0.0000e+00\n",
      "Epoch 1336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5242 - accuracy: 0.0312 - val_loss: 89.2119 - val_accuracy: 0.0588\n",
      "Epoch 1337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.1301 - accuracy: 0.0312 - val_loss: 105.5030 - val_accuracy: 0.0000e+00\n",
      "Epoch 1338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.4093 - accuracy: 0.0000e+00 - val_loss: 108.3841 - val_accuracy: 0.0000e+00\n",
      "Epoch 1339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4734 - accuracy: 0.0156 - val_loss: 98.7082 - val_accuracy: 0.0000e+00\n",
      "Epoch 1340/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3281 - accuracy: 0.0156 - val_loss: 89.7788 - val_accuracy: 0.0588\n",
      "Epoch 1341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1809 - accuracy: 0.0000e+00 - val_loss: 83.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 1342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.4849 - accuracy: 0.0000e+00 - val_loss: 99.6446 - val_accuracy: 0.0000e+00\n",
      "Epoch 1343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.8307 - accuracy: 0.0000e+00 - val_loss: 102.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 1344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.0386 - accuracy: 0.0000e+00 - val_loss: 93.6200 - val_accuracy: 0.0588\n",
      "Epoch 1345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1378 - accuracy: 0.0000e+00 - val_loss: 85.4108 - val_accuracy: 0.0000e+00\n",
      "Epoch 1346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.6784 - accuracy: 0.0000e+00 - val_loss: 78.2881 - val_accuracy: 0.0000e+00\n",
      "Epoch 1347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2459 - accuracy: 0.0000e+00 - val_loss: 75.9975 - val_accuracy: 0.0000e+00\n",
      "Epoch 1348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3632 - accuracy: 0.0000e+00 - val_loss: 86.4354 - val_accuracy: 0.0000e+00\n",
      "Epoch 1349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.9051 - accuracy: 0.0000e+00 - val_loss: 98.7197 - val_accuracy: 0.0000e+00\n",
      "Epoch 1350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.1063 - accuracy: 0.0000e+00 - val_loss: 96.8771 - val_accuracy: 0.0000e+00\n",
      "Epoch 1351/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 76.7986 - accuracy: 0.0000e+00 - val_loss: 89.9879 - val_accuracy: 0.0588\n",
      "Epoch 1352/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4389 - accuracy: 0.0000e+00 - val_loss: 91.3871 - val_accuracy: 0.0588\n",
      "Epoch 1353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.1382 - accuracy: 0.0000e+00 - val_loss: 95.4655 - val_accuracy: 0.0588\n",
      "Epoch 1354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3316 - accuracy: 0.0156 - val_loss: 95.5454 - val_accuracy: 0.0000e+00\n",
      "Epoch 1355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.9498 - accuracy: 0.0000e+00 - val_loss: 98.3997 - val_accuracy: 0.0000e+00\n",
      "Epoch 1356/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.4659 - accuracy: 0.0000e+00 - val_loss: 93.2725 - val_accuracy: 0.0000e+00\n",
      "Epoch 1357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6885 - accuracy: 0.0000e+00 - val_loss: 93.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 1358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0240 - accuracy: 0.0000e+00 - val_loss: 92.2782 - val_accuracy: 0.0000e+00\n",
      "Epoch 1359/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 74.4669 - accuracy: 0.0000e+00 - val_loss: 103.6517 - val_accuracy: 0.0588\n",
      "Epoch 1360/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9601 - accuracy: 0.0000e+00 - val_loss: 112.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 1361/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 83.3064 - accuracy: 0.0156 - val_loss: 103.0621 - val_accuracy: 0.0000e+00\n",
      "Epoch 1362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4449 - accuracy: 0.0000e+00 - val_loss: 84.5293 - val_accuracy: 0.0588\n",
      "Epoch 1363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0926 - accuracy: 0.0156 - val_loss: 76.0792 - val_accuracy: 0.0000e+00\n",
      "Epoch 1364/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 88.2736 - accuracy: 0.0000e+00 - val_loss: 79.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 1365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.0049 - accuracy: 0.0000e+00 - val_loss: 91.3210 - val_accuracy: 0.0000e+00\n",
      "Epoch 1366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2744 - accuracy: 0.0000e+00 - val_loss: 98.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 1367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1114 - accuracy: 0.0000e+00 - val_loss: 94.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 1368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5747 - accuracy: 0.0000e+00 - val_loss: 86.3369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 61.7813 - accuracy: 0.0156 - val_loss: 82.3249 - val_accuracy: 0.0000e+00\n",
      "Epoch 1370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6208 - accuracy: 0.0156 - val_loss: 85.7313 - val_accuracy: 0.0000e+00\n",
      "Epoch 1371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7671 - accuracy: 0.0000e+00 - val_loss: 85.3707 - val_accuracy: 0.0000e+00\n",
      "Epoch 1372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.8016 - accuracy: 0.0000e+00 - val_loss: 92.2484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.1172 - accuracy: 0.0000e+00 - val_loss: 100.8699 - val_accuracy: 0.0588\n",
      "Epoch 1374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.6097 - accuracy: 0.0000e+00 - val_loss: 103.9951 - val_accuracy: 0.0588\n",
      "Epoch 1375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7086 - accuracy: 0.0000e+00 - val_loss: 96.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 1376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7636 - accuracy: 0.0000e+00 - val_loss: 92.1729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9718 - accuracy: 0.0156 - val_loss: 88.1304 - val_accuracy: 0.0588\n",
      "Epoch 1378/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1518 - accuracy: 0.0000e+00 - val_loss: 96.3391 - val_accuracy: 0.0000e+00\n",
      "Epoch 1379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.7790 - accuracy: 0.0000e+00 - val_loss: 103.2074 - val_accuracy: 0.0000e+00\n",
      "Epoch 1380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.9063 - accuracy: 0.0000e+00 - val_loss: 112.5369 - val_accuracy: 0.0000e+00\n",
      "Epoch 1381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.7686 - accuracy: 0.0000e+00 - val_loss: 102.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.2287 - accuracy: 0.0000e+00 - val_loss: 93.5323 - val_accuracy: 0.0000e+00\n",
      "Epoch 1383/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2345 - accuracy: 0.0000e+00 - val_loss: 86.7253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1384/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.3433 - accuracy: 0.0000e+00 - val_loss: 85.3105 - val_accuracy: 0.0000e+00\n",
      "Epoch 1385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1639 - accuracy: 0.0000e+00 - val_loss: 91.6142 - val_accuracy: 0.0000e+00\n",
      "Epoch 1386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2860 - accuracy: 0.0000e+00 - val_loss: 88.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 1387/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.8858 - accuracy: 0.0000e+00 - val_loss: 86.9920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1820 - accuracy: 0.0000e+00 - val_loss: 92.8118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4520 - accuracy: 0.0000e+00 - val_loss: 99.6287 - val_accuracy: 0.0000e+00\n",
      "Epoch 1390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1703 - accuracy: 0.0156 - val_loss: 98.8238 - val_accuracy: 0.0000e+00\n",
      "Epoch 1391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4041 - accuracy: 0.0156 - val_loss: 97.6340 - val_accuracy: 0.0000e+00\n",
      "Epoch 1392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.9847 - accuracy: 0.0000e+00 - val_loss: 88.0735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1027 - accuracy: 0.0156 - val_loss: 75.8890 - val_accuracy: 0.0588\n",
      "Epoch 1394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2967 - accuracy: 0.0000e+00 - val_loss: 86.2720 - val_accuracy: 0.0000e+00\n",
      "Epoch 1395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1343 - accuracy: 0.0000e+00 - val_loss: 102.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 1396/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.0085 - accuracy: 0.0000e+00 - val_loss: 111.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 1397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 81.7639 - accuracy: 0.0156 - val_loss: 94.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6477 - accuracy: 0.0156 - val_loss: 83.3447 - val_accuracy: 0.0588\n",
      "Epoch 1399/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4387 - accuracy: 0.0000e+00 - val_loss: 82.7096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.6615 - accuracy: 0.0000e+00 - val_loss: 92.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 1401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.5110 - accuracy: 0.0000e+00 - val_loss: 111.8509 - val_accuracy: 0.0000e+00\n",
      "Epoch 1402/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.9388 - accuracy: 0.0000e+00 - val_loss: 113.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 1403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.1840 - accuracy: 0.0000e+00 - val_loss: 96.2086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6943 - accuracy: 0.0000e+00 - val_loss: 75.8477 - val_accuracy: 0.0588\n",
      "Epoch 1405/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.7284 - accuracy: 0.0000e+00 - val_loss: 65.8787 - val_accuracy: 0.0000e+00\n",
      "Epoch 1406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9157 - accuracy: 0.0156 - val_loss: 75.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 1407/10000\n",
      "64/64 [==============================] - 0s 562us/step - loss: 68.5679 - accuracy: 0.0000e+00 - val_loss: 91.2931 - val_accuracy: 0.0000e+00\n",
      "Epoch 1408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2364 - accuracy: 0.0000e+00 - val_loss: 101.2953 - val_accuracy: 0.0588\n",
      "Epoch 1409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3825 - accuracy: 0.0000e+00 - val_loss: 105.5737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1410/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.2305 - accuracy: 0.0000e+00 - val_loss: 90.1148 - val_accuracy: 0.0588\n",
      "Epoch 1411/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 69.9170 - accuracy: 0.0000e+00 - val_loss: 78.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 1412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1636 - accuracy: 0.0000e+00 - val_loss: 74.2410 - val_accuracy: 0.0000e+00\n",
      "Epoch 1413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9938 - accuracy: 0.0000e+00 - val_loss: 90.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 1414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2550 - accuracy: 0.0000e+00 - val_loss: 100.4009 - val_accuracy: 0.0000e+00\n",
      "Epoch 1415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.9292 - accuracy: 0.0156 - val_loss: 98.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 1416/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 77.3152 - accuracy: 0.0000e+00 - val_loss: 87.6017 - val_accuracy: 0.0000e+00\n",
      "Epoch 1417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2751 - accuracy: 0.0000e+00 - val_loss: 83.2083 - val_accuracy: 0.0000e+00\n",
      "Epoch 1418/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 59.1849 - accuracy: 0.0156 - val_loss: 80.3922 - val_accuracy: 0.0000e+00\n",
      "Epoch 1419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.9974 - accuracy: 0.0156 - val_loss: 74.1124 - val_accuracy: 0.0000e+00\n",
      "Epoch 1420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.3497 - accuracy: 0.0000e+00 - val_loss: 69.8924 - val_accuracy: 0.0000e+00\n",
      "Epoch 1421/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.5884 - accuracy: 0.0156 - val_loss: 68.8023 - val_accuracy: 0.0000e+00\n",
      "Epoch 1422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.9780 - accuracy: 0.0156 - val_loss: 67.1951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1423/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.4632 - accuracy: 0.0156 - val_loss: 71.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 1424/10000\n",
      "64/64 [==============================] - 0s 167us/step - loss: 62.9237 - accuracy: 0.0000e+00 - val_loss: 77.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1674 - accuracy: 0.0000e+00 - val_loss: 78.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 1426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2850 - accuracy: 0.0000e+00 - val_loss: 82.9391 - val_accuracy: 0.0000e+00\n",
      "Epoch 1427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.2613 - accuracy: 0.0000e+00 - val_loss: 85.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 1428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.7745 - accuracy: 0.0156 - val_loss: 86.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 1429/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 80.1366 - accuracy: 0.0000e+00 - val_loss: 78.6406 - val_accuracy: 0.0000e+00\n",
      "Epoch 1430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0278 - accuracy: 0.0156 - val_loss: 68.1798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5421 - accuracy: 0.0156 - val_loss: 66.9083 - val_accuracy: 0.0000e+00\n",
      "Epoch 1432/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9019 - accuracy: 0.0156 - val_loss: 75.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 1433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4896 - accuracy: 0.0000e+00 - val_loss: 88.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 1434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8656 - accuracy: 0.0000e+00 - val_loss: 94.7167 - val_accuracy: 0.0000e+00\n",
      "Epoch 1435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.3983 - accuracy: 0.0000e+00 - val_loss: 85.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 1436/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 90.0057 - accuracy: 0.0000e+00 - val_loss: 77.3005 - val_accuracy: 0.0000e+00\n",
      "Epoch 1437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 69.8218 - accuracy: 0.0000e+00 - val_loss: 69.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 1438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4527 - accuracy: 0.0000e+00 - val_loss: 74.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 1439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0510 - accuracy: 0.0000e+00 - val_loss: 90.5736 - val_accuracy: 0.0000e+00\n",
      "Epoch 1440/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.2525 - accuracy: 0.0000e+00 - val_loss: 103.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1441/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.5508 - accuracy: 0.0000e+00 - val_loss: 99.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1442/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.3621 - accuracy: 0.0000e+00 - val_loss: 91.9120 - val_accuracy: 0.0588\n",
      "Epoch 1443/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.0887 - accuracy: 0.0000e+00 - val_loss: 78.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 1444/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.7316 - accuracy: 0.0156 - val_loss: 73.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 1445/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 51.1266 - accuracy: 0.0000e+00 - val_loss: 89.5049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1446/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.4277 - accuracy: 0.0000e+00 - val_loss: 103.6276 - val_accuracy: 0.0000e+00\n",
      "Epoch 1447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 84.5339 - accuracy: 0.0156 - val_loss: 106.9407 - val_accuracy: 0.0000e+00\n",
      "Epoch 1448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 80.3221 - accuracy: 0.0000e+00 - val_loss: 98.3290 - val_accuracy: 0.0000e+00\n",
      "Epoch 1449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2810 - accuracy: 0.0000e+00 - val_loss: 86.8215 - val_accuracy: 0.0000e+00\n",
      "Epoch 1450/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.5211 - accuracy: 0.0000e+00 - val_loss: 84.4399 - val_accuracy: 0.0588\n",
      "Epoch 1451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2455 - accuracy: 0.0000e+00 - val_loss: 87.7795 - val_accuracy: 0.0000e+00\n",
      "Epoch 1452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.2999 - accuracy: 0.0000e+00 - val_loss: 91.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1453/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.4667 - accuracy: 0.0156 - val_loss: 98.8808 - val_accuracy: 0.0000e+00\n",
      "Epoch 1454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9644 - accuracy: 0.0156 - val_loss: 93.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1455/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.7801 - accuracy: 0.0000e+00 - val_loss: 86.2739 - val_accuracy: 0.0000e+00\n",
      "Epoch 1456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9242 - accuracy: 0.0312 - val_loss: 81.7817 - val_accuracy: 0.0000e+00\n",
      "Epoch 1457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.3969 - accuracy: 0.0156 - val_loss: 76.9382 - val_accuracy: 0.0000e+00\n",
      "Epoch 1458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.1522 - accuracy: 0.0156 - val_loss: 90.6618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6290 - accuracy: 0.0000e+00 - val_loss: 103.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1460/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3407 - accuracy: 0.0156 - val_loss: 104.5560 - val_accuracy: 0.0000e+00\n",
      "Epoch 1461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1753 - accuracy: 0.0312 - val_loss: 103.3595 - val_accuracy: 0.0000e+00\n",
      "Epoch 1462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8407 - accuracy: 0.0000e+00 - val_loss: 91.4492 - val_accuracy: 0.0588\n",
      "Epoch 1463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.3412 - accuracy: 0.0000e+00 - val_loss: 79.8344 - val_accuracy: 0.0000e+00\n",
      "Epoch 1464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 71.5307 - accuracy: 0.0156 - val_loss: 83.8865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7501 - accuracy: 0.0156 - val_loss: 95.9998 - val_accuracy: 0.0588\n",
      "Epoch 1466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0371 - accuracy: 0.0156 - val_loss: 101.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 1467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.1055 - accuracy: 0.0156 - val_loss: 99.5573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1468/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.7856 - accuracy: 0.0156 - val_loss: 90.0106 - val_accuracy: 0.0588\n",
      "Epoch 1469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3340 - accuracy: 0.0000e+00 - val_loss: 83.8114 - val_accuracy: 0.0588\n",
      "Epoch 1470/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 73.4533 - accuracy: 0.0000e+00 - val_loss: 75.5590 - val_accuracy: 0.0000e+00\n",
      "Epoch 1471/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 77.5361 - accuracy: 0.0000e+00 - val_loss: 75.4027 - val_accuracy: 0.0000e+00\n",
      "Epoch 1472/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 65.7234 - accuracy: 0.0000e+00 - val_loss: 73.6389 - val_accuracy: 0.0000e+00\n",
      "Epoch 1473/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.2291 - accuracy: 0.0000e+00 - val_loss: 80.5792 - val_accuracy: 0.0588\n",
      "Epoch 1474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.7826 - accuracy: 0.0156 - val_loss: 81.4757 - val_accuracy: 0.0000e+00\n",
      "Epoch 1475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.3583 - accuracy: 0.0156 - val_loss: 83.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 1476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.5023 - accuracy: 0.0000e+00 - val_loss: 93.4680 - val_accuracy: 0.0000e+00\n",
      "Epoch 1477/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.8581 - accuracy: 0.0156 - val_loss: 90.5148 - val_accuracy: 0.0000e+00\n",
      "Epoch 1478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.7325 - accuracy: 0.0000e+00 - val_loss: 86.5654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1479/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.1097 - accuracy: 0.0000e+00 - val_loss: 80.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 1480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2560 - accuracy: 0.0000e+00 - val_loss: 84.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 1481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3231 - accuracy: 0.0000e+00 - val_loss: 87.4521 - val_accuracy: 0.0000e+00\n",
      "Epoch 1482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.5298 - accuracy: 0.0156 - val_loss: 99.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 1483/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.8879 - accuracy: 0.0000e+00 - val_loss: 98.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 1484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.9614 - accuracy: 0.0000e+00 - val_loss: 92.6836 - val_accuracy: 0.0000e+00\n",
      "Epoch 1485/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 58.1942 - accuracy: 0.0000e+00 - val_loss: 86.4667 - val_accuracy: 0.0000e+00\n",
      "Epoch 1486/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5555 - accuracy: 0.0000e+00 - val_loss: 90.1527 - val_accuracy: 0.0588\n",
      "Epoch 1487/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.4638 - accuracy: 0.0000e+00 - val_loss: 101.8508 - val_accuracy: 0.0000e+00\n",
      "Epoch 1488/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1141 - accuracy: 0.0156 - val_loss: 108.3880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1489/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 54.7830 - accuracy: 0.0000e+00 - val_loss: 117.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 1490/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 70.1488 - accuracy: 0.0156 - val_loss: 112.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1491/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 69.9960 - accuracy: 0.0156 - val_loss: 99.0434 - val_accuracy: 0.0000e+00\n",
      "Epoch 1492/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 79.5890 - accuracy: 0.0156 - val_loss: 90.0798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1493/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.4509 - accuracy: 0.0156 - val_loss: 86.5935 - val_accuracy: 0.0000e+00\n",
      "Epoch 1494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5762 - accuracy: 0.0000e+00 - val_loss: 89.3930 - val_accuracy: 0.0000e+00\n",
      "Epoch 1495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1500 - accuracy: 0.0000e+00 - val_loss: 94.7684 - val_accuracy: 0.0000e+00\n",
      "Epoch 1496/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9255 - accuracy: 0.0000e+00 - val_loss: 94.5598 - val_accuracy: 0.0000e+00\n",
      "Epoch 1497/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.4274 - accuracy: 0.0000e+0 - 0s 250us/step - loss: 67.4783 - accuracy: 0.0000e+00 - val_loss: 90.3849 - val_accuracy: 0.0000e+00\n",
      "Epoch 1498/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.1404 - accuracy: 0.0000e+00 - val_loss: 79.4134 - val_accuracy: 0.0000e+00\n",
      "Epoch 1499/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0511 - accuracy: 0.0000e+00 - val_loss: 82.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6225 - accuracy: 0.0156 - val_loss: 92.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 1501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1922 - accuracy: 0.0156 - val_loss: 111.1548 - val_accuracy: 0.0000e+00\n",
      "Epoch 1502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8109 - accuracy: 0.0000e+00 - val_loss: 123.6012 - val_accuracy: 0.0000e+00\n",
      "Epoch 1503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.2252 - accuracy: 0.0156 - val_loss: 117.7444 - val_accuracy: 0.0000e+00\n",
      "Epoch 1504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2238 - accuracy: 0.0000e+00 - val_loss: 94.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 1505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0527 - accuracy: 0.0000e+00 - val_loss: 78.4942 - val_accuracy: 0.0000e+00\n",
      "Epoch 1506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6022 - accuracy: 0.0000e+00 - val_loss: 74.0222 - val_accuracy: 0.0588\n",
      "Epoch 1507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5942 - accuracy: 0.0156 - val_loss: 87.0889 - val_accuracy: 0.0000e+00\n",
      "Epoch 1508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8592 - accuracy: 0.0156 - val_loss: 106.6079 - val_accuracy: 0.0000e+00\n",
      "Epoch 1509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.6666 - accuracy: 0.0000e+00 - val_loss: 101.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 1510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9048 - accuracy: 0.0156 - val_loss: 87.6851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.5028 - accuracy: 0.0000e+00 - val_loss: 74.3946 - val_accuracy: 0.0000e+00\n",
      "Epoch 1512/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.9473 - accuracy: 0.0000e+00 - val_loss: 77.2193 - val_accuracy: 0.0588\n",
      "Epoch 1513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4525 - accuracy: 0.0000e+00 - val_loss: 88.5462 - val_accuracy: 0.0000e+00\n",
      "Epoch 1514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4369 - accuracy: 0.0000e+00 - val_loss: 97.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 1515/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 61.4509 - accuracy: 0.0156 - val_loss: 105.6461 - val_accuracy: 0.0000e+00\n",
      "Epoch 1516/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.1784 - accuracy: 0.0000e+00 - val_loss: 106.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 1517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4291 - accuracy: 0.0156 - val_loss: 92.2813 - val_accuracy: 0.0000e+00\n",
      "Epoch 1518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5158 - accuracy: 0.0000e+00 - val_loss: 81.7115 - val_accuracy: 0.0000e+00\n",
      "Epoch 1519/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.3243 - accuracy: 0.0156 - val_loss: 85.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 1520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 55.9079 - accuracy: 0.0000e+00 - val_loss: 88.4100 - val_accuracy: 0.0000e+00\n",
      "Epoch 1521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8433 - accuracy: 0.0156 - val_loss: 94.9764 - val_accuracy: 0.0000e+00\n",
      "Epoch 1522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.3150 - accuracy: 0.0000e+00 - val_loss: 99.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 1523/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.8375 - accuracy: 0.0000e+00 - val_loss: 98.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1524/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1773 - accuracy: 0.0000e+00 - val_loss: 89.1108 - val_accuracy: 0.0588\n",
      "Epoch 1525/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.6226 - accuracy: 0.0000e+00 - val_loss: 82.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1526/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.2645 - accuracy: 0.0000e+00 - val_loss: 82.1555 - val_accuracy: 0.0000e+00\n",
      "Epoch 1527/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.7586 - accuracy: 0.0000e+00 - val_loss: 91.0481 - val_accuracy: 0.0000e+00\n",
      "Epoch 1528/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 71.2376 - accuracy: 0.0000e+00 - val_loss: 94.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 1529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4851 - accuracy: 0.0000e+00 - val_loss: 90.7654 - val_accuracy: 0.0000e+00\n",
      "Epoch 1530/10000\n",
      "64/64 [==============================] - 0s 183us/step - loss: 60.3710 - accuracy: 0.0156 - val_loss: 73.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 1531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5201 - accuracy: 0.0156 - val_loss: 64.1532 - val_accuracy: 0.0588\n",
      "Epoch 1532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3593 - accuracy: 0.0000e+00 - val_loss: 70.0547 - val_accuracy: 0.0588\n",
      "Epoch 1533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1142 - accuracy: 0.0000e+00 - val_loss: 95.7158 - val_accuracy: 0.0000e+00\n",
      "Epoch 1534/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.6830 - accuracy: 0.0000e+00 - val_loss: 103.9107 - val_accuracy: 0.0000e+00\n",
      "Epoch 1535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.5458 - accuracy: 0.0000e+00 - val_loss: 98.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 1536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2416 - accuracy: 0.0156 - val_loss: 86.2171 - val_accuracy: 0.0000e+00\n",
      "Epoch 1537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1441 - accuracy: 0.0156 - val_loss: 79.1319 - val_accuracy: 0.0000e+00\n",
      "Epoch 1538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.4987 - accuracy: 0.0000e+00 - val_loss: 80.5230 - val_accuracy: 0.0000e+00\n",
      "Epoch 1539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 79.8332 - accuracy: 0.0000e+00 - val_loss: 95.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0873 - accuracy: 0.0000e+00 - val_loss: 115.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 1541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3010 - accuracy: 0.0000e+00 - val_loss: 124.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 1542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4027 - accuracy: 0.0000e+00 - val_loss: 107.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.4076 - accuracy: 0.0156 - val_loss: 88.0682 - val_accuracy: 0.0000e+00\n",
      "Epoch 1544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.9933 - accuracy: 0.0000e+00 - val_loss: 70.7232 - val_accuracy: 0.0000e+00\n",
      "Epoch 1545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.0209 - accuracy: 0.0000e+00 - val_loss: 71.0670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7324 - accuracy: 0.0000e+00 - val_loss: 87.9845 - val_accuracy: 0.0000e+00\n",
      "Epoch 1547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 67.9881 - accuracy: 0.0000e+00 - val_loss: 98.7060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7363 - accuracy: 0.0000e+00 - val_loss: 94.2612 - val_accuracy: 0.0000e+00\n",
      "Epoch 1549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.8144 - accuracy: 0.0000e+00 - val_loss: 79.0460 - val_accuracy: 0.0000e+00\n",
      "Epoch 1550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3254 - accuracy: 0.0000e+00 - val_loss: 79.2310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9861 - accuracy: 0.0156 - val_loss: 79.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 1552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5373 - accuracy: 0.0000e+00 - val_loss: 83.0718 - val_accuracy: 0.0588\n",
      "Epoch 1553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0555 - accuracy: 0.0000e+00 - val_loss: 88.2289 - val_accuracy: 0.0000e+00\n",
      "Epoch 1554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2779 - accuracy: 0.0000e+00 - val_loss: 93.7640 - val_accuracy: 0.0000e+00\n",
      "Epoch 1555/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.9978 - accuracy: 0.0000e+00 - val_loss: 102.9044 - val_accuracy: 0.0588\n",
      "Epoch 1556/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.4908 - accuracy: 0.0469 - val_loss: 100.8565 - val_accuracy: 0.0588\n",
      "Epoch 1557/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.7673 - accuracy: 0.0000e+00 - val_loss: 100.1230 - val_accuracy: 0.0588\n",
      "Epoch 1558/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 44.3828 - accuracy: 0.0156 - val_loss: 91.6088 - val_accuracy: 0.0000e+00\n",
      "Epoch 1559/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.9101 - accuracy: 0.0312 - val_loss: 85.8470 - val_accuracy: 0.0588\n",
      "Epoch 1560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4863 - accuracy: 0.0000e+00 - val_loss: 82.8389 - val_accuracy: 0.0588\n",
      "Epoch 1561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 67.2347 - accuracy: 0.0156 - val_loss: 81.2866 - val_accuracy: 0.0588\n",
      "Epoch 1562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9613 - accuracy: 0.0156 - val_loss: 92.9253 - val_accuracy: 0.0000e+00\n",
      "Epoch 1563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5054 - accuracy: 0.0000e+00 - val_loss: 94.0351 - val_accuracy: 0.0000e+00\n",
      "Epoch 1564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0645 - accuracy: 0.0000e+00 - val_loss: 96.5384 - val_accuracy: 0.0000e+00\n",
      "Epoch 1565/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.1488 - accuracy: 0.0000e+00 - val_loss: 91.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.8899 - accuracy: 0.0000e+00 - val_loss: 87.7466 - val_accuracy: 0.0000e+00\n",
      "Epoch 1567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1430 - accuracy: 0.0000e+00 - val_loss: 85.0985 - val_accuracy: 0.0000e+00\n",
      "Epoch 1568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.0363 - accuracy: 0.0000e+00 - val_loss: 90.7407 - val_accuracy: 0.0000e+00\n",
      "Epoch 1569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.0087 - accuracy: 0.0000e+00 - val_loss: 99.6740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6119 - accuracy: 0.0000e+00 - val_loss: 99.5389 - val_accuracy: 0.0000e+00\n",
      "Epoch 1571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7222 - accuracy: 0.0000e+00 - val_loss: 96.8620 - val_accuracy: 0.0000e+00\n",
      "Epoch 1572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7674 - accuracy: 0.0000e+00 - val_loss: 100.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 1573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5716 - accuracy: 0.0000e+00 - val_loss: 96.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 1574/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.1446 - accuracy: 0.0000e+00 - val_loss: 93.6380 - val_accuracy: 0.0000e+00\n",
      "Epoch 1575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3899 - accuracy: 0.0000e+00 - val_loss: 95.2815 - val_accuracy: 0.0588\n",
      "Epoch 1576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5883 - accuracy: 0.0000e+00 - val_loss: 94.3538 - val_accuracy: 0.0588\n",
      "Epoch 1577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1741 - accuracy: 0.0000e+00 - val_loss: 85.0229 - val_accuracy: 0.0588\n",
      "Epoch 1578/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7658 - accuracy: 0.0000e+00 - val_loss: 78.0585 - val_accuracy: 0.0000e+00\n",
      "Epoch 1579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4474 - accuracy: 0.0000e+00 - val_loss: 87.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.2208 - accuracy: 0.0156 - val_loss: 109.7333 - val_accuracy: 0.0000e+00\n",
      "Epoch 1581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.6967 - accuracy: 0.0000e+00 - val_loss: 114.0655 - val_accuracy: 0.0000e+00\n",
      "Epoch 1582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 75.1097 - accuracy: 0.0000e+00 - val_loss: 100.2809 - val_accuracy: 0.0588\n",
      "Epoch 1583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.8200 - accuracy: 0.0000e+00 - val_loss: 95.8925 - val_accuracy: 0.0588\n",
      "Epoch 1584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5542 - accuracy: 0.0000e+00 - val_loss: 87.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 1585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1312 - accuracy: 0.0156 - val_loss: 94.4067 - val_accuracy: 0.0588\n",
      "Epoch 1586/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.0881 - accuracy: 0.0000e+00 - val_loss: 99.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 1587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4399 - accuracy: 0.0000e+00 - val_loss: 109.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 1588/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.5537 - accuracy: 0.0000e+00 - val_loss: 107.2803 - val_accuracy: 0.0588\n",
      "Epoch 1589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6470 - accuracy: 0.0156 - val_loss: 100.5601 - val_accuracy: 0.0000e+00\n",
      "Epoch 1590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.5696 - accuracy: 0.0000e+00 - val_loss: 85.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 1591/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.2597 - accuracy: 0.0312 - val_loss: 77.2880 - val_accuracy: 0.0000e+00\n",
      "Epoch 1592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6460 - accuracy: 0.0000e+00 - val_loss: 72.2073 - val_accuracy: 0.0000e+00\n",
      "Epoch 1593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.9523 - accuracy: 0.0000e+00 - val_loss: 85.4475 - val_accuracy: 0.0000e+00\n",
      "Epoch 1594/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2451 - accuracy: 0.0156 - val_loss: 101.3731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.6284 - accuracy: 0.0156 - val_loss: 102.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 1596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0182 - accuracy: 0.0000e+00 - val_loss: 97.2035 - val_accuracy: 0.0588\n",
      "Epoch 1597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.2890 - accuracy: 0.0000e+00 - val_loss: 86.9481 - val_accuracy: 0.0000e+00\n",
      "Epoch 1598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1533 - accuracy: 0.0000e+00 - val_loss: 78.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 1599/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 45.3596 - accuracy: 0.0156 - val_loss: 82.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1600/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.9548 - accuracy: 0.0156 - val_loss: 94.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1601/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.4720 - accuracy: 0.0000e+00 - val_loss: 96.8573 - val_accuracy: 0.0000e+00\n",
      "Epoch 1602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5107 - accuracy: 0.0000e+00 - val_loss: 92.2755 - val_accuracy: 0.0588\n",
      "Epoch 1603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.0087 - accuracy: 0.0000e+00 - val_loss: 84.1933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1604/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.3289 - accuracy: 0.0000e+00 - val_loss: 87.3490 - val_accuracy: 0.0588\n",
      "Epoch 1605/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.0430 - accuracy: 0.0156 - val_loss: 93.1945 - val_accuracy: 0.0000e+00\n",
      "Epoch 1606/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 72.7708 - accuracy: 0.0000e+00 - val_loss: 90.9426 - val_accuracy: 0.0588\n",
      "Epoch 1607/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.1746 - accuracy: 0.0156 - val_loss: 85.0404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1608/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.7859 - accuracy: 0.0000e+00 - val_loss: 84.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1609/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 66.2322 - accuracy: 0.0156 - val_loss: 91.0710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6204 - accuracy: 0.0000e+00 - val_loss: 93.3295 - val_accuracy: 0.0000e+00\n",
      "Epoch 1611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5824 - accuracy: 0.0000e+00 - val_loss: 96.9482 - val_accuracy: 0.0588\n",
      "Epoch 1612/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.5711 - accuracy: 0.0000e+00 - val_loss: 90.2493 - val_accuracy: 0.0588\n",
      "Epoch 1613/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 44.7009 - accuracy: 0.0156 - val_loss: 80.1405 - val_accuracy: 0.0000e+00\n",
      "Epoch 1614/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.7541 - accuracy: 0.0312 - val_loss: 79.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1615/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.8844 - accuracy: 0.0000e+00 - val_loss: 94.7656 - val_accuracy: 0.0000e+00\n",
      "Epoch 1616/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.8198 - accuracy: 0.0000e+00 - val_loss: 103.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 1617/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 91.4098 - accuracy: 0.0000e+00 - val_loss: 97.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 1618/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1468 - accuracy: 0.0000e+00 - val_loss: 88.6843 - val_accuracy: 0.0000e+00\n",
      "Epoch 1619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.5133 - accuracy: 0.0156 - val_loss: 87.2661 - val_accuracy: 0.0588\n",
      "Epoch 1620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.8342 - accuracy: 0.0156 - val_loss: 94.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 1621/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.9345 - accuracy: 0.0156 - val_loss: 100.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 1622/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7259 - accuracy: 0.0156 - val_loss: 94.6618 - val_accuracy: 0.0588\n",
      "Epoch 1623/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.2598 - accuracy: 0.0000e+00 - val_loss: 99.2422 - val_accuracy: 0.0000e+00\n",
      "Epoch 1624/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.9600 - accuracy: 0.0000e+00 - val_loss: 108.0782 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1625/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 52.0761 - accuracy: 0.0000e+00 - val_loss: 114.8539 - val_accuracy: 0.0000e+00\n",
      "Epoch 1626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2987 - accuracy: 0.0000e+00 - val_loss: 111.0740 - val_accuracy: 0.0000e+00\n",
      "Epoch 1627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.7361 - accuracy: 0.0000e+00 - val_loss: 104.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 1628/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3463 - accuracy: 0.0000e+00 - val_loss: 90.2674 - val_accuracy: 0.0000e+00\n",
      "Epoch 1629/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 74.1186 - accuracy: 0.0000e+00 - val_loss: 88.7240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5572 - accuracy: 0.0156 - val_loss: 89.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 1631/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 59.1404 - accuracy: 0.0000e+00 - val_loss: 86.9710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7922 - accuracy: 0.0000e+00 - val_loss: 81.7636 - val_accuracy: 0.0000e+00\n",
      "Epoch 1633/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.0382 - accuracy: 0.0312 - val_loss: 80.9495 - val_accuracy: 0.0000e+00\n",
      "Epoch 1634/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7026 - accuracy: 0.0156 - val_loss: 79.1141 - val_accuracy: 0.0000e+00\n",
      "Epoch 1635/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 54.8925 - accuracy: 0.0000e+00 - val_loss: 75.3892 - val_accuracy: 0.0000e+00\n",
      "Epoch 1636/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.6540 - accuracy: 0.0000e+00 - val_loss: 69.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1637/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.3299 - accuracy: 0.0000e+00 - val_loss: 78.2058 - val_accuracy: 0.0000e+00\n",
      "Epoch 1638/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.6156 - accuracy: 0.0000e+00 - val_loss: 96.9966 - val_accuracy: 0.0000e+00\n",
      "Epoch 1639/10000\n",
      "64/64 [==============================] - 0s 258us/step - loss: 51.9060 - accuracy: 0.0156 - val_loss: 108.6116 - val_accuracy: 0.0000e+00\n",
      "Epoch 1640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.5942 - accuracy: 0.0000e+00 - val_loss: 120.5060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1641/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 61.0139 - accuracy: 0.0000e+00 - val_loss: 122.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 1642/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.5428 - accuracy: 0.0000e+00 - val_loss: 112.5975 - val_accuracy: 0.0588\n",
      "Epoch 1643/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.9404 - accuracy: 0.0000e+00 - val_loss: 91.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 1644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9205 - accuracy: 0.0312 - val_loss: 86.0438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1645/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4473 - accuracy: 0.0000e+00 - val_loss: 87.0317 - val_accuracy: 0.0000e+00\n",
      "Epoch 1646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6595 - accuracy: 0.0000e+00 - val_loss: 92.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 1647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6255 - accuracy: 0.0000e+00 - val_loss: 101.2704 - val_accuracy: 0.0000e+00\n",
      "Epoch 1648/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 46.0936 - accuracy: 0.0000e+00 - val_loss: 99.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 1649/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.9315 - accuracy: 0.0000e+00 - val_loss: 94.5316 - val_accuracy: 0.0000e+00\n",
      "Epoch 1650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5944 - accuracy: 0.0156 - val_loss: 98.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 1651/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.0418 - accuracy: 0.0000e+00 - val_loss: 99.7170 - val_accuracy: 0.0000e+00\n",
      "Epoch 1652/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.1232 - accuracy: 0.0000e+00 - val_loss: 87.4422 - val_accuracy: 0.0588\n",
      "Epoch 1653/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 53.1070 - accuracy: 0.0312 - val_loss: 85.0274 - val_accuracy: 0.0588\n",
      "Epoch 1654/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 49.1644 - accuracy: 0.0156 - val_loss: 83.0776 - val_accuracy: 0.0588\n",
      "Epoch 1655/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.2416 - accuracy: 0.0000e+00 - val_loss: 83.0865 - val_accuracy: 0.0588\n",
      "Epoch 1656/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.0109 - accuracy: 0.0156 - val_loss: 90.5086 - val_accuracy: 0.0000e+00\n",
      "Epoch 1657/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.8060 - accuracy: 0.0000e+00 - val_loss: 99.4969 - val_accuracy: 0.0588\n",
      "Epoch 1658/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6397 - accuracy: 0.0000e+00 - val_loss: 99.9020 - val_accuracy: 0.0000e+00\n",
      "Epoch 1659/10000\n",
      "64/64 [==============================] - 0s 204us/step - loss: 58.4342 - accuracy: 0.0156 - val_loss: 90.4464 - val_accuracy: 0.0000e+00\n",
      "Epoch 1660/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 52.1400 - accuracy: 0.0000e+00 - val_loss: 81.2246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1661/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.2021 - accuracy: 0.0000e+00 - val_loss: 77.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 1662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5450 - accuracy: 0.0000e+00 - val_loss: 86.3298 - val_accuracy: 0.0588\n",
      "Epoch 1663/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 50.9454 - accuracy: 0.0156 - val_loss: 95.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 1664/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 49.3508 - accuracy: 0.0000e+00 - val_loss: 94.6730 - val_accuracy: 0.0000e+00\n",
      "Epoch 1665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8258 - accuracy: 0.0000e+00 - val_loss: 85.1094 - val_accuracy: 0.0588\n",
      "Epoch 1666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0088 - accuracy: 0.0000e+00 - val_loss: 91.9808 - val_accuracy: 0.0000e+00\n",
      "Epoch 1667/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.6298 - accuracy: 0.0000e+00 - val_loss: 94.5909 - val_accuracy: 0.0000e+00\n",
      "Epoch 1668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1689 - accuracy: 0.0156 - val_loss: 94.6651 - val_accuracy: 0.0000e+00\n",
      "Epoch 1669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.2469 - accuracy: 0.0000e+00 - val_loss: 97.5277 - val_accuracy: 0.0588\n",
      "Epoch 1670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9102 - accuracy: 0.0000e+00 - val_loss: 101.6350 - val_accuracy: 0.0588\n",
      "Epoch 1671/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.1323 - accuracy: 0.0000e+00 - val_loss: 98.3487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1672/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3084 - accuracy: 0.0156 - val_loss: 99.7363 - val_accuracy: 0.0000e+00\n",
      "Epoch 1673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.5143 - accuracy: 0.0000e+00 - val_loss: 92.7747 - val_accuracy: 0.0588\n",
      "Epoch 1674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2312 - accuracy: 0.0000e+00 - val_loss: 89.3047 - val_accuracy: 0.0588\n",
      "Epoch 1675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.6147 - accuracy: 0.0000e+00 - val_loss: 88.9565 - val_accuracy: 0.0588\n",
      "Epoch 1676/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.9668 - accuracy: 0.0000e+00 - val_loss: 91.0633 - val_accuracy: 0.0588\n",
      "Epoch 1677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.8697 - accuracy: 0.0156 - val_loss: 105.5082 - val_accuracy: 0.0588\n",
      "Epoch 1678/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.0295 - accuracy: 0.0156 - val_loss: 123.0995 - val_accuracy: 0.0000e+00\n",
      "Epoch 1679/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.7907 - accuracy: 0.0000e+00 - val_loss: 130.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 1680/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 63.5700 - accuracy: 0.0156 - val_loss: 116.9118 - val_accuracy: 0.0588\n",
      "Epoch 1681/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.8341 - accuracy: 0.0000e+00 - val_loss: 91.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 1682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5704 - accuracy: 0.0000e+00 - val_loss: 77.3679 - val_accuracy: 0.0588\n",
      "Epoch 1683/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.8740 - accuracy: 0.0000e+00 - val_loss: 82.6919 - val_accuracy: 0.0000e+00\n",
      "Epoch 1684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1011 - accuracy: 0.0000e+00 - val_loss: 102.8330 - val_accuracy: 0.0000e+00\n",
      "Epoch 1685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4595 - accuracy: 0.0000e+00 - val_loss: 111.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 1686/10000\n",
      "64/64 [==============================] - 0s 243us/step - loss: 66.8959 - accuracy: 0.0000e+00 - val_loss: 100.1652 - val_accuracy: 0.0000e+00\n",
      "Epoch 1687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8101 - accuracy: 0.0000e+00 - val_loss: 86.0942 - val_accuracy: 0.0000e+00\n",
      "Epoch 1688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3187 - accuracy: 0.0156 - val_loss: 77.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 1689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.9634 - accuracy: 0.0000e+00 - val_loss: 76.4721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.0189 - accuracy: 0.0156 - val_loss: 88.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 1691/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.9473 - accuracy: 0.0000e+00 - val_loss: 97.1616 - val_accuracy: 0.0000e+00\n",
      "Epoch 1692/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.3426 - accuracy: 0.0000e+00 - val_loss: 92.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 1693/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.8909 - accuracy: 0.0000e+00 - val_loss: 81.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 1694/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 87.1375 - accuracy: 0.0000e+00 - val_loss: 70.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 1695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.2116 - accuracy: 0.0000e+00 - val_loss: 72.3910 - val_accuracy: 0.0000e+00\n",
      "Epoch 1696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8530 - accuracy: 0.0000e+00 - val_loss: 89.5992 - val_accuracy: 0.0000e+00\n",
      "Epoch 1697/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.1486 - accuracy: 0.0000e+00 - val_loss: 99.2291 - val_accuracy: 0.0000e+00\n",
      "Epoch 1698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2989 - accuracy: 0.0000e+00 - val_loss: 105.4240 - val_accuracy: 0.0000e+00\n",
      "Epoch 1699/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3435 - accuracy: 0.0000e+00 - val_loss: 103.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 1700/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.7433 - accuracy: 0.0000e+00 - val_loss: 96.2920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.5011 - accuracy: 0.0156 - val_loss: 96.5536 - val_accuracy: 0.0000e+00\n",
      "Epoch 1702/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.4894 - accuracy: 0.0312 - val_loss: 108.0187 - val_accuracy: 0.0000e+00\n",
      "Epoch 1703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4755 - accuracy: 0.0000e+00 - val_loss: 116.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 1704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1741 - accuracy: 0.0000e+00 - val_loss: 102.8830 - val_accuracy: 0.0000e+00\n",
      "Epoch 1705/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.1903 - accuracy: 0.0000e+00 - val_loss: 84.5857 - val_accuracy: 0.0000e+00\n",
      "Epoch 1706/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.8431 - accuracy: 0.0156 - val_loss: 84.0753 - val_accuracy: 0.0000e+00\n",
      "Epoch 1707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4838 - accuracy: 0.0000e+00 - val_loss: 84.9564 - val_accuracy: 0.0000e+00\n",
      "Epoch 1708/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 67.6289 - accuracy: 0.0000e+00 - val_loss: 95.7894 - val_accuracy: 0.0000e+00\n",
      "Epoch 1709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7915 - accuracy: 0.0156 - val_loss: 120.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1710/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3027 - accuracy: 0.0000e+00 - val_loss: 120.5347 - val_accuracy: 0.0000e+00\n",
      "Epoch 1711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2753 - accuracy: 0.0000e+00 - val_loss: 104.3027 - val_accuracy: 0.0588\n",
      "Epoch 1712/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 52.7159 - accuracy: 0.0000e+00 - val_loss: 80.8280 - val_accuracy: 0.0000e+00\n",
      "Epoch 1713/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 54.0830 - accuracy: 0.0000e+00 - val_loss: 80.1147 - val_accuracy: 0.0000e+00\n",
      "Epoch 1714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8136 - accuracy: 0.0156 - val_loss: 88.8413 - val_accuracy: 0.0000e+00\n",
      "Epoch 1715/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 52.1770 - accuracy: 0.0000e+00 - val_loss: 100.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1716/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5307 - accuracy: 0.0000e+00 - val_loss: 100.7349 - val_accuracy: 0.0000e+00\n",
      "Epoch 1717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9587 - accuracy: 0.0000e+00 - val_loss: 95.5231 - val_accuracy: 0.0000e+00\n",
      "Epoch 1718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2084 - accuracy: 0.0000e+00 - val_loss: 93.3175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1719/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.6618 - accuracy: 0.0156 - val_loss: 80.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 1720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0759 - accuracy: 0.0156 - val_loss: 78.7222 - val_accuracy: 0.0000e+00\n",
      "Epoch 1721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.7479 - accuracy: 0.0156 - val_loss: 87.8352 - val_accuracy: 0.0588\n",
      "Epoch 1722/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 38.9997 - accuracy: 0.0000e+00 - val_loss: 104.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 1723/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.5678 - accuracy: 0.0000e+00 - val_loss: 124.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 1724/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 60.5503 - accuracy: 0.0156 - val_loss: 104.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.6063 - accuracy: 0.0000e+00 - val_loss: 82.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 1726/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.8163 - accuracy: 0.0000e+00 - val_loss: 77.7424 - val_accuracy: 0.0000e+00\n",
      "Epoch 1727/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 71.8022 - accuracy: 0.0156 - val_loss: 81.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 1728/10000\n",
      "64/64 [==============================] - 0s 227us/step - loss: 69.5029 - accuracy: 0.0156 - val_loss: 91.8786 - val_accuracy: 0.0588\n",
      "Epoch 1729/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 38.3530 - accuracy: 0.0000e+00 - val_loss: 99.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1730/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.9909 - accuracy: 0.0156 - val_loss: 93.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 1731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.4944 - accuracy: 0.0000e+00 - val_loss: 80.2671 - val_accuracy: 0.0588\n",
      "Epoch 1732/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 55.2904 - accuracy: 0.0000e+00 - val_loss: 76.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 1733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2544 - accuracy: 0.0000e+00 - val_loss: 78.2166 - val_accuracy: 0.0000e+00\n",
      "Epoch 1734/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 58.2914 - accuracy: 0.0000e+00 - val_loss: 90.4432 - val_accuracy: 0.0000e+00\n",
      "Epoch 1735/10000\n",
      "64/64 [==============================] - 0s 185us/step - loss: 51.2471 - accuracy: 0.0000e+00 - val_loss: 96.5457 - val_accuracy: 0.0588\n",
      "Epoch 1736/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 64.5556 - accuracy: 0.0000e+00 - val_loss: 96.3939 - val_accuracy: 0.0000e+00\n",
      "Epoch 1737/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.6208 - accuracy: 0.0156 - val_loss: 91.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3793 - accuracy: 0.0156 - val_loss: 85.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 1739/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 65.5605 - accuracy: 0.0156 - val_loss: 87.2405 - val_accuracy: 0.0000e+00\n",
      "Epoch 1740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.7896 - accuracy: 0.0000e+00 - val_loss: 96.1301 - val_accuracy: 0.0000e+00\n",
      "Epoch 1741/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.2496 - accuracy: 0.0000e+00 - val_loss: 103.1285 - val_accuracy: 0.0000e+00\n",
      "Epoch 1742/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0847 - accuracy: 0.0156 - val_loss: 96.8297 - val_accuracy: 0.0000e+00\n",
      "Epoch 1743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.2738 - accuracy: 0.0312 - val_loss: 80.7521 - val_accuracy: 0.0000e+00\n",
      "Epoch 1744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.5262 - accuracy: 0.0000e+00 - val_loss: 85.1731 - val_accuracy: 0.0588\n",
      "Epoch 1745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5310 - accuracy: 0.0000e+00 - val_loss: 102.8175 - val_accuracy: 0.0000e+00\n",
      "Epoch 1746/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0375 - accuracy: 0.0156 - val_loss: 114.3986 - val_accuracy: 0.0000e+00\n",
      "Epoch 1747/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 56.2388 - accuracy: 0.0000e+00 - val_loss: 113.2951 - val_accuracy: 0.0000e+00\n",
      "Epoch 1748/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.2222 - accuracy: 0.0156 - val_loss: 106.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 1749/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.3193 - accuracy: 0.0156 - val_loss: 89.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 1750/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 52.9028 - accuracy: 0.0156 - val_loss: 86.2035 - val_accuracy: 0.0000e+00\n",
      "Epoch 1751/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.9753 - accuracy: 0.0156 - val_loss: 87.5376 - val_accuracy: 0.0000e+00\n",
      "Epoch 1752/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.7903 - accuracy: 0.0156 - val_loss: 97.3716 - val_accuracy: 0.0000e+00\n",
      "Epoch 1753/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.6358 - accuracy: 0.0000e+00 - val_loss: 99.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 1754/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 53.6912 - accuracy: 0.0000e+00 - val_loss: 104.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 1755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9976 - accuracy: 0.0156 - val_loss: 99.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 1756/10000\n",
      "64/64 [==============================] - 0s 216us/step - loss: 53.7569 - accuracy: 0.0156 - val_loss: 84.9798 - val_accuracy: 0.0000e+00\n",
      "Epoch 1757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6675 - accuracy: 0.0156 - val_loss: 74.2738 - val_accuracy: 0.0000e+00\n",
      "Epoch 1758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3747 - accuracy: 0.0000e+00 - val_loss: 67.9981 - val_accuracy: 0.0000e+00\n",
      "Epoch 1759/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 68.5030 - accuracy: 0.0000e+00 - val_loss: 76.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 1760/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3674 - accuracy: 0.0000e+00 - val_loss: 92.5385 - val_accuracy: 0.0000e+00\n",
      "Epoch 1761/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0922 - accuracy: 0.0000e+00 - val_loss: 90.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 1762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1782 - accuracy: 0.0000e+00 - val_loss: 87.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 1763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 72.2861 - accuracy: 0.0000e+00 - val_loss: 80.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 1764/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.9352 - accuracy: 0.0000e+00 - val_loss: 81.9272 - val_accuracy: 0.0000e+00\n",
      "Epoch 1765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1480 - accuracy: 0.0000e+00 - val_loss: 87.1550 - val_accuracy: 0.0000e+00\n",
      "Epoch 1766/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 67.1688 - accuracy: 0.0000e+00 - val_loss: 90.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 1767/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 53.1320 - accuracy: 0.0156 - val_loss: 89.5676 - val_accuracy: 0.0588\n",
      "Epoch 1768/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8865 - accuracy: 0.0156 - val_loss: 88.7624 - val_accuracy: 0.0000e+00\n",
      "Epoch 1769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.9801 - accuracy: 0.0000e+00 - val_loss: 96.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 1770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7201 - accuracy: 0.0000e+00 - val_loss: 96.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 1771/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 85.4270 - accuracy: 0.0156 - val_loss: 99.6278 - val_accuracy: 0.0000e+00\n",
      "Epoch 1772/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 64.3877 - accuracy: 0.0156 - val_loss: 97.2353 - val_accuracy: 0.0000e+00\n",
      "Epoch 1773/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.8502 - accuracy: 0.0156 - val_loss: 90.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 1774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 77.8664 - accuracy: 0.0156 - val_loss: 85.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 1775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0830 - accuracy: 0.0000e+00 - val_loss: 84.7404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1776/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.0331 - accuracy: 0.0156 - val_loss: 85.9836 - val_accuracy: 0.0588\n",
      "Epoch 1777/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 46.9491 - accuracy: 0.0000e+00 - val_loss: 90.2825 - val_accuracy: 0.0000e+00\n",
      "Epoch 1778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7106 - accuracy: 0.0000e+00 - val_loss: 96.7737 - val_accuracy: 0.0000e+00\n",
      "Epoch 1779/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 70.7278 - accuracy: 0.0000e+00 - val_loss: 100.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 1780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.5869 - accuracy: 0.0000e+00 - val_loss: 94.9663 - val_accuracy: 0.0000e+00\n",
      "Epoch 1781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.6468 - accuracy: 0.0000e+00 - val_loss: 80.5053 - val_accuracy: 0.0000e+00\n",
      "Epoch 1782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 68.4515 - accuracy: 0.0156 - val_loss: 74.9606 - val_accuracy: 0.0000e+00\n",
      "Epoch 1783/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 64.2750 - accuracy: 0.0156 - val_loss: 84.1863 - val_accuracy: 0.0000e+00\n",
      "Epoch 1784/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.5682 - accuracy: 0.0156 - val_loss: 85.6722 - val_accuracy: 0.0000e+00\n",
      "Epoch 1785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.7966 - accuracy: 0.0000e+00 - val_loss: 91.5235 - val_accuracy: 0.0588\n",
      "Epoch 1786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8506 - accuracy: 0.0000e+00 - val_loss: 86.6954 - val_accuracy: 0.0588\n",
      "Epoch 1787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3729 - accuracy: 0.0000e+00 - val_loss: 81.3878 - val_accuracy: 0.0588\n",
      "Epoch 1788/10000\n",
      "64/64 [==============================] - 0s 213us/step - loss: 52.2524 - accuracy: 0.0000e+00 - val_loss: 78.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 1789/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 54.8013 - accuracy: 0.0000e+00 - val_loss: 82.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 1790/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8859 - accuracy: 0.0000e+00 - val_loss: 86.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 1791/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 55.7221 - accuracy: 0.0156 - val_loss: 96.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4047 - accuracy: 0.0000e+00 - val_loss: 94.8151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1793/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 66.0332 - accuracy: 0.0156 - val_loss: 93.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 1794/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.3358 - accuracy: 0.0000e+00 - val_loss: 87.3864 - val_accuracy: 0.0000e+00\n",
      "Epoch 1795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4245 - accuracy: 0.0000e+00 - val_loss: 85.4618 - val_accuracy: 0.0000e+00\n",
      "Epoch 1796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3638 - accuracy: 0.0156 - val_loss: 96.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 1797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.2717 - accuracy: 0.0000e+00 - val_loss: 104.2324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.0461 - accuracy: 0.0312 - val_loss: 89.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 1799/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 57.4624 - accuracy: 0.0000e+00 - val_loss: 74.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 1800/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 46.5889 - accuracy: 0.0156 - val_loss: 75.0731 - val_accuracy: 0.0000e+00\n",
      "Epoch 1801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1043 - accuracy: 0.0000e+00 - val_loss: 83.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.1094 - accuracy: 0.0000e+00 - val_loss: 91.3948 - val_accuracy: 0.0000e+00\n",
      "Epoch 1803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.1480 - accuracy: 0.0156 - val_loss: 101.6992 - val_accuracy: 0.0000e+00\n",
      "Epoch 1804/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.3157 - accuracy: 0.0312 - val_loss: 104.9503 - val_accuracy: 0.0588\n",
      "Epoch 1805/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2610 - accuracy: 0.0000e+00 - val_loss: 95.2697 - val_accuracy: 0.0000e+00\n",
      "Epoch 1806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5499 - accuracy: 0.0000e+00 - val_loss: 89.8809 - val_accuracy: 0.0000e+00\n",
      "Epoch 1807/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 51.8137 - accuracy: 0.0000e+00 - val_loss: 87.3540 - val_accuracy: 0.0000e+00\n",
      "Epoch 1808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3791 - accuracy: 0.0000e+00 - val_loss: 84.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 1809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4398 - accuracy: 0.0000e+00 - val_loss: 85.3492 - val_accuracy: 0.0000e+00\n",
      "Epoch 1810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.1566 - accuracy: 0.0000e+00 - val_loss: 81.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 1811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9853 - accuracy: 0.0000e+00 - val_loss: 78.9747 - val_accuracy: 0.0000e+00\n",
      "Epoch 1812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4198 - accuracy: 0.0156 - val_loss: 80.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 1813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.4160 - accuracy: 0.0156 - val_loss: 102.1330 - val_accuracy: 0.0588\n",
      "Epoch 1814/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8253 - accuracy: 0.0000e+00 - val_loss: 108.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 1815/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 75.8005 - accuracy: 0.0312 - val_loss: 97.4451 - val_accuracy: 0.0588\n",
      "Epoch 1816/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 56.0193 - accuracy: 0.0156 - val_loss: 85.2396 - val_accuracy: 0.0000e+00\n",
      "Epoch 1817/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 46.5892 - accuracy: 0.0000e+00 - val_loss: 80.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 1818/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 63.5668 - accuracy: 0.0000e+00 - val_loss: 86.1142 - val_accuracy: 0.0588\n",
      "Epoch 1819/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 65.4656 - accuracy: 0.0156 - val_loss: 96.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 1820/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.4490 - accuracy: 0.0469 - val_loss: 97.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 1821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.7280 - accuracy: 0.0000e+00 - val_loss: 94.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 1822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.7536 - accuracy: 0.0156 - val_loss: 81.4467 - val_accuracy: 0.0588\n",
      "Epoch 1823/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.0350 - accuracy: 0.0312 - val_loss: 84.7762 - val_accuracy: 0.0588\n",
      "Epoch 1824/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 63.4686 - accuracy: 0.0000e+00 - val_loss: 84.8120 - val_accuracy: 0.0588\n",
      "Epoch 1825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2656 - accuracy: 0.0000e+00 - val_loss: 90.2585 - val_accuracy: 0.0588\n",
      "Epoch 1826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5419 - accuracy: 0.0156 - val_loss: 98.1820 - val_accuracy: 0.0000e+00\n",
      "Epoch 1827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.2445 - accuracy: 0.0000e+00 - val_loss: 92.5449 - val_accuracy: 0.0000e+00\n",
      "Epoch 1828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.4802 - accuracy: 0.0000e+00 - val_loss: 92.1200 - val_accuracy: 0.0000e+00\n",
      "Epoch 1829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2204 - accuracy: 0.0000e+00 - val_loss: 98.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 1830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9909 - accuracy: 0.0000e+00 - val_loss: 96.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 1831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0380 - accuracy: 0.0469 - val_loss: 89.6673 - val_accuracy: 0.0000e+00\n",
      "Epoch 1832/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 59.8638 - accuracy: 0.0156 - val_loss: 86.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 1833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6260 - accuracy: 0.0000e+00 - val_loss: 80.3497 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1284 - accuracy: 0.0000e+00 - val_loss: 86.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 1835/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.5432 - accuracy: 0.0000e+00 - val_loss: 96.1655 - val_accuracy: 0.0000e+00\n",
      "Epoch 1836/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 64.5520 - accuracy: 0.0000e+00 - val_loss: 92.9854 - val_accuracy: 0.0000e+00\n",
      "Epoch 1837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5899 - accuracy: 0.0000e+00 - val_loss: 84.5026 - val_accuracy: 0.0588\n",
      "Epoch 1838/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 56.7222 - accuracy: 0.0000e+00 - val_loss: 73.4814 - val_accuracy: 0.0588\n",
      "Epoch 1839/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 59.8624 - accuracy: 0.0000e+00 - val_loss: 73.0497 - val_accuracy: 0.0588\n",
      "Epoch 1840/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2364 - accuracy: 0.0000e+00 - val_loss: 92.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 1841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4858 - accuracy: 0.0000e+00 - val_loss: 110.6705 - val_accuracy: 0.0000e+00\n",
      "Epoch 1842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6549 - accuracy: 0.0000e+00 - val_loss: 108.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 1843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9996 - accuracy: 0.0000e+00 - val_loss: 96.1557 - val_accuracy: 0.0000e+00\n",
      "Epoch 1844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5821 - accuracy: 0.0000e+00 - val_loss: 89.4179 - val_accuracy: 0.0588\n",
      "Epoch 1845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0553 - accuracy: 0.0156 - val_loss: 88.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 1846/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 65.6194 - accuracy: 0.0156 - val_loss: 94.6271 - val_accuracy: 0.0588\n",
      "Epoch 1847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8761 - accuracy: 0.0312 - val_loss: 107.7041 - val_accuracy: 0.0588\n",
      "Epoch 1848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1910 - accuracy: 0.0000e+00 - val_loss: 122.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 1849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5289 - accuracy: 0.0156 - val_loss: 123.1457 - val_accuracy: 0.0000e+00\n",
      "Epoch 1850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8538 - accuracy: 0.0000e+00 - val_loss: 100.5318 - val_accuracy: 0.0588\n",
      "Epoch 1851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6882 - accuracy: 0.0000e+00 - val_loss: 86.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 1852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9129 - accuracy: 0.0156 - val_loss: 82.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 1853/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4190 - accuracy: 0.0312 - val_loss: 84.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 1854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7355 - accuracy: 0.0000e+00 - val_loss: 92.1310 - val_accuracy: 0.0588\n",
      "Epoch 1855/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 47.6932 - accuracy: 0.0000e+00 - val_loss: 96.8869 - val_accuracy: 0.0588\n",
      "Epoch 1856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2845 - accuracy: 0.0156 - val_loss: 98.8459 - val_accuracy: 0.0588\n",
      "Epoch 1857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1180 - accuracy: 0.0000e+00 - val_loss: 100.9430 - val_accuracy: 0.0588\n",
      "Epoch 1858/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 61.1154 - accuracy: 0.0000e+00 - val_loss: 92.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1859/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 48.9359 - accuracy: 0.0000e+00 - val_loss: 90.2838 - val_accuracy: 0.0000e+00\n",
      "Epoch 1860/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.8490 - accuracy: 0.0000e+00 - val_loss: 93.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 1861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8439 - accuracy: 0.0000e+00 - val_loss: 97.2806 - val_accuracy: 0.0000e+00\n",
      "Epoch 1862/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.6001 - accuracy: 0.0000e+00 - val_loss: 95.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 1863/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.6027 - accuracy: 0.0156 - val_loss: 93.0610 - val_accuracy: 0.0588\n",
      "Epoch 1864/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 65.3778 - accuracy: 0.0000e+00 - val_loss: 99.2955 - val_accuracy: 0.0588\n",
      "Epoch 1865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1048 - accuracy: 0.0000e+00 - val_loss: 106.6160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.6971 - accuracy: 0.0000e+00 - val_loss: 109.5324 - val_accuracy: 0.0000e+00\n",
      "Epoch 1867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3881 - accuracy: 0.0312 - val_loss: 104.0721 - val_accuracy: 0.0000e+00\n",
      "Epoch 1868/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.2179 - accuracy: 0.031 - 0s 125us/step - loss: 49.2850 - accuracy: 0.0469 - val_loss: 91.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 1869/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 54.1641 - accuracy: 0.0156 - val_loss: 92.4674 - val_accuracy: 0.0588\n",
      "Epoch 1870/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.9353 - accuracy: 0.0000e+00 - val_loss: 85.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 1871/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.0972 - accuracy: 0.0156 - val_loss: 91.0233 - val_accuracy: 0.0588\n",
      "Epoch 1872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6191 - accuracy: 0.0000e+00 - val_loss: 91.6151 - val_accuracy: 0.0588\n",
      "Epoch 1873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4468 - accuracy: 0.0000e+00 - val_loss: 96.2569 - val_accuracy: 0.0000e+00\n",
      "Epoch 1874/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 52.4736 - accuracy: 0.0312 - val_loss: 90.7341 - val_accuracy: 0.0000e+00\n",
      "Epoch 1875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.3626 - accuracy: 0.0000e+00 - val_loss: 84.8433 - val_accuracy: 0.0588\n",
      "Epoch 1876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4210 - accuracy: 0.0000e+00 - val_loss: 78.3669 - val_accuracy: 0.0000e+00\n",
      "Epoch 1877/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2304 - accuracy: 0.0312 - val_loss: 72.4552 - val_accuracy: 0.0588\n",
      "Epoch 1878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.0953 - accuracy: 0.0000e+00 - val_loss: 74.9732 - val_accuracy: 0.0000e+00\n",
      "Epoch 1879/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 58.8609 - accuracy: 0.0000e+00 - val_loss: 94.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 1880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.7808 - accuracy: 0.0000e+00 - val_loss: 110.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 1881/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 64.9788 - accuracy: 0.0312 - val_loss: 95.5366 - val_accuracy: 0.0000e+00\n",
      "Epoch 1882/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.0045 - accuracy: 0.0000e+00 - val_loss: 82.9538 - val_accuracy: 0.0000e+00\n",
      "Epoch 1883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9398 - accuracy: 0.0000e+00 - val_loss: 83.3954 - val_accuracy: 0.0000e+00\n",
      "Epoch 1884/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0856 - accuracy: 0.0156 - val_loss: 90.7080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1885/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 57.1818 - accuracy: 0.0000e+00 - val_loss: 94.7759 - val_accuracy: 0.0000e+00\n",
      "Epoch 1886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6729 - accuracy: 0.0000e+00 - val_loss: 93.9934 - val_accuracy: 0.0588\n",
      "Epoch 1887/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.5129 - accuracy: 0.0312 - val_loss: 91.6025 - val_accuracy: 0.0000e+00\n",
      "Epoch 1888/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4879 - accuracy: 0.0000e+00 - val_loss: 86.7694 - val_accuracy: 0.0000e+00\n",
      "Epoch 1889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1425 - accuracy: 0.0000e+00 - val_loss: 86.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1013 - accuracy: 0.0000e+00 - val_loss: 91.2933 - val_accuracy: 0.0000e+00\n",
      "Epoch 1891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 82.0470 - accuracy: 0.0000e+00 - val_loss: 103.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 1892/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 55.3840 - accuracy: 0.0156 - val_loss: 105.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 1893/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.6867 - accuracy: 0.0312 - val_loss: 107.1000 - val_accuracy: 0.0000e+00\n",
      "Epoch 1894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5370 - accuracy: 0.0000e+00 - val_loss: 95.0602 - val_accuracy: 0.0000e+00\n",
      "Epoch 1895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5210 - accuracy: 0.0000e+00 - val_loss: 81.1431 - val_accuracy: 0.0000e+00\n",
      "Epoch 1896/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.8145 - accuracy: 0.0000e+00 - val_loss: 75.8453 - val_accuracy: 0.0000e+00\n",
      "Epoch 1897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6923 - accuracy: 0.0000e+00 - val_loss: 88.5328 - val_accuracy: 0.0000e+00\n",
      "Epoch 1898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0666 - accuracy: 0.0156 - val_loss: 95.6172 - val_accuracy: 0.0000e+00\n",
      "Epoch 1899/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.5584 - accuracy: 0.0156 - val_loss: 98.5768 - val_accuracy: 0.0588\n",
      "Epoch 1900/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 42.0628 - accuracy: 0.0156 - val_loss: 92.3320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1901/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.6900 - accuracy: 0.0000e+00 - val_loss: 89.1130 - val_accuracy: 0.0000e+00\n",
      "Epoch 1902/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 46.7216 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 51.3457 - accuracy: 0.0000e+00 - val_loss: 92.1695 - val_accuracy: 0.0000e+00\n",
      "Epoch 1903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2030 - accuracy: 0.0000e+00 - val_loss: 87.9781 - val_accuracy: 0.0000e+00\n",
      "Epoch 1904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2467 - accuracy: 0.0000e+00 - val_loss: 84.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 1905/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.5787 - accuracy: 0.0000e+00 - val_loss: 83.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 1906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2763 - accuracy: 0.0000e+00 - val_loss: 91.3200 - val_accuracy: 0.0000e+00\n",
      "Epoch 1907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9293 - accuracy: 0.0000e+00 - val_loss: 112.7712 - val_accuracy: 0.0000e+00\n",
      "Epoch 1908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.3183 - accuracy: 0.0000e+00 - val_loss: 101.8605 - val_accuracy: 0.0000e+00\n",
      "Epoch 1909/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.2696 - accuracy: 0.0000e+00 - val_loss: 84.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 1910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6994 - accuracy: 0.0312 - val_loss: 83.7098 - val_accuracy: 0.0000e+00\n",
      "Epoch 1911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8202 - accuracy: 0.0000e+00 - val_loss: 81.3507 - val_accuracy: 0.0000e+00\n",
      "Epoch 1912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5486 - accuracy: 0.0000e+00 - val_loss: 81.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 1913/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.8665 - accuracy: 0.0156 - val_loss: 84.2891 - val_accuracy: 0.0000e+00\n",
      "Epoch 1914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9548 - accuracy: 0.0000e+00 - val_loss: 90.1856 - val_accuracy: 0.0000e+00\n",
      "Epoch 1915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.6636 - accuracy: 0.0000e+00 - val_loss: 91.5356 - val_accuracy: 0.0000e+00\n",
      "Epoch 1916/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.5880 - accuracy: 0.0000e+00 - val_loss: 92.6772 - val_accuracy: 0.0000e+00\n",
      "Epoch 1917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6644 - accuracy: 0.0000e+00 - val_loss: 94.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 1918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.8105 - accuracy: 0.0000e+00 - val_loss: 87.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 1919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2308 - accuracy: 0.0000e+00 - val_loss: 77.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 1920/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.3931 - accuracy: 0.0156 - val_loss: 76.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 1921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9967 - accuracy: 0.0156 - val_loss: 76.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 1922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.7254 - accuracy: 0.0000e+00 - val_loss: 86.0897 - val_accuracy: 0.0000e+00\n",
      "Epoch 1923/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.7621 - accuracy: 0.0156 - val_loss: 85.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 1924/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0152 - accuracy: 0.0000e+00 - val_loss: 85.5672 - val_accuracy: 0.0000e+00\n",
      "Epoch 1925/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.6627 - accuracy: 0.0000e+00 - val_loss: 81.5826 - val_accuracy: 0.0000e+00\n",
      "Epoch 1926/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.3830 - accuracy: 0.0000e+00 - val_loss: 82.6680 - val_accuracy: 0.0000e+00\n",
      "Epoch 1927/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.8706 - accuracy: 0.0000e+00 - val_loss: 80.3186 - val_accuracy: 0.0000e+00\n",
      "Epoch 1928/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1496 - accuracy: 0.0312 - val_loss: 80.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 1929/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.7592 - accuracy: 0.0000e+00 - val_loss: 88.5487 - val_accuracy: 0.0000e+00\n",
      "Epoch 1930/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4685 - accuracy: 0.0000e+00 - val_loss: 99.8360 - val_accuracy: 0.0000e+00\n",
      "Epoch 1931/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3880 - accuracy: 0.0312 - val_loss: 104.2643 - val_accuracy: 0.0000e+00\n",
      "Epoch 1932/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.9194 - accuracy: 0.0000e+00 - val_loss: 93.6195 - val_accuracy: 0.0000e+00\n",
      "Epoch 1933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1323 - accuracy: 0.0000e+00 - val_loss: 80.3544 - val_accuracy: 0.0000e+00\n",
      "Epoch 1934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5259 - accuracy: 0.0000e+00 - val_loss: 73.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 1935/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1980 - accuracy: 0.0312 - val_loss: 79.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 1936/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 46.3243 - accuracy: 0.0156 - val_loss: 92.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 1937/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 52.8988 - accuracy: 0.0000e+00 - val_loss: 103.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 1938/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 124us/step - loss: 50.4147 - accuracy: 0.0156 - val_loss: 110.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 1939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8503 - accuracy: 0.0312 - val_loss: 104.7529 - val_accuracy: 0.0000e+00\n",
      "Epoch 1940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.3894 - accuracy: 0.0000e+00 - val_loss: 83.4019 - val_accuracy: 0.0000e+00\n",
      "Epoch 1941/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 64.7224 - accuracy: 0.0000e+00 - val_loss: 76.7271 - val_accuracy: 0.0000e+00\n",
      "Epoch 1942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 70.7025 - accuracy: 0.0000e+00 - val_loss: 91.0523 - val_accuracy: 0.0000e+00\n",
      "Epoch 1943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3090 - accuracy: 0.0156 - val_loss: 115.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 1944/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.0321 - accuracy: 0.0000e+00 - val_loss: 123.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 1945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1651 - accuracy: 0.0000e+00 - val_loss: 105.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 1946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6625 - accuracy: 0.0312 - val_loss: 83.0811 - val_accuracy: 0.0000e+00\n",
      "Epoch 1947/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.2620 - accuracy: 0.0000e+00 - val_loss: 75.2878 - val_accuracy: 0.0000e+00\n",
      "Epoch 1948/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.2201 - accuracy: 0.0000e+00 - val_loss: 71.8320 - val_accuracy: 0.0000e+00\n",
      "Epoch 1949/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.1624 - accuracy: 0.0000e+00 - val_loss: 71.6531 - val_accuracy: 0.0000e+00\n",
      "Epoch 1950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1676 - accuracy: 0.0000e+00 - val_loss: 79.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 1951/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2000 - accuracy: 0.0000e+00 - val_loss: 90.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 1952/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.2945 - accuracy: 0.0000e+00 - val_loss: 95.1001 - val_accuracy: 0.0000e+00\n",
      "Epoch 1953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1817 - accuracy: 0.0156 - val_loss: 88.7729 - val_accuracy: 0.0000e+00\n",
      "Epoch 1954/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.7119 - accuracy: 0.0312 - val_loss: 85.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 1955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0741 - accuracy: 0.0000e+00 - val_loss: 81.3480 - val_accuracy: 0.0588\n",
      "Epoch 1956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 79.8568 - accuracy: 0.0000e+00 - val_loss: 84.8246 - val_accuracy: 0.0000e+00\n",
      "Epoch 1957/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.6878 - accuracy: 0.0000e+00 - val_loss: 95.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 1958/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.6073 - accuracy: 0.0312 - val_loss: 99.3180 - val_accuracy: 0.0000e+00\n",
      "Epoch 1959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8858 - accuracy: 0.0000e+00 - val_loss: 86.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 1960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7281 - accuracy: 0.0000e+00 - val_loss: 72.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 1961/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.5848 - accuracy: 0.0000e+00 - val_loss: 74.5006 - val_accuracy: 0.0000e+00\n",
      "Epoch 1962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.3616 - accuracy: 0.0000e+00 - val_loss: 101.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 1963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1090 - accuracy: 0.0000e+00 - val_loss: 125.8895 - val_accuracy: 0.0000e+00\n",
      "Epoch 1964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3890 - accuracy: 0.0156 - val_loss: 118.1678 - val_accuracy: 0.0000e+00\n",
      "Epoch 1965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9503 - accuracy: 0.0000e+00 - val_loss: 95.9920 - val_accuracy: 0.0000e+00\n",
      "Epoch 1966/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.9999 - accuracy: 0.0000e+00 - val_loss: 89.0327 - val_accuracy: 0.0588\n",
      "Epoch 1967/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 75.7253 - accuracy: 0.0000e+00 - val_loss: 106.4359 - val_accuracy: 0.0000e+00\n",
      "Epoch 1968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1794 - accuracy: 0.0000e+00 - val_loss: 121.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 1969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 73.5827 - accuracy: 0.0000e+00 - val_loss: 131.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 1970/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 55.0974 - accuracy: 0.0312 - val_loss: 111.6700 - val_accuracy: 0.0000e+00\n",
      "Epoch 1971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.6520 - accuracy: 0.0000e+00 - val_loss: 87.0155 - val_accuracy: 0.0588\n",
      "Epoch 1972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.9573 - accuracy: 0.0000e+00 - val_loss: 80.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 1973/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.3971 - accuracy: 0.0156 - val_loss: 76.0427 - val_accuracy: 0.0000e+00\n",
      "Epoch 1974/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 82.7511 - accuracy: 0.0156 - val_loss: 81.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 1975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4202 - accuracy: 0.0000e+00 - val_loss: 87.5944 - val_accuracy: 0.0000e+00\n",
      "Epoch 1976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1586 - accuracy: 0.0000e+00 - val_loss: 85.8404 - val_accuracy: 0.0000e+00\n",
      "Epoch 1977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.7097 - accuracy: 0.0000e+00 - val_loss: 92.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 1978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8910 - accuracy: 0.0000e+00 - val_loss: 97.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 1979/10000\n",
      "64/64 [==============================] - 0s 258us/step - loss: 49.1122 - accuracy: 0.0000e+00 - val_loss: 102.5018 - val_accuracy: 0.0000e+00\n",
      "Epoch 1980/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.6161 - accuracy: 0.0000e+00 - val_loss: 98.9526 - val_accuracy: 0.0000e+00\n",
      "Epoch 1981/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.6768 - accuracy: 0.0000e+00 - val_loss: 90.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 1982/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 39.5370 - accuracy: 0.0156 - val_loss: 83.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 1983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6493 - accuracy: 0.0156 - val_loss: 80.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 1984/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 73.5542 - accuracy: 0.0000e+00 - val_loss: 86.0681 - val_accuracy: 0.0588\n",
      "Epoch 1985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4340 - accuracy: 0.0156 - val_loss: 109.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 1986/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 59.3694 - accuracy: 0.0000e+00 - val_loss: 128.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 1987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6595 - accuracy: 0.0156 - val_loss: 121.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 1988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9332 - accuracy: 0.0156 - val_loss: 98.5471 - val_accuracy: 0.0000e+00\n",
      "Epoch 1989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1972 - accuracy: 0.0000e+00 - val_loss: 87.7151 - val_accuracy: 0.0000e+00\n",
      "Epoch 1990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.0421 - accuracy: 0.0000e+00 - val_loss: 90.9662 - val_accuracy: 0.0000e+00\n",
      "Epoch 1991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.7242 - accuracy: 0.0156 - val_loss: 98.1451 - val_accuracy: 0.0588\n",
      "Epoch 1992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.6832 - accuracy: 0.0000e+00 - val_loss: 97.4739 - val_accuracy: 0.0588\n",
      "Epoch 1993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0204 - accuracy: 0.0000e+00 - val_loss: 96.3542 - val_accuracy: 0.0000e+00\n",
      "Epoch 1994/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 48.1650 - accuracy: 0.0156 - val_loss: 98.6735 - val_accuracy: 0.0000e+00\n",
      "Epoch 1995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8293 - accuracy: 0.0000e+00 - val_loss: 96.6480 - val_accuracy: 0.0000e+00\n",
      "Epoch 1996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6723 - accuracy: 0.0156 - val_loss: 94.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 1997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4580 - accuracy: 0.0000e+00 - val_loss: 94.5160 - val_accuracy: 0.0000e+00\n",
      "Epoch 1998/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 49.9886 - accuracy: 0.0000e+00 - val_loss: 90.8818 - val_accuracy: 0.0588\n",
      "Epoch 1999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3358 - accuracy: 0.0000e+00 - val_loss: 94.6700 - val_accuracy: 0.0588\n",
      "Epoch 2000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.4024 - accuracy: 0.0000e+00 - val_loss: 92.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 2001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0910 - accuracy: 0.0156 - val_loss: 93.5554 - val_accuracy: 0.0000e+00\n",
      "Epoch 2002/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 54.8498 - accuracy: 0.0000e+00 - val_loss: 98.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 2003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9065 - accuracy: 0.0000e+00 - val_loss: 99.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 2004/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 63.0215 - accuracy: 0.0000e+00 - val_loss: 99.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1433 - accuracy: 0.0000e+00 - val_loss: 91.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2006/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 48.7334 - accuracy: 0.0000e+00 - val_loss: 80.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2007/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 55.8248 - accuracy: 0.0000e+00 - val_loss: 68.9467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2008/10000\n",
      "64/64 [==============================] - 0s 185us/step - loss: 85.5239 - accuracy: 0.0000e+00 - val_loss: 74.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 2009/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 54.9928 - accuracy: 0.0000e+00 - val_loss: 84.2906 - val_accuracy: 0.0000e+00\n",
      "Epoch 2010/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.5461 - accuracy: 0.0000e+00 - val_loss: 83.7081 - val_accuracy: 0.0000e+00\n",
      "Epoch 2011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 55.7358 - accuracy: 0.0000e+00 - val_loss: 85.5967 - val_accuracy: 0.0000e+00\n",
      "Epoch 2012/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 51.3638 - accuracy: 0.0156 - val_loss: 87.9629 - val_accuracy: 0.0000e+00\n",
      "Epoch 2013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2920 - accuracy: 0.0000e+00 - val_loss: 85.2020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6370 - accuracy: 0.0000e+00 - val_loss: 79.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 2015/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 60.8512 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 65.1966 - accuracy: 0.0000e+00 - val_loss: 92.8911 - val_accuracy: 0.0000e+00\n",
      "Epoch 2016/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 57.5747 - accuracy: 0.0000e+00 - val_loss: 102.2088 - val_accuracy: 0.0000e+00\n",
      "Epoch 2017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5226 - accuracy: 0.0000e+00 - val_loss: 103.6869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.1337 - accuracy: 0.0000e+00 - val_loss: 102.7249 - val_accuracy: 0.0000e+00\n",
      "Epoch 2019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3964 - accuracy: 0.0000e+00 - val_loss: 101.0764 - val_accuracy: 0.0000e+00\n",
      "Epoch 2020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.4068 - accuracy: 0.0000e+00 - val_loss: 98.7020 - val_accuracy: 0.0000e+00\n",
      "Epoch 2021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4367 - accuracy: 0.0156 - val_loss: 85.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 2022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1053 - accuracy: 0.0156 - val_loss: 78.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 2023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5997 - accuracy: 0.0000e+00 - val_loss: 80.7120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1725 - accuracy: 0.0156 - val_loss: 87.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 2025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0019 - accuracy: 0.0000e+00 - val_loss: 93.0262 - val_accuracy: 0.0000e+00\n",
      "Epoch 2026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3455 - accuracy: 0.0156 - val_loss: 94.7468 - val_accuracy: 0.0000e+00\n",
      "Epoch 2027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2617 - accuracy: 0.0156 - val_loss: 87.9000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6197 - accuracy: 0.0000e+00 - val_loss: 87.1298 - val_accuracy: 0.0000e+00\n",
      "Epoch 2029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3861 - accuracy: 0.0156 - val_loss: 81.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 2030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0062 - accuracy: 0.0000e+00 - val_loss: 82.3531 - val_accuracy: 0.0000e+00\n",
      "Epoch 2031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0459 - accuracy: 0.0000e+00 - val_loss: 87.1576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.3662 - accuracy: 0.0000e+00 - val_loss: 94.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.1083 - accuracy: 0.0000e+00 - val_loss: 100.5453 - val_accuracy: 0.0000e+00\n",
      "Epoch 2034/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1453 - accuracy: 0.0000e+00 - val_loss: 99.4012 - val_accuracy: 0.0000e+00\n",
      "Epoch 2035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6244 - accuracy: 0.0156 - val_loss: 93.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 2036/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0726 - accuracy: 0.0000e+00 - val_loss: 86.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1054 - accuracy: 0.0000e+00 - val_loss: 88.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 2038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0913 - accuracy: 0.0000e+00 - val_loss: 88.9619 - val_accuracy: 0.0588\n",
      "Epoch 2039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3655 - accuracy: 0.0000e+00 - val_loss: 94.7369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2040/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5046 - accuracy: 0.0000e+00 - val_loss: 97.0788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2988 - accuracy: 0.0156 - val_loss: 91.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 2042/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 50.3342 - accuracy: 0.0000e+00 - val_loss: 84.4871 - val_accuracy: 0.0000e+00\n",
      "Epoch 2043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1916 - accuracy: 0.0156 - val_loss: 85.8448 - val_accuracy: 0.0588\n",
      "Epoch 2044/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1327 - accuracy: 0.0000e+00 - val_loss: 101.9268 - val_accuracy: 0.0588\n",
      "Epoch 2045/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.3944 - accuracy: 0.0000e+00 - val_loss: 114.8315 - val_accuracy: 0.0000e+00\n",
      "Epoch 2046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3709 - accuracy: 0.0000e+00 - val_loss: 114.5614 - val_accuracy: 0.0000e+00\n",
      "Epoch 2047/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.8410 - accuracy: 0.0000e+00 - val_loss: 104.7463 - val_accuracy: 0.0588\n",
      "Epoch 2048/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.5805 - accuracy: 0.0312 - val_loss: 85.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3023 - accuracy: 0.0000e+00 - val_loss: 90.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 2050/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.8277 - accuracy: 0.0000e+00 - val_loss: 113.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 2051/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.1654 - accuracy: 0.0156 - val_loss: 130.1583 - val_accuracy: 0.0000e+00\n",
      "Epoch 2052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8547 - accuracy: 0.0312 - val_loss: 122.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4155 - accuracy: 0.0000e+00 - val_loss: 97.2747 - val_accuracy: 0.0588\n",
      "Epoch 2054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.7859 - accuracy: 0.0000e+00 - val_loss: 84.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 2055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6397 - accuracy: 0.0000e+00 - val_loss: 85.5753 - val_accuracy: 0.0588\n",
      "Epoch 2056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3032 - accuracy: 0.0156 - val_loss: 96.0994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6839 - accuracy: 0.0000e+00 - val_loss: 107.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 2058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.6532 - accuracy: 0.0000e+00 - val_loss: 114.9651 - val_accuracy: 0.0000e+00\n",
      "Epoch 2059/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 57.7359 - accuracy: 0.0156 - val_loss: 98.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 2060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0426 - accuracy: 0.0000e+00 - val_loss: 79.1533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1177 - accuracy: 0.0000e+00 - val_loss: 75.6290 - val_accuracy: 0.0000e+00\n",
      "Epoch 2062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.5273 - accuracy: 0.0156 - val_loss: 77.7230 - val_accuracy: 0.0000e+00\n",
      "Epoch 2063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.5177 - accuracy: 0.0000e+00 - val_loss: 85.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 2064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0870 - accuracy: 0.0000e+00 - val_loss: 91.0610 - val_accuracy: 0.0000e+00\n",
      "Epoch 2065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8642 - accuracy: 0.0000e+00 - val_loss: 98.7648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5530 - accuracy: 0.0156 - val_loss: 100.3137 - val_accuracy: 0.0588\n",
      "Epoch 2067/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.0652 - accuracy: 0.0156 - val_loss: 88.3596 - val_accuracy: 0.0588\n",
      "Epoch 2068/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.5759 - accuracy: 0.0000e+00 - val_loss: 88.9033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.5883 - accuracy: 0.0000e+00 - val_loss: 93.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 2070/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 66.7724 - accuracy: 0.0000e+00 - val_loss: 103.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 2071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9337 - accuracy: 0.0000e+00 - val_loss: 99.3199 - val_accuracy: 0.0588\n",
      "Epoch 2072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2372 - accuracy: 0.0000e+00 - val_loss: 97.3198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8157 - accuracy: 0.0000e+00 - val_loss: 101.1252 - val_accuracy: 0.0000e+00\n",
      "Epoch 2074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.4727 - accuracy: 0.0000e+00 - val_loss: 110.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 2075/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 71.3298 - accuracy: 0.0156 - val_loss: 101.5196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6558 - accuracy: 0.0000e+00 - val_loss: 91.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 2077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5904 - accuracy: 0.0000e+00 - val_loss: 96.2680 - val_accuracy: 0.0000e+00\n",
      "Epoch 2078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6308 - accuracy: 0.0000e+00 - val_loss: 104.0073 - val_accuracy: 0.0588\n",
      "Epoch 2079/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 44.3990 - accuracy: 0.0000e+00 - val_loss: 97.8468 - val_accuracy: 0.0000e+00\n",
      "Epoch 2080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1771 - accuracy: 0.0000e+00 - val_loss: 88.6832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2081/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 44.4159 - accuracy: 0.0000e+00 - val_loss: 82.3836 - val_accuracy: 0.0000e+00\n",
      "Epoch 2082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6625 - accuracy: 0.0156 - val_loss: 95.7816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8071 - accuracy: 0.0000e+00 - val_loss: 117.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 2084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5487 - accuracy: 0.0000e+00 - val_loss: 122.5313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.8403 - accuracy: 0.0000e+00 - val_loss: 103.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 2086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2901 - accuracy: 0.0156 - val_loss: 83.2326 - val_accuracy: 0.0000e+00\n",
      "Epoch 2087/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 59.2605 - accuracy: 0.0000e+00 - val_loss: 80.7625 - val_accuracy: 0.0000e+00\n",
      "Epoch 2088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3790 - accuracy: 0.0000e+00 - val_loss: 90.1915 - val_accuracy: 0.0000e+00\n",
      "Epoch 2089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2884 - accuracy: 0.0000e+00 - val_loss: 94.8426 - val_accuracy: 0.0000e+00\n",
      "Epoch 2090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7322 - accuracy: 0.0000e+00 - val_loss: 86.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 2091/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 51.6034 - accuracy: 0.0000e+00 - val_loss: 83.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 2092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.2050 - accuracy: 0.0000e+00 - val_loss: 100.5975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.8086 - accuracy: 0.0000e+00 - val_loss: 121.3619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4392 - accuracy: 0.0000e+00 - val_loss: 121.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7376 - accuracy: 0.0000e+00 - val_loss: 95.2808 - val_accuracy: 0.0588\n",
      "Epoch 2096/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.9962 - accuracy: 0.0000e+00 - val_loss: 79.4377 - val_accuracy: 0.0000e+00\n",
      "Epoch 2097/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 52.5315 - accuracy: 0.0000e+00 - val_loss: 82.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2098/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 68.3714 - accuracy: 0.0000e+00 - val_loss: 108.2496 - val_accuracy: 0.0000e+00\n",
      "Epoch 2099/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.0850 - accuracy: 0.0000e+00 - val_loss: 115.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.5319 - accuracy: 0.0000e+00 - val_loss: 92.7271 - val_accuracy: 0.0588\n",
      "Epoch 2101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0197 - accuracy: 0.0000e+00 - val_loss: 79.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3691 - accuracy: 0.0312 - val_loss: 76.6868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.4436 - accuracy: 0.0156 - val_loss: 88.5677 - val_accuracy: 0.0588\n",
      "Epoch 2104/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 45.2813 - accuracy: 0.0000e+00 - val_loss: 101.5595 - val_accuracy: 0.0000e+00\n",
      "Epoch 2105/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2877 - accuracy: 0.0000e+00 - val_loss: 104.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1151 - accuracy: 0.0156 - val_loss: 95.8134 - val_accuracy: 0.0588\n",
      "Epoch 2107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7789 - accuracy: 0.0000e+00 - val_loss: 86.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 2108/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0420 - accuracy: 0.0156 - val_loss: 91.1813 - val_accuracy: 0.0000e+00\n",
      "Epoch 2109/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.2461 - accuracy: 0.0000e+00 - val_loss: 110.5816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.1075 - accuracy: 0.0000e+00 - val_loss: 116.6485 - val_accuracy: 0.0000e+00\n",
      "Epoch 2111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.5714 - accuracy: 0.0156 - val_loss: 99.8495 - val_accuracy: 0.0000e+00\n",
      "Epoch 2112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1057 - accuracy: 0.0156 - val_loss: 85.5774 - val_accuracy: 0.0000e+00\n",
      "Epoch 2113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5678 - accuracy: 0.0000e+00 - val_loss: 82.0419 - val_accuracy: 0.0000e+00\n",
      "Epoch 2114/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 52.9302 - accuracy: 0.0000e+00 - val_loss: 79.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8230 - accuracy: 0.0000e+00 - val_loss: 87.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2116/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 40.9914 - accuracy: 0.0156 - val_loss: 102.5497 - val_accuracy: 0.0588\n",
      "Epoch 2117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.3537 - accuracy: 0.0000e+00 - val_loss: 116.8929 - val_accuracy: 0.0000e+00\n",
      "Epoch 2118/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 51.6842 - accuracy: 0.0156 - val_loss: 112.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2119/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 38.6863 - accuracy: 0.0000e+00 - val_loss: 88.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 2120/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 63.0687 - accuracy: 0.0156 - val_loss: 71.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 2121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0278 - accuracy: 0.0000e+00 - val_loss: 72.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 2122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 76.6825 - accuracy: 0.0000e+00 - val_loss: 106.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 2123/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 66.9970 - accuracy: 0.0000e+00 - val_loss: 128.9579 - val_accuracy: 0.0000e+00\n",
      "Epoch 2124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 66.8599 - accuracy: 0.0000e+00 - val_loss: 120.8682 - val_accuracy: 0.0000e+00\n",
      "Epoch 2125/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2506 - accuracy: 0.0000e+00 - val_loss: 104.0418 - val_accuracy: 0.0588\n",
      "Epoch 2126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1894 - accuracy: 0.0156 - val_loss: 96.9807 - val_accuracy: 0.0588\n",
      "Epoch 2127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2889 - accuracy: 0.0000e+00 - val_loss: 99.7954 - val_accuracy: 0.0588\n",
      "Epoch 2128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6125 - accuracy: 0.0000e+00 - val_loss: 95.6273 - val_accuracy: 0.0588\n",
      "Epoch 2129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4920 - accuracy: 0.0000e+00 - val_loss: 96.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.2140 - accuracy: 0.0000e+00 - val_loss: 103.1973 - val_accuracy: 0.0000e+00\n",
      "Epoch 2131/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 45.6805 - accuracy: 0.0156 - val_loss: 100.3990 - val_accuracy: 0.0588\n",
      "Epoch 2132/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3790 - accuracy: 0.0000e+00 - val_loss: 90.9864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2133/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3021 - accuracy: 0.0156 - val_loss: 97.1188 - val_accuracy: 0.0000e+00\n",
      "Epoch 2134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5949 - accuracy: 0.0156 - val_loss: 99.8607 - val_accuracy: 0.0588\n",
      "Epoch 2135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5465 - accuracy: 0.0000e+00 - val_loss: 94.6976 - val_accuracy: 0.0588\n",
      "Epoch 2136/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.3645 - accuracy: 0.0000e+00 - val_loss: 87.6994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2137/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 43.2882 - accuracy: 0.0000e+00 - val_loss: 81.8460 - val_accuracy: 0.0000e+00\n",
      "Epoch 2138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1774 - accuracy: 0.0000e+00 - val_loss: 84.7511 - val_accuracy: 0.0588\n",
      "Epoch 2139/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 49.1784 - accuracy: 0.0000e+00 - val_loss: 102.0458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1979 - accuracy: 0.0312 - val_loss: 127.5569 - val_accuracy: 0.0000e+00\n",
      "Epoch 2141/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.5067 - accuracy: 0.0000e+00 - val_loss: 131.4715 - val_accuracy: 0.0588\n",
      "Epoch 2142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2952 - accuracy: 0.0156 - val_loss: 122.5558 - val_accuracy: 0.0000e+00\n",
      "Epoch 2143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7896 - accuracy: 0.0000e+00 - val_loss: 121.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1369 - accuracy: 0.0000e+00 - val_loss: 126.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 2145/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 60.2962 - accuracy: 0.0000e+00 - val_loss: 114.3383 - val_accuracy: 0.0000e+00\n",
      "Epoch 2146/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 55.5571 - accuracy: 0.0000e+00 - val_loss: 102.3612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2147/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 62.7589 - accuracy: 0.0000e+00 - val_loss: 101.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9184 - accuracy: 0.0000e+00 - val_loss: 116.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 2149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4737 - accuracy: 0.0000e+00 - val_loss: 121.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 2150/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 45.0756 - accuracy: 0.0000e+00 - val_loss: 109.5516 - val_accuracy: 0.0000e+00\n",
      "Epoch 2151/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3818 - accuracy: 0.0000e+00 - val_loss: 97.4021 - val_accuracy: 0.0588\n",
      "Epoch 2152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0984 - accuracy: 0.0000e+00 - val_loss: 91.4623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1033 - accuracy: 0.0000e+00 - val_loss: 97.2542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2154/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 53.6848 - accuracy: 0.0000e+00 - val_loss: 104.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 2155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 74.5997 - accuracy: 0.0000e+00 - val_loss: 111.6991 - val_accuracy: 0.0000e+00\n",
      "Epoch 2156/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.9068 - accuracy: 0.0156 - val_loss: 110.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 2157/10000\n",
      "64/64 [==============================] - 0s 213us/step - loss: 56.9797 - accuracy: 0.0312 - val_loss: 111.8793 - val_accuracy: 0.0588\n",
      "Epoch 2158/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2862 - accuracy: 0.0000e+00 - val_loss: 111.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 2159/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 50.2725 - accuracy: 0.0156 - val_loss: 110.8206 - val_accuracy: 0.0000e+00\n",
      "Epoch 2160/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 52.3084 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 46.7969 - accuracy: 0.0000e+00 - val_loss: 95.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2161/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.7153 - accuracy: 0.0156 - val_loss: 81.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 2162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9563 - accuracy: 0.0156 - val_loss: 90.3217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2163/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8920 - accuracy: 0.0000e+00 - val_loss: 112.5348 - val_accuracy: 0.0588\n",
      "Epoch 2164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9216 - accuracy: 0.0000e+00 - val_loss: 121.8403 - val_accuracy: 0.0000e+00\n",
      "Epoch 2165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.6207 - accuracy: 0.0156 - val_loss: 105.5281 - val_accuracy: 0.0588\n",
      "Epoch 2166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1204 - accuracy: 0.0000e+00 - val_loss: 92.4643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5708 - accuracy: 0.0000e+00 - val_loss: 91.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 2168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.5940 - accuracy: 0.0156 - val_loss: 102.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 2169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1465 - accuracy: 0.0156 - val_loss: 111.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 2170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.5353 - accuracy: 0.0000e+00 - val_loss: 118.6343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9008 - accuracy: 0.0156 - val_loss: 125.4272 - val_accuracy: 0.0000e+00\n",
      "Epoch 2172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4104 - accuracy: 0.0000e+00 - val_loss: 124.5212 - val_accuracy: 0.0000e+00\n",
      "Epoch 2173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1806 - accuracy: 0.0156 - val_loss: 108.7807 - val_accuracy: 0.0000e+00\n",
      "Epoch 2174/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 55.9812 - accuracy: 0.0156 - val_loss: 91.2697 - val_accuracy: 0.0588\n",
      "Epoch 2175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.3023 - accuracy: 0.0000e+00 - val_loss: 82.9531 - val_accuracy: 0.0588\n",
      "Epoch 2176/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.0975 - accuracy: 0.0312 - val_loss: 84.1840 - val_accuracy: 0.0588\n",
      "Epoch 2177/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.2123 - accuracy: 0.0000e+00 - val_loss: 97.3973 - val_accuracy: 0.0000e+00\n",
      "Epoch 2178/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 45.5778 - accuracy: 0.0000e+00 - val_loss: 113.3040 - val_accuracy: 0.0000e+00\n",
      "Epoch 2179/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.2583 - accuracy: 0.0000e+00 - val_loss: 126.8970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2180/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 61.4166 - accuracy: 0.0000e+00 - val_loss: 113.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 2181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5141 - accuracy: 0.0000e+00 - val_loss: 95.2327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9415 - accuracy: 0.0000e+00 - val_loss: 83.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1132 - accuracy: 0.0156 - val_loss: 94.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 2184/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.3744 - accuracy: 0.0469 - val_loss: 109.9247 - val_accuracy: 0.0588\n",
      "Epoch 2185/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 50.2271 - accuracy: 0.0000e+00 - val_loss: 124.2987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2186/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1396 - accuracy: 0.0000e+00 - val_loss: 124.6938 - val_accuracy: 0.0588\n",
      "Epoch 2187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.3481 - accuracy: 0.0000e+00 - val_loss: 109.8288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2188/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 44.1913 - accuracy: 0.0000e+00 - val_loss: 101.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 2189/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.5202 - accuracy: 0.0000e+00 - val_loss: 97.7685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.6977 - accuracy: 0.0000e+00 - val_loss: 106.5835 - val_accuracy: 0.0588\n",
      "Epoch 2191/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 49.3149 - accuracy: 0.0000e+00 - val_loss: 122.2924 - val_accuracy: 0.0000e+00\n",
      "Epoch 2192/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 68.8262 - accuracy: 0.0156 - val_loss: 130.1942 - val_accuracy: 0.0000e+00\n",
      "Epoch 2193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.7051 - accuracy: 0.0000e+00 - val_loss: 121.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 2194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4859 - accuracy: 0.0156 - val_loss: 107.9997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1627 - accuracy: 0.0000e+00 - val_loss: 109.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2196/10000\n",
      "64/64 [==============================] - 0s 230us/step - loss: 57.6870 - accuracy: 0.0000e+00 - val_loss: 102.3740 - val_accuracy: 0.0588\n",
      "Epoch 2197/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.1404 - accuracy: 0.0000e+00 - val_loss: 100.8011 - val_accuracy: 0.0588\n",
      "Epoch 2198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1880 - accuracy: 0.0000e+00 - val_loss: 110.2773 - val_accuracy: 0.0588\n",
      "Epoch 2199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0026 - accuracy: 0.0156 - val_loss: 111.9864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.2935 - accuracy: 0.0000e+00 - val_loss: 104.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 2201/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.0922 - accuracy: 0.0000e+00 - val_loss: 92.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7566 - accuracy: 0.0000e+00 - val_loss: 89.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 2203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3434 - accuracy: 0.0156 - val_loss: 100.2297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2204/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.7500 - accuracy: 0.0000e+00 - val_loss: 122.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 2205/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 51.1805 - accuracy: 0.0000e+00 - val_loss: 132.6764 - val_accuracy: 0.0000e+00\n",
      "Epoch 2206/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 43.4632 - accuracy: 0.0000e+00 - val_loss: 125.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 2207/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 52.8980 - accuracy: 0.0000e+00 - val_loss: 110.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0415 - accuracy: 0.0312 - val_loss: 107.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2209/10000\n",
      "64/64 [==============================] - 0s 205us/step - loss: 52.2974 - accuracy: 0.0000e+00 - val_loss: 109.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 2210/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 45.7648 - accuracy: 0.0156 - val_loss: 111.1840 - val_accuracy: 0.0000e+00\n",
      "Epoch 2211/10000\n",
      "64/64 [==============================] - 0s 181us/step - loss: 55.0482 - accuracy: 0.0000e+00 - val_loss: 100.6386 - val_accuracy: 0.0000e+00\n",
      "Epoch 2212/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 48.4330 - accuracy: 0.0000e+00 - val_loss: 102.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2213/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4478 - accuracy: 0.0000e+00 - val_loss: 107.8398 - val_accuracy: 0.0588\n",
      "Epoch 2214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0118 - accuracy: 0.0156 - val_loss: 109.0367 - val_accuracy: 0.0588\n",
      "Epoch 2215/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0996 - accuracy: 0.0000e+00 - val_loss: 104.4127 - val_accuracy: 0.0588\n",
      "Epoch 2216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9983 - accuracy: 0.0156 - val_loss: 107.7717 - val_accuracy: 0.0000e+00\n",
      "Epoch 2217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.0437 - accuracy: 0.0156 - val_loss: 112.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2218/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 39.6045 - accuracy: 0.0312 - val_loss: 108.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 2219/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 50.4744 - accuracy: 0.0000e+00 - val_loss: 106.4575 - val_accuracy: 0.0000e+00\n",
      "Epoch 2220/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 47.4021 - accuracy: 0.0000e+00 - val_loss: 102.2989 - val_accuracy: 0.0000e+00\n",
      "Epoch 2221/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 51.7418 - accuracy: 0.0156 - val_loss: 98.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 2222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.2010 - accuracy: 0.0000e+00 - val_loss: 103.1500 - val_accuracy: 0.0588\n",
      "Epoch 2223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2350 - accuracy: 0.0312 - val_loss: 104.2224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.9294 - accuracy: 0.0000e+00 - val_loss: 97.3131 - val_accuracy: 0.0000e+00\n",
      "Epoch 2225/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 43.8866 - accuracy: 0.0000e+00 - val_loss: 100.0787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2226/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.2063 - accuracy: 0.0000e+00 - val_loss: 90.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7235 - accuracy: 0.0000e+00 - val_loss: 86.8427 - val_accuracy: 0.0588\n",
      "Epoch 2228/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.0974 - accuracy: 0.0000e+00 - val_loss: 90.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2229/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 57.9713 - accuracy: 0.0000e+00 - val_loss: 98.9768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6852 - accuracy: 0.0000e+00 - val_loss: 100.5162 - val_accuracy: 0.0000e+00\n",
      "Epoch 2231/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 53.0170 - accuracy: 0.0000e+00 - val_loss: 102.6483 - val_accuracy: 0.0000e+00\n",
      "Epoch 2232/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5371 - accuracy: 0.0000e+00 - val_loss: 102.6891 - val_accuracy: 0.0000e+00\n",
      "Epoch 2233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1330 - accuracy: 0.0156 - val_loss: 98.1895 - val_accuracy: 0.0000e+00\n",
      "Epoch 2234/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 60.3249 - accuracy: 0.0000e+00 - val_loss: 97.0384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2235/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 42.3190 - accuracy: 0.0000e+00 - val_loss: 100.3234 - val_accuracy: 0.0000e+00\n",
      "Epoch 2236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7537 - accuracy: 0.0156 - val_loss: 99.4370 - val_accuracy: 0.0588\n",
      "Epoch 2237/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 47.4683 - accuracy: 0.0000e+00 - val_loss: 90.9499 - val_accuracy: 0.0588\n",
      "Epoch 2238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0259 - accuracy: 0.0000e+00 - val_loss: 90.2019 - val_accuracy: 0.0588\n",
      "Epoch 2239/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 40.5798 - accuracy: 0.0000e+00 - val_loss: 101.0958 - val_accuracy: 0.0588\n",
      "Epoch 2240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9160 - accuracy: 0.0000e+00 - val_loss: 111.7151 - val_accuracy: 0.0588\n",
      "Epoch 2241/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 53.4437 - accuracy: 0.0000e+00 - val_loss: 115.2385 - val_accuracy: 0.0000e+00\n",
      "Epoch 2242/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 64.2680 - accuracy: 0.0000e+00 - val_loss: 122.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 2243/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 38.2981 - accuracy: 0.0000e+00 - val_loss: 123.6592 - val_accuracy: 0.0000e+00\n",
      "Epoch 2244/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 49.3838 - accuracy: 0.0156 - val_loss: 120.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 2245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6948 - accuracy: 0.0000e+00 - val_loss: 112.7592 - val_accuracy: 0.0588\n",
      "Epoch 2246/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 47.6345 - accuracy: 0.0000e+00 - val_loss: 105.8575 - val_accuracy: 0.0000e+00\n",
      "Epoch 2247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6292 - accuracy: 0.0000e+00 - val_loss: 98.1597 - val_accuracy: 0.0000e+00\n",
      "Epoch 2248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9426 - accuracy: 0.0000e+00 - val_loss: 99.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0288 - accuracy: 0.0000e+00 - val_loss: 113.0652 - val_accuracy: 0.0588\n",
      "Epoch 2250/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 46.2494 - accuracy: 0.0000e+00 - val_loss: 122.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 2251/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 47.9707 - accuracy: 0.0312 - val_loss: 121.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 2252/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.6454 - accuracy: 0.0000e+00 - val_loss: 105.6500 - val_accuracy: 0.0000e+00\n",
      "Epoch 2253/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 56.0720 - accuracy: 0.0000e+00 - val_loss: 92.0236 - val_accuracy: 0.0588\n",
      "Epoch 2254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2417 - accuracy: 0.0000e+00 - val_loss: 85.2320 - val_accuracy: 0.0588\n",
      "Epoch 2255/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 62.2878 - accuracy: 0.0000e+00 - val_loss: 91.1877 - val_accuracy: 0.0588\n",
      "Epoch 2256/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 67.8192 - accuracy: 0.0312 - val_loss: 100.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.6656 - accuracy: 0.0000e+00 - val_loss: 113.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 2258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.8871 - accuracy: 0.0000e+00 - val_loss: 102.0384 - val_accuracy: 0.0588\n",
      "Epoch 2259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1175 - accuracy: 0.0000e+00 - val_loss: 85.1589 - val_accuracy: 0.0588\n",
      "Epoch 2260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0592 - accuracy: 0.0312 - val_loss: 77.8474 - val_accuracy: 0.0588\n",
      "Epoch 2261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6764 - accuracy: 0.0000e+00 - val_loss: 83.9707 - val_accuracy: 0.0000e+00\n",
      "Epoch 2262/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 46.5649 - accuracy: 0.0000e+00 - val_loss: 99.1542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 57.4200 - accuracy: 0.0156 - val_loss: 124.4047 - val_accuracy: 0.0000e+00\n",
      "Epoch 2264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.7200 - accuracy: 0.0156 - val_loss: 127.0684 - val_accuracy: 0.0000e+00\n",
      "Epoch 2265/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 40.2169 - accuracy: 0.0156 - val_loss: 113.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 2266/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.5522 - accuracy: 0.0312 - val_loss: 94.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 2267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6748 - accuracy: 0.0000e+00 - val_loss: 87.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 2268/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 49.1391 - accuracy: 0.0000e+00 - val_loss: 93.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 2269/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 58.1685 - accuracy: 0.0156 - val_loss: 99.4674 - val_accuracy: 0.0000e+00\n",
      "Epoch 2270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9703 - accuracy: 0.0156 - val_loss: 103.0433 - val_accuracy: 0.0000e+00\n",
      "Epoch 2271/10000\n",
      "64/64 [==============================] - 0s 59us/step - loss: 47.5907 - accuracy: 0.0000e+00 - val_loss: 113.4172 - val_accuracy: 0.0000e+00\n",
      "Epoch 2272/10000\n",
      "64/64 [==============================] - 0s 2us/step - loss: 47.2668 - accuracy: 0.0000e+00 - val_loss: 128.5689 - val_accuracy: 0.0000e+00\n",
      "Epoch 2273/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 57.0874 - accuracy: 0.0312 - val_loss: 125.4565 - val_accuracy: 0.0000e+00\n",
      "Epoch 2274/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 54.1164 - accuracy: 0.0000e+0 - 0s 96us/step - loss: 50.3370 - accuracy: 0.0000e+00 - val_loss: 109.4209 - val_accuracy: 0.0000e+00\n",
      "Epoch 2275/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 55.4810 - accuracy: 0.0469 - val_loss: 100.3336 - val_accuracy: 0.0588\n",
      "Epoch 2276/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 49.1475 - accuracy: 0.0000e+00 - val_loss: 105.2077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2277/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 42.3368 - accuracy: 0.0156 - val_loss: 103.5694 - val_accuracy: 0.0588\n",
      "Epoch 2278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7371 - accuracy: 0.0000e+00 - val_loss: 100.7903 - val_accuracy: 0.0588\n",
      "Epoch 2279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5478 - accuracy: 0.0156 - val_loss: 96.7410 - val_accuracy: 0.0588\n",
      "Epoch 2280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4891 - accuracy: 0.0000e+00 - val_loss: 93.4447 - val_accuracy: 0.0588\n",
      "Epoch 2281/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 53.5678 - accuracy: 0.0156 - val_loss: 101.4847 - val_accuracy: 0.0000e+00\n",
      "Epoch 2282/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 43.2855 - accuracy: 0.0000e+00 - val_loss: 97.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 2283/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 35.4973 - accuracy: 0.0156 - val_loss: 92.9592 - val_accuracy: 0.0000e+00\n",
      "Epoch 2284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6203 - accuracy: 0.0156 - val_loss: 102.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2285/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.8188 - accuracy: 0.0312 - val_loss: 106.8098 - val_accuracy: 0.0000e+00\n",
      "Epoch 2286/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.2577 - accuracy: 0.0156 - val_loss: 111.6550 - val_accuracy: 0.0000e+00\n",
      "Epoch 2287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0666 - accuracy: 0.0156 - val_loss: 102.7228 - val_accuracy: 0.0588\n",
      "Epoch 2288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8559 - accuracy: 0.0000e+00 - val_loss: 88.4133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7450 - accuracy: 0.0000e+00 - val_loss: 87.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.6776 - accuracy: 0.0000e+00 - val_loss: 114.1325 - val_accuracy: 0.0588\n",
      "Epoch 2291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3877 - accuracy: 0.0000e+00 - val_loss: 142.7544 - val_accuracy: 0.0000e+00\n",
      "Epoch 2292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1965 - accuracy: 0.0156 - val_loss: 134.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 2293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8396 - accuracy: 0.0000e+00 - val_loss: 107.4451 - val_accuracy: 0.0588\n",
      "Epoch 2294/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.9481 - accuracy: 0.0000e+00 - val_loss: 92.6024 - val_accuracy: 0.0000e+00\n",
      "Epoch 2295/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.2196 - accuracy: 0.0156 - val_loss: 93.5337 - val_accuracy: 0.0000e+00\n",
      "Epoch 2296/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.0312 - accuracy: 0.0156 - val_loss: 105.5644 - val_accuracy: 0.0000e+00\n",
      "Epoch 2297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5086 - accuracy: 0.0000e+00 - val_loss: 118.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2298/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1343 - accuracy: 0.0312 - val_loss: 127.1566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2299/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 64.5492 - accuracy: 0.0000e+00 - val_loss: 126.8177 - val_accuracy: 0.0000e+00\n",
      "Epoch 2300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9022 - accuracy: 0.0000e+00 - val_loss: 113.0197 - val_accuracy: 0.0588\n",
      "Epoch 2301/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 45.5422 - accuracy: 0.0000e+00 - val_loss: 98.1463 - val_accuracy: 0.0000e+00\n",
      "Epoch 2302/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 41.2255 - accuracy: 0.0156 - val_loss: 92.3570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.0740 - accuracy: 0.0000e+00 - val_loss: 99.1479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.3681 - accuracy: 0.0000e+00 - val_loss: 104.9583 - val_accuracy: 0.0000e+00\n",
      "Epoch 2305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.8784 - accuracy: 0.0156 - val_loss: 109.8103 - val_accuracy: 0.0000e+00\n",
      "Epoch 2306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9587 - accuracy: 0.0156 - val_loss: 113.2196 - val_accuracy: 0.0000e+00\n",
      "Epoch 2307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.2823 - accuracy: 0.0000e+00 - val_loss: 114.2053 - val_accuracy: 0.0000e+00\n",
      "Epoch 2308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8521 - accuracy: 0.0156 - val_loss: 115.1120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0205 - accuracy: 0.0000e+00 - val_loss: 111.6564 - val_accuracy: 0.0000e+00\n",
      "Epoch 2310/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.7244 - accuracy: 0.0000e+00 - val_loss: 105.9904 - val_accuracy: 0.0000e+00\n",
      "Epoch 2311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.6916 - accuracy: 0.0000e+00 - val_loss: 110.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2312/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.6154 - accuracy: 0.0156 - val_loss: 117.1712 - val_accuracy: 0.0000e+00\n",
      "Epoch 2313/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.8975 - accuracy: 0.0000e+00 - val_loss: 122.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2314/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 36.2267 - accuracy: 0.0000e+00 - val_loss: 108.9655 - val_accuracy: 0.0000e+00\n",
      "Epoch 2315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.1418 - accuracy: 0.0000e+00 - val_loss: 98.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 2316/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 61.3267 - accuracy: 0.0156 - val_loss: 94.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 2317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.9330 - accuracy: 0.0000e+00 - val_loss: 104.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 2318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.8582 - accuracy: 0.0000e+00 - val_loss: 116.4425 - val_accuracy: 0.0000e+00\n",
      "Epoch 2319/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.6683 - accuracy: 0.0000e+00 - val_loss: 116.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 2320/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 61.3561 - accuracy: 0.0156 - val_loss: 111.8521 - val_accuracy: 0.0588\n",
      "Epoch 2321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.1739 - accuracy: 0.0156 - val_loss: 117.3445 - val_accuracy: 0.0588\n",
      "Epoch 2322/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 39.6103 - accuracy: 0.0000e+00 - val_loss: 113.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 2323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2614 - accuracy: 0.0000e+00 - val_loss: 113.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2339 - accuracy: 0.0156 - val_loss: 105.7963 - val_accuracy: 0.0000e+00\n",
      "Epoch 2325/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 43.7751 - accuracy: 0.0000e+00 - val_loss: 107.8287 - val_accuracy: 0.0000e+00\n",
      "Epoch 2326/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.2970 - accuracy: 0.0312 - val_loss: 114.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 2327/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 54.6008 - accuracy: 0.0156 - val_loss: 115.5768 - val_accuracy: 0.0000e+00\n",
      "Epoch 2328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.0158 - accuracy: 0.0312 - val_loss: 102.3969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2329/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 63.7663 - accuracy: 0.0000e+00 - val_loss: 87.7636 - val_accuracy: 0.0000e+00\n",
      "Epoch 2330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2922 - accuracy: 0.0000e+00 - val_loss: 89.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 2331/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.3938 - accuracy: 0.0156 - val_loss: 108.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2332/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 46.1295 - accuracy: 0.0000e+00 - val_loss: 117.2258 - val_accuracy: 0.0588\n",
      "Epoch 2333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4958 - accuracy: 0.0312 - val_loss: 110.2004 - val_accuracy: 0.0000e+00\n",
      "Epoch 2334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4885 - accuracy: 0.0000e+00 - val_loss: 97.4490 - val_accuracy: 0.0000e+00\n",
      "Epoch 2335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7657 - accuracy: 0.0156 - val_loss: 92.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 2336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6065 - accuracy: 0.0000e+00 - val_loss: 92.9688 - val_accuracy: 0.0000e+00\n",
      "Epoch 2337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8987 - accuracy: 0.0000e+00 - val_loss: 100.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6592 - accuracy: 0.0312 - val_loss: 104.1503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2339/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.2431 - accuracy: 0.0156 - val_loss: 104.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 2340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3770 - accuracy: 0.0000e+00 - val_loss: 93.8209 - val_accuracy: 0.0000e+00\n",
      "Epoch 2341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8918 - accuracy: 0.0156 - val_loss: 84.0903 - val_accuracy: 0.0588\n",
      "Epoch 2342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4783 - accuracy: 0.0156 - val_loss: 88.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.3766 - accuracy: 0.0000e+00 - val_loss: 94.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6501 - accuracy: 0.0312 - val_loss: 105.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 2345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7182 - accuracy: 0.0000e+00 - val_loss: 116.7639 - val_accuracy: 0.0000e+00\n",
      "Epoch 2346/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 45.4137 - accuracy: 0.0000e+00 - val_loss: 111.9979 - val_accuracy: 0.0000e+00\n",
      "Epoch 2347/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 47.9798 - accuracy: 0.0156 - val_loss: 98.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 2348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1496 - accuracy: 0.0000e+00 - val_loss: 91.1806 - val_accuracy: 0.0000e+00\n",
      "Epoch 2349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6500 - accuracy: 0.0000e+00 - val_loss: 103.6648 - val_accuracy: 0.0000e+00\n",
      "Epoch 2350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.9465 - accuracy: 0.0000e+00 - val_loss: 126.3100 - val_accuracy: 0.0000e+00\n",
      "Epoch 2351/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0882 - accuracy: 0.0156 - val_loss: 124.8453 - val_accuracy: 0.0000e+00\n",
      "Epoch 2352/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 49.8745 - accuracy: 0.0000e+00 - val_loss: 105.2779 - val_accuracy: 0.0000e+00\n",
      "Epoch 2353/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1842 - accuracy: 0.0000e+00 - val_loss: 89.1199 - val_accuracy: 0.0000e+00\n",
      "Epoch 2354/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 172us/step - loss: 57.3754 - accuracy: 0.0000e+00 - val_loss: 97.8172 - val_accuracy: 0.0000e+00\n",
      "Epoch 2355/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 59.1074 - accuracy: 0.0156 - val_loss: 118.1985 - val_accuracy: 0.0588\n",
      "Epoch 2356/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.7900 - accuracy: 0.0156 - val_loss: 132.5498 - val_accuracy: 0.0000e+00\n",
      "Epoch 2357/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 41.1988 - accuracy: 0.0000e+00 - val_loss: 137.7097 - val_accuracy: 0.0000e+00\n",
      "Epoch 2358/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 46.3007 - accuracy: 0.0000e+00 - val_loss: 127.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 2359/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.0443 - accuracy: 0.0000e+00 - val_loss: 110.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 2360/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2897 - accuracy: 0.0000e+00 - val_loss: 97.5980 - val_accuracy: 0.0588\n",
      "Epoch 2361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5084 - accuracy: 0.0156 - val_loss: 92.4240 - val_accuracy: 0.0588\n",
      "Epoch 2362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.6147 - accuracy: 0.0000e+00 - val_loss: 104.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 2363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1157 - accuracy: 0.0156 - val_loss: 114.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 2364/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.1852 - accuracy: 0.0000e+00 - val_loss: 110.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2365/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8395 - accuracy: 0.0000e+00 - val_loss: 100.7206 - val_accuracy: 0.0000e+00\n",
      "Epoch 2366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1915 - accuracy: 0.0000e+00 - val_loss: 94.5971 - val_accuracy: 0.0588\n",
      "Epoch 2367/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 35.2060 - accuracy: 0.0000e+00 - val_loss: 98.4496 - val_accuracy: 0.0588\n",
      "Epoch 2368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0201 - accuracy: 0.0000e+00 - val_loss: 109.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 2369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5177 - accuracy: 0.0000e+00 - val_loss: 104.8714 - val_accuracy: 0.0588\n",
      "Epoch 2370/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.4969 - accuracy: 0.0000e+00 - val_loss: 93.8566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9731 - accuracy: 0.0000e+00 - val_loss: 94.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8078 - accuracy: 0.0000e+00 - val_loss: 105.9595 - val_accuracy: 0.0000e+00\n",
      "Epoch 2373/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 49.2634 - accuracy: 0.0156 - val_loss: 108.7282 - val_accuracy: 0.0588\n",
      "Epoch 2374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.1767 - accuracy: 0.0000e+00 - val_loss: 106.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 2375/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 43.8840 - accuracy: 0.0000e+00 - val_loss: 107.0861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2376/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 69.0915 - accuracy: 0.0000e+00 - val_loss: 116.2291 - val_accuracy: 0.0000e+00\n",
      "Epoch 2377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5113 - accuracy: 0.0000e+00 - val_loss: 130.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 2378/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5397 - accuracy: 0.0000e+00 - val_loss: 129.0645 - val_accuracy: 0.0000e+00\n",
      "Epoch 2379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4342 - accuracy: 0.0000e+00 - val_loss: 123.4369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2380/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 58.6467 - accuracy: 0.0000e+00 - val_loss: 116.6227 - val_accuracy: 0.0000e+00\n",
      "Epoch 2381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5920 - accuracy: 0.0000e+00 - val_loss: 119.4724 - val_accuracy: 0.0000e+00\n",
      "Epoch 2382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.4021 - accuracy: 0.0156 - val_loss: 127.0640 - val_accuracy: 0.0000e+00\n",
      "Epoch 2383/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 49.2735 - accuracy: 0.0000e+00 - val_loss: 131.2620 - val_accuracy: 0.0000e+00\n",
      "Epoch 2384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0715 - accuracy: 0.0156 - val_loss: 122.0418 - val_accuracy: 0.0000e+00\n",
      "Epoch 2385/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5428 - accuracy: 0.0000e+00 - val_loss: 119.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 2386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0913 - accuracy: 0.0000e+00 - val_loss: 106.5329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9583 - accuracy: 0.0000e+00 - val_loss: 94.1257 - val_accuracy: 0.0000e+00\n",
      "Epoch 2388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3244 - accuracy: 0.0000e+00 - val_loss: 93.6963 - val_accuracy: 0.0000e+00\n",
      "Epoch 2389/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.0562 - accuracy: 0.0000e+00 - val_loss: 99.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 2390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.0746 - accuracy: 0.0156 - val_loss: 107.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 2391/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 42.0918 - accuracy: 0.0156 - val_loss: 112.1901 - val_accuracy: 0.0000e+00\n",
      "Epoch 2392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.5945 - accuracy: 0.0156 - val_loss: 103.7567 - val_accuracy: 0.0000e+00\n",
      "Epoch 2393/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.0778 - accuracy: 0.0156 - val_loss: 105.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2394/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8236 - accuracy: 0.0000e+00 - val_loss: 104.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2395/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.8000 - accuracy: 0.0156 - val_loss: 109.8308 - val_accuracy: 0.0000e+00\n",
      "Epoch 2396/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5166 - accuracy: 0.0000e+00 - val_loss: 114.1977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2397/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0378 - accuracy: 0.0156 - val_loss: 121.3830 - val_accuracy: 0.0000e+00\n",
      "Epoch 2398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9398 - accuracy: 0.0156 - val_loss: 114.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 2399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9304 - accuracy: 0.0000e+00 - val_loss: 104.3349 - val_accuracy: 0.0000e+00\n",
      "Epoch 2400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3246 - accuracy: 0.0000e+00 - val_loss: 101.7663 - val_accuracy: 0.0000e+00\n",
      "Epoch 2401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.1290 - accuracy: 0.0156 - val_loss: 101.6390 - val_accuracy: 0.0000e+00\n",
      "Epoch 2402/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.4213 - accuracy: 0.0156 - val_loss: 107.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 2403/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 31.7096 - accuracy: 0.0156 - val_loss: 113.8374 - val_accuracy: 0.0588\n",
      "Epoch 2404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2955 - accuracy: 0.0000e+00 - val_loss: 109.3179 - val_accuracy: 0.0588\n",
      "Epoch 2405/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 45.5035 - accuracy: 0.0000e+00 - val_loss: 94.5983 - val_accuracy: 0.0000e+00\n",
      "Epoch 2406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0689 - accuracy: 0.0000e+00 - val_loss: 87.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 2407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3740 - accuracy: 0.0156 - val_loss: 89.7438 - val_accuracy: 0.0588\n",
      "Epoch 2408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1107 - accuracy: 0.0000e+00 - val_loss: 99.9074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7021 - accuracy: 0.0000e+00 - val_loss: 109.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 2410/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 39.2576 - accuracy: 0.0000e+00 - val_loss: 111.3660 - val_accuracy: 0.0000e+00\n",
      "Epoch 2411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.6003 - accuracy: 0.0000e+00 - val_loss: 101.4400 - val_accuracy: 0.0000e+00\n",
      "Epoch 2412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4917 - accuracy: 0.0000e+00 - val_loss: 89.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2413/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4989 - accuracy: 0.0156 - val_loss: 83.9554 - val_accuracy: 0.0000e+00\n",
      "Epoch 2414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.7575 - accuracy: 0.0000e+00 - val_loss: 82.6408 - val_accuracy: 0.0000e+00\n",
      "Epoch 2415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.4105 - accuracy: 0.0000e+00 - val_loss: 83.4512 - val_accuracy: 0.0000e+00\n",
      "Epoch 2416/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.7613 - accuracy: 0.0000e+00 - val_loss: 92.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 2417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8342 - accuracy: 0.0000e+00 - val_loss: 96.3033 - val_accuracy: 0.0000e+00\n",
      "Epoch 2418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3082 - accuracy: 0.0000e+00 - val_loss: 96.8508 - val_accuracy: 0.0588\n",
      "Epoch 2419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8412 - accuracy: 0.0156 - val_loss: 96.3465 - val_accuracy: 0.0588\n",
      "Epoch 2420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7091 - accuracy: 0.0469 - val_loss: 84.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 2421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9525 - accuracy: 0.0000e+00 - val_loss: 81.4611 - val_accuracy: 0.0000e+00\n",
      "Epoch 2422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0178 - accuracy: 0.0000e+00 - val_loss: 93.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 2423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9866 - accuracy: 0.0156 - val_loss: 114.4711 - val_accuracy: 0.0000e+00\n",
      "Epoch 2424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4802 - accuracy: 0.0156 - val_loss: 128.3816 - val_accuracy: 0.0588\n",
      "Epoch 2425/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.4179 - accuracy: 0.0312 - val_loss: 120.3735 - val_accuracy: 0.0588\n",
      "Epoch 2426/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.8360 - accuracy: 0.0000e+00 - val_loss: 105.0981 - val_accuracy: 0.0000e+00\n",
      "Epoch 2427/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.0665 - accuracy: 0.0000e+00 - val_loss: 100.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 2428/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 41.7365 - accuracy: 0.0000e+00 - val_loss: 103.8608 - val_accuracy: 0.0588\n",
      "Epoch 2429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.3673 - accuracy: 0.0000e+00 - val_loss: 105.9426 - val_accuracy: 0.0588\n",
      "Epoch 2430/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.2062 - accuracy: 0.0156 - val_loss: 105.5178 - val_accuracy: 0.0588\n",
      "Epoch 2431/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.3906 - accuracy: 0.0156 - val_loss: 112.7551 - val_accuracy: 0.0588\n",
      "Epoch 2432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.6491 - accuracy: 0.0312 - val_loss: 115.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4352 - accuracy: 0.0312 - val_loss: 111.9515 - val_accuracy: 0.0000e+00\n",
      "Epoch 2434/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 60.4534 - accuracy: 0.0156 - val_loss: 105.0111 - val_accuracy: 0.0000e+00\n",
      "Epoch 2435/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9841 - accuracy: 0.0156 - val_loss: 101.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 2436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9651 - accuracy: 0.0000e+00 - val_loss: 106.1759 - val_accuracy: 0.0000e+00\n",
      "Epoch 2437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.9718 - accuracy: 0.0156 - val_loss: 105.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2438/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.9971 - accuracy: 0.0000e+00 - val_loss: 99.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2439/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.6453 - accuracy: 0.0156 - val_loss: 102.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 2440/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 50.7958 - accuracy: 0.0469 - val_loss: 97.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 2441/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2919 - accuracy: 0.0000e+00 - val_loss: 94.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 2442/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.1508 - accuracy: 0.0000e+00 - val_loss: 98.4703 - val_accuracy: 0.0588\n",
      "Epoch 2443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4821 - accuracy: 0.0000e+00 - val_loss: 97.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 2444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3524 - accuracy: 0.0000e+00 - val_loss: 98.3237 - val_accuracy: 0.0000e+00\n",
      "Epoch 2445/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 53.6460 - accuracy: 0.0000e+00 - val_loss: 92.1056 - val_accuracy: 0.0588\n",
      "Epoch 2446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8544 - accuracy: 0.0000e+00 - val_loss: 85.7057 - val_accuracy: 0.0000e+00\n",
      "Epoch 2447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5340 - accuracy: 0.0000e+00 - val_loss: 95.3301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3117 - accuracy: 0.0000e+00 - val_loss: 106.5755 - val_accuracy: 0.0588\n",
      "Epoch 2449/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.1668 - accuracy: 0.0156 - val_loss: 112.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 2450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2131 - accuracy: 0.0000e+00 - val_loss: 109.9670 - val_accuracy: 0.0588\n",
      "Epoch 2451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4394 - accuracy: 0.0000e+00 - val_loss: 109.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 2452/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.1876 - accuracy: 0.0156 - val_loss: 115.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 2453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7183 - accuracy: 0.0000e+00 - val_loss: 114.4091 - val_accuracy: 0.0588\n",
      "Epoch 2454/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.8836 - accuracy: 0.0000e+00 - val_loss: 109.5537 - val_accuracy: 0.0588\n",
      "Epoch 2455/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.3316 - accuracy: 0.0156 - val_loss: 105.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1872 - accuracy: 0.0000e+00 - val_loss: 100.5706 - val_accuracy: 0.0588\n",
      "Epoch 2457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.3296 - accuracy: 0.0156 - val_loss: 100.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 2458/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 56.1443 - accuracy: 0.0000e+00 - val_loss: 128.2721 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0367 - accuracy: 0.0156 - val_loss: 148.6319 - val_accuracy: 0.0000e+00\n",
      "Epoch 2460/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.8829 - accuracy: 0.0000e+00 - val_loss: 133.3368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2461/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.9387 - accuracy: 0.0000e+00 - val_loss: 110.8150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7447 - accuracy: 0.0312 - val_loss: 100.6508 - val_accuracy: 0.0000e+00\n",
      "Epoch 2463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6050 - accuracy: 0.0000e+00 - val_loss: 93.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 2464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1213 - accuracy: 0.0000e+00 - val_loss: 88.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 2465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4846 - accuracy: 0.0000e+00 - val_loss: 94.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 2466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8993 - accuracy: 0.0312 - val_loss: 95.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 2467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8570 - accuracy: 0.0000e+00 - val_loss: 95.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 2468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2790 - accuracy: 0.0000e+00 - val_loss: 93.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 2469/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1168 - accuracy: 0.0156 - val_loss: 86.3070 - val_accuracy: 0.0000e+00\n",
      "Epoch 2470/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.2539 - accuracy: 0.0000e+00 - val_loss: 81.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 2471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2622 - accuracy: 0.0000e+00 - val_loss: 83.9412 - val_accuracy: 0.0000e+00\n",
      "Epoch 2472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2179 - accuracy: 0.0156 - val_loss: 91.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 2473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2678 - accuracy: 0.0156 - val_loss: 99.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2474/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 39.2119 - accuracy: 0.0156 - val_loss: 106.2389 - val_accuracy: 0.0000e+00\n",
      "Epoch 2475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.1880 - accuracy: 0.0000e+00 - val_loss: 103.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 2476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3570 - accuracy: 0.0156 - val_loss: 101.0686 - val_accuracy: 0.0588\n",
      "Epoch 2477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1324 - accuracy: 0.0156 - val_loss: 101.2002 - val_accuracy: 0.0588\n",
      "Epoch 2478/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 57.8623 - accuracy: 0.0000e+00 - val_loss: 99.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2145 - accuracy: 0.0000e+00 - val_loss: 103.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 2480/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 50.7890 - accuracy: 0.0000e+00 - val_loss: 106.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 2481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0500 - accuracy: 0.0156 - val_loss: 101.8910 - val_accuracy: 0.0000e+00\n",
      "Epoch 2482/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4727 - accuracy: 0.0000e+00 - val_loss: 92.1966 - val_accuracy: 0.0000e+00\n",
      "Epoch 2483/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 39.8777 - accuracy: 0.0000e+00 - val_loss: 97.3600 - val_accuracy: 0.0000e+00\n",
      "Epoch 2484/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 52.8270 - accuracy: 0.0156 - val_loss: 95.3644 - val_accuracy: 0.0000e+00\n",
      "Epoch 2485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0240 - accuracy: 0.0156 - val_loss: 102.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2486/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0445 - accuracy: 0.0000e+00 - val_loss: 112.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 2487/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2174 - accuracy: 0.0000e+00 - val_loss: 113.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 2488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.7751 - accuracy: 0.0156 - val_loss: 110.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 2489/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 54.5458 - accuracy: 0.0000e+00 - val_loss: 105.6060 - val_accuracy: 0.0588\n",
      "Epoch 2490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1875 - accuracy: 0.0000e+00 - val_loss: 97.7812 - val_accuracy: 0.0588\n",
      "Epoch 2491/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 51.3322 - accuracy: 0.0000e+00 - val_loss: 91.3777 - val_accuracy: 0.0000e+00\n",
      "Epoch 2492/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 49.8551 - accuracy: 0.0156 - val_loss: 104.7374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2493/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 54.4122 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 43.9676 - accuracy: 0.0000e+00 - val_loss: 117.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 2494/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 48.0303 - accuracy: 0.0000e+00 - val_loss: 117.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 2495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.2746 - accuracy: 0.0000e+00 - val_loss: 101.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 2496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7109 - accuracy: 0.0000e+00 - val_loss: 86.7068 - val_accuracy: 0.0000e+00\n",
      "Epoch 2497/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 62.2845 - accuracy: 0.0000e+00 - val_loss: 85.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 2498/10000\n",
      "64/64 [==============================] - 0s 243us/step - loss: 47.6252 - accuracy: 0.0000e+00 - val_loss: 90.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 2499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3470 - accuracy: 0.0000e+00 - val_loss: 93.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.3075 - accuracy: 0.0000e+00 - val_loss: 103.6304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2501/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 49.5404 - accuracy: 0.0000e+00 - val_loss: 106.0141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.8282 - accuracy: 0.0000e+00 - val_loss: 103.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 2503/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.7786 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 52.2226 - accuracy: 0.0000e+00 - val_loss: 96.2999 - val_accuracy: 0.0000e+00\n",
      "Epoch 2504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6941 - accuracy: 0.0000e+00 - val_loss: 87.2115 - val_accuracy: 0.0000e+00\n",
      "Epoch 2505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9682 - accuracy: 0.0000e+00 - val_loss: 86.2474 - val_accuracy: 0.0000e+00\n",
      "Epoch 2506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.2285 - accuracy: 0.0000e+00 - val_loss: 88.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 2507/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 48.0554 - accuracy: 0.0000e+00 - val_loss: 95.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 2508/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 38.2821 - accuracy: 0.0000e+00 - val_loss: 104.6466 - val_accuracy: 0.0000e+00\n",
      "Epoch 2509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4176 - accuracy: 0.0156 - val_loss: 113.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2510/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 44.7444 - accuracy: 0.0156 - val_loss: 114.2623 - val_accuracy: 0.0588\n",
      "Epoch 2511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.4767 - accuracy: 0.0000e+00 - val_loss: 106.0698 - val_accuracy: 0.0588\n",
      "Epoch 2512/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 33.9547 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 36.7932 - accuracy: 0.0000e+00 - val_loss: 100.8062 - val_accuracy: 0.0588\n",
      "Epoch 2513/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 43.9846 - accuracy: 0.0625 - val_loss: 89.2757 - val_accuracy: 0.0588\n",
      "Epoch 2514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5720 - accuracy: 0.0000e+00 - val_loss: 95.3897 - val_accuracy: 0.0000e+00\n",
      "Epoch 2515/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 28.8495 - accuracy: 0.0000e+00 - val_loss: 108.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 2516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.8428 - accuracy: 0.0000e+00 - val_loss: 107.1417 - val_accuracy: 0.0000e+00\n",
      "Epoch 2517/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 43.1358 - accuracy: 0.0000e+00 - val_loss: 95.5549 - val_accuracy: 0.0588\n",
      "Epoch 2518/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.4240 - accuracy: 0.0000e+00 - val_loss: 92.2935 - val_accuracy: 0.0000e+00\n",
      "Epoch 2519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3672 - accuracy: 0.0000e+00 - val_loss: 94.2686 - val_accuracy: 0.0000e+00\n",
      "Epoch 2520/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 41.4943 - accuracy: 0.0156 - val_loss: 100.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8090 - accuracy: 0.0000e+00 - val_loss: 114.1574 - val_accuracy: 0.0000e+00\n",
      "Epoch 2522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7339 - accuracy: 0.0000e+00 - val_loss: 119.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 2523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5722 - accuracy: 0.0156 - val_loss: 108.3504 - val_accuracy: 0.0000e+00\n",
      "Epoch 2524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2389 - accuracy: 0.0156 - val_loss: 91.2623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1708 - accuracy: 0.0000e+00 - val_loss: 98.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 2526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9402 - accuracy: 0.0000e+00 - val_loss: 117.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 2527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9812 - accuracy: 0.0000e+00 - val_loss: 135.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2528/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.9613 - accuracy: 0.0000e+00 - val_loss: 144.0448 - val_accuracy: 0.0000e+00\n",
      "Epoch 2529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.4735 - accuracy: 0.0156 - val_loss: 130.1826 - val_accuracy: 0.0588\n",
      "Epoch 2530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9292 - accuracy: 0.0000e+00 - val_loss: 114.3374 - val_accuracy: 0.0000e+00\n",
      "Epoch 2531/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.2528 - accuracy: 0.0000e+00 - val_loss: 101.0633 - val_accuracy: 0.0000e+00\n",
      "Epoch 2532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.9531 - accuracy: 0.0000e+00 - val_loss: 104.8977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.5212 - accuracy: 0.0156 - val_loss: 109.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2534/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.5982 - accuracy: 0.0000e+00 - val_loss: 101.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 2535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0671 - accuracy: 0.0000e+00 - val_loss: 98.0525 - val_accuracy: 0.0000e+00\n",
      "Epoch 2536/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 54.8138 - accuracy: 0.0000e+00 - val_loss: 100.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 2537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.8349 - accuracy: 0.0000e+00 - val_loss: 96.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 2538/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 55.9007 - accuracy: 0.0000e+00 - val_loss: 96.2932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2539/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 54.0236 - accuracy: 0.0156 - val_loss: 85.3879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9745 - accuracy: 0.0156 - val_loss: 73.6950 - val_accuracy: 0.0000e+00\n",
      "Epoch 2541/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 56.3372 - accuracy: 0.0000e+00 - val_loss: 66.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 2542/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 51.5204 - accuracy: 0.0000e+00 - val_loss: 74.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 2543/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.1463 - accuracy: 0.0156 - val_loss: 88.3732 - val_accuracy: 0.0588\n",
      "Epoch 2544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.9782 - accuracy: 0.0156 - val_loss: 94.9591 - val_accuracy: 0.0000e+00\n",
      "Epoch 2545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.2215 - accuracy: 0.0156 - val_loss: 89.8648 - val_accuracy: 0.0588\n",
      "Epoch 2546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.6087 - accuracy: 0.0000e+00 - val_loss: 80.6551 - val_accuracy: 0.0000e+00\n",
      "Epoch 2547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6052 - accuracy: 0.0312 - val_loss: 82.9986 - val_accuracy: 0.0000e+00\n",
      "Epoch 2548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0828 - accuracy: 0.0000e+00 - val_loss: 85.0588 - val_accuracy: 0.0000e+00\n",
      "Epoch 2549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7548 - accuracy: 0.0156 - val_loss: 87.4863 - val_accuracy: 0.0000e+00\n",
      "Epoch 2550/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 47.7167 - accuracy: 0.0000e+00 - val_loss: 94.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 2551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.8795 - accuracy: 0.0000e+00 - val_loss: 99.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 2552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7722 - accuracy: 0.0000e+00 - val_loss: 105.6904 - val_accuracy: 0.0588\n",
      "Epoch 2553/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6900 - accuracy: 0.0156 - val_loss: 104.1725 - val_accuracy: 0.0588\n",
      "Epoch 2554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0175 - accuracy: 0.0312 - val_loss: 95.3709 - val_accuracy: 0.0000e+00\n",
      "Epoch 2555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.0446 - accuracy: 0.0000e+00 - val_loss: 94.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 2556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0308 - accuracy: 0.0000e+00 - val_loss: 99.4383 - val_accuracy: 0.0000e+00\n",
      "Epoch 2557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5113 - accuracy: 0.0156 - val_loss: 104.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2420 - accuracy: 0.0000e+00 - val_loss: 99.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 2559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.7436 - accuracy: 0.0000e+00 - val_loss: 90.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2560/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.7478 - accuracy: 0.0156 - val_loss: 92.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 2561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3889 - accuracy: 0.0000e+00 - val_loss: 98.3266 - val_accuracy: 0.0000e+00\n",
      "Epoch 2562/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 57.5104 - accuracy: 0.0156 - val_loss: 98.7750 - val_accuracy: 0.0000e+00\n",
      "Epoch 2563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2443 - accuracy: 0.0156 - val_loss: 96.3357 - val_accuracy: 0.0000e+00\n",
      "Epoch 2564/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 41.6884 - accuracy: 0.0000e+00 - val_loss: 100.2731 - val_accuracy: 0.0000e+00\n",
      "Epoch 2565/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 43.7648 - accuracy: 0.0156 - val_loss: 102.1993 - val_accuracy: 0.0000e+00\n",
      "Epoch 2566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1882 - accuracy: 0.0000e+00 - val_loss: 100.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 2567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9116 - accuracy: 0.0000e+00 - val_loss: 93.7051 - val_accuracy: 0.0588\n",
      "Epoch 2568/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.8246 - accuracy: 0.0000e+00 - val_loss: 97.5492 - val_accuracy: 0.0000e+00\n",
      "Epoch 2569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4603 - accuracy: 0.0000e+00 - val_loss: 113.1710 - val_accuracy: 0.0000e+00\n",
      "Epoch 2570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6513 - accuracy: 0.0156 - val_loss: 123.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2571/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 43.5954 - accuracy: 0.0000e+00 - val_loss: 123.5456 - val_accuracy: 0.0000e+00\n",
      "Epoch 2572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7105 - accuracy: 0.0156 - val_loss: 106.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 2573/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 65.4808 - accuracy: 0.0156 - val_loss: 94.2861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2574/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 41.5436 - accuracy: 0.0000e+00 - val_loss: 103.3441 - val_accuracy: 0.0000e+00\n",
      "Epoch 2575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0166 - accuracy: 0.0000e+00 - val_loss: 111.2414 - val_accuracy: 0.0000e+00\n",
      "Epoch 2576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0050 - accuracy: 0.0000e+00 - val_loss: 114.9937 - val_accuracy: 0.0588\n",
      "Epoch 2577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0988 - accuracy: 0.0156 - val_loss: 115.2844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1005 - accuracy: 0.0000e+00 - val_loss: 102.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 2579/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 56.1368 - accuracy: 0.0156 - val_loss: 92.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 2580/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 43.6282 - accuracy: 0.0000e+00 - val_loss: 90.4971 - val_accuracy: 0.0000e+00\n",
      "Epoch 2581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3504 - accuracy: 0.0000e+00 - val_loss: 105.1825 - val_accuracy: 0.0000e+00\n",
      "Epoch 2582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4872 - accuracy: 0.0000e+00 - val_loss: 115.6807 - val_accuracy: 0.0000e+00\n",
      "Epoch 2583/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 59.5319 - accuracy: 0.0312 - val_loss: 116.5793 - val_accuracy: 0.0588\n",
      "Epoch 2584/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 43.8459 - accuracy: 0.0000e+00 - val_loss: 115.2918 - val_accuracy: 0.0000e+00\n",
      "Epoch 2585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2975 - accuracy: 0.0000e+00 - val_loss: 112.7802 - val_accuracy: 0.0000e+00\n",
      "Epoch 2586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8008 - accuracy: 0.0000e+00 - val_loss: 105.7965 - val_accuracy: 0.0000e+00\n",
      "Epoch 2587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4766 - accuracy: 0.0000e+00 - val_loss: 105.5241 - val_accuracy: 0.0000e+00\n",
      "Epoch 2588/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.4650 - accuracy: 0.0000e+00 - val_loss: 113.9323 - val_accuracy: 0.0588\n",
      "Epoch 2589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0524 - accuracy: 0.0000e+00 - val_loss: 119.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 2590/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 41.6031 - accuracy: 0.0000e+00 - val_loss: 112.8692 - val_accuracy: 0.0588\n",
      "Epoch 2591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3736 - accuracy: 0.0156 - val_loss: 103.6368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.7044 - accuracy: 0.0156 - val_loss: 95.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 2593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.4865 - accuracy: 0.0000e+00 - val_loss: 100.1201 - val_accuracy: 0.0588\n",
      "Epoch 2594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6460 - accuracy: 0.0312 - val_loss: 116.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 2595/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0649 - accuracy: 0.0000e+00 - val_loss: 119.0533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2863 - accuracy: 0.0000e+00 - val_loss: 103.9018 - val_accuracy: 0.0588\n",
      "Epoch 2597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4726 - accuracy: 0.0156 - val_loss: 98.6150 - val_accuracy: 0.0000e+00\n",
      "Epoch 2598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.9199 - accuracy: 0.0156 - val_loss: 96.7983 - val_accuracy: 0.0588\n",
      "Epoch 2599/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3465 - accuracy: 0.0000e+00 - val_loss: 102.1502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2600/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 40.8430 - accuracy: 0.0000e+00 - val_loss: 108.5620 - val_accuracy: 0.0000e+00\n",
      "Epoch 2601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0907 - accuracy: 0.0000e+00 - val_loss: 102.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 2602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.9657 - accuracy: 0.0000e+00 - val_loss: 98.4443 - val_accuracy: 0.0000e+00\n",
      "Epoch 2603/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8314 - accuracy: 0.0000e+00 - val_loss: 93.3264 - val_accuracy: 0.0000e+00\n",
      "Epoch 2604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 64.6593 - accuracy: 0.0156 - val_loss: 102.1463 - val_accuracy: 0.0000e+00\n",
      "Epoch 2605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8153 - accuracy: 0.0156 - val_loss: 114.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 2606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.1071 - accuracy: 0.0000e+00 - val_loss: 117.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 2607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7065 - accuracy: 0.0000e+00 - val_loss: 107.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 2608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6402 - accuracy: 0.0000e+00 - val_loss: 97.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 2609/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.2993 - accuracy: 0.0312 - val_loss: 94.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2610/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 38.0145 - accuracy: 0.0000e+00 - val_loss: 108.5626 - val_accuracy: 0.0000e+00\n",
      "Epoch 2611/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.8071 - accuracy: 0.0000e+00 - val_loss: 130.8533 - val_accuracy: 0.0000e+00\n",
      "Epoch 2612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0274 - accuracy: 0.0156 - val_loss: 134.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4715 - accuracy: 0.0000e+00 - val_loss: 126.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.7610 - accuracy: 0.0156 - val_loss: 121.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2615/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 33.3940 - accuracy: 0.0156 - val_loss: 117.6232 - val_accuracy: 0.0588\n",
      "Epoch 2616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6610 - accuracy: 0.0000e+00 - val_loss: 116.3495 - val_accuracy: 0.0588\n",
      "Epoch 2617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4774 - accuracy: 0.0156 - val_loss: 117.9922 - val_accuracy: 0.0000e+00\n",
      "Epoch 2618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0571 - accuracy: 0.0000e+00 - val_loss: 118.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 2619/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.9201 - accuracy: 0.0156 - val_loss: 118.6660 - val_accuracy: 0.0000e+00\n",
      "Epoch 2620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7074 - accuracy: 0.0156 - val_loss: 119.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 2621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.4682 - accuracy: 0.0000e+00 - val_loss: 110.9509 - val_accuracy: 0.0588\n",
      "Epoch 2622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4496 - accuracy: 0.0000e+00 - val_loss: 105.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3877 - accuracy: 0.0000e+00 - val_loss: 111.2294 - val_accuracy: 0.0000e+00\n",
      "Epoch 2624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5423 - accuracy: 0.0156 - val_loss: 114.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 2625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.4194 - accuracy: 0.0156 - val_loss: 105.5347 - val_accuracy: 0.0000e+00\n",
      "Epoch 2626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2335 - accuracy: 0.0312 - val_loss: 100.1788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2627/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.3257 - accuracy: 0.0000e+00 - val_loss: 100.6870 - val_accuracy: 0.0000e+00\n",
      "Epoch 2628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.7816 - accuracy: 0.0156 - val_loss: 105.1718 - val_accuracy: 0.0000e+00\n",
      "Epoch 2629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0344 - accuracy: 0.0000e+00 - val_loss: 110.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 2630/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.3776 - accuracy: 0.0156 - val_loss: 108.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 2631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8349 - accuracy: 0.0000e+00 - val_loss: 104.9615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9591 - accuracy: 0.0000e+00 - val_loss: 94.7510 - val_accuracy: 0.0000e+00\n",
      "Epoch 2633/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.2188 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 33.6883 - accuracy: 0.0000e+00 - val_loss: 84.2300 - val_accuracy: 0.0588\n",
      "Epoch 2634/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 49.3561 - accuracy: 0.0312 - val_loss: 91.1404 - val_accuracy: 0.0000e+00\n",
      "Epoch 2635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2824 - accuracy: 0.0000e+00 - val_loss: 101.0029 - val_accuracy: 0.0000e+00\n",
      "Epoch 2636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6710 - accuracy: 0.0156 - val_loss: 105.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 2637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6041 - accuracy: 0.0000e+00 - val_loss: 102.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 2638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.0893 - accuracy: 0.0000e+00 - val_loss: 101.9788 - val_accuracy: 0.0000e+00\n",
      "Epoch 2639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9244 - accuracy: 0.0000e+00 - val_loss: 99.8668 - val_accuracy: 0.0588\n",
      "Epoch 2640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5730 - accuracy: 0.0000e+00 - val_loss: 101.4485 - val_accuracy: 0.0588\n",
      "Epoch 2641/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0531 - accuracy: 0.0000e+00 - val_loss: 109.2602 - val_accuracy: 0.0588\n",
      "Epoch 2642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1588 - accuracy: 0.0000e+00 - val_loss: 119.1618 - val_accuracy: 0.0000e+00\n",
      "Epoch 2643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4097 - accuracy: 0.0000e+00 - val_loss: 121.4704 - val_accuracy: 0.0000e+00\n",
      "Epoch 2644/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 31.2571 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 37.1213 - accuracy: 0.0000e+00 - val_loss: 116.0423 - val_accuracy: 0.0000e+00\n",
      "Epoch 2645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8150 - accuracy: 0.0000e+00 - val_loss: 110.2673 - val_accuracy: 0.0000e+00\n",
      "Epoch 2646/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 45.8017 - accuracy: 0.0000e+00 - val_loss: 103.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 2647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7144 - accuracy: 0.0156 - val_loss: 112.7228 - val_accuracy: 0.0000e+00\n",
      "Epoch 2648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1426 - accuracy: 0.0000e+00 - val_loss: 122.2832 - val_accuracy: 0.0000e+00\n",
      "Epoch 2649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5769 - accuracy: 0.0000e+00 - val_loss: 124.8325 - val_accuracy: 0.0588\n",
      "Epoch 2650/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.6581 - accuracy: 0.0156 - val_loss: 119.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 2651/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4355 - accuracy: 0.0312 - val_loss: 109.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2266 - accuracy: 0.0000e+00 - val_loss: 100.3339 - val_accuracy: 0.0000e+00\n",
      "Epoch 2653/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 39.7621 - accuracy: 0.0000e+00 - val_loss: 103.0179 - val_accuracy: 0.0000e+00\n",
      "Epoch 2654/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1045 - accuracy: 0.0000e+00 - val_loss: 118.6365 - val_accuracy: 0.0000e+00\n",
      "Epoch 2655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.8714 - accuracy: 0.0156 - val_loss: 126.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 2656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0531 - accuracy: 0.0000e+00 - val_loss: 123.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 2657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1043 - accuracy: 0.0000e+00 - val_loss: 122.2044 - val_accuracy: 0.0588\n",
      "Epoch 2658/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 54.6477 - accuracy: 0.0156 - val_loss: 123.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 2659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4281 - accuracy: 0.0000e+00 - val_loss: 121.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 2660/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.7784 - accuracy: 0.0000e+00 - val_loss: 123.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 2661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.8629 - accuracy: 0.0312 - val_loss: 120.9433 - val_accuracy: 0.0588\n",
      "Epoch 2662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6827 - accuracy: 0.0000e+00 - val_loss: 114.0387 - val_accuracy: 0.0000e+00\n",
      "Epoch 2663/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6324 - accuracy: 0.0000e+00 - val_loss: 119.8144 - val_accuracy: 0.0588\n",
      "Epoch 2664/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9725 - accuracy: 0.0000e+00 - val_loss: 130.9869 - val_accuracy: 0.0000e+00\n",
      "Epoch 2665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8478 - accuracy: 0.0156 - val_loss: 134.9922 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8265 - accuracy: 0.0000e+00 - val_loss: 132.0217 - val_accuracy: 0.0000e+00\n",
      "Epoch 2667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.8858 - accuracy: 0.0156 - val_loss: 113.9455 - val_accuracy: 0.0000e+00\n",
      "Epoch 2668/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 34.6074 - accuracy: 0.0000e+00 - val_loss: 98.1341 - val_accuracy: 0.0588\n",
      "Epoch 2669/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 51.2090 - accuracy: 0.0156 - val_loss: 86.4985 - val_accuracy: 0.0000e+00\n",
      "Epoch 2670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8932 - accuracy: 0.0156 - val_loss: 88.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 2671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4534 - accuracy: 0.0000e+00 - val_loss: 94.3830 - val_accuracy: 0.0588\n",
      "Epoch 2672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3368 - accuracy: 0.0000e+00 - val_loss: 100.1055 - val_accuracy: 0.0588\n",
      "Epoch 2673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9747 - accuracy: 0.0000e+00 - val_loss: 107.2155 - val_accuracy: 0.0588\n",
      "Epoch 2674/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.1934 - accuracy: 0.0000e+00 - val_loss: 115.9987 - val_accuracy: 0.0000e+00\n",
      "Epoch 2675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2724 - accuracy: 0.0000e+00 - val_loss: 138.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2137 - accuracy: 0.0000e+00 - val_loss: 140.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 2677/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.8439 - accuracy: 0.0000e+00 - val_loss: 129.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 2678/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 44.8856 - accuracy: 0.0156 - val_loss: 122.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8830 - accuracy: 0.0000e+00 - val_loss: 134.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 2680/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.0264 - accuracy: 0.0156 - val_loss: 135.6302 - val_accuracy: 0.0000e+00\n",
      "Epoch 2681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2117 - accuracy: 0.0000e+00 - val_loss: 136.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2682/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.7972 - accuracy: 0.0000e+00 - val_loss: 129.2917 - val_accuracy: 0.0000e+00\n",
      "Epoch 2683/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 66.0293 - accuracy: 0.0156 - val_loss: 115.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 2684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8588 - accuracy: 0.0156 - val_loss: 108.2097 - val_accuracy: 0.0588\n",
      "Epoch 2685/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.0805 - accuracy: 0.0000e+00 - val_loss: 102.1643 - val_accuracy: 0.0588\n",
      "Epoch 2686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0355 - accuracy: 0.0156 - val_loss: 98.6180 - val_accuracy: 0.0588\n",
      "Epoch 2687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.0584 - accuracy: 0.0000e+00 - val_loss: 99.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2688/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 40.6570 - accuracy: 0.0156 - val_loss: 115.4861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7911 - accuracy: 0.0000e+00 - val_loss: 117.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 2690/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 43.1917 - accuracy: 0.0000e+00 - val_loss: 110.6635 - val_accuracy: 0.0000e+00\n",
      "Epoch 2691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8272 - accuracy: 0.0156 - val_loss: 113.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 2692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2173 - accuracy: 0.0156 - val_loss: 106.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5675 - accuracy: 0.0000e+00 - val_loss: 103.5468 - val_accuracy: 0.0588\n",
      "Epoch 2694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.5669 - accuracy: 0.0156 - val_loss: 108.1583 - val_accuracy: 0.0588\n",
      "Epoch 2695/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.7979 - accuracy: 0.0156 - val_loss: 114.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 2696/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.6839 - accuracy: 0.0000e+00 - val_loss: 113.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 2697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9300 - accuracy: 0.0156 - val_loss: 108.1957 - val_accuracy: 0.0000e+00\n",
      "Epoch 2698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2253 - accuracy: 0.0000e+00 - val_loss: 102.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 2699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.0914 - accuracy: 0.0156 - val_loss: 96.9861 - val_accuracy: 0.0588\n",
      "Epoch 2700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0350 - accuracy: 0.0156 - val_loss: 94.9668 - val_accuracy: 0.0588\n",
      "Epoch 2701/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 53.4425 - accuracy: 0.0000e+00 - val_loss: 95.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 2702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0581 - accuracy: 0.0000e+00 - val_loss: 98.8227 - val_accuracy: 0.0000e+00\n",
      "Epoch 2703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2894 - accuracy: 0.0000e+00 - val_loss: 105.2040 - val_accuracy: 0.0000e+00\n",
      "Epoch 2704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9934 - accuracy: 0.0000e+00 - val_loss: 114.8946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2705/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 48.2789 - accuracy: 0.0000e+00 - val_loss: 120.9993 - val_accuracy: 0.0000e+00\n",
      "Epoch 2706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9391 - accuracy: 0.0156 - val_loss: 124.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 2707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3045 - accuracy: 0.0156 - val_loss: 127.9757 - val_accuracy: 0.0000e+00\n",
      "Epoch 2708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1309 - accuracy: 0.0000e+00 - val_loss: 129.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2624 - accuracy: 0.0156 - val_loss: 119.2736 - val_accuracy: 0.0000e+00\n",
      "Epoch 2710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1392 - accuracy: 0.0000e+00 - val_loss: 110.7747 - val_accuracy: 0.0588\n",
      "Epoch 2711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6509 - accuracy: 0.0000e+00 - val_loss: 109.7873 - val_accuracy: 0.0588\n",
      "Epoch 2712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2209 - accuracy: 0.0156 - val_loss: 107.0777 - val_accuracy: 0.0000e+00\n",
      "Epoch 2713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3781 - accuracy: 0.0000e+00 - val_loss: 108.0953 - val_accuracy: 0.0000e+00\n",
      "Epoch 2714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5404 - accuracy: 0.0000e+00 - val_loss: 116.0444 - val_accuracy: 0.0000e+00\n",
      "Epoch 2715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3818 - accuracy: 0.0000e+00 - val_loss: 117.7175 - val_accuracy: 0.0000e+00\n",
      "Epoch 2716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.3209 - accuracy: 0.0000e+00 - val_loss: 105.3246 - val_accuracy: 0.0000e+00\n",
      "Epoch 2717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1959 - accuracy: 0.0000e+00 - val_loss: 94.3980 - val_accuracy: 0.0000e+00\n",
      "Epoch 2718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5656 - accuracy: 0.0000e+00 - val_loss: 96.5219 - val_accuracy: 0.0000e+00\n",
      "Epoch 2719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2670 - accuracy: 0.0000e+00 - val_loss: 99.5203 - val_accuracy: 0.0000e+00\n",
      "Epoch 2720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8658 - accuracy: 0.0000e+00 - val_loss: 106.5615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3042 - accuracy: 0.0312 - val_loss: 109.7725 - val_accuracy: 0.0588\n",
      "Epoch 2722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9656 - accuracy: 0.0156 - val_loss: 117.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 2723/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 35.3741 - accuracy: 0.0000e+00 - val_loss: 125.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2724/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.5031 - accuracy: 0.0000e+00 - val_loss: 126.7002 - val_accuracy: 0.0000e+00\n",
      "Epoch 2725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2258 - accuracy: 0.0000e+00 - val_loss: 113.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 2726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4550 - accuracy: 0.0000e+00 - val_loss: 118.7986 - val_accuracy: 0.0588\n",
      "Epoch 2727/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 41.0834 - accuracy: 0.0312 - val_loss: 120.8845 - val_accuracy: 0.0588\n",
      "Epoch 2728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1429 - accuracy: 0.0000e+00 - val_loss: 115.9061 - val_accuracy: 0.0588\n",
      "Epoch 2729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4309 - accuracy: 0.0000e+00 - val_loss: 114.9518 - val_accuracy: 0.0000e+00\n",
      "Epoch 2730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.4667 - accuracy: 0.0000e+00 - val_loss: 120.6729 - val_accuracy: 0.0000e+00\n",
      "Epoch 2731/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8847 - accuracy: 0.0156 - val_loss: 122.4846 - val_accuracy: 0.0000e+00\n",
      "Epoch 2732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6193 - accuracy: 0.0156 - val_loss: 122.7058 - val_accuracy: 0.0000e+00\n",
      "Epoch 2733/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 31.7004 - accuracy: 0.0000e+00 - val_loss: 114.3048 - val_accuracy: 0.0588\n",
      "Epoch 2734/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 61.8139 - accuracy: 0.0156 - val_loss: 113.1328 - val_accuracy: 0.0000e+00\n",
      "Epoch 2735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0234 - accuracy: 0.0000e+00 - val_loss: 124.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 2736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5099 - accuracy: 0.0156 - val_loss: 127.5517 - val_accuracy: 0.0000e+00\n",
      "Epoch 2737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.9771 - accuracy: 0.0156 - val_loss: 137.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2738/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 51.9019 - accuracy: 0.0312 - val_loss: 141.1163 - val_accuracy: 0.0000e+00\n",
      "Epoch 2739/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 40.9569 - accuracy: 0.0000e+00 - val_loss: 119.5069 - val_accuracy: 0.0000e+00\n",
      "Epoch 2740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.3283 - accuracy: 0.0000e+00 - val_loss: 103.2627 - val_accuracy: 0.0000e+00\n",
      "Epoch 2741/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2693 - accuracy: 0.0000e+00 - val_loss: 93.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 2742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6990 - accuracy: 0.0000e+00 - val_loss: 88.1888 - val_accuracy: 0.0000e+00\n",
      "Epoch 2743/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 55.8498 - accuracy: 0.0000e+00 - val_loss: 85.0041 - val_accuracy: 0.0000e+00\n",
      "Epoch 2744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9096 - accuracy: 0.0000e+00 - val_loss: 85.7619 - val_accuracy: 0.0000e+00\n",
      "Epoch 2745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9937 - accuracy: 0.0000e+00 - val_loss: 86.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 2746/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 42.4017 - accuracy: 0.0000e+00 - val_loss: 95.9735 - val_accuracy: 0.0000e+00\n",
      "Epoch 2747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3455 - accuracy: 0.0000e+00 - val_loss: 97.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 2748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7752 - accuracy: 0.0000e+00 - val_loss: 97.5630 - val_accuracy: 0.0000e+00\n",
      "Epoch 2749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1098 - accuracy: 0.0156 - val_loss: 98.5368 - val_accuracy: 0.0000e+00\n",
      "Epoch 2750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5235 - accuracy: 0.0156 - val_loss: 103.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 2751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5052 - accuracy: 0.0000e+00 - val_loss: 109.9682 - val_accuracy: 0.0000e+00\n",
      "Epoch 2752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3696 - accuracy: 0.0156 - val_loss: 124.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 2753/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.1887 - accuracy: 0.0000e+00 - val_loss: 123.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 2754/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 41.4132 - accuracy: 0.0156 - val_loss: 111.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 2755/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.6689 - accuracy: 0.0000e+00 - val_loss: 109.3847 - val_accuracy: 0.0000e+00\n",
      "Epoch 2756/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 44.3043 - accuracy: 0.0000e+00 - val_loss: 115.6301 - val_accuracy: 0.0000e+00\n",
      "Epoch 2757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7178 - accuracy: 0.0156 - val_loss: 112.6070 - val_accuracy: 0.0588\n",
      "Epoch 2758/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 41.9314 - accuracy: 0.0156 - val_loss: 115.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 2759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9131 - accuracy: 0.0156 - val_loss: 122.7827 - val_accuracy: 0.0588\n",
      "Epoch 2760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5777 - accuracy: 0.0156 - val_loss: 127.3297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.6270 - accuracy: 0.0000e+00 - val_loss: 124.2194 - val_accuracy: 0.0000e+00\n",
      "Epoch 2762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6853 - accuracy: 0.0000e+00 - val_loss: 120.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 2763/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 28.4189 - accuracy: 0.0156 - val_loss: 105.9496 - val_accuracy: 0.0000e+00\n",
      "Epoch 2764/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 45.6823 - accuracy: 0.0156 - val_loss: 94.3752 - val_accuracy: 0.0000e+00\n",
      "Epoch 2765/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 33.7618 - accuracy: 0.0312 - val_loss: 98.4677 - val_accuracy: 0.0000e+00\n",
      "Epoch 2766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 74.2808 - accuracy: 0.0156 - val_loss: 129.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 2767/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 49.9011 - accuracy: 0.0000e+00 - val_loss: 140.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 2768/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.3246 - accuracy: 0.0000e+00 - val_loss: 130.3438 - val_accuracy: 0.0000e+00\n",
      "Epoch 2769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5981 - accuracy: 0.0156 - val_loss: 117.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2770/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 35.1897 - accuracy: 0.0156 - val_loss: 108.5879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2771/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.6699 - accuracy: 0.0156 - val_loss: 114.0130 - val_accuracy: 0.0000e+00\n",
      "Epoch 2772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8078 - accuracy: 0.0000e+00 - val_loss: 125.9701 - val_accuracy: 0.0000e+00\n",
      "Epoch 2773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3724 - accuracy: 0.0000e+00 - val_loss: 132.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3684 - accuracy: 0.0156 - val_loss: 131.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 2775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4214 - accuracy: 0.0000e+00 - val_loss: 123.3143 - val_accuracy: 0.0000e+00\n",
      "Epoch 2776/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.5584 - accuracy: 0.0000e+00 - val_loss: 115.2524 - val_accuracy: 0.0588\n",
      "Epoch 2777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7701 - accuracy: 0.0000e+00 - val_loss: 112.8120 - val_accuracy: 0.0000e+00\n",
      "Epoch 2778/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 48.3259 - accuracy: 0.0000e+00 - val_loss: 115.9554 - val_accuracy: 0.0588\n",
      "Epoch 2779/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 51.1996 - accuracy: 0.0000e+00 - val_loss: 122.4477 - val_accuracy: 0.0000e+00\n",
      "Epoch 2780/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.3471 - accuracy: 0.0156 - val_loss: 122.9337 - val_accuracy: 0.0000e+00\n",
      "Epoch 2781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8480 - accuracy: 0.0000e+00 - val_loss: 117.6623 - val_accuracy: 0.0000e+00\n",
      "Epoch 2782/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.7827 - accuracy: 0.0000e+00 - val_loss: 121.5655 - val_accuracy: 0.0000e+00\n",
      "Epoch 2783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1970 - accuracy: 0.0156 - val_loss: 128.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 2784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.9900 - accuracy: 0.0000e+00 - val_loss: 128.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 2785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1166 - accuracy: 0.0312 - val_loss: 111.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 2786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2165 - accuracy: 0.0000e+00 - val_loss: 96.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 2787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.7349 - accuracy: 0.0000e+00 - val_loss: 92.2009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2788/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5534 - accuracy: 0.0000e+00 - val_loss: 99.4680 - val_accuracy: 0.0000e+00\n",
      "Epoch 2789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8543 - accuracy: 0.0156 - val_loss: 118.3965 - val_accuracy: 0.0000e+00\n",
      "Epoch 2790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.6115 - accuracy: 0.0000e+00 - val_loss: 127.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2791/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1178 - accuracy: 0.0156 - val_loss: 117.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 2792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0917 - accuracy: 0.0156 - val_loss: 110.3720 - val_accuracy: 0.0588\n",
      "Epoch 2793/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9993 - accuracy: 0.0000e+00 - val_loss: 112.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 2794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7280 - accuracy: 0.0156 - val_loss: 117.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 2795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1182 - accuracy: 0.0156 - val_loss: 119.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 2796/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 43.2982 - accuracy: 0.0000e+00 - val_loss: 117.7957 - val_accuracy: 0.0000e+00\n",
      "Epoch 2797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7927 - accuracy: 0.0000e+00 - val_loss: 116.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 2798/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 35.3699 - accuracy: 0.0000e+00 - val_loss: 112.6568 - val_accuracy: 0.0588\n",
      "Epoch 2799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4496 - accuracy: 0.0156 - val_loss: 107.4801 - val_accuracy: 0.0000e+00\n",
      "Epoch 2800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8642 - accuracy: 0.0000e+00 - val_loss: 110.0733 - val_accuracy: 0.0000e+00\n",
      "Epoch 2801/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.8822 - accuracy: 0.0000e+00 - val_loss: 118.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 2802/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.6013 - accuracy: 0.0000e+00 - val_loss: 128.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2803/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.0302 - accuracy: 0.0156 - val_loss: 122.0685 - val_accuracy: 0.0000e+00\n",
      "Epoch 2804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4614 - accuracy: 0.0000e+00 - val_loss: 116.8936 - val_accuracy: 0.0000e+00\n",
      "Epoch 2805/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.2837 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.9804 - accuracy: 0.0000e+00 - val_loss: 106.7503 - val_accuracy: 0.0000e+00\n",
      "Epoch 2806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1526 - accuracy: 0.0156 - val_loss: 106.5464 - val_accuracy: 0.0000e+00\n",
      "Epoch 2807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0689 - accuracy: 0.0000e+00 - val_loss: 110.3381 - val_accuracy: 0.0000e+00\n",
      "Epoch 2808/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.8306 - accuracy: 0.0312 - val_loss: 113.4948 - val_accuracy: 0.0588\n",
      "Epoch 2809/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.3001 - accuracy: 0.0000e+00 - val_loss: 119.2117 - val_accuracy: 0.0000e+00\n",
      "Epoch 2810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0911 - accuracy: 0.0000e+00 - val_loss: 114.0832 - val_accuracy: 0.0588\n",
      "Epoch 2811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1653 - accuracy: 0.0000e+00 - val_loss: 114.2273 - val_accuracy: 0.0588\n",
      "Epoch 2812/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.7263 - accuracy: 0.0156 - val_loss: 115.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 2813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.0953 - accuracy: 0.0156 - val_loss: 117.3461 - val_accuracy: 0.0000e+00\n",
      "Epoch 2814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1872 - accuracy: 0.0000e+00 - val_loss: 123.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 2815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7351 - accuracy: 0.0000e+00 - val_loss: 122.7959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3826 - accuracy: 0.0156 - val_loss: 118.2489 - val_accuracy: 0.0000e+00\n",
      "Epoch 2817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6057 - accuracy: 0.0000e+00 - val_loss: 119.7668 - val_accuracy: 0.0000e+00\n",
      "Epoch 2818/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.9210 - accuracy: 0.0000e+00 - val_loss: 126.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 2819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7068 - accuracy: 0.0156 - val_loss: 117.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 2820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5368 - accuracy: 0.0156 - val_loss: 100.6871 - val_accuracy: 0.0000e+00\n",
      "Epoch 2821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9746 - accuracy: 0.0156 - val_loss: 101.5634 - val_accuracy: 0.0000e+00\n",
      "Epoch 2822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2097 - accuracy: 0.0000e+00 - val_loss: 114.6962 - val_accuracy: 0.0000e+00\n",
      "Epoch 2823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.9047 - accuracy: 0.0000e+00 - val_loss: 124.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 2824/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 47.4392 - accuracy: 0.0000e+00 - val_loss: 124.8852 - val_accuracy: 0.0000e+00\n",
      "Epoch 2825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2038 - accuracy: 0.0000e+00 - val_loss: 108.5661 - val_accuracy: 0.0000e+00\n",
      "Epoch 2826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.7021 - accuracy: 0.0000e+00 - val_loss: 103.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 2827/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.4260 - accuracy: 0.0000e+00 - val_loss: 106.5299 - val_accuracy: 0.0000e+00\n",
      "Epoch 2828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1353 - accuracy: 0.0156 - val_loss: 124.2159 - val_accuracy: 0.0000e+00\n",
      "Epoch 2829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2169 - accuracy: 0.0000e+00 - val_loss: 129.7243 - val_accuracy: 0.0000e+00\n",
      "Epoch 2830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6648 - accuracy: 0.0156 - val_loss: 113.0940 - val_accuracy: 0.0000e+00\n",
      "Epoch 2831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7908 - accuracy: 0.0000e+00 - val_loss: 95.8643 - val_accuracy: 0.0000e+00\n",
      "Epoch 2832/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 79.2239 - accuracy: 0.0156 - val_loss: 94.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 2833/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 51.0249 - accuracy: 0.0156 - val_loss: 111.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 2834/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.5403 - accuracy: 0.0000e+00 - val_loss: 112.9937 - val_accuracy: 0.0000e+00\n",
      "Epoch 2835/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 45.9191 - accuracy: 0.0000e+00 - val_loss: 111.4411 - val_accuracy: 0.0000e+00\n",
      "Epoch 2836/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 52.6180 - accuracy: 0.0156 - val_loss: 103.8052 - val_accuracy: 0.0000e+00\n",
      "Epoch 2837/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 36.2535 - accuracy: 0.0000e+00 - val_loss: 99.4617 - val_accuracy: 0.0588\n",
      "Epoch 2838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0250 - accuracy: 0.0156 - val_loss: 100.2908 - val_accuracy: 0.0588\n",
      "Epoch 2839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1843 - accuracy: 0.0000e+00 - val_loss: 102.1607 - val_accuracy: 0.0588\n",
      "Epoch 2840/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 37.0679 - accuracy: 0.0000e+00 - val_loss: 111.8520 - val_accuracy: 0.0000e+00\n",
      "Epoch 2841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8956 - accuracy: 0.0156 - val_loss: 116.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.7528 - accuracy: 0.0000e+00 - val_loss: 119.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 2843/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 50.4758 - accuracy: 0.0000e+00 - val_loss: 128.9679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2844/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.5128 - accuracy: 0.0000e+00 - val_loss: 132.2404 - val_accuracy: 0.0000e+00\n",
      "Epoch 2845/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 55.9264 - accuracy: 0.0156 - val_loss: 126.9421 - val_accuracy: 0.0588\n",
      "Epoch 2846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3608 - accuracy: 0.0156 - val_loss: 109.0683 - val_accuracy: 0.0000e+00\n",
      "Epoch 2847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.0225 - accuracy: 0.0312 - val_loss: 92.5006 - val_accuracy: 0.0588\n",
      "Epoch 2848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 59.3388 - accuracy: 0.0000e+00 - val_loss: 98.1930 - val_accuracy: 0.0588\n",
      "Epoch 2849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2535 - accuracy: 0.0156 - val_loss: 121.6252 - val_accuracy: 0.0588\n",
      "Epoch 2850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1605 - accuracy: 0.0156 - val_loss: 135.7416 - val_accuracy: 0.0000e+00\n",
      "Epoch 2851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9455 - accuracy: 0.0156 - val_loss: 142.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 2852/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 38.1853 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 43.1169 - accuracy: 0.0000e+00 - val_loss: 132.7302 - val_accuracy: 0.0000e+00\n",
      "Epoch 2853/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 48.2525 - accuracy: 0.0000e+00 - val_loss: 119.4656 - val_accuracy: 0.0588\n",
      "Epoch 2854/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 41.2273 - accuracy: 0.0156 - val_loss: 108.3932 - val_accuracy: 0.0000e+00\n",
      "Epoch 2855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4528 - accuracy: 0.0156 - val_loss: 110.2049 - val_accuracy: 0.0588\n",
      "Epoch 2856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2188 - accuracy: 0.0156 - val_loss: 115.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 2857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 62.2867 - accuracy: 0.0000e+00 - val_loss: 118.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 2858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6191 - accuracy: 0.0000e+00 - val_loss: 115.4616 - val_accuracy: 0.0000e+00\n",
      "Epoch 2859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8823 - accuracy: 0.0000e+00 - val_loss: 113.4815 - val_accuracy: 0.0588\n",
      "Epoch 2860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1366 - accuracy: 0.0000e+00 - val_loss: 112.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 2861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2146 - accuracy: 0.0156 - val_loss: 114.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 2862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9108 - accuracy: 0.0156 - val_loss: 117.3598 - val_accuracy: 0.0000e+00\n",
      "Epoch 2863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0587 - accuracy: 0.0000e+00 - val_loss: 115.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 2864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4438 - accuracy: 0.0000e+00 - val_loss: 112.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 2865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.1114 - accuracy: 0.0000e+00 - val_loss: 115.7356 - val_accuracy: 0.0000e+00\n",
      "Epoch 2866/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.2627 - accuracy: 0.0312 - val_loss: 136.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 2867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4559 - accuracy: 0.0156 - val_loss: 130.8479 - val_accuracy: 0.0000e+00\n",
      "Epoch 2868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5242 - accuracy: 0.0000e+00 - val_loss: 107.6115 - val_accuracy: 0.0000e+00\n",
      "Epoch 2869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.8410 - accuracy: 0.0312 - val_loss: 99.2547 - val_accuracy: 0.0000e+00\n",
      "Epoch 2870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8835 - accuracy: 0.0000e+00 - val_loss: 98.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 2871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9171 - accuracy: 0.0000e+00 - val_loss: 105.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 2872/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.8100 - accuracy: 0.0156 - val_loss: 122.3163 - val_accuracy: 0.0588\n",
      "Epoch 2873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1831 - accuracy: 0.0000e+00 - val_loss: 128.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 2874/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 51.8562 - accuracy: 0.0312 - val_loss: 127.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 2875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2603 - accuracy: 0.0000e+00 - val_loss: 119.9783 - val_accuracy: 0.0000e+00\n",
      "Epoch 2876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.2674 - accuracy: 0.0156 - val_loss: 117.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 2877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8871 - accuracy: 0.0000e+00 - val_loss: 123.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 2878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5712 - accuracy: 0.0000e+00 - val_loss: 134.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 2879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.2414 - accuracy: 0.0156 - val_loss: 126.5653 - val_accuracy: 0.0000e+00\n",
      "Epoch 2880/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.1862 - accuracy: 0.0000e+00 - val_loss: 115.4605 - val_accuracy: 0.0588\n",
      "Epoch 2881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7307 - accuracy: 0.0000e+00 - val_loss: 104.9612 - val_accuracy: 0.0000e+00\n",
      "Epoch 2882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.9228 - accuracy: 0.0000e+00 - val_loss: 109.9949 - val_accuracy: 0.0000e+00\n",
      "Epoch 2883/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4955 - accuracy: 0.0156 - val_loss: 118.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 2884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5628 - accuracy: 0.0156 - val_loss: 125.3066 - val_accuracy: 0.0000e+00\n",
      "Epoch 2885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0200 - accuracy: 0.0156 - val_loss: 128.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 2886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6646 - accuracy: 0.0156 - val_loss: 111.6528 - val_accuracy: 0.0000e+00\n",
      "Epoch 2887/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.7686 - accuracy: 0.0156 - val_loss: 103.7820 - val_accuracy: 0.0000e+00\n",
      "Epoch 2888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4586 - accuracy: 0.0156 - val_loss: 107.1615 - val_accuracy: 0.0000e+00\n",
      "Epoch 2889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.1430 - accuracy: 0.0000e+00 - val_loss: 110.5155 - val_accuracy: 0.0000e+00\n",
      "Epoch 2890/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.3850 - accuracy: 0.0000e+00 - val_loss: 117.6297 - val_accuracy: 0.0000e+00\n",
      "Epoch 2891/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.8220 - accuracy: 0.0156 - val_loss: 121.0570 - val_accuracy: 0.0000e+00\n",
      "Epoch 2892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7349 - accuracy: 0.0000e+00 - val_loss: 127.9112 - val_accuracy: 0.0588\n",
      "Epoch 2893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7591 - accuracy: 0.0312 - val_loss: 129.9979 - val_accuracy: 0.0588\n",
      "Epoch 2894/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.1791 - accuracy: 0.0000e+00 - val_loss: 126.6844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0836 - accuracy: 0.0000e+00 - val_loss: 114.7864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9652 - accuracy: 0.0000e+00 - val_loss: 104.1989 - val_accuracy: 0.0000e+00\n",
      "Epoch 2897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.0980 - accuracy: 0.0000e+00 - val_loss: 99.6844 - val_accuracy: 0.0000e+00\n",
      "Epoch 2898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6247 - accuracy: 0.0000e+00 - val_loss: 111.6959 - val_accuracy: 0.0000e+00\n",
      "Epoch 2899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3067 - accuracy: 0.0000e+00 - val_loss: 116.5092 - val_accuracy: 0.0000e+00\n",
      "Epoch 2900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7110 - accuracy: 0.0000e+00 - val_loss: 121.6719 - val_accuracy: 0.0000e+00\n",
      "Epoch 2901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.8496 - accuracy: 0.0000e+00 - val_loss: 121.3939 - val_accuracy: 0.0588\n",
      "Epoch 2902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8847 - accuracy: 0.0000e+00 - val_loss: 128.3743 - val_accuracy: 0.0588\n",
      "Epoch 2903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5594 - accuracy: 0.0000e+00 - val_loss: 135.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 2904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9274 - accuracy: 0.0156 - val_loss: 140.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 2905/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6355 - accuracy: 0.0000e+00 - val_loss: 139.9658 - val_accuracy: 0.0000e+00\n",
      "Epoch 2906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6912 - accuracy: 0.0000e+00 - val_loss: 128.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 2907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5678 - accuracy: 0.0000e+00 - val_loss: 108.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 2908/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 47.8400 - accuracy: 0.0000e+00 - val_loss: 107.5919 - val_accuracy: 0.0000e+00\n",
      "Epoch 2909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7883 - accuracy: 0.0000e+00 - val_loss: 109.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 2910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4468 - accuracy: 0.0312 - val_loss: 116.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 2911/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 37.4460 - accuracy: 0.0000e+00 - val_loss: 119.4242 - val_accuracy: 0.0000e+00\n",
      "Epoch 2912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.7236 - accuracy: 0.0000e+00 - val_loss: 124.3538 - val_accuracy: 0.0000e+00\n",
      "Epoch 2913/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 48.1976 - accuracy: 0.0156 - val_loss: 125.6270 - val_accuracy: 0.0000e+00\n",
      "Epoch 2914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.9278 - accuracy: 0.0000e+00 - val_loss: 126.5414 - val_accuracy: 0.0000e+00\n",
      "Epoch 2915/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3698 - accuracy: 0.0156 - val_loss: 119.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 2916/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.7700 - accuracy: 0.0000e+00 - val_loss: 110.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 2917/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5206 - accuracy: 0.0156 - val_loss: 103.3183 - val_accuracy: 0.0000e+00\n",
      "Epoch 2918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.1560 - accuracy: 0.0000e+00 - val_loss: 97.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 2919/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 42.8514 - accuracy: 0.0000e+00 - val_loss: 103.9576 - val_accuracy: 0.0000e+00\n",
      "Epoch 2920/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 36.4228 - accuracy: 0.0156 - val_loss: 119.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2297 - accuracy: 0.0312 - val_loss: 134.1469 - val_accuracy: 0.0000e+00\n",
      "Epoch 2922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3258 - accuracy: 0.0156 - val_loss: 127.5565 - val_accuracy: 0.0000e+00\n",
      "Epoch 2923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5166 - accuracy: 0.0156 - val_loss: 120.1007 - val_accuracy: 0.0000e+00\n",
      "Epoch 2924/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1481 - accuracy: 0.0000e+00 - val_loss: 115.7946 - val_accuracy: 0.0000e+00\n",
      "Epoch 2925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7542 - accuracy: 0.0000e+00 - val_loss: 113.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 2926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8803 - accuracy: 0.0000e+00 - val_loss: 126.3861 - val_accuracy: 0.0000e+00\n",
      "Epoch 2927/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.6140 - accuracy: 0.0312 - val_loss: 136.4551 - val_accuracy: 0.0000e+00\n",
      "Epoch 2928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0910 - accuracy: 0.0156 - val_loss: 130.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 2929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3532 - accuracy: 0.0000e+00 - val_loss: 112.5142 - val_accuracy: 0.0000e+00\n",
      "Epoch 2930/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 55.9770 - accuracy: 0.0000e+00 - val_loss: 111.9818 - val_accuracy: 0.0588\n",
      "Epoch 2931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.1977 - accuracy: 0.0000e+00 - val_loss: 119.0504 - val_accuracy: 0.0588\n",
      "Epoch 2932/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 43.0395 - accuracy: 0.0000e+00 - val_loss: 125.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 2933/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 51.0803 - accuracy: 0.0312 - val_loss: 126.8014 - val_accuracy: 0.0000e+00\n",
      "Epoch 2934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1526 - accuracy: 0.0000e+00 - val_loss: 119.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 2935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4866 - accuracy: 0.0312 - val_loss: 113.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 2936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 65.8055 - accuracy: 0.0000e+00 - val_loss: 122.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8793 - accuracy: 0.0000e+00 - val_loss: 129.2450 - val_accuracy: 0.0000e+00\n",
      "Epoch 2938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4710 - accuracy: 0.0156 - val_loss: 139.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 2939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.4675 - accuracy: 0.0000e+00 - val_loss: 144.8236 - val_accuracy: 0.0000e+00\n",
      "Epoch 2940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 65.0356 - accuracy: 0.0000e+00 - val_loss: 130.6119 - val_accuracy: 0.0000e+00\n",
      "Epoch 2941/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.3148 - accuracy: 0.0000e+00 - val_loss: 117.3394 - val_accuracy: 0.0588\n",
      "Epoch 2942/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 62.1521 - accuracy: 0.0156 - val_loss: 121.5467 - val_accuracy: 0.0000e+00\n",
      "Epoch 2943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.9729 - accuracy: 0.0156 - val_loss: 127.0828 - val_accuracy: 0.0000e+00\n",
      "Epoch 2944/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 32.7131 - accuracy: 0.0156 - val_loss: 130.8941 - val_accuracy: 0.0000e+00\n",
      "Epoch 2945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2842 - accuracy: 0.0156 - val_loss: 128.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 2946/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 42.7986 - accuracy: 0.0156 - val_loss: 117.8969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5172 - accuracy: 0.0156 - val_loss: 108.4116 - val_accuracy: 0.0000e+00\n",
      "Epoch 2948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6185 - accuracy: 0.0156 - val_loss: 107.6591 - val_accuracy: 0.0588\n",
      "Epoch 2949/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.5010 - accuracy: 0.0156 - val_loss: 111.9297 - val_accuracy: 0.0588\n",
      "Epoch 2950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2278 - accuracy: 0.0000e+00 - val_loss: 116.5632 - val_accuracy: 0.0000e+00\n",
      "Epoch 2951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3745 - accuracy: 0.0000e+00 - val_loss: 118.0360 - val_accuracy: 0.0000e+00\n",
      "Epoch 2952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6773 - accuracy: 0.0000e+00 - val_loss: 121.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 2953/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.6746 - accuracy: 0.0000e+00 - val_loss: 120.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 2954/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 43.6828 - accuracy: 0.0000e+00 - val_loss: 118.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 2955/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7230 - accuracy: 0.0000e+00 - val_loss: 123.6603 - val_accuracy: 0.0000e+00\n",
      "Epoch 2956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1456 - accuracy: 0.0000e+00 - val_loss: 129.4005 - val_accuracy: 0.0000e+00\n",
      "Epoch 2957/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 43.4517 - accuracy: 0.0000e+00 - val_loss: 129.9032 - val_accuracy: 0.0000e+00\n",
      "Epoch 2958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5996 - accuracy: 0.0000e+00 - val_loss: 122.9545 - val_accuracy: 0.0000e+00\n",
      "Epoch 2959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0926 - accuracy: 0.0156 - val_loss: 115.3420 - val_accuracy: 0.0588\n",
      "Epoch 2960/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 56.9089 - accuracy: 0.0000e+00 - val_loss: 113.9546 - val_accuracy: 0.0000e+00\n",
      "Epoch 2961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.5750 - accuracy: 0.0156 - val_loss: 120.2482 - val_accuracy: 0.0000e+00\n",
      "Epoch 2962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3434 - accuracy: 0.0000e+00 - val_loss: 128.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 2963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1828 - accuracy: 0.0000e+00 - val_loss: 125.1502 - val_accuracy: 0.0000e+00\n",
      "Epoch 2964/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6309 - accuracy: 0.0000e+00 - val_loss: 115.9901 - val_accuracy: 0.0588\n",
      "Epoch 2965/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 46.7964 - accuracy: 0.0000e+00 - val_loss: 111.3275 - val_accuracy: 0.0000e+00\n",
      "Epoch 2966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4491 - accuracy: 0.0000e+00 - val_loss: 107.6157 - val_accuracy: 0.0000e+00\n",
      "Epoch 2967/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.5109 - accuracy: 0.0156 - val_loss: 109.3725 - val_accuracy: 0.0000e+00\n",
      "Epoch 2968/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.7603 - accuracy: 0.0000e+00 - val_loss: 114.6637 - val_accuracy: 0.0000e+00\n",
      "Epoch 2969/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.3386 - accuracy: 0.0156 - val_loss: 125.3826 - val_accuracy: 0.0000e+00\n",
      "Epoch 2970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5446 - accuracy: 0.0156 - val_loss: 140.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 2971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7468 - accuracy: 0.0156 - val_loss: 146.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 2972/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 37.8948 - accuracy: 0.0000e+00 - val_loss: 139.4872 - val_accuracy: 0.0000e+00\n",
      "Epoch 2973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1342 - accuracy: 0.0000e+00 - val_loss: 122.0997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.5700 - accuracy: 0.0156 - val_loss: 116.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 2975/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5788 - accuracy: 0.0000e+00 - val_loss: 116.9369 - val_accuracy: 0.0000e+00\n",
      "Epoch 2976/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 50.6994 - accuracy: 0.0000e+00 - val_loss: 122.4366 - val_accuracy: 0.0588\n",
      "Epoch 2977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8364 - accuracy: 0.0156 - val_loss: 127.1969 - val_accuracy: 0.0000e+00\n",
      "Epoch 2978/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 45.4937 - accuracy: 0.0156 - val_loss: 124.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 2979/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 59.2251 - accuracy: 0.0156 - val_loss: 125.8039 - val_accuracy: 0.0000e+00\n",
      "Epoch 2980/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 48.5768 - accuracy: 0.0000e+00 - val_loss: 123.7927 - val_accuracy: 0.0000e+00\n",
      "Epoch 2981/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 56.4083 - accuracy: 0.0469 - val_loss: 124.1828 - val_accuracy: 0.0000e+00\n",
      "Epoch 2982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9719 - accuracy: 0.0000e+00 - val_loss: 126.5175 - val_accuracy: 0.0000e+00\n",
      "Epoch 2983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9962 - accuracy: 0.0000e+00 - val_loss: 127.1879 - val_accuracy: 0.0000e+00\n",
      "Epoch 2984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3639 - accuracy: 0.0156 - val_loss: 127.9333 - val_accuracy: 0.0000e+00\n",
      "Epoch 2985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7262 - accuracy: 0.0000e+00 - val_loss: 121.3421 - val_accuracy: 0.0000e+00\n",
      "Epoch 2986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5438 - accuracy: 0.0156 - val_loss: 113.5256 - val_accuracy: 0.0000e+00\n",
      "Epoch 2987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5569 - accuracy: 0.0312 - val_loss: 115.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 2988/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 41.3640 - accuracy: 0.0000e+00 - val_loss: 116.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 2989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0268 - accuracy: 0.0000e+00 - val_loss: 114.8427 - val_accuracy: 0.0000e+00\n",
      "Epoch 2990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.1467 - accuracy: 0.0000e+00 - val_loss: 112.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 2991/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4245 - accuracy: 0.0000e+00 - val_loss: 117.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 2992/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 42.9170 - accuracy: 0.0156 - val_loss: 122.4594 - val_accuracy: 0.0588\n",
      "Epoch 2993/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.1438 - accuracy: 0.0156 - val_loss: 125.1486 - val_accuracy: 0.0000e+00\n",
      "Epoch 2994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4197 - accuracy: 0.0000e+00 - val_loss: 123.4451 - val_accuracy: 0.0588\n",
      "Epoch 2995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6181 - accuracy: 0.0312 - val_loss: 122.9945 - val_accuracy: 0.0588\n",
      "Epoch 2996/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 37.6168 - accuracy: 0.0156 - val_loss: 124.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 2997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.7287 - accuracy: 0.0000e+00 - val_loss: 121.5195 - val_accuracy: 0.0588\n",
      "Epoch 2998/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0958 - accuracy: 0.0000e+00 - val_loss: 118.7551 - val_accuracy: 0.0588\n",
      "Epoch 2999/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.5320 - accuracy: 0.0000e+00 - val_loss: 120.7692 - val_accuracy: 0.0588\n",
      "Epoch 3000/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 43.4916 - accuracy: 0.0156 - val_loss: 123.9329 - val_accuracy: 0.0000e+00\n",
      "Epoch 3001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3187 - accuracy: 0.0156 - val_loss: 123.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 3002/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6361 - accuracy: 0.0156 - val_loss: 123.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 3003/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8995 - accuracy: 0.0000e+00 - val_loss: 125.9347 - val_accuracy: 0.0588\n",
      "Epoch 3004/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7735 - accuracy: 0.0000e+00 - val_loss: 130.0230 - val_accuracy: 0.0588\n",
      "Epoch 3005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0592 - accuracy: 0.0000e+00 - val_loss: 126.2358 - val_accuracy: 0.0588\n",
      "Epoch 3006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0479 - accuracy: 0.0000e+00 - val_loss: 116.4515 - val_accuracy: 0.0588\n",
      "Epoch 3007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1182 - accuracy: 0.0156 - val_loss: 112.1770 - val_accuracy: 0.1176\n",
      "Epoch 3008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5395 - accuracy: 0.0156 - val_loss: 117.5612 - val_accuracy: 0.0000e+00\n",
      "Epoch 3009/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.2357 - accuracy: 0.0156 - val_loss: 122.0756 - val_accuracy: 0.0000e+00\n",
      "Epoch 3010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9877 - accuracy: 0.0000e+00 - val_loss: 116.7399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3011/10000\n",
      "64/64 [==============================] - 0s 52us/step - loss: 48.6586 - accuracy: 0.0000e+00 - val_loss: 111.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 3012/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 41.1274 - accuracy: 0.0000e+00 - val_loss: 108.5923 - val_accuracy: 0.0000e+00\n",
      "Epoch 3013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1399 - accuracy: 0.0156 - val_loss: 111.7234 - val_accuracy: 0.0000e+00\n",
      "Epoch 3014/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5188 - accuracy: 0.0312 - val_loss: 119.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 3015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2617 - accuracy: 0.0312 - val_loss: 126.9794 - val_accuracy: 0.0000e+00\n",
      "Epoch 3016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8473 - accuracy: 0.0000e+00 - val_loss: 123.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 3017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4693 - accuracy: 0.0156 - val_loss: 115.7812 - val_accuracy: 0.0588\n",
      "Epoch 3018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7113 - accuracy: 0.0156 - val_loss: 118.6259 - val_accuracy: 0.0588\n",
      "Epoch 3019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0890 - accuracy: 0.0156 - val_loss: 127.3113 - val_accuracy: 0.0000e+00\n",
      "Epoch 3020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5444 - accuracy: 0.0000e+00 - val_loss: 136.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 3021/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.5972 - accuracy: 0.0312 - val_loss: 129.1216 - val_accuracy: 0.0000e+00\n",
      "Epoch 3022/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 45.7816 - accuracy: 0.0156 - val_loss: 117.8389 - val_accuracy: 0.0000e+00\n",
      "Epoch 3023/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.4510 - accuracy: 0.0156 - val_loss: 115.7365 - val_accuracy: 0.0000e+00\n",
      "Epoch 3024/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 74.4445 - accuracy: 0.0000e+00 - val_loss: 123.7797 - val_accuracy: 0.0000e+00\n",
      "Epoch 3025/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 45.7013 - accuracy: 0.0000e+00 - val_loss: 123.4771 - val_accuracy: 0.0000e+00\n",
      "Epoch 3026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5907 - accuracy: 0.0156 - val_loss: 116.6741 - val_accuracy: 0.0588\n",
      "Epoch 3027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5952 - accuracy: 0.0156 - val_loss: 104.8445 - val_accuracy: 0.0000e+00\n",
      "Epoch 3028/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.0307 - accuracy: 0.0000e+00 - val_loss: 99.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 3029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2795 - accuracy: 0.0000e+00 - val_loss: 106.5617 - val_accuracy: 0.0000e+00\n",
      "Epoch 3030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.3506 - accuracy: 0.0156 - val_loss: 126.7453 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0578 - accuracy: 0.0000e+00 - val_loss: 146.0973 - val_accuracy: 0.0000e+00\n",
      "Epoch 3032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6670 - accuracy: 0.0000e+00 - val_loss: 143.5786 - val_accuracy: 0.0000e+00\n",
      "Epoch 3033/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5635 - accuracy: 0.0156 - val_loss: 124.6148 - val_accuracy: 0.0000e+00\n",
      "Epoch 3034/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 56.1101 - accuracy: 0.0156 - val_loss: 109.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 3035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8480 - accuracy: 0.0156 - val_loss: 111.1654 - val_accuracy: 0.0588\n",
      "Epoch 3036/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 46.0772 - accuracy: 0.0156 - val_loss: 121.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 3037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1758 - accuracy: 0.0000e+00 - val_loss: 131.2552 - val_accuracy: 0.0000e+00\n",
      "Epoch 3038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6875 - accuracy: 0.0000e+00 - val_loss: 120.7794 - val_accuracy: 0.0000e+00\n",
      "Epoch 3039/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0170 - accuracy: 0.0156 - val_loss: 108.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 3040/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.1768 - accuracy: 0.0000e+00 - val_loss: 106.7485 - val_accuracy: 0.0000e+00\n",
      "Epoch 3041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4644 - accuracy: 0.0000e+00 - val_loss: 105.3025 - val_accuracy: 0.0000e+00\n",
      "Epoch 3042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.8653 - accuracy: 0.0156 - val_loss: 103.9374 - val_accuracy: 0.0000e+00\n",
      "Epoch 3043/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4716 - accuracy: 0.0156 - val_loss: 106.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 3044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0673 - accuracy: 0.0312 - val_loss: 114.4158 - val_accuracy: 0.0000e+00\n",
      "Epoch 3045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.1945 - accuracy: 0.0000e+00 - val_loss: 114.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 3046/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.3897 - accuracy: 0.0000e+00 - val_loss: 118.9270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3047/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0110 - accuracy: 0.0000e+00 - val_loss: 128.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 3048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7032 - accuracy: 0.0000e+00 - val_loss: 131.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 3049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2150 - accuracy: 0.0156 - val_loss: 125.6613 - val_accuracy: 0.0588\n",
      "Epoch 3050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0286 - accuracy: 0.0000e+00 - val_loss: 119.7532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3051/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7993 - accuracy: 0.0000e+00 - val_loss: 121.0637 - val_accuracy: 0.0000e+00\n",
      "Epoch 3052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 61.8447 - accuracy: 0.0000e+00 - val_loss: 122.2777 - val_accuracy: 0.0000e+00\n",
      "Epoch 3053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.1914 - accuracy: 0.0156 - val_loss: 131.9077 - val_accuracy: 0.0588\n",
      "Epoch 3054/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.6364 - accuracy: 0.0156 - val_loss: 134.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 3055/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.9099 - accuracy: 0.0000e+00 - val_loss: 127.2153 - val_accuracy: 0.0000e+00\n",
      "Epoch 3056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3192 - accuracy: 0.0000e+00 - val_loss: 111.7176 - val_accuracy: 0.0000e+00\n",
      "Epoch 3057/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 37.8232 - accuracy: 0.0000e+00 - val_loss: 104.3403 - val_accuracy: 0.0000e+00\n",
      "Epoch 3058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0338 - accuracy: 0.0000e+00 - val_loss: 99.5241 - val_accuracy: 0.0588\n",
      "Epoch 3059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.5500 - accuracy: 0.0156 - val_loss: 112.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 3060/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.0684 - accuracy: 0.0000e+00 - val_loss: 117.7621 - val_accuracy: 0.0588\n",
      "Epoch 3061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.1987 - accuracy: 0.0156 - val_loss: 112.9035 - val_accuracy: 0.0588\n",
      "Epoch 3062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.3989 - accuracy: 0.0000e+00 - val_loss: 99.8800 - val_accuracy: 0.1176\n",
      "Epoch 3063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1718 - accuracy: 0.0156 - val_loss: 99.1243 - val_accuracy: 0.1176\n",
      "Epoch 3064/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 58.7802 - accuracy: 0.0000e+00 - val_loss: 106.3018 - val_accuracy: 0.0588\n",
      "Epoch 3065/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9247 - accuracy: 0.0156 - val_loss: 118.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 3066/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5699 - accuracy: 0.0156 - val_loss: 132.4185 - val_accuracy: 0.0000e+00\n",
      "Epoch 3067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9786 - accuracy: 0.0156 - val_loss: 128.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3068/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 37.0582 - accuracy: 0.0000e+00 - val_loss: 123.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 3069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.1509 - accuracy: 0.0000e+00 - val_loss: 122.1702 - val_accuracy: 0.0588\n",
      "Epoch 3070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1408 - accuracy: 0.0156 - val_loss: 116.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 3071/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 49.1423 - accuracy: 0.0156 - val_loss: 111.8038 - val_accuracy: 0.0000e+00\n",
      "Epoch 3072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2422 - accuracy: 0.0156 - val_loss: 105.0864 - val_accuracy: 0.0588\n",
      "Epoch 3073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.8554 - accuracy: 0.0000e+00 - val_loss: 104.3377 - val_accuracy: 0.0588\n",
      "Epoch 3074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.7912 - accuracy: 0.0000e+00 - val_loss: 102.6717 - val_accuracy: 0.0588\n",
      "Epoch 3075/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.0793 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 29.1891 - accuracy: 0.0156 - val_loss: 107.0271 - val_accuracy: 0.0588\n",
      "Epoch 3076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.2093 - accuracy: 0.0000e+00 - val_loss: 102.9057 - val_accuracy: 0.0588\n",
      "Epoch 3077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7564 - accuracy: 0.0156 - val_loss: 95.7460 - val_accuracy: 0.0588\n",
      "Epoch 3078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6852 - accuracy: 0.0000e+00 - val_loss: 104.2736 - val_accuracy: 0.0588\n",
      "Epoch 3079/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 42.5574 - accuracy: 0.0156 - val_loss: 119.7770 - val_accuracy: 0.0000e+00\n",
      "Epoch 3080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.6430 - accuracy: 0.0000e+00 - val_loss: 129.4722 - val_accuracy: 0.0000e+00\n",
      "Epoch 3081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1573 - accuracy: 0.0000e+00 - val_loss: 125.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 3082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0990 - accuracy: 0.0156 - val_loss: 117.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 3083/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 44.6984 - accuracy: 0.0000e+00 - val_loss: 111.6803 - val_accuracy: 0.0000e+00\n",
      "Epoch 3084/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.8959 - accuracy: 0.0000e+00 - val_loss: 115.0802 - val_accuracy: 0.0000e+00\n",
      "Epoch 3085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8730 - accuracy: 0.0000e+00 - val_loss: 117.4334 - val_accuracy: 0.0000e+00\n",
      "Epoch 3086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7040 - accuracy: 0.0000e+00 - val_loss: 120.0243 - val_accuracy: 0.0000e+00\n",
      "Epoch 3087/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.8721 - accuracy: 0.0156 - val_loss: 129.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 3088/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1442 - accuracy: 0.0156 - val_loss: 132.3589 - val_accuracy: 0.0588\n",
      "Epoch 3089/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 56.8920 - accuracy: 0.0000e+00 - val_loss: 127.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 3090/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5987 - accuracy: 0.0000e+00 - val_loss: 111.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 3091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0359 - accuracy: 0.0000e+00 - val_loss: 104.6421 - val_accuracy: 0.0000e+00\n",
      "Epoch 3092/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 59.8525 - accuracy: 0.0000e+00 - val_loss: 106.8759 - val_accuracy: 0.0000e+00\n",
      "Epoch 3093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5477 - accuracy: 0.0312 - val_loss: 111.6664 - val_accuracy: 0.0000e+00\n",
      "Epoch 3094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5045 - accuracy: 0.0156 - val_loss: 113.2582 - val_accuracy: 0.0000e+00\n",
      "Epoch 3095/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 45.4550 - accuracy: 0.0000e+00 - val_loss: 115.1499 - val_accuracy: 0.0000e+00\n",
      "Epoch 3096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0391 - accuracy: 0.0156 - val_loss: 112.4963 - val_accuracy: 0.0000e+00\n",
      "Epoch 3097/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.6136 - accuracy: 0.0156 - val_loss: 114.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 3098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 60.3983 - accuracy: 0.0000e+00 - val_loss: 117.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 3099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9948 - accuracy: 0.0000e+00 - val_loss: 119.3608 - val_accuracy: 0.0000e+00\n",
      "Epoch 3100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.3064 - accuracy: 0.0000e+00 - val_loss: 119.0980 - val_accuracy: 0.0000e+00\n",
      "Epoch 3101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5914 - accuracy: 0.0000e+00 - val_loss: 119.2024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3102/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 43.3841 - accuracy: 0.0000e+00 - val_loss: 119.7836 - val_accuracy: 0.0588\n",
      "Epoch 3103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3203 - accuracy: 0.0156 - val_loss: 124.2467 - val_accuracy: 0.0000e+00\n",
      "Epoch 3104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6572 - accuracy: 0.0000e+00 - val_loss: 126.7448 - val_accuracy: 0.0000e+00\n",
      "Epoch 3105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0399 - accuracy: 0.0000e+00 - val_loss: 116.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 3106/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 53.4623 - accuracy: 0.0000e+00 - val_loss: 114.0819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3107/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 52.4382 - accuracy: 0.0000e+00 - val_loss: 117.0147 - val_accuracy: 0.0000e+00\n",
      "Epoch 3108/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4666 - accuracy: 0.0000e+00 - val_loss: 123.6781 - val_accuracy: 0.0000e+00\n",
      "Epoch 3109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.3352 - accuracy: 0.0000e+00 - val_loss: 123.2423 - val_accuracy: 0.0000e+00\n",
      "Epoch 3110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8533 - accuracy: 0.0156 - val_loss: 125.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 3111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1608 - accuracy: 0.0000e+00 - val_loss: 130.1239 - val_accuracy: 0.0000e+00\n",
      "Epoch 3112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9111 - accuracy: 0.0156 - val_loss: 128.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 3113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.3809 - accuracy: 0.0000e+00 - val_loss: 125.2884 - val_accuracy: 0.0588\n",
      "Epoch 3114/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 41.2540 - accuracy: 0.0156 - val_loss: 121.4897 - val_accuracy: 0.0588\n",
      "Epoch 3115/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.5982 - accuracy: 0.0156 - val_loss: 123.6673 - val_accuracy: 0.0588\n",
      "Epoch 3116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4920 - accuracy: 0.0000e+00 - val_loss: 122.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 3117/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.4832 - accuracy: 0.0000e+00 - val_loss: 125.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 3118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6359 - accuracy: 0.0000e+00 - val_loss: 126.1172 - val_accuracy: 0.0000e+00\n",
      "Epoch 3119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2763 - accuracy: 0.0000e+00 - val_loss: 127.8725 - val_accuracy: 0.1176\n",
      "Epoch 3120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2510 - accuracy: 0.0000e+00 - val_loss: 122.1743 - val_accuracy: 0.1176\n",
      "Epoch 3121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0190 - accuracy: 0.0156 - val_loss: 117.6445 - val_accuracy: 0.1176\n",
      "Epoch 3122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0435 - accuracy: 0.0000e+00 - val_loss: 121.0463 - val_accuracy: 0.0588\n",
      "Epoch 3123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9345 - accuracy: 0.0000e+00 - val_loss: 121.5483 - val_accuracy: 0.0588\n",
      "Epoch 3124/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2852 - accuracy: 0.0156 - val_loss: 118.9978 - val_accuracy: 0.0588\n",
      "Epoch 3125/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 36.9857 - accuracy: 0.0156 - val_loss: 114.0909 - val_accuracy: 0.0588\n",
      "Epoch 3126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0616 - accuracy: 0.0000e+00 - val_loss: 119.1022 - val_accuracy: 0.0000e+00\n",
      "Epoch 3127/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.4905 - accuracy: 0.0000e+0 - 0s 78us/step - loss: 35.3215 - accuracy: 0.0000e+00 - val_loss: 125.9702 - val_accuracy: 0.0588\n",
      "Epoch 3128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9938 - accuracy: 0.0156 - val_loss: 126.8516 - val_accuracy: 0.0588\n",
      "Epoch 3129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6538 - accuracy: 0.0156 - val_loss: 117.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 3130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.0573 - accuracy: 0.0156 - val_loss: 108.1367 - val_accuracy: 0.0588\n",
      "Epoch 3131/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.0210 - accuracy: 0.0000e+00 - val_loss: 106.4344 - val_accuracy: 0.0588\n",
      "Epoch 3132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2460 - accuracy: 0.0000e+00 - val_loss: 108.1702 - val_accuracy: 0.0588\n",
      "Epoch 3133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0867 - accuracy: 0.0000e+00 - val_loss: 118.3483 - val_accuracy: 0.0588\n",
      "Epoch 3134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6616 - accuracy: 0.0000e+00 - val_loss: 126.2635 - val_accuracy: 0.0588\n",
      "Epoch 3135/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 63us/step - loss: 59.8597 - accuracy: 0.0156 - val_loss: 130.5265 - val_accuracy: 0.0588\n",
      "Epoch 3136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7035 - accuracy: 0.0000e+00 - val_loss: 122.4548 - val_accuracy: 0.1176\n",
      "Epoch 3137/10000\n",
      "64/64 [==============================] - 0s 106us/step - loss: 34.3083 - accuracy: 0.0156 - val_loss: 113.0562 - val_accuracy: 0.0588\n",
      "Epoch 3138/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 50.3550 - accuracy: 0.0000e+00 - val_loss: 110.6300 - val_accuracy: 0.0588\n",
      "Epoch 3139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3036 - accuracy: 0.0156 - val_loss: 112.6880 - val_accuracy: 0.0588\n",
      "Epoch 3140/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 55.5435 - accuracy: 0.0000e+00 - val_loss: 130.4685 - val_accuracy: 0.0588\n",
      "Epoch 3141/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3417 - accuracy: 0.0000e+00 - val_loss: 130.8810 - val_accuracy: 0.0000e+00\n",
      "Epoch 3142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2572 - accuracy: 0.0156 - val_loss: 121.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 3143/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 50.4368 - accuracy: 0.0156 - val_loss: 112.1593 - val_accuracy: 0.0000e+00\n",
      "Epoch 3144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4870 - accuracy: 0.0000e+00 - val_loss: 106.4786 - val_accuracy: 0.0588\n",
      "Epoch 3145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5413 - accuracy: 0.0156 - val_loss: 106.0336 - val_accuracy: 0.0000e+00\n",
      "Epoch 3146/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 49.9560 - accuracy: 0.0000e+00 - val_loss: 114.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 3147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8091 - accuracy: 0.0156 - val_loss: 115.9135 - val_accuracy: 0.0588\n",
      "Epoch 3148/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.8008 - accuracy: 0.0000e+00 - val_loss: 111.4101 - val_accuracy: 0.0000e+00\n",
      "Epoch 3149/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 48.3813 - accuracy: 0.0156 - val_loss: 108.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 3150/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8673 - accuracy: 0.0000e+00 - val_loss: 113.9658 - val_accuracy: 0.0588\n",
      "Epoch 3151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0319 - accuracy: 0.0000e+00 - val_loss: 124.3212 - val_accuracy: 0.0000e+00\n",
      "Epoch 3152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7995 - accuracy: 0.0000e+00 - val_loss: 131.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 3153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6060 - accuracy: 0.0156 - val_loss: 135.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 3154/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 34.8663 - accuracy: 0.0000e+00 - val_loss: 132.1466 - val_accuracy: 0.0000e+00\n",
      "Epoch 3155/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1540 - accuracy: 0.0156 - val_loss: 131.7027 - val_accuracy: 0.0588\n",
      "Epoch 3156/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9896 - accuracy: 0.0000e+00 - val_loss: 128.4045 - val_accuracy: 0.0000e+00\n",
      "Epoch 3157/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 44.4923 - accuracy: 0.0000e+00 - val_loss: 127.8526 - val_accuracy: 0.0588\n",
      "Epoch 3158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1638 - accuracy: 0.0000e+00 - val_loss: 135.3377 - val_accuracy: 0.0000e+00\n",
      "Epoch 3159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1132 - accuracy: 0.0000e+00 - val_loss: 128.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 3160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6696 - accuracy: 0.0000e+00 - val_loss: 120.0983 - val_accuracy: 0.0588\n",
      "Epoch 3161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7084 - accuracy: 0.0000e+00 - val_loss: 113.9500 - val_accuracy: 0.0588\n",
      "Epoch 3162/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 46.3981 - accuracy: 0.0000e+00 - val_loss: 106.2584 - val_accuracy: 0.0588\n",
      "Epoch 3163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 47.5072 - accuracy: 0.0156 - val_loss: 109.4782 - val_accuracy: 0.0000e+00\n",
      "Epoch 3164/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.6066 - accuracy: 0.0000e+00 - val_loss: 122.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 3165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6557 - accuracy: 0.0000e+00 - val_loss: 135.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 3166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4706 - accuracy: 0.0000e+00 - val_loss: 140.2027 - val_accuracy: 0.0000e+00\n",
      "Epoch 3167/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.9293 - accuracy: 0.0000e+00 - val_loss: 124.8704 - val_accuracy: 0.0000e+00\n",
      "Epoch 3168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 48.6817 - accuracy: 0.0000e+00 - val_loss: 109.4541 - val_accuracy: 0.0000e+00\n",
      "Epoch 3169/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.3889 - accuracy: 0.0000e+00 - val_loss: 98.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9188 - accuracy: 0.0000e+00 - val_loss: 93.8601 - val_accuracy: 0.0000e+00\n",
      "Epoch 3171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.3402 - accuracy: 0.0000e+00 - val_loss: 94.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 3172/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 32.8484 - accuracy: 0.0312 - val_loss: 100.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 3173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7081 - accuracy: 0.0000e+00 - val_loss: 105.2830 - val_accuracy: 0.0000e+00\n",
      "Epoch 3174/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.4229 - accuracy: 0.0000e+00 - val_loss: 110.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 3175/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4999 - accuracy: 0.0156 - val_loss: 112.2236 - val_accuracy: 0.0000e+00\n",
      "Epoch 3176/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3649 - accuracy: 0.0156 - val_loss: 110.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 3177/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 39.1278 - accuracy: 0.0000e+00 - val_loss: 111.8717 - val_accuracy: 0.0000e+00\n",
      "Epoch 3178/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 33.0150 - accuracy: 0.0000e+00 - val_loss: 118.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 3179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3798 - accuracy: 0.0000e+00 - val_loss: 125.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3180/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0502 - accuracy: 0.0156 - val_loss: 130.8302 - val_accuracy: 0.0000e+00\n",
      "Epoch 3181/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4871 - accuracy: 0.0000e+00 - val_loss: 133.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2330 - accuracy: 0.0000e+00 - val_loss: 134.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 3183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7215 - accuracy: 0.0000e+00 - val_loss: 133.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 3184/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 39.3460 - accuracy: 0.0000e+00 - val_loss: 129.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 3185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6509 - accuracy: 0.0312 - val_loss: 120.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 3186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3067 - accuracy: 0.0156 - val_loss: 117.9283 - val_accuracy: 0.0000e+00\n",
      "Epoch 3187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4883 - accuracy: 0.0156 - val_loss: 120.2806 - val_accuracy: 0.0588\n",
      "Epoch 3188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.9757 - accuracy: 0.0156 - val_loss: 125.8109 - val_accuracy: 0.0588\n",
      "Epoch 3189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4391 - accuracy: 0.0156 - val_loss: 128.9913 - val_accuracy: 0.0588\n",
      "Epoch 3190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8583 - accuracy: 0.0000e+00 - val_loss: 129.1149 - val_accuracy: 0.0588\n",
      "Epoch 3191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.5904 - accuracy: 0.0156 - val_loss: 121.9317 - val_accuracy: 0.0000e+00\n",
      "Epoch 3192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3136 - accuracy: 0.0000e+00 - val_loss: 115.2644 - val_accuracy: 0.0588\n",
      "Epoch 3193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.7265 - accuracy: 0.0000e+00 - val_loss: 114.2933 - val_accuracy: 0.0588\n",
      "Epoch 3194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9618 - accuracy: 0.0156 - val_loss: 109.4461 - val_accuracy: 0.0588\n",
      "Epoch 3195/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.4388 - accuracy: 0.0156 - val_loss: 101.6058 - val_accuracy: 0.0588\n",
      "Epoch 3196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0386 - accuracy: 0.0000e+00 - val_loss: 100.3942 - val_accuracy: 0.0588\n",
      "Epoch 3197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7670 - accuracy: 0.0156 - val_loss: 112.6618 - val_accuracy: 0.0588\n",
      "Epoch 3198/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 37.4396 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.3340 - accuracy: 0.0156 - val_loss: 134.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 3199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1460 - accuracy: 0.0000e+00 - val_loss: 141.6888 - val_accuracy: 0.0000e+00\n",
      "Epoch 3200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8651 - accuracy: 0.0000e+00 - val_loss: 132.8426 - val_accuracy: 0.0000e+00\n",
      "Epoch 3201/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 35.0588 - accuracy: 0.0000e+00 - val_loss: 122.9974 - val_accuracy: 0.0000e+00\n",
      "Epoch 3202/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.3213 - accuracy: 0.0000e+00 - val_loss: 117.2544 - val_accuracy: 0.0000e+00\n",
      "Epoch 3203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5265 - accuracy: 0.0000e+00 - val_loss: 121.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 3204/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 40.2133 - accuracy: 0.0312 - val_loss: 130.3890 - val_accuracy: 0.0000e+00\n",
      "Epoch 3205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5816 - accuracy: 0.0156 - val_loss: 134.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4523 - accuracy: 0.0156 - val_loss: 129.2822 - val_accuracy: 0.0000e+00\n",
      "Epoch 3207/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 48.7837 - accuracy: 0.0312 - val_loss: 113.8467 - val_accuracy: 0.0588\n",
      "Epoch 3208/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3565 - accuracy: 0.0000e+00 - val_loss: 99.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 3209/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 41.5166 - accuracy: 0.0312 - val_loss: 96.1935 - val_accuracy: 0.0588\n",
      "Epoch 3210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4455 - accuracy: 0.0000e+00 - val_loss: 96.8006 - val_accuracy: 0.0588\n",
      "Epoch 3211/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8663 - accuracy: 0.0000e+00 - val_loss: 103.3420 - val_accuracy: 0.0000e+00\n",
      "Epoch 3212/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 33.2381 - accuracy: 0.0000e+00 - val_loss: 112.5255 - val_accuracy: 0.0588\n",
      "Epoch 3213/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.7367 - accuracy: 0.0000e+00 - val_loss: 126.0605 - val_accuracy: 0.0000e+00\n",
      "Epoch 3214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0213 - accuracy: 0.0000e+00 - val_loss: 133.9479 - val_accuracy: 0.0588\n",
      "Epoch 3215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8304 - accuracy: 0.0156 - val_loss: 133.7750 - val_accuracy: 0.0588\n",
      "Epoch 3216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1699 - accuracy: 0.0000e+00 - val_loss: 129.2972 - val_accuracy: 0.0588\n",
      "Epoch 3217/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 33.4892 - accuracy: 0.0000e+00 - val_loss: 122.5565 - val_accuracy: 0.1176\n",
      "Epoch 3218/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 38.4531 - accuracy: 0.0000e+00 - val_loss: 121.0384 - val_accuracy: 0.0000e+00\n",
      "Epoch 3219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.8226 - accuracy: 0.0000e+00 - val_loss: 135.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 3220/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 40.1985 - accuracy: 0.0156 - val_loss: 139.0797 - val_accuracy: 0.0000e+00\n",
      "Epoch 3221/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 43.1853 - accuracy: 0.0000e+00 - val_loss: 126.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 3222/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9979 - accuracy: 0.0000e+00 - val_loss: 120.4292 - val_accuracy: 0.0588\n",
      "Epoch 3223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1506 - accuracy: 0.0156 - val_loss: 118.7639 - val_accuracy: 0.0000e+00\n",
      "Epoch 3224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8673 - accuracy: 0.0156 - val_loss: 125.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 3225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7434 - accuracy: 0.0156 - val_loss: 136.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 3226/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7548 - accuracy: 0.0156 - val_loss: 138.9849 - val_accuracy: 0.0000e+00\n",
      "Epoch 3227/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.9118 - accuracy: 0.0000e+00 - val_loss: 137.8969 - val_accuracy: 0.0588\n",
      "Epoch 3228/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.7093 - accuracy: 0.0156 - val_loss: 133.0310 - val_accuracy: 0.0588\n",
      "Epoch 3229/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 47.9109 - accuracy: 0.0312 - val_loss: 127.9020 - val_accuracy: 0.0588\n",
      "Epoch 3230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3876 - accuracy: 0.0000e+00 - val_loss: 126.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 3231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3975 - accuracy: 0.0000e+00 - val_loss: 142.2879 - val_accuracy: 0.0000e+00\n",
      "Epoch 3232/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 41.4335 - accuracy: 0.0000e+00 - val_loss: 137.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 3233/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7895 - accuracy: 0.0000e+00 - val_loss: 134.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 3234/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.3468 - accuracy: 0.0156 - val_loss: 120.9960 - val_accuracy: 0.0000e+00\n",
      "Epoch 3235/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 40.6222 - accuracy: 0.0312 - val_loss: 111.8023 - val_accuracy: 0.0588\n",
      "Epoch 3236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6254 - accuracy: 0.0156 - val_loss: 110.1171 - val_accuracy: 0.0588\n",
      "Epoch 3237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1141 - accuracy: 0.0156 - val_loss: 109.8487 - val_accuracy: 0.0588\n",
      "Epoch 3238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.0057 - accuracy: 0.0156 - val_loss: 117.3154 - val_accuracy: 0.0588\n",
      "Epoch 3239/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.1693 - accuracy: 0.0156 - val_loss: 118.6235 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5069 - accuracy: 0.0000e+00 - val_loss: 117.0894 - val_accuracy: 0.0588\n",
      "Epoch 3241/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8797 - accuracy: 0.0156 - val_loss: 125.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 3242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1530 - accuracy: 0.0000e+00 - val_loss: 135.1611 - val_accuracy: 0.0000e+00\n",
      "Epoch 3243/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 25.9247 - accuracy: 0.0156 - val_loss: 132.7943 - val_accuracy: 0.0000e+00\n",
      "Epoch 3244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 63.1763 - accuracy: 0.0000e+00 - val_loss: 138.5694 - val_accuracy: 0.0000e+00\n",
      "Epoch 3245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0580 - accuracy: 0.0156 - val_loss: 137.2965 - val_accuracy: 0.0000e+00\n",
      "Epoch 3246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2783 - accuracy: 0.0312 - val_loss: 135.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 3247/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 46.7579 - accuracy: 0.0156 - val_loss: 141.0329 - val_accuracy: 0.0000e+00\n",
      "Epoch 3248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8604 - accuracy: 0.0156 - val_loss: 136.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 3249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0204 - accuracy: 0.0000e+00 - val_loss: 132.9650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1509 - accuracy: 0.0000e+00 - val_loss: 130.8727 - val_accuracy: 0.0588\n",
      "Epoch 3251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0149 - accuracy: 0.0156 - val_loss: 127.8063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7810 - accuracy: 0.0000e+00 - val_loss: 121.5132 - val_accuracy: 0.0000e+00\n",
      "Epoch 3253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.2332 - accuracy: 0.0000e+00 - val_loss: 124.8194 - val_accuracy: 0.0000e+00\n",
      "Epoch 3254/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 45.8689 - accuracy: 0.0000e+00 - val_loss: 139.1009 - val_accuracy: 0.0000e+00\n",
      "Epoch 3255/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 44.0262 - accuracy: 0.0000e+00 - val_loss: 131.4372 - val_accuracy: 0.0000e+00\n",
      "Epoch 3256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.3196 - accuracy: 0.0000e+00 - val_loss: 127.2418 - val_accuracy: 0.0000e+00\n",
      "Epoch 3257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0007 - accuracy: 0.0156 - val_loss: 119.4833 - val_accuracy: 0.0000e+00\n",
      "Epoch 3258/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 42.9765 - accuracy: 0.0156 - val_loss: 119.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 3259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8656 - accuracy: 0.0000e+00 - val_loss: 127.9444 - val_accuracy: 0.0000e+00\n",
      "Epoch 3260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4477 - accuracy: 0.0156 - val_loss: 127.4167 - val_accuracy: 0.0588\n",
      "Epoch 3261/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 55.0016 - accuracy: 0.0156 - val_loss: 124.0186 - val_accuracy: 0.0588\n",
      "Epoch 3262/10000\n",
      "64/64 [==============================] - 0s 24us/step - loss: 37.1891 - accuracy: 0.0156 - val_loss: 121.9527 - val_accuracy: 0.0588\n",
      "Epoch 3263/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 44.4377 - accuracy: 0.0000e+00 - val_loss: 125.2979 - val_accuracy: 0.0588\n",
      "Epoch 3264/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 35.6456 - accuracy: 0.0000e+00 - val_loss: 125.2975 - val_accuracy: 0.0588\n",
      "Epoch 3265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7130 - accuracy: 0.0156 - val_loss: 129.7230 - val_accuracy: 0.0588\n",
      "Epoch 3266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2267 - accuracy: 0.0156 - val_loss: 132.5063 - val_accuracy: 0.0000e+00\n",
      "Epoch 3267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6473 - accuracy: 0.0000e+00 - val_loss: 134.1828 - val_accuracy: 0.0588\n",
      "Epoch 3268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3421 - accuracy: 0.0000e+00 - val_loss: 144.2561 - val_accuracy: 0.0000e+00\n",
      "Epoch 3269/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 43.8405 - accuracy: 0.0156 - val_loss: 146.2200 - val_accuracy: 0.0000e+00\n",
      "Epoch 3270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5406 - accuracy: 0.0000e+00 - val_loss: 131.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 3271/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 43.2059 - accuracy: 0.0156 - val_loss: 123.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 3272/10000\n",
      "64/64 [==============================] - 0s 206us/step - loss: 40.7412 - accuracy: 0.0000e+00 - val_loss: 118.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 3273/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 34.7759 - accuracy: 0.0156 - val_loss: 111.4893 - val_accuracy: 0.0588\n",
      "Epoch 3274/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 40.9580 - accuracy: 0.0000e+00 - val_loss: 111.3870 - val_accuracy: 0.0588\n",
      "Epoch 3275/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.8319 - accuracy: 0.0000e+00 - val_loss: 107.9874 - val_accuracy: 0.0588\n",
      "Epoch 3276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6237 - accuracy: 0.0000e+00 - val_loss: 107.3785 - val_accuracy: 0.0588\n",
      "Epoch 3277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9022 - accuracy: 0.0000e+00 - val_loss: 117.8431 - val_accuracy: 0.0588\n",
      "Epoch 3278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3211 - accuracy: 0.0000e+00 - val_loss: 137.6960 - val_accuracy: 0.0588\n",
      "Epoch 3279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0693 - accuracy: 0.0000e+00 - val_loss: 146.0438 - val_accuracy: 0.0588\n",
      "Epoch 3280/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 48.4760 - accuracy: 0.0000e+00 - val_loss: 147.5387 - val_accuracy: 0.0588\n",
      "Epoch 3281/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8258 - accuracy: 0.0156 - val_loss: 137.7582 - val_accuracy: 0.0588\n",
      "Epoch 3282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.0625 - accuracy: 0.0156 - val_loss: 131.2625 - val_accuracy: 0.0000e+00\n",
      "Epoch 3283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9829 - accuracy: 0.0156 - val_loss: 122.0624 - val_accuracy: 0.0000e+00\n",
      "Epoch 3284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.4898 - accuracy: 0.0156 - val_loss: 127.0729 - val_accuracy: 0.0000e+00\n",
      "Epoch 3285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0430 - accuracy: 0.0000e+00 - val_loss: 127.2648 - val_accuracy: 0.0588\n",
      "Epoch 3286/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 40.0261 - accuracy: 0.0312 - val_loss: 120.5667 - val_accuracy: 0.0000e+00\n",
      "Epoch 3287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.7904 - accuracy: 0.0156 - val_loss: 113.3173 - val_accuracy: 0.0588\n",
      "Epoch 3288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9707 - accuracy: 0.0000e+00 - val_loss: 111.8536 - val_accuracy: 0.0588\n",
      "Epoch 3289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7087 - accuracy: 0.0156 - val_loss: 119.3333 - val_accuracy: 0.0588\n",
      "Epoch 3290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8091 - accuracy: 0.0000e+00 - val_loss: 122.7539 - val_accuracy: 0.0588\n",
      "Epoch 3291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9130 - accuracy: 0.0000e+00 - val_loss: 119.9146 - val_accuracy: 0.0588\n",
      "Epoch 3292/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5024 - accuracy: 0.0312 - val_loss: 113.1930 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.4692 - accuracy: 0.0156 - val_loss: 106.3669 - val_accuracy: 0.1176\n",
      "Epoch 3294/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.8377 - accuracy: 0.0000e+00 - val_loss: 105.0050 - val_accuracy: 0.0588\n",
      "Epoch 3295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.0940 - accuracy: 0.0156 - val_loss: 109.8823 - val_accuracy: 0.0000e+00\n",
      "Epoch 3296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8144 - accuracy: 0.0000e+00 - val_loss: 117.4660 - val_accuracy: 0.1176\n",
      "Epoch 3297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1410 - accuracy: 0.0156 - val_loss: 123.4695 - val_accuracy: 0.0588\n",
      "Epoch 3298/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3627 - accuracy: 0.0000e+00 - val_loss: 129.8802 - val_accuracy: 0.0588\n",
      "Epoch 3299/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 46.2455 - accuracy: 0.0000e+00 - val_loss: 128.8410 - val_accuracy: 0.0588\n",
      "Epoch 3300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5712 - accuracy: 0.0000e+00 - val_loss: 130.3410 - val_accuracy: 0.0588\n",
      "Epoch 3301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9443 - accuracy: 0.0156 - val_loss: 137.4290 - val_accuracy: 0.0588\n",
      "Epoch 3302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3331 - accuracy: 0.0000e+00 - val_loss: 138.0370 - val_accuracy: 0.0588\n",
      "Epoch 3303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3073 - accuracy: 0.0000e+00 - val_loss: 134.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 3304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0530 - accuracy: 0.0156 - val_loss: 127.2699 - val_accuracy: 0.0000e+00\n",
      "Epoch 3305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9519 - accuracy: 0.0000e+00 - val_loss: 127.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 3306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4868 - accuracy: 0.0469 - val_loss: 133.9322 - val_accuracy: 0.0000e+00\n",
      "Epoch 3307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4528 - accuracy: 0.0156 - val_loss: 137.0170 - val_accuracy: 0.0000e+00\n",
      "Epoch 3308/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 40.1047 - accuracy: 0.0312 - val_loss: 128.6210 - val_accuracy: 0.0588\n",
      "Epoch 3309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.9806 - accuracy: 0.0000e+00 - val_loss: 118.1849 - val_accuracy: 0.0588\n",
      "Epoch 3310/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.2158 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 44.2104 - accuracy: 0.0000e+00 - val_loss: 113.9879 - val_accuracy: 0.0588\n",
      "Epoch 3311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7950 - accuracy: 0.0156 - val_loss: 115.9861 - val_accuracy: 0.0588\n",
      "Epoch 3312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.6673 - accuracy: 0.0000e+00 - val_loss: 128.1174 - val_accuracy: 0.1176\n",
      "Epoch 3313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8427 - accuracy: 0.0312 - val_loss: 139.3143 - val_accuracy: 0.0588\n",
      "Epoch 3314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1962 - accuracy: 0.0000e+00 - val_loss: 134.6307 - val_accuracy: 0.0588\n",
      "Epoch 3315/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.8326 - accuracy: 0.0312 - val_loss: 123.2180 - val_accuracy: 0.1176\n",
      "Epoch 3316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5767 - accuracy: 0.0000e+00 - val_loss: 124.3953 - val_accuracy: 0.0588\n",
      "Epoch 3317/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 46.0970 - accuracy: 0.0000e+00 - val_loss: 130.6713 - val_accuracy: 0.1176\n",
      "Epoch 3318/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 40.6379 - accuracy: 0.0156 - val_loss: 132.4328 - val_accuracy: 0.0588\n",
      "Epoch 3319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.2456 - accuracy: 0.0000e+00 - val_loss: 130.4855 - val_accuracy: 0.0588\n",
      "Epoch 3320/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.4089 - accuracy: 0.0000e+00 - val_loss: 131.3481 - val_accuracy: 0.0588\n",
      "Epoch 3321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.4147 - accuracy: 0.0000e+00 - val_loss: 131.5954 - val_accuracy: 0.1176\n",
      "Epoch 3322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3622 - accuracy: 0.0000e+00 - val_loss: 125.7878 - val_accuracy: 0.0588\n",
      "Epoch 3323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7153 - accuracy: 0.0000e+00 - val_loss: 128.3188 - val_accuracy: 0.0588\n",
      "Epoch 3324/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.1961 - accuracy: 0.0000e+00 - val_loss: 131.1199 - val_accuracy: 0.0588\n",
      "Epoch 3325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9897 - accuracy: 0.0156 - val_loss: 133.1288 - val_accuracy: 0.0588\n",
      "Epoch 3326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0145 - accuracy: 0.0000e+00 - val_loss: 133.7321 - val_accuracy: 0.0588\n",
      "Epoch 3327/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.1478 - accuracy: 0.0000e+00 - val_loss: 127.5802 - val_accuracy: 0.0588\n",
      "Epoch 3328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7376 - accuracy: 0.0000e+00 - val_loss: 116.2138 - val_accuracy: 0.0588\n",
      "Epoch 3329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.4417 - accuracy: 0.0000e+00 - val_loss: 117.7606 - val_accuracy: 0.0588\n",
      "Epoch 3330/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 54.7825 - accuracy: 0.0156 - val_loss: 125.6730 - val_accuracy: 0.0588\n",
      "Epoch 3331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6544 - accuracy: 0.0156 - val_loss: 136.0020 - val_accuracy: 0.0588\n",
      "Epoch 3332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7142 - accuracy: 0.0000e+00 - val_loss: 135.4454 - val_accuracy: 0.0588\n",
      "Epoch 3333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6457 - accuracy: 0.0156 - val_loss: 133.1674 - val_accuracy: 0.0588\n",
      "Epoch 3334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9213 - accuracy: 0.0000e+00 - val_loss: 120.1371 - val_accuracy: 0.0588\n",
      "Epoch 3335/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 35.0859 - accuracy: 0.0000e+00 - val_loss: 114.3670 - val_accuracy: 0.0588\n",
      "Epoch 3336/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 43.8360 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 39.5226 - accuracy: 0.0000e+00 - val_loss: 110.5435 - val_accuracy: 0.1176\n",
      "Epoch 3337/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.4404 - accuracy: 0.0156 - val_loss: 113.0922 - val_accuracy: 0.1176\n",
      "Epoch 3338/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 49.6046 - accuracy: 0.0000e+00 - val_loss: 117.3129 - val_accuracy: 0.0588\n",
      "Epoch 3339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3782 - accuracy: 0.0000e+00 - val_loss: 122.0039 - val_accuracy: 0.0588\n",
      "Epoch 3340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1840 - accuracy: 0.0000e+00 - val_loss: 117.2241 - val_accuracy: 0.0588\n",
      "Epoch 3341/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 52.9903 - accuracy: 0.0000e+0 - 0s 188us/step - loss: 45.3172 - accuracy: 0.0000e+00 - val_loss: 105.8530 - val_accuracy: 0.0588\n",
      "Epoch 3342/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.2643 - accuracy: 0.0156 - val_loss: 97.8566 - val_accuracy: 0.1176\n",
      "Epoch 3343/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 40.1432 - accuracy: 0.0000e+00 - val_loss: 97.8547 - val_accuracy: 0.1176\n",
      "Epoch 3344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4427 - accuracy: 0.0000e+00 - val_loss: 111.9190 - val_accuracy: 0.0588\n",
      "Epoch 3345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.5933 - accuracy: 0.0000e+00 - val_loss: 130.8279 - val_accuracy: 0.0588\n",
      "Epoch 3346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1122 - accuracy: 0.0312 - val_loss: 143.5716 - val_accuracy: 0.0588\n",
      "Epoch 3347/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.9887 - accuracy: 0.0000e+00 - val_loss: 136.0825 - val_accuracy: 0.0588\n",
      "Epoch 3348/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 50.5051 - accuracy: 0.0312 - val_loss: 123.9676 - val_accuracy: 0.0588\n",
      "Epoch 3349/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.6488 - accuracy: 0.0156 - val_loss: 109.0905 - val_accuracy: 0.0588\n",
      "Epoch 3350/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3908 - accuracy: 0.0000e+00 - val_loss: 106.2762 - val_accuracy: 0.0588\n",
      "Epoch 3351/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.2536 - accuracy: 0.0000e+00 - val_loss: 112.5581 - val_accuracy: 0.0588\n",
      "Epoch 3352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.2226 - accuracy: 0.0000e+00 - val_loss: 123.4275 - val_accuracy: 0.0588\n",
      "Epoch 3353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1987 - accuracy: 0.0000e+00 - val_loss: 124.5860 - val_accuracy: 0.1176\n",
      "Epoch 3354/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.5282 - accuracy: 0.0156 - val_loss: 116.9504 - val_accuracy: 0.0588\n",
      "Epoch 3355/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6495 - accuracy: 0.0000e+00 - val_loss: 117.5285 - val_accuracy: 0.0588\n",
      "Epoch 3356/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 39.3447 - accuracy: 0.0000e+00 - val_loss: 120.2017 - val_accuracy: 0.0000e+00\n",
      "Epoch 3357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8538 - accuracy: 0.0156 - val_loss: 126.1622 - val_accuracy: 0.0000e+00\n",
      "Epoch 3358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 54.2000 - accuracy: 0.0312 - val_loss: 124.2574 - val_accuracy: 0.0000e+00\n",
      "Epoch 3359/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3574 - accuracy: 0.0000e+00 - val_loss: 121.8653 - val_accuracy: 0.0000e+00\n",
      "Epoch 3360/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 38.0248 - accuracy: 0.0000e+00 - val_loss: 119.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 3361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6793 - accuracy: 0.0156 - val_loss: 119.8922 - val_accuracy: 0.1176\n",
      "Epoch 3362/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7258 - accuracy: 0.0000e+00 - val_loss: 126.3129 - val_accuracy: 0.0588\n",
      "Epoch 3363/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 37.7946 - accuracy: 0.0156 - val_loss: 124.7135 - val_accuracy: 0.0000e+00\n",
      "Epoch 3364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8157 - accuracy: 0.0000e+00 - val_loss: 118.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 3365/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 35.1683 - accuracy: 0.0156 - val_loss: 109.8026 - val_accuracy: 0.0588\n",
      "Epoch 3366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.7069 - accuracy: 0.0156 - val_loss: 100.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 3367/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 33.6883 - accuracy: 0.0000e+00 - val_loss: 96.2406 - val_accuracy: 0.0588\n",
      "Epoch 3368/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.5378 - accuracy: 0.0000e+00 - val_loss: 106.2473 - val_accuracy: 0.0588\n",
      "Epoch 3369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3823 - accuracy: 0.0000e+00 - val_loss: 114.9488 - val_accuracy: 0.0588\n",
      "Epoch 3370/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.5407 - accuracy: 0.0000e+00 - val_loss: 112.1186 - val_accuracy: 0.0588\n",
      "Epoch 3371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8736 - accuracy: 0.0000e+00 - val_loss: 112.3516 - val_accuracy: 0.0588\n",
      "Epoch 3372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7925 - accuracy: 0.0000e+00 - val_loss: 113.1072 - val_accuracy: 0.1176\n",
      "Epoch 3373/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4265 - accuracy: 0.0000e+00 - val_loss: 113.7780 - val_accuracy: 0.0588\n",
      "Epoch 3374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.9798 - accuracy: 0.0312 - val_loss: 121.7571 - val_accuracy: 0.1176\n",
      "Epoch 3375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.3465 - accuracy: 0.0156 - val_loss: 125.6756 - val_accuracy: 0.1176\n",
      "Epoch 3376/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 38.9960 - accuracy: 0.0156 - val_loss: 121.3040 - val_accuracy: 0.0588\n",
      "Epoch 3377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6696 - accuracy: 0.0000e+00 - val_loss: 110.3646 - val_accuracy: 0.0000e+00\n",
      "Epoch 3378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.5270 - accuracy: 0.0156 - val_loss: 105.7150 - val_accuracy: 0.0588\n",
      "Epoch 3379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6906 - accuracy: 0.0156 - val_loss: 114.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 3380/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.4730 - accuracy: 0.0000e+00 - val_loss: 121.6051 - val_accuracy: 0.0000e+00\n",
      "Epoch 3381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7609 - accuracy: 0.0156 - val_loss: 121.3928 - val_accuracy: 0.0000e+00\n",
      "Epoch 3382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7717 - accuracy: 0.0156 - val_loss: 114.3287 - val_accuracy: 0.0000e+00\n",
      "Epoch 3383/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.3815 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 30.0537 - accuracy: 0.0000e+00 - val_loss: 112.6779 - val_accuracy: 0.0000e+00\n",
      "Epoch 3384/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 36.2712 - accuracy: 0.0000e+00 - val_loss: 112.3937 - val_accuracy: 0.0000e+00\n",
      "Epoch 3385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6166 - accuracy: 0.0000e+00 - val_loss: 113.7477 - val_accuracy: 0.0588\n",
      "Epoch 3386/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 40.4234 - accuracy: 0.0000e+00 - val_loss: 114.2513 - val_accuracy: 0.0588\n",
      "Epoch 3387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7030 - accuracy: 0.0000e+00 - val_loss: 118.0973 - val_accuracy: 0.0588\n",
      "Epoch 3388/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 36.6198 - accuracy: 0.0000e+00 - val_loss: 130.3096 - val_accuracy: 0.0000e+00\n",
      "Epoch 3389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0239 - accuracy: 0.0000e+00 - val_loss: 130.3605 - val_accuracy: 0.0000e+00\n",
      "Epoch 3390/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 27.3774 - accuracy: 0.0000e+00 - val_loss: 122.4683 - val_accuracy: 0.0000e+00\n",
      "Epoch 3391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8505 - accuracy: 0.0000e+00 - val_loss: 116.4951 - val_accuracy: 0.0000e+00\n",
      "Epoch 3392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9659 - accuracy: 0.0000e+00 - val_loss: 115.6666 - val_accuracy: 0.0588\n",
      "Epoch 3393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 60.8557 - accuracy: 0.0000e+00 - val_loss: 121.2037 - val_accuracy: 0.0588\n",
      "Epoch 3394/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.7988 - accuracy: 0.0000e+00 - val_loss: 121.7196 - val_accuracy: 0.0588\n",
      "Epoch 3395/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0551 - accuracy: 0.0000e+00 - val_loss: 130.0410 - val_accuracy: 0.1176\n",
      "Epoch 3396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1943 - accuracy: 0.0000e+00 - val_loss: 141.0738 - val_accuracy: 0.0588\n",
      "Epoch 3397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4398 - accuracy: 0.0000e+00 - val_loss: 141.6385 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3398/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.4028 - accuracy: 0.0000e+00 - val_loss: 129.9256 - val_accuracy: 0.0588\n",
      "Epoch 3399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7845 - accuracy: 0.0000e+00 - val_loss: 110.2715 - val_accuracy: 0.0588\n",
      "Epoch 3400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8182 - accuracy: 0.0312 - val_loss: 102.1626 - val_accuracy: 0.0588\n",
      "Epoch 3401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4501 - accuracy: 0.0156 - val_loss: 106.2796 - val_accuracy: 0.0588\n",
      "Epoch 3402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5435 - accuracy: 0.0000e+00 - val_loss: 114.5258 - val_accuracy: 0.0588\n",
      "Epoch 3403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2286 - accuracy: 0.0156 - val_loss: 118.6368 - val_accuracy: 0.0588\n",
      "Epoch 3404/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0359 - accuracy: 0.0000e+00 - val_loss: 120.0098 - val_accuracy: 0.0000e+00\n",
      "Epoch 3405/10000\n",
      "64/64 [==============================] - 0s 68us/step - loss: 41.9858 - accuracy: 0.0000e+00 - val_loss: 115.8035 - val_accuracy: 0.0000e+00\n",
      "Epoch 3406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7186 - accuracy: 0.0000e+00 - val_loss: 106.0163 - val_accuracy: 0.0588\n",
      "Epoch 3407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4028 - accuracy: 0.0000e+00 - val_loss: 100.6543 - val_accuracy: 0.0588\n",
      "Epoch 3408/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 35.3319 - accuracy: 0.0156 - val_loss: 102.8099 - val_accuracy: 0.0588\n",
      "Epoch 3409/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 42.8213 - accuracy: 0.0156 - val_loss: 111.9898 - val_accuracy: 0.1176\n",
      "Epoch 3410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4557 - accuracy: 0.0156 - val_loss: 125.8163 - val_accuracy: 0.0588\n",
      "Epoch 3411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1986 - accuracy: 0.0312 - val_loss: 137.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 3412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0642 - accuracy: 0.0000e+00 - val_loss: 131.7629 - val_accuracy: 0.0000e+00\n",
      "Epoch 3413/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.5385 - accuracy: 0.0000e+00 - val_loss: 112.6758 - val_accuracy: 0.1176\n",
      "Epoch 3414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 51.3235 - accuracy: 0.0000e+00 - val_loss: 101.2466 - val_accuracy: 0.0588\n",
      "Epoch 3415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5488 - accuracy: 0.0156 - val_loss: 97.1123 - val_accuracy: 0.1176\n",
      "Epoch 3416/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 35.1078 - accuracy: 0.0000e+00 - val_loss: 102.8066 - val_accuracy: 0.0588\n",
      "Epoch 3417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8472 - accuracy: 0.0000e+00 - val_loss: 117.3733 - val_accuracy: 0.0588\n",
      "Epoch 3418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8262 - accuracy: 0.0156 - val_loss: 114.1322 - val_accuracy: 0.0588\n",
      "Epoch 3419/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 46.1397 - accuracy: 0.0000e+00 - val_loss: 109.5021 - val_accuracy: 0.0588\n",
      "Epoch 3420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9200 - accuracy: 0.0312 - val_loss: 103.9060 - val_accuracy: 0.1176\n",
      "Epoch 3421/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.0942 - accuracy: 0.0000e+00 - val_loss: 104.2871 - val_accuracy: 0.0588\n",
      "Epoch 3422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6213 - accuracy: 0.0000e+00 - val_loss: 104.9681 - val_accuracy: 0.0588\n",
      "Epoch 3423/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 50.5046 - accuracy: 0.0000e+00 - val_loss: 105.6097 - val_accuracy: 0.0588\n",
      "Epoch 3424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.0552 - accuracy: 0.0312 - val_loss: 106.1593 - val_accuracy: 0.0588\n",
      "Epoch 3425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2931 - accuracy: 0.0000e+00 - val_loss: 106.3796 - val_accuracy: 0.0588\n",
      "Epoch 3426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5911 - accuracy: 0.0156 - val_loss: 103.8104 - val_accuracy: 0.0588\n",
      "Epoch 3427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5435 - accuracy: 0.0156 - val_loss: 101.1526 - val_accuracy: 0.0588\n",
      "Epoch 3428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0446 - accuracy: 0.0000e+00 - val_loss: 103.2204 - val_accuracy: 0.0000e+00\n",
      "Epoch 3429/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 55.3312 - accuracy: 0.0156 - val_loss: 102.8271 - val_accuracy: 0.0588\n",
      "Epoch 3430/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 39.9584 - accuracy: 0.0000e+00 - val_loss: 102.5206 - val_accuracy: 0.0588\n",
      "Epoch 3431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2774 - accuracy: 0.0000e+00 - val_loss: 103.8018 - val_accuracy: 0.0588\n",
      "Epoch 3432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.3530 - accuracy: 0.0156 - val_loss: 106.6614 - val_accuracy: 0.1176\n",
      "Epoch 3433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3253 - accuracy: 0.0000e+00 - val_loss: 116.6677 - val_accuracy: 0.0588\n",
      "Epoch 3434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4157 - accuracy: 0.0000e+00 - val_loss: 117.4401 - val_accuracy: 0.0588\n",
      "Epoch 3435/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.7915 - accuracy: 0.0000e+00 - val_loss: 107.2241 - val_accuracy: 0.0588\n",
      "Epoch 3436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6762 - accuracy: 0.0000e+00 - val_loss: 101.8319 - val_accuracy: 0.0588\n",
      "Epoch 3437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5973 - accuracy: 0.0000e+00 - val_loss: 106.5946 - val_accuracy: 0.0588\n",
      "Epoch 3438/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.6898 - accuracy: 0.0000e+00 - val_loss: 109.1168 - val_accuracy: 0.1176\n",
      "Epoch 3439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.8324 - accuracy: 0.0000e+00 - val_loss: 115.7991 - val_accuracy: 0.0588\n",
      "Epoch 3440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3172 - accuracy: 0.0000e+00 - val_loss: 123.0382 - val_accuracy: 0.0588\n",
      "Epoch 3441/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1817 - accuracy: 0.0000e+00 - val_loss: 125.6914 - val_accuracy: 0.1176\n",
      "Epoch 3442/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.2303 - accuracy: 0.0156 - val_loss: 132.5251 - val_accuracy: 0.0588\n",
      "Epoch 3443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5710 - accuracy: 0.0156 - val_loss: 138.7085 - val_accuracy: 0.0588\n",
      "Epoch 3444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5387 - accuracy: 0.0156 - val_loss: 139.2910 - val_accuracy: 0.0588\n",
      "Epoch 3445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3737 - accuracy: 0.0000e+00 - val_loss: 130.7611 - val_accuracy: 0.0588\n",
      "Epoch 3446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5300 - accuracy: 0.0000e+00 - val_loss: 125.5393 - val_accuracy: 0.0588\n",
      "Epoch 3447/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.8777 - accuracy: 0.0000e+00 - val_loss: 127.2776 - val_accuracy: 0.0000e+00\n",
      "Epoch 3448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7489 - accuracy: 0.0000e+00 - val_loss: 131.3192 - val_accuracy: 0.0000e+00\n",
      "Epoch 3449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5777 - accuracy: 0.0000e+00 - val_loss: 139.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 3450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5166 - accuracy: 0.0000e+00 - val_loss: 131.4595 - val_accuracy: 0.0000e+00\n",
      "Epoch 3451/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 61.5886 - accuracy: 0.0000e+00 - val_loss: 123.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 3452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6556 - accuracy: 0.0156 - val_loss: 117.4128 - val_accuracy: 0.0000e+00\n",
      "Epoch 3453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1036 - accuracy: 0.0000e+00 - val_loss: 120.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 3454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6799 - accuracy: 0.0000e+00 - val_loss: 131.5732 - val_accuracy: 0.0000e+00\n",
      "Epoch 3455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1128 - accuracy: 0.0000e+00 - val_loss: 136.0694 - val_accuracy: 0.0588\n",
      "Epoch 3456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2631 - accuracy: 0.0000e+00 - val_loss: 136.6710 - val_accuracy: 0.0588\n",
      "Epoch 3457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6096 - accuracy: 0.0156 - val_loss: 133.7530 - val_accuracy: 0.0588\n",
      "Epoch 3458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5724 - accuracy: 0.0156 - val_loss: 129.5584 - val_accuracy: 0.1176\n",
      "Epoch 3459/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.3820 - accuracy: 0.0000e+00 - val_loss: 126.2467 - val_accuracy: 0.1176\n",
      "Epoch 3460/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 28.3140 - accuracy: 0.0156 - val_loss: 129.8951 - val_accuracy: 0.0588\n",
      "Epoch 3461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0467 - accuracy: 0.0156 - val_loss: 136.4743 - val_accuracy: 0.0588\n",
      "Epoch 3462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5899 - accuracy: 0.0156 - val_loss: 129.2471 - val_accuracy: 0.0588\n",
      "Epoch 3463/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 38.5206 - accuracy: 0.0000e+00 - val_loss: 125.9959 - val_accuracy: 0.0588\n",
      "Epoch 3464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3470 - accuracy: 0.0312 - val_loss: 130.7907 - val_accuracy: 0.0588\n",
      "Epoch 3465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6984 - accuracy: 0.0000e+00 - val_loss: 133.1999 - val_accuracy: 0.0588\n",
      "Epoch 3466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8041 - accuracy: 0.0000e+00 - val_loss: 132.1951 - val_accuracy: 0.0588\n",
      "Epoch 3467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3770 - accuracy: 0.0000e+00 - val_loss: 134.3948 - val_accuracy: 0.0588\n",
      "Epoch 3468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2715 - accuracy: 0.0156 - val_loss: 121.1444 - val_accuracy: 0.0588\n",
      "Epoch 3469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7013 - accuracy: 0.0000e+00 - val_loss: 117.1128 - val_accuracy: 0.0588\n",
      "Epoch 3470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8839 - accuracy: 0.0000e+00 - val_loss: 114.7128 - val_accuracy: 0.0588\n",
      "Epoch 3471/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.2981 - accuracy: 0.0000e+00 - val_loss: 118.3704 - val_accuracy: 0.0588\n",
      "Epoch 3472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0437 - accuracy: 0.0156 - val_loss: 132.6689 - val_accuracy: 0.0588\n",
      "Epoch 3473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.5015 - accuracy: 0.0000e+00 - val_loss: 130.5774 - val_accuracy: 0.0588\n",
      "Epoch 3474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.2016 - accuracy: 0.0000e+00 - val_loss: 136.1351 - val_accuracy: 0.0588\n",
      "Epoch 3475/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 53.4467 - accuracy: 0.0000e+00 - val_loss: 134.7344 - val_accuracy: 0.0588\n",
      "Epoch 3476/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.9475 - accuracy: 0.0000e+00 - val_loss: 131.7140 - val_accuracy: 0.0588\n",
      "Epoch 3477/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 31.5284 - accuracy: 0.0156 - val_loss: 127.8865 - val_accuracy: 0.0588\n",
      "Epoch 3478/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9392 - accuracy: 0.0000e+00 - val_loss: 125.4911 - val_accuracy: 0.0588\n",
      "Epoch 3479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.8115 - accuracy: 0.0000e+00 - val_loss: 118.9741 - val_accuracy: 0.0588\n",
      "Epoch 3480/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.5881 - accuracy: 0.0000e+00 - val_loss: 127.8182 - val_accuracy: 0.0588\n",
      "Epoch 3481/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 32.1451 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 36.1771 - accuracy: 0.0000e+00 - val_loss: 138.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 3482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5736 - accuracy: 0.0312 - val_loss: 139.6881 - val_accuracy: 0.0588\n",
      "Epoch 3483/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 45.9268 - accuracy: 0.0000e+00 - val_loss: 130.7517 - val_accuracy: 0.0588\n",
      "Epoch 3484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 57.8778 - accuracy: 0.0000e+00 - val_loss: 120.7008 - val_accuracy: 0.0588\n",
      "Epoch 3485/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5491 - accuracy: 0.0000e+00 - val_loss: 115.3249 - val_accuracy: 0.0588\n",
      "Epoch 3486/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 37.6052 - accuracy: 0.0000e+00 - val_loss: 114.2790 - val_accuracy: 0.0588\n",
      "Epoch 3487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.6189 - accuracy: 0.0000e+00 - val_loss: 123.1870 - val_accuracy: 0.0588\n",
      "Epoch 3488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 52.8959 - accuracy: 0.0000e+00 - val_loss: 147.7010 - val_accuracy: 0.0588\n",
      "Epoch 3489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.6732 - accuracy: 0.0156 - val_loss: 163.8936 - val_accuracy: 0.0588\n",
      "Epoch 3490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2681 - accuracy: 0.0000e+00 - val_loss: 151.9969 - val_accuracy: 0.0588\n",
      "Epoch 3491/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 37.6278 - accuracy: 0.0000e+00 - val_loss: 138.0656 - val_accuracy: 0.0588\n",
      "Epoch 3492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5432 - accuracy: 0.0156 - val_loss: 122.0087 - val_accuracy: 0.1176\n",
      "Epoch 3493/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.1819 - accuracy: 0.0000e+00 - val_loss: 119.6037 - val_accuracy: 0.1176\n",
      "Epoch 3494/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 34.8468 - accuracy: 0.0000e+00 - val_loss: 128.0375 - val_accuracy: 0.0588\n",
      "Epoch 3495/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 36.4675 - accuracy: 0.0000e+00 - val_loss: 145.9003 - val_accuracy: 0.0588\n",
      "Epoch 3496/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 40.3151 - accuracy: 0.0000e+00 - val_loss: 147.5926 - val_accuracy: 0.0588\n",
      "Epoch 3497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.4659 - accuracy: 0.0000e+00 - val_loss: 132.2088 - val_accuracy: 0.0588\n",
      "Epoch 3498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7620 - accuracy: 0.0156 - val_loss: 121.4927 - val_accuracy: 0.0588\n",
      "Epoch 3499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.7055 - accuracy: 0.0000e+00 - val_loss: 115.9607 - val_accuracy: 0.0588\n",
      "Epoch 3500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4333 - accuracy: 0.0000e+00 - val_loss: 123.7913 - val_accuracy: 0.0588\n",
      "Epoch 3501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6267 - accuracy: 0.0000e+00 - val_loss: 142.1627 - val_accuracy: 0.0588\n",
      "Epoch 3502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8202 - accuracy: 0.0000e+00 - val_loss: 152.8898 - val_accuracy: 0.0588\n",
      "Epoch 3503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1483 - accuracy: 0.0156 - val_loss: 153.5370 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3504/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 39.0451 - accuracy: 0.0000e+00 - val_loss: 144.7825 - val_accuracy: 0.0588\n",
      "Epoch 3505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9888 - accuracy: 0.0000e+00 - val_loss: 128.7711 - val_accuracy: 0.0588\n",
      "Epoch 3506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9337 - accuracy: 0.0000e+00 - val_loss: 125.1293 - val_accuracy: 0.0588\n",
      "Epoch 3507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6236 - accuracy: 0.0156 - val_loss: 133.3610 - val_accuracy: 0.0588\n",
      "Epoch 3508/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4005 - accuracy: 0.0312 - val_loss: 140.3737 - val_accuracy: 0.0588\n",
      "Epoch 3509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9544 - accuracy: 0.0156 - val_loss: 132.8483 - val_accuracy: 0.0588\n",
      "Epoch 3510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4088 - accuracy: 0.0000e+00 - val_loss: 121.7625 - val_accuracy: 0.0588\n",
      "Epoch 3511/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0394 - accuracy: 0.0000e+00 - val_loss: 125.3913 - val_accuracy: 0.1176\n",
      "Epoch 3512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6782 - accuracy: 0.0000e+00 - val_loss: 132.9203 - val_accuracy: 0.0588\n",
      "Epoch 3513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0620 - accuracy: 0.0000e+00 - val_loss: 143.0502 - val_accuracy: 0.1176\n",
      "Epoch 3514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5544 - accuracy: 0.0156 - val_loss: 151.0084 - val_accuracy: 0.1176\n",
      "Epoch 3515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5975 - accuracy: 0.0000e+00 - val_loss: 152.2187 - val_accuracy: 0.0588\n",
      "Epoch 3516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2131 - accuracy: 0.0000e+00 - val_loss: 149.8131 - val_accuracy: 0.0588\n",
      "Epoch 3517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1096 - accuracy: 0.0000e+00 - val_loss: 144.1530 - val_accuracy: 0.0588\n",
      "Epoch 3518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6391 - accuracy: 0.0000e+00 - val_loss: 142.8463 - val_accuracy: 0.0588\n",
      "Epoch 3519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2592 - accuracy: 0.0000e+00 - val_loss: 141.5249 - val_accuracy: 0.0588\n",
      "Epoch 3520/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2376 - accuracy: 0.0156 - val_loss: 133.3788 - val_accuracy: 0.0588\n",
      "Epoch 3521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8161 - accuracy: 0.0000e+00 - val_loss: 127.8551 - val_accuracy: 0.0000e+00\n",
      "Epoch 3522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0278 - accuracy: 0.0156 - val_loss: 125.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0558 - accuracy: 0.0156 - val_loss: 122.2528 - val_accuracy: 0.0000e+00\n",
      "Epoch 3524/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 32.6200 - accuracy: 0.0000e+00 - val_loss: 121.3829 - val_accuracy: 0.0000e+00\n",
      "Epoch 3525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4901 - accuracy: 0.0000e+00 - val_loss: 129.2953 - val_accuracy: 0.0000e+00\n",
      "Epoch 3526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6075 - accuracy: 0.0312 - val_loss: 135.8520 - val_accuracy: 0.0588\n",
      "Epoch 3527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2151 - accuracy: 0.0156 - val_loss: 134.0776 - val_accuracy: 0.0000e+00\n",
      "Epoch 3528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.9188 - accuracy: 0.0000e+00 - val_loss: 123.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 3529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7812 - accuracy: 0.0000e+00 - val_loss: 119.5150 - val_accuracy: 0.0000e+00\n",
      "Epoch 3530/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 47.7484 - accuracy: 0.0156 - val_loss: 119.5407 - val_accuracy: 0.0588\n",
      "Epoch 3531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.1777 - accuracy: 0.0156 - val_loss: 125.0015 - val_accuracy: 0.0000e+00\n",
      "Epoch 3532/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.6435 - accuracy: 0.0000e+00 - val_loss: 130.4716 - val_accuracy: 0.0588\n",
      "Epoch 3533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8861 - accuracy: 0.0156 - val_loss: 128.7461 - val_accuracy: 0.0588\n",
      "Epoch 3534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0153 - accuracy: 0.0156 - val_loss: 128.5075 - val_accuracy: 0.0588\n",
      "Epoch 3535/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 38.4563 - accuracy: 0.0156 - val_loss: 124.6608 - val_accuracy: 0.0588\n",
      "Epoch 3536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2975 - accuracy: 0.0156 - val_loss: 122.6686 - val_accuracy: 0.0588\n",
      "Epoch 3537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.2278 - accuracy: 0.0000e+00 - val_loss: 117.8664 - val_accuracy: 0.0588\n",
      "Epoch 3538/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8936 - accuracy: 0.0000e+00 - val_loss: 118.3648 - val_accuracy: 0.0588\n",
      "Epoch 3539/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4777 - accuracy: 0.0156 - val_loss: 122.8662 - val_accuracy: 0.0588\n",
      "Epoch 3540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9567 - accuracy: 0.0000e+00 - val_loss: 127.4602 - val_accuracy: 0.0588\n",
      "Epoch 3541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.3796 - accuracy: 0.0000e+00 - val_loss: 131.5602 - val_accuracy: 0.0588\n",
      "Epoch 3542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4435 - accuracy: 0.0000e+00 - val_loss: 131.2219 - val_accuracy: 0.0588\n",
      "Epoch 3543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2894 - accuracy: 0.0156 - val_loss: 125.8370 - val_accuracy: 0.0588\n",
      "Epoch 3544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5969 - accuracy: 0.0000e+00 - val_loss: 125.9151 - val_accuracy: 0.0588\n",
      "Epoch 3545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.4893 - accuracy: 0.0156 - val_loss: 131.1734 - val_accuracy: 0.0588\n",
      "Epoch 3546/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.8857 - accuracy: 0.0156 - val_loss: 136.1902 - val_accuracy: 0.0588\n",
      "Epoch 3547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9712 - accuracy: 0.0000e+00 - val_loss: 133.4469 - val_accuracy: 0.0588\n",
      "Epoch 3548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0920 - accuracy: 0.0312 - val_loss: 135.7957 - val_accuracy: 0.0588\n",
      "Epoch 3549/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.1325 - accuracy: 0.0000e+00 - val_loss: 125.6920 - val_accuracy: 0.0588\n",
      "Epoch 3550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8407 - accuracy: 0.0156 - val_loss: 115.8303 - val_accuracy: 0.0588\n",
      "Epoch 3551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9737 - accuracy: 0.0000e+00 - val_loss: 116.4359 - val_accuracy: 0.0588\n",
      "Epoch 3552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5570 - accuracy: 0.0156 - val_loss: 123.5292 - val_accuracy: 0.0588\n",
      "Epoch 3553/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7396 - accuracy: 0.0312 - val_loss: 129.4042 - val_accuracy: 0.0588\n",
      "Epoch 3554/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 50.0654 - accuracy: 0.0156 - val_loss: 133.8990 - val_accuracy: 0.0588\n",
      "Epoch 3555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2933 - accuracy: 0.0000e+00 - val_loss: 143.0954 - val_accuracy: 0.0588\n",
      "Epoch 3556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1912 - accuracy: 0.0000e+00 - val_loss: 147.0469 - val_accuracy: 0.1176\n",
      "Epoch 3557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8910 - accuracy: 0.0312 - val_loss: 148.1236 - val_accuracy: 0.0588\n",
      "Epoch 3558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2174 - accuracy: 0.0156 - val_loss: 144.4283 - val_accuracy: 0.0588\n",
      "Epoch 3559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3381 - accuracy: 0.0000e+00 - val_loss: 133.4205 - val_accuracy: 0.1176\n",
      "Epoch 3560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 49.4333 - accuracy: 0.0000e+00 - val_loss: 127.0234 - val_accuracy: 0.1176\n",
      "Epoch 3561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0487 - accuracy: 0.0156 - val_loss: 130.0294 - val_accuracy: 0.0588\n",
      "Epoch 3562/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3873 - accuracy: 0.0312 - val_loss: 132.4250 - val_accuracy: 0.0588\n",
      "Epoch 3563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5977 - accuracy: 0.0156 - val_loss: 124.9199 - val_accuracy: 0.0588\n",
      "Epoch 3564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6946 - accuracy: 0.0625 - val_loss: 119.1349 - val_accuracy: 0.0588\n",
      "Epoch 3565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3871 - accuracy: 0.0156 - val_loss: 115.7026 - val_accuracy: 0.1176\n",
      "Epoch 3566/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5277 - accuracy: 0.0000e+00 - val_loss: 113.4851 - val_accuracy: 0.0588\n",
      "Epoch 3567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2401 - accuracy: 0.0156 - val_loss: 121.0042 - val_accuracy: 0.1176\n",
      "Epoch 3568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5033 - accuracy: 0.0000e+00 - val_loss: 133.3510 - val_accuracy: 0.0588\n",
      "Epoch 3569/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 37.1899 - accuracy: 0.0156 - val_loss: 137.9650 - val_accuracy: 0.0588\n",
      "Epoch 3570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.3870 - accuracy: 0.0000e+00 - val_loss: 129.7012 - val_accuracy: 0.0588\n",
      "Epoch 3571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1204 - accuracy: 0.0000e+00 - val_loss: 123.0111 - val_accuracy: 0.0588\n",
      "Epoch 3572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.4239 - accuracy: 0.0312 - val_loss: 123.4136 - val_accuracy: 0.0588\n",
      "Epoch 3573/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.4877 - accuracy: 0.0000e+00 - val_loss: 128.0623 - val_accuracy: 0.0588\n",
      "Epoch 3574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4884 - accuracy: 0.0000e+00 - val_loss: 123.9815 - val_accuracy: 0.0588\n",
      "Epoch 3575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7454 - accuracy: 0.0000e+00 - val_loss: 115.8109 - val_accuracy: 0.0588\n",
      "Epoch 3576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8862 - accuracy: 0.0156 - val_loss: 113.5925 - val_accuracy: 0.0588\n",
      "Epoch 3577/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 33.3317 - accuracy: 0.0000e+00 - val_loss: 116.7405 - val_accuracy: 0.0588\n",
      "Epoch 3578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5791 - accuracy: 0.0312 - val_loss: 120.2933 - val_accuracy: 0.0588\n",
      "Epoch 3579/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 29.2825 - accuracy: 0.0312 - val_loss: 135.6321 - val_accuracy: 0.0588\n",
      "Epoch 3580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9012 - accuracy: 0.0156 - val_loss: 151.1228 - val_accuracy: 0.0588\n",
      "Epoch 3581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1278 - accuracy: 0.0000e+00 - val_loss: 148.1175 - val_accuracy: 0.0588\n",
      "Epoch 3582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2219 - accuracy: 0.0156 - val_loss: 133.9722 - val_accuracy: 0.0588\n",
      "Epoch 3583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7739 - accuracy: 0.0000e+00 - val_loss: 130.3371 - val_accuracy: 0.0588\n",
      "Epoch 3584/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.0314 - accuracy: 0.0000e+00 - val_loss: 130.3063 - val_accuracy: 0.0588\n",
      "Epoch 3585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2226 - accuracy: 0.0156 - val_loss: 144.6648 - val_accuracy: 0.0588\n",
      "Epoch 3586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0402 - accuracy: 0.0156 - val_loss: 155.7528 - val_accuracy: 0.0588\n",
      "Epoch 3587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3638 - accuracy: 0.0000e+00 - val_loss: 154.4678 - val_accuracy: 0.0588\n",
      "Epoch 3588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1548 - accuracy: 0.0156 - val_loss: 135.0894 - val_accuracy: 0.0000e+00\n",
      "Epoch 3589/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 43.8677 - accuracy: 0.0156 - val_loss: 117.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 3590/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6164 - accuracy: 0.0000e+00 - val_loss: 120.2043 - val_accuracy: 0.0000e+00\n",
      "Epoch 3591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6357 - accuracy: 0.0000e+00 - val_loss: 125.6701 - val_accuracy: 0.0000e+00\n",
      "Epoch 3592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0240 - accuracy: 0.0000e+00 - val_loss: 135.2737 - val_accuracy: 0.0588\n",
      "Epoch 3593/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 48.4852 - accuracy: 0.0156 - val_loss: 137.2322 - val_accuracy: 0.0588\n",
      "Epoch 3594/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 44.2073 - accuracy: 0.0156 - val_loss: 129.1624 - val_accuracy: 0.0588\n",
      "Epoch 3595/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 36.1183 - accuracy: 0.0000e+00 - val_loss: 115.1110 - val_accuracy: 0.0588\n",
      "Epoch 3596/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 39.5931 - accuracy: 0.0000e+00 - val_loss: 107.8449 - val_accuracy: 0.0588\n",
      "Epoch 3597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2685 - accuracy: 0.0000e+00 - val_loss: 108.3264 - val_accuracy: 0.0588\n",
      "Epoch 3598/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 35.9889 - accuracy: 0.0000e+00 - val_loss: 121.6351 - val_accuracy: 0.0588\n",
      "Epoch 3599/10000\n",
      "64/64 [==============================] - 0s 219us/step - loss: 23.1312 - accuracy: 0.0156 - val_loss: 135.0422 - val_accuracy: 0.0588\n",
      "Epoch 3600/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 33.9101 - accuracy: 0.0156 - val_loss: 134.3109 - val_accuracy: 0.0588\n",
      "Epoch 3601/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 41.0242 - accuracy: 0.0156 - val_loss: 124.6924 - val_accuracy: 0.0588\n",
      "Epoch 3602/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 27.9918 - accuracy: 0.0000e+00 - val_loss: 118.6724 - val_accuracy: 0.0588\n",
      "Epoch 3603/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 26.4964 - accuracy: 0.0000e+00 - val_loss: 120.4080 - val_accuracy: 0.0588\n",
      "Epoch 3604/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 37.2526 - accuracy: 0.0156 - val_loss: 124.5899 - val_accuracy: 0.0588\n",
      "Epoch 3605/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.9099 - accuracy: 0.0156 - val_loss: 131.1334 - val_accuracy: 0.1176\n",
      "Epoch 3606/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 42.2920 - accuracy: 0.0000e+00 - val_loss: 139.8013 - val_accuracy: 0.0588\n",
      "Epoch 3607/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 34.6667 - accuracy: 0.0156 - val_loss: 137.6305 - val_accuracy: 0.0588\n",
      "Epoch 3608/10000\n",
      "64/64 [==============================] - 0s 219us/step - loss: 43.7948 - accuracy: 0.0000e+00 - val_loss: 134.7238 - val_accuracy: 0.0588\n",
      "Epoch 3609/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 37.2052 - accuracy: 0.0000e+00 - val_loss: 129.7184 - val_accuracy: 0.0588\n",
      "Epoch 3610/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 198us/step - loss: 41.9284 - accuracy: 0.0000e+00 - val_loss: 123.5745 - val_accuracy: 0.1176\n",
      "Epoch 3611/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.6214 - accuracy: 0.0000e+00 - val_loss: 122.7261 - val_accuracy: 0.1176\n",
      "Epoch 3612/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 37.5607 - accuracy: 0.0000e+00 - val_loss: 131.0331 - val_accuracy: 0.0588\n",
      "Epoch 3613/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 36.9657 - accuracy: 0.0156 - val_loss: 141.3878 - val_accuracy: 0.0588\n",
      "Epoch 3614/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 31.3578 - accuracy: 0.0156 - val_loss: 138.5567 - val_accuracy: 0.0588\n",
      "Epoch 3615/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 36.6171 - accuracy: 0.0156 - val_loss: 129.4194 - val_accuracy: 0.1176\n",
      "Epoch 3616/10000\n",
      "64/64 [==============================] - 0s 212us/step - loss: 25.5110 - accuracy: 0.0156 - val_loss: 120.7453 - val_accuracy: 0.1176\n",
      "Epoch 3617/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 46.2580 - accuracy: 0.0156 - val_loss: 112.5363 - val_accuracy: 0.0588\n",
      "Epoch 3618/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 45.1876 - accuracy: 0.0000e+00 - val_loss: 110.3796 - val_accuracy: 0.0588\n",
      "Epoch 3619/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 27.2591 - accuracy: 0.0000e+00 - val_loss: 116.5886 - val_accuracy: 0.0588\n",
      "Epoch 3620/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.8011 - accuracy: 0.0156 - val_loss: 123.1484 - val_accuracy: 0.0588\n",
      "Epoch 3621/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 33.7419 - accuracy: 0.0469 - val_loss: 131.8248 - val_accuracy: 0.0588\n",
      "Epoch 3622/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 38.0851 - accuracy: 0.0156 - val_loss: 124.0455 - val_accuracy: 0.0588\n",
      "Epoch 3623/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 37.6356 - accuracy: 0.0000e+00 - val_loss: 123.0142 - val_accuracy: 0.0588\n",
      "Epoch 3624/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 48.8943 - accuracy: 0.0000e+00 - val_loss: 123.4488 - val_accuracy: 0.0588\n",
      "Epoch 3625/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.8804 - accuracy: 0.0000e+00 - val_loss: 126.0437 - val_accuracy: 0.0588\n",
      "Epoch 3626/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.3230 - accuracy: 0.0000e+00 - val_loss: 134.9064 - val_accuracy: 0.0588\n",
      "Epoch 3627/10000\n",
      "64/64 [==============================] - 0s 252us/step - loss: 36.7672 - accuracy: 0.0000e+00 - val_loss: 136.2915 - val_accuracy: 0.0588\n",
      "Epoch 3628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.9286 - accuracy: 0.0000e+00 - val_loss: 127.6899 - val_accuracy: 0.0588\n",
      "Epoch 3629/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 31.3360 - accuracy: 0.0000e+00 - val_loss: 113.9641 - val_accuracy: 0.0588\n",
      "Epoch 3630/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 50.6569 - accuracy: 0.0000e+00 - val_loss: 105.2984 - val_accuracy: 0.0588\n",
      "Epoch 3631/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 45.0248 - accuracy: 0.0156 - val_loss: 102.0959 - val_accuracy: 0.0588\n",
      "Epoch 3632/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 41.1121 - accuracy: 0.0000e+00 - val_loss: 115.2248 - val_accuracy: 0.0588\n",
      "Epoch 3633/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 44.5603 - accuracy: 0.0156 - val_loss: 138.1491 - val_accuracy: 0.0588\n",
      "Epoch 3634/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 46.9183 - accuracy: 0.0000e+00 - val_loss: 155.5193 - val_accuracy: 0.0588\n",
      "Epoch 3635/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.8229 - accuracy: 0.0000e+00 - val_loss: 151.0028 - val_accuracy: 0.0588\n",
      "Epoch 3636/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 35.8091 - accuracy: 0.0156 - val_loss: 129.9526 - val_accuracy: 0.0588\n",
      "Epoch 3637/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.4561 - accuracy: 0.0000e+00 - val_loss: 115.5442 - val_accuracy: 0.0588\n",
      "Epoch 3638/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.8299 - accuracy: 0.0000e+00 - val_loss: 110.7184 - val_accuracy: 0.0588\n",
      "Epoch 3639/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 37.9504 - accuracy: 0.0312 - val_loss: 119.0907 - val_accuracy: 0.0588\n",
      "Epoch 3640/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 37.7811 - accuracy: 0.0000e+00 - val_loss: 127.9027 - val_accuracy: 0.1176\n",
      "Epoch 3641/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.8517 - accuracy: 0.0625 - val_loss: 131.6795 - val_accuracy: 0.0588\n",
      "Epoch 3642/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.1618 - accuracy: 0.0156 - val_loss: 120.4655 - val_accuracy: 0.0588\n",
      "Epoch 3643/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 50.5131 - accuracy: 0.0156 - val_loss: 115.7133 - val_accuracy: 0.1176\n",
      "Epoch 3644/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.6464 - accuracy: 0.0000e+00 - val_loss: 117.9547 - val_accuracy: 0.1176\n",
      "Epoch 3645/10000\n",
      "64/64 [==============================] - 0s 166us/step - loss: 31.2356 - accuracy: 0.0156 - val_loss: 121.4702 - val_accuracy: 0.1176\n",
      "Epoch 3646/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 36.9287 - accuracy: 0.0000e+00 - val_loss: 122.0532 - val_accuracy: 0.1176\n",
      "Epoch 3647/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 47.9725 - accuracy: 0.0156 - val_loss: 122.8805 - val_accuracy: 0.1176\n",
      "Epoch 3648/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 47.8370 - accuracy: 0.0000e+00 - val_loss: 122.7758 - val_accuracy: 0.0588\n",
      "Epoch 3649/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.4302 - accuracy: 0.0156 - val_loss: 120.9639 - val_accuracy: 0.0588\n",
      "Epoch 3650/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.2436 - accuracy: 0.0000e+00 - val_loss: 127.4310 - val_accuracy: 0.0588\n",
      "Epoch 3651/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.5789 - accuracy: 0.0000e+00 - val_loss: 132.1439 - val_accuracy: 0.0588\n",
      "Epoch 3652/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 42.9430 - accuracy: 0.0156 - val_loss: 128.4573 - val_accuracy: 0.0588\n",
      "Epoch 3653/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 43.4291 - accuracy: 0.0000e+00 - val_loss: 129.4936 - val_accuracy: 0.0588\n",
      "Epoch 3654/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.8333 - accuracy: 0.0156 - val_loss: 130.0127 - val_accuracy: 0.0588\n",
      "Epoch 3655/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 28.9740 - accuracy: 0.0000e+00 - val_loss: 127.1843 - val_accuracy: 0.1176\n",
      "Epoch 3656/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 54.0185 - accuracy: 0.0000e+00 - val_loss: 123.4061 - val_accuracy: 0.0588\n",
      "Epoch 3657/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 38.9115 - accuracy: 0.0000e+00 - val_loss: 123.0864 - val_accuracy: 0.0588\n",
      "Epoch 3658/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.9956 - accuracy: 0.0000e+00 - val_loss: 123.3392 - val_accuracy: 0.0588\n",
      "Epoch 3659/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.6954 - accuracy: 0.0156 - val_loss: 123.4831 - val_accuracy: 0.0588\n",
      "Epoch 3660/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 39.3978 - accuracy: 0.0156 - val_loss: 135.5121 - val_accuracy: 0.0588\n",
      "Epoch 3661/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 41.2595 - accuracy: 0.0000e+00 - val_loss: 144.2235 - val_accuracy: 0.0588\n",
      "Epoch 3662/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 42.6947 - accuracy: 0.0312 - val_loss: 142.7358 - val_accuracy: 0.0588\n",
      "Epoch 3663/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 26.7461 - accuracy: 0.0312 - val_loss: 138.5460 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3664/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 36.5674 - accuracy: 0.0000e+00 - val_loss: 134.8834 - val_accuracy: 0.0588\n",
      "Epoch 3665/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.8218 - accuracy: 0.0312 - val_loss: 127.2359 - val_accuracy: 0.0588\n",
      "Epoch 3666/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 43.5826 - accuracy: 0.0156 - val_loss: 124.4204 - val_accuracy: 0.0588\n",
      "Epoch 3667/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.2820 - accuracy: 0.0000e+00 - val_loss: 124.6757 - val_accuracy: 0.1176\n",
      "Epoch 3668/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.1168 - accuracy: 0.0000e+00 - val_loss: 137.4374 - val_accuracy: 0.0588\n",
      "Epoch 3669/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 29.5408 - accuracy: 0.0156 - val_loss: 144.0367 - val_accuracy: 0.0588\n",
      "Epoch 3670/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 51.3262 - accuracy: 0.0000e+00 - val_loss: 133.7022 - val_accuracy: 0.0588\n",
      "Epoch 3671/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 30.6482 - accuracy: 0.0312 - val_loss: 122.3210 - val_accuracy: 0.0588\n",
      "Epoch 3672/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 36.3021 - accuracy: 0.0156 - val_loss: 115.5915 - val_accuracy: 0.0588\n",
      "Epoch 3673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 50.6723 - accuracy: 0.0000e+00 - val_loss: 114.3739 - val_accuracy: 0.0588\n",
      "Epoch 3674/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 64.7727 - accuracy: 0.0469 - val_loss: 123.9517 - val_accuracy: 0.0000e+00\n",
      "Epoch 3675/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 35.0563 - accuracy: 0.0312 - val_loss: 131.7881 - val_accuracy: 0.0000e+00\n",
      "Epoch 3676/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 37.7856 - accuracy: 0.0000e+00 - val_loss: 133.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 3677/10000\n",
      "64/64 [==============================] - 0s 208us/step - loss: 30.3854 - accuracy: 0.0156 - val_loss: 136.1741 - val_accuracy: 0.0588\n",
      "Epoch 3678/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 39.0432 - accuracy: 0.0312 - val_loss: 131.8311 - val_accuracy: 0.0588\n",
      "Epoch 3679/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 34.8325 - accuracy: 0.0000e+00 - val_loss: 123.3106 - val_accuracy: 0.0588\n",
      "Epoch 3680/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.0329 - accuracy: 0.0000e+00 - val_loss: 114.6016 - val_accuracy: 0.0588\n",
      "Epoch 3681/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.6878 - accuracy: 0.0000e+00 - val_loss: 105.2196 - val_accuracy: 0.0588\n",
      "Epoch 3682/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 37.6288 - accuracy: 0.0000e+00 - val_loss: 99.4409 - val_accuracy: 0.0000e+00\n",
      "Epoch 3683/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 36.3006 - accuracy: 0.0000e+00 - val_loss: 111.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 3684/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 36.2532 - accuracy: 0.0156 - val_loss: 118.6949 - val_accuracy: 0.0000e+00\n",
      "Epoch 3685/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.2606 - accuracy: 0.0156 - val_loss: 116.4662 - val_accuracy: 0.0000e+00\n",
      "Epoch 3686/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 47.1273 - accuracy: 0.0000e+00 - val_loss: 111.2112 - val_accuracy: 0.0000e+00\n",
      "Epoch 3687/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1116 - accuracy: 0.0000e+00 - val_loss: 103.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 3688/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 52.9620 - accuracy: 0.0000e+00 - val_loss: 100.3202 - val_accuracy: 0.0000e+00\n",
      "Epoch 3689/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 38.2614 - accuracy: 0.0156 - val_loss: 104.2124 - val_accuracy: 0.0000e+00\n",
      "Epoch 3690/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 27.1721 - accuracy: 0.0156 - val_loss: 109.4008 - val_accuracy: 0.0588\n",
      "Epoch 3691/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 40.4896 - accuracy: 0.0000e+00 - val_loss: 125.9389 - val_accuracy: 0.0000e+00\n",
      "Epoch 3692/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 44.6952 - accuracy: 0.0312 - val_loss: 150.9591 - val_accuracy: 0.0000e+00\n",
      "Epoch 3693/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 45.7780 - accuracy: 0.0312 - val_loss: 151.6183 - val_accuracy: 0.0000e+00\n",
      "Epoch 3694/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 66.8003 - accuracy: 0.0156 - val_loss: 127.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 3695/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.5784 - accuracy: 0.0156 - val_loss: 106.5801 - val_accuracy: 0.0588\n",
      "Epoch 3696/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 43.5054 - accuracy: 0.0156 - val_loss: 102.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 3697/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 63.1004 - accuracy: 0.0000e+00 - val_loss: 103.2716 - val_accuracy: 0.0000e+00\n",
      "Epoch 3698/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 48.5241 - accuracy: 0.0156 - val_loss: 117.3573 - val_accuracy: 0.0588\n",
      "Epoch 3699/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 32.0806 - accuracy: 0.0156 - val_loss: 135.1287 - val_accuracy: 0.0588\n",
      "Epoch 3700/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.8758 - accuracy: 0.0156 - val_loss: 138.9446 - val_accuracy: 0.0588\n",
      "Epoch 3701/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.0773 - accuracy: 0.0156 - val_loss: 131.0329 - val_accuracy: 0.0588\n",
      "Epoch 3702/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 30.6758 - accuracy: 0.0312 - val_loss: 117.6527 - val_accuracy: 0.0000e+00\n",
      "Epoch 3703/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 30.4013 - accuracy: 0.0000e+00 - val_loss: 110.8807 - val_accuracy: 0.0588\n",
      "Epoch 3704/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 42.9156 - accuracy: 0.0000e+00 - val_loss: 114.7569 - val_accuracy: 0.0588\n",
      "Epoch 3705/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 32.8422 - accuracy: 0.0000e+00 - val_loss: 126.8691 - val_accuracy: 0.0000e+00\n",
      "Epoch 3706/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 31.0452 - accuracy: 0.0000e+00 - val_loss: 139.2571 - val_accuracy: 0.0588\n",
      "Epoch 3707/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 30.0758 - accuracy: 0.0156 - val_loss: 144.6449 - val_accuracy: 0.0588\n",
      "Epoch 3708/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 38.6184 - accuracy: 0.0000e+00 - val_loss: 137.6405 - val_accuracy: 0.0588\n",
      "Epoch 3709/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8247 - accuracy: 0.0000e+00 - val_loss: 136.0161 - val_accuracy: 0.0588\n",
      "Epoch 3710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3143 - accuracy: 0.0000e+00 - val_loss: 129.6769 - val_accuracy: 0.0588\n",
      "Epoch 3711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4773 - accuracy: 0.0156 - val_loss: 119.6992 - val_accuracy: 0.1176\n",
      "Epoch 3712/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 29.6155 - accuracy: 0.0000e+00 - val_loss: 115.0339 - val_accuracy: 0.0588\n",
      "Epoch 3713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5688 - accuracy: 0.0156 - val_loss: 115.9796 - val_accuracy: 0.0588\n",
      "Epoch 3714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.0337 - accuracy: 0.0156 - val_loss: 140.2581 - val_accuracy: 0.0588\n",
      "Epoch 3715/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.9896 - accuracy: 0.0156 - val_loss: 157.6743 - val_accuracy: 0.0588\n",
      "Epoch 3716/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 44.9932 - accuracy: 0.0156 - val_loss: 155.8367 - val_accuracy: 0.0588\n",
      "Epoch 3717/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 32.1588 - accuracy: 0.0156 - val_loss: 137.8895 - val_accuracy: 0.0588\n",
      "Epoch 3718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1888 - accuracy: 0.0000e+00 - val_loss: 123.6043 - val_accuracy: 0.0588\n",
      "Epoch 3719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1437 - accuracy: 0.0156 - val_loss: 120.2000 - val_accuracy: 0.1176\n",
      "Epoch 3720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4887 - accuracy: 0.0156 - val_loss: 135.9581 - val_accuracy: 0.0588\n",
      "Epoch 3721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7309 - accuracy: 0.0000e+00 - val_loss: 141.6222 - val_accuracy: 0.0588\n",
      "Epoch 3722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2598 - accuracy: 0.0000e+00 - val_loss: 123.8623 - val_accuracy: 0.0588\n",
      "Epoch 3723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5308 - accuracy: 0.0312 - val_loss: 109.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4999 - accuracy: 0.0156 - val_loss: 103.8158 - val_accuracy: 0.0588\n",
      "Epoch 3725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8358 - accuracy: 0.0000e+00 - val_loss: 106.7937 - val_accuracy: 0.0588\n",
      "Epoch 3726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3783 - accuracy: 0.0000e+00 - val_loss: 105.6747 - val_accuracy: 0.0588\n",
      "Epoch 3727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9323 - accuracy: 0.0156 - val_loss: 107.4082 - val_accuracy: 0.0588\n",
      "Epoch 3728/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.8958 - accuracy: 0.0000e+00 - val_loss: 113.4205 - val_accuracy: 0.0588\n",
      "Epoch 3729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6437 - accuracy: 0.0156 - val_loss: 121.3686 - val_accuracy: 0.0000e+00\n",
      "Epoch 3730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0175 - accuracy: 0.0000e+00 - val_loss: 123.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 3731/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 41.0032 - accuracy: 0.0156 - val_loss: 127.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 3732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0527 - accuracy: 0.0000e+00 - val_loss: 126.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 3733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1575 - accuracy: 0.0000e+00 - val_loss: 129.3701 - val_accuracy: 0.0000e+00\n",
      "Epoch 3734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 52.9860 - accuracy: 0.0000e+00 - val_loss: 136.3055 - val_accuracy: 0.0588\n",
      "Epoch 3735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4737 - accuracy: 0.0000e+00 - val_loss: 139.8511 - val_accuracy: 0.0588\n",
      "Epoch 3736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8607 - accuracy: 0.0000e+00 - val_loss: 136.9650 - val_accuracy: 0.0588\n",
      "Epoch 3737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2143 - accuracy: 0.0000e+00 - val_loss: 132.8741 - val_accuracy: 0.1176\n",
      "Epoch 3738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0960 - accuracy: 0.0156 - val_loss: 127.8439 - val_accuracy: 0.1176\n",
      "Epoch 3739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6419 - accuracy: 0.0000e+00 - val_loss: 119.2495 - val_accuracy: 0.1176\n",
      "Epoch 3740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6602 - accuracy: 0.0312 - val_loss: 118.7572 - val_accuracy: 0.1176\n",
      "Epoch 3741/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 29.2666 - accuracy: 0.0000e+00 - val_loss: 123.3303 - val_accuracy: 0.0588\n",
      "Epoch 3742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3906 - accuracy: 0.0156 - val_loss: 133.2939 - val_accuracy: 0.0588\n",
      "Epoch 3743/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8229 - accuracy: 0.0000e+00 - val_loss: 152.9276 - val_accuracy: 0.0588\n",
      "Epoch 3744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1422 - accuracy: 0.0000e+00 - val_loss: 159.8643 - val_accuracy: 0.0588\n",
      "Epoch 3745/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6519 - accuracy: 0.0000e+00 - val_loss: 152.7955 - val_accuracy: 0.0588\n",
      "Epoch 3746/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0203 - accuracy: 0.0156 - val_loss: 144.4373 - val_accuracy: 0.0588\n",
      "Epoch 3747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9403 - accuracy: 0.0000e+00 - val_loss: 142.5860 - val_accuracy: 0.0588\n",
      "Epoch 3748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7594 - accuracy: 0.0000e+00 - val_loss: 141.1530 - val_accuracy: 0.0588\n",
      "Epoch 3749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1482 - accuracy: 0.0156 - val_loss: 137.5367 - val_accuracy: 0.0588\n",
      "Epoch 3750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1716 - accuracy: 0.0000e+00 - val_loss: 133.7225 - val_accuracy: 0.0588\n",
      "Epoch 3751/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.2496 - accuracy: 0.0000e+00 - val_loss: 130.1820 - val_accuracy: 0.0588\n",
      "Epoch 3752/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.8680 - accuracy: 0.0000e+00 - val_loss: 131.2682 - val_accuracy: 0.0588\n",
      "Epoch 3753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7738 - accuracy: 0.0156 - val_loss: 136.6602 - val_accuracy: 0.0588\n",
      "Epoch 3754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.4832 - accuracy: 0.0000e+00 - val_loss: 141.8241 - val_accuracy: 0.0588\n",
      "Epoch 3755/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 46.4109 - accuracy: 0.0000e+00 - val_loss: 139.6339 - val_accuracy: 0.0588\n",
      "Epoch 3756/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9211 - accuracy: 0.0156 - val_loss: 136.7585 - val_accuracy: 0.1176\n",
      "Epoch 3757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0909 - accuracy: 0.0000e+00 - val_loss: 129.6088 - val_accuracy: 0.0588\n",
      "Epoch 3758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4930 - accuracy: 0.0156 - val_loss: 134.4464 - val_accuracy: 0.0588\n",
      "Epoch 3759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4259 - accuracy: 0.0000e+00 - val_loss: 140.5321 - val_accuracy: 0.0588\n",
      "Epoch 3760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3578 - accuracy: 0.0156 - val_loss: 144.2290 - val_accuracy: 0.1176\n",
      "Epoch 3761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2492 - accuracy: 0.0156 - val_loss: 138.4528 - val_accuracy: 0.1176\n",
      "Epoch 3762/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.2097 - accuracy: 0.0000e+00 - val_loss: 129.3848 - val_accuracy: 0.0588\n",
      "Epoch 3763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5572 - accuracy: 0.0156 - val_loss: 126.4485 - val_accuracy: 0.1176\n",
      "Epoch 3764/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 51.6307 - accuracy: 0.0156 - val_loss: 128.3698 - val_accuracy: 0.0588\n",
      "Epoch 3765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2805 - accuracy: 0.0156 - val_loss: 131.0396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9195 - accuracy: 0.0156 - val_loss: 135.7890 - val_accuracy: 0.0000e+00\n",
      "Epoch 3767/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6011 - accuracy: 0.0000e+00 - val_loss: 135.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 3768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.2144 - accuracy: 0.0312 - val_loss: 129.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 3769/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 34.1632 - accuracy: 0.0000e+00 - val_loss: 130.8677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3770/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 42.2902 - accuracy: 0.0000e+00 - val_loss: 132.8121 - val_accuracy: 0.0588\n",
      "Epoch 3771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6067 - accuracy: 0.0000e+00 - val_loss: 136.7819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7718 - accuracy: 0.0312 - val_loss: 144.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 3773/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3958 - accuracy: 0.0000e+00 - val_loss: 140.6785 - val_accuracy: 0.0588\n",
      "Epoch 3774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7734 - accuracy: 0.0000e+00 - val_loss: 131.6897 - val_accuracy: 0.0000e+00\n",
      "Epoch 3775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3139 - accuracy: 0.0156 - val_loss: 119.0385 - val_accuracy: 0.0000e+00\n",
      "Epoch 3776/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 31.5430 - accuracy: 0.0000e+00 - val_loss: 117.2769 - val_accuracy: 0.0000e+00\n",
      "Epoch 3777/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.2676 - accuracy: 0.0000e+00 - val_loss: 126.5156 - val_accuracy: 0.0000e+00\n",
      "Epoch 3778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5338 - accuracy: 0.0000e+00 - val_loss: 138.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 3779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2799 - accuracy: 0.0000e+00 - val_loss: 147.3073 - val_accuracy: 0.0000e+00\n",
      "Epoch 3780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9477 - accuracy: 0.0000e+00 - val_loss: 145.1568 - val_accuracy: 0.0588\n",
      "Epoch 3781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.4408 - accuracy: 0.0000e+00 - val_loss: 145.2951 - val_accuracy: 0.0000e+00\n",
      "Epoch 3782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6769 - accuracy: 0.0156 - val_loss: 140.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 3783/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3710 - accuracy: 0.0156 - val_loss: 135.0831 - val_accuracy: 0.0588\n",
      "Epoch 3784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.1035 - accuracy: 0.0000e+00 - val_loss: 127.4543 - val_accuracy: 0.0588\n",
      "Epoch 3785/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9040 - accuracy: 0.0000e+00 - val_loss: 120.3822 - val_accuracy: 0.0588\n",
      "Epoch 3786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8087 - accuracy: 0.0000e+00 - val_loss: 119.9554 - val_accuracy: 0.0588\n",
      "Epoch 3787/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 39.7625 - accuracy: 0.0156 - val_loss: 117.4164 - val_accuracy: 0.0588\n",
      "Epoch 3788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5237 - accuracy: 0.0000e+00 - val_loss: 119.1342 - val_accuracy: 0.0588\n",
      "Epoch 3789/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.5380 - accuracy: 0.0156 - val_loss: 123.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 3790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0428 - accuracy: 0.0000e+00 - val_loss: 130.0004 - val_accuracy: 0.0000e+00\n",
      "Epoch 3791/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 29.1821 - accuracy: 0.0000e+00 - val_loss: 136.8939 - val_accuracy: 0.0588\n",
      "Epoch 3792/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.2200 - accuracy: 0.0000e+00 - val_loss: 142.4931 - val_accuracy: 0.0588\n",
      "Epoch 3793/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3831 - accuracy: 0.0000e+00 - val_loss: 146.9351 - val_accuracy: 0.0588\n",
      "Epoch 3794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6714 - accuracy: 0.0000e+00 - val_loss: 132.4756 - val_accuracy: 0.0588\n",
      "Epoch 3795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8628 - accuracy: 0.0156 - val_loss: 120.2564 - val_accuracy: 0.1176\n",
      "Epoch 3796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9944 - accuracy: 0.0469 - val_loss: 114.4909 - val_accuracy: 0.0588\n",
      "Epoch 3797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5230 - accuracy: 0.0156 - val_loss: 122.1566 - val_accuracy: 0.0588\n",
      "Epoch 3798/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 48.4881 - accuracy: 0.0000e+00 - val_loss: 129.9696 - val_accuracy: 0.1176\n",
      "Epoch 3799/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 38.8098 - accuracy: 0.0000e+00 - val_loss: 127.5656 - val_accuracy: 0.0588\n",
      "Epoch 3800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6975 - accuracy: 0.0000e+00 - val_loss: 125.1249 - val_accuracy: 0.0588\n",
      "Epoch 3801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8297 - accuracy: 0.0000e+00 - val_loss: 132.0846 - val_accuracy: 0.0588\n",
      "Epoch 3802/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.0595 - accuracy: 0.0000e+00 - val_loss: 137.2363 - val_accuracy: 0.0588\n",
      "Epoch 3803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6290 - accuracy: 0.0156 - val_loss: 141.0486 - val_accuracy: 0.0588\n",
      "Epoch 3804/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.8734 - accuracy: 0.0000e+00 - val_loss: 142.3187 - val_accuracy: 0.0588\n",
      "Epoch 3805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.8694 - accuracy: 0.0000e+00 - val_loss: 135.5204 - val_accuracy: 0.0588\n",
      "Epoch 3806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9750 - accuracy: 0.0000e+00 - val_loss: 139.0461 - val_accuracy: 0.0588\n",
      "Epoch 3807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.0853 - accuracy: 0.0000e+00 - val_loss: 141.8850 - val_accuracy: 0.0588\n",
      "Epoch 3808/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.5905 - accuracy: 0.0000e+00 - val_loss: 138.5618 - val_accuracy: 0.0588\n",
      "Epoch 3809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8439 - accuracy: 0.0156 - val_loss: 131.2656 - val_accuracy: 0.0588\n",
      "Epoch 3810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6987 - accuracy: 0.0156 - val_loss: 125.9536 - val_accuracy: 0.0588\n",
      "Epoch 3811/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9876 - accuracy: 0.0000e+00 - val_loss: 122.1668 - val_accuracy: 0.0588\n",
      "Epoch 3812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2082 - accuracy: 0.0000e+00 - val_loss: 124.2552 - val_accuracy: 0.0588\n",
      "Epoch 3813/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 34.2806 - accuracy: 0.0156 - val_loss: 128.8634 - val_accuracy: 0.0588\n",
      "Epoch 3814/10000\n",
      "64/64 [==============================] - 0s 202us/step - loss: 43.2412 - accuracy: 0.0000e+00 - val_loss: 132.4486 - val_accuracy: 0.0588\n",
      "Epoch 3815/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 33.8642 - accuracy: 0.0000e+00 - val_loss: 135.8373 - val_accuracy: 0.0588\n",
      "Epoch 3816/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 43.5985 - accuracy: 0.0000e+00 - val_loss: 137.6210 - val_accuracy: 0.0588\n",
      "Epoch 3817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6476 - accuracy: 0.0000e+00 - val_loss: 140.4191 - val_accuracy: 0.0588\n",
      "Epoch 3818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1904 - accuracy: 0.0000e+00 - val_loss: 134.8389 - val_accuracy: 0.0588\n",
      "Epoch 3819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9353 - accuracy: 0.0156 - val_loss: 130.8927 - val_accuracy: 0.0588\n",
      "Epoch 3820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3583 - accuracy: 0.0312 - val_loss: 130.1658 - val_accuracy: 0.0588\n",
      "Epoch 3821/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.9769 - accuracy: 0.0156 - val_loss: 133.7444 - val_accuracy: 0.0588\n",
      "Epoch 3822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7896 - accuracy: 0.0000e+00 - val_loss: 145.8733 - val_accuracy: 0.0588\n",
      "Epoch 3823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0303 - accuracy: 0.0000e+00 - val_loss: 141.1445 - val_accuracy: 0.0588\n",
      "Epoch 3824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2492 - accuracy: 0.0000e+00 - val_loss: 128.4461 - val_accuracy: 0.0588\n",
      "Epoch 3825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4839 - accuracy: 0.0000e+00 - val_loss: 124.0897 - val_accuracy: 0.0588\n",
      "Epoch 3826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4569 - accuracy: 0.0000e+00 - val_loss: 124.5715 - val_accuracy: 0.0588\n",
      "Epoch 3827/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 48.5742 - accuracy: 0.0156 - val_loss: 121.3135 - val_accuracy: 0.0588\n",
      "Epoch 3828/10000\n",
      "64/64 [==============================] - 0s 687us/step - loss: 34.2138 - accuracy: 0.0312 - val_loss: 127.7781 - val_accuracy: 0.0588\n",
      "Epoch 3829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1338 - accuracy: 0.0000e+00 - val_loss: 126.3745 - val_accuracy: 0.0588\n",
      "Epoch 3830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3661 - accuracy: 0.0156 - val_loss: 119.6941 - val_accuracy: 0.0588\n",
      "Epoch 3831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.3204 - accuracy: 0.0156 - val_loss: 122.5589 - val_accuracy: 0.0588\n",
      "Epoch 3832/10000\n",
      "64/64 [==============================] - 0s 266us/step - loss: 21.8102 - accuracy: 0.0312 - val_loss: 125.1549 - val_accuracy: 0.0000e+00\n",
      "Epoch 3833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4317 - accuracy: 0.0156 - val_loss: 135.8198 - val_accuracy: 0.0000e+00\n",
      "Epoch 3834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9486 - accuracy: 0.0156 - val_loss: 150.4502 - val_accuracy: 0.0000e+00\n",
      "Epoch 3835/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.4979 - accuracy: 0.0156 - val_loss: 159.4111 - val_accuracy: 0.0000e+00\n",
      "Epoch 3836/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 28.5393 - accuracy: 0.0000e+00 - val_loss: 148.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 3837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.1489 - accuracy: 0.0000e+00 - val_loss: 136.8356 - val_accuracy: 0.0000e+00\n",
      "Epoch 3838/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 44.7596 - accuracy: 0.0156 - val_loss: 124.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 3839/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.8975 - accuracy: 0.0156 - val_loss: 118.0218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3840/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5403 - accuracy: 0.0000e+00 - val_loss: 117.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 3841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7686 - accuracy: 0.0000e+00 - val_loss: 118.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 3842/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 39.4006 - accuracy: 0.0156 - val_loss: 122.1861 - val_accuracy: 0.0000e+00\n",
      "Epoch 3843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1757 - accuracy: 0.0000e+00 - val_loss: 119.4892 - val_accuracy: 0.0000e+00\n",
      "Epoch 3844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2046 - accuracy: 0.0000e+00 - val_loss: 122.7452 - val_accuracy: 0.0000e+00\n",
      "Epoch 3845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1621 - accuracy: 0.0156 - val_loss: 124.6911 - val_accuracy: 0.0000e+00\n",
      "Epoch 3846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1623 - accuracy: 0.0156 - val_loss: 125.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 3847/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3535 - accuracy: 0.0000e+00 - val_loss: 132.2584 - val_accuracy: 0.0000e+00\n",
      "Epoch 3848/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.5510 - accuracy: 0.0156 - val_loss: 129.3714 - val_accuracy: 0.0000e+00\n",
      "Epoch 3849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1817 - accuracy: 0.0156 - val_loss: 126.0534 - val_accuracy: 0.0000e+00\n",
      "Epoch 3850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5274 - accuracy: 0.0000e+00 - val_loss: 125.0393 - val_accuracy: 0.0000e+00\n",
      "Epoch 3851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2088 - accuracy: 0.0312 - val_loss: 128.1919 - val_accuracy: 0.0000e+00\n",
      "Epoch 3852/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2657 - accuracy: 0.0312 - val_loss: 132.3464 - val_accuracy: 0.0000e+00\n",
      "Epoch 3853/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 27.3090 - accuracy: 0.0156 - val_loss: 134.5660 - val_accuracy: 0.0588\n",
      "Epoch 3854/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.2812 - accuracy: 0.0000e+00 - val_loss: 131.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9417 - accuracy: 0.0000e+00 - val_loss: 127.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 3856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1638 - accuracy: 0.0156 - val_loss: 125.7386 - val_accuracy: 0.0588\n",
      "Epoch 3857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2514 - accuracy: 0.0000e+00 - val_loss: 127.8120 - val_accuracy: 0.0588\n",
      "Epoch 3858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5016 - accuracy: 0.0000e+00 - val_loss: 129.5303 - val_accuracy: 0.0588\n",
      "Epoch 3859/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3923 - accuracy: 0.0000e+00 - val_loss: 137.0466 - val_accuracy: 0.0000e+00\n",
      "Epoch 3860/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2309 - accuracy: 0.0000e+00 - val_loss: 139.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 3861/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5967 - accuracy: 0.0312 - val_loss: 139.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 3862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3142 - accuracy: 0.0156 - val_loss: 127.8842 - val_accuracy: 0.0588\n",
      "Epoch 3863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.9227 - accuracy: 0.0156 - val_loss: 111.1274 - val_accuracy: 0.0588\n",
      "Epoch 3864/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 36.9487 - accuracy: 0.0000e+00 - val_loss: 107.2343 - val_accuracy: 0.0588\n",
      "Epoch 3865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7982 - accuracy: 0.0000e+00 - val_loss: 113.0953 - val_accuracy: 0.0588\n",
      "Epoch 3866/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 31.8566 - accuracy: 0.0156 - val_loss: 121.4624 - val_accuracy: 0.0588\n",
      "Epoch 3867/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6264 - accuracy: 0.0000e+00 - val_loss: 133.7416 - val_accuracy: 0.0588\n",
      "Epoch 3868/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.9135 - accuracy: 0.0156 - val_loss: 148.9909 - val_accuracy: 0.0000e+00\n",
      "Epoch 3869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3606 - accuracy: 0.0000e+00 - val_loss: 155.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 3870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 58.6119 - accuracy: 0.0156 - val_loss: 148.2287 - val_accuracy: 0.0000e+00\n",
      "Epoch 3871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3219 - accuracy: 0.0000e+00 - val_loss: 139.3820 - val_accuracy: 0.0000e+00\n",
      "Epoch 3872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.9781 - accuracy: 0.0000e+00 - val_loss: 126.7990 - val_accuracy: 0.0000e+00\n",
      "Epoch 3873/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 31.2950 - accuracy: 0.0000e+00 - val_loss: 121.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 3874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9861 - accuracy: 0.0000e+00 - val_loss: 122.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 3875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.2936 - accuracy: 0.0000e+00 - val_loss: 127.3329 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3876/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.8007 - accuracy: 0.0156 - val_loss: 131.7160 - val_accuracy: 0.0000e+00\n",
      "Epoch 3877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 53.3296 - accuracy: 0.0000e+00 - val_loss: 128.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 3878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5315 - accuracy: 0.0000e+00 - val_loss: 126.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 3879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1599 - accuracy: 0.0156 - val_loss: 130.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 3880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8047 - accuracy: 0.0000e+00 - val_loss: 140.2530 - val_accuracy: 0.0000e+00\n",
      "Epoch 3881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0446 - accuracy: 0.0000e+00 - val_loss: 148.1270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2690 - accuracy: 0.0000e+00 - val_loss: 151.6032 - val_accuracy: 0.0000e+00\n",
      "Epoch 3883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1972 - accuracy: 0.0156 - val_loss: 142.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 3884/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2486 - accuracy: 0.0156 - val_loss: 127.2042 - val_accuracy: 0.0000e+00\n",
      "Epoch 3885/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.5140 - accuracy: 0.0000e+00 - val_loss: 117.1518 - val_accuracy: 0.0000e+00\n",
      "Epoch 3886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5929 - accuracy: 0.0156 - val_loss: 115.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 3887/10000\n",
      "64/64 [==============================] - 0s 64us/step - loss: 27.8050 - accuracy: 0.0000e+00 - val_loss: 125.7615 - val_accuracy: 0.0000e+00\n",
      "Epoch 3888/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 24.9229 - accuracy: 0.0156 - val_loss: 129.2870 - val_accuracy: 0.0000e+00\n",
      "Epoch 3889/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8920 - accuracy: 0.0000e+00 - val_loss: 135.5613 - val_accuracy: 0.0000e+00\n",
      "Epoch 3890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4247 - accuracy: 0.0000e+00 - val_loss: 136.7446 - val_accuracy: 0.0000e+00\n",
      "Epoch 3891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4035 - accuracy: 0.0156 - val_loss: 129.5936 - val_accuracy: 0.0588\n",
      "Epoch 3892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3147 - accuracy: 0.0000e+00 - val_loss: 129.7677 - val_accuracy: 0.0000e+00\n",
      "Epoch 3893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7363 - accuracy: 0.0000e+00 - val_loss: 140.3052 - val_accuracy: 0.0000e+00\n",
      "Epoch 3894/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3583 - accuracy: 0.0156 - val_loss: 137.2747 - val_accuracy: 0.0000e+00\n",
      "Epoch 3895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8703 - accuracy: 0.0000e+00 - val_loss: 133.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 3896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6541 - accuracy: 0.0156 - val_loss: 129.6221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5650 - accuracy: 0.0000e+00 - val_loss: 129.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 3898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7529 - accuracy: 0.0000e+00 - val_loss: 131.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3899/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 36.7047 - accuracy: 0.0156 - val_loss: 131.6177 - val_accuracy: 0.0588\n",
      "Epoch 3900/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 34.8210 - accuracy: 0.0156 - val_loss: 128.7391 - val_accuracy: 0.0588\n",
      "Epoch 3901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7495 - accuracy: 0.0000e+00 - val_loss: 127.4633 - val_accuracy: 0.0588\n",
      "Epoch 3902/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3032 - accuracy: 0.0000e+00 - val_loss: 124.1994 - val_accuracy: 0.0588\n",
      "Epoch 3903/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.4553 - accuracy: 0.0000e+00 - val_loss: 130.2303 - val_accuracy: 0.0588\n",
      "Epoch 3904/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3971 - accuracy: 0.0000e+00 - val_loss: 132.7901 - val_accuracy: 0.0588\n",
      "Epoch 3905/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.9641 - accuracy: 0.0000e+00 - val_loss: 137.4878 - val_accuracy: 0.0588\n",
      "Epoch 3906/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 29.2749 - accuracy: 0.0000e+00 - val_loss: 134.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 3907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4224 - accuracy: 0.0000e+00 - val_loss: 124.7557 - val_accuracy: 0.0000e+00\n",
      "Epoch 3908/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 41.6854 - accuracy: 0.0000e+00 - val_loss: 119.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 3909/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.6013 - accuracy: 0.0156 - val_loss: 120.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 3910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4917 - accuracy: 0.0000e+00 - val_loss: 127.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 3911/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 33.0269 - accuracy: 0.0000e+00 - val_loss: 131.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 3912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5996 - accuracy: 0.0156 - val_loss: 141.4503 - val_accuracy: 0.0000e+00\n",
      "Epoch 3913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3557 - accuracy: 0.0156 - val_loss: 135.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 3914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0301 - accuracy: 0.0156 - val_loss: 127.4795 - val_accuracy: 0.0000e+00\n",
      "Epoch 3915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2914 - accuracy: 0.0000e+00 - val_loss: 127.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 3916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1726 - accuracy: 0.0000e+00 - val_loss: 134.3076 - val_accuracy: 0.0000e+00\n",
      "Epoch 3917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1115 - accuracy: 0.0156 - val_loss: 138.0408 - val_accuracy: 0.0000e+00\n",
      "Epoch 3918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0379 - accuracy: 0.0156 - val_loss: 134.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 3919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3747 - accuracy: 0.0000e+00 - val_loss: 127.8318 - val_accuracy: 0.0000e+00\n",
      "Epoch 3920/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3412 - accuracy: 0.0000e+00 - val_loss: 124.8296 - val_accuracy: 0.0000e+00\n",
      "Epoch 3921/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3896 - accuracy: 0.0000e+00 - val_loss: 121.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 3922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3945 - accuracy: 0.0156 - val_loss: 120.7194 - val_accuracy: 0.0000e+00\n",
      "Epoch 3923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1659 - accuracy: 0.0156 - val_loss: 128.4114 - val_accuracy: 0.0000e+00\n",
      "Epoch 3924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0151 - accuracy: 0.0156 - val_loss: 134.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 3925/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3345 - accuracy: 0.0156 - val_loss: 143.3596 - val_accuracy: 0.0000e+00\n",
      "Epoch 3926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5922 - accuracy: 0.0156 - val_loss: 139.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 3927/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 23.2438 - accuracy: 0.0312 - val_loss: 130.5819 - val_accuracy: 0.0000e+00\n",
      "Epoch 3928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0727 - accuracy: 0.0156 - val_loss: 119.9720 - val_accuracy: 0.0000e+00\n",
      "Epoch 3929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0536 - accuracy: 0.0000e+00 - val_loss: 116.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 3930/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4848 - accuracy: 0.0156 - val_loss: 119.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 3931/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.5728 - accuracy: 0.0000e+00 - val_loss: 133.5795 - val_accuracy: 0.0000e+00\n",
      "Epoch 3932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5398 - accuracy: 0.0156 - val_loss: 140.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 3933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5685 - accuracy: 0.0156 - val_loss: 143.8178 - val_accuracy: 0.0000e+00\n",
      "Epoch 3934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2220 - accuracy: 0.0000e+00 - val_loss: 142.8742 - val_accuracy: 0.0000e+00\n",
      "Epoch 3935/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 27.6159 - accuracy: 0.0156 - val_loss: 133.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 3936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2733 - accuracy: 0.0000e+00 - val_loss: 127.0813 - val_accuracy: 0.0588\n",
      "Epoch 3937/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6923 - accuracy: 0.0156 - val_loss: 130.5514 - val_accuracy: 0.0000e+00\n",
      "Epoch 3938/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 52.9908 - accuracy: 0.0000e+00 - val_loss: 134.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 3939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5162 - accuracy: 0.0000e+00 - val_loss: 133.0399 - val_accuracy: 0.0000e+00\n",
      "Epoch 3940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0990 - accuracy: 0.0156 - val_loss: 126.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 3941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4121 - accuracy: 0.0156 - val_loss: 124.5278 - val_accuracy: 0.0000e+00\n",
      "Epoch 3942/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.9786 - accuracy: 0.0312 - val_loss: 124.6106 - val_accuracy: 0.0000e+00\n",
      "Epoch 3943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8574 - accuracy: 0.0156 - val_loss: 127.7596 - val_accuracy: 0.0000e+00\n",
      "Epoch 3944/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 22.6956 - accuracy: 0.0156 - val_loss: 134.7487 - val_accuracy: 0.0000e+00\n",
      "Epoch 3945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4287 - accuracy: 0.0156 - val_loss: 142.5105 - val_accuracy: 0.0588\n",
      "Epoch 3946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3074 - accuracy: 0.0469 - val_loss: 148.9816 - val_accuracy: 0.0588\n",
      "Epoch 3947/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 38.7044 - accuracy: 0.0000e+00 - val_loss: 150.6023 - val_accuracy: 0.0588\n",
      "Epoch 3948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2987 - accuracy: 0.0156 - val_loss: 135.4866 - val_accuracy: 0.0588\n",
      "Epoch 3949/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6080 - accuracy: 0.0156 - val_loss: 121.5172 - val_accuracy: 0.1176\n",
      "Epoch 3950/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 32.7109 - accuracy: 0.0156 - val_loss: 117.3961 - val_accuracy: 0.1176\n",
      "Epoch 3951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5179 - accuracy: 0.0156 - val_loss: 119.3598 - val_accuracy: 0.0588\n",
      "Epoch 3952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8057 - accuracy: 0.0156 - val_loss: 124.3844 - val_accuracy: 0.0588\n",
      "Epoch 3953/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 25.9623 - accuracy: 0.0000e+00 - val_loss: 123.6912 - val_accuracy: 0.0588\n",
      "Epoch 3954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3450 - accuracy: 0.0156 - val_loss: 122.6670 - val_accuracy: 0.0588\n",
      "Epoch 3955/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 41.9432 - accuracy: 0.0000e+00 - val_loss: 121.4738 - val_accuracy: 0.0588\n",
      "Epoch 3956/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.3702 - accuracy: 0.0156 - val_loss: 124.6300 - val_accuracy: 0.0588\n",
      "Epoch 3957/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7823 - accuracy: 0.0156 - val_loss: 126.1946 - val_accuracy: 0.0588\n",
      "Epoch 3958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6105 - accuracy: 0.0000e+00 - val_loss: 136.7112 - val_accuracy: 0.0588\n",
      "Epoch 3959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2836 - accuracy: 0.0156 - val_loss: 139.0418 - val_accuracy: 0.0588\n",
      "Epoch 3960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6224 - accuracy: 0.0000e+00 - val_loss: 130.4984 - val_accuracy: 0.0588\n",
      "Epoch 3961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6726 - accuracy: 0.0156 - val_loss: 119.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 3962/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2235 - accuracy: 0.0000e+00 - val_loss: 119.7220 - val_accuracy: 0.0000e+00\n",
      "Epoch 3963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7524 - accuracy: 0.0000e+00 - val_loss: 128.0892 - val_accuracy: 0.0000e+00\n",
      "Epoch 3964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2758 - accuracy: 0.0000e+00 - val_loss: 134.1756 - val_accuracy: 0.0000e+00\n",
      "Epoch 3965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9964 - accuracy: 0.0312 - val_loss: 129.7875 - val_accuracy: 0.0000e+00\n",
      "Epoch 3966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2363 - accuracy: 0.0156 - val_loss: 124.2538 - val_accuracy: 0.0588\n",
      "Epoch 3967/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 44.1919 - accuracy: 0.0000e+00 - val_loss: 123.5894 - val_accuracy: 0.0588\n",
      "Epoch 3968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7269 - accuracy: 0.0000e+00 - val_loss: 128.1440 - val_accuracy: 0.0000e+00\n",
      "Epoch 3969/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.9601 - accuracy: 0.0000e+00 - val_loss: 134.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 3970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0230 - accuracy: 0.0156 - val_loss: 130.1449 - val_accuracy: 0.0000e+00\n",
      "Epoch 3971/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8386 - accuracy: 0.0000e+00 - val_loss: 113.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 3972/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4739 - accuracy: 0.0312 - val_loss: 105.0081 - val_accuracy: 0.0588\n",
      "Epoch 3973/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3127 - accuracy: 0.0156 - val_loss: 104.9332 - val_accuracy: 0.0588\n",
      "Epoch 3974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1489 - accuracy: 0.0000e+00 - val_loss: 116.2688 - val_accuracy: 0.0588\n",
      "Epoch 3975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6873 - accuracy: 0.0312 - val_loss: 125.2331 - val_accuracy: 0.0588\n",
      "Epoch 3976/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 30.0620 - accuracy: 0.0000e+00 - val_loss: 129.9372 - val_accuracy: 0.0588\n",
      "Epoch 3977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5559 - accuracy: 0.0156 - val_loss: 128.7714 - val_accuracy: 0.0588\n",
      "Epoch 3978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.7190 - accuracy: 0.0000e+00 - val_loss: 124.5787 - val_accuracy: 0.1176\n",
      "Epoch 3979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5063 - accuracy: 0.0156 - val_loss: 120.0876 - val_accuracy: 0.1176\n",
      "Epoch 3980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5781 - accuracy: 0.0156 - val_loss: 123.9947 - val_accuracy: 0.1176\n",
      "Epoch 3981/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 30.0894 - accuracy: 0.0156 - val_loss: 135.6472 - val_accuracy: 0.0588\n",
      "Epoch 3982/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 23.6684 - accuracy: 0.0000e+00 - val_loss: 150.8576 - val_accuracy: 0.0588\n",
      "Epoch 3983/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9486 - accuracy: 0.0156 - val_loss: 154.6888 - val_accuracy: 0.0588\n",
      "Epoch 3984/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 35.8280 - accuracy: 0.0156 - val_loss: 132.7230 - val_accuracy: 0.0588\n",
      "Epoch 3985/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0756 - accuracy: 0.0000e+00 - val_loss: 122.2883 - val_accuracy: 0.0588\n",
      "Epoch 3986/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6565 - accuracy: 0.0000e+00 - val_loss: 116.9219 - val_accuracy: 0.0588\n",
      "Epoch 3987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4604 - accuracy: 0.0000e+00 - val_loss: 117.7571 - val_accuracy: 0.1176\n",
      "Epoch 3988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5994 - accuracy: 0.0156 - val_loss: 125.2608 - val_accuracy: 0.0588\n",
      "Epoch 3989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4806 - accuracy: 0.0000e+00 - val_loss: 125.4307 - val_accuracy: 0.1176\n",
      "Epoch 3990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1711 - accuracy: 0.0000e+00 - val_loss: 127.8253 - val_accuracy: 0.1176\n",
      "Epoch 3991/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 39.1965 - accuracy: 0.0000e+00 - val_loss: 127.5874 - val_accuracy: 0.1176\n",
      "Epoch 3992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5513 - accuracy: 0.0000e+00 - val_loss: 131.2761 - val_accuracy: 0.1176\n",
      "Epoch 3993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1306 - accuracy: 0.0156 - val_loss: 138.5721 - val_accuracy: 0.0588\n",
      "Epoch 3994/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.5736 - accuracy: 0.0000e+00 - val_loss: 141.9705 - val_accuracy: 0.0588\n",
      "Epoch 3995/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2074 - accuracy: 0.0156 - val_loss: 136.0161 - val_accuracy: 0.1176\n",
      "Epoch 3996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6473 - accuracy: 0.0156 - val_loss: 129.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 3997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.3730 - accuracy: 0.0312 - val_loss: 125.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 3998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.3431 - accuracy: 0.0000e+00 - val_loss: 125.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 3999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4411 - accuracy: 0.0000e+00 - val_loss: 131.9384 - val_accuracy: 0.0000e+00\n",
      "Epoch 4000/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9337 - accuracy: 0.0156 - val_loss: 139.1002 - val_accuracy: 0.0588\n",
      "Epoch 4001/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9285 - accuracy: 0.0156 - val_loss: 138.6139 - val_accuracy: 0.0000e+00\n",
      "Epoch 4002/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0841 - accuracy: 0.0156 - val_loss: 132.9463 - val_accuracy: 0.0000e+00\n",
      "Epoch 4003/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 34.5260 - accuracy: 0.0156 - val_loss: 136.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 4004/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.5119 - accuracy: 0.0156 - val_loss: 133.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 4005/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 58.7891 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 56.3997 - accuracy: 0.0000e+00 - val_loss: 132.2330 - val_accuracy: 0.0000e+00\n",
      "Epoch 4006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5620 - accuracy: 0.0156 - val_loss: 137.8499 - val_accuracy: 0.0000e+00\n",
      "Epoch 4007/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 45.7712 - accuracy: 0.0000e+00 - val_loss: 137.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 4008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4711 - accuracy: 0.0312 - val_loss: 130.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 4009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.7871 - accuracy: 0.0156 - val_loss: 123.1560 - val_accuracy: 0.0000e+00\n",
      "Epoch 4010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9821 - accuracy: 0.0000e+00 - val_loss: 126.4535 - val_accuracy: 0.0000e+00\n",
      "Epoch 4011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1609 - accuracy: 0.0156 - val_loss: 139.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 4012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3506 - accuracy: 0.0312 - val_loss: 145.4239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4013/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.7909 - accuracy: 0.0000e+00 - val_loss: 145.5510 - val_accuracy: 0.0000e+00\n",
      "Epoch 4014/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6804 - accuracy: 0.0156 - val_loss: 139.5876 - val_accuracy: 0.0000e+00\n",
      "Epoch 4015/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 28.0572 - accuracy: 0.0000e+00 - val_loss: 132.4734 - val_accuracy: 0.0000e+00\n",
      "Epoch 4016/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3826 - accuracy: 0.0000e+00 - val_loss: 124.9470 - val_accuracy: 0.0588\n",
      "Epoch 4017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.7398 - accuracy: 0.0000e+00 - val_loss: 129.6881 - val_accuracy: 0.0588\n",
      "Epoch 4018/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7252 - accuracy: 0.0312 - val_loss: 131.8136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4019/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.0308 - accuracy: 0.0312 - val_loss: 138.0447 - val_accuracy: 0.0000e+00\n",
      "Epoch 4020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2457 - accuracy: 0.0156 - val_loss: 130.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 4021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6219 - accuracy: 0.0000e+00 - val_loss: 129.3993 - val_accuracy: 0.0000e+00\n",
      "Epoch 4022/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 23.6804 - accuracy: 0.0156 - val_loss: 124.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 4023/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 38.9349 - accuracy: 0.0156 - val_loss: 115.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 4024/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 26.1951 - accuracy: 0.0312 - val_loss: 110.5501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4025/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 38.4433 - accuracy: 0.0156 - val_loss: 114.4529 - val_accuracy: 0.0000e+00\n",
      "Epoch 4026/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 29.0786 - accuracy: 0.0156 - val_loss: 122.8676 - val_accuracy: 0.0000e+00\n",
      "Epoch 4027/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.6130 - accuracy: 0.0000e+00 - val_loss: 122.9382 - val_accuracy: 0.0000e+00\n",
      "Epoch 4028/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.9370 - accuracy: 0.0000e+00 - val_loss: 121.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 4029/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 48.8210 - accuracy: 0.0156 - val_loss: 129.0756 - val_accuracy: 0.0588\n",
      "Epoch 4030/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 29.0341 - accuracy: 0.0000e+00 - val_loss: 145.6063 - val_accuracy: 0.0588\n",
      "Epoch 4031/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 44.3588 - accuracy: 0.0156 - val_loss: 153.5206 - val_accuracy: 0.0588\n",
      "Epoch 4032/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.3366 - accuracy: 0.0000e+00 - val_loss: 140.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4033/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 42.4659 - accuracy: 0.0156 - val_loss: 120.4555 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4034/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 33.7158 - accuracy: 0.0000e+00 - val_loss: 108.8368 - val_accuracy: 0.0000e+00\n",
      "Epoch 4035/10000\n",
      "64/64 [==============================] - 0s 208us/step - loss: 38.6047 - accuracy: 0.0000e+00 - val_loss: 108.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4036/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 42.9014 - accuracy: 0.0000e+00 - val_loss: 130.0703 - val_accuracy: 0.0000e+00\n",
      "Epoch 4037/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 35.0122 - accuracy: 0.0000e+00 - val_loss: 148.1123 - val_accuracy: 0.0000e+00\n",
      "Epoch 4038/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.9299 - accuracy: 0.0000e+00 - val_loss: 145.5904 - val_accuracy: 0.0000e+00\n",
      "Epoch 4039/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.0876 - accuracy: 0.0312 - val_loss: 135.4015 - val_accuracy: 0.0000e+00\n",
      "Epoch 4040/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.9494 - accuracy: 0.0000e+00 - val_loss: 129.4504 - val_accuracy: 0.0000e+00\n",
      "Epoch 4041/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 42.5257 - accuracy: 0.0000e+00 - val_loss: 123.0785 - val_accuracy: 0.0000e+00\n",
      "Epoch 4042/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 33.8951 - accuracy: 0.0000e+00 - val_loss: 128.3609 - val_accuracy: 0.0000e+00\n",
      "Epoch 4043/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.5758 - accuracy: 0.0156 - val_loss: 129.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 4044/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.2602 - accuracy: 0.0000e+00 - val_loss: 130.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 4045/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.2805 - accuracy: 0.0469 - val_loss: 127.8032 - val_accuracy: 0.0000e+00\n",
      "Epoch 4046/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.7707 - accuracy: 0.0156 - val_loss: 131.2127 - val_accuracy: 0.0000e+00\n",
      "Epoch 4047/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 32.8113 - accuracy: 0.0156 - val_loss: 129.2229 - val_accuracy: 0.0000e+00\n",
      "Epoch 4048/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 32.9193 - accuracy: 0.0156 - val_loss: 126.1448 - val_accuracy: 0.0000e+00\n",
      "Epoch 4049/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.7941 - accuracy: 0.0156 - val_loss: 127.2266 - val_accuracy: 0.0000e+00\n",
      "Epoch 4050/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.2561 - accuracy: 0.0000e+00 - val_loss: 132.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 4051/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.4527 - accuracy: 0.0312 - val_loss: 132.5596 - val_accuracy: 0.0000e+00\n",
      "Epoch 4052/10000\n",
      "64/64 [==============================] - 0s 169us/step - loss: 36.6215 - accuracy: 0.0312 - val_loss: 132.9832 - val_accuracy: 0.0000e+00\n",
      "Epoch 4053/10000\n",
      "64/64 [==============================] - 0s 32us/step - loss: 33.4010 - accuracy: 0.0000e+00 - val_loss: 133.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 4054/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 24.7768 - accuracy: 0.0000e+00 - val_loss: 132.6215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4055/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.4176 - accuracy: 0.0469 - val_loss: 136.7145 - val_accuracy: 0.0000e+00\n",
      "Epoch 4056/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 38.7741 - accuracy: 0.0156 - val_loss: 143.3221 - val_accuracy: 0.0000e+00\n",
      "Epoch 4057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4943 - accuracy: 0.0156 - val_loss: 143.5260 - val_accuracy: 0.0588\n",
      "Epoch 4058/10000\n",
      "64/64 [==============================] - 0s 111us/step - loss: 46.3690 - accuracy: 0.0000e+00 - val_loss: 132.0601 - val_accuracy: 0.0000e+00\n",
      "Epoch 4059/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.6741 - accuracy: 0.0156 - val_loss: 124.5506 - val_accuracy: 0.0000e+00\n",
      "Epoch 4060/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 40.0709 - accuracy: 0.0000e+00 - val_loss: 120.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 4061/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 32.8215 - accuracy: 0.0000e+00 - val_loss: 126.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 4062/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 29.3521 - accuracy: 0.0156 - val_loss: 132.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 4063/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 36.1368 - accuracy: 0.0000e+00 - val_loss: 137.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 4064/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.8226 - accuracy: 0.0312 - val_loss: 136.7204 - val_accuracy: 0.0000e+00\n",
      "Epoch 4065/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 23.1191 - accuracy: 0.0000e+00 - val_loss: 137.7907 - val_accuracy: 0.0588\n",
      "Epoch 4066/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.1088 - accuracy: 0.0156 - val_loss: 134.1220 - val_accuracy: 0.0000e+00\n",
      "Epoch 4067/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.4665 - accuracy: 0.0000e+00 - val_loss: 127.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 4068/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 39.0031 - accuracy: 0.0000e+00 - val_loss: 125.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 4069/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 21.9249 - accuracy: 0.0000e+00 - val_loss: 123.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 4070/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 38.1790 - accuracy: 0.0156 - val_loss: 125.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 4071/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 39.1918 - accuracy: 0.0000e+00 - val_loss: 128.9429 - val_accuracy: 0.0000e+00\n",
      "Epoch 4072/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1005 - accuracy: 0.0469 - val_loss: 134.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 4073/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.8554 - accuracy: 0.0000e+00 - val_loss: 136.5602 - val_accuracy: 0.0000e+00\n",
      "Epoch 4074/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 22.7954 - accuracy: 0.0000e+00 - val_loss: 140.6889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4075/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.3658 - accuracy: 0.0000e+0 - 0s 0us/step - loss: 32.7789 - accuracy: 0.0000e+00 - val_loss: 141.8250 - val_accuracy: 0.0000e+00\n",
      "Epoch 4076/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.0537 - accuracy: 0.0156 - val_loss: 139.4140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4077/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.7633 - accuracy: 0.0000e+00 - val_loss: 139.1698 - val_accuracy: 0.0000e+00\n",
      "Epoch 4078/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 35.4562 - accuracy: 0.0000e+00 - val_loss: 145.5448 - val_accuracy: 0.0000e+00\n",
      "Epoch 4079/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 34.7304 - accuracy: 0.0312 - val_loss: 147.1934 - val_accuracy: 0.0000e+00\n",
      "Epoch 4080/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 27.3180 - accuracy: 0.0156 - val_loss: 134.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 4081/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 34.9185 - accuracy: 0.0312 - val_loss: 128.1631 - val_accuracy: 0.0588\n",
      "Epoch 4082/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 55.8509 - accuracy: 0.0156 - val_loss: 128.3521 - val_accuracy: 0.0000e+00\n",
      "Epoch 4083/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 21.3705 - accuracy: 0.0000e+00 - val_loss: 131.7111 - val_accuracy: 0.1176\n",
      "Epoch 4084/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 37.9524 - accuracy: 0.0000e+00 - val_loss: 133.7082 - val_accuracy: 0.1176\n",
      "Epoch 4085/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 31.3121 - accuracy: 0.0000e+00 - val_loss: 132.9488 - val_accuracy: 0.0588\n",
      "Epoch 4086/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 40.5742 - accuracy: 0.0156 - val_loss: 132.7668 - val_accuracy: 0.1176\n",
      "Epoch 4087/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 27.5726 - accuracy: 0.0156 - val_loss: 133.9728 - val_accuracy: 0.0588\n",
      "Epoch 4088/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.1179 - accuracy: 0.0156 - val_loss: 128.7126 - val_accuracy: 0.0588\n",
      "Epoch 4089/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 32.2683 - accuracy: 0.0156 - val_loss: 132.3616 - val_accuracy: 0.1176\n",
      "Epoch 4090/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 25.1904 - accuracy: 0.0000e+00 - val_loss: 138.5789 - val_accuracy: 0.0588\n",
      "Epoch 4091/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 38.5431 - accuracy: 0.0156 - val_loss: 140.0363 - val_accuracy: 0.0588\n",
      "Epoch 4092/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 41.9967 - accuracy: 0.0156 - val_loss: 138.1344 - val_accuracy: 0.0588\n",
      "Epoch 4093/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.7403 - accuracy: 0.0000e+00 - val_loss: 135.1857 - val_accuracy: 0.0588\n",
      "Epoch 4094/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.8749 - accuracy: 0.0156 - val_loss: 137.1438 - val_accuracy: 0.1176\n",
      "Epoch 4095/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 35.3643 - accuracy: 0.0000e+00 - val_loss: 140.7285 - val_accuracy: 0.0588\n",
      "Epoch 4096/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 27.6126 - accuracy: 0.0312 - val_loss: 145.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 4097/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.3458 - accuracy: 0.0000e+00 - val_loss: 136.7436 - val_accuracy: 0.0588\n",
      "Epoch 4098/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.6159 - accuracy: 0.0000e+00 - val_loss: 129.0040 - val_accuracy: 0.0588\n",
      "Epoch 4099/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.0720 - accuracy: 0.0000e+00 - val_loss: 127.5825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4100/10000\n",
      "64/64 [==============================] - 0s 160us/step - loss: 43.5325 - accuracy: 0.0000e+00 - val_loss: 133.0914 - val_accuracy: 0.0000e+00\n",
      "Epoch 4101/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 34.4549 - accuracy: 0.0000e+00 - val_loss: 145.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 4102/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 30.2116 - accuracy: 0.0000e+00 - val_loss: 151.3409 - val_accuracy: 0.0000e+00\n",
      "Epoch 4103/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 32.9472 - accuracy: 0.0156 - val_loss: 143.6413 - val_accuracy: 0.0000e+00\n",
      "Epoch 4104/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 24.1518 - accuracy: 0.0000e+00 - val_loss: 138.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 4105/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 40.4763 - accuracy: 0.0156 - val_loss: 145.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 4106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8345 - accuracy: 0.0156 - val_loss: 150.5189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9392 - accuracy: 0.0156 - val_loss: 142.8472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4108/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.9359 - accuracy: 0.0000e+00 - val_loss: 132.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 4109/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.7877 - accuracy: 0.0000e+00 - val_loss: 119.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 4110/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 31.3146 - accuracy: 0.0156 - val_loss: 112.6022 - val_accuracy: 0.0588\n",
      "Epoch 4111/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 31.6889 - accuracy: 0.0156 - val_loss: 122.0264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4112/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 29.6022 - accuracy: 0.0156 - val_loss: 144.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 4113/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.1243 - accuracy: 0.0156 - val_loss: 155.2802 - val_accuracy: 0.0000e+00\n",
      "Epoch 4114/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.5028 - accuracy: 0.0000e+00 - val_loss: 142.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 4115/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 44.8839 - accuracy: 0.0156 - val_loss: 139.9929 - val_accuracy: 0.0000e+00\n",
      "Epoch 4116/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 33.5489 - accuracy: 0.0000e+00 - val_loss: 140.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 4117/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 34.0728 - accuracy: 0.0156 - val_loss: 140.1722 - val_accuracy: 0.0000e+00\n",
      "Epoch 4118/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.8061 - accuracy: 0.0000e+00 - val_loss: 136.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 4119/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 29.7450 - accuracy: 0.0000e+00 - val_loss: 134.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 4120/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 42.5710 - accuracy: 0.0000e+00 - val_loss: 129.6279 - val_accuracy: 0.0000e+00\n",
      "Epoch 4121/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 36.3654 - accuracy: 0.0312 - val_loss: 131.8797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4122/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 31.0835 - accuracy: 0.0000e+00 - val_loss: 135.4702 - val_accuracy: 0.0588\n",
      "Epoch 4123/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.9173 - accuracy: 0.0156 - val_loss: 136.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 4124/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.5665 - accuracy: 0.0000e+00 - val_loss: 136.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 4125/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.1379 - accuracy: 0.0000e+00 - val_loss: 139.4370 - val_accuracy: 0.0000e+00\n",
      "Epoch 4126/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 32.0938 - accuracy: 0.0000e+00 - val_loss: 142.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 4127/10000\n",
      "64/64 [==============================] - 0s 210us/step - loss: 38.7242 - accuracy: 0.0000e+00 - val_loss: 147.7077 - val_accuracy: 0.0000e+00\n",
      "Epoch 4128/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 24.3040 - accuracy: 0.0156 - val_loss: 144.2264 - val_accuracy: 0.0000e+00\n",
      "Epoch 4129/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 30.7560 - accuracy: 0.0156 - val_loss: 134.1460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4130/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 41.6078 - accuracy: 0.0000e+00 - val_loss: 130.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 4131/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 40.3298 - accuracy: 0.0156 - val_loss: 133.6915 - val_accuracy: 0.0000e+00\n",
      "Epoch 4132/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 26.5264 - accuracy: 0.0156 - val_loss: 136.3289 - val_accuracy: 0.0000e+00\n",
      "Epoch 4133/10000\n",
      "64/64 [==============================] - 0s 163us/step - loss: 29.9887 - accuracy: 0.0156 - val_loss: 133.4579 - val_accuracy: 0.0000e+00\n",
      "Epoch 4134/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.1092 - accuracy: 0.0156 - val_loss: 132.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 4135/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.5267 - accuracy: 0.0000e+00 - val_loss: 129.9400 - val_accuracy: 0.0000e+00\n",
      "Epoch 4136/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 30.5054 - accuracy: 0.0000e+00 - val_loss: 128.1585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4137/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 28.5296 - accuracy: 0.0312 - val_loss: 132.5145 - val_accuracy: 0.0000e+00\n",
      "Epoch 4138/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 22.5760 - accuracy: 0.0000e+00 - val_loss: 137.6239 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4139/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 22.9322 - accuracy: 0.0312 - val_loss: 138.7265 - val_accuracy: 0.0000e+00\n",
      "Epoch 4140/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 28.5749 - accuracy: 0.0156 - val_loss: 133.4348 - val_accuracy: 0.0000e+00\n",
      "Epoch 4141/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9793 - accuracy: 0.0156 - val_loss: 126.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 4142/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 44.3482 - accuracy: 0.0156 - val_loss: 131.4672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4364 - accuracy: 0.0156 - val_loss: 137.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 4144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2100 - accuracy: 0.0000e+00 - val_loss: 137.5233 - val_accuracy: 0.0000e+00\n",
      "Epoch 4145/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 24.5956 - accuracy: 0.0312 - val_loss: 138.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 4146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0592 - accuracy: 0.0000e+00 - val_loss: 136.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 4147/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.1817 - accuracy: 0.0156 - val_loss: 132.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 4148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7265 - accuracy: 0.0156 - val_loss: 135.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 4149/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4343 - accuracy: 0.0156 - val_loss: 142.9446 - val_accuracy: 0.0000e+00\n",
      "Epoch 4150/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6366 - accuracy: 0.0312 - val_loss: 151.3855 - val_accuracy: 0.0000e+00\n",
      "Epoch 4151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0273 - accuracy: 0.0000e+00 - val_loss: 141.9490 - val_accuracy: 0.0000e+00\n",
      "Epoch 4152/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8040 - accuracy: 0.0000e+00 - val_loss: 137.1702 - val_accuracy: 0.0588\n",
      "Epoch 4153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0612 - accuracy: 0.0156 - val_loss: 128.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.0972 - accuracy: 0.0156 - val_loss: 132.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 4155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4851 - accuracy: 0.0156 - val_loss: 134.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 4156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0827 - accuracy: 0.0000e+00 - val_loss: 136.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 4157/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 35.0677 - accuracy: 0.0000e+00 - val_loss: 141.0599 - val_accuracy: 0.0000e+00\n",
      "Epoch 4158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1130 - accuracy: 0.0000e+00 - val_loss: 145.8301 - val_accuracy: 0.0000e+00\n",
      "Epoch 4159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3393 - accuracy: 0.0000e+00 - val_loss: 138.9408 - val_accuracy: 0.0000e+00\n",
      "Epoch 4160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0531 - accuracy: 0.0312 - val_loss: 129.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 4161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7411 - accuracy: 0.0000e+00 - val_loss: 127.6685 - val_accuracy: 0.0000e+00\n",
      "Epoch 4162/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5911 - accuracy: 0.0000e+00 - val_loss: 144.4805 - val_accuracy: 0.0000e+00\n",
      "Epoch 4163/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4692 - accuracy: 0.0000e+00 - val_loss: 158.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 4164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.7316 - accuracy: 0.0156 - val_loss: 156.7151 - val_accuracy: 0.0588\n",
      "Epoch 4165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5113 - accuracy: 0.0000e+00 - val_loss: 141.5894 - val_accuracy: 0.0588\n",
      "Epoch 4166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5046 - accuracy: 0.0000e+00 - val_loss: 130.5770 - val_accuracy: 0.0588\n",
      "Epoch 4167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6498 - accuracy: 0.0000e+00 - val_loss: 128.5023 - val_accuracy: 0.1176\n",
      "Epoch 4168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5551 - accuracy: 0.0156 - val_loss: 134.9267 - val_accuracy: 0.0588\n",
      "Epoch 4169/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 32.1312 - accuracy: 0.0156 - val_loss: 141.9383 - val_accuracy: 0.0000e+00\n",
      "Epoch 4170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2622 - accuracy: 0.0156 - val_loss: 142.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 4171/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0628 - accuracy: 0.0000e+00 - val_loss: 139.9931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4172/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7432 - accuracy: 0.0000e+00 - val_loss: 139.6838 - val_accuracy: 0.0588\n",
      "Epoch 4173/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.1602 - accuracy: 0.0000e+00 - val_loss: 147.6138 - val_accuracy: 0.0000e+00\n",
      "Epoch 4174/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.1148 - accuracy: 0.0000e+00 - val_loss: 149.1390 - val_accuracy: 0.0000e+00\n",
      "Epoch 4175/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 35.5757 - accuracy: 0.0156 - val_loss: 146.2553 - val_accuracy: 0.0000e+00\n",
      "Epoch 4176/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.9050 - accuracy: 0.0156 - val_loss: 137.8851 - val_accuracy: 0.0000e+00\n",
      "Epoch 4177/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 44.6190 - accuracy: 0.0156 - val_loss: 133.1512 - val_accuracy: 0.0000e+00\n",
      "Epoch 4178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6768 - accuracy: 0.0312 - val_loss: 128.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 4179/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 38.9316 - accuracy: 0.0000e+00 - val_loss: 125.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 4180/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.5734 - accuracy: 0.0156 - val_loss: 133.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 4181/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3036 - accuracy: 0.0156 - val_loss: 140.6462 - val_accuracy: 0.0000e+00\n",
      "Epoch 4182/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0150 - accuracy: 0.0000e+00 - val_loss: 140.4079 - val_accuracy: 0.0000e+00\n",
      "Epoch 4183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8919 - accuracy: 0.0156 - val_loss: 132.3864 - val_accuracy: 0.0000e+00\n",
      "Epoch 4184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4683 - accuracy: 0.0156 - val_loss: 129.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 4185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7481 - accuracy: 0.0000e+00 - val_loss: 133.4806 - val_accuracy: 0.0588\n",
      "Epoch 4186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4898 - accuracy: 0.0000e+00 - val_loss: 143.2058 - val_accuracy: 0.0000e+00\n",
      "Epoch 4187/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 43.8883 - accuracy: 0.0000e+00 - val_loss: 156.0111 - val_accuracy: 0.0588\n",
      "Epoch 4188/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 25.1675 - accuracy: 0.0000e+00 - val_loss: 159.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4189/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.2325 - accuracy: 0.0312 - val_loss: 152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2022 - accuracy: 0.0156 - val_loss: 143.0378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.3187 - accuracy: 0.0000e+00 - val_loss: 139.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 4192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6181 - accuracy: 0.0000e+00 - val_loss: 141.5652 - val_accuracy: 0.0000e+00\n",
      "Epoch 4193/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 37.9335 - accuracy: 0.0156 - val_loss: 142.2904 - val_accuracy: 0.0000e+00\n",
      "Epoch 4194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0808 - accuracy: 0.0000e+00 - val_loss: 142.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 4195/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 33.3873 - accuracy: 0.0000e+00 - val_loss: 130.8484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3804 - accuracy: 0.0156 - val_loss: 129.6023 - val_accuracy: 0.0000e+00\n",
      "Epoch 4197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4320 - accuracy: 0.0156 - val_loss: 136.4432 - val_accuracy: 0.0588\n",
      "Epoch 4198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2332 - accuracy: 0.0000e+00 - val_loss: 150.5208 - val_accuracy: 0.0000e+00\n",
      "Epoch 4199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3774 - accuracy: 0.0156 - val_loss: 160.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 4200/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 35.4488 - accuracy: 0.0000e+00 - val_loss: 148.2480 - val_accuracy: 0.0000e+00\n",
      "Epoch 4201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8143 - accuracy: 0.0000e+00 - val_loss: 136.5436 - val_accuracy: 0.0000e+00\n",
      "Epoch 4202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1111 - accuracy: 0.0156 - val_loss: 127.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 4203/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 44.2214 - accuracy: 0.0156 - val_loss: 130.9908 - val_accuracy: 0.0588\n",
      "Epoch 4204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7773 - accuracy: 0.0000e+00 - val_loss: 135.9466 - val_accuracy: 0.0588\n",
      "Epoch 4205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2539 - accuracy: 0.0156 - val_loss: 142.3152 - val_accuracy: 0.0588\n",
      "Epoch 4206/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 42.6465 - accuracy: 0.0312 - val_loss: 135.7182 - val_accuracy: 0.0588\n",
      "Epoch 4207/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.0999 - accuracy: 0.0000e+00 - val_loss: 129.4199 - val_accuracy: 0.0000e+00\n",
      "Epoch 4208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1215 - accuracy: 0.0312 - val_loss: 125.2397 - val_accuracy: 0.0000e+00\n",
      "Epoch 4209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3008 - accuracy: 0.0000e+00 - val_loss: 135.6089 - val_accuracy: 0.0000e+00\n",
      "Epoch 4210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8731 - accuracy: 0.0156 - val_loss: 146.3718 - val_accuracy: 0.0000e+00\n",
      "Epoch 4211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8302 - accuracy: 0.0000e+00 - val_loss: 150.1558 - val_accuracy: 0.0588\n",
      "Epoch 4212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8373 - accuracy: 0.0312 - val_loss: 149.1588 - val_accuracy: 0.0588\n",
      "Epoch 4213/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.6851 - accuracy: 0.0000e+00 - val_loss: 148.0128 - val_accuracy: 0.0588\n",
      "Epoch 4214/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5009 - accuracy: 0.0000e+00 - val_loss: 139.9625 - val_accuracy: 0.0000e+00\n",
      "Epoch 4215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0657 - accuracy: 0.0000e+00 - val_loss: 125.7093 - val_accuracy: 0.0000e+00\n",
      "Epoch 4216/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 40.7726 - accuracy: 0.0000e+00 - val_loss: 120.5949 - val_accuracy: 0.0000e+00\n",
      "Epoch 4217/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.2604 - accuracy: 0.0000e+00 - val_loss: 117.5786 - val_accuracy: 0.0588\n",
      "Epoch 4218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8503 - accuracy: 0.0000e+00 - val_loss: 127.6134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6425 - accuracy: 0.0000e+00 - val_loss: 135.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 4220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.3687 - accuracy: 0.0000e+00 - val_loss: 136.8714 - val_accuracy: 0.0000e+00\n",
      "Epoch 4221/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1541 - accuracy: 0.0000e+00 - val_loss: 131.4472 - val_accuracy: 0.0000e+00\n",
      "Epoch 4222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8301 - accuracy: 0.0156 - val_loss: 122.3615 - val_accuracy: 0.0000e+00\n",
      "Epoch 4223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9723 - accuracy: 0.0156 - val_loss: 117.4040 - val_accuracy: 0.0000e+00\n",
      "Epoch 4224/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 41.8129 - accuracy: 0.0000e+00 - val_loss: 116.5930 - val_accuracy: 0.0000e+00\n",
      "Epoch 4225/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.9946 - accuracy: 0.0000e+00 - val_loss: 123.0893 - val_accuracy: 0.0000e+00\n",
      "Epoch 4226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4927 - accuracy: 0.0000e+00 - val_loss: 133.6919 - val_accuracy: 0.0000e+00\n",
      "Epoch 4227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2880 - accuracy: 0.0156 - val_loss: 136.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 4228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8733 - accuracy: 0.0156 - val_loss: 128.2234 - val_accuracy: 0.0588\n",
      "Epoch 4229/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5286 - accuracy: 0.0469 - val_loss: 129.2386 - val_accuracy: 0.0000e+00\n",
      "Epoch 4230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8353 - accuracy: 0.0000e+00 - val_loss: 130.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 4231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.1621 - accuracy: 0.0000e+00 - val_loss: 136.1225 - val_accuracy: 0.0588\n",
      "Epoch 4232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9202 - accuracy: 0.0000e+00 - val_loss: 137.0615 - val_accuracy: 0.0000e+00\n",
      "Epoch 4233/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 35.0430 - accuracy: 0.0156 - val_loss: 135.4568 - val_accuracy: 0.0000e+00\n",
      "Epoch 4234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3933 - accuracy: 0.0000e+00 - val_loss: 123.2663 - val_accuracy: 0.0000e+00\n",
      "Epoch 4235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6452 - accuracy: 0.0000e+00 - val_loss: 118.9045 - val_accuracy: 0.0588\n",
      "Epoch 4236/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.3902 - accuracy: 0.0156 - val_loss: 116.2988 - val_accuracy: 0.0000e+00\n",
      "Epoch 4237/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6920 - accuracy: 0.0000e+00 - val_loss: 120.1346 - val_accuracy: 0.0588\n",
      "Epoch 4238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5372 - accuracy: 0.0156 - val_loss: 133.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 4239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4958 - accuracy: 0.0000e+00 - val_loss: 149.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 4240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8877 - accuracy: 0.0000e+00 - val_loss: 151.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 4241/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0703 - accuracy: 0.0000e+00 - val_loss: 155.6190 - val_accuracy: 0.0588\n",
      "Epoch 4242/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 35.8455 - accuracy: 0.0000e+00 - val_loss: 143.8988 - val_accuracy: 0.1176\n",
      "Epoch 4243/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 37.7248 - accuracy: 0.0000e+00 - val_loss: 131.5098 - val_accuracy: 0.0000e+00\n",
      "Epoch 4244/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 39.1343 - accuracy: 0.0000e+00 - val_loss: 120.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0125 - accuracy: 0.0312 - val_loss: 119.0065 - val_accuracy: 0.0588\n",
      "Epoch 4246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2743 - accuracy: 0.0000e+00 - val_loss: 122.2552 - val_accuracy: 0.0588\n",
      "Epoch 4247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9464 - accuracy: 0.0000e+00 - val_loss: 134.1994 - val_accuracy: 0.0588\n",
      "Epoch 4248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2635 - accuracy: 0.0000e+00 - val_loss: 146.5063 - val_accuracy: 0.0588\n",
      "Epoch 4249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6663 - accuracy: 0.0000e+00 - val_loss: 135.6739 - val_accuracy: 0.0588\n",
      "Epoch 4250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6574 - accuracy: 0.0000e+00 - val_loss: 126.1804 - val_accuracy: 0.0588\n",
      "Epoch 4251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4722 - accuracy: 0.0156 - val_loss: 127.6828 - val_accuracy: 0.0588\n",
      "Epoch 4252/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 32.1960 - accuracy: 0.0000e+00 - val_loss: 128.1935 - val_accuracy: 0.0588\n",
      "Epoch 4253/10000\n",
      "64/64 [==============================] - 0s 189us/step - loss: 44.1853 - accuracy: 0.0000e+00 - val_loss: 129.4035 - val_accuracy: 0.1176\n",
      "Epoch 4254/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 54.5239 - accuracy: 0.0000e+00 - val_loss: 135.2065 - val_accuracy: 0.0588\n",
      "Epoch 4255/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 31.4995 - accuracy: 0.0000e+00 - val_loss: 138.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 4256/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 36.3288 - accuracy: 0.0156 - val_loss: 136.3422 - val_accuracy: 0.0000e+00\n",
      "Epoch 4257/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 35.7547 - accuracy: 0.0000e+00 - val_loss: 136.6375 - val_accuracy: 0.0000e+00\n",
      "Epoch 4258/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 25.2721 - accuracy: 0.0156 - val_loss: 138.4961 - val_accuracy: 0.0000e+00\n",
      "Epoch 4259/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.8118 - accuracy: 0.0000e+00 - val_loss: 135.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 4260/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 31.6772 - accuracy: 0.0156 - val_loss: 133.2764 - val_accuracy: 0.0000e+00\n",
      "Epoch 4261/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 50.1474 - accuracy: 0.0156 - val_loss: 140.9239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4262/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 34.4096 - accuracy: 0.0312 - val_loss: 147.8781 - val_accuracy: 0.0000e+00\n",
      "Epoch 4263/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 27.5289 - accuracy: 0.0000e+00 - val_loss: 145.3912 - val_accuracy: 0.0000e+00\n",
      "Epoch 4264/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 36.5986 - accuracy: 0.0312 - val_loss: 148.9498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4265/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 43.4175 - accuracy: 0.0000e+00 - val_loss: 150.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 4266/10000\n",
      "64/64 [==============================] - 0s 176us/step - loss: 32.4229 - accuracy: 0.0156 - val_loss: 146.3805 - val_accuracy: 0.0000e+00\n",
      "Epoch 4267/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 36.7071 - accuracy: 0.0000e+00 - val_loss: 139.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 4268/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.0183 - accuracy: 0.0156 - val_loss: 132.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4269/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 40.9600 - accuracy: 0.0156 - val_loss: 132.7469 - val_accuracy: 0.0000e+00\n",
      "Epoch 4270/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 29.0002 - accuracy: 0.0156 - val_loss: 138.6443 - val_accuracy: 0.0000e+00\n",
      "Epoch 4271/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.6347 - accuracy: 0.0000e+00 - val_loss: 147.5728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4272/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 31.7958 - accuracy: 0.0000e+00 - val_loss: 143.4553 - val_accuracy: 0.0000e+00\n",
      "Epoch 4273/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 23.6584 - accuracy: 0.0000e+00 - val_loss: 141.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 4274/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 34.1590 - accuracy: 0.0156 - val_loss: 144.2152 - val_accuracy: 0.0588\n",
      "Epoch 4275/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 29.6399 - accuracy: 0.0000e+00 - val_loss: 141.6906 - val_accuracy: 0.0588\n",
      "Epoch 4276/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 29.0195 - accuracy: 0.0000e+00 - val_loss: 137.0780 - val_accuracy: 0.0588\n",
      "Epoch 4277/10000\n",
      "64/64 [==============================] - 0s 186us/step - loss: 35.6975 - accuracy: 0.0000e+00 - val_loss: 134.7287 - val_accuracy: 0.1176\n",
      "Epoch 4278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.8007 - accuracy: 0.0000e+00 - val_loss: 127.2420 - val_accuracy: 0.0588\n",
      "Epoch 4279/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.3275 - accuracy: 0.0000e+00 - val_loss: 122.4088 - val_accuracy: 0.0588\n",
      "Epoch 4280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7285 - accuracy: 0.0000e+00 - val_loss: 122.2051 - val_accuracy: 0.0000e+00\n",
      "Epoch 4281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9071 - accuracy: 0.0156 - val_loss: 126.1282 - val_accuracy: 0.0000e+00\n",
      "Epoch 4282/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.1988 - accuracy: 0.0156 - val_loss: 125.9612 - val_accuracy: 0.0000e+00\n",
      "Epoch 4283/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 32.1169 - accuracy: 0.0000e+00 - val_loss: 122.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 4284/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 35.0245 - accuracy: 0.0156 - val_loss: 120.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4285/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 39.2008 - accuracy: 0.0000e+00 - val_loss: 123.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4286/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 25.4999 - accuracy: 0.0000e+00 - val_loss: 124.9569 - val_accuracy: 0.0588\n",
      "Epoch 4287/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 30.6294 - accuracy: 0.0156 - val_loss: 124.7338 - val_accuracy: 0.0588\n",
      "Epoch 4288/10000\n",
      "64/64 [==============================] - 0s 168us/step - loss: 31.7635 - accuracy: 0.0000e+00 - val_loss: 126.9842 - val_accuracy: 0.0000e+00\n",
      "Epoch 4289/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.8624 - accuracy: 0.0000e+00 - val_loss: 132.7610 - val_accuracy: 0.0000e+00\n",
      "Epoch 4290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5613 - accuracy: 0.0000e+00 - val_loss: 133.4169 - val_accuracy: 0.0000e+00\n",
      "Epoch 4291/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.0871 - accuracy: 0.0000e+00 - val_loss: 124.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8652 - accuracy: 0.0156 - val_loss: 124.3411 - val_accuracy: 0.0000e+00\n",
      "Epoch 4293/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.4533 - accuracy: 0.0156 - val_loss: 135.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 4294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3176 - accuracy: 0.0000e+00 - val_loss: 146.8107 - val_accuracy: 0.0000e+00\n",
      "Epoch 4295/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.0230 - accuracy: 0.0156 - val_loss: 151.0629 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0228 - accuracy: 0.0156 - val_loss: 142.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 4297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7244 - accuracy: 0.0000e+00 - val_loss: 126.6091 - val_accuracy: 0.0000e+00\n",
      "Epoch 4298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8988 - accuracy: 0.0000e+00 - val_loss: 121.1810 - val_accuracy: 0.0000e+00\n",
      "Epoch 4299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7465 - accuracy: 0.0000e+00 - val_loss: 127.8890 - val_accuracy: 0.0000e+00\n",
      "Epoch 4300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0358 - accuracy: 0.0000e+00 - val_loss: 137.3585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6077 - accuracy: 0.0156 - val_loss: 134.6520 - val_accuracy: 0.0000e+00\n",
      "Epoch 4302/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 38.4957 - accuracy: 0.0000e+00 - val_loss: 131.2691 - val_accuracy: 0.0000e+00\n",
      "Epoch 4303/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.1992 - accuracy: 0.0000e+00 - val_loss: 130.5094 - val_accuracy: 0.0000e+00\n",
      "Epoch 4304/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 36.5188 - accuracy: 0.0000e+00 - val_loss: 129.9559 - val_accuracy: 0.0000e+00\n",
      "Epoch 4305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8728 - accuracy: 0.0156 - val_loss: 126.9604 - val_accuracy: 0.0000e+00\n",
      "Epoch 4306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8020 - accuracy: 0.0000e+00 - val_loss: 119.4417 - val_accuracy: 0.0000e+00\n",
      "Epoch 4307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6524 - accuracy: 0.0312 - val_loss: 122.9098 - val_accuracy: 0.0000e+00\n",
      "Epoch 4308/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 30.9539 - accuracy: 0.0000e+00 - val_loss: 123.5948 - val_accuracy: 0.0000e+00\n",
      "Epoch 4309/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.0332 - accuracy: 0.0000e+00 - val_loss: 126.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 4310/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.8458 - accuracy: 0.0000e+00 - val_loss: 131.9045 - val_accuracy: 0.0000e+00\n",
      "Epoch 4311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8384 - accuracy: 0.0156 - val_loss: 131.7137 - val_accuracy: 0.0000e+00\n",
      "Epoch 4312/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.8087 - accuracy: 0.0156 - val_loss: 135.1189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4313/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 29.9726 - accuracy: 0.0156 - val_loss: 132.9745 - val_accuracy: 0.0000e+00\n",
      "Epoch 4314/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.4319 - accuracy: 0.0000e+00 - val_loss: 130.4938 - val_accuracy: 0.0000e+00\n",
      "Epoch 4315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9891 - accuracy: 0.0000e+00 - val_loss: 126.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 4316/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2290 - accuracy: 0.0156 - val_loss: 127.9976 - val_accuracy: 0.0000e+00\n",
      "Epoch 4317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6571 - accuracy: 0.0000e+00 - val_loss: 133.3152 - val_accuracy: 0.0000e+00\n",
      "Epoch 4318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.1881 - accuracy: 0.0000e+00 - val_loss: 144.3800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1196 - accuracy: 0.0000e+00 - val_loss: 146.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 4320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1793 - accuracy: 0.0000e+00 - val_loss: 139.3699 - val_accuracy: 0.0000e+00\n",
      "Epoch 4321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4082 - accuracy: 0.0156 - val_loss: 128.0114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4322/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 32.9125 - accuracy: 0.0000e+00 - val_loss: 121.2746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4323/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 27.6613 - accuracy: 0.0312 - val_loss: 129.1442 - val_accuracy: 0.0588\n",
      "Epoch 4324/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.7818 - accuracy: 0.0000e+00 - val_loss: 138.4279 - val_accuracy: 0.0000e+00\n",
      "Epoch 4325/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 38.7712 - accuracy: 0.0312 - val_loss: 138.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 4326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4958 - accuracy: 0.0000e+00 - val_loss: 133.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 4327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0380 - accuracy: 0.0000e+00 - val_loss: 137.5724 - val_accuracy: 0.0588\n",
      "Epoch 4328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3119 - accuracy: 0.0000e+00 - val_loss: 131.7231 - val_accuracy: 0.0588\n",
      "Epoch 4329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1448 - accuracy: 0.0000e+00 - val_loss: 115.4975 - val_accuracy: 0.0000e+00\n",
      "Epoch 4330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4172 - accuracy: 0.0156 - val_loss: 108.4473 - val_accuracy: 0.0000e+00\n",
      "Epoch 4331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9863 - accuracy: 0.0000e+00 - val_loss: 108.5711 - val_accuracy: 0.0000e+00\n",
      "Epoch 4332/10000\n",
      "64/64 [==============================] - 0s 200us/step - loss: 38.9634 - accuracy: 0.0156 - val_loss: 114.5486 - val_accuracy: 0.0000e+00\n",
      "Epoch 4333/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7763 - accuracy: 0.0000e+00 - val_loss: 122.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2440 - accuracy: 0.0156 - val_loss: 126.4509 - val_accuracy: 0.0000e+00\n",
      "Epoch 4335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4998 - accuracy: 0.0156 - val_loss: 125.6645 - val_accuracy: 0.0000e+00\n",
      "Epoch 4336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3632 - accuracy: 0.0156 - val_loss: 125.4126 - val_accuracy: 0.0000e+00\n",
      "Epoch 4337/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6317 - accuracy: 0.0000e+00 - val_loss: 122.8102 - val_accuracy: 0.0000e+00\n",
      "Epoch 4338/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3091 - accuracy: 0.0312 - val_loss: 122.6246 - val_accuracy: 0.0000e+00\n",
      "Epoch 4339/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 34.1457 - accuracy: 0.0156 - val_loss: 128.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 4340/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 35.3817 - accuracy: 0.0156 - val_loss: 123.7037 - val_accuracy: 0.0000e+00\n",
      "Epoch 4341/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 39.8711 - accuracy: 0.0312 - val_loss: 114.7109 - val_accuracy: 0.0000e+00\n",
      "Epoch 4342/10000\n",
      "64/64 [==============================] - 0s 214us/step - loss: 31.3734 - accuracy: 0.0156 - val_loss: 110.7984 - val_accuracy: 0.0000e+00\n",
      "Epoch 4343/10000\n",
      "64/64 [==============================] - 0s 182us/step - loss: 27.0952 - accuracy: 0.0312 - val_loss: 114.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 4344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5171 - accuracy: 0.0156 - val_loss: 117.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 4345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2602 - accuracy: 0.0156 - val_loss: 118.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 4346/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.8524 - accuracy: 0.0312 - val_loss: 120.6865 - val_accuracy: 0.0000e+00\n",
      "Epoch 4347/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8501 - accuracy: 0.0000e+00 - val_loss: 124.1229 - val_accuracy: 0.0000e+00\n",
      "Epoch 4348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8604 - accuracy: 0.0000e+00 - val_loss: 131.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 4349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2253 - accuracy: 0.0156 - val_loss: 128.7005 - val_accuracy: 0.0000e+00\n",
      "Epoch 4350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1856 - accuracy: 0.0000e+00 - val_loss: 121.8873 - val_accuracy: 0.0000e+00\n",
      "Epoch 4351/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.8818 - accuracy: 0.0469 - val_loss: 118.5987 - val_accuracy: 0.0000e+00\n",
      "Epoch 4352/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.7702 - accuracy: 0.0000e+00 - val_loss: 117.6598 - val_accuracy: 0.0000e+00\n",
      "Epoch 4353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6454 - accuracy: 0.0000e+00 - val_loss: 117.1853 - val_accuracy: 0.0000e+00\n",
      "Epoch 4354/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 34.0775 - accuracy: 0.0156 - val_loss: 126.2338 - val_accuracy: 0.0000e+00\n",
      "Epoch 4355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0509 - accuracy: 0.0000e+00 - val_loss: 127.0386 - val_accuracy: 0.0588\n",
      "Epoch 4356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6786 - accuracy: 0.0000e+00 - val_loss: 132.3024 - val_accuracy: 0.0588\n",
      "Epoch 4357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3331 - accuracy: 0.0000e+00 - val_loss: 137.3741 - val_accuracy: 0.0588\n",
      "Epoch 4358/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.6866 - accuracy: 0.0000e+00 - val_loss: 137.5373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4359/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 37.8736 - accuracy: 0.0000e+00 - val_loss: 127.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 4360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4227 - accuracy: 0.0000e+00 - val_loss: 111.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 4361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6712 - accuracy: 0.0000e+00 - val_loss: 103.7012 - val_accuracy: 0.0588\n",
      "Epoch 4362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0042 - accuracy: 0.0156 - val_loss: 106.7124 - val_accuracy: 0.0000e+00\n",
      "Epoch 4363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0490 - accuracy: 0.0156 - val_loss: 114.1156 - val_accuracy: 0.0000e+00\n",
      "Epoch 4364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3724 - accuracy: 0.0000e+00 - val_loss: 121.1320 - val_accuracy: 0.0000e+00\n",
      "Epoch 4365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5582 - accuracy: 0.0000e+00 - val_loss: 111.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1572 - accuracy: 0.0000e+00 - val_loss: 99.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 4367/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.7104 - accuracy: 0.0000e+00 - val_loss: 102.6333 - val_accuracy: 0.0000e+00\n",
      "Epoch 4368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4474 - accuracy: 0.0156 - val_loss: 104.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 4369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8515 - accuracy: 0.0000e+00 - val_loss: 108.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 4370/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 23.2739 - accuracy: 0.0156 - val_loss: 118.4956 - val_accuracy: 0.0000e+00\n",
      "Epoch 4371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5869 - accuracy: 0.0000e+00 - val_loss: 133.1921 - val_accuracy: 0.0000e+00\n",
      "Epoch 4372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0390 - accuracy: 0.0000e+00 - val_loss: 136.7710 - val_accuracy: 0.0000e+00\n",
      "Epoch 4373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8980 - accuracy: 0.0156 - val_loss: 129.2485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 54.4840 - accuracy: 0.0000e+00 - val_loss: 121.0521 - val_accuracy: 0.0000e+00\n",
      "Epoch 4375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6102 - accuracy: 0.0156 - val_loss: 123.6525 - val_accuracy: 0.0588\n",
      "Epoch 4376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9289 - accuracy: 0.0156 - val_loss: 132.2821 - val_accuracy: 0.0588\n",
      "Epoch 4377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6626 - accuracy: 0.0000e+00 - val_loss: 130.4566 - val_accuracy: 0.0588\n",
      "Epoch 4378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0442 - accuracy: 0.0156 - val_loss: 119.6643 - val_accuracy: 0.0588\n",
      "Epoch 4379/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 32.8034 - accuracy: 0.0156 - val_loss: 117.2412 - val_accuracy: 0.0000e+00\n",
      "Epoch 4380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4107 - accuracy: 0.0000e+00 - val_loss: 123.0622 - val_accuracy: 0.0000e+00\n",
      "Epoch 4381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2920 - accuracy: 0.0000e+00 - val_loss: 125.2018 - val_accuracy: 0.0588\n",
      "Epoch 4382/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 30.8404 - accuracy: 0.0156 - val_loss: 122.9062 - val_accuracy: 0.0588\n",
      "Epoch 4383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0581 - accuracy: 0.0000e+00 - val_loss: 111.6372 - val_accuracy: 0.1176\n",
      "Epoch 4384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5755 - accuracy: 0.0312 - val_loss: 109.2568 - val_accuracy: 0.0588\n",
      "Epoch 4385/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.1382 - accuracy: 0.0000e+00 - val_loss: 112.3403 - val_accuracy: 0.0588\n",
      "Epoch 4386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2392 - accuracy: 0.0000e+00 - val_loss: 113.1410 - val_accuracy: 0.0588\n",
      "Epoch 4387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9639 - accuracy: 0.0156 - val_loss: 116.9792 - val_accuracy: 0.0588\n",
      "Epoch 4388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7643 - accuracy: 0.0156 - val_loss: 119.4455 - val_accuracy: 0.0588\n",
      "Epoch 4389/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 44.1983 - accuracy: 0.0312 - val_loss: 116.5337 - val_accuracy: 0.0588\n",
      "Epoch 4390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3764 - accuracy: 0.0000e+00 - val_loss: 121.3791 - val_accuracy: 0.0588\n",
      "Epoch 4391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6148 - accuracy: 0.0000e+00 - val_loss: 134.2123 - val_accuracy: 0.0588\n",
      "Epoch 4392/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 50.5230 - accuracy: 0.0156 - val_loss: 131.4742 - val_accuracy: 0.0588\n",
      "Epoch 4393/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.4903 - accuracy: 0.0156 - val_loss: 119.7199 - val_accuracy: 0.0588\n",
      "Epoch 4394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1118 - accuracy: 0.0000e+00 - val_loss: 116.3230 - val_accuracy: 0.1176\n",
      "Epoch 4395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6894 - accuracy: 0.0000e+00 - val_loss: 120.0808 - val_accuracy: 0.0588\n",
      "Epoch 4396/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 35.9192 - accuracy: 0.0312 - val_loss: 116.1213 - val_accuracy: 0.0588\n",
      "Epoch 4397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4705 - accuracy: 0.0000e+00 - val_loss: 111.5677 - val_accuracy: 0.0588\n",
      "Epoch 4398/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8578 - accuracy: 0.0000e+00 - val_loss: 109.4411 - val_accuracy: 0.0588\n",
      "Epoch 4399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5206 - accuracy: 0.0000e+00 - val_loss: 106.2963 - val_accuracy: 0.1176\n",
      "Epoch 4400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7895 - accuracy: 0.0000e+00 - val_loss: 103.6029 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0399 - accuracy: 0.0000e+00 - val_loss: 106.0927 - val_accuracy: 0.0588\n",
      "Epoch 4402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4599 - accuracy: 0.0312 - val_loss: 115.9115 - val_accuracy: 0.0588\n",
      "Epoch 4403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2127 - accuracy: 0.0000e+00 - val_loss: 122.6572 - val_accuracy: 0.0588\n",
      "Epoch 4404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5937 - accuracy: 0.0000e+00 - val_loss: 113.8510 - val_accuracy: 0.0588\n",
      "Epoch 4405/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.1926 - accuracy: 0.0000e+00 - val_loss: 105.8844 - val_accuracy: 0.0588\n",
      "Epoch 4406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4252 - accuracy: 0.0156 - val_loss: 111.1243 - val_accuracy: 0.0588\n",
      "Epoch 4407/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 37.1821 - accuracy: 0.0156 - val_loss: 118.2575 - val_accuracy: 0.0588\n",
      "Epoch 4408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6409 - accuracy: 0.0000e+00 - val_loss: 128.4849 - val_accuracy: 0.0588\n",
      "Epoch 4409/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.5329 - accuracy: 0.031 - 0s 125us/step - loss: 39.1282 - accuracy: 0.0156 - val_loss: 132.1153 - val_accuracy: 0.0588\n",
      "Epoch 4410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3323 - accuracy: 0.0000e+00 - val_loss: 126.2701 - val_accuracy: 0.1176\n",
      "Epoch 4411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9919 - accuracy: 0.0312 - val_loss: 123.5750 - val_accuracy: 0.0588\n",
      "Epoch 4412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7362 - accuracy: 0.0156 - val_loss: 126.1332 - val_accuracy: 0.0588\n",
      "Epoch 4413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6964 - accuracy: 0.0312 - val_loss: 133.6628 - val_accuracy: 0.0588\n",
      "Epoch 4414/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 33.3316 - accuracy: 0.0000e+00 - val_loss: 140.9293 - val_accuracy: 0.0588\n",
      "Epoch 4415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3641 - accuracy: 0.0000e+00 - val_loss: 139.0007 - val_accuracy: 0.1176\n",
      "Epoch 4416/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8869 - accuracy: 0.0000e+00 - val_loss: 123.2994 - val_accuracy: 0.0588\n",
      "Epoch 4417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6235 - accuracy: 0.0156 - val_loss: 107.8964 - val_accuracy: 0.0588\n",
      "Epoch 4418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5119 - accuracy: 0.0312 - val_loss: 96.1038 - val_accuracy: 0.0588\n",
      "Epoch 4419/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.4653 - accuracy: 0.0156 - val_loss: 95.9483 - val_accuracy: 0.0588\n",
      "Epoch 4420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7311 - accuracy: 0.0000e+00 - val_loss: 114.3791 - val_accuracy: 0.0588\n",
      "Epoch 4421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2561 - accuracy: 0.0000e+00 - val_loss: 129.1957 - val_accuracy: 0.0588\n",
      "Epoch 4422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1919 - accuracy: 0.0000e+00 - val_loss: 118.3185 - val_accuracy: 0.0588\n",
      "Epoch 4423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2229 - accuracy: 0.0000e+00 - val_loss: 107.3015 - val_accuracy: 0.0588\n",
      "Epoch 4424/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 29.2726 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 33.1768 - accuracy: 0.0000e+00 - val_loss: 101.3876 - val_accuracy: 0.0588\n",
      "Epoch 4425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6711 - accuracy: 0.0156 - val_loss: 104.5054 - val_accuracy: 0.0588\n",
      "Epoch 4426/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 40.6179 - accuracy: 0.0312 - val_loss: 118.5682 - val_accuracy: 0.0588\n",
      "Epoch 4427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5144 - accuracy: 0.0156 - val_loss: 135.4597 - val_accuracy: 0.0588\n",
      "Epoch 4428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9085 - accuracy: 0.0000e+00 - val_loss: 137.4394 - val_accuracy: 0.0588\n",
      "Epoch 4429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6252 - accuracy: 0.0000e+00 - val_loss: 128.6487 - val_accuracy: 0.0588\n",
      "Epoch 4430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.8461 - accuracy: 0.0000e+00 - val_loss: 118.1713 - val_accuracy: 0.0588\n",
      "Epoch 4431/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 33.2134 - accuracy: 0.0000e+00 - val_loss: 110.8653 - val_accuracy: 0.0588\n",
      "Epoch 4432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.2813 - accuracy: 0.0156 - val_loss: 110.8914 - val_accuracy: 0.0588\n",
      "Epoch 4433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4769 - accuracy: 0.0000e+00 - val_loss: 112.8881 - val_accuracy: 0.1176\n",
      "Epoch 4434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3913 - accuracy: 0.0000e+00 - val_loss: 107.2661 - val_accuracy: 0.0588\n",
      "Epoch 4435/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.2663 - accuracy: 0.0156 - val_loss: 99.7058 - val_accuracy: 0.0588\n",
      "Epoch 4436/10000\n",
      "64/64 [==============================] - 0s 39us/step - loss: 22.4585 - accuracy: 0.0156 - val_loss: 93.6206 - val_accuracy: 0.0588\n",
      "Epoch 4437/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 53.4384 - accuracy: 0.0156 - val_loss: 94.0767 - val_accuracy: 0.0588\n",
      "Epoch 4438/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 28.0647 - accuracy: 0.0000e+00 - val_loss: 97.7718 - val_accuracy: 0.0588\n",
      "Epoch 4439/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 55.5721 - accuracy: 0.0156 - val_loss: 117.4104 - val_accuracy: 0.0588\n",
      "Epoch 4440/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 33.7609 - accuracy: 0.0156 - val_loss: 127.4873 - val_accuracy: 0.0588\n",
      "Epoch 4441/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 38.2322 - accuracy: 0.0156 - val_loss: 120.8939 - val_accuracy: 0.0588\n",
      "Epoch 4442/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 36.7054 - accuracy: 0.0000e+00 - val_loss: 121.4326 - val_accuracy: 0.0588\n",
      "Epoch 4443/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.4465 - accuracy: 0.0156 - val_loss: 125.6477 - val_accuracy: 0.0588\n",
      "Epoch 4444/10000\n",
      "64/64 [==============================] - 0s 211us/step - loss: 35.9618 - accuracy: 0.0000e+00 - val_loss: 124.7989 - val_accuracy: 0.0588\n",
      "Epoch 4445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7770 - accuracy: 0.0156 - val_loss: 117.7807 - val_accuracy: 0.0588\n",
      "Epoch 4446/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 34.9262 - accuracy: 0.0000e+00 - val_loss: 119.6358 - val_accuracy: 0.0588\n",
      "Epoch 4447/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 48.1248 - accuracy: 0.0312 - val_loss: 125.1043 - val_accuracy: 0.0588\n",
      "Epoch 4448/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 36.1331 - accuracy: 0.0000e+00 - val_loss: 117.5360 - val_accuracy: 0.0588\n",
      "Epoch 4449/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 43.4173 - accuracy: 0.0000e+00 - val_loss: 110.2127 - val_accuracy: 0.0588\n",
      "Epoch 4450/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 32.5048 - accuracy: 0.0000e+00 - val_loss: 115.4952 - val_accuracy: 0.0588\n",
      "Epoch 4451/10000\n",
      "64/64 [==============================] - 0s 217us/step - loss: 27.9068 - accuracy: 0.0000e+00 - val_loss: 125.8645 - val_accuracy: 0.0588\n",
      "Epoch 4452/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 35.1372 - accuracy: 0.0156 - val_loss: 133.0878 - val_accuracy: 0.0588\n",
      "Epoch 4453/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 37.2373 - accuracy: 0.0156 - val_loss: 127.4169 - val_accuracy: 0.0588\n",
      "Epoch 4454/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 134us/step - loss: 31.2107 - accuracy: 0.0000e+00 - val_loss: 116.9935 - val_accuracy: 0.0588\n",
      "Epoch 4455/10000\n",
      "64/64 [==============================] - 0s 0us/step - loss: 32.8048 - accuracy: 0.0312 - val_loss: 111.8525 - val_accuracy: 0.0588\n",
      "Epoch 4456/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 32.2413 - accuracy: 0.0000e+00 - val_loss: 113.3358 - val_accuracy: 0.0588\n",
      "Epoch 4457/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 35.9804 - accuracy: 0.0000e+00 - val_loss: 114.6839 - val_accuracy: 0.0588\n",
      "Epoch 4458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4847 - accuracy: 0.0156 - val_loss: 122.4813 - val_accuracy: 0.0588\n",
      "Epoch 4459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3642 - accuracy: 0.0000e+00 - val_loss: 133.7202 - val_accuracy: 0.0588\n",
      "Epoch 4460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8009 - accuracy: 0.0156 - val_loss: 135.4605 - val_accuracy: 0.0588\n",
      "Epoch 4461/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8476 - accuracy: 0.0156 - val_loss: 139.1949 - val_accuracy: 0.0588\n",
      "Epoch 4462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5508 - accuracy: 0.0000e+00 - val_loss: 128.5672 - val_accuracy: 0.0588\n",
      "Epoch 4463/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 43.4223 - accuracy: 0.0000e+00 - val_loss: 125.4174 - val_accuracy: 0.0588\n",
      "Epoch 4464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6825 - accuracy: 0.0000e+00 - val_loss: 126.1331 - val_accuracy: 0.0588\n",
      "Epoch 4465/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 34.9326 - accuracy: 0.0000e+00 - val_loss: 128.3024 - val_accuracy: 0.0588\n",
      "Epoch 4466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8907 - accuracy: 0.0156 - val_loss: 128.0430 - val_accuracy: 0.0588\n",
      "Epoch 4467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2429 - accuracy: 0.0156 - val_loss: 123.5880 - val_accuracy: 0.0588\n",
      "Epoch 4468/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 33.6633 - accuracy: 0.0000e+00 - val_loss: 117.7468 - val_accuracy: 0.0588\n",
      "Epoch 4469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5633 - accuracy: 0.0000e+00 - val_loss: 114.3127 - val_accuracy: 0.0588\n",
      "Epoch 4470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8718 - accuracy: 0.0312 - val_loss: 115.3148 - val_accuracy: 0.0588\n",
      "Epoch 4471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8449 - accuracy: 0.0156 - val_loss: 119.9543 - val_accuracy: 0.0588\n",
      "Epoch 4472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6974 - accuracy: 0.0000e+00 - val_loss: 135.7455 - val_accuracy: 0.0588\n",
      "Epoch 4473/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 27.3257 - accuracy: 0.0000e+00 - val_loss: 145.0990 - val_accuracy: 0.0588\n",
      "Epoch 4474/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7039 - accuracy: 0.0000e+00 - val_loss: 140.9252 - val_accuracy: 0.0588\n",
      "Epoch 4475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2316 - accuracy: 0.0000e+00 - val_loss: 136.9046 - val_accuracy: 0.0588\n",
      "Epoch 4476/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1463 - accuracy: 0.0156 - val_loss: 136.1897 - val_accuracy: 0.0588\n",
      "Epoch 4477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6101 - accuracy: 0.0156 - val_loss: 138.8283 - val_accuracy: 0.0000e+00\n",
      "Epoch 4478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4813 - accuracy: 0.0156 - val_loss: 136.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4479/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 28.0024 - accuracy: 0.0156 - val_loss: 121.9711 - val_accuracy: 0.0000e+00\n",
      "Epoch 4480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3559 - accuracy: 0.0000e+00 - val_loss: 109.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 4481/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4179 - accuracy: 0.0156 - val_loss: 104.7943 - val_accuracy: 0.0588\n",
      "Epoch 4482/10000\n",
      "64/64 [==============================] - 0s 108us/step - loss: 34.3845 - accuracy: 0.0000e+00 - val_loss: 109.5455 - val_accuracy: 0.0588\n",
      "Epoch 4483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7835 - accuracy: 0.0000e+00 - val_loss: 120.5704 - val_accuracy: 0.0000e+00\n",
      "Epoch 4484/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.9290 - accuracy: 0.0000e+00 - val_loss: 126.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 4485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5899 - accuracy: 0.0000e+00 - val_loss: 126.7875 - val_accuracy: 0.0588\n",
      "Epoch 4486/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 39.0447 - accuracy: 0.0156 - val_loss: 122.6175 - val_accuracy: 0.0588\n",
      "Epoch 4487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6820 - accuracy: 0.0000e+00 - val_loss: 119.7028 - val_accuracy: 0.0588\n",
      "Epoch 4488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6103 - accuracy: 0.0000e+00 - val_loss: 114.9673 - val_accuracy: 0.0588\n",
      "Epoch 4489/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.0673 - accuracy: 0.0156 - val_loss: 114.9404 - val_accuracy: 0.0588\n",
      "Epoch 4490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9531 - accuracy: 0.0156 - val_loss: 115.0713 - val_accuracy: 0.0588\n",
      "Epoch 4491/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0084 - accuracy: 0.0000e+00 - val_loss: 122.1132 - val_accuracy: 0.0588\n",
      "Epoch 4492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1235 - accuracy: 0.0000e+00 - val_loss: 130.5724 - val_accuracy: 0.0588\n",
      "Epoch 4493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9540 - accuracy: 0.0000e+00 - val_loss: 132.5314 - val_accuracy: 0.0588\n",
      "Epoch 4494/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8699 - accuracy: 0.0000e+00 - val_loss: 129.1611 - val_accuracy: 0.0588\n",
      "Epoch 4495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2782 - accuracy: 0.0000e+00 - val_loss: 125.6954 - val_accuracy: 0.0588\n",
      "Epoch 4496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8346 - accuracy: 0.0000e+00 - val_loss: 114.8671 - val_accuracy: 0.0588\n",
      "Epoch 4497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2868 - accuracy: 0.0000e+00 - val_loss: 104.3082 - val_accuracy: 0.0588\n",
      "Epoch 4498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4101 - accuracy: 0.0000e+00 - val_loss: 104.1004 - val_accuracy: 0.0588\n",
      "Epoch 4499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4715 - accuracy: 0.0312 - val_loss: 117.0654 - val_accuracy: 0.0588\n",
      "Epoch 4500/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 32.0233 - accuracy: 0.0156 - val_loss: 131.6710 - val_accuracy: 0.0588\n",
      "Epoch 4501/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 30.1084 - accuracy: 0.0000e+00 - val_loss: 128.1903 - val_accuracy: 0.0588\n",
      "Epoch 4502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.4649 - accuracy: 0.0000e+00 - val_loss: 122.1039 - val_accuracy: 0.0588\n",
      "Epoch 4503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4689 - accuracy: 0.0000e+00 - val_loss: 113.9533 - val_accuracy: 0.0588\n",
      "Epoch 4504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8421 - accuracy: 0.0000e+00 - val_loss: 108.3213 - val_accuracy: 0.0588\n",
      "Epoch 4505/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 28.4383 - accuracy: 0.0000e+00 - val_loss: 107.9985 - val_accuracy: 0.0588\n",
      "Epoch 4506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.7667 - accuracy: 0.0156 - val_loss: 116.7375 - val_accuracy: 0.0588\n",
      "Epoch 4507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3097 - accuracy: 0.0000e+00 - val_loss: 121.1766 - val_accuracy: 0.0588\n",
      "Epoch 4508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9152 - accuracy: 0.0156 - val_loss: 116.6841 - val_accuracy: 0.0588\n",
      "Epoch 4509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5130 - accuracy: 0.0000e+00 - val_loss: 113.9090 - val_accuracy: 0.0588\n",
      "Epoch 4510/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.1199 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 26.5671 - accuracy: 0.0312 - val_loss: 118.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6240 - accuracy: 0.0000e+00 - val_loss: 131.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 4512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0408 - accuracy: 0.0312 - val_loss: 138.3515 - val_accuracy: 0.0588\n",
      "Epoch 4513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8239 - accuracy: 0.0156 - val_loss: 144.1143 - val_accuracy: 0.0588\n",
      "Epoch 4514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3139 - accuracy: 0.0156 - val_loss: 148.1514 - val_accuracy: 0.0000e+00\n",
      "Epoch 4515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5011 - accuracy: 0.0000e+00 - val_loss: 145.8331 - val_accuracy: 0.0588\n",
      "Epoch 4516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5240 - accuracy: 0.0156 - val_loss: 139.7181 - val_accuracy: 0.0588\n",
      "Epoch 4517/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.4430 - accuracy: 0.0000e+00 - val_loss: 137.6691 - val_accuracy: 0.0588\n",
      "Epoch 4518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2921 - accuracy: 0.0000e+00 - val_loss: 131.9271 - val_accuracy: 0.0000e+00\n",
      "Epoch 4519/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8932 - accuracy: 0.0156 - val_loss: 124.5159 - val_accuracy: 0.0000e+00\n",
      "Epoch 4520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4843 - accuracy: 0.0156 - val_loss: 126.3404 - val_accuracy: 0.0000e+00\n",
      "Epoch 4521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6358 - accuracy: 0.0000e+00 - val_loss: 123.7342 - val_accuracy: 0.0588\n",
      "Epoch 4522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6712 - accuracy: 0.0156 - val_loss: 120.7460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9803 - accuracy: 0.0000e+00 - val_loss: 122.2192 - val_accuracy: 0.0000e+00\n",
      "Epoch 4524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7206 - accuracy: 0.0000e+00 - val_loss: 128.2077 - val_accuracy: 0.0588\n",
      "Epoch 4525/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5172 - accuracy: 0.0000e+00 - val_loss: 136.7884 - val_accuracy: 0.0000e+00\n",
      "Epoch 4526/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.2569 - accuracy: 0.0156 - val_loss: 141.2531 - val_accuracy: 0.0000e+00\n",
      "Epoch 4527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1010 - accuracy: 0.0000e+00 - val_loss: 141.4405 - val_accuracy: 0.0000e+00\n",
      "Epoch 4528/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5431 - accuracy: 0.0000e+00 - val_loss: 137.5243 - val_accuracy: 0.0000e+00\n",
      "Epoch 4529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6721 - accuracy: 0.0000e+00 - val_loss: 132.7590 - val_accuracy: 0.0000e+00\n",
      "Epoch 4530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7033 - accuracy: 0.0000e+00 - val_loss: 132.9902 - val_accuracy: 0.0588\n",
      "Epoch 4531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8359 - accuracy: 0.0156 - val_loss: 127.9171 - val_accuracy: 0.0588\n",
      "Epoch 4532/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3114 - accuracy: 0.0156 - val_loss: 124.9230 - val_accuracy: 0.0588\n",
      "Epoch 4533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5212 - accuracy: 0.0156 - val_loss: 124.1406 - val_accuracy: 0.0588\n",
      "Epoch 4534/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.1366 - accuracy: 0.0000e+00 - val_loss: 126.6993 - val_accuracy: 0.0588\n",
      "Epoch 4535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2338 - accuracy: 0.0000e+00 - val_loss: 128.4571 - val_accuracy: 0.0588\n",
      "Epoch 4536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4215 - accuracy: 0.0156 - val_loss: 125.7048 - val_accuracy: 0.0588\n",
      "Epoch 4537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7899 - accuracy: 0.0000e+00 - val_loss: 119.5231 - val_accuracy: 0.0588\n",
      "Epoch 4538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3641 - accuracy: 0.0156 - val_loss: 114.9580 - val_accuracy: 0.0588\n",
      "Epoch 4539/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5469 - accuracy: 0.0000e+00 - val_loss: 118.1656 - val_accuracy: 0.0588\n",
      "Epoch 4540/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0947 - accuracy: 0.0000e+00 - val_loss: 120.2613 - val_accuracy: 0.0588\n",
      "Epoch 4541/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7278 - accuracy: 0.0000e+00 - val_loss: 124.6406 - val_accuracy: 0.0588\n",
      "Epoch 4542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2041 - accuracy: 0.0156 - val_loss: 115.5304 - val_accuracy: 0.0588\n",
      "Epoch 4543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4139 - accuracy: 0.0000e+00 - val_loss: 112.3425 - val_accuracy: 0.0588\n",
      "Epoch 4544/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8319 - accuracy: 0.0156 - val_loss: 113.5551 - val_accuracy: 0.0588\n",
      "Epoch 4545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9397 - accuracy: 0.0000e+00 - val_loss: 121.7065 - val_accuracy: 0.0588\n",
      "Epoch 4546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7942 - accuracy: 0.0000e+00 - val_loss: 133.7908 - val_accuracy: 0.0588\n",
      "Epoch 4547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0927 - accuracy: 0.0000e+00 - val_loss: 136.4560 - val_accuracy: 0.0588\n",
      "Epoch 4548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6809 - accuracy: 0.0000e+00 - val_loss: 136.8749 - val_accuracy: 0.0588\n",
      "Epoch 4549/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.9000 - accuracy: 0.0312 - val_loss: 135.0464 - val_accuracy: 0.0588\n",
      "Epoch 4550/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3345 - accuracy: 0.0156 - val_loss: 128.8254 - val_accuracy: 0.1176\n",
      "Epoch 4551/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9834 - accuracy: 0.0156 - val_loss: 126.9065 - val_accuracy: 0.0588\n",
      "Epoch 4552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3125 - accuracy: 0.0156 - val_loss: 132.5761 - val_accuracy: 0.0588\n",
      "Epoch 4553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8680 - accuracy: 0.0156 - val_loss: 142.7581 - val_accuracy: 0.0588\n",
      "Epoch 4554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2607 - accuracy: 0.0000e+00 - val_loss: 146.2858 - val_accuracy: 0.0588\n",
      "Epoch 4555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5906 - accuracy: 0.0000e+00 - val_loss: 135.5030 - val_accuracy: 0.0588\n",
      "Epoch 4556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3316 - accuracy: 0.0156 - val_loss: 126.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 4557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2940 - accuracy: 0.0000e+00 - val_loss: 122.5071 - val_accuracy: 0.0588\n",
      "Epoch 4558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5949 - accuracy: 0.0000e+00 - val_loss: 117.1536 - val_accuracy: 0.0000e+00\n",
      "Epoch 4559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7505 - accuracy: 0.0156 - val_loss: 119.5593 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4560/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.0520 - accuracy: 0.0000e+00 - val_loss: 126.0662 - val_accuracy: 0.0000e+00\n",
      "Epoch 4561/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8147 - accuracy: 0.0000e+00 - val_loss: 142.2278 - val_accuracy: 0.0000e+00\n",
      "Epoch 4562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.1048 - accuracy: 0.0312 - val_loss: 146.2740 - val_accuracy: 0.0000e+00\n",
      "Epoch 4563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0818 - accuracy: 0.0000e+00 - val_loss: 135.5144 - val_accuracy: 0.0000e+00\n",
      "Epoch 4564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3768 - accuracy: 0.0156 - val_loss: 127.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 4565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4672 - accuracy: 0.0156 - val_loss: 122.3471 - val_accuracy: 0.1176\n",
      "Epoch 4566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5328 - accuracy: 0.0469 - val_loss: 121.6938 - val_accuracy: 0.1176\n",
      "Epoch 4567/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.3936 - accuracy: 0.0156 - val_loss: 124.0589 - val_accuracy: 0.0588\n",
      "Epoch 4568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9567 - accuracy: 0.0000e+00 - val_loss: 129.1380 - val_accuracy: 0.0588\n",
      "Epoch 4569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2824 - accuracy: 0.0156 - val_loss: 139.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8736 - accuracy: 0.0000e+00 - val_loss: 141.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 4571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5665 - accuracy: 0.0000e+00 - val_loss: 133.3478 - val_accuracy: 0.0000e+00\n",
      "Epoch 4572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0056 - accuracy: 0.0000e+00 - val_loss: 124.4797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 55.7654 - accuracy: 0.0000e+00 - val_loss: 130.4282 - val_accuracy: 0.0000e+00\n",
      "Epoch 4574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0013 - accuracy: 0.0000e+00 - val_loss: 134.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 4575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4762 - accuracy: 0.0000e+00 - val_loss: 132.6593 - val_accuracy: 0.0588\n",
      "Epoch 4576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2914 - accuracy: 0.0156 - val_loss: 123.4565 - val_accuracy: 0.0588\n",
      "Epoch 4577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0197 - accuracy: 0.0000e+00 - val_loss: 117.9925 - val_accuracy: 0.0588\n",
      "Epoch 4578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5590 - accuracy: 0.0156 - val_loss: 114.9055 - val_accuracy: 0.0588\n",
      "Epoch 4579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0052 - accuracy: 0.0156 - val_loss: 117.4484 - val_accuracy: 0.0588\n",
      "Epoch 4580/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8011 - accuracy: 0.0156 - val_loss: 119.1021 - val_accuracy: 0.0000e+00\n",
      "Epoch 4581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9072 - accuracy: 0.0000e+00 - val_loss: 123.1932 - val_accuracy: 0.0000e+00\n",
      "Epoch 4582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1880 - accuracy: 0.0312 - val_loss: 128.9944 - val_accuracy: 0.0000e+00\n",
      "Epoch 4583/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.6793 - accuracy: 0.0312 - val_loss: 132.8485 - val_accuracy: 0.0000e+00\n",
      "Epoch 4584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9146 - accuracy: 0.0000e+00 - val_loss: 135.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 4585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3494 - accuracy: 0.0000e+00 - val_loss: 136.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 4586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6026 - accuracy: 0.0000e+00 - val_loss: 132.8534 - val_accuracy: 0.0000e+00\n",
      "Epoch 4587/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5801 - accuracy: 0.0156 - val_loss: 131.8045 - val_accuracy: 0.0588\n",
      "Epoch 4588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7948 - accuracy: 0.0000e+00 - val_loss: 128.5218 - val_accuracy: 0.0588\n",
      "Epoch 4589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3805 - accuracy: 0.0000e+00 - val_loss: 122.1030 - val_accuracy: 0.0588\n",
      "Epoch 4590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9489 - accuracy: 0.0156 - val_loss: 126.2519 - val_accuracy: 0.0588\n",
      "Epoch 4591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1799 - accuracy: 0.0000e+00 - val_loss: 126.9876 - val_accuracy: 0.0588\n",
      "Epoch 4592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4329 - accuracy: 0.0000e+00 - val_loss: 123.2593 - val_accuracy: 0.0588\n",
      "Epoch 4593/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.6442 - accuracy: 0.062 - 0s 125us/step - loss: 42.0719 - accuracy: 0.0312 - val_loss: 118.2932 - val_accuracy: 0.0588\n",
      "Epoch 4594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6483 - accuracy: 0.0000e+00 - val_loss: 120.3557 - val_accuracy: 0.0588\n",
      "Epoch 4595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.1611 - accuracy: 0.0156 - val_loss: 131.9572 - val_accuracy: 0.0588\n",
      "Epoch 4596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6855 - accuracy: 0.0000e+00 - val_loss: 146.4338 - val_accuracy: 0.0000e+00\n",
      "Epoch 4597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9580 - accuracy: 0.0000e+00 - val_loss: 145.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 4598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.6055 - accuracy: 0.0156 - val_loss: 132.6373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3548 - accuracy: 0.0312 - val_loss: 119.2888 - val_accuracy: 0.1176\n",
      "Epoch 4600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0307 - accuracy: 0.0000e+00 - val_loss: 115.8228 - val_accuracy: 0.0588\n",
      "Epoch 4601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5092 - accuracy: 0.0156 - val_loss: 115.6539 - val_accuracy: 0.0588\n",
      "Epoch 4602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1898 - accuracy: 0.0000e+00 - val_loss: 122.9951 - val_accuracy: 0.0588\n",
      "Epoch 4603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8315 - accuracy: 0.0000e+00 - val_loss: 125.6328 - val_accuracy: 0.0588\n",
      "Epoch 4604/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.1130 - accuracy: 0.0156 - val_loss: 125.3412 - val_accuracy: 0.0588\n",
      "Epoch 4605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.8348 - accuracy: 0.0156 - val_loss: 124.0375 - val_accuracy: 0.0588\n",
      "Epoch 4606/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 48.5992 - accuracy: 0.0000e+00 - val_loss: 118.4490 - val_accuracy: 0.0588\n",
      "Epoch 4607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0697 - accuracy: 0.0000e+00 - val_loss: 123.5912 - val_accuracy: 0.0588\n",
      "Epoch 4608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5930 - accuracy: 0.0000e+00 - val_loss: 127.5750 - val_accuracy: 0.0000e+00\n",
      "Epoch 4609/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.8569 - accuracy: 0.0000e+00 - val_loss: 135.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 4610/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.9550 - accuracy: 0.0000e+00 - val_loss: 138.7740 - val_accuracy: 0.0000e+00\n",
      "Epoch 4611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2047 - accuracy: 0.0000e+00 - val_loss: 143.8734 - val_accuracy: 0.0000e+00\n",
      "Epoch 4612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7776 - accuracy: 0.0000e+00 - val_loss: 141.4996 - val_accuracy: 0.0000e+00\n",
      "Epoch 4613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8809 - accuracy: 0.0000e+00 - val_loss: 135.2449 - val_accuracy: 0.0000e+00\n",
      "Epoch 4614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7965 - accuracy: 0.0000e+00 - val_loss: 125.5381 - val_accuracy: 0.1176\n",
      "Epoch 4615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9623 - accuracy: 0.0000e+00 - val_loss: 116.6789 - val_accuracy: 0.1176\n",
      "Epoch 4616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4692 - accuracy: 0.0000e+00 - val_loss: 110.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 4617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4315 - accuracy: 0.0156 - val_loss: 117.4969 - val_accuracy: 0.0000e+00\n",
      "Epoch 4618/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9211 - accuracy: 0.0156 - val_loss: 130.3262 - val_accuracy: 0.0000e+00\n",
      "Epoch 4619/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.7091 - accuracy: 0.0000e+00 - val_loss: 120.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 4620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7533 - accuracy: 0.0000e+00 - val_loss: 103.1825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8180 - accuracy: 0.0000e+00 - val_loss: 99.4751 - val_accuracy: 0.0000e+00\n",
      "Epoch 4622/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8814 - accuracy: 0.0000e+00 - val_loss: 106.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 4623/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3631 - accuracy: 0.0156 - val_loss: 121.0728 - val_accuracy: 0.0000e+00\n",
      "Epoch 4624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6842 - accuracy: 0.0000e+00 - val_loss: 140.6537 - val_accuracy: 0.0000e+00\n",
      "Epoch 4625/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 46.3544 - accuracy: 0.0000e+00 - val_loss: 149.2159 - val_accuracy: 0.0000e+00\n",
      "Epoch 4626/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9332 - accuracy: 0.0000e+00 - val_loss: 145.4955 - val_accuracy: 0.0000e+00\n",
      "Epoch 4627/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4930 - accuracy: 0.0000e+00 - val_loss: 127.0330 - val_accuracy: 0.0000e+00\n",
      "Epoch 4628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8781 - accuracy: 0.0000e+00 - val_loss: 117.4408 - val_accuracy: 0.0000e+00\n",
      "Epoch 4629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4009 - accuracy: 0.0312 - val_loss: 115.8007 - val_accuracy: 0.0000e+00\n",
      "Epoch 4630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9062 - accuracy: 0.0312 - val_loss: 119.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 4631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5202 - accuracy: 0.0156 - val_loss: 124.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 4632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6381 - accuracy: 0.0156 - val_loss: 132.3484 - val_accuracy: 0.0000e+00\n",
      "Epoch 4633/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5839 - accuracy: 0.0312 - val_loss: 132.3829 - val_accuracy: 0.0000e+00\n",
      "Epoch 4634/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.3379 - accuracy: 0.0000e+00 - val_loss: 125.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 4635/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4930 - accuracy: 0.0156 - val_loss: 117.2896 - val_accuracy: 0.0588\n",
      "Epoch 4636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4650 - accuracy: 0.0000e+00 - val_loss: 119.0148 - val_accuracy: 0.0000e+00\n",
      "Epoch 4637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6422 - accuracy: 0.0156 - val_loss: 122.5101 - val_accuracy: 0.0588\n",
      "Epoch 4638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8272 - accuracy: 0.0000e+00 - val_loss: 130.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 4639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4249 - accuracy: 0.0000e+00 - val_loss: 131.9834 - val_accuracy: 0.0588\n",
      "Epoch 4640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7772 - accuracy: 0.0156 - val_loss: 121.4413 - val_accuracy: 0.0588\n",
      "Epoch 4641/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3622 - accuracy: 0.0156 - val_loss: 111.5839 - val_accuracy: 0.0588\n",
      "Epoch 4642/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.1248 - accuracy: 0.0000e+00 - val_loss: 111.9612 - val_accuracy: 0.0588\n",
      "Epoch 4643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3803 - accuracy: 0.0469 - val_loss: 125.0765 - val_accuracy: 0.0588\n",
      "Epoch 4644/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.2207 - accuracy: 0.0000e+00 - val_loss: 132.5220 - val_accuracy: 0.0588\n",
      "Epoch 4645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9615 - accuracy: 0.0000e+00 - val_loss: 132.8236 - val_accuracy: 0.0588\n",
      "Epoch 4646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1521 - accuracy: 0.0000e+00 - val_loss: 131.7897 - val_accuracy: 0.0000e+00\n",
      "Epoch 4647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7367 - accuracy: 0.0000e+00 - val_loss: 136.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 4648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9572 - accuracy: 0.0000e+00 - val_loss: 135.2020 - val_accuracy: 0.0000e+00\n",
      "Epoch 4649/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2716 - accuracy: 0.0000e+00 - val_loss: 129.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7284 - accuracy: 0.0312 - val_loss: 124.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 4651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8515 - accuracy: 0.0000e+00 - val_loss: 126.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 4652/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.6509 - accuracy: 0.0000e+00 - val_loss: 131.4453 - val_accuracy: 0.0000e+00\n",
      "Epoch 4653/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2534 - accuracy: 0.0000e+00 - val_loss: 127.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 4654/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.9937 - accuracy: 0.0000e+00 - val_loss: 125.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 4655/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5164 - accuracy: 0.0000e+00 - val_loss: 128.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 4656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5280 - accuracy: 0.0000e+00 - val_loss: 126.3180 - val_accuracy: 0.0588\n",
      "Epoch 4657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6744 - accuracy: 0.0156 - val_loss: 127.3583 - val_accuracy: 0.0588\n",
      "Epoch 4658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2274 - accuracy: 0.0156 - val_loss: 131.1875 - val_accuracy: 0.0588\n",
      "Epoch 4659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6941 - accuracy: 0.0156 - val_loss: 137.6465 - val_accuracy: 0.0000e+00\n",
      "Epoch 4660/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.8063 - accuracy: 0.0000e+00 - val_loss: 137.6499 - val_accuracy: 0.0000e+00\n",
      "Epoch 4661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8559 - accuracy: 0.0156 - val_loss: 128.9800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6481 - accuracy: 0.0312 - val_loss: 122.5793 - val_accuracy: 0.0000e+00\n",
      "Epoch 4663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8317 - accuracy: 0.0000e+00 - val_loss: 121.2872 - val_accuracy: 0.0000e+00\n",
      "Epoch 4664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 24.8744 - accuracy: 0.0156 - val_loss: 123.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 4665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4395 - accuracy: 0.0156 - val_loss: 120.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 4666/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0768 - accuracy: 0.0156 - val_loss: 119.9693 - val_accuracy: 0.0588\n",
      "Epoch 4667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2628 - accuracy: 0.0000e+00 - val_loss: 123.7293 - val_accuracy: 0.0000e+00\n",
      "Epoch 4668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0554 - accuracy: 0.0000e+00 - val_loss: 126.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 4669/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7995 - accuracy: 0.0000e+00 - val_loss: 122.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 4670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6008 - accuracy: 0.0156 - val_loss: 120.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 4671/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5417 - accuracy: 0.0000e+00 - val_loss: 118.7876 - val_accuracy: 0.1176\n",
      "Epoch 4672/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1736 - accuracy: 0.0000e+00 - val_loss: 121.4433 - val_accuracy: 0.0588\n",
      "Epoch 4673/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3513 - accuracy: 0.0156 - val_loss: 127.7337 - val_accuracy: 0.0588\n",
      "Epoch 4674/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.2270 - accuracy: 0.0312 - val_loss: 135.2723 - val_accuracy: 0.0588\n",
      "Epoch 4675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4477 - accuracy: 0.0000e+00 - val_loss: 138.7209 - val_accuracy: 0.0588\n",
      "Epoch 4676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1429 - accuracy: 0.0000e+00 - val_loss: 133.4893 - val_accuracy: 0.0588\n",
      "Epoch 4677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9662 - accuracy: 0.0156 - val_loss: 130.3027 - val_accuracy: 0.0588\n",
      "Epoch 4678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9962 - accuracy: 0.0156 - val_loss: 122.1549 - val_accuracy: 0.0588\n",
      "Epoch 4679/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0492 - accuracy: 0.0000e+00 - val_loss: 117.0720 - val_accuracy: 0.0588\n",
      "Epoch 4680/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4257 - accuracy: 0.0000e+00 - val_loss: 112.2199 - val_accuracy: 0.0588\n",
      "Epoch 4681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6306 - accuracy: 0.0156 - val_loss: 118.0243 - val_accuracy: 0.0588\n",
      "Epoch 4682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9416 - accuracy: 0.0000e+00 - val_loss: 130.4801 - val_accuracy: 0.0588\n",
      "Epoch 4683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6660 - accuracy: 0.0000e+00 - val_loss: 141.9000 - val_accuracy: 0.0588\n",
      "Epoch 4684/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.2013 - accuracy: 0.031 - 0s 62us/step - loss: 40.6002 - accuracy: 0.0156 - val_loss: 146.0704 - val_accuracy: 0.0588\n",
      "Epoch 4685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 56.8541 - accuracy: 0.0000e+00 - val_loss: 135.5488 - val_accuracy: 0.0588\n",
      "Epoch 4686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0858 - accuracy: 0.0000e+00 - val_loss: 118.6547 - val_accuracy: 0.0588\n",
      "Epoch 4687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2517 - accuracy: 0.0156 - val_loss: 108.7105 - val_accuracy: 0.0588\n",
      "Epoch 4688/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.8373 - accuracy: 0.0000e+00 - val_loss: 103.5560 - val_accuracy: 0.0588\n",
      "Epoch 4689/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0913 - accuracy: 0.0000e+00 - val_loss: 111.5406 - val_accuracy: 0.0000e+00\n",
      "Epoch 4690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8302 - accuracy: 0.0000e+00 - val_loss: 119.2257 - val_accuracy: 0.0000e+00\n",
      "Epoch 4691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0558 - accuracy: 0.0000e+00 - val_loss: 125.3581 - val_accuracy: 0.0000e+00\n",
      "Epoch 4692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.0548 - accuracy: 0.0156 - val_loss: 132.7099 - val_accuracy: 0.0000e+00\n",
      "Epoch 4693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8470 - accuracy: 0.0000e+00 - val_loss: 134.8075 - val_accuracy: 0.0000e+00\n",
      "Epoch 4694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2377 - accuracy: 0.0000e+00 - val_loss: 127.8241 - val_accuracy: 0.0000e+00\n",
      "Epoch 4695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6581 - accuracy: 0.0000e+00 - val_loss: 121.1592 - val_accuracy: 0.0588\n",
      "Epoch 4696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0245 - accuracy: 0.0000e+00 - val_loss: 118.5173 - val_accuracy: 0.0000e+00\n",
      "Epoch 4697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0751 - accuracy: 0.0000e+00 - val_loss: 121.3049 - val_accuracy: 0.0588\n",
      "Epoch 4698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8414 - accuracy: 0.0000e+00 - val_loss: 127.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 4699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7496 - accuracy: 0.0156 - val_loss: 141.1150 - val_accuracy: 0.0000e+00\n",
      "Epoch 4700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0832 - accuracy: 0.0312 - val_loss: 140.7357 - val_accuracy: 0.0000e+00\n",
      "Epoch 4701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0484 - accuracy: 0.0156 - val_loss: 136.9842 - val_accuracy: 0.0588\n",
      "Epoch 4702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.4729 - accuracy: 0.0000e+00 - val_loss: 135.3475 - val_accuracy: 0.0588\n",
      "Epoch 4703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9996 - accuracy: 0.0000e+00 - val_loss: 134.4850 - val_accuracy: 0.0588\n",
      "Epoch 4704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7145 - accuracy: 0.0000e+00 - val_loss: 137.2465 - val_accuracy: 0.0588\n",
      "Epoch 4705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9939 - accuracy: 0.0000e+00 - val_loss: 138.5542 - val_accuracy: 0.1176\n",
      "Epoch 4706/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.1518 - accuracy: 0.0000e+00 - val_loss: 140.6373 - val_accuracy: 0.0588\n",
      "Epoch 4707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7647 - accuracy: 0.0156 - val_loss: 144.3104 - val_accuracy: 0.0588\n",
      "Epoch 4708/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.9162 - accuracy: 0.0312 - val_loss: 143.1315 - val_accuracy: 0.0588\n",
      "Epoch 4709/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6009 - accuracy: 0.0000e+00 - val_loss: 129.7695 - val_accuracy: 0.0588\n",
      "Epoch 4710/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4758 - accuracy: 0.0000e+00 - val_loss: 120.3929 - val_accuracy: 0.0588\n",
      "Epoch 4711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6128 - accuracy: 0.0000e+00 - val_loss: 122.2746 - val_accuracy: 0.0588\n",
      "Epoch 4712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4251 - accuracy: 0.0000e+00 - val_loss: 130.5350 - val_accuracy: 0.0588\n",
      "Epoch 4713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6965 - accuracy: 0.0000e+00 - val_loss: 135.2626 - val_accuracy: 0.0588\n",
      "Epoch 4714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2322 - accuracy: 0.0000e+00 - val_loss: 145.7061 - val_accuracy: 0.0588\n",
      "Epoch 4715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4314 - accuracy: 0.0000e+00 - val_loss: 144.7124 - val_accuracy: 0.0588\n",
      "Epoch 4716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.5137 - accuracy: 0.0156 - val_loss: 139.7368 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4717/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5611 - accuracy: 0.0312 - val_loss: 140.2079 - val_accuracy: 0.0588\n",
      "Epoch 4718/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0927 - accuracy: 0.0000e+00 - val_loss: 133.7344 - val_accuracy: 0.1176\n",
      "Epoch 4719/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.9327 - accuracy: 0.0156 - val_loss: 126.0607 - val_accuracy: 0.0588\n",
      "Epoch 4720/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.2058 - accuracy: 0.0000e+00 - val_loss: 122.3253 - val_accuracy: 0.0588\n",
      "Epoch 4721/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.1599 - accuracy: 0.0156 - val_loss: 127.8654 - val_accuracy: 0.0588\n",
      "Epoch 4722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1292 - accuracy: 0.0156 - val_loss: 132.2300 - val_accuracy: 0.0588\n",
      "Epoch 4723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8216 - accuracy: 0.0000e+00 - val_loss: 126.3826 - val_accuracy: 0.0588\n",
      "Epoch 4724/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7740 - accuracy: 0.0312 - val_loss: 116.7067 - val_accuracy: 0.0588\n",
      "Epoch 4725/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7537 - accuracy: 0.0156 - val_loss: 113.5798 - val_accuracy: 0.0588\n",
      "Epoch 4726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5678 - accuracy: 0.0000e+00 - val_loss: 116.6696 - val_accuracy: 0.0588\n",
      "Epoch 4727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8078 - accuracy: 0.0000e+00 - val_loss: 128.8009 - val_accuracy: 0.0588\n",
      "Epoch 4728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7743 - accuracy: 0.0156 - val_loss: 133.2878 - val_accuracy: 0.0588\n",
      "Epoch 4729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4850 - accuracy: 0.0156 - val_loss: 126.1022 - val_accuracy: 0.0588\n",
      "Epoch 4730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9422 - accuracy: 0.0000e+00 - val_loss: 120.0147 - val_accuracy: 0.0588\n",
      "Epoch 4731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6317 - accuracy: 0.0000e+00 - val_loss: 120.5570 - val_accuracy: 0.0588\n",
      "Epoch 4732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5809 - accuracy: 0.0156 - val_loss: 113.0423 - val_accuracy: 0.0588\n",
      "Epoch 4733/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4214 - accuracy: 0.0156 - val_loss: 105.6257 - val_accuracy: 0.0588\n",
      "Epoch 4734/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.7201 - accuracy: 0.0000e+00 - val_loss: 105.2177 - val_accuracy: 0.0588\n",
      "Epoch 4735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6479 - accuracy: 0.0000e+00 - val_loss: 101.4806 - val_accuracy: 0.0588\n",
      "Epoch 4736/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.3705 - accuracy: 0.0156 - val_loss: 120.1765 - val_accuracy: 0.0588\n",
      "Epoch 4737/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9062 - accuracy: 0.0000e+00 - val_loss: 141.2640 - val_accuracy: 0.0588\n",
      "Epoch 4738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3562 - accuracy: 0.0000e+00 - val_loss: 137.9740 - val_accuracy: 0.0588\n",
      "Epoch 4739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0816 - accuracy: 0.0000e+00 - val_loss: 123.4790 - val_accuracy: 0.1176\n",
      "Epoch 4740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9443 - accuracy: 0.0000e+00 - val_loss: 113.6138 - val_accuracy: 0.0588\n",
      "Epoch 4741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0778 - accuracy: 0.0000e+00 - val_loss: 112.8005 - val_accuracy: 0.0588\n",
      "Epoch 4742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2735 - accuracy: 0.0156 - val_loss: 113.0975 - val_accuracy: 0.0588\n",
      "Epoch 4743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9109 - accuracy: 0.0000e+00 - val_loss: 108.9004 - val_accuracy: 0.0588\n",
      "Epoch 4744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4384 - accuracy: 0.0156 - val_loss: 103.3215 - val_accuracy: 0.0588\n",
      "Epoch 4745/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.6576 - accuracy: 0.0156 - val_loss: 103.6563 - val_accuracy: 0.0588\n",
      "Epoch 4746/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3087 - accuracy: 0.0312 - val_loss: 109.3022 - val_accuracy: 0.0588\n",
      "Epoch 4747/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1022 - accuracy: 0.0000e+00 - val_loss: 115.0375 - val_accuracy: 0.0588\n",
      "Epoch 4748/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9438 - accuracy: 0.0156 - val_loss: 118.6997 - val_accuracy: 0.0588\n",
      "Epoch 4749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7367 - accuracy: 0.0156 - val_loss: 121.9203 - val_accuracy: 0.0588\n",
      "Epoch 4750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9369 - accuracy: 0.0156 - val_loss: 115.3095 - val_accuracy: 0.0588\n",
      "Epoch 4751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5427 - accuracy: 0.0156 - val_loss: 116.0434 - val_accuracy: 0.0588\n",
      "Epoch 4752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5490 - accuracy: 0.0156 - val_loss: 123.0928 - val_accuracy: 0.0588\n",
      "Epoch 4753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6483 - accuracy: 0.0000e+00 - val_loss: 129.1101 - val_accuracy: 0.0588\n",
      "Epoch 4754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7359 - accuracy: 0.0156 - val_loss: 135.5909 - val_accuracy: 0.0588\n",
      "Epoch 4755/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3999 - accuracy: 0.0000e+00 - val_loss: 140.3935 - val_accuracy: 0.0588\n",
      "Epoch 4756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6998 - accuracy: 0.0000e+00 - val_loss: 146.0316 - val_accuracy: 0.1176\n",
      "Epoch 4757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9973 - accuracy: 0.0156 - val_loss: 145.7159 - val_accuracy: 0.0588\n",
      "Epoch 4758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4273 - accuracy: 0.0156 - val_loss: 138.4665 - val_accuracy: 0.0588\n",
      "Epoch 4759/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.8527 - accuracy: 0.0000e+00 - val_loss: 131.6822 - val_accuracy: 0.0588\n",
      "Epoch 4760/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.0525 - accuracy: 0.0000e+00 - val_loss: 121.1803 - val_accuracy: 0.0588\n",
      "Epoch 4761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6506 - accuracy: 0.0000e+00 - val_loss: 116.2366 - val_accuracy: 0.0588\n",
      "Epoch 4762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0336 - accuracy: 0.0156 - val_loss: 114.9071 - val_accuracy: 0.0588\n",
      "Epoch 4763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6871 - accuracy: 0.0000e+00 - val_loss: 113.5400 - val_accuracy: 0.0588\n",
      "Epoch 4764/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1469 - accuracy: 0.0156 - val_loss: 118.4264 - val_accuracy: 0.0588\n",
      "Epoch 4765/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6525 - accuracy: 0.0000e+00 - val_loss: 127.5555 - val_accuracy: 0.0588\n",
      "Epoch 4766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0552 - accuracy: 0.0000e+00 - val_loss: 129.6335 - val_accuracy: 0.1176\n",
      "Epoch 4767/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1181 - accuracy: 0.0000e+00 - val_loss: 134.9105 - val_accuracy: 0.0588\n",
      "Epoch 4768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5984 - accuracy: 0.0000e+00 - val_loss: 138.1430 - val_accuracy: 0.0588\n",
      "Epoch 4769/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3621 - accuracy: 0.0156 - val_loss: 140.6962 - val_accuracy: 0.0588\n",
      "Epoch 4770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4679 - accuracy: 0.0156 - val_loss: 135.6747 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4771/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.1735 - accuracy: 0.0000e+00 - val_loss: 132.4204 - val_accuracy: 0.0588\n",
      "Epoch 4772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4145 - accuracy: 0.0156 - val_loss: 126.6248 - val_accuracy: 0.0588\n",
      "Epoch 4773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8604 - accuracy: 0.0000e+00 - val_loss: 119.2832 - val_accuracy: 0.0588\n",
      "Epoch 4774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8602 - accuracy: 0.0156 - val_loss: 117.5487 - val_accuracy: 0.0588\n",
      "Epoch 4775/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.2587 - accuracy: 0.0000e+00 - val_loss: 113.8217 - val_accuracy: 0.0588\n",
      "Epoch 4776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7710 - accuracy: 0.0000e+00 - val_loss: 117.1573 - val_accuracy: 0.0588\n",
      "Epoch 4777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8269 - accuracy: 0.0000e+00 - val_loss: 121.9071 - val_accuracy: 0.0588\n",
      "Epoch 4778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5064 - accuracy: 0.0156 - val_loss: 146.1628 - val_accuracy: 0.0588\n",
      "Epoch 4779/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.9387 - accuracy: 0.0156 - val_loss: 147.3952 - val_accuracy: 0.0588\n",
      "Epoch 4780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.5129 - accuracy: 0.0000e+00 - val_loss: 138.8865 - val_accuracy: 0.0588\n",
      "Epoch 4781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5241 - accuracy: 0.0000e+00 - val_loss: 129.6111 - val_accuracy: 0.0588\n",
      "Epoch 4782/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.5911 - accuracy: 0.0000e+00 - val_loss: 128.9529 - val_accuracy: 0.0588\n",
      "Epoch 4783/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.9405 - accuracy: 0.0000e+00 - val_loss: 128.2919 - val_accuracy: 0.0588\n",
      "Epoch 4784/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.0212 - accuracy: 0.0156 - val_loss: 128.2254 - val_accuracy: 0.0588\n",
      "Epoch 4785/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.0616 - accuracy: 0.0000e+00 - val_loss: 129.0447 - val_accuracy: 0.0588\n",
      "Epoch 4786/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 23.6487 - accuracy: 0.0156 - val_loss: 131.1225 - val_accuracy: 0.0588\n",
      "Epoch 4787/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4219 - accuracy: 0.0000e+00 - val_loss: 132.6113 - val_accuracy: 0.0588\n",
      "Epoch 4788/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9112 - accuracy: 0.0156 - val_loss: 124.0958 - val_accuracy: 0.0588\n",
      "Epoch 4789/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1969 - accuracy: 0.0156 - val_loss: 118.5900 - val_accuracy: 0.0588\n",
      "Epoch 4790/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.0608 - accuracy: 0.0000e+00 - val_loss: 117.0075 - val_accuracy: 0.0588\n",
      "Epoch 4791/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8613 - accuracy: 0.0000e+00 - val_loss: 126.4737 - val_accuracy: 0.0588\n",
      "Epoch 4792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1540 - accuracy: 0.0000e+00 - val_loss: 143.0937 - val_accuracy: 0.0000e+00\n",
      "Epoch 4793/10000\n",
      "64/64 [==============================] - 0s 206us/step - loss: 34.1213 - accuracy: 0.0000e+00 - val_loss: 143.7516 - val_accuracy: 0.0000e+00\n",
      "Epoch 4794/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 30.1053 - accuracy: 0.0156 - val_loss: 136.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 4795/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 23.1801 - accuracy: 0.0000e+00 - val_loss: 129.1235 - val_accuracy: 0.0000e+00\n",
      "Epoch 4796/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 34.2535 - accuracy: 0.0000e+00 - val_loss: 121.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 4797/10000\n",
      "64/64 [==============================] - 0s 49us/step - loss: 37.3099 - accuracy: 0.0312 - val_loss: 115.9666 - val_accuracy: 0.0000e+00\n",
      "Epoch 4798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4909 - accuracy: 0.0156 - val_loss: 120.3410 - val_accuracy: 0.0588\n",
      "Epoch 4799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5893 - accuracy: 0.0156 - val_loss: 138.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 4800/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4212 - accuracy: 0.0000e+00 - val_loss: 157.5371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8279 - accuracy: 0.0000e+00 - val_loss: 152.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 4802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6718 - accuracy: 0.0000e+00 - val_loss: 129.6394 - val_accuracy: 0.0000e+00\n",
      "Epoch 4803/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7492 - accuracy: 0.0000e+00 - val_loss: 118.3832 - val_accuracy: 0.0000e+00\n",
      "Epoch 4804/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 37.6661 - accuracy: 0.0156 - val_loss: 118.1371 - val_accuracy: 0.0000e+00\n",
      "Epoch 4805/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 33.0463 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 26.6533 - accuracy: 0.0156 - val_loss: 125.3512 - val_accuracy: 0.0588\n",
      "Epoch 4806/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.3315 - accuracy: 0.0312 - val_loss: 137.4168 - val_accuracy: 0.0588\n",
      "Epoch 4807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8963 - accuracy: 0.0156 - val_loss: 136.7420 - val_accuracy: 0.0588\n",
      "Epoch 4808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0082 - accuracy: 0.0000e+00 - val_loss: 135.3894 - val_accuracy: 0.0588\n",
      "Epoch 4809/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 23.7687 - accuracy: 0.0156 - val_loss: 133.6747 - val_accuracy: 0.0588\n",
      "Epoch 4810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9167 - accuracy: 0.0000e+00 - val_loss: 129.1966 - val_accuracy: 0.0588\n",
      "Epoch 4811/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5167 - accuracy: 0.0156 - val_loss: 125.7334 - val_accuracy: 0.0588\n",
      "Epoch 4812/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.3207 - accuracy: 0.0156 - val_loss: 126.2121 - val_accuracy: 0.0588\n",
      "Epoch 4813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5970 - accuracy: 0.0312 - val_loss: 127.6076 - val_accuracy: 0.0000e+00\n",
      "Epoch 4814/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 27.3352 - accuracy: 0.0156 - val_loss: 127.2800 - val_accuracy: 0.0000e+00\n",
      "Epoch 4815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9883 - accuracy: 0.0312 - val_loss: 127.6811 - val_accuracy: 0.0000e+00\n",
      "Epoch 4816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3782 - accuracy: 0.0156 - val_loss: 134.0856 - val_accuracy: 0.0000e+00\n",
      "Epoch 4817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0358 - accuracy: 0.0312 - val_loss: 141.3675 - val_accuracy: 0.0000e+00\n",
      "Epoch 4818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9817 - accuracy: 0.0000e+00 - val_loss: 142.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 4819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4050 - accuracy: 0.0000e+00 - val_loss: 140.5576 - val_accuracy: 0.1176\n",
      "Epoch 4820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3742 - accuracy: 0.0000e+00 - val_loss: 136.5948 - val_accuracy: 0.1176\n",
      "Epoch 4821/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2958 - accuracy: 0.0000e+00 - val_loss: 135.3503 - val_accuracy: 0.0588\n",
      "Epoch 4822/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 36.9541 - accuracy: 0.0469 - val_loss: 131.5566 - val_accuracy: 0.0588\n",
      "Epoch 4823/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8381 - accuracy: 0.0156 - val_loss: 124.9467 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0800 - accuracy: 0.0156 - val_loss: 121.0568 - val_accuracy: 0.0588\n",
      "Epoch 4825/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.3263 - accuracy: 0.0156 - val_loss: 129.9779 - val_accuracy: 0.0000e+00\n",
      "Epoch 4826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7789 - accuracy: 0.0156 - val_loss: 132.1154 - val_accuracy: 0.0000e+00\n",
      "Epoch 4827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8273 - accuracy: 0.0156 - val_loss: 130.3708 - val_accuracy: 0.0588\n",
      "Epoch 4828/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.6394 - accuracy: 0.0000e+00 - val_loss: 128.5004 - val_accuracy: 0.0588\n",
      "Epoch 4829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2161 - accuracy: 0.0156 - val_loss: 121.0837 - val_accuracy: 0.0588\n",
      "Epoch 4830/10000\n",
      "64/64 [==============================] - 0s 191us/step - loss: 29.0917 - accuracy: 0.0000e+00 - val_loss: 116.1151 - val_accuracy: 0.0588\n",
      "Epoch 4831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4276 - accuracy: 0.0000e+00 - val_loss: 118.8554 - val_accuracy: 0.0588\n",
      "Epoch 4832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4664 - accuracy: 0.0156 - val_loss: 131.9387 - val_accuracy: 0.0000e+00\n",
      "Epoch 4833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0350 - accuracy: 0.0000e+00 - val_loss: 140.2743 - val_accuracy: 0.0000e+00\n",
      "Epoch 4834/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.2131 - accuracy: 0.0000e+00 - val_loss: 141.7290 - val_accuracy: 0.0000e+00\n",
      "Epoch 4835/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.4872 - accuracy: 0.0156 - val_loss: 138.6646 - val_accuracy: 0.0588\n",
      "Epoch 4836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6898 - accuracy: 0.0312 - val_loss: 134.8496 - val_accuracy: 0.0000e+00\n",
      "Epoch 4837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4067 - accuracy: 0.0156 - val_loss: 134.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 4838/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 35.4039 - accuracy: 0.0000e+00 - val_loss: 133.3254 - val_accuracy: 0.0588\n",
      "Epoch 4839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3593 - accuracy: 0.0156 - val_loss: 136.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 4840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8979 - accuracy: 0.0000e+00 - val_loss: 140.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 4841/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.4316 - accuracy: 0.0000e+00 - val_loss: 146.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 4842/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.5359 - accuracy: 0.0156 - val_loss: 144.4041 - val_accuracy: 0.0000e+00\n",
      "Epoch 4843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7259 - accuracy: 0.0000e+00 - val_loss: 132.3076 - val_accuracy: 0.0588\n",
      "Epoch 4844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7045 - accuracy: 0.0000e+00 - val_loss: 117.4917 - val_accuracy: 0.0588\n",
      "Epoch 4845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3792 - accuracy: 0.0000e+00 - val_loss: 106.0106 - val_accuracy: 0.1176\n",
      "Epoch 4846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7919 - accuracy: 0.0000e+00 - val_loss: 105.1441 - val_accuracy: 0.1176\n",
      "Epoch 4847/10000\n",
      "64/64 [==============================] - 0s 183us/step - loss: 28.4724 - accuracy: 0.0000e+00 - val_loss: 108.3193 - val_accuracy: 0.1176\n",
      "Epoch 4848/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 38.5957 - accuracy: 0.0000e+00 - val_loss: 123.4880 - val_accuracy: 0.0588\n",
      "Epoch 4849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8135 - accuracy: 0.0000e+00 - val_loss: 143.3354 - val_accuracy: 0.0588\n",
      "Epoch 4850/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 33.3765 - accuracy: 0.0000e+00 - val_loss: 137.1508 - val_accuracy: 0.0588\n",
      "Epoch 4851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6259 - accuracy: 0.0156 - val_loss: 119.8637 - val_accuracy: 0.0588\n",
      "Epoch 4852/10000\n",
      "64/64 [==============================] - 0s 570us/step - loss: 44.4322 - accuracy: 0.0156 - val_loss: 113.9996 - val_accuracy: 0.0588\n",
      "Epoch 4853/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9924 - accuracy: 0.0000e+00 - val_loss: 112.9694 - val_accuracy: 0.0588\n",
      "Epoch 4854/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.0908 - accuracy: 0.0000e+00 - val_loss: 118.6413 - val_accuracy: 0.1176\n",
      "Epoch 4855/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.3431 - accuracy: 0.0000e+00 - val_loss: 120.5791 - val_accuracy: 0.1176\n",
      "Epoch 4856/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.4439 - accuracy: 0.0000e+00 - val_loss: 115.6243 - val_accuracy: 0.1176\n",
      "Epoch 4857/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 21.0654 - accuracy: 0.0000e+00 - val_loss: 113.8159 - val_accuracy: 0.0588\n",
      "Epoch 4858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3195 - accuracy: 0.0156 - val_loss: 124.9600 - val_accuracy: 0.0588\n",
      "Epoch 4859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0953 - accuracy: 0.0000e+00 - val_loss: 135.4394 - val_accuracy: 0.0588\n",
      "Epoch 4860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1537 - accuracy: 0.0156 - val_loss: 136.3217 - val_accuracy: 0.0588\n",
      "Epoch 4861/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 35.4502 - accuracy: 0.0156 - val_loss: 122.4523 - val_accuracy: 0.0588\n",
      "Epoch 4862/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 29.8698 - accuracy: 0.0000e+00 - val_loss: 115.5168 - val_accuracy: 0.1176\n",
      "Epoch 4863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9854 - accuracy: 0.0156 - val_loss: 116.0353 - val_accuracy: 0.0588\n",
      "Epoch 4864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0085 - accuracy: 0.0156 - val_loss: 116.5183 - val_accuracy: 0.0588\n",
      "Epoch 4865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8991 - accuracy: 0.0156 - val_loss: 125.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 4866/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0710 - accuracy: 0.0000e+00 - val_loss: 133.6557 - val_accuracy: 0.0588\n",
      "Epoch 4867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1186 - accuracy: 0.0000e+00 - val_loss: 138.1697 - val_accuracy: 0.0000e+00\n",
      "Epoch 4868/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.1643 - accuracy: 0.0156 - val_loss: 133.9398 - val_accuracy: 0.0000e+00\n",
      "Epoch 4869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4893 - accuracy: 0.0156 - val_loss: 122.3688 - val_accuracy: 0.0588\n",
      "Epoch 4870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6905 - accuracy: 0.0000e+00 - val_loss: 112.6743 - val_accuracy: 0.0588\n",
      "Epoch 4871/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.5202 - accuracy: 0.0000e+00 - val_loss: 111.3106 - val_accuracy: 0.0588\n",
      "Epoch 4872/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 25.4098 - accuracy: 0.0312 - val_loss: 118.0555 - val_accuracy: 0.0588\n",
      "Epoch 4873/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.8718 - accuracy: 0.0469 - val_loss: 134.0043 - val_accuracy: 0.0588\n",
      "Epoch 4874/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.6569 - accuracy: 0.0156 - val_loss: 143.9270 - val_accuracy: 0.0588\n",
      "Epoch 4875/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.3899 - accuracy: 0.0000e+00 - val_loss: 143.0477 - val_accuracy: 0.0588\n",
      "Epoch 4876/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.8568 - accuracy: 0.0000e+00 - val_loss: 142.3092 - val_accuracy: 0.0588\n",
      "Epoch 4877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9103 - accuracy: 0.0156 - val_loss: 138.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 4878/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.8266 - accuracy: 0.0000e+00 - val_loss: 135.0820 - val_accuracy: 0.0000e+00\n",
      "Epoch 4879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9326 - accuracy: 0.0156 - val_loss: 128.7217 - val_accuracy: 0.0000e+00\n",
      "Epoch 4880/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 27.6084 - accuracy: 0.0000e+00 - val_loss: 121.9730 - val_accuracy: 0.0000e+00\n",
      "Epoch 4881/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 44.2049 - accuracy: 0.0156 - val_loss: 122.4315 - val_accuracy: 0.0588\n",
      "Epoch 4882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.8236 - accuracy: 0.0000e+00 - val_loss: 135.8333 - val_accuracy: 0.0000e+00\n",
      "Epoch 4883/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.0391 - accuracy: 0.0156 - val_loss: 146.6875 - val_accuracy: 0.0000e+00\n",
      "Epoch 4884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1078 - accuracy: 0.0000e+00 - val_loss: 145.4593 - val_accuracy: 0.0000e+00\n",
      "Epoch 4885/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.2867 - accuracy: 0.0156 - val_loss: 126.6013 - val_accuracy: 0.0000e+00\n",
      "Epoch 4886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4986 - accuracy: 0.0000e+00 - val_loss: 118.8702 - val_accuracy: 0.0588\n",
      "Epoch 4887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9700 - accuracy: 0.0156 - val_loss: 118.6629 - val_accuracy: 0.0588\n",
      "Epoch 4888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4145 - accuracy: 0.0156 - val_loss: 124.9752 - val_accuracy: 0.0588\n",
      "Epoch 4889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1059 - accuracy: 0.0000e+00 - val_loss: 132.1615 - val_accuracy: 0.0588\n",
      "Epoch 4890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6394 - accuracy: 0.0156 - val_loss: 132.9706 - val_accuracy: 0.0588\n",
      "Epoch 4891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7283 - accuracy: 0.0156 - val_loss: 123.8517 - val_accuracy: 0.0588\n",
      "Epoch 4892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8179 - accuracy: 0.0000e+00 - val_loss: 118.4311 - val_accuracy: 0.1176\n",
      "Epoch 4893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9065 - accuracy: 0.0312 - val_loss: 121.1026 - val_accuracy: 0.1176\n",
      "Epoch 4894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9368 - accuracy: 0.0000e+00 - val_loss: 128.6778 - val_accuracy: 0.0588\n",
      "Epoch 4895/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7533 - accuracy: 0.0000e+00 - val_loss: 137.6140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0117 - accuracy: 0.0000e+00 - val_loss: 144.3019 - val_accuracy: 0.0000e+00\n",
      "Epoch 4897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1657 - accuracy: 0.0000e+00 - val_loss: 147.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 4898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3095 - accuracy: 0.0000e+00 - val_loss: 134.8376 - val_accuracy: 0.0000e+00\n",
      "Epoch 4899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0999 - accuracy: 0.0156 - val_loss: 117.8134 - val_accuracy: 0.0000e+00\n",
      "Epoch 4900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3065 - accuracy: 0.0000e+00 - val_loss: 115.3278 - val_accuracy: 0.0000e+00\n",
      "Epoch 4901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0748 - accuracy: 0.0469 - val_loss: 120.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 4902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.9715 - accuracy: 0.0156 - val_loss: 123.9555 - val_accuracy: 0.0000e+00\n",
      "Epoch 4903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0601 - accuracy: 0.0469 - val_loss: 126.8902 - val_accuracy: 0.0000e+00\n",
      "Epoch 4904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9604 - accuracy: 0.0156 - val_loss: 143.4501 - val_accuracy: 0.0000e+00\n",
      "Epoch 4905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5124 - accuracy: 0.0156 - val_loss: 153.5114 - val_accuracy: 0.0588\n",
      "Epoch 4906/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9701 - accuracy: 0.0000e+00 - val_loss: 150.4069 - val_accuracy: 0.0588\n",
      "Epoch 4907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6044 - accuracy: 0.0000e+00 - val_loss: 140.4689 - val_accuracy: 0.0588\n",
      "Epoch 4908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8802 - accuracy: 0.0000e+00 - val_loss: 129.2467 - val_accuracy: 0.0588\n",
      "Epoch 4909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3765 - accuracy: 0.0000e+00 - val_loss: 121.2387 - val_accuracy: 0.0588\n",
      "Epoch 4910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6639 - accuracy: 0.0000e+00 - val_loss: 125.7512 - val_accuracy: 0.0000e+00\n",
      "Epoch 4911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.2808 - accuracy: 0.0000e+00 - val_loss: 129.2572 - val_accuracy: 0.0000e+00\n",
      "Epoch 4912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9147 - accuracy: 0.0469 - val_loss: 125.1139 - val_accuracy: 0.0000e+00\n",
      "Epoch 4913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8956 - accuracy: 0.0000e+00 - val_loss: 117.2135 - val_accuracy: 0.0000e+00\n",
      "Epoch 4914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7197 - accuracy: 0.0000e+00 - val_loss: 116.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 4915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2754 - accuracy: 0.0000e+00 - val_loss: 112.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 4916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1350 - accuracy: 0.0000e+00 - val_loss: 117.2797 - val_accuracy: 0.0000e+00\n",
      "Epoch 4917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9019 - accuracy: 0.0000e+00 - val_loss: 128.4635 - val_accuracy: 0.0000e+00\n",
      "Epoch 4918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9847 - accuracy: 0.0000e+00 - val_loss: 143.4786 - val_accuracy: 0.0000e+00\n",
      "Epoch 4919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5623 - accuracy: 0.0000e+00 - val_loss: 141.6354 - val_accuracy: 0.0000e+00\n",
      "Epoch 4920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8246 - accuracy: 0.0000e+00 - val_loss: 137.1232 - val_accuracy: 0.0000e+00\n",
      "Epoch 4921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9267 - accuracy: 0.0156 - val_loss: 133.7260 - val_accuracy: 0.0000e+00\n",
      "Epoch 4922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9682 - accuracy: 0.0000e+00 - val_loss: 127.4582 - val_accuracy: 0.0000e+00\n",
      "Epoch 4923/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4991 - accuracy: 0.0156 - val_loss: 121.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 4924/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 37.3534 - accuracy: 0.0000e+00 - val_loss: 125.2890 - val_accuracy: 0.0000e+00\n",
      "Epoch 4925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9050 - accuracy: 0.0156 - val_loss: 145.3825 - val_accuracy: 0.0000e+00\n",
      "Epoch 4926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8840 - accuracy: 0.0156 - val_loss: 152.2428 - val_accuracy: 0.0000e+00\n",
      "Epoch 4927/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9363 - accuracy: 0.0156 - val_loss: 143.8671 - val_accuracy: 0.0000e+00\n",
      "Epoch 4928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1790 - accuracy: 0.0000e+00 - val_loss: 145.0826 - val_accuracy: 0.0000e+00\n",
      "Epoch 4929/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 40.2370 - accuracy: 0.0000e+00 - val_loss: 140.7140 - val_accuracy: 0.0000e+00\n",
      "Epoch 4930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9911 - accuracy: 0.0000e+00 - val_loss: 134.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 4931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.8366 - accuracy: 0.0000e+00 - val_loss: 125.7008 - val_accuracy: 0.0000e+00\n",
      "Epoch 4932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7898 - accuracy: 0.0156 - val_loss: 118.7721 - val_accuracy: 0.0588\n",
      "Epoch 4933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0476 - accuracy: 0.0156 - val_loss: 111.6619 - val_accuracy: 0.0588\n",
      "Epoch 4934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5641 - accuracy: 0.0000e+00 - val_loss: 108.2448 - val_accuracy: 0.0588\n",
      "Epoch 4935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2779 - accuracy: 0.0156 - val_loss: 117.7867 - val_accuracy: 0.0588\n",
      "Epoch 4936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9574 - accuracy: 0.0000e+00 - val_loss: 134.1375 - val_accuracy: 0.0588\n",
      "Epoch 4937/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0729 - accuracy: 0.0000e+00 - val_loss: 133.9941 - val_accuracy: 0.0588\n",
      "Epoch 4938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3849 - accuracy: 0.0156 - val_loss: 118.9854 - val_accuracy: 0.0588\n",
      "Epoch 4939/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9148 - accuracy: 0.0000e+00 - val_loss: 116.3774 - val_accuracy: 0.0588\n",
      "Epoch 4940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.5286 - accuracy: 0.0312 - val_loss: 120.1381 - val_accuracy: 0.0588\n",
      "Epoch 4941/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 31.7571 - accuracy: 0.0000e+00 - val_loss: 126.5790 - val_accuracy: 0.0588\n",
      "Epoch 4942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0212 - accuracy: 0.0156 - val_loss: 135.7319 - val_accuracy: 0.0588\n",
      "Epoch 4943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7886 - accuracy: 0.0000e+00 - val_loss: 143.0108 - val_accuracy: 0.0588\n",
      "Epoch 4944/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5423 - accuracy: 0.0000e+00 - val_loss: 138.5458 - val_accuracy: 0.0588\n",
      "Epoch 4945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4860 - accuracy: 0.0000e+00 - val_loss: 130.1643 - val_accuracy: 0.0588\n",
      "Epoch 4946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6821 - accuracy: 0.0000e+00 - val_loss: 121.0681 - val_accuracy: 0.0588\n",
      "Epoch 4947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8407 - accuracy: 0.0156 - val_loss: 125.0108 - val_accuracy: 0.0588\n",
      "Epoch 4948/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3644 - accuracy: 0.0156 - val_loss: 131.4257 - val_accuracy: 0.0588\n",
      "Epoch 4949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5348 - accuracy: 0.0000e+00 - val_loss: 134.1639 - val_accuracy: 0.0588\n",
      "Epoch 4950/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 34.4452 - accuracy: 0.0000e+00 - val_loss: 140.7177 - val_accuracy: 0.0588\n",
      "Epoch 4951/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.7729 - accuracy: 0.0000e+00 - val_loss: 137.6395 - val_accuracy: 0.0588\n",
      "Epoch 4952/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 38.7192 - accuracy: 0.0000e+00 - val_loss: 130.4460 - val_accuracy: 0.0588\n",
      "Epoch 4953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8991 - accuracy: 0.0156 - val_loss: 128.3408 - val_accuracy: 0.0588\n",
      "Epoch 4954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9037 - accuracy: 0.0000e+00 - val_loss: 127.1458 - val_accuracy: 0.0588\n",
      "Epoch 4955/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.7539 - accuracy: 0.0156 - val_loss: 125.6311 - val_accuracy: 0.0588\n",
      "Epoch 4956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1391 - accuracy: 0.0156 - val_loss: 132.0844 - val_accuracy: 0.0588\n",
      "Epoch 4957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5869 - accuracy: 0.0156 - val_loss: 138.8631 - val_accuracy: 0.0588\n",
      "Epoch 4958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3837 - accuracy: 0.0000e+00 - val_loss: 140.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 4959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9120 - accuracy: 0.0156 - val_loss: 138.5939 - val_accuracy: 0.0000e+00\n",
      "Epoch 4960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6266 - accuracy: 0.0000e+00 - val_loss: 130.3460 - val_accuracy: 0.0000e+00\n",
      "Epoch 4961/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8018 - accuracy: 0.0156 - val_loss: 118.6867 - val_accuracy: 0.0588\n",
      "Epoch 4962/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0524 - accuracy: 0.0000e+00 - val_loss: 109.4342 - val_accuracy: 0.0588\n",
      "Epoch 4963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2435 - accuracy: 0.0000e+00 - val_loss: 113.0558 - val_accuracy: 0.0588\n",
      "Epoch 4964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9996 - accuracy: 0.0000e+00 - val_loss: 123.2062 - val_accuracy: 0.0588\n",
      "Epoch 4965/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.5038 - accuracy: 0.0312 - val_loss: 127.7361 - val_accuracy: 0.0588\n",
      "Epoch 4966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1130 - accuracy: 0.0156 - val_loss: 127.9225 - val_accuracy: 0.0588\n",
      "Epoch 4967/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5624 - accuracy: 0.0312 - val_loss: 133.3495 - val_accuracy: 0.0588\n",
      "Epoch 4968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8271 - accuracy: 0.0000e+00 - val_loss: 128.5624 - val_accuracy: 0.0588\n",
      "Epoch 4969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9000 - accuracy: 0.0156 - val_loss: 127.9454 - val_accuracy: 0.0588\n",
      "Epoch 4970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4686 - accuracy: 0.0000e+00 - val_loss: 135.3765 - val_accuracy: 0.0588\n",
      "Epoch 4971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7942 - accuracy: 0.0000e+00 - val_loss: 143.0865 - val_accuracy: 0.0588\n",
      "Epoch 4972/10000\n",
      "64/64 [==============================] - 0s 99us/step - loss: 36.2996 - accuracy: 0.0156 - val_loss: 151.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 4973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3914 - accuracy: 0.0156 - val_loss: 145.6996 - val_accuracy: 0.0000e+00\n",
      "Epoch 4974/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.6731 - accuracy: 0.0312 - val_loss: 135.7074 - val_accuracy: 0.0000e+00\n",
      "Epoch 4975/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 18.4711 - accuracy: 0.0000e+00 - val_loss: 121.0077 - val_accuracy: 0.0588\n",
      "Epoch 4976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7059 - accuracy: 0.0312 - val_loss: 109.4722 - val_accuracy: 0.0588\n",
      "Epoch 4977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.6993 - accuracy: 0.0156 - val_loss: 112.9162 - val_accuracy: 0.0588\n",
      "Epoch 4978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5368 - accuracy: 0.0000e+00 - val_loss: 114.3303 - val_accuracy: 0.0588\n",
      "Epoch 4979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0713 - accuracy: 0.0000e+00 - val_loss: 120.8036 - val_accuracy: 0.0588\n",
      "Epoch 4980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6870 - accuracy: 0.0000e+00 - val_loss: 122.0911 - val_accuracy: 0.0588\n",
      "Epoch 4981/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3781 - accuracy: 0.0000e+00 - val_loss: 122.5873 - val_accuracy: 0.0588\n",
      "Epoch 4982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2507 - accuracy: 0.0156 - val_loss: 125.6184 - val_accuracy: 0.0588\n",
      "Epoch 4983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2584 - accuracy: 0.0000e+00 - val_loss: 127.6134 - val_accuracy: 0.0588\n",
      "Epoch 4984/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3067 - accuracy: 0.0000e+00 - val_loss: 131.2030 - val_accuracy: 0.0588\n",
      "Epoch 4985/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.1230 - accuracy: 0.0000e+00 - val_loss: 123.4598 - val_accuracy: 0.0588\n",
      "Epoch 4986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6256 - accuracy: 0.0312 - val_loss: 113.1561 - val_accuracy: 0.0588\n",
      "Epoch 4987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9821 - accuracy: 0.0156 - val_loss: 112.6432 - val_accuracy: 0.1176\n",
      "Epoch 4988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3080 - accuracy: 0.0000e+00 - val_loss: 119.5977 - val_accuracy: 0.0000e+00\n",
      "Epoch 4989/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7849 - accuracy: 0.0000e+00 - val_loss: 131.3126 - val_accuracy: 0.0588\n",
      "Epoch 4990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6061 - accuracy: 0.0000e+00 - val_loss: 146.3314 - val_accuracy: 0.0588\n",
      "Epoch 4991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8116 - accuracy: 0.0000e+00 - val_loss: 146.7036 - val_accuracy: 0.0588\n",
      "Epoch 4992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4814 - accuracy: 0.0000e+00 - val_loss: 139.0651 - val_accuracy: 0.0588\n",
      "Epoch 4993/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 28.1726 - accuracy: 0.0312 - val_loss: 137.4003 - val_accuracy: 0.0588\n",
      "Epoch 4994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2336 - accuracy: 0.0000e+00 - val_loss: 134.4182 - val_accuracy: 0.0588\n",
      "Epoch 4995/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 31.8790 - accuracy: 0.0000e+00 - val_loss: 131.4052 - val_accuracy: 0.0588\n",
      "Epoch 4996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0412 - accuracy: 0.0156 - val_loss: 127.6952 - val_accuracy: 0.0588\n",
      "Epoch 4997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4942 - accuracy: 0.0312 - val_loss: 125.8011 - val_accuracy: 0.0588\n",
      "Epoch 4998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3863 - accuracy: 0.0312 - val_loss: 126.6958 - val_accuracy: 0.0588\n",
      "Epoch 4999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8601 - accuracy: 0.0156 - val_loss: 125.1687 - val_accuracy: 0.0588\n",
      "Epoch 5000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1934 - accuracy: 0.0156 - val_loss: 126.1779 - val_accuracy: 0.0588\n",
      "Epoch 5001/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8945 - accuracy: 0.0000e+00 - val_loss: 130.2623 - val_accuracy: 0.0588\n",
      "Epoch 5002/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6005 - accuracy: 0.0000e+00 - val_loss: 130.4492 - val_accuracy: 0.0588\n",
      "Epoch 5003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6277 - accuracy: 0.0156 - val_loss: 125.2013 - val_accuracy: 0.0588\n",
      "Epoch 5004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1351 - accuracy: 0.0000e+00 - val_loss: 119.9809 - val_accuracy: 0.0588\n",
      "Epoch 5005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.7408 - accuracy: 0.0156 - val_loss: 122.7736 - val_accuracy: 0.0588\n",
      "Epoch 5006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4884 - accuracy: 0.0000e+00 - val_loss: 131.1320 - val_accuracy: 0.0588\n",
      "Epoch 5007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1935 - accuracy: 0.0156 - val_loss: 141.5454 - val_accuracy: 0.0588\n",
      "Epoch 5008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4055 - accuracy: 0.0000e+00 - val_loss: 145.4222 - val_accuracy: 0.0588\n",
      "Epoch 5009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0394 - accuracy: 0.0156 - val_loss: 137.0329 - val_accuracy: 0.0588\n",
      "Epoch 5010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0530 - accuracy: 0.0000e+00 - val_loss: 123.3015 - val_accuracy: 0.0588\n",
      "Epoch 5011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0573 - accuracy: 0.0000e+00 - val_loss: 122.9426 - val_accuracy: 0.0588\n",
      "Epoch 5012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2909 - accuracy: 0.0000e+00 - val_loss: 126.8232 - val_accuracy: 0.0588\n",
      "Epoch 5013/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7099 - accuracy: 0.0000e+00 - val_loss: 128.0818 - val_accuracy: 0.0588\n",
      "Epoch 5014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1673 - accuracy: 0.0000e+00 - val_loss: 126.3518 - val_accuracy: 0.0588\n",
      "Epoch 5015/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 41.2369 - accuracy: 0.0000e+00 - val_loss: 130.7705 - val_accuracy: 0.0588\n",
      "Epoch 5016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4811 - accuracy: 0.0000e+00 - val_loss: 136.7850 - val_accuracy: 0.0588\n",
      "Epoch 5017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4689 - accuracy: 0.0000e+00 - val_loss: 134.8497 - val_accuracy: 0.0588\n",
      "Epoch 5018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9374 - accuracy: 0.0312 - val_loss: 132.4167 - val_accuracy: 0.0588\n",
      "Epoch 5019/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3588 - accuracy: 0.0156 - val_loss: 125.6408 - val_accuracy: 0.0588\n",
      "Epoch 5020/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5386 - accuracy: 0.0000e+00 - val_loss: 120.7606 - val_accuracy: 0.0588\n",
      "Epoch 5021/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1237 - accuracy: 0.0000e+00 - val_loss: 117.2489 - val_accuracy: 0.0588\n",
      "Epoch 5022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1175 - accuracy: 0.0000e+00 - val_loss: 117.7962 - val_accuracy: 0.0588\n",
      "Epoch 5023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2396 - accuracy: 0.0156 - val_loss: 119.9571 - val_accuracy: 0.0588\n",
      "Epoch 5024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1436 - accuracy: 0.0156 - val_loss: 131.3383 - val_accuracy: 0.0588\n",
      "Epoch 5025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8647 - accuracy: 0.0312 - val_loss: 138.8011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5026/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 29.3642 - accuracy: 0.0156 - val_loss: 136.2193 - val_accuracy: 0.0000e+00\n",
      "Epoch 5027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0128 - accuracy: 0.0156 - val_loss: 131.0582 - val_accuracy: 0.0000e+00\n",
      "Epoch 5028/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1227 - accuracy: 0.0000e+00 - val_loss: 126.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9577 - accuracy: 0.0000e+00 - val_loss: 126.0201 - val_accuracy: 0.0000e+00\n",
      "Epoch 5030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4964 - accuracy: 0.0156 - val_loss: 131.5361 - val_accuracy: 0.0000e+00\n",
      "Epoch 5031/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.2985 - accuracy: 0.0000e+00 - val_loss: 137.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5032/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2338 - accuracy: 0.0156 - val_loss: 136.4033 - val_accuracy: 0.0000e+00\n",
      "Epoch 5033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3844 - accuracy: 0.0000e+00 - val_loss: 134.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 5034/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2889 - accuracy: 0.0156 - val_loss: 131.5493 - val_accuracy: 0.0000e+00\n",
      "Epoch 5035/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 63us/step - loss: 38.1948 - accuracy: 0.0469 - val_loss: 132.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5036/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 37.9350 - accuracy: 0.0156 - val_loss: 135.3933 - val_accuracy: 0.0588\n",
      "Epoch 5037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6696 - accuracy: 0.0156 - val_loss: 130.8718 - val_accuracy: 0.0588\n",
      "Epoch 5038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.5815 - accuracy: 0.0156 - val_loss: 122.0525 - val_accuracy: 0.0588\n",
      "Epoch 5039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6588 - accuracy: 0.0000e+00 - val_loss: 115.5396 - val_accuracy: 0.0588\n",
      "Epoch 5040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3856 - accuracy: 0.0156 - val_loss: 123.9427 - val_accuracy: 0.0588\n",
      "Epoch 5041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6552 - accuracy: 0.0000e+00 - val_loss: 139.7038 - val_accuracy: 0.0588\n",
      "Epoch 5042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1143 - accuracy: 0.0156 - val_loss: 144.6114 - val_accuracy: 0.0000e+00\n",
      "Epoch 5043/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.7556 - accuracy: 0.0156 - val_loss: 138.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 5044/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5117 - accuracy: 0.0000e+00 - val_loss: 130.5803 - val_accuracy: 0.0000e+00\n",
      "Epoch 5045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7126 - accuracy: 0.0156 - val_loss: 132.0982 - val_accuracy: 0.0000e+00\n",
      "Epoch 5046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7152 - accuracy: 0.0000e+00 - val_loss: 137.7254 - val_accuracy: 0.0000e+00\n",
      "Epoch 5047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2181 - accuracy: 0.0000e+00 - val_loss: 138.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5048/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3607 - accuracy: 0.0000e+00 - val_loss: 132.5271 - val_accuracy: 0.0000e+00\n",
      "Epoch 5049/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 42.7715 - accuracy: 0.0000e+00 - val_loss: 128.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 5050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8522 - accuracy: 0.0469 - val_loss: 128.7962 - val_accuracy: 0.0000e+00\n",
      "Epoch 5051/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4690 - accuracy: 0.0000e+00 - val_loss: 129.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 5052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8137 - accuracy: 0.0312 - val_loss: 129.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 5053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1024 - accuracy: 0.0156 - val_loss: 123.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 5054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9006 - accuracy: 0.0000e+00 - val_loss: 124.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4937 - accuracy: 0.0000e+00 - val_loss: 127.5440 - val_accuracy: 0.0000e+00\n",
      "Epoch 5056/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.5275 - accuracy: 0.0000e+00 - val_loss: 131.1707 - val_accuracy: 0.0000e+00\n",
      "Epoch 5057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9319 - accuracy: 0.0000e+00 - val_loss: 130.8605 - val_accuracy: 0.0000e+00\n",
      "Epoch 5058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2119 - accuracy: 0.0000e+00 - val_loss: 129.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5059/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 30.3308 - accuracy: 0.0156 - val_loss: 123.8564 - val_accuracy: 0.0588\n",
      "Epoch 5060/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0045 - accuracy: 0.0000e+00 - val_loss: 121.0227 - val_accuracy: 0.0588\n",
      "Epoch 5061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6687 - accuracy: 0.0000e+00 - val_loss: 120.6086 - val_accuracy: 0.0588\n",
      "Epoch 5062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3592 - accuracy: 0.0000e+00 - val_loss: 130.2876 - val_accuracy: 0.0588\n",
      "Epoch 5063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9538 - accuracy: 0.0156 - val_loss: 134.9242 - val_accuracy: 0.0588\n",
      "Epoch 5064/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4931 - accuracy: 0.0156 - val_loss: 142.7007 - val_accuracy: 0.0000e+00\n",
      "Epoch 5065/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3244 - accuracy: 0.0000e+00 - val_loss: 144.7552 - val_accuracy: 0.0000e+00\n",
      "Epoch 5066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6392 - accuracy: 0.0156 - val_loss: 142.9918 - val_accuracy: 0.0000e+00\n",
      "Epoch 5067/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6061 - accuracy: 0.0000e+00 - val_loss: 138.9647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0121 - accuracy: 0.0156 - val_loss: 127.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 5069/10000\n",
      "64/64 [==============================] - 0s 115us/step - loss: 19.1252 - accuracy: 0.0000e+00 - val_loss: 111.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5070/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.7539 - accuracy: 0.0312 - val_loss: 101.5171 - val_accuracy: 0.0000e+00\n",
      "Epoch 5071/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4412 - accuracy: 0.0156 - val_loss: 110.7580 - val_accuracy: 0.0000e+00\n",
      "Epoch 5072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8245 - accuracy: 0.0312 - val_loss: 130.1544 - val_accuracy: 0.0000e+00\n",
      "Epoch 5073/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 39.8133 - accuracy: 0.0000e+00 - val_loss: 134.6872 - val_accuracy: 0.0000e+00\n",
      "Epoch 5074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3947 - accuracy: 0.0000e+00 - val_loss: 131.5198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5297 - accuracy: 0.0000e+00 - val_loss: 128.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4757 - accuracy: 0.0000e+00 - val_loss: 128.0823 - val_accuracy: 0.0000e+00\n",
      "Epoch 5077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6705 - accuracy: 0.0312 - val_loss: 128.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 5078/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2032 - accuracy: 0.0000e+00 - val_loss: 130.0711 - val_accuracy: 0.0000e+00\n",
      "Epoch 5079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0175 - accuracy: 0.0000e+00 - val_loss: 134.2044 - val_accuracy: 0.0000e+00\n",
      "Epoch 5080/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0294 - accuracy: 0.0156 - val_loss: 134.3121 - val_accuracy: 0.0000e+00\n",
      "Epoch 5081/10000\n",
      "64/64 [==============================] - 0s 192us/step - loss: 21.7568 - accuracy: 0.0156 - val_loss: 131.2108 - val_accuracy: 0.0588\n",
      "Epoch 5082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0922 - accuracy: 0.0000e+00 - val_loss: 118.9898 - val_accuracy: 0.0000e+00\n",
      "Epoch 5083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2099 - accuracy: 0.0000e+00 - val_loss: 109.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2190 - accuracy: 0.0000e+00 - val_loss: 113.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8796 - accuracy: 0.0156 - val_loss: 129.9438 - val_accuracy: 0.0000e+00\n",
      "Epoch 5086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7054 - accuracy: 0.0000e+00 - val_loss: 146.9051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8391 - accuracy: 0.0000e+00 - val_loss: 151.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 5088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9883 - accuracy: 0.0000e+00 - val_loss: 140.2041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8912 - accuracy: 0.0000e+00 - val_loss: 127.3663 - val_accuracy: 0.0588\n",
      "Epoch 5090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2475 - accuracy: 0.0000e+00 - val_loss: 116.0192 - val_accuracy: 0.0588\n",
      "Epoch 5091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8853 - accuracy: 0.0000e+00 - val_loss: 108.9296 - val_accuracy: 0.0588\n",
      "Epoch 5092/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2351 - accuracy: 0.0000e+00 - val_loss: 112.9271 - val_accuracy: 0.0588\n",
      "Epoch 5093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8765 - accuracy: 0.0000e+00 - val_loss: 124.1749 - val_accuracy: 0.0588\n",
      "Epoch 5094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6759 - accuracy: 0.0000e+00 - val_loss: 126.1770 - val_accuracy: 0.0588\n",
      "Epoch 5095/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.0843 - accuracy: 0.0000e+00 - val_loss: 130.4027 - val_accuracy: 0.0588\n",
      "Epoch 5096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7032 - accuracy: 0.0000e+00 - val_loss: 132.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 5097/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 16.8444 - accuracy: 0.0000e+00 - val_loss: 129.5016 - val_accuracy: 0.0000e+00\n",
      "Epoch 5098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.6237 - accuracy: 0.0000e+00 - val_loss: 129.2077 - val_accuracy: 0.0588\n",
      "Epoch 5099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7432 - accuracy: 0.0156 - val_loss: 126.3721 - val_accuracy: 0.0588\n",
      "Epoch 5100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3241 - accuracy: 0.0156 - val_loss: 124.8450 - val_accuracy: 0.1176\n",
      "Epoch 5101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5065 - accuracy: 0.0000e+00 - val_loss: 126.2924 - val_accuracy: 0.0588\n",
      "Epoch 5102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2835 - accuracy: 0.0000e+00 - val_loss: 127.2842 - val_accuracy: 0.0588\n",
      "Epoch 5103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7290 - accuracy: 0.0156 - val_loss: 130.4154 - val_accuracy: 0.0588\n",
      "Epoch 5104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9169 - accuracy: 0.0000e+00 - val_loss: 124.1773 - val_accuracy: 0.0588\n",
      "Epoch 5105/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8557 - accuracy: 0.0000e+00 - val_loss: 120.2348 - val_accuracy: 0.0588\n",
      "Epoch 5106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2905 - accuracy: 0.0156 - val_loss: 122.4195 - val_accuracy: 0.0588\n",
      "Epoch 5107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2307 - accuracy: 0.0000e+00 - val_loss: 124.5643 - val_accuracy: 0.0588\n",
      "Epoch 5108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5959 - accuracy: 0.0000e+00 - val_loss: 126.8778 - val_accuracy: 0.0588\n",
      "Epoch 5109/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6923 - accuracy: 0.0156 - val_loss: 127.8305 - val_accuracy: 0.0588\n",
      "Epoch 5110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3117 - accuracy: 0.0000e+00 - val_loss: 128.4528 - val_accuracy: 0.0588\n",
      "Epoch 5111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.8105 - accuracy: 0.0000e+00 - val_loss: 130.6227 - val_accuracy: 0.0588\n",
      "Epoch 5112/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 31.8418 - accuracy: 0.0156 - val_loss: 133.7731 - val_accuracy: 0.0588\n",
      "Epoch 5113/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5421 - accuracy: 0.0156 - val_loss: 129.3599 - val_accuracy: 0.0588\n",
      "Epoch 5114/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6601 - accuracy: 0.0000e+00 - val_loss: 123.1591 - val_accuracy: 0.0588\n",
      "Epoch 5115/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9239 - accuracy: 0.0312 - val_loss: 118.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5341 - accuracy: 0.0312 - val_loss: 115.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4304 - accuracy: 0.0000e+00 - val_loss: 116.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 5118/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.2266 - accuracy: 0.0156 - val_loss: 122.4815 - val_accuracy: 0.0000e+00\n",
      "Epoch 5119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.5487 - accuracy: 0.0000e+00 - val_loss: 127.3691 - val_accuracy: 0.0000e+00\n",
      "Epoch 5120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8473 - accuracy: 0.0000e+00 - val_loss: 132.0536 - val_accuracy: 0.0588\n",
      "Epoch 5121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0215 - accuracy: 0.0156 - val_loss: 134.7985 - val_accuracy: 0.0588\n",
      "Epoch 5122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9194 - accuracy: 0.0312 - val_loss: 132.4414 - val_accuracy: 0.0588\n",
      "Epoch 5123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9051 - accuracy: 0.0000e+00 - val_loss: 135.0977 - val_accuracy: 0.0588\n",
      "Epoch 5124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8578 - accuracy: 0.0156 - val_loss: 133.8418 - val_accuracy: 0.0588\n",
      "Epoch 5125/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0194 - accuracy: 0.0312 - val_loss: 125.4687 - val_accuracy: 0.0588\n",
      "Epoch 5126/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6364 - accuracy: 0.0000e+00 - val_loss: 120.7464 - val_accuracy: 0.0588\n",
      "Epoch 5127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.1823 - accuracy: 0.0000e+00 - val_loss: 123.1283 - val_accuracy: 0.0000e+00\n",
      "Epoch 5128/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5223 - accuracy: 0.0156 - val_loss: 127.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 5129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7012 - accuracy: 0.0000e+00 - val_loss: 122.5626 - val_accuracy: 0.0000e+00\n",
      "Epoch 5130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3738 - accuracy: 0.0000e+00 - val_loss: 113.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4643 - accuracy: 0.0156 - val_loss: 106.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5132/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8909 - accuracy: 0.0156 - val_loss: 103.5350 - val_accuracy: 0.0000e+00\n",
      "Epoch 5133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9224 - accuracy: 0.0000e+00 - val_loss: 108.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 5134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3912 - accuracy: 0.0312 - val_loss: 128.8589 - val_accuracy: 0.0000e+00\n",
      "Epoch 5135/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 30.3091 - accuracy: 0.0000e+0 - 0s 102us/step - loss: 29.0674 - accuracy: 0.0000e+00 - val_loss: 146.9884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8376 - accuracy: 0.0000e+00 - val_loss: 142.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 5137/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 49.2717 - accuracy: 0.0000e+00 - val_loss: 127.1792 - val_accuracy: 0.0000e+00\n",
      "Epoch 5138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4184 - accuracy: 0.0000e+00 - val_loss: 114.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 5139/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 20.2972 - accuracy: 0.0000e+00 - val_loss: 108.3654 - val_accuracy: 0.0000e+00\n",
      "Epoch 5140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2279 - accuracy: 0.0312 - val_loss: 111.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 5141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6328 - accuracy: 0.0000e+00 - val_loss: 114.2821 - val_accuracy: 0.0000e+00\n",
      "Epoch 5142/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5815 - accuracy: 0.0156 - val_loss: 122.3666 - val_accuracy: 0.0000e+00\n",
      "Epoch 5143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2183 - accuracy: 0.0000e+00 - val_loss: 125.0499 - val_accuracy: 0.0000e+00\n",
      "Epoch 5144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9738 - accuracy: 0.0000e+00 - val_loss: 119.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 5145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2966 - accuracy: 0.0000e+00 - val_loss: 108.7337 - val_accuracy: 0.0588\n",
      "Epoch 5146/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8507 - accuracy: 0.0000e+00 - val_loss: 101.2826 - val_accuracy: 0.0588\n",
      "Epoch 5147/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 31.5192 - accuracy: 0.0000e+00 - val_loss: 107.0747 - val_accuracy: 0.0588\n",
      "Epoch 5148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.8188 - accuracy: 0.0000e+00 - val_loss: 139.7275 - val_accuracy: 0.0588\n",
      "Epoch 5149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.1449 - accuracy: 0.0000e+00 - val_loss: 150.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 5150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5455 - accuracy: 0.0000e+00 - val_loss: 132.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2328 - accuracy: 0.0000e+00 - val_loss: 121.9627 - val_accuracy: 0.1176\n",
      "Epoch 5152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8905 - accuracy: 0.0000e+00 - val_loss: 117.0729 - val_accuracy: 0.0588\n",
      "Epoch 5153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9968 - accuracy: 0.0156 - val_loss: 118.6366 - val_accuracy: 0.0588\n",
      "Epoch 5154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5385 - accuracy: 0.0156 - val_loss: 127.2154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5155/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.1181 - accuracy: 0.0156 - val_loss: 134.0459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.2097 - accuracy: 0.0000e+00 - val_loss: 138.3056 - val_accuracy: 0.0000e+00\n",
      "Epoch 5157/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4850 - accuracy: 0.0000e+00 - val_loss: 136.8978 - val_accuracy: 0.0000e+00\n",
      "Epoch 5158/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 32.2921 - accuracy: 0.0000e+00 - val_loss: 135.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 5159/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.7119 - accuracy: 0.0000e+00 - val_loss: 144.1237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0872 - accuracy: 0.0000e+00 - val_loss: 147.1455 - val_accuracy: 0.0000e+00\n",
      "Epoch 5161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2915 - accuracy: 0.0156 - val_loss: 137.9619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.4033 - accuracy: 0.0000e+00 - val_loss: 131.8343 - val_accuracy: 0.0000e+00\n",
      "Epoch 5163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.5637 - accuracy: 0.0156 - val_loss: 140.6540 - val_accuracy: 0.0000e+00\n",
      "Epoch 5164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7263 - accuracy: 0.0000e+00 - val_loss: 140.2944 - val_accuracy: 0.0000e+00\n",
      "Epoch 5165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5678 - accuracy: 0.0156 - val_loss: 134.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6883 - accuracy: 0.0156 - val_loss: 126.1032 - val_accuracy: 0.0000e+00\n",
      "Epoch 5167/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.4392 - accuracy: 0.0000e+00 - val_loss: 122.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 5168/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 32.6634 - accuracy: 0.0000e+00 - val_loss: 124.4276 - val_accuracy: 0.0000e+00\n",
      "Epoch 5169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.1021 - accuracy: 0.0000e+00 - val_loss: 128.4706 - val_accuracy: 0.0000e+00\n",
      "Epoch 5170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9757 - accuracy: 0.0000e+00 - val_loss: 128.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 5171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8881 - accuracy: 0.0156 - val_loss: 126.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 5172/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 22.1224 - accuracy: 0.0312 - val_loss: 121.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 5173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5404 - accuracy: 0.0156 - val_loss: 120.5020 - val_accuracy: 0.0000e+00\n",
      "Epoch 5174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6241 - accuracy: 0.0156 - val_loss: 121.6237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7332 - accuracy: 0.0156 - val_loss: 124.9237 - val_accuracy: 0.0000e+00\n",
      "Epoch 5176/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6334 - accuracy: 0.0156 - val_loss: 123.2403 - val_accuracy: 0.0000e+00\n",
      "Epoch 5177/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.5062 - accuracy: 0.0156 - val_loss: 124.4174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3085 - accuracy: 0.0000e+00 - val_loss: 126.4903 - val_accuracy: 0.0000e+00\n",
      "Epoch 5179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2764 - accuracy: 0.0000e+00 - val_loss: 127.8918 - val_accuracy: 0.0000e+00\n",
      "Epoch 5180/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 28.0637 - accuracy: 0.0156 - val_loss: 128.0212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5181/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 44.1668 - accuracy: 0.0000e+00 - val_loss: 132.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 5182/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 30.8001 - accuracy: 0.0000e+00 - val_loss: 138.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 5183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6677 - accuracy: 0.0000e+00 - val_loss: 143.7113 - val_accuracy: 0.0000e+00\n",
      "Epoch 5184/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1832 - accuracy: 0.0000e+00 - val_loss: 138.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1499 - accuracy: 0.0312 - val_loss: 132.2052 - val_accuracy: 0.0000e+00\n",
      "Epoch 5186/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4177 - accuracy: 0.0000e+00 - val_loss: 126.3126 - val_accuracy: 0.0000e+00\n",
      "Epoch 5187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5935 - accuracy: 0.0000e+00 - val_loss: 123.1637 - val_accuracy: 0.0000e+00\n",
      "Epoch 5188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7731 - accuracy: 0.0156 - val_loss: 127.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 5189/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6437 - accuracy: 0.0000e+00 - val_loss: 137.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5190/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0419 - accuracy: 0.0000e+00 - val_loss: 137.2723 - val_accuracy: 0.0000e+00\n",
      "Epoch 5191/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 26.4432 - accuracy: 0.0000e+00 - val_loss: 134.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 5192/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 21.0325 - accuracy: 0.0000e+00 - val_loss: 129.7608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6079 - accuracy: 0.0000e+00 - val_loss: 130.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 5194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4829 - accuracy: 0.0000e+00 - val_loss: 127.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8693 - accuracy: 0.0312 - val_loss: 120.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 5196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3888 - accuracy: 0.0000e+00 - val_loss: 114.3700 - val_accuracy: 0.0000e+00\n",
      "Epoch 5197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4909 - accuracy: 0.0312 - val_loss: 111.8346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5198/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.4807 - accuracy: 0.0000e+00 - val_loss: 119.3736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0848 - accuracy: 0.0000e+00 - val_loss: 122.7736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8273 - accuracy: 0.0312 - val_loss: 125.9376 - val_accuracy: 0.0000e+00\n",
      "Epoch 5201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7887 - accuracy: 0.0000e+00 - val_loss: 127.5709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5202/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 31.8924 - accuracy: 0.0000e+00 - val_loss: 126.7264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7746 - accuracy: 0.0469 - val_loss: 125.9491 - val_accuracy: 0.0588\n",
      "Epoch 5204/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 34.7307 - accuracy: 0.0156 - val_loss: 125.5017 - val_accuracy: 0.0000e+00\n",
      "Epoch 5205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7665 - accuracy: 0.0000e+00 - val_loss: 123.4485 - val_accuracy: 0.0000e+00\n",
      "Epoch 5206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1857 - accuracy: 0.0000e+00 - val_loss: 119.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 5207/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1783 - accuracy: 0.0000e+00 - val_loss: 106.6097 - val_accuracy: 0.0000e+00\n",
      "Epoch 5208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.7465 - accuracy: 0.0000e+00 - val_loss: 102.0013 - val_accuracy: 0.0000e+00\n",
      "Epoch 5209/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.5206 - accuracy: 0.0156 - val_loss: 112.9410 - val_accuracy: 0.0000e+00\n",
      "Epoch 5210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7175 - accuracy: 0.0312 - val_loss: 133.3412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3794 - accuracy: 0.0156 - val_loss: 137.5593 - val_accuracy: 0.0588\n",
      "Epoch 5212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2204 - accuracy: 0.0000e+00 - val_loss: 134.1844 - val_accuracy: 0.0588\n",
      "Epoch 5213/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5248 - accuracy: 0.0156 - val_loss: 132.4024 - val_accuracy: 0.0588\n",
      "Epoch 5214/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 30.9068 - accuracy: 0.0469 - val_loss: 131.8937 - val_accuracy: 0.0588\n",
      "Epoch 5215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8435 - accuracy: 0.0000e+00 - val_loss: 135.2794 - val_accuracy: 0.0588\n",
      "Epoch 5216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4397 - accuracy: 0.0000e+00 - val_loss: 139.8160 - val_accuracy: 0.0588\n",
      "Epoch 5217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6936 - accuracy: 0.0000e+00 - val_loss: 139.4723 - val_accuracy: 0.0588\n",
      "Epoch 5218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9542 - accuracy: 0.0000e+00 - val_loss: 129.1225 - val_accuracy: 0.0588\n",
      "Epoch 5219/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6624 - accuracy: 0.0156 - val_loss: 120.8217 - val_accuracy: 0.0588\n",
      "Epoch 5220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1698 - accuracy: 0.0312 - val_loss: 117.4123 - val_accuracy: 0.0588\n",
      "Epoch 5221/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4503 - accuracy: 0.0000e+00 - val_loss: 117.2546 - val_accuracy: 0.0588\n",
      "Epoch 5222/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1956 - accuracy: 0.0000e+00 - val_loss: 111.4763 - val_accuracy: 0.0000e+00\n",
      "Epoch 5223/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7019 - accuracy: 0.0000e+00 - val_loss: 109.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 5224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1123 - accuracy: 0.0156 - val_loss: 114.1291 - val_accuracy: 0.0000e+00\n",
      "Epoch 5225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6310 - accuracy: 0.0000e+00 - val_loss: 123.6453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5226/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2350 - accuracy: 0.0000e+00 - val_loss: 134.3523 - val_accuracy: 0.0000e+00\n",
      "Epoch 5227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5380 - accuracy: 0.0000e+00 - val_loss: 142.0720 - val_accuracy: 0.0000e+00\n",
      "Epoch 5228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5685 - accuracy: 0.0156 - val_loss: 143.9751 - val_accuracy: 0.0000e+00\n",
      "Epoch 5229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2939 - accuracy: 0.0156 - val_loss: 139.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1277 - accuracy: 0.0000e+00 - val_loss: 132.8391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0985 - accuracy: 0.0156 - val_loss: 127.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 5232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1652 - accuracy: 0.0000e+00 - val_loss: 127.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4673 - accuracy: 0.0000e+00 - val_loss: 131.0901 - val_accuracy: 0.0000e+00\n",
      "Epoch 5234/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6718 - accuracy: 0.0000e+00 - val_loss: 127.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 5235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3831 - accuracy: 0.0156 - val_loss: 120.5639 - val_accuracy: 0.0588\n",
      "Epoch 5236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4981 - accuracy: 0.0156 - val_loss: 116.9414 - val_accuracy: 0.0588\n",
      "Epoch 5237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0660 - accuracy: 0.0000e+00 - val_loss: 112.5179 - val_accuracy: 0.1176\n",
      "Epoch 5238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1828 - accuracy: 0.0156 - val_loss: 109.2510 - val_accuracy: 0.0588\n",
      "Epoch 5239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3761 - accuracy: 0.0312 - val_loss: 112.3896 - val_accuracy: 0.0588\n",
      "Epoch 5240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7071 - accuracy: 0.0000e+00 - val_loss: 125.6951 - val_accuracy: 0.0588\n",
      "Epoch 5241/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0111 - accuracy: 0.0156 - val_loss: 142.3996 - val_accuracy: 0.0588\n",
      "Epoch 5242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7161 - accuracy: 0.0156 - val_loss: 152.7144 - val_accuracy: 0.0588\n",
      "Epoch 5243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6438 - accuracy: 0.0469 - val_loss: 150.8363 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4347 - accuracy: 0.0156 - val_loss: 146.2566 - val_accuracy: 0.0588\n",
      "Epoch 5245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9944 - accuracy: 0.0000e+00 - val_loss: 142.1284 - val_accuracy: 0.0000e+00\n",
      "Epoch 5246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6683 - accuracy: 0.0000e+00 - val_loss: 137.0933 - val_accuracy: 0.0000e+00\n",
      "Epoch 5247/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9726 - accuracy: 0.0000e+00 - val_loss: 135.6394 - val_accuracy: 0.0588\n",
      "Epoch 5248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7702 - accuracy: 0.0000e+00 - val_loss: 128.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2366 - accuracy: 0.0000e+00 - val_loss: 119.5940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1130 - accuracy: 0.0000e+00 - val_loss: 119.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 5251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6978 - accuracy: 0.0000e+00 - val_loss: 129.8661 - val_accuracy: 0.0000e+00\n",
      "Epoch 5252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7326 - accuracy: 0.0156 - val_loss: 133.0697 - val_accuracy: 0.0588\n",
      "Epoch 5253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0476 - accuracy: 0.0000e+00 - val_loss: 127.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8561 - accuracy: 0.0000e+00 - val_loss: 124.1233 - val_accuracy: 0.0000e+00\n",
      "Epoch 5255/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6759 - accuracy: 0.0156 - val_loss: 118.6198 - val_accuracy: 0.0000e+00\n",
      "Epoch 5256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6165 - accuracy: 0.0469 - val_loss: 114.7847 - val_accuracy: 0.0000e+00\n",
      "Epoch 5257/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 39.9681 - accuracy: 0.0156 - val_loss: 124.8765 - val_accuracy: 0.0000e+00\n",
      "Epoch 5258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7115 - accuracy: 0.0156 - val_loss: 134.3378 - val_accuracy: 0.0588\n",
      "Epoch 5259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9831 - accuracy: 0.0000e+00 - val_loss: 126.4705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6322 - accuracy: 0.0000e+00 - val_loss: 115.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 5261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9736 - accuracy: 0.0000e+00 - val_loss: 113.3302 - val_accuracy: 0.0000e+00\n",
      "Epoch 5262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3641 - accuracy: 0.0000e+00 - val_loss: 116.1889 - val_accuracy: 0.0000e+00\n",
      "Epoch 5263/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7318 - accuracy: 0.0312 - val_loss: 122.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 5264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4534 - accuracy: 0.0156 - val_loss: 126.1719 - val_accuracy: 0.0588\n",
      "Epoch 5265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1271 - accuracy: 0.0000e+00 - val_loss: 130.1533 - val_accuracy: 0.0588\n",
      "Epoch 5266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0512 - accuracy: 0.0000e+00 - val_loss: 131.6356 - val_accuracy: 0.0588\n",
      "Epoch 5267/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0096 - accuracy: 0.0156 - val_loss: 138.1840 - val_accuracy: 0.0588\n",
      "Epoch 5268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4221 - accuracy: 0.0156 - val_loss: 136.2006 - val_accuracy: 0.0588\n",
      "Epoch 5269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4077 - accuracy: 0.0000e+00 - val_loss: 129.0468 - val_accuracy: 0.0588\n",
      "Epoch 5270/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0065 - accuracy: 0.0156 - val_loss: 121.5791 - val_accuracy: 0.1176\n",
      "Epoch 5271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.6262 - accuracy: 0.0000e+00 - val_loss: 120.7011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5272/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5345 - accuracy: 0.0000e+00 - val_loss: 134.1313 - val_accuracy: 0.0000e+00\n",
      "Epoch 5273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5058 - accuracy: 0.0000e+00 - val_loss: 147.6005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5274/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6945 - accuracy: 0.0156 - val_loss: 150.2164 - val_accuracy: 0.0000e+00\n",
      "Epoch 5275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6870 - accuracy: 0.0156 - val_loss: 144.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7020 - accuracy: 0.0000e+00 - val_loss: 132.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 5277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.8007 - accuracy: 0.0000e+00 - val_loss: 121.2591 - val_accuracy: 0.0000e+00\n",
      "Epoch 5278/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7207 - accuracy: 0.0000e+00 - val_loss: 118.5623 - val_accuracy: 0.0000e+00\n",
      "Epoch 5279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5926 - accuracy: 0.0000e+00 - val_loss: 130.6801 - val_accuracy: 0.0000e+00\n",
      "Epoch 5280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.2945 - accuracy: 0.0000e+00 - val_loss: 146.3721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5281/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.3865 - accuracy: 0.0312 - val_loss: 143.9652 - val_accuracy: 0.0000e+00\n",
      "Epoch 5282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2980 - accuracy: 0.0156 - val_loss: 134.8070 - val_accuracy: 0.0000e+00\n",
      "Epoch 5283/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1218 - accuracy: 0.0000e+00 - val_loss: 125.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7969 - accuracy: 0.0000e+00 - val_loss: 124.8367 - val_accuracy: 0.0000e+00\n",
      "Epoch 5285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1440 - accuracy: 0.0000e+00 - val_loss: 124.6197 - val_accuracy: 0.0000e+00\n",
      "Epoch 5286/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6994 - accuracy: 0.0312 - val_loss: 132.6030 - val_accuracy: 0.0000e+00\n",
      "Epoch 5287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6105 - accuracy: 0.0156 - val_loss: 142.4543 - val_accuracy: 0.0588\n",
      "Epoch 5288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3309 - accuracy: 0.0156 - val_loss: 144.6058 - val_accuracy: 0.0588\n",
      "Epoch 5289/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7505 - accuracy: 0.0625 - val_loss: 132.3165 - val_accuracy: 0.0588\n",
      "Epoch 5290/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9692 - accuracy: 0.0000e+00 - val_loss: 124.8355 - val_accuracy: 0.0000e+00\n",
      "Epoch 5291/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 23.6325 - accuracy: 0.0156 - val_loss: 124.9150 - val_accuracy: 0.0588\n",
      "Epoch 5292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1998 - accuracy: 0.0000e+00 - val_loss: 125.9162 - val_accuracy: 0.0588\n",
      "Epoch 5293/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0955 - accuracy: 0.0000e+00 - val_loss: 128.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 5294/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 29.5508 - accuracy: 0.0000e+00 - val_loss: 126.5296 - val_accuracy: 0.0000e+00\n",
      "Epoch 5295/10000\n",
      "64/64 [==============================] - 0s 453us/step - loss: 28.5393 - accuracy: 0.0000e+00 - val_loss: 115.4077 - val_accuracy: 0.0000e+00\n",
      "Epoch 5296/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4136 - accuracy: 0.0156 - val_loss: 116.9982 - val_accuracy: 0.0000e+00\n",
      "Epoch 5297/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.3562 - accuracy: 0.0000e+00 - val_loss: 117.8073 - val_accuracy: 0.0000e+00\n",
      "Epoch 5298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5438 - accuracy: 0.0312 - val_loss: 126.1650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9870 - accuracy: 0.0000e+00 - val_loss: 129.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4020 - accuracy: 0.0000e+00 - val_loss: 131.8086 - val_accuracy: 0.0000e+00\n",
      "Epoch 5301/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1178 - accuracy: 0.0000e+00 - val_loss: 133.8759 - val_accuracy: 0.0588\n",
      "Epoch 5302/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9096 - accuracy: 0.0156 - val_loss: 134.0936 - val_accuracy: 0.0000e+00\n",
      "Epoch 5303/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 43.5217 - accuracy: 0.0156 - val_loss: 129.1530 - val_accuracy: 0.0000e+00\n",
      "Epoch 5304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.5991 - accuracy: 0.0000e+00 - val_loss: 125.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 5305/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.4317 - accuracy: 0.0000e+00 - val_loss: 120.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 5306/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 35.1623 - accuracy: 0.0000e+00 - val_loss: 118.6548 - val_accuracy: 0.0000e+00\n",
      "Epoch 5307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6112 - accuracy: 0.0000e+00 - val_loss: 117.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9737 - accuracy: 0.0156 - val_loss: 119.8433 - val_accuracy: 0.0000e+00\n",
      "Epoch 5309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7585 - accuracy: 0.0000e+00 - val_loss: 127.1858 - val_accuracy: 0.0000e+00\n",
      "Epoch 5310/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 30.5842 - accuracy: 0.0000e+00 - val_loss: 133.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 5311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4544 - accuracy: 0.0000e+00 - val_loss: 140.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 5312/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 31.4408 - accuracy: 0.0000e+00 - val_loss: 147.6668 - val_accuracy: 0.0000e+00\n",
      "Epoch 5313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1863 - accuracy: 0.0000e+00 - val_loss: 149.6812 - val_accuracy: 0.0000e+00\n",
      "Epoch 5314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3266 - accuracy: 0.0000e+00 - val_loss: 141.4211 - val_accuracy: 0.0000e+00\n",
      "Epoch 5315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1056 - accuracy: 0.0000e+00 - val_loss: 133.0492 - val_accuracy: 0.0000e+00\n",
      "Epoch 5316/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 31.7379 - accuracy: 0.0312 - val_loss: 123.0505 - val_accuracy: 0.0588\n",
      "Epoch 5317/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3000 - accuracy: 0.0156 - val_loss: 123.4018 - val_accuracy: 0.0588\n",
      "Epoch 5318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9437 - accuracy: 0.0000e+00 - val_loss: 131.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 5319/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 36.6607 - accuracy: 0.0312 - val_loss: 139.8359 - val_accuracy: 0.0000e+00\n",
      "Epoch 5320/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5238 - accuracy: 0.0469 - val_loss: 143.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 5321/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.4773 - accuracy: 0.0000e+00 - val_loss: 135.7157 - val_accuracy: 0.0000e+00\n",
      "Epoch 5322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2679 - accuracy: 0.0000e+00 - val_loss: 128.0022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5662 - accuracy: 0.0000e+00 - val_loss: 124.9453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1847 - accuracy: 0.0156 - val_loss: 130.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 5325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1430 - accuracy: 0.0156 - val_loss: 138.2021 - val_accuracy: 0.0588\n",
      "Epoch 5326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8470 - accuracy: 0.0000e+00 - val_loss: 144.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 5327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4968 - accuracy: 0.0156 - val_loss: 147.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.8376 - accuracy: 0.0000e+00 - val_loss: 141.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5329/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 23.7259 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 36.0559 - accuracy: 0.0000e+00 - val_loss: 131.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 5330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2672 - accuracy: 0.0156 - val_loss: 123.3218 - val_accuracy: 0.0000e+00\n",
      "Epoch 5331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6549 - accuracy: 0.0000e+00 - val_loss: 120.9557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8449 - accuracy: 0.0312 - val_loss: 125.3307 - val_accuracy: 0.0000e+00\n",
      "Epoch 5333/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 37.8043 - accuracy: 0.0156 - val_loss: 129.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5334/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 42.0358 - accuracy: 0.0156 - val_loss: 138.3258 - val_accuracy: 0.0000e+00\n",
      "Epoch 5335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1909 - accuracy: 0.0000e+00 - val_loss: 140.9896 - val_accuracy: 0.0000e+00\n",
      "Epoch 5336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4727 - accuracy: 0.0000e+00 - val_loss: 136.4852 - val_accuracy: 0.0000e+00\n",
      "Epoch 5337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2783 - accuracy: 0.0000e+00 - val_loss: 128.9817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5338/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 34.0338 - accuracy: 0.0000e+00 - val_loss: 126.9950 - val_accuracy: 0.0000e+00\n",
      "Epoch 5339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3287 - accuracy: 0.0156 - val_loss: 129.7961 - val_accuracy: 0.0000e+00\n",
      "Epoch 5340/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8547 - accuracy: 0.0156 - val_loss: 124.8696 - val_accuracy: 0.0588\n",
      "Epoch 5341/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3413 - accuracy: 0.0000e+00 - val_loss: 120.2388 - val_accuracy: 0.0588\n",
      "Epoch 5342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6367 - accuracy: 0.0312 - val_loss: 119.5937 - val_accuracy: 0.0588\n",
      "Epoch 5343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2614 - accuracy: 0.0156 - val_loss: 117.1129 - val_accuracy: 0.0000e+00\n",
      "Epoch 5344/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 24.5230 - accuracy: 0.0312 - val_loss: 118.6286 - val_accuracy: 0.0000e+00\n",
      "Epoch 5345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4934 - accuracy: 0.0000e+00 - val_loss: 129.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 5346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.4751 - accuracy: 0.0156 - val_loss: 141.2828 - val_accuracy: 0.0000e+00\n",
      "Epoch 5347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0020 - accuracy: 0.0000e+00 - val_loss: 133.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 5348/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 35.3921 - accuracy: 0.0156 - val_loss: 127.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 5349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2035 - accuracy: 0.0156 - val_loss: 125.7610 - val_accuracy: 0.0000e+00\n",
      "Epoch 5350/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 28.7625 - accuracy: 0.0156 - val_loss: 125.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 5351/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 39.5523 - accuracy: 0.031 - 0s 62us/step - loss: 44.1878 - accuracy: 0.0156 - val_loss: 130.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 5352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0934 - accuracy: 0.0000e+00 - val_loss: 140.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 5353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2818 - accuracy: 0.0000e+00 - val_loss: 155.3499 - val_accuracy: 0.0000e+00\n",
      "Epoch 5354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6665 - accuracy: 0.0156 - val_loss: 155.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 5355/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.7238 - accuracy: 0.0000e+00 - val_loss: 145.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1154 - accuracy: 0.0156 - val_loss: 127.1318 - val_accuracy: 0.0000e+00\n",
      "Epoch 5357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0871 - accuracy: 0.0156 - val_loss: 119.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 5358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.0844 - accuracy: 0.0000e+00 - val_loss: 121.4051 - val_accuracy: 0.0000e+00\n",
      "Epoch 5359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6727 - accuracy: 0.0000e+00 - val_loss: 125.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 5360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0580 - accuracy: 0.0000e+00 - val_loss: 121.8077 - val_accuracy: 0.0000e+00\n",
      "Epoch 5361/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5389 - accuracy: 0.0156 - val_loss: 123.1961 - val_accuracy: 0.0000e+00\n",
      "Epoch 5362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5394 - accuracy: 0.0156 - val_loss: 128.4187 - val_accuracy: 0.0000e+00\n",
      "Epoch 5363/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1782 - accuracy: 0.0000e+00 - val_loss: 132.6674 - val_accuracy: 0.0588\n",
      "Epoch 5364/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.8124 - accuracy: 0.0000e+00 - val_loss: 128.1431 - val_accuracy: 0.0588\n",
      "Epoch 5365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0261 - accuracy: 0.0156 - val_loss: 132.0577 - val_accuracy: 0.0588\n",
      "Epoch 5366/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 30.5735 - accuracy: 0.0156 - val_loss: 139.5980 - val_accuracy: 0.0588\n",
      "Epoch 5367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7517 - accuracy: 0.0000e+00 - val_loss: 143.7604 - val_accuracy: 0.0588\n",
      "Epoch 5368/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0377 - accuracy: 0.0000e+00 - val_loss: 131.6118 - val_accuracy: 0.0588\n",
      "Epoch 5369/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.5343 - accuracy: 0.0000e+00 - val_loss: 122.0679 - val_accuracy: 0.0588\n",
      "Epoch 5370/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 23.6256 - accuracy: 0.0312 - val_loss: 121.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 5371/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 42.2746 - accuracy: 0.0156 - val_loss: 129.3663 - val_accuracy: 0.0000e+00\n",
      "Epoch 5372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5267 - accuracy: 0.0000e+00 - val_loss: 132.0572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3367 - accuracy: 0.0000e+00 - val_loss: 128.2963 - val_accuracy: 0.0000e+00\n",
      "Epoch 5374/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8030 - accuracy: 0.0156 - val_loss: 123.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 5375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6445 - accuracy: 0.0156 - val_loss: 127.9720 - val_accuracy: 0.0000e+00\n",
      "Epoch 5376/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 18.1215 - accuracy: 0.0156 - val_loss: 132.9334 - val_accuracy: 0.0000e+00\n",
      "Epoch 5377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9360 - accuracy: 0.0000e+00 - val_loss: 131.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 5378/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 35.1928 - accuracy: 0.0000e+00 - val_loss: 134.3529 - val_accuracy: 0.0000e+00\n",
      "Epoch 5379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8264 - accuracy: 0.0000e+00 - val_loss: 139.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 5380/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2730 - accuracy: 0.0156 - val_loss: 141.4835 - val_accuracy: 0.0000e+00\n",
      "Epoch 5381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6358 - accuracy: 0.0000e+00 - val_loss: 136.3346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5382/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6896 - accuracy: 0.0156 - val_loss: 135.8009 - val_accuracy: 0.0000e+00\n",
      "Epoch 5383/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.3071 - accuracy: 0.0000e+00 - val_loss: 131.0984 - val_accuracy: 0.0000e+00\n",
      "Epoch 5384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3920 - accuracy: 0.0156 - val_loss: 123.2203 - val_accuracy: 0.0588\n",
      "Epoch 5385/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4256 - accuracy: 0.0156 - val_loss: 121.2540 - val_accuracy: 0.0588\n",
      "Epoch 5386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1455 - accuracy: 0.0000e+00 - val_loss: 132.7647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5387/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 26.2361 - accuracy: 0.0156 - val_loss: 140.7673 - val_accuracy: 0.0000e+00\n",
      "Epoch 5388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7645 - accuracy: 0.0312 - val_loss: 141.1670 - val_accuracy: 0.0000e+00\n",
      "Epoch 5389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0567 - accuracy: 0.0156 - val_loss: 138.9342 - val_accuracy: 0.0000e+00\n",
      "Epoch 5390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3593 - accuracy: 0.0156 - val_loss: 133.1303 - val_accuracy: 0.0000e+00\n",
      "Epoch 5391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6209 - accuracy: 0.0312 - val_loss: 125.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 5392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9100 - accuracy: 0.0000e+00 - val_loss: 120.7693 - val_accuracy: 0.0000e+00\n",
      "Epoch 5393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2685 - accuracy: 0.0156 - val_loss: 122.8763 - val_accuracy: 0.0000e+00\n",
      "Epoch 5394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1022 - accuracy: 0.0469 - val_loss: 122.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 5395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2808 - accuracy: 0.0000e+00 - val_loss: 125.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 5396/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8515 - accuracy: 0.0156 - val_loss: 123.5848 - val_accuracy: 0.0000e+00\n",
      "Epoch 5397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8457 - accuracy: 0.0000e+00 - val_loss: 130.0516 - val_accuracy: 0.0588\n",
      "Epoch 5398/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 25.9523 - accuracy: 0.0156 - val_loss: 132.4413 - val_accuracy: 0.0000e+00\n",
      "Epoch 5399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9743 - accuracy: 0.0156 - val_loss: 129.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 5400/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5231 - accuracy: 0.0312 - val_loss: 126.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 5401/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 48.4536 - accuracy: 0.0000e+00 - val_loss: 125.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 5402/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 26.0161 - accuracy: 0.0000e+00 - val_loss: 125.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 5403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1455 - accuracy: 0.0312 - val_loss: 128.8844 - val_accuracy: 0.0000e+00\n",
      "Epoch 5404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5031 - accuracy: 0.0000e+00 - val_loss: 135.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 5405/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 30.9564 - accuracy: 0.0156 - val_loss: 130.1017 - val_accuracy: 0.0000e+00\n",
      "Epoch 5406/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9841 - accuracy: 0.0000e+00 - val_loss: 119.9833 - val_accuracy: 0.0000e+00\n",
      "Epoch 5407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0152 - accuracy: 0.0000e+00 - val_loss: 127.4513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5408/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 17.9421 - accuracy: 0.0156 - val_loss: 133.6266 - val_accuracy: 0.0000e+00\n",
      "Epoch 5409/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 38.5689 - accuracy: 0.0156 - val_loss: 131.7216 - val_accuracy: 0.0000e+00\n",
      "Epoch 5410/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 43.9222 - accuracy: 0.0156 - val_loss: 130.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8271 - accuracy: 0.0156 - val_loss: 130.9622 - val_accuracy: 0.0588\n",
      "Epoch 5412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.9201 - accuracy: 0.0000e+00 - val_loss: 137.1941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5605 - accuracy: 0.0000e+00 - val_loss: 140.9693 - val_accuracy: 0.0000e+00\n",
      "Epoch 5414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9286 - accuracy: 0.0312 - val_loss: 144.7909 - val_accuracy: 0.0000e+00\n",
      "Epoch 5415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6506 - accuracy: 0.0000e+00 - val_loss: 145.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 5416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1664 - accuracy: 0.0000e+00 - val_loss: 134.3739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3320 - accuracy: 0.0156 - val_loss: 124.3111 - val_accuracy: 0.0000e+00\n",
      "Epoch 5418/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1708 - accuracy: 0.0000e+00 - val_loss: 121.1931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5419/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 21.3726 - accuracy: 0.0156 - val_loss: 119.1950 - val_accuracy: 0.0000e+00\n",
      "Epoch 5420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4338 - accuracy: 0.0000e+00 - val_loss: 117.2851 - val_accuracy: 0.0000e+00\n",
      "Epoch 5421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4104 - accuracy: 0.0312 - val_loss: 119.1125 - val_accuracy: 0.0588\n",
      "Epoch 5422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6479 - accuracy: 0.0000e+00 - val_loss: 117.4385 - val_accuracy: 0.0588\n",
      "Epoch 5423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7220 - accuracy: 0.0000e+00 - val_loss: 121.7658 - val_accuracy: 0.0588\n",
      "Epoch 5424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5455 - accuracy: 0.0000e+00 - val_loss: 133.7918 - val_accuracy: 0.0588\n",
      "Epoch 5425/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 29.3442 - accuracy: 0.0156 - val_loss: 142.6763 - val_accuracy: 0.0588\n",
      "Epoch 5426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3066 - accuracy: 0.0000e+00 - val_loss: 146.2336 - val_accuracy: 0.0588\n",
      "Epoch 5427/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.5765 - accuracy: 0.0000e+00 - val_loss: 147.3121 - val_accuracy: 0.0588\n",
      "Epoch 5428/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 34.0216 - accuracy: 0.0156 - val_loss: 146.9053 - val_accuracy: 0.0588\n",
      "Epoch 5429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3002 - accuracy: 0.0156 - val_loss: 133.8719 - val_accuracy: 0.0588\n",
      "Epoch 5430/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 19.3297 - accuracy: 0.0469 - val_loss: 125.3450 - val_accuracy: 0.0588\n",
      "Epoch 5431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7374 - accuracy: 0.0000e+00 - val_loss: 125.1441 - val_accuracy: 0.0000e+00\n",
      "Epoch 5432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1310 - accuracy: 0.0156 - val_loss: 129.4803 - val_accuracy: 0.0000e+00\n",
      "Epoch 5433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.1175 - accuracy: 0.0156 - val_loss: 129.4041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9496 - accuracy: 0.0156 - val_loss: 124.0658 - val_accuracy: 0.0000e+00\n",
      "Epoch 5435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.0423 - accuracy: 0.0000e+00 - val_loss: 114.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 5436/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9002 - accuracy: 0.0156 - val_loss: 119.6705 - val_accuracy: 0.0000e+00\n",
      "Epoch 5437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7185 - accuracy: 0.0000e+00 - val_loss: 130.5111 - val_accuracy: 0.0000e+00\n",
      "Epoch 5438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7347 - accuracy: 0.0000e+00 - val_loss: 139.6622 - val_accuracy: 0.0000e+00\n",
      "Epoch 5439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0509 - accuracy: 0.0156 - val_loss: 148.2384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5440/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.2523 - accuracy: 0.0156 - val_loss: 150.7968 - val_accuracy: 0.0000e+00\n",
      "Epoch 5441/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 29.4440 - accuracy: 0.0000e+00 - val_loss: 143.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 5442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3671 - accuracy: 0.0000e+00 - val_loss: 132.3741 - val_accuracy: 0.0000e+00\n",
      "Epoch 5443/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 30.5459 - accuracy: 0.0312 - val_loss: 121.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 5444/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.4515 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 32.9990 - accuracy: 0.0000e+00 - val_loss: 126.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 5445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.7609 - accuracy: 0.0000e+00 - val_loss: 130.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 5446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6224 - accuracy: 0.0000e+00 - val_loss: 123.7281 - val_accuracy: 0.0000e+00\n",
      "Epoch 5447/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1607 - accuracy: 0.0000e+00 - val_loss: 122.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 5448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6754 - accuracy: 0.0000e+00 - val_loss: 119.6087 - val_accuracy: 0.0000e+00\n",
      "Epoch 5449/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7424 - accuracy: 0.0000e+00 - val_loss: 116.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 5450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6252 - accuracy: 0.0156 - val_loss: 116.7721 - val_accuracy: 0.0000e+00\n",
      "Epoch 5451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8188 - accuracy: 0.0000e+00 - val_loss: 127.0619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5452/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 151us/step - loss: 32.4656 - accuracy: 0.0156 - val_loss: 136.5644 - val_accuracy: 0.0000e+00\n",
      "Epoch 5453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0031 - accuracy: 0.0000e+00 - val_loss: 142.5566 - val_accuracy: 0.0000e+00\n",
      "Epoch 5454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.6073 - accuracy: 0.0156 - val_loss: 143.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 5455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8713 - accuracy: 0.0156 - val_loss: 140.3900 - val_accuracy: 0.0000e+00\n",
      "Epoch 5456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7717 - accuracy: 0.0000e+00 - val_loss: 142.1134 - val_accuracy: 0.0000e+00\n",
      "Epoch 5457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5635 - accuracy: 0.0000e+00 - val_loss: 133.5260 - val_accuracy: 0.0000e+00\n",
      "Epoch 5458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0642 - accuracy: 0.0000e+00 - val_loss: 125.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 5459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 51.6444 - accuracy: 0.0156 - val_loss: 124.2562 - val_accuracy: 0.0000e+00\n",
      "Epoch 5460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5073 - accuracy: 0.0000e+00 - val_loss: 135.3400 - val_accuracy: 0.0000e+00\n",
      "Epoch 5461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5535 - accuracy: 0.0000e+00 - val_loss: 150.7284 - val_accuracy: 0.0000e+00\n",
      "Epoch 5462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8146 - accuracy: 0.0312 - val_loss: 157.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 5463/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 37.3408 - accuracy: 0.0000e+00 - val_loss: 158.1223 - val_accuracy: 0.0000e+00\n",
      "Epoch 5464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1706 - accuracy: 0.0312 - val_loss: 151.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.3324 - accuracy: 0.0312 - val_loss: 130.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5466/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3164 - accuracy: 0.0156 - val_loss: 116.0753 - val_accuracy: 0.0588\n",
      "Epoch 5467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1997 - accuracy: 0.0312 - val_loss: 117.4145 - val_accuracy: 0.0588\n",
      "Epoch 5468/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 27.7642 - accuracy: 0.0000e+00 - val_loss: 119.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3166 - accuracy: 0.0000e+00 - val_loss: 117.9388 - val_accuracy: 0.0000e+00\n",
      "Epoch 5470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4093 - accuracy: 0.0000e+00 - val_loss: 123.3014 - val_accuracy: 0.0000e+00\n",
      "Epoch 5471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6345 - accuracy: 0.0156 - val_loss: 127.3175 - val_accuracy: 0.0000e+00\n",
      "Epoch 5472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9795 - accuracy: 0.0156 - val_loss: 123.3430 - val_accuracy: 0.0000e+00\n",
      "Epoch 5473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9973 - accuracy: 0.0000e+00 - val_loss: 120.0687 - val_accuracy: 0.0000e+00\n",
      "Epoch 5474/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 32.5414 - accuracy: 0.0000e+00 - val_loss: 129.5381 - val_accuracy: 0.0588\n",
      "Epoch 5475/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1244 - accuracy: 0.0312 - val_loss: 134.9761 - val_accuracy: 0.0588\n",
      "Epoch 5476/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 42.2796 - accuracy: 0.0312 - val_loss: 136.5360 - val_accuracy: 0.0588\n",
      "Epoch 5477/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5338 - accuracy: 0.0156 - val_loss: 129.1989 - val_accuracy: 0.0588\n",
      "Epoch 5478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9253 - accuracy: 0.0000e+00 - val_loss: 123.8406 - val_accuracy: 0.0588\n",
      "Epoch 5479/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 40.6472 - accuracy: 0.0000e+00 - val_loss: 129.7437 - val_accuracy: 0.0000e+00\n",
      "Epoch 5480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9968 - accuracy: 0.0312 - val_loss: 138.2557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5481/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1023 - accuracy: 0.0000e+00 - val_loss: 128.5719 - val_accuracy: 0.0000e+00\n",
      "Epoch 5482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6799 - accuracy: 0.0156 - val_loss: 121.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 5483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4482 - accuracy: 0.0000e+00 - val_loss: 119.0902 - val_accuracy: 0.0588\n",
      "Epoch 5484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.6785 - accuracy: 0.0312 - val_loss: 122.6829 - val_accuracy: 0.0000e+00\n",
      "Epoch 5485/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8799 - accuracy: 0.0000e+00 - val_loss: 130.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 5486/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 22.5910 - accuracy: 0.0000e+00 - val_loss: 141.6895 - val_accuracy: 0.0000e+00\n",
      "Epoch 5487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3236 - accuracy: 0.0469 - val_loss: 143.6549 - val_accuracy: 0.0000e+00\n",
      "Epoch 5488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.5842 - accuracy: 0.0000e+00 - val_loss: 144.6452 - val_accuracy: 0.0588\n",
      "Epoch 5489/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 28.8460 - accuracy: 0.0000e+00 - val_loss: 141.3625 - val_accuracy: 0.0588\n",
      "Epoch 5490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4299 - accuracy: 0.0156 - val_loss: 134.5299 - val_accuracy: 0.0588\n",
      "Epoch 5491/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.7844 - accuracy: 0.0156 - val_loss: 132.2800 - val_accuracy: 0.0588\n",
      "Epoch 5492/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 26.9524 - accuracy: 0.0156 - val_loss: 134.1494 - val_accuracy: 0.0588\n",
      "Epoch 5493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4687 - accuracy: 0.0000e+00 - val_loss: 136.9075 - val_accuracy: 0.0588\n",
      "Epoch 5494/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2136 - accuracy: 0.0000e+00 - val_loss: 128.4189 - val_accuracy: 0.0588\n",
      "Epoch 5495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0314 - accuracy: 0.0000e+00 - val_loss: 116.8686 - val_accuracy: 0.0588\n",
      "Epoch 5496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4906 - accuracy: 0.0156 - val_loss: 109.4725 - val_accuracy: 0.0588\n",
      "Epoch 5497/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 34.4651 - accuracy: 0.0312 - val_loss: 109.7413 - val_accuracy: 0.0588\n",
      "Epoch 5498/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3029 - accuracy: 0.0000e+00 - val_loss: 117.1901 - val_accuracy: 0.0588\n",
      "Epoch 5499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0737 - accuracy: 0.0000e+00 - val_loss: 126.4212 - val_accuracy: 0.0588\n",
      "Epoch 5500/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 33.1286 - accuracy: 0.0156 - val_loss: 128.5812 - val_accuracy: 0.0000e+00\n",
      "Epoch 5501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4146 - accuracy: 0.0000e+00 - val_loss: 137.4755 - val_accuracy: 0.0000e+00\n",
      "Epoch 5502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9922 - accuracy: 0.0156 - val_loss: 140.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5503/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4146 - accuracy: 0.0156 - val_loss: 132.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 5504/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8689 - accuracy: 0.0000e+00 - val_loss: 124.3671 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5505/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1102 - accuracy: 0.0156 - val_loss: 122.1548 - val_accuracy: 0.0588\n",
      "Epoch 5506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6799 - accuracy: 0.0000e+00 - val_loss: 125.9915 - val_accuracy: 0.0588\n",
      "Epoch 5507/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4661 - accuracy: 0.0000e+00 - val_loss: 125.8051 - val_accuracy: 0.0588\n",
      "Epoch 5508/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.5011 - accuracy: 0.0000e+00 - val_loss: 126.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 5509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6492 - accuracy: 0.0312 - val_loss: 125.4055 - val_accuracy: 0.0000e+00\n",
      "Epoch 5510/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 40.1675 - accuracy: 0.0000e+00 - val_loss: 122.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 5511/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5246 - accuracy: 0.0000e+00 - val_loss: 128.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6706 - accuracy: 0.0000e+00 - val_loss: 134.8254 - val_accuracy: 0.0000e+00\n",
      "Epoch 5513/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2959 - accuracy: 0.0000e+00 - val_loss: 137.2407 - val_accuracy: 0.0000e+00\n",
      "Epoch 5514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3675 - accuracy: 0.0000e+00 - val_loss: 138.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 5515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6611 - accuracy: 0.0156 - val_loss: 144.6194 - val_accuracy: 0.0588\n",
      "Epoch 5516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0435 - accuracy: 0.0000e+00 - val_loss: 135.9518 - val_accuracy: 0.0588\n",
      "Epoch 5517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3268 - accuracy: 0.0000e+00 - val_loss: 117.5718 - val_accuracy: 0.0588\n",
      "Epoch 5518/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.4578 - accuracy: 0.0000e+00 - val_loss: 117.1231 - val_accuracy: 0.1176\n",
      "Epoch 5519/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 34.7942 - accuracy: 0.0000e+00 - val_loss: 124.5594 - val_accuracy: 0.1176\n",
      "Epoch 5520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5752 - accuracy: 0.0000e+00 - val_loss: 138.8026 - val_accuracy: 0.0588\n",
      "Epoch 5521/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9714 - accuracy: 0.0000e+00 - val_loss: 143.9232 - val_accuracy: 0.0588\n",
      "Epoch 5522/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5856 - accuracy: 0.0000e+00 - val_loss: 140.3849 - val_accuracy: 0.0588\n",
      "Epoch 5523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7958 - accuracy: 0.0156 - val_loss: 134.3818 - val_accuracy: 0.0588\n",
      "Epoch 5524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8822 - accuracy: 0.0156 - val_loss: 126.8789 - val_accuracy: 0.0588\n",
      "Epoch 5525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3821 - accuracy: 0.0000e+00 - val_loss: 120.9305 - val_accuracy: 0.0588\n",
      "Epoch 5526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9158 - accuracy: 0.0000e+00 - val_loss: 117.6798 - val_accuracy: 0.0588\n",
      "Epoch 5527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6845 - accuracy: 0.0000e+00 - val_loss: 119.7529 - val_accuracy: 0.0588\n",
      "Epoch 5528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7416 - accuracy: 0.0000e+00 - val_loss: 125.3562 - val_accuracy: 0.0588\n",
      "Epoch 5529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3738 - accuracy: 0.0000e+00 - val_loss: 131.2841 - val_accuracy: 0.0588\n",
      "Epoch 5530/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.6400 - accuracy: 0.0000e+00 - val_loss: 132.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 5531/10000\n",
      "64/64 [==============================] - 0s 55us/step - loss: 21.9013 - accuracy: 0.0000e+00 - val_loss: 138.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1855 - accuracy: 0.0156 - val_loss: 139.8169 - val_accuracy: 0.0000e+00\n",
      "Epoch 5533/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 23.9603 - accuracy: 0.0156 - val_loss: 132.9927 - val_accuracy: 0.0000e+00\n",
      "Epoch 5534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.3534 - accuracy: 0.0000e+00 - val_loss: 126.8859 - val_accuracy: 0.0000e+00\n",
      "Epoch 5535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6811 - accuracy: 0.0000e+00 - val_loss: 129.2523 - val_accuracy: 0.0000e+00\n",
      "Epoch 5536/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6151 - accuracy: 0.0000e+00 - val_loss: 133.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 5537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1475 - accuracy: 0.0156 - val_loss: 136.7272 - val_accuracy: 0.0000e+00\n",
      "Epoch 5538/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4895 - accuracy: 0.0000e+00 - val_loss: 136.7025 - val_accuracy: 0.0000e+00\n",
      "Epoch 5539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7613 - accuracy: 0.0156 - val_loss: 135.5513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8341 - accuracy: 0.0000e+00 - val_loss: 127.5831 - val_accuracy: 0.0588\n",
      "Epoch 5541/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.3216 - accuracy: 0.0156 - val_loss: 123.7849 - val_accuracy: 0.0588\n",
      "Epoch 5542/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 35.3729 - accuracy: 0.0000e+00 - val_loss: 124.3312 - val_accuracy: 0.0588\n",
      "Epoch 5543/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.3814 - accuracy: 0.0156 - val_loss: 129.5257 - val_accuracy: 0.0588\n",
      "Epoch 5544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3050 - accuracy: 0.0156 - val_loss: 135.5724 - val_accuracy: 0.0000e+00\n",
      "Epoch 5545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3077 - accuracy: 0.0312 - val_loss: 142.6810 - val_accuracy: 0.0000e+00\n",
      "Epoch 5546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6632 - accuracy: 0.0000e+00 - val_loss: 133.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 5547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1375 - accuracy: 0.0156 - val_loss: 119.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 5548/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6621 - accuracy: 0.0156 - val_loss: 108.4263 - val_accuracy: 0.0000e+00\n",
      "Epoch 5549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1777 - accuracy: 0.0000e+00 - val_loss: 108.3795 - val_accuracy: 0.0000e+00\n",
      "Epoch 5550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.4527 - accuracy: 0.0156 - val_loss: 115.7746 - val_accuracy: 0.0000e+00\n",
      "Epoch 5551/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 43.3356 - accuracy: 0.0000e+00 - val_loss: 123.7116 - val_accuracy: 0.0000e+00\n",
      "Epoch 5552/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 25.3992 - accuracy: 0.0156 - val_loss: 128.9318 - val_accuracy: 0.0000e+00\n",
      "Epoch 5553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6600 - accuracy: 0.0156 - val_loss: 127.4650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5554/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8605 - accuracy: 0.0000e+00 - val_loss: 126.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 5555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7896 - accuracy: 0.0000e+00 - val_loss: 122.5852 - val_accuracy: 0.0000e+00\n",
      "Epoch 5556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3443 - accuracy: 0.0000e+00 - val_loss: 121.7825 - val_accuracy: 0.0000e+00\n",
      "Epoch 5557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2803 - accuracy: 0.0000e+00 - val_loss: 122.3093 - val_accuracy: 0.0000e+00\n",
      "Epoch 5558/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8596 - accuracy: 0.0156 - val_loss: 133.4625 - val_accuracy: 0.0000e+00\n",
      "Epoch 5559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4814 - accuracy: 0.0156 - val_loss: 131.0414 - val_accuracy: 0.0000e+00\n",
      "Epoch 5560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0005 - accuracy: 0.0312 - val_loss: 122.5739 - val_accuracy: 0.0000e+00\n",
      "Epoch 5561/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3968 - accuracy: 0.0000e+00 - val_loss: 117.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8215 - accuracy: 0.0156 - val_loss: 116.4733 - val_accuracy: 0.0000e+00\n",
      "Epoch 5563/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 30.9250 - accuracy: 0.0000e+00 - val_loss: 119.5019 - val_accuracy: 0.0000e+00\n",
      "Epoch 5564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9145 - accuracy: 0.0156 - val_loss: 129.9850 - val_accuracy: 0.0000e+00\n",
      "Epoch 5565/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4504 - accuracy: 0.0156 - val_loss: 145.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 5566/10000\n",
      "64/64 [==============================] - 0s 56us/step - loss: 27.6577 - accuracy: 0.0156 - val_loss: 152.0598 - val_accuracy: 0.0000e+00\n",
      "Epoch 5567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3503 - accuracy: 0.0156 - val_loss: 150.7602 - val_accuracy: 0.0000e+00\n",
      "Epoch 5568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6754 - accuracy: 0.0469 - val_loss: 137.0090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6220 - accuracy: 0.0000e+00 - val_loss: 118.3472 - val_accuracy: 0.0000e+00\n",
      "Epoch 5570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4276 - accuracy: 0.0000e+00 - val_loss: 107.3226 - val_accuracy: 0.0588\n",
      "Epoch 5571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8638 - accuracy: 0.0000e+00 - val_loss: 109.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 5572/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9594 - accuracy: 0.0000e+00 - val_loss: 120.2992 - val_accuracy: 0.0000e+00\n",
      "Epoch 5573/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.6821 - accuracy: 0.0000e+00 - val_loss: 130.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 5574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8784 - accuracy: 0.0000e+00 - val_loss: 135.9059 - val_accuracy: 0.0000e+00\n",
      "Epoch 5575/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1029 - accuracy: 0.0156 - val_loss: 128.9923 - val_accuracy: 0.0000e+00\n",
      "Epoch 5576/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5796 - accuracy: 0.0312 - val_loss: 122.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 5577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9833 - accuracy: 0.0000e+00 - val_loss: 128.0863 - val_accuracy: 0.0000e+00\n",
      "Epoch 5578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4741 - accuracy: 0.0312 - val_loss: 135.4479 - val_accuracy: 0.0000e+00\n",
      "Epoch 5579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1202 - accuracy: 0.0000e+00 - val_loss: 145.6507 - val_accuracy: 0.0000e+00\n",
      "Epoch 5580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9202 - accuracy: 0.0000e+00 - val_loss: 147.9826 - val_accuracy: 0.0000e+00\n",
      "Epoch 5581/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3409 - accuracy: 0.0156 - val_loss: 136.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5582/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6950 - accuracy: 0.0312 - val_loss: 126.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 5583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4850 - accuracy: 0.0156 - val_loss: 123.6332 - val_accuracy: 0.0000e+00\n",
      "Epoch 5584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7346 - accuracy: 0.0156 - val_loss: 128.5648 - val_accuracy: 0.0000e+00\n",
      "Epoch 5585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5333 - accuracy: 0.0156 - val_loss: 131.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 5586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.9525 - accuracy: 0.0156 - val_loss: 135.4563 - val_accuracy: 0.0000e+00\n",
      "Epoch 5587/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7203 - accuracy: 0.0156 - val_loss: 128.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5588/10000\n",
      "64/64 [==============================] - 0s 68us/step - loss: 42.5660 - accuracy: 0.0312 - val_loss: 124.2187 - val_accuracy: 0.0000e+00\n",
      "Epoch 5589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4635 - accuracy: 0.0156 - val_loss: 123.6067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1533 - accuracy: 0.0156 - val_loss: 124.2130 - val_accuracy: 0.0000e+00\n",
      "Epoch 5591/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.9243 - accuracy: 0.0156 - val_loss: 121.1875 - val_accuracy: 0.0588\n",
      "Epoch 5592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3938 - accuracy: 0.0000e+00 - val_loss: 117.7288 - val_accuracy: 0.0000e+00\n",
      "Epoch 5593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2083 - accuracy: 0.0000e+00 - val_loss: 124.8878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5594/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.9811 - accuracy: 0.0312 - val_loss: 141.5939 - val_accuracy: 0.0000e+00\n",
      "Epoch 5595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3022 - accuracy: 0.0312 - val_loss: 143.5773 - val_accuracy: 0.0000e+00\n",
      "Epoch 5596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0953 - accuracy: 0.0000e+00 - val_loss: 134.4552 - val_accuracy: 0.0000e+00\n",
      "Epoch 5597/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 24.5994 - accuracy: 0.0000e+00 - val_loss: 121.1203 - val_accuracy: 0.0000e+00\n",
      "Epoch 5598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5845 - accuracy: 0.0156 - val_loss: 114.9320 - val_accuracy: 0.0000e+00\n",
      "Epoch 5599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7706 - accuracy: 0.0312 - val_loss: 114.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 5600/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7215 - accuracy: 0.0312 - val_loss: 122.7875 - val_accuracy: 0.0000e+00\n",
      "Epoch 5601/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0877 - accuracy: 0.0000e+00 - val_loss: 142.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5602/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.5886 - accuracy: 0.0000e+00 - val_loss: 151.5434 - val_accuracy: 0.0000e+00\n",
      "Epoch 5603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7984 - accuracy: 0.0156 - val_loss: 138.2177 - val_accuracy: 0.0000e+00\n",
      "Epoch 5604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9957 - accuracy: 0.0312 - val_loss: 130.2577 - val_accuracy: 0.0000e+00\n",
      "Epoch 5605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5460 - accuracy: 0.0156 - val_loss: 125.7444 - val_accuracy: 0.0588\n",
      "Epoch 5606/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4861 - accuracy: 0.0312 - val_loss: 122.1471 - val_accuracy: 0.0000e+00\n",
      "Epoch 5607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5784 - accuracy: 0.0000e+00 - val_loss: 118.9620 - val_accuracy: 0.0000e+00\n",
      "Epoch 5608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3870 - accuracy: 0.0000e+00 - val_loss: 114.7375 - val_accuracy: 0.0000e+00\n",
      "Epoch 5609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5664 - accuracy: 0.0156 - val_loss: 110.3582 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5610/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9194 - accuracy: 0.0156 - val_loss: 111.5799 - val_accuracy: 0.0000e+00\n",
      "Epoch 5611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2383 - accuracy: 0.0000e+00 - val_loss: 122.3140 - val_accuracy: 0.0000e+00\n",
      "Epoch 5612/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5843 - accuracy: 0.0156 - val_loss: 137.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 5613/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4936 - accuracy: 0.0000e+00 - val_loss: 138.7840 - val_accuracy: 0.0000e+00\n",
      "Epoch 5614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4017 - accuracy: 0.0000e+00 - val_loss: 128.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 5615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8805 - accuracy: 0.0312 - val_loss: 126.5234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2722 - accuracy: 0.0312 - val_loss: 125.5412 - val_accuracy: 0.0000e+00\n",
      "Epoch 5617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1409 - accuracy: 0.0000e+00 - val_loss: 121.7489 - val_accuracy: 0.0588\n",
      "Epoch 5618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8022 - accuracy: 0.0000e+00 - val_loss: 118.0789 - val_accuracy: 0.0588\n",
      "Epoch 5619/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 31.6762 - accuracy: 0.0156 - val_loss: 118.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2104 - accuracy: 0.0312 - val_loss: 124.7336 - val_accuracy: 0.0000e+00\n",
      "Epoch 5621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6183 - accuracy: 0.0156 - val_loss: 130.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 5622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5869 - accuracy: 0.0156 - val_loss: 127.8004 - val_accuracy: 0.0000e+00\n",
      "Epoch 5623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5056 - accuracy: 0.0000e+00 - val_loss: 123.7513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5920 - accuracy: 0.0000e+00 - val_loss: 124.0110 - val_accuracy: 0.0000e+00\n",
      "Epoch 5625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2727 - accuracy: 0.0156 - val_loss: 127.9621 - val_accuracy: 0.0000e+00\n",
      "Epoch 5626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9923 - accuracy: 0.0000e+00 - val_loss: 133.9553 - val_accuracy: 0.0000e+00\n",
      "Epoch 5627/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 43.4829 - accuracy: 0.0000e+00 - val_loss: 132.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2244 - accuracy: 0.0000e+00 - val_loss: 135.0865 - val_accuracy: 0.0588\n",
      "Epoch 5629/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2389 - accuracy: 0.0156 - val_loss: 134.4401 - val_accuracy: 0.0000e+00\n",
      "Epoch 5630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2796 - accuracy: 0.0000e+00 - val_loss: 130.4105 - val_accuracy: 0.0000e+00\n",
      "Epoch 5631/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.6499 - accuracy: 0.0000e+00 - val_loss: 125.4696 - val_accuracy: 0.0000e+00\n",
      "Epoch 5632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0932 - accuracy: 0.0000e+00 - val_loss: 123.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 5633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3215 - accuracy: 0.0312 - val_loss: 122.8003 - val_accuracy: 0.0588\n",
      "Epoch 5634/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1372 - accuracy: 0.0000e+00 - val_loss: 125.5926 - val_accuracy: 0.0588\n",
      "Epoch 5635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5827 - accuracy: 0.0156 - val_loss: 127.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 5636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4670 - accuracy: 0.0000e+00 - val_loss: 127.9608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5637/10000\n",
      "64/64 [==============================] - 0s 109us/step - loss: 30.9651 - accuracy: 0.0156 - val_loss: 127.1731 - val_accuracy: 0.0000e+00\n",
      "Epoch 5638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6225 - accuracy: 0.0000e+00 - val_loss: 127.1119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5639/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7697 - accuracy: 0.0000e+00 - val_loss: 125.7119 - val_accuracy: 0.0000e+00\n",
      "Epoch 5640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0653 - accuracy: 0.0000e+00 - val_loss: 121.7756 - val_accuracy: 0.0000e+00\n",
      "Epoch 5641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3111 - accuracy: 0.0156 - val_loss: 120.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5642/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4415 - accuracy: 0.0000e+00 - val_loss: 130.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 5643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6851 - accuracy: 0.0156 - val_loss: 139.1384 - val_accuracy: 0.0000e+00\n",
      "Epoch 5644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.3661 - accuracy: 0.0000e+00 - val_loss: 137.7782 - val_accuracy: 0.0000e+00\n",
      "Epoch 5645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7383 - accuracy: 0.0000e+00 - val_loss: 127.3470 - val_accuracy: 0.0000e+00\n",
      "Epoch 5646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3653 - accuracy: 0.0000e+00 - val_loss: 123.8775 - val_accuracy: 0.0000e+00\n",
      "Epoch 5647/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.5315 - accuracy: 0.0156 - val_loss: 124.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 5648/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 24.4067 - accuracy: 0.0000e+00 - val_loss: 127.6917 - val_accuracy: 0.0588\n",
      "Epoch 5649/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.4882 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 39.6593 - accuracy: 0.0000e+00 - val_loss: 140.5058 - val_accuracy: 0.0588\n",
      "Epoch 5650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5729 - accuracy: 0.0156 - val_loss: 158.2885 - val_accuracy: 0.0000e+00\n",
      "Epoch 5651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2329 - accuracy: 0.0312 - val_loss: 165.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 5652/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.8768 - accuracy: 0.0156 - val_loss: 158.4845 - val_accuracy: 0.0000e+00\n",
      "Epoch 5653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2068 - accuracy: 0.0000e+00 - val_loss: 146.9878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1276 - accuracy: 0.0156 - val_loss: 136.0496 - val_accuracy: 0.0588\n",
      "Epoch 5655/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4402 - accuracy: 0.0312 - val_loss: 129.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 5656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7880 - accuracy: 0.0156 - val_loss: 131.9696 - val_accuracy: 0.0000e+00\n",
      "Epoch 5657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1864 - accuracy: 0.0000e+00 - val_loss: 134.7122 - val_accuracy: 0.0000e+00\n",
      "Epoch 5658/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 26.5471 - accuracy: 0.0156 - val_loss: 134.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 5659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9852 - accuracy: 0.0156 - val_loss: 125.0762 - val_accuracy: 0.0000e+00\n",
      "Epoch 5660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0611 - accuracy: 0.0000e+00 - val_loss: 121.6783 - val_accuracy: 0.0000e+00\n",
      "Epoch 5661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2147 - accuracy: 0.0000e+00 - val_loss: 131.5004 - val_accuracy: 0.0000e+00\n",
      "Epoch 5662/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.2407 - accuracy: 0.0000e+00 - val_loss: 141.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 5663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1667 - accuracy: 0.0156 - val_loss: 141.0538 - val_accuracy: 0.0000e+00\n",
      "Epoch 5664/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8255 - accuracy: 0.0156 - val_loss: 132.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 5665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.3385 - accuracy: 0.0156 - val_loss: 128.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 5666/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2767 - accuracy: 0.0000e+00 - val_loss: 127.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 5667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4895 - accuracy: 0.0000e+00 - val_loss: 136.8116 - val_accuracy: 0.0000e+00\n",
      "Epoch 5668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1641 - accuracy: 0.0156 - val_loss: 141.3026 - val_accuracy: 0.0000e+00\n",
      "Epoch 5669/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 23.0006 - accuracy: 0.0000e+00 - val_loss: 143.4884 - val_accuracy: 0.0000e+00\n",
      "Epoch 5670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2231 - accuracy: 0.0000e+00 - val_loss: 141.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 5671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1114 - accuracy: 0.0000e+00 - val_loss: 145.2622 - val_accuracy: 0.0000e+00\n",
      "Epoch 5672/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 35.8552 - accuracy: 0.0000e+00 - val_loss: 144.4212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5673/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.2729 - accuracy: 0.0000e+00 - val_loss: 142.2753 - val_accuracy: 0.0000e+00\n",
      "Epoch 5674/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.6224 - accuracy: 0.0469 - val_loss: 138.4352 - val_accuracy: 0.0588\n",
      "Epoch 5675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9010 - accuracy: 0.0156 - val_loss: 142.3454 - val_accuracy: 0.0000e+00\n",
      "Epoch 5676/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 41.5825 - accuracy: 0.0000e+00 - val_loss: 141.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 5677/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 35.7423 - accuracy: 0.0000e+00 - val_loss: 133.0502 - val_accuracy: 0.0000e+00\n",
      "Epoch 5678/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9498 - accuracy: 0.0156 - val_loss: 128.8362 - val_accuracy: 0.0000e+00\n",
      "Epoch 5679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5668 - accuracy: 0.0156 - val_loss: 129.3557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5680/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 26.5694 - accuracy: 0.0000e+00 - val_loss: 131.5796 - val_accuracy: 0.0000e+00\n",
      "Epoch 5681/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.1813 - accuracy: 0.0156 - val_loss: 134.0154 - val_accuracy: 0.0000e+00\n",
      "Epoch 5682/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3395 - accuracy: 0.0000e+00 - val_loss: 131.2786 - val_accuracy: 0.0588\n",
      "Epoch 5683/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3170 - accuracy: 0.0000e+00 - val_loss: 127.7604 - val_accuracy: 0.0000e+00\n",
      "Epoch 5684/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7578 - accuracy: 0.0156 - val_loss: 128.4781 - val_accuracy: 0.0000e+00\n",
      "Epoch 5685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0751 - accuracy: 0.0156 - val_loss: 130.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 5686/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 41.1218 - accuracy: 0.0156 - val_loss: 133.4349 - val_accuracy: 0.0588\n",
      "Epoch 5687/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.1204 - accuracy: 0.0000e+00 - val_loss: 131.8665 - val_accuracy: 0.0000e+00\n",
      "Epoch 5688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7042 - accuracy: 0.0312 - val_loss: 128.6672 - val_accuracy: 0.0000e+00\n",
      "Epoch 5689/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 30.3352 - accuracy: 0.0000e+00 - val_loss: 124.3362 - val_accuracy: 0.0000e+00\n",
      "Epoch 5690/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 31.2310 - accuracy: 0.0156 - val_loss: 124.7882 - val_accuracy: 0.0000e+00\n",
      "Epoch 5691/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.8137 - accuracy: 0.0156 - val_loss: 131.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5692/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.2227 - accuracy: 0.0312 - val_loss: 131.2787 - val_accuracy: 0.0000e+00\n",
      "Epoch 5693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0741 - accuracy: 0.0156 - val_loss: 128.9027 - val_accuracy: 0.0000e+00\n",
      "Epoch 5694/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8494 - accuracy: 0.0156 - val_loss: 125.1525 - val_accuracy: 0.0588\n",
      "Epoch 5695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9869 - accuracy: 0.0156 - val_loss: 132.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 5696/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6771 - accuracy: 0.0156 - val_loss: 137.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 5697/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.6106 - accuracy: 0.0469 - val_loss: 140.9648 - val_accuracy: 0.0000e+00\n",
      "Epoch 5698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2842 - accuracy: 0.0156 - val_loss: 144.0979 - val_accuracy: 0.0000e+00\n",
      "Epoch 5699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5335 - accuracy: 0.0000e+00 - val_loss: 145.0592 - val_accuracy: 0.0000e+00\n",
      "Epoch 5700/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 30.4423 - accuracy: 0.0156 - val_loss: 140.6524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5701/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.7983 - accuracy: 0.0156 - val_loss: 136.2202 - val_accuracy: 0.0000e+00\n",
      "Epoch 5702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5450 - accuracy: 0.0000e+00 - val_loss: 130.1383 - val_accuracy: 0.0000e+00\n",
      "Epoch 5703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6200 - accuracy: 0.0000e+00 - val_loss: 123.7675 - val_accuracy: 0.0000e+00\n",
      "Epoch 5704/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.6408 - accuracy: 0.062 - 0s 125us/step - loss: 20.6543 - accuracy: 0.0469 - val_loss: 121.7681 - val_accuracy: 0.0000e+00\n",
      "Epoch 5705/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 24.8241 - accuracy: 0.0000e+00 - val_loss: 125.1603 - val_accuracy: 0.0000e+00\n",
      "Epoch 5706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3827 - accuracy: 0.0156 - val_loss: 128.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 5707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8403 - accuracy: 0.0000e+00 - val_loss: 126.7809 - val_accuracy: 0.0000e+00\n",
      "Epoch 5708/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 16.4964 - accuracy: 0.0312 - val_loss: 125.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 5709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1876 - accuracy: 0.0156 - val_loss: 126.0289 - val_accuracy: 0.0000e+00\n",
      "Epoch 5710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9266 - accuracy: 0.0312 - val_loss: 132.3325 - val_accuracy: 0.0000e+00\n",
      "Epoch 5711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7529 - accuracy: 0.0000e+00 - val_loss: 129.6364 - val_accuracy: 0.0000e+00\n",
      "Epoch 5712/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.5197 - accuracy: 0.0312 - val_loss: 118.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 5713/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 30.8816 - accuracy: 0.0000e+00 - val_loss: 109.9715 - val_accuracy: 0.0000e+00\n",
      "Epoch 5714/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 21.5415 - accuracy: 0.0000e+00 - val_loss: 106.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5715/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.3695 - accuracy: 0.0156 - val_loss: 109.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 5716/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.0484 - accuracy: 0.0000e+00 - val_loss: 115.2374 - val_accuracy: 0.0000e+00\n",
      "Epoch 5717/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 30.8604 - accuracy: 0.0156 - val_loss: 133.3199 - val_accuracy: 0.0000e+00\n",
      "Epoch 5718/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 22.7296 - accuracy: 0.0156 - val_loss: 138.5788 - val_accuracy: 0.0000e+00\n",
      "Epoch 5719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7740 - accuracy: 0.0000e+00 - val_loss: 133.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 5720/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6193 - accuracy: 0.0000e+00 - val_loss: 130.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 5721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8741 - accuracy: 0.0312 - val_loss: 132.3937 - val_accuracy: 0.0000e+00\n",
      "Epoch 5722/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4197 - accuracy: 0.0156 - val_loss: 134.6190 - val_accuracy: 0.0000e+00\n",
      "Epoch 5723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7716 - accuracy: 0.0312 - val_loss: 136.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 5724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9085 - accuracy: 0.0000e+00 - val_loss: 136.9609 - val_accuracy: 0.0000e+00\n",
      "Epoch 5725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1640 - accuracy: 0.0469 - val_loss: 137.4776 - val_accuracy: 0.0000e+00\n",
      "Epoch 5726/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 36.2161 - accuracy: 0.031 - 0s 56us/step - loss: 31.7214 - accuracy: 0.0156 - val_loss: 132.3008 - val_accuracy: 0.0000e+00\n",
      "Epoch 5727/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5156 - accuracy: 0.0312 - val_loss: 128.4619 - val_accuracy: 0.0000e+00\n",
      "Epoch 5728/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.6479 - accuracy: 0.0000e+00 - val_loss: 120.7234 - val_accuracy: 0.0000e+00\n",
      "Epoch 5729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2135 - accuracy: 0.0312 - val_loss: 119.6588 - val_accuracy: 0.0000e+00\n",
      "Epoch 5730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8670 - accuracy: 0.0000e+00 - val_loss: 130.0548 - val_accuracy: 0.0000e+00\n",
      "Epoch 5731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.6675 - accuracy: 0.0312 - val_loss: 139.2304 - val_accuracy: 0.0000e+00\n",
      "Epoch 5732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9844 - accuracy: 0.0000e+00 - val_loss: 135.3348 - val_accuracy: 0.0000e+00\n",
      "Epoch 5733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9497 - accuracy: 0.0000e+00 - val_loss: 132.8834 - val_accuracy: 0.0000e+00\n",
      "Epoch 5734/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.5471 - accuracy: 0.0000e+0 - 0s 70us/step - loss: 27.8178 - accuracy: 0.0312 - val_loss: 131.1481 - val_accuracy: 0.0588\n",
      "Epoch 5735/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7691 - accuracy: 0.0000e+00 - val_loss: 129.2407 - val_accuracy: 0.1176\n",
      "Epoch 5736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.5061 - accuracy: 0.0000e+00 - val_loss: 131.4570 - val_accuracy: 0.1176\n",
      "Epoch 5737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4712 - accuracy: 0.0000e+00 - val_loss: 132.1462 - val_accuracy: 0.0588\n",
      "Epoch 5738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0253 - accuracy: 0.0000e+00 - val_loss: 143.8240 - val_accuracy: 0.0588\n",
      "Epoch 5739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9702 - accuracy: 0.0156 - val_loss: 152.2957 - val_accuracy: 0.0588\n",
      "Epoch 5740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7421 - accuracy: 0.0000e+00 - val_loss: 142.6071 - val_accuracy: 0.0588\n",
      "Epoch 5741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9818 - accuracy: 0.0000e+00 - val_loss: 123.9908 - val_accuracy: 0.0588\n",
      "Epoch 5742/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 34.3086 - accuracy: 0.0312 - val_loss: 121.6712 - val_accuracy: 0.0000e+00\n",
      "Epoch 5743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9481 - accuracy: 0.0000e+00 - val_loss: 134.2436 - val_accuracy: 0.0000e+00\n",
      "Epoch 5744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1403 - accuracy: 0.0000e+00 - val_loss: 141.5708 - val_accuracy: 0.0000e+00\n",
      "Epoch 5745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4270 - accuracy: 0.0156 - val_loss: 142.7774 - val_accuracy: 0.0000e+00\n",
      "Epoch 5746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7536 - accuracy: 0.0156 - val_loss: 137.0650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5747/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7373 - accuracy: 0.0000e+00 - val_loss: 131.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 5748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9368 - accuracy: 0.0000e+00 - val_loss: 128.6563 - val_accuracy: 0.0000e+00\n",
      "Epoch 5749/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9830 - accuracy: 0.0000e+00 - val_loss: 124.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0876 - accuracy: 0.0156 - val_loss: 120.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 5751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3012 - accuracy: 0.0000e+00 - val_loss: 120.6294 - val_accuracy: 0.0000e+00\n",
      "Epoch 5752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0941 - accuracy: 0.0000e+00 - val_loss: 112.9691 - val_accuracy: 0.0588\n",
      "Epoch 5753/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 30.5101 - accuracy: 0.0000e+00 - val_loss: 105.7762 - val_accuracy: 0.0588\n",
      "Epoch 5754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4178 - accuracy: 0.0156 - val_loss: 105.6732 - val_accuracy: 0.0588\n",
      "Epoch 5755/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 34.9929 - accuracy: 0.0000e+00 - val_loss: 111.9921 - val_accuracy: 0.0000e+00\n",
      "Epoch 5756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6022 - accuracy: 0.0156 - val_loss: 121.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 5757/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3095 - accuracy: 0.0000e+00 - val_loss: 131.1764 - val_accuracy: 0.0000e+00\n",
      "Epoch 5758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8115 - accuracy: 0.0156 - val_loss: 134.0900 - val_accuracy: 0.0000e+00\n",
      "Epoch 5759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1995 - accuracy: 0.0000e+00 - val_loss: 127.2703 - val_accuracy: 0.0000e+00\n",
      "Epoch 5760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1905 - accuracy: 0.0156 - val_loss: 118.2371 - val_accuracy: 0.0000e+00\n",
      "Epoch 5761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4200 - accuracy: 0.0156 - val_loss: 111.9052 - val_accuracy: 0.0588\n",
      "Epoch 5762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9193 - accuracy: 0.0156 - val_loss: 110.5473 - val_accuracy: 0.0588\n",
      "Epoch 5763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0218 - accuracy: 0.0156 - val_loss: 117.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 5764/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 36.9782 - accuracy: 0.0156 - val_loss: 127.3936 - val_accuracy: 0.0000e+00\n",
      "Epoch 5765/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2387 - accuracy: 0.0156 - val_loss: 135.8268 - val_accuracy: 0.0000e+00\n",
      "Epoch 5766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7309 - accuracy: 0.0000e+00 - val_loss: 132.3572 - val_accuracy: 0.0000e+00\n",
      "Epoch 5767/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.6000 - accuracy: 0.0000e+00 - val_loss: 123.2729 - val_accuracy: 0.0000e+00\n",
      "Epoch 5768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9299 - accuracy: 0.0156 - val_loss: 119.5897 - val_accuracy: 0.0000e+00\n",
      "Epoch 5769/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 32.8291 - accuracy: 0.0156 - val_loss: 120.7286 - val_accuracy: 0.0000e+00\n",
      "Epoch 5770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4163 - accuracy: 0.0312 - val_loss: 125.6186 - val_accuracy: 0.0000e+00\n",
      "Epoch 5771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3520 - accuracy: 0.0000e+00 - val_loss: 130.4290 - val_accuracy: 0.0000e+00\n",
      "Epoch 5772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9295 - accuracy: 0.0156 - val_loss: 126.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 5773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9976 - accuracy: 0.0156 - val_loss: 125.6955 - val_accuracy: 0.0000e+00\n",
      "Epoch 5774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4725 - accuracy: 0.0000e+00 - val_loss: 126.5518 - val_accuracy: 0.0000e+00\n",
      "Epoch 5775/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 29.1379 - accuracy: 0.0000e+00 - val_loss: 124.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 5776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5124 - accuracy: 0.0000e+00 - val_loss: 118.8233 - val_accuracy: 0.0000e+00\n",
      "Epoch 5777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2461 - accuracy: 0.0000e+00 - val_loss: 112.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 5778/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.9433 - accuracy: 0.0000e+00 - val_loss: 113.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3770 - accuracy: 0.0000e+00 - val_loss: 119.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5780/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 15.3013 - accuracy: 0.0000e+00 - val_loss: 124.4736 - val_accuracy: 0.0000e+00\n",
      "Epoch 5781/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.8056 - accuracy: 0.0312 - val_loss: 124.0986 - val_accuracy: 0.0000e+00\n",
      "Epoch 5782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0905 - accuracy: 0.0156 - val_loss: 121.5561 - val_accuracy: 0.0000e+00\n",
      "Epoch 5783/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.9755 - accuracy: 0.0312 - val_loss: 115.9915 - val_accuracy: 0.0000e+00\n",
      "Epoch 5784/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 33.0280 - accuracy: 0.0000e+00 - val_loss: 118.2794 - val_accuracy: 0.0000e+00\n",
      "Epoch 5785/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 22.3816 - accuracy: 0.0156 - val_loss: 120.1833 - val_accuracy: 0.0000e+00\n",
      "Epoch 5786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9033 - accuracy: 0.0000e+00 - val_loss: 125.6521 - val_accuracy: 0.0000e+00\n",
      "Epoch 5787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7921 - accuracy: 0.0000e+00 - val_loss: 128.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 5788/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 26.0366 - accuracy: 0.0156 - val_loss: 128.1787 - val_accuracy: 0.0000e+00\n",
      "Epoch 5789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7191 - accuracy: 0.0000e+00 - val_loss: 122.6881 - val_accuracy: 0.0000e+00\n",
      "Epoch 5790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2979 - accuracy: 0.0156 - val_loss: 117.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 5791/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 32.3562 - accuracy: 0.0000e+00 - val_loss: 112.7773 - val_accuracy: 0.0000e+00\n",
      "Epoch 5792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6529 - accuracy: 0.0156 - val_loss: 106.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 5793/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 25.3886 - accuracy: 0.0000e+00 - val_loss: 106.1996 - val_accuracy: 0.0588\n",
      "Epoch 5794/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3770 - accuracy: 0.0156 - val_loss: 107.6387 - val_accuracy: 0.0588\n",
      "Epoch 5795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5246 - accuracy: 0.0156 - val_loss: 114.1435 - val_accuracy: 0.0588\n",
      "Epoch 5796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0635 - accuracy: 0.0000e+00 - val_loss: 124.1308 - val_accuracy: 0.0588\n",
      "Epoch 5797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4959 - accuracy: 0.0000e+00 - val_loss: 135.4268 - val_accuracy: 0.0588\n",
      "Epoch 5798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5625 - accuracy: 0.0000e+00 - val_loss: 141.9417 - val_accuracy: 0.0588\n",
      "Epoch 5799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3402 - accuracy: 0.0000e+00 - val_loss: 139.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 5800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9824 - accuracy: 0.0000e+00 - val_loss: 131.3941 - val_accuracy: 0.0000e+00\n",
      "Epoch 5801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3708 - accuracy: 0.0000e+00 - val_loss: 123.2413 - val_accuracy: 0.0000e+00\n",
      "Epoch 5802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5275 - accuracy: 0.0000e+00 - val_loss: 117.8599 - val_accuracy: 0.0000e+00\n",
      "Epoch 5803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9784 - accuracy: 0.0000e+00 - val_loss: 114.9511 - val_accuracy: 0.0000e+00\n",
      "Epoch 5804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1025 - accuracy: 0.0000e+00 - val_loss: 117.5041 - val_accuracy: 0.0000e+00\n",
      "Epoch 5805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6660 - accuracy: 0.0000e+00 - val_loss: 127.3050 - val_accuracy: 0.0588\n",
      "Epoch 5806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3837 - accuracy: 0.0156 - val_loss: 134.1830 - val_accuracy: 0.0000e+00\n",
      "Epoch 5807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9705 - accuracy: 0.0000e+00 - val_loss: 131.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 5808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6640 - accuracy: 0.0000e+00 - val_loss: 127.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.9015 - accuracy: 0.0156 - val_loss: 125.3453 - val_accuracy: 0.0000e+00\n",
      "Epoch 5810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6476 - accuracy: 0.0000e+00 - val_loss: 122.9482 - val_accuracy: 0.0000e+00\n",
      "Epoch 5811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0613 - accuracy: 0.0156 - val_loss: 121.9990 - val_accuracy: 0.0000e+00\n",
      "Epoch 5812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7824 - accuracy: 0.0156 - val_loss: 129.7751 - val_accuracy: 0.0588\n",
      "Epoch 5813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8301 - accuracy: 0.0000e+00 - val_loss: 130.2993 - val_accuracy: 0.0588\n",
      "Epoch 5814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1018 - accuracy: 0.0000e+00 - val_loss: 122.2314 - val_accuracy: 0.0588\n",
      "Epoch 5815/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4324 - accuracy: 0.0000e+00 - val_loss: 114.9807 - val_accuracy: 0.0588\n",
      "Epoch 5816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.1712 - accuracy: 0.0000e+00 - val_loss: 112.7208 - val_accuracy: 0.0588\n",
      "Epoch 5817/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7518 - accuracy: 0.0000e+00 - val_loss: 116.3091 - val_accuracy: 0.0000e+00\n",
      "Epoch 5818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 74us/step - loss: 36.6499 - accuracy: 0.0000e+00 - val_loss: 123.3102 - val_accuracy: 0.0588\n",
      "Epoch 5819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6970 - accuracy: 0.0000e+00 - val_loss: 129.4697 - val_accuracy: 0.0000e+00\n",
      "Epoch 5820/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.4303 - accuracy: 0.0156 - val_loss: 127.2477 - val_accuracy: 0.0000e+00\n",
      "Epoch 5821/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2823 - accuracy: 0.0000e+00 - val_loss: 124.8954 - val_accuracy: 0.0000e+00\n",
      "Epoch 5822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7577 - accuracy: 0.0000e+00 - val_loss: 129.2142 - val_accuracy: 0.0000e+00\n",
      "Epoch 5823/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 20.0492 - accuracy: 0.0000e+00 - val_loss: 130.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2245 - accuracy: 0.0156 - val_loss: 125.6754 - val_accuracy: 0.0000e+00\n",
      "Epoch 5825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8248 - accuracy: 0.0156 - val_loss: 121.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 5826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5785 - accuracy: 0.0156 - val_loss: 126.0354 - val_accuracy: 0.0000e+00\n",
      "Epoch 5827/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.6424 - accuracy: 0.0156 - val_loss: 131.8450 - val_accuracy: 0.0000e+00\n",
      "Epoch 5828/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 38.5038 - accuracy: 0.0156 - val_loss: 135.5264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5829/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2063 - accuracy: 0.0312 - val_loss: 132.3022 - val_accuracy: 0.0000e+00\n",
      "Epoch 5830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4454 - accuracy: 0.0625 - val_loss: 132.3897 - val_accuracy: 0.0000e+00\n",
      "Epoch 5831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7200 - accuracy: 0.0000e+00 - val_loss: 128.4823 - val_accuracy: 0.0000e+00\n",
      "Epoch 5832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8899 - accuracy: 0.0000e+00 - val_loss: 122.4319 - val_accuracy: 0.0000e+00\n",
      "Epoch 5833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1094 - accuracy: 0.0156 - val_loss: 116.8024 - val_accuracy: 0.0000e+00\n",
      "Epoch 5834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4100 - accuracy: 0.0000e+00 - val_loss: 114.8085 - val_accuracy: 0.0000e+00\n",
      "Epoch 5835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6994 - accuracy: 0.0000e+00 - val_loss: 115.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 5836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8938 - accuracy: 0.0000e+00 - val_loss: 127.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 5837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4905 - accuracy: 0.0156 - val_loss: 138.9326 - val_accuracy: 0.0000e+00\n",
      "Epoch 5838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3031 - accuracy: 0.0156 - val_loss: 144.9432 - val_accuracy: 0.0000e+00\n",
      "Epoch 5839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6506 - accuracy: 0.0000e+00 - val_loss: 143.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 5840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.9259 - accuracy: 0.0000e+00 - val_loss: 143.0277 - val_accuracy: 0.0000e+00\n",
      "Epoch 5841/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0967 - accuracy: 0.0000e+00 - val_loss: 141.7989 - val_accuracy: 0.0000e+00\n",
      "Epoch 5842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2528 - accuracy: 0.0312 - val_loss: 137.8547 - val_accuracy: 0.0588\n",
      "Epoch 5843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6539 - accuracy: 0.0000e+00 - val_loss: 141.1733 - val_accuracy: 0.0588\n",
      "Epoch 5844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3391 - accuracy: 0.0312 - val_loss: 145.6499 - val_accuracy: 0.0588\n",
      "Epoch 5845/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3936 - accuracy: 0.0000e+00 - val_loss: 148.8891 - val_accuracy: 0.0588\n",
      "Epoch 5846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0449 - accuracy: 0.0156 - val_loss: 140.0226 - val_accuracy: 0.0588\n",
      "Epoch 5847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1793 - accuracy: 0.0156 - val_loss: 132.2346 - val_accuracy: 0.0000e+00\n",
      "Epoch 5848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3266 - accuracy: 0.0000e+00 - val_loss: 124.9779 - val_accuracy: 0.0588\n",
      "Epoch 5849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0844 - accuracy: 0.0000e+00 - val_loss: 122.5735 - val_accuracy: 0.0000e+00\n",
      "Epoch 5850/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2781 - accuracy: 0.0000e+00 - val_loss: 124.3817 - val_accuracy: 0.0000e+00\n",
      "Epoch 5851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3493 - accuracy: 0.0000e+00 - val_loss: 137.7862 - val_accuracy: 0.0588\n",
      "Epoch 5852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9939 - accuracy: 0.0156 - val_loss: 140.4689 - val_accuracy: 0.0588\n",
      "Epoch 5853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2610 - accuracy: 0.0156 - val_loss: 136.8670 - val_accuracy: 0.0588\n",
      "Epoch 5854/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3861 - accuracy: 0.0156 - val_loss: 136.8363 - val_accuracy: 0.0588\n",
      "Epoch 5855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2960 - accuracy: 0.0156 - val_loss: 130.5350 - val_accuracy: 0.0588\n",
      "Epoch 5856/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9367 - accuracy: 0.0156 - val_loss: 120.1404 - val_accuracy: 0.0588\n",
      "Epoch 5857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8887 - accuracy: 0.0156 - val_loss: 114.1176 - val_accuracy: 0.1176\n",
      "Epoch 5858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1909 - accuracy: 0.0156 - val_loss: 117.3015 - val_accuracy: 0.0588\n",
      "Epoch 5859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6029 - accuracy: 0.0000e+00 - val_loss: 128.7438 - val_accuracy: 0.0000e+00\n",
      "Epoch 5860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6207 - accuracy: 0.0156 - val_loss: 136.6557 - val_accuracy: 0.0000e+00\n",
      "Epoch 5861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1911 - accuracy: 0.0000e+00 - val_loss: 138.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 5862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.1316 - accuracy: 0.0312 - val_loss: 136.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 5863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3364 - accuracy: 0.0000e+00 - val_loss: 126.4182 - val_accuracy: 0.0000e+00\n",
      "Epoch 5864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5439 - accuracy: 0.0156 - val_loss: 120.0842 - val_accuracy: 0.0588\n",
      "Epoch 5865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0014 - accuracy: 0.0156 - val_loss: 121.7418 - val_accuracy: 0.0588\n",
      "Epoch 5866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3931 - accuracy: 0.0156 - val_loss: 129.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 5867/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7715 - accuracy: 0.0156 - val_loss: 135.7451 - val_accuracy: 0.0588\n",
      "Epoch 5868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2924 - accuracy: 0.0000e+00 - val_loss: 136.4084 - val_accuracy: 0.0588\n",
      "Epoch 5869/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7835 - accuracy: 0.0000e+00 - val_loss: 130.2957 - val_accuracy: 0.0588\n",
      "Epoch 5870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1348 - accuracy: 0.0156 - val_loss: 125.6718 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5871/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.0129 - accuracy: 0.0156 - val_loss: 125.4264 - val_accuracy: 0.0000e+00\n",
      "Epoch 5872/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.0233 - accuracy: 0.0156 - val_loss: 131.0656 - val_accuracy: 0.0000e+00\n",
      "Epoch 5873/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 36.7872 - accuracy: 0.0156 - val_loss: 145.1381 - val_accuracy: 0.0000e+00\n",
      "Epoch 5874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1556 - accuracy: 0.0156 - val_loss: 153.3032 - val_accuracy: 0.0000e+00\n",
      "Epoch 5875/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.0529 - accuracy: 0.0000e+00 - val_loss: 151.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 5876/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 38.6622 - accuracy: 0.0000e+00 - val_loss: 149.4179 - val_accuracy: 0.0000e+00\n",
      "Epoch 5877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9393 - accuracy: 0.0156 - val_loss: 135.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 5878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6397 - accuracy: 0.0000e+00 - val_loss: 123.9411 - val_accuracy: 0.0588\n",
      "Epoch 5879/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 32.1490 - accuracy: 0.0000e+00 - val_loss: 120.6619 - val_accuracy: 0.0588\n",
      "Epoch 5880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5980 - accuracy: 0.0156 - val_loss: 128.2130 - val_accuracy: 0.0588\n",
      "Epoch 5881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4048 - accuracy: 0.0000e+00 - val_loss: 131.1670 - val_accuracy: 0.0588\n",
      "Epoch 5882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.6198 - accuracy: 0.0312 - val_loss: 122.3732 - val_accuracy: 0.0000e+00\n",
      "Epoch 5883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2098 - accuracy: 0.0000e+00 - val_loss: 113.9890 - val_accuracy: 0.0588\n",
      "Epoch 5884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4677 - accuracy: 0.0000e+00 - val_loss: 111.5024 - val_accuracy: 0.0588\n",
      "Epoch 5885/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.7852 - accuracy: 0.0312 - val_loss: 111.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 5886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3648 - accuracy: 0.0156 - val_loss: 111.2472 - val_accuracy: 0.0000e+00\n",
      "Epoch 5887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8560 - accuracy: 0.0156 - val_loss: 108.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 5888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2576 - accuracy: 0.0312 - val_loss: 111.9595 - val_accuracy: 0.0000e+00\n",
      "Epoch 5889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0872 - accuracy: 0.0156 - val_loss: 119.0917 - val_accuracy: 0.0588\n",
      "Epoch 5890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2403 - accuracy: 0.0000e+00 - val_loss: 129.2728 - val_accuracy: 0.0588\n",
      "Epoch 5891/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7503 - accuracy: 0.0156 - val_loss: 139.7789 - val_accuracy: 0.0000e+00\n",
      "Epoch 5892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6375 - accuracy: 0.0156 - val_loss: 142.0745 - val_accuracy: 0.0000e+00\n",
      "Epoch 5893/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.2001 - accuracy: 0.0156 - val_loss: 136.3011 - val_accuracy: 0.0000e+00\n",
      "Epoch 5894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4412 - accuracy: 0.0000e+00 - val_loss: 127.8196 - val_accuracy: 0.0000e+00\n",
      "Epoch 5895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 47.7437 - accuracy: 0.0156 - val_loss: 125.3031 - val_accuracy: 0.0588\n",
      "Epoch 5896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2171 - accuracy: 0.0000e+00 - val_loss: 131.8498 - val_accuracy: 0.0000e+00\n",
      "Epoch 5897/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9807 - accuracy: 0.0000e+00 - val_loss: 137.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 5898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5089 - accuracy: 0.0156 - val_loss: 139.8581 - val_accuracy: 0.0000e+00\n",
      "Epoch 5899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3687 - accuracy: 0.0000e+00 - val_loss: 132.6995 - val_accuracy: 0.0000e+00\n",
      "Epoch 5900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9668 - accuracy: 0.0156 - val_loss: 118.0866 - val_accuracy: 0.0000e+00\n",
      "Epoch 5901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4796 - accuracy: 0.0000e+00 - val_loss: 110.2238 - val_accuracy: 0.0000e+00\n",
      "Epoch 5902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0900 - accuracy: 0.0000e+00 - val_loss: 109.3317 - val_accuracy: 0.0000e+00\n",
      "Epoch 5903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2922 - accuracy: 0.0000e+00 - val_loss: 127.0456 - val_accuracy: 0.0000e+00\n",
      "Epoch 5904/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.9359 - accuracy: 0.0000e+00 - val_loss: 143.7391 - val_accuracy: 0.0000e+00\n",
      "Epoch 5905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8224 - accuracy: 0.0156 - val_loss: 147.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 5906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1993 - accuracy: 0.0156 - val_loss: 148.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 5907/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.5498 - accuracy: 0.0000e+00 - val_loss: 142.3532 - val_accuracy: 0.0000e+00\n",
      "Epoch 5908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7004 - accuracy: 0.0000e+00 - val_loss: 138.8386 - val_accuracy: 0.0000e+00\n",
      "Epoch 5909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9732 - accuracy: 0.0156 - val_loss: 135.7881 - val_accuracy: 0.0000e+00\n",
      "Epoch 5910/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4437 - accuracy: 0.0156 - val_loss: 135.2313 - val_accuracy: 0.0000e+00\n",
      "Epoch 5911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4217 - accuracy: 0.0000e+00 - val_loss: 132.5032 - val_accuracy: 0.0588\n",
      "Epoch 5912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2453 - accuracy: 0.0156 - val_loss: 128.8812 - val_accuracy: 0.0588\n",
      "Epoch 5913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6289 - accuracy: 0.0156 - val_loss: 125.8777 - val_accuracy: 0.0588\n",
      "Epoch 5914/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7341 - accuracy: 0.0000e+00 - val_loss: 123.7722 - val_accuracy: 0.0588\n",
      "Epoch 5915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6099 - accuracy: 0.0312 - val_loss: 114.3724 - val_accuracy: 0.0588\n",
      "Epoch 5916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5350 - accuracy: 0.0312 - val_loss: 109.2092 - val_accuracy: 0.0000e+00\n",
      "Epoch 5917/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 30.6034 - accuracy: 0.0000e+00 - val_loss: 118.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5918/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3773 - accuracy: 0.0156 - val_loss: 127.8126 - val_accuracy: 0.0000e+00\n",
      "Epoch 5919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0457 - accuracy: 0.0000e+00 - val_loss: 128.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 5920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7071 - accuracy: 0.0156 - val_loss: 125.8441 - val_accuracy: 0.0588\n",
      "Epoch 5921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9821 - accuracy: 0.0000e+00 - val_loss: 127.4569 - val_accuracy: 0.0588\n",
      "Epoch 5922/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 34.1431 - accuracy: 0.0156 - val_loss: 132.3512 - val_accuracy: 0.0588\n",
      "Epoch 5923/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6914 - accuracy: 0.0000e+00 - val_loss: 137.6294 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6074 - accuracy: 0.0000e+00 - val_loss: 139.8447 - val_accuracy: 0.0588\n",
      "Epoch 5925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6829 - accuracy: 0.0312 - val_loss: 135.5025 - val_accuracy: 0.0588\n",
      "Epoch 5926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6770 - accuracy: 0.0312 - val_loss: 132.8520 - val_accuracy: 0.0588\n",
      "Epoch 5927/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 33.0535 - accuracy: 0.0156 - val_loss: 131.2137 - val_accuracy: 0.0588\n",
      "Epoch 5928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2617 - accuracy: 0.0000e+00 - val_loss: 129.0251 - val_accuracy: 0.0588\n",
      "Epoch 5929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0597 - accuracy: 0.0312 - val_loss: 127.5571 - val_accuracy: 0.0000e+00\n",
      "Epoch 5930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9742 - accuracy: 0.0000e+00 - val_loss: 131.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 5931/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 41.7358 - accuracy: 0.0000e+00 - val_loss: 136.8279 - val_accuracy: 0.0000e+00\n",
      "Epoch 5932/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3345 - accuracy: 0.0000e+00 - val_loss: 135.9160 - val_accuracy: 0.0588\n",
      "Epoch 5933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6121 - accuracy: 0.0156 - val_loss: 136.3733 - val_accuracy: 0.0588\n",
      "Epoch 5934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5197 - accuracy: 0.0000e+00 - val_loss: 138.1032 - val_accuracy: 0.1176\n",
      "Epoch 5935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2617 - accuracy: 0.0156 - val_loss: 137.3277 - val_accuracy: 0.0588\n",
      "Epoch 5936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7570 - accuracy: 0.0000e+00 - val_loss: 138.5240 - val_accuracy: 0.0000e+00\n",
      "Epoch 5937/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 19.9242 - accuracy: 0.0000e+00 - val_loss: 137.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 5938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7390 - accuracy: 0.0000e+00 - val_loss: 132.2679 - val_accuracy: 0.0588\n",
      "Epoch 5939/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 20.7819 - accuracy: 0.031 - 0s 97us/step - loss: 29.0366 - accuracy: 0.0156 - val_loss: 123.7280 - val_accuracy: 0.0588\n",
      "Epoch 5940/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 25.7665 - accuracy: 0.0000e+00 - val_loss: 120.3478 - val_accuracy: 0.0588\n",
      "Epoch 5941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1772 - accuracy: 0.0156 - val_loss: 124.4391 - val_accuracy: 0.0588\n",
      "Epoch 5942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5044 - accuracy: 0.0156 - val_loss: 131.4396 - val_accuracy: 0.0000e+00\n",
      "Epoch 5943/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7282 - accuracy: 0.0156 - val_loss: 141.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 5944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8657 - accuracy: 0.0000e+00 - val_loss: 147.4094 - val_accuracy: 0.0000e+00\n",
      "Epoch 5945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3445 - accuracy: 0.0000e+00 - val_loss: 143.7550 - val_accuracy: 0.0000e+00\n",
      "Epoch 5946/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.1873 - accuracy: 0.0156 - val_loss: 136.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 5947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0699 - accuracy: 0.0000e+00 - val_loss: 127.8577 - val_accuracy: 0.0588\n",
      "Epoch 5948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0136 - accuracy: 0.0000e+00 - val_loss: 126.2529 - val_accuracy: 0.0588\n",
      "Epoch 5949/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 21.6489 - accuracy: 0.0000e+00 - val_loss: 120.0388 - val_accuracy: 0.0588\n",
      "Epoch 5950/10000\n",
      "64/64 [==============================] - 0s 112us/step - loss: 28.1214 - accuracy: 0.0000e+00 - val_loss: 116.8581 - val_accuracy: 0.0588\n",
      "Epoch 5951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9486 - accuracy: 0.0156 - val_loss: 117.6727 - val_accuracy: 0.0588\n",
      "Epoch 5952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5104 - accuracy: 0.0156 - val_loss: 120.2059 - val_accuracy: 0.0588\n",
      "Epoch 5953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4188 - accuracy: 0.0000e+00 - val_loss: 123.5321 - val_accuracy: 0.0588\n",
      "Epoch 5954/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5085 - accuracy: 0.0000e+00 - val_loss: 129.3792 - val_accuracy: 0.0588\n",
      "Epoch 5955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5261 - accuracy: 0.0000e+00 - val_loss: 129.8121 - val_accuracy: 0.0588\n",
      "Epoch 5956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.4415 - accuracy: 0.0312 - val_loss: 125.3856 - val_accuracy: 0.0588\n",
      "Epoch 5957/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5019 - accuracy: 0.0000e+00 - val_loss: 131.3719 - val_accuracy: 0.0588\n",
      "Epoch 5958/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 24.0674 - accuracy: 0.0156 - val_loss: 136.0228 - val_accuracy: 0.0588\n",
      "Epoch 5959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9477 - accuracy: 0.0312 - val_loss: 135.4907 - val_accuracy: 0.0588\n",
      "Epoch 5960/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4876 - accuracy: 0.0156 - val_loss: 123.1417 - val_accuracy: 0.0588\n",
      "Epoch 5961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7223 - accuracy: 0.0000e+00 - val_loss: 115.6410 - val_accuracy: 0.0000e+00\n",
      "Epoch 5962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6752 - accuracy: 0.0156 - val_loss: 113.3212 - val_accuracy: 0.0000e+00\n",
      "Epoch 5963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7797 - accuracy: 0.0000e+00 - val_loss: 124.5864 - val_accuracy: 0.0000e+00\n",
      "Epoch 5964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1516 - accuracy: 0.0000e+00 - val_loss: 141.3477 - val_accuracy: 0.0000e+00\n",
      "Epoch 5965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7953 - accuracy: 0.0156 - val_loss: 152.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 5966/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.5735 - accuracy: 0.0156 - val_loss: 145.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 5967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1457 - accuracy: 0.0000e+00 - val_loss: 138.6668 - val_accuracy: 0.0000e+00\n",
      "Epoch 5968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3329 - accuracy: 0.0000e+00 - val_loss: 127.8759 - val_accuracy: 0.0588\n",
      "Epoch 5969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0369 - accuracy: 0.0000e+00 - val_loss: 123.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 5970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0600 - accuracy: 0.0156 - val_loss: 127.0027 - val_accuracy: 0.0588\n",
      "Epoch 5971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0930 - accuracy: 0.0156 - val_loss: 136.4816 - val_accuracy: 0.0000e+00\n",
      "Epoch 5972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9976 - accuracy: 0.0312 - val_loss: 145.3067 - val_accuracy: 0.0000e+00\n",
      "Epoch 5973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.5986 - accuracy: 0.0000e+00 - val_loss: 148.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 5974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2186 - accuracy: 0.0000e+00 - val_loss: 141.1086 - val_accuracy: 0.0000e+00\n",
      "Epoch 5975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.6440 - accuracy: 0.0156 - val_loss: 129.4647 - val_accuracy: 0.0000e+00\n",
      "Epoch 5976/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4407 - accuracy: 0.0000e+00 - val_loss: 128.5394 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9560 - accuracy: 0.0156 - val_loss: 130.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 5978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6916 - accuracy: 0.0000e+00 - val_loss: 137.0132 - val_accuracy: 0.0000e+00\n",
      "Epoch 5979/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6450 - accuracy: 0.0312 - val_loss: 142.3016 - val_accuracy: 0.0000e+00\n",
      "Epoch 5980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0380 - accuracy: 0.0000e+00 - val_loss: 148.2796 - val_accuracy: 0.0000e+00\n",
      "Epoch 5981/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7472 - accuracy: 0.0000e+00 - val_loss: 142.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 5982/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.4911 - accuracy: 0.0000e+00 - val_loss: 132.3308 - val_accuracy: 0.0000e+00\n",
      "Epoch 5983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5114 - accuracy: 0.0000e+00 - val_loss: 121.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 5984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1387 - accuracy: 0.0156 - val_loss: 119.7558 - val_accuracy: 0.0000e+00\n",
      "Epoch 5985/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8199 - accuracy: 0.0000e+00 - val_loss: 125.3840 - val_accuracy: 0.0000e+00\n",
      "Epoch 5986/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0305 - accuracy: 0.0625 - val_loss: 132.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 5987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1449 - accuracy: 0.0000e+00 - val_loss: 133.8228 - val_accuracy: 0.0000e+00\n",
      "Epoch 5988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0120 - accuracy: 0.0000e+00 - val_loss: 132.3415 - val_accuracy: 0.0000e+00\n",
      "Epoch 5989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7839 - accuracy: 0.0469 - val_loss: 133.5928 - val_accuracy: 0.0588\n",
      "Epoch 5990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9797 - accuracy: 0.0156 - val_loss: 140.8633 - val_accuracy: 0.0588\n",
      "Epoch 5991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1514 - accuracy: 0.0000e+00 - val_loss: 139.5397 - val_accuracy: 0.0588\n",
      "Epoch 5992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1453 - accuracy: 0.0000e+00 - val_loss: 140.7541 - val_accuracy: 0.0588\n",
      "Epoch 5993/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9976 - accuracy: 0.0312 - val_loss: 140.9387 - val_accuracy: 0.0000e+00\n",
      "Epoch 5994/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.1749 - accuracy: 0.0000e+00 - val_loss: 140.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 5995/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.0714 - accuracy: 0.0312 - val_loss: 132.9931 - val_accuracy: 0.0000e+00\n",
      "Epoch 5996/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 25.9033 - accuracy: 0.0156 - val_loss: 123.0779 - val_accuracy: 0.0000e+00\n",
      "Epoch 5997/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 27.7869 - accuracy: 0.0312 - val_loss: 126.2372 - val_accuracy: 0.0000e+00\n",
      "Epoch 5998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8273 - accuracy: 0.0156 - val_loss: 135.3857 - val_accuracy: 0.0588\n",
      "Epoch 5999/10000\n",
      "64/64 [==============================] - 0s 250us/step - loss: 32.1999 - accuracy: 0.0000e+00 - val_loss: 140.3900 - val_accuracy: 0.0588\n",
      "Epoch 6000/10000\n",
      "64/64 [==============================] - 0s 312us/step - loss: 30.1715 - accuracy: 0.0156 - val_loss: 137.3134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6001/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.0279 - accuracy: 0.0000e+00 - val_loss: 131.8832 - val_accuracy: 0.0588\n",
      "Epoch 6002/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 33.8234 - accuracy: 0.0156 - val_loss: 126.6591 - val_accuracy: 0.0588\n",
      "Epoch 6003/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 26.1932 - accuracy: 0.0000e+00 - val_loss: 128.1120 - val_accuracy: 0.0588\n",
      "Epoch 6004/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 26.4543 - accuracy: 0.0000e+00 - val_loss: 130.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 6005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0158 - accuracy: 0.0000e+00 - val_loss: 129.9505 - val_accuracy: 0.0000e+00\n",
      "Epoch 6006/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 20.7924 - accuracy: 0.0000e+00 - val_loss: 117.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 6007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2137 - accuracy: 0.0156 - val_loss: 120.4972 - val_accuracy: 0.0588\n",
      "Epoch 6008/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.3526 - accuracy: 0.0000e+00 - val_loss: 127.6661 - val_accuracy: 0.0588\n",
      "Epoch 6009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1145 - accuracy: 0.0000e+00 - val_loss: 139.1438 - val_accuracy: 0.0588\n",
      "Epoch 6010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4481 - accuracy: 0.0000e+00 - val_loss: 145.0682 - val_accuracy: 0.0588\n",
      "Epoch 6011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5306 - accuracy: 0.0312 - val_loss: 136.7424 - val_accuracy: 0.0588\n",
      "Epoch 6012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2315 - accuracy: 0.0000e+00 - val_loss: 131.4878 - val_accuracy: 0.0588\n",
      "Epoch 6013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9917 - accuracy: 0.0156 - val_loss: 130.5126 - val_accuracy: 0.1176\n",
      "Epoch 6014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6683 - accuracy: 0.0000e+00 - val_loss: 132.3676 - val_accuracy: 0.0588\n",
      "Epoch 6015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5898 - accuracy: 0.0156 - val_loss: 139.3578 - val_accuracy: 0.0588\n",
      "Epoch 6016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0187 - accuracy: 0.0312 - val_loss: 147.3806 - val_accuracy: 0.0588\n",
      "Epoch 6017/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3900 - accuracy: 0.0156 - val_loss: 137.3584 - val_accuracy: 0.0588\n",
      "Epoch 6018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2423 - accuracy: 0.0000e+00 - val_loss: 128.7104 - val_accuracy: 0.1176\n",
      "Epoch 6019/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.0534 - accuracy: 0.0000e+00 - val_loss: 124.5535 - val_accuracy: 0.0588\n",
      "Epoch 6020/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3989 - accuracy: 0.0000e+00 - val_loss: 127.8340 - val_accuracy: 0.0588\n",
      "Epoch 6021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1169 - accuracy: 0.0156 - val_loss: 131.4279 - val_accuracy: 0.1176\n",
      "Epoch 6022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0647 - accuracy: 0.0000e+00 - val_loss: 133.1188 - val_accuracy: 0.1176\n",
      "Epoch 6023/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0267 - accuracy: 0.0156 - val_loss: 132.2258 - val_accuracy: 0.1176\n",
      "Epoch 6024/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2264 - accuracy: 0.0000e+00 - val_loss: 129.9165 - val_accuracy: 0.1176\n",
      "Epoch 6025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3034 - accuracy: 0.0000e+00 - val_loss: 128.2572 - val_accuracy: 0.1176\n",
      "Epoch 6026/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.2470 - accuracy: 0.0000e+00 - val_loss: 126.5798 - val_accuracy: 0.0588\n",
      "Epoch 6027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2568 - accuracy: 0.0000e+00 - val_loss: 129.8072 - val_accuracy: 0.0588\n",
      "Epoch 6028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5353 - accuracy: 0.0000e+00 - val_loss: 133.1541 - val_accuracy: 0.0588\n",
      "Epoch 6029/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 42.6771 - accuracy: 0.0156 - val_loss: 133.8542 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6030/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 47.3664 - accuracy: 0.0469 - val_loss: 136.9678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1560 - accuracy: 0.0000e+00 - val_loss: 144.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6032/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.3954 - accuracy: 0.0000e+00 - val_loss: 147.9522 - val_accuracy: 0.0000e+00\n",
      "Epoch 6033/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.1804 - accuracy: 0.0000e+00 - val_loss: 143.4943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6034/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 24.7604 - accuracy: 0.0000e+00 - val_loss: 131.6500 - val_accuracy: 0.0588\n",
      "Epoch 6035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6186 - accuracy: 0.0156 - val_loss: 122.6100 - val_accuracy: 0.0588\n",
      "Epoch 6036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7206 - accuracy: 0.0000e+00 - val_loss: 117.1700 - val_accuracy: 0.0588\n",
      "Epoch 6037/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 19.2457 - accuracy: 0.0000e+00 - val_loss: 116.1734 - val_accuracy: 0.0588\n",
      "Epoch 6038/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5752 - accuracy: 0.0000e+00 - val_loss: 126.8543 - val_accuracy: 0.0588\n",
      "Epoch 6039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4745 - accuracy: 0.0156 - val_loss: 134.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 6040/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 28.3360 - accuracy: 0.0156 - val_loss: 134.7967 - val_accuracy: 0.0000e+00\n",
      "Epoch 6041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0552 - accuracy: 0.0000e+00 - val_loss: 132.6153 - val_accuracy: 0.0000e+00\n",
      "Epoch 6042/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2417 - accuracy: 0.0000e+00 - val_loss: 128.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 6043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0812 - accuracy: 0.0000e+00 - val_loss: 122.2026 - val_accuracy: 0.0000e+00\n",
      "Epoch 6044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2575 - accuracy: 0.0000e+00 - val_loss: 115.2653 - val_accuracy: 0.0588\n",
      "Epoch 6045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5015 - accuracy: 0.0000e+00 - val_loss: 113.9052 - val_accuracy: 0.0588\n",
      "Epoch 6046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9571 - accuracy: 0.0000e+00 - val_loss: 119.2571 - val_accuracy: 0.0588\n",
      "Epoch 6047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3485 - accuracy: 0.0000e+00 - val_loss: 125.8454 - val_accuracy: 0.0588\n",
      "Epoch 6048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5142 - accuracy: 0.0156 - val_loss: 131.9256 - val_accuracy: 0.0588\n",
      "Epoch 6049/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1929 - accuracy: 0.0156 - val_loss: 131.8705 - val_accuracy: 0.0588\n",
      "Epoch 6050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1034 - accuracy: 0.0000e+00 - val_loss: 137.7044 - val_accuracy: 0.0588\n",
      "Epoch 6051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0984 - accuracy: 0.0156 - val_loss: 140.1025 - val_accuracy: 0.0588\n",
      "Epoch 6052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2022 - accuracy: 0.0000e+00 - val_loss: 147.4531 - val_accuracy: 0.0588\n",
      "Epoch 6053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3002 - accuracy: 0.0156 - val_loss: 141.5139 - val_accuracy: 0.0000e+00\n",
      "Epoch 6054/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3896 - accuracy: 0.0000e+00 - val_loss: 136.3834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6055/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 46.3698 - accuracy: 0.0000e+00 - val_loss: 131.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9125 - accuracy: 0.0000e+00 - val_loss: 129.6370 - val_accuracy: 0.0000e+00\n",
      "Epoch 6057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4707 - accuracy: 0.0156 - val_loss: 129.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 6058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2056 - accuracy: 0.0469 - val_loss: 126.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 6059/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.9387 - accuracy: 0.0000e+00 - val_loss: 122.0270 - val_accuracy: 0.0000e+00\n",
      "Epoch 6060/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8481 - accuracy: 0.0156 - val_loss: 118.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0237 - accuracy: 0.0312 - val_loss: 121.1292 - val_accuracy: 0.0000e+00\n",
      "Epoch 6062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3922 - accuracy: 0.0156 - val_loss: 123.7410 - val_accuracy: 0.0000e+00\n",
      "Epoch 6063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7025 - accuracy: 0.0156 - val_loss: 119.6310 - val_accuracy: 0.0000e+00\n",
      "Epoch 6064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1292 - accuracy: 0.0000e+00 - val_loss: 124.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3990 - accuracy: 0.0469 - val_loss: 123.8653 - val_accuracy: 0.0000e+00\n",
      "Epoch 6066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9435 - accuracy: 0.0000e+00 - val_loss: 120.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 6067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9228 - accuracy: 0.0312 - val_loss: 129.5895 - val_accuracy: 0.0000e+00\n",
      "Epoch 6068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.1130 - accuracy: 0.0469 - val_loss: 135.2735 - val_accuracy: 0.0000e+00\n",
      "Epoch 6069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1395 - accuracy: 0.0000e+00 - val_loss: 123.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1311 - accuracy: 0.0000e+00 - val_loss: 111.2827 - val_accuracy: 0.0000e+00\n",
      "Epoch 6071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1373 - accuracy: 0.0000e+00 - val_loss: 106.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 6072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9110 - accuracy: 0.0156 - val_loss: 110.3728 - val_accuracy: 0.0000e+00\n",
      "Epoch 6073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2912 - accuracy: 0.0000e+00 - val_loss: 116.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 6074/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2099 - accuracy: 0.0156 - val_loss: 117.0453 - val_accuracy: 0.0000e+00\n",
      "Epoch 6075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7851 - accuracy: 0.0000e+00 - val_loss: 114.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 6076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5438 - accuracy: 0.0000e+00 - val_loss: 117.7660 - val_accuracy: 0.0000e+00\n",
      "Epoch 6077/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2731 - accuracy: 0.0000e+00 - val_loss: 125.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 6078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3826 - accuracy: 0.0156 - val_loss: 132.3068 - val_accuracy: 0.0000e+00\n",
      "Epoch 6079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2964 - accuracy: 0.0156 - val_loss: 130.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 6080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6209 - accuracy: 0.0156 - val_loss: 122.2012 - val_accuracy: 0.0000e+00\n",
      "Epoch 6081/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5439 - accuracy: 0.0000e+00 - val_loss: 118.6559 - val_accuracy: 0.0000e+00\n",
      "Epoch 6082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4589 - accuracy: 0.0000e+00 - val_loss: 122.8491 - val_accuracy: 0.0000e+00\n",
      "Epoch 6083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4692 - accuracy: 0.0000e+00 - val_loss: 130.2089 - val_accuracy: 0.0000e+00\n",
      "Epoch 6084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3338 - accuracy: 0.0000e+00 - val_loss: 131.1899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5074 - accuracy: 0.0156 - val_loss: 118.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 6086/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3788 - accuracy: 0.0000e+00 - val_loss: 111.3443 - val_accuracy: 0.0000e+00\n",
      "Epoch 6087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.6190 - accuracy: 0.0000e+00 - val_loss: 116.7742 - val_accuracy: 0.0588\n",
      "Epoch 6088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0051 - accuracy: 0.0156 - val_loss: 128.1568 - val_accuracy: 0.0588\n",
      "Epoch 6089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2890 - accuracy: 0.0156 - val_loss: 136.1527 - val_accuracy: 0.0588\n",
      "Epoch 6090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9170 - accuracy: 0.0000e+00 - val_loss: 124.8119 - val_accuracy: 0.0588\n",
      "Epoch 6091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8190 - accuracy: 0.0000e+00 - val_loss: 118.1565 - val_accuracy: 0.0588\n",
      "Epoch 6092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8339 - accuracy: 0.0000e+00 - val_loss: 115.2189 - val_accuracy: 0.1176\n",
      "Epoch 6093/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 49.2254 - accuracy: 0.0156 - val_loss: 113.8703 - val_accuracy: 0.1176\n",
      "Epoch 6094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1540 - accuracy: 0.0000e+00 - val_loss: 119.4498 - val_accuracy: 0.0000e+00\n",
      "Epoch 6095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5581 - accuracy: 0.0156 - val_loss: 129.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 6096/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7524 - accuracy: 0.0000e+00 - val_loss: 138.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 6097/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1696 - accuracy: 0.0000e+00 - val_loss: 147.9513 - val_accuracy: 0.0000e+00\n",
      "Epoch 6098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2001 - accuracy: 0.0156 - val_loss: 144.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 6099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5595 - accuracy: 0.0312 - val_loss: 132.2508 - val_accuracy: 0.0000e+00\n",
      "Epoch 6100/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 23.5110 - accuracy: 0.0156 - val_loss: 125.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 6101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8704 - accuracy: 0.0000e+00 - val_loss: 126.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6102/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4929 - accuracy: 0.0000e+00 - val_loss: 123.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 6103/10000\n",
      "64/64 [==============================] - 0s 169us/step - loss: 24.5787 - accuracy: 0.0156 - val_loss: 124.1997 - val_accuracy: 0.0000e+00\n",
      "Epoch 6104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8434 - accuracy: 0.0156 - val_loss: 127.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 6105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7239 - accuracy: 0.0000e+00 - val_loss: 122.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 6106/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.9091 - accuracy: 0.0000e+00 - val_loss: 118.1587 - val_accuracy: 0.0000e+00\n",
      "Epoch 6107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5103 - accuracy: 0.0469 - val_loss: 113.9692 - val_accuracy: 0.0000e+00\n",
      "Epoch 6108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0121 - accuracy: 0.0000e+00 - val_loss: 108.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4295 - accuracy: 0.0156 - val_loss: 104.1228 - val_accuracy: 0.0000e+00\n",
      "Epoch 6110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2170 - accuracy: 0.0000e+00 - val_loss: 105.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 6111/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6257 - accuracy: 0.0000e+00 - val_loss: 119.6617 - val_accuracy: 0.0000e+00\n",
      "Epoch 6112/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.6303 - accuracy: 0.0000e+00 - val_loss: 134.2003 - val_accuracy: 0.0000e+00\n",
      "Epoch 6113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6642 - accuracy: 0.0156 - val_loss: 136.6285 - val_accuracy: 0.0000e+00\n",
      "Epoch 6114/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2509 - accuracy: 0.0156 - val_loss: 131.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 6115/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 33.5140 - accuracy: 0.0000e+00 - val_loss: 125.3711 - val_accuracy: 0.0588\n",
      "Epoch 6116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7943 - accuracy: 0.0312 - val_loss: 122.1349 - val_accuracy: 0.0000e+00\n",
      "Epoch 6117/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9591 - accuracy: 0.0156 - val_loss: 119.3511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3906 - accuracy: 0.0000e+00 - val_loss: 125.7187 - val_accuracy: 0.0000e+00\n",
      "Epoch 6119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5823 - accuracy: 0.0000e+00 - val_loss: 131.0122 - val_accuracy: 0.0000e+00\n",
      "Epoch 6120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4463 - accuracy: 0.0156 - val_loss: 131.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 6121/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6390 - accuracy: 0.0000e+00 - val_loss: 128.7194 - val_accuracy: 0.0000e+00\n",
      "Epoch 6122/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3491 - accuracy: 0.0000e+00 - val_loss: 129.3833 - val_accuracy: 0.0000e+00\n",
      "Epoch 6123/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0646 - accuracy: 0.0000e+00 - val_loss: 132.8652 - val_accuracy: 0.0000e+00\n",
      "Epoch 6124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4719 - accuracy: 0.0000e+00 - val_loss: 130.9672 - val_accuracy: 0.0000e+00\n",
      "Epoch 6125/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 27.9312 - accuracy: 0.0000e+00 - val_loss: 130.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 6126/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.1571 - accuracy: 0.0156 - val_loss: 127.0422 - val_accuracy: 0.0000e+00\n",
      "Epoch 6127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7954 - accuracy: 0.0156 - val_loss: 127.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7660 - accuracy: 0.0000e+00 - val_loss: 138.5631 - val_accuracy: 0.0000e+00\n",
      "Epoch 6129/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2445 - accuracy: 0.0156 - val_loss: 144.9339 - val_accuracy: 0.0000e+00\n",
      "Epoch 6130/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.8080 - accuracy: 0.0156 - val_loss: 138.8811 - val_accuracy: 0.0000e+00\n",
      "Epoch 6131/10000\n",
      "64/64 [==============================] - 0s 204us/step - loss: 25.2684 - accuracy: 0.0000e+00 - val_loss: 139.6808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6132/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7091 - accuracy: 0.0156 - val_loss: 141.5906 - val_accuracy: 0.0588\n",
      "Epoch 6133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4858 - accuracy: 0.0156 - val_loss: 139.8093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6134/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 30.7099 - accuracy: 0.0156 - val_loss: 141.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 6135/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 39.6252 - accuracy: 0.0000e+00 - val_loss: 140.1349 - val_accuracy: 0.0588\n",
      "Epoch 6136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8815 - accuracy: 0.0156 - val_loss: 139.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6137/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 18.7181 - accuracy: 0.0000e+00 - val_loss: 134.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 6138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0392 - accuracy: 0.0000e+00 - val_loss: 127.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 6139/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 27.7053 - accuracy: 0.0156 - val_loss: 130.2597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6140/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 40.8239 - accuracy: 0.0000e+00 - val_loss: 132.3858 - val_accuracy: 0.0000e+00\n",
      "Epoch 6141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7762 - accuracy: 0.0156 - val_loss: 122.1370 - val_accuracy: 0.0000e+00\n",
      "Epoch 6142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5739 - accuracy: 0.0000e+00 - val_loss: 116.6593 - val_accuracy: 0.0000e+00\n",
      "Epoch 6143/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0535 - accuracy: 0.0156 - val_loss: 122.0375 - val_accuracy: 0.0000e+00\n",
      "Epoch 6144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0642 - accuracy: 0.0156 - val_loss: 129.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 6145/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4090 - accuracy: 0.0156 - val_loss: 135.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 6146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3583 - accuracy: 0.0156 - val_loss: 138.8111 - val_accuracy: 0.0000e+00\n",
      "Epoch 6147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6147 - accuracy: 0.0156 - val_loss: 143.1393 - val_accuracy: 0.0588\n",
      "Epoch 6148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8259 - accuracy: 0.0000e+00 - val_loss: 149.8855 - val_accuracy: 0.0588\n",
      "Epoch 6149/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5193 - accuracy: 0.0000e+00 - val_loss: 153.4155 - val_accuracy: 0.0588\n",
      "Epoch 6150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4304 - accuracy: 0.0156 - val_loss: 146.6185 - val_accuracy: 0.0588\n",
      "Epoch 6151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3981 - accuracy: 0.0156 - val_loss: 139.8076 - val_accuracy: 0.0000e+00\n",
      "Epoch 6152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9465 - accuracy: 0.0000e+00 - val_loss: 136.2490 - val_accuracy: 0.0000e+00\n",
      "Epoch 6153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6117 - accuracy: 0.0000e+00 - val_loss: 133.4063 - val_accuracy: 0.0000e+00\n",
      "Epoch 6154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6506 - accuracy: 0.0000e+00 - val_loss: 130.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 6155/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.2011 - accuracy: 0.0156 - val_loss: 119.8543 - val_accuracy: 0.0000e+00\n",
      "Epoch 6156/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.2292 - accuracy: 0.0000e+00 - val_loss: 109.3107 - val_accuracy: 0.0000e+00\n",
      "Epoch 6157/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 28.6857 - accuracy: 0.0156 - val_loss: 104.2760 - val_accuracy: 0.0000e+00\n",
      "Epoch 6158/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9055 - accuracy: 0.0000e+00 - val_loss: 115.7937 - val_accuracy: 0.0000e+00\n",
      "Epoch 6159/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2639 - accuracy: 0.0156 - val_loss: 136.3354 - val_accuracy: 0.0588\n",
      "Epoch 6160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9024 - accuracy: 0.0000e+00 - val_loss: 134.4537 - val_accuracy: 0.0000e+00\n",
      "Epoch 6161/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4746 - accuracy: 0.0156 - val_loss: 130.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 6162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.6373 - accuracy: 0.0000e+00 - val_loss: 136.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 6163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0737 - accuracy: 0.0000e+00 - val_loss: 140.9840 - val_accuracy: 0.0000e+00\n",
      "Epoch 6164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.1393 - accuracy: 0.0312 - val_loss: 138.8442 - val_accuracy: 0.0000e+00\n",
      "Epoch 6165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2039 - accuracy: 0.0156 - val_loss: 128.2823 - val_accuracy: 0.0000e+00\n",
      "Epoch 6166/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 26.2367 - accuracy: 0.0000e+00 - val_loss: 118.5918 - val_accuracy: 0.0000e+00\n",
      "Epoch 6167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8556 - accuracy: 0.0000e+00 - val_loss: 110.6814 - val_accuracy: 0.0000e+00\n",
      "Epoch 6168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6308 - accuracy: 0.0156 - val_loss: 116.0751 - val_accuracy: 0.0000e+00\n",
      "Epoch 6169/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2854 - accuracy: 0.0312 - val_loss: 129.7402 - val_accuracy: 0.0000e+00\n",
      "Epoch 6170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6056 - accuracy: 0.0156 - val_loss: 127.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 6171/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1215 - accuracy: 0.0000e+00 - val_loss: 126.8511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2169 - accuracy: 0.0000e+00 - val_loss: 129.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 6173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2509 - accuracy: 0.0156 - val_loss: 133.2887 - val_accuracy: 0.0588\n",
      "Epoch 6174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7212 - accuracy: 0.0156 - val_loss: 138.4267 - val_accuracy: 0.0588\n",
      "Epoch 6175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4330 - accuracy: 0.0000e+00 - val_loss: 142.5428 - val_accuracy: 0.0588\n",
      "Epoch 6176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9911 - accuracy: 0.0156 - val_loss: 145.2825 - val_accuracy: 0.0588\n",
      "Epoch 6177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6550 - accuracy: 0.0000e+00 - val_loss: 141.7472 - val_accuracy: 0.0588\n",
      "Epoch 6178/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1065 - accuracy: 0.0000e+00 - val_loss: 135.7541 - val_accuracy: 0.0000e+00\n",
      "Epoch 6179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5319 - accuracy: 0.0000e+00 - val_loss: 130.5166 - val_accuracy: 0.0588\n",
      "Epoch 6180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9031 - accuracy: 0.0156 - val_loss: 125.2691 - val_accuracy: 0.0588\n",
      "Epoch 6181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9229 - accuracy: 0.0156 - val_loss: 123.8322 - val_accuracy: 0.0588\n",
      "Epoch 6182/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.2928 - accuracy: 0.0000e+00 - val_loss: 120.1792 - val_accuracy: 0.0588\n",
      "Epoch 6183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3643 - accuracy: 0.0000e+00 - val_loss: 119.1690 - val_accuracy: 0.0000e+00\n",
      "Epoch 6184/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6462 - accuracy: 0.0156 - val_loss: 122.3863 - val_accuracy: 0.0000e+00\n",
      "Epoch 6185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9567 - accuracy: 0.0000e+00 - val_loss: 127.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 6186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5163 - accuracy: 0.0156 - val_loss: 131.2743 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6187/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2249 - accuracy: 0.0156 - val_loss: 134.5905 - val_accuracy: 0.0000e+00\n",
      "Epoch 6188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0399 - accuracy: 0.0156 - val_loss: 133.6086 - val_accuracy: 0.0000e+00\n",
      "Epoch 6189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9101 - accuracy: 0.0000e+00 - val_loss: 129.5122 - val_accuracy: 0.0000e+00\n",
      "Epoch 6190/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.1736 - accuracy: 0.0312 - val_loss: 133.3062 - val_accuracy: 0.0000e+00\n",
      "Epoch 6191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3140 - accuracy: 0.0156 - val_loss: 132.1621 - val_accuracy: 0.0000e+00\n",
      "Epoch 6192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4440 - accuracy: 0.0156 - val_loss: 132.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6193/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.5711 - accuracy: 0.0469 - val_loss: 133.7035 - val_accuracy: 0.0000e+00\n",
      "Epoch 6194/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2417 - accuracy: 0.0000e+00 - val_loss: 135.6129 - val_accuracy: 0.0588\n",
      "Epoch 6195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9704 - accuracy: 0.0000e+00 - val_loss: 132.4719 - val_accuracy: 0.0588\n",
      "Epoch 6196/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3786 - accuracy: 0.0312 - val_loss: 127.0475 - val_accuracy: 0.0588\n",
      "Epoch 6197/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0387 - accuracy: 0.0156 - val_loss: 121.5523 - val_accuracy: 0.0588\n",
      "Epoch 6198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4432 - accuracy: 0.0000e+00 - val_loss: 117.2311 - val_accuracy: 0.0000e+00\n",
      "Epoch 6199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.6650 - accuracy: 0.0000e+00 - val_loss: 118.8565 - val_accuracy: 0.0588\n",
      "Epoch 6200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1571 - accuracy: 0.0156 - val_loss: 123.0951 - val_accuracy: 0.0588\n",
      "Epoch 6201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7878 - accuracy: 0.0000e+00 - val_loss: 130.7173 - val_accuracy: 0.0588\n",
      "Epoch 6202/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 25.0092 - accuracy: 0.0156 - val_loss: 135.3593 - val_accuracy: 0.0588\n",
      "Epoch 6203/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9690 - accuracy: 0.0156 - val_loss: 136.9345 - val_accuracy: 0.0588\n",
      "Epoch 6204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9777 - accuracy: 0.0000e+00 - val_loss: 134.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 6205/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 28.3654 - accuracy: 0.0156 - val_loss: 128.4014 - val_accuracy: 0.0000e+00\n",
      "Epoch 6206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5315 - accuracy: 0.0156 - val_loss: 124.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 6207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4314 - accuracy: 0.0000e+00 - val_loss: 125.4305 - val_accuracy: 0.0000e+00\n",
      "Epoch 6208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0967 - accuracy: 0.0156 - val_loss: 131.5249 - val_accuracy: 0.0000e+00\n",
      "Epoch 6209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4894 - accuracy: 0.0000e+00 - val_loss: 135.0869 - val_accuracy: 0.0000e+00\n",
      "Epoch 6210/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8112 - accuracy: 0.0312 - val_loss: 141.1662 - val_accuracy: 0.0000e+00\n",
      "Epoch 6211/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0429 - accuracy: 0.0000e+00 - val_loss: 143.8469 - val_accuracy: 0.0000e+00\n",
      "Epoch 6212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5285 - accuracy: 0.0156 - val_loss: 141.4040 - val_accuracy: 0.0000e+00\n",
      "Epoch 6213/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0557 - accuracy: 0.0000e+00 - val_loss: 134.6184 - val_accuracy: 0.0000e+00\n",
      "Epoch 6214/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 36.2776 - accuracy: 0.0000e+00 - val_loss: 129.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 6215/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3423 - accuracy: 0.0000e+00 - val_loss: 136.1783 - val_accuracy: 0.0000e+00\n",
      "Epoch 6216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1905 - accuracy: 0.0156 - val_loss: 141.7177 - val_accuracy: 0.0000e+00\n",
      "Epoch 6217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0662 - accuracy: 0.0156 - val_loss: 151.3408 - val_accuracy: 0.0000e+00\n",
      "Epoch 6218/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6325 - accuracy: 0.0156 - val_loss: 153.5455 - val_accuracy: 0.0000e+00\n",
      "Epoch 6219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8348 - accuracy: 0.0000e+00 - val_loss: 139.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 6220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.7198 - accuracy: 0.0000e+00 - val_loss: 135.3772 - val_accuracy: 0.0588\n",
      "Epoch 6221/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.8018 - accuracy: 0.0000e+00 - val_loss: 139.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 6222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8529 - accuracy: 0.0000e+00 - val_loss: 142.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 6223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2285 - accuracy: 0.0156 - val_loss: 144.3042 - val_accuracy: 0.0000e+00\n",
      "Epoch 6224/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8870 - accuracy: 0.0156 - val_loss: 146.0549 - val_accuracy: 0.0000e+00\n",
      "Epoch 6225/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 34.6388 - accuracy: 0.0000e+0 - 0s 71us/step - loss: 32.1787 - accuracy: 0.0000e+00 - val_loss: 143.9372 - val_accuracy: 0.0000e+00\n",
      "Epoch 6226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0175 - accuracy: 0.0156 - val_loss: 142.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 6227/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0356 - accuracy: 0.0156 - val_loss: 142.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6228/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 24.4871 - accuracy: 0.0156 - val_loss: 141.3873 - val_accuracy: 0.0000e+00\n",
      "Epoch 6229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6286 - accuracy: 0.0000e+00 - val_loss: 137.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 6230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8037 - accuracy: 0.0156 - val_loss: 134.2704 - val_accuracy: 0.0588\n",
      "Epoch 6231/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9450 - accuracy: 0.0000e+00 - val_loss: 129.9285 - val_accuracy: 0.0588\n",
      "Epoch 6232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9774 - accuracy: 0.0000e+00 - val_loss: 123.4296 - val_accuracy: 0.0588\n",
      "Epoch 6233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6128 - accuracy: 0.0000e+00 - val_loss: 131.1332 - val_accuracy: 0.0588\n",
      "Epoch 6234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4975 - accuracy: 0.0000e+00 - val_loss: 141.2680 - val_accuracy: 0.0588\n",
      "Epoch 6235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7820 - accuracy: 0.0000e+00 - val_loss: 147.4174 - val_accuracy: 0.0588\n",
      "Epoch 6236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6586 - accuracy: 0.0156 - val_loss: 148.8269 - val_accuracy: 0.0588\n",
      "Epoch 6237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5255 - accuracy: 0.0000e+00 - val_loss: 137.7564 - val_accuracy: 0.0588\n",
      "Epoch 6238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3737 - accuracy: 0.0156 - val_loss: 131.4538 - val_accuracy: 0.0588\n",
      "Epoch 6239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4049 - accuracy: 0.0312 - val_loss: 123.6179 - val_accuracy: 0.0588\n",
      "Epoch 6240/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1888 - accuracy: 0.0156 - val_loss: 113.8193 - val_accuracy: 0.0588\n",
      "Epoch 6241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8680 - accuracy: 0.0000e+00 - val_loss: 112.1142 - val_accuracy: 0.0000e+00\n",
      "Epoch 6242/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.5847 - accuracy: 0.0000e+00 - val_loss: 118.2050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1864 - accuracy: 0.0156 - val_loss: 123.9043 - val_accuracy: 0.0000e+00\n",
      "Epoch 6244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9372 - accuracy: 0.0000e+00 - val_loss: 132.0853 - val_accuracy: 0.0000e+00\n",
      "Epoch 6245/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2161 - accuracy: 0.0000e+00 - val_loss: 143.9517 - val_accuracy: 0.0000e+00\n",
      "Epoch 6246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2175 - accuracy: 0.0156 - val_loss: 148.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 6247/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 26.0284 - accuracy: 0.0312 - val_loss: 143.8290 - val_accuracy: 0.0000e+00\n",
      "Epoch 6248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1560 - accuracy: 0.0156 - val_loss: 133.1198 - val_accuracy: 0.0000e+00\n",
      "Epoch 6249/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4810 - accuracy: 0.0312 - val_loss: 127.2404 - val_accuracy: 0.0000e+00\n",
      "Epoch 6250/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.7744 - accuracy: 0.0156 - val_loss: 126.5488 - val_accuracy: 0.0000e+00\n",
      "Epoch 6251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1288 - accuracy: 0.0000e+00 - val_loss: 132.8110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6370 - accuracy: 0.0000e+00 - val_loss: 141.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 6253/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7621 - accuracy: 0.0000e+00 - val_loss: 133.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 6254/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0364 - accuracy: 0.0156 - val_loss: 127.7561 - val_accuracy: 0.0000e+00\n",
      "Epoch 6255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6133 - accuracy: 0.0000e+00 - val_loss: 131.0003 - val_accuracy: 0.0000e+00\n",
      "Epoch 6256/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4205 - accuracy: 0.0000e+00 - val_loss: 135.1642 - val_accuracy: 0.0000e+00\n",
      "Epoch 6257/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 25.2417 - accuracy: 0.0312 - val_loss: 139.1132 - val_accuracy: 0.0588\n",
      "Epoch 6258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9267 - accuracy: 0.0000e+00 - val_loss: 135.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 6259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.1983 - accuracy: 0.0156 - val_loss: 128.9414 - val_accuracy: 0.0000e+00\n",
      "Epoch 6260/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0171 - accuracy: 0.0000e+00 - val_loss: 129.3735 - val_accuracy: 0.0000e+00\n",
      "Epoch 6261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3024 - accuracy: 0.0156 - val_loss: 131.2770 - val_accuracy: 0.0000e+00\n",
      "Epoch 6262/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8716 - accuracy: 0.0312 - val_loss: 127.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 6263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8206 - accuracy: 0.0156 - val_loss: 121.9806 - val_accuracy: 0.0000e+00\n",
      "Epoch 6264/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 20.2463 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 23.5119 - accuracy: 0.0156 - val_loss: 119.7208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0951 - accuracy: 0.0156 - val_loss: 125.2380 - val_accuracy: 0.0000e+00\n",
      "Epoch 6266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8441 - accuracy: 0.0000e+00 - val_loss: 129.4939 - val_accuracy: 0.0000e+00\n",
      "Epoch 6267/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 33.1964 - accuracy: 0.0312 - val_loss: 131.0999 - val_accuracy: 0.0000e+00\n",
      "Epoch 6268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4162 - accuracy: 0.0312 - val_loss: 141.4034 - val_accuracy: 0.0000e+00\n",
      "Epoch 6269/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4190 - accuracy: 0.0156 - val_loss: 140.9684 - val_accuracy: 0.0000e+00\n",
      "Epoch 6270/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 40.9014 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 29.7937 - accuracy: 0.0000e+00 - val_loss: 136.4017 - val_accuracy: 0.0000e+00\n",
      "Epoch 6271/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 33.9735 - accuracy: 0.0312 - val_loss: 137.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6272/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 31.7235 - accuracy: 0.0000e+00 - val_loss: 139.1439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8840 - accuracy: 0.0312 - val_loss: 144.1493 - val_accuracy: 0.0000e+00\n",
      "Epoch 6274/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 41.0406 - accuracy: 0.0000e+00 - val_loss: 133.2814 - val_accuracy: 0.0588\n",
      "Epoch 6275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9069 - accuracy: 0.0156 - val_loss: 124.0994 - val_accuracy: 0.0000e+00\n",
      "Epoch 6276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4025 - accuracy: 0.0156 - val_loss: 118.2847 - val_accuracy: 0.0000e+00\n",
      "Epoch 6277/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5309 - accuracy: 0.0000e+00 - val_loss: 119.5535 - val_accuracy: 0.0000e+00\n",
      "Epoch 6278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1399 - accuracy: 0.0156 - val_loss: 129.5460 - val_accuracy: 0.0000e+00\n",
      "Epoch 6279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7291 - accuracy: 0.0000e+00 - val_loss: 134.4908 - val_accuracy: 0.0588\n",
      "Epoch 6280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4093 - accuracy: 0.0000e+00 - val_loss: 131.8741 - val_accuracy: 0.0000e+00\n",
      "Epoch 6281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7757 - accuracy: 0.0312 - val_loss: 127.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 6282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3554 - accuracy: 0.0000e+00 - val_loss: 121.1213 - val_accuracy: 0.0000e+00\n",
      "Epoch 6283/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.4115 - accuracy: 0.0156 - val_loss: 115.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 6284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2872 - accuracy: 0.0156 - val_loss: 115.8730 - val_accuracy: 0.0588\n",
      "Epoch 6285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2922 - accuracy: 0.0312 - val_loss: 116.8123 - val_accuracy: 0.0000e+00\n",
      "Epoch 6286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0330 - accuracy: 0.0000e+00 - val_loss: 124.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1213 - accuracy: 0.0156 - val_loss: 131.8300 - val_accuracy: 0.0000e+00\n",
      "Epoch 6288/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3866 - accuracy: 0.0000e+00 - val_loss: 135.3479 - val_accuracy: 0.0000e+00\n",
      "Epoch 6289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2191 - accuracy: 0.0156 - val_loss: 138.5220 - val_accuracy: 0.0000e+00\n",
      "Epoch 6290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3406 - accuracy: 0.0000e+00 - val_loss: 136.8113 - val_accuracy: 0.0000e+00\n",
      "Epoch 6291/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 18.6987 - accuracy: 0.0000e+00 - val_loss: 133.6296 - val_accuracy: 0.0588\n",
      "Epoch 6292/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 22.8179 - accuracy: 0.0000e+00 - val_loss: 132.5002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7689 - accuracy: 0.0156 - val_loss: 132.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 6294/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8662 - accuracy: 0.0156 - val_loss: 132.4675 - val_accuracy: 0.0000e+00\n",
      "Epoch 6295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5718 - accuracy: 0.0156 - val_loss: 136.6009 - val_accuracy: 0.0000e+00\n",
      "Epoch 6296/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.5516 - accuracy: 0.0469 - val_loss: 141.7700 - val_accuracy: 0.0000e+00\n",
      "Epoch 6297/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.7473 - accuracy: 0.0000e+00 - val_loss: 138.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 6298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4704 - accuracy: 0.0156 - val_loss: 133.8073 - val_accuracy: 0.0588\n",
      "Epoch 6299/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 17.0576 - accuracy: 0.0000e+00 - val_loss: 120.5682 - val_accuracy: 0.0588\n",
      "Epoch 6300/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 25.6630 - accuracy: 0.0469 - val_loss: 110.3660 - val_accuracy: 0.0588\n",
      "Epoch 6301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3084 - accuracy: 0.0312 - val_loss: 111.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 6302/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 28.7448 - accuracy: 0.0000e+00 - val_loss: 123.0644 - val_accuracy: 0.0000e+00\n",
      "Epoch 6303/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 28.1414 - accuracy: 0.0156 - val_loss: 138.2211 - val_accuracy: 0.0588\n",
      "Epoch 6304/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 19.4018 - accuracy: 0.0000e+00 - val_loss: 145.6786 - val_accuracy: 0.0000e+00\n",
      "Epoch 6305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1951 - accuracy: 0.0000e+00 - val_loss: 144.8305 - val_accuracy: 0.0000e+00\n",
      "Epoch 6306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1341 - accuracy: 0.0000e+00 - val_loss: 134.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6307/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7782 - accuracy: 0.0156 - val_loss: 128.0253 - val_accuracy: 0.0588\n",
      "Epoch 6308/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2620 - accuracy: 0.0156 - val_loss: 119.1688 - val_accuracy: 0.0588\n",
      "Epoch 6309/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4205 - accuracy: 0.0000e+00 - val_loss: 116.2914 - val_accuracy: 0.0588\n",
      "Epoch 6310/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 21.6191 - accuracy: 0.0156 - val_loss: 121.3847 - val_accuracy: 0.0000e+00\n",
      "Epoch 6311/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 21.6151 - accuracy: 0.0156 - val_loss: 134.0473 - val_accuracy: 0.0000e+00\n",
      "Epoch 6312/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6568 - accuracy: 0.0156 - val_loss: 147.4208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6313/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 44.0446 - accuracy: 0.0000e+00 - val_loss: 143.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 6314/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5398 - accuracy: 0.0156 - val_loss: 135.2952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6315/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 20.9024 - accuracy: 0.0312 - val_loss: 130.1677 - val_accuracy: 0.0000e+00\n",
      "Epoch 6316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7213 - accuracy: 0.0312 - val_loss: 129.0818 - val_accuracy: 0.0000e+00\n",
      "Epoch 6317/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3350 - accuracy: 0.0156 - val_loss: 129.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 6318/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 18.1441 - accuracy: 0.0000e+00 - val_loss: 132.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 6319/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9845 - accuracy: 0.0000e+00 - val_loss: 132.9858 - val_accuracy: 0.0000e+00\n",
      "Epoch 6320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0234 - accuracy: 0.0000e+00 - val_loss: 133.2406 - val_accuracy: 0.0000e+00\n",
      "Epoch 6321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4325 - accuracy: 0.0000e+00 - val_loss: 140.2936 - val_accuracy: 0.0000e+00\n",
      "Epoch 6322/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 28.2634 - accuracy: 0.0156 - val_loss: 144.7985 - val_accuracy: 0.0000e+00\n",
      "Epoch 6323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8867 - accuracy: 0.0156 - val_loss: 149.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 6324/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9641 - accuracy: 0.0000e+00 - val_loss: 152.9138 - val_accuracy: 0.0588\n",
      "Epoch 6325/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 21.2882 - accuracy: 0.0312 - val_loss: 148.3446 - val_accuracy: 0.0588\n",
      "Epoch 6326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3577 - accuracy: 0.0156 - val_loss: 144.0157 - val_accuracy: 0.0588\n",
      "Epoch 6327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3861 - accuracy: 0.0312 - val_loss: 139.9483 - val_accuracy: 0.0588\n",
      "Epoch 6328/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4032 - accuracy: 0.0156 - val_loss: 137.7457 - val_accuracy: 0.0588\n",
      "Epoch 6329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9289 - accuracy: 0.0156 - val_loss: 134.4517 - val_accuracy: 0.0588\n",
      "Epoch 6330/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5774 - accuracy: 0.0156 - val_loss: 131.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 6331/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5438 - accuracy: 0.0000e+00 - val_loss: 133.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 6332/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8300 - accuracy: 0.0000e+00 - val_loss: 128.7633 - val_accuracy: 0.0000e+00\n",
      "Epoch 6333/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 21.6645 - accuracy: 0.0156 - val_loss: 121.5928 - val_accuracy: 0.0000e+00\n",
      "Epoch 6334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3614 - accuracy: 0.0000e+00 - val_loss: 120.4880 - val_accuracy: 0.0000e+00\n",
      "Epoch 6335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7722 - accuracy: 0.0156 - val_loss: 115.8872 - val_accuracy: 0.0000e+00\n",
      "Epoch 6336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5334 - accuracy: 0.0156 - val_loss: 112.9644 - val_accuracy: 0.0000e+00\n",
      "Epoch 6337/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.1427 - accuracy: 0.0156 - val_loss: 116.4890 - val_accuracy: 0.0000e+00\n",
      "Epoch 6338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.8685 - accuracy: 0.0156 - val_loss: 125.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 6339/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 37.3265 - accuracy: 0.0000e+00 - val_loss: 141.6861 - val_accuracy: 0.0000e+00\n",
      "Epoch 6340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2541 - accuracy: 0.0156 - val_loss: 148.5052 - val_accuracy: 0.0000e+00\n",
      "Epoch 6341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3886 - accuracy: 0.0156 - val_loss: 151.1312 - val_accuracy: 0.0588\n",
      "Epoch 6342/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.3268 - accuracy: 0.0156 - val_loss: 146.9067 - val_accuracy: 0.0000e+00\n",
      "Epoch 6343/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 26.1055 - accuracy: 0.0000e+00 - val_loss: 139.9932 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6344/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7332 - accuracy: 0.0156 - val_loss: 136.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6464 - accuracy: 0.0156 - val_loss: 136.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 6346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5027 - accuracy: 0.0000e+00 - val_loss: 136.4689 - val_accuracy: 0.0000e+00\n",
      "Epoch 6347/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1924 - accuracy: 0.0000e+00 - val_loss: 131.4785 - val_accuracy: 0.0000e+00\n",
      "Epoch 6348/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4119 - accuracy: 0.0000e+00 - val_loss: 123.5000 - val_accuracy: 0.0588\n",
      "Epoch 6349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5190 - accuracy: 0.0000e+00 - val_loss: 118.9842 - val_accuracy: 0.0588\n",
      "Epoch 6350/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 23.6254 - accuracy: 0.0000e+00 - val_loss: 128.2396 - val_accuracy: 0.0588\n",
      "Epoch 6351/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3869 - accuracy: 0.0000e+00 - val_loss: 139.5653 - val_accuracy: 0.0588\n",
      "Epoch 6352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7857 - accuracy: 0.0312 - val_loss: 136.5016 - val_accuracy: 0.0000e+00\n",
      "Epoch 6353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3136 - accuracy: 0.0156 - val_loss: 131.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 6354/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0867 - accuracy: 0.0312 - val_loss: 128.3208 - val_accuracy: 0.0000e+00\n",
      "Epoch 6355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5853 - accuracy: 0.0000e+00 - val_loss: 130.8766 - val_accuracy: 0.0000e+00\n",
      "Epoch 6356/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.3160 - accuracy: 0.0156 - val_loss: 140.1356 - val_accuracy: 0.0000e+00\n",
      "Epoch 6357/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4838 - accuracy: 0.0000e+00 - val_loss: 152.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 6358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2402 - accuracy: 0.0156 - val_loss: 153.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 6359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4370 - accuracy: 0.0156 - val_loss: 137.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 6360/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 23.4686 - accuracy: 0.062 - 0s 62us/step - loss: 24.1868 - accuracy: 0.0312 - val_loss: 121.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 6361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1400 - accuracy: 0.0000e+00 - val_loss: 118.9474 - val_accuracy: 0.0000e+00\n",
      "Epoch 6362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1480 - accuracy: 0.0000e+00 - val_loss: 117.9290 - val_accuracy: 0.0000e+00\n",
      "Epoch 6363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0760 - accuracy: 0.0156 - val_loss: 125.3928 - val_accuracy: 0.0588\n",
      "Epoch 6364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9261 - accuracy: 0.0156 - val_loss: 131.7847 - val_accuracy: 0.0588\n",
      "Epoch 6365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4263 - accuracy: 0.0156 - val_loss: 130.5753 - val_accuracy: 0.0588\n",
      "Epoch 6366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 46.6130 - accuracy: 0.0156 - val_loss: 123.9012 - val_accuracy: 0.0588\n",
      "Epoch 6367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3636 - accuracy: 0.0000e+00 - val_loss: 121.2479 - val_accuracy: 0.0588\n",
      "Epoch 6368/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.1752 - accuracy: 0.0000e+00 - val_loss: 116.4048 - val_accuracy: 0.0588\n",
      "Epoch 6369/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.4011 - accuracy: 0.0000e+00 - val_loss: 115.6035 - val_accuracy: 0.0588\n",
      "Epoch 6370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6097 - accuracy: 0.0312 - val_loss: 125.1321 - val_accuracy: 0.0588\n",
      "Epoch 6371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2262 - accuracy: 0.0156 - val_loss: 135.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 6372/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8558 - accuracy: 0.0312 - val_loss: 136.8743 - val_accuracy: 0.0000e+00\n",
      "Epoch 6373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1369 - accuracy: 0.0156 - val_loss: 132.7395 - val_accuracy: 0.0000e+00\n",
      "Epoch 6374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9830 - accuracy: 0.0000e+00 - val_loss: 131.5211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6375/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 21.8868 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 36.7507 - accuracy: 0.0000e+00 - val_loss: 137.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0241 - accuracy: 0.0156 - val_loss: 141.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 6377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1627 - accuracy: 0.0312 - val_loss: 145.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 6378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7169 - accuracy: 0.0000e+00 - val_loss: 147.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 6379/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7301 - accuracy: 0.0156 - val_loss: 142.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 6380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0322 - accuracy: 0.0000e+00 - val_loss: 138.6650 - val_accuracy: 0.0000e+00\n",
      "Epoch 6381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2264 - accuracy: 0.0156 - val_loss: 131.4320 - val_accuracy: 0.0000e+00\n",
      "Epoch 6382/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0169 - accuracy: 0.0000e+00 - val_loss: 129.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 6383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5092 - accuracy: 0.0000e+00 - val_loss: 130.2993 - val_accuracy: 0.0000e+00\n",
      "Epoch 6384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2404 - accuracy: 0.0156 - val_loss: 131.2059 - val_accuracy: 0.0000e+00\n",
      "Epoch 6385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8855 - accuracy: 0.0156 - val_loss: 131.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6386/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 22.5191 - accuracy: 0.0156 - val_loss: 129.1133 - val_accuracy: 0.0000e+00\n",
      "Epoch 6387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9749 - accuracy: 0.0312 - val_loss: 121.2358 - val_accuracy: 0.0000e+00\n",
      "Epoch 6388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5326 - accuracy: 0.0156 - val_loss: 115.1540 - val_accuracy: 0.0000e+00\n",
      "Epoch 6389/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 31.4248 - accuracy: 0.0000e+00 - val_loss: 119.7659 - val_accuracy: 0.0588\n",
      "Epoch 6390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.9813 - accuracy: 0.0000e+00 - val_loss: 130.7160 - val_accuracy: 0.0588\n",
      "Epoch 6391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9201 - accuracy: 0.0156 - val_loss: 138.9698 - val_accuracy: 0.0588\n",
      "Epoch 6392/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2921 - accuracy: 0.0000e+00 - val_loss: 145.4462 - val_accuracy: 0.0588\n",
      "Epoch 6393/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0101 - accuracy: 0.0156 - val_loss: 150.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 6394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2538 - accuracy: 0.0000e+00 - val_loss: 154.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 6395/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 40.3365 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 28.1320 - accuracy: 0.0000e+00 - val_loss: 150.9560 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6396/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 25.1577 - accuracy: 0.0156 - val_loss: 140.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 6397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2444 - accuracy: 0.0000e+00 - val_loss: 133.1720 - val_accuracy: 0.0000e+00\n",
      "Epoch 6398/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7257 - accuracy: 0.0156 - val_loss: 132.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 6399/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8903 - accuracy: 0.0000e+00 - val_loss: 129.3211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7327 - accuracy: 0.0000e+00 - val_loss: 130.2462 - val_accuracy: 0.0000e+00\n",
      "Epoch 6401/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 22.3030 - accuracy: 0.0000e+00 - val_loss: 131.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 6402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8516 - accuracy: 0.0156 - val_loss: 130.7796 - val_accuracy: 0.0000e+00\n",
      "Epoch 6403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9662 - accuracy: 0.0000e+00 - val_loss: 131.1374 - val_accuracy: 0.0000e+00\n",
      "Epoch 6404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3227 - accuracy: 0.0000e+00 - val_loss: 132.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3838 - accuracy: 0.0156 - val_loss: 125.4676 - val_accuracy: 0.0000e+00\n",
      "Epoch 6406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0607 - accuracy: 0.0156 - val_loss: 122.9762 - val_accuracy: 0.0000e+00\n",
      "Epoch 6407/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 25.4281 - accuracy: 0.0000e+00 - val_loss: 123.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 6408/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6922 - accuracy: 0.0000e+00 - val_loss: 131.1508 - val_accuracy: 0.0588\n",
      "Epoch 6409/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6412 - accuracy: 0.0156 - val_loss: 141.4328 - val_accuracy: 0.0588\n",
      "Epoch 6410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5379 - accuracy: 0.0156 - val_loss: 138.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 6411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6418 - accuracy: 0.0312 - val_loss: 138.6661 - val_accuracy: 0.0000e+00\n",
      "Epoch 6412/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6859 - accuracy: 0.0000e+00 - val_loss: 141.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 6413/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 37.3466 - accuracy: 0.0000e+00 - val_loss: 140.3952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6414/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6748 - accuracy: 0.0000e+00 - val_loss: 137.9754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6415/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3437 - accuracy: 0.0156 - val_loss: 139.4471 - val_accuracy: 0.0000e+00\n",
      "Epoch 6416/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.3222 - accuracy: 0.0000e+00 - val_loss: 142.0417 - val_accuracy: 0.0588\n",
      "Epoch 6417/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 32.0655 - accuracy: 0.0469 - val_loss: 139.0011 - val_accuracy: 0.0588\n",
      "Epoch 6418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5680 - accuracy: 0.0312 - val_loss: 137.0087 - val_accuracy: 0.0588\n",
      "Epoch 6419/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.5249 - accuracy: 0.0156 - val_loss: 130.1246 - val_accuracy: 0.0588\n",
      "Epoch 6420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4446 - accuracy: 0.0312 - val_loss: 126.6711 - val_accuracy: 0.0000e+00\n",
      "Epoch 6421/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 28.2366 - accuracy: 0.0156 - val_loss: 127.3399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6422/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2714 - accuracy: 0.0156 - val_loss: 128.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 6423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1549 - accuracy: 0.0312 - val_loss: 129.1902 - val_accuracy: 0.0000e+00\n",
      "Epoch 6424/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 26.8213 - accuracy: 0.0156 - val_loss: 127.7427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6425/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 26.5917 - accuracy: 0.0156 - val_loss: 130.3834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6426/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.3609 - accuracy: 0.0156 - val_loss: 137.3082 - val_accuracy: 0.0000e+00\n",
      "Epoch 6427/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1906 - accuracy: 0.0156 - val_loss: 147.8507 - val_accuracy: 0.0000e+00\n",
      "Epoch 6428/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 24.3518 - accuracy: 0.0469 - val_loss: 143.7916 - val_accuracy: 0.0000e+00\n",
      "Epoch 6429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4289 - accuracy: 0.0156 - val_loss: 130.8197 - val_accuracy: 0.0588\n",
      "Epoch 6430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1288 - accuracy: 0.0000e+00 - val_loss: 124.9773 - val_accuracy: 0.0588\n",
      "Epoch 6431/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0028 - accuracy: 0.0000e+00 - val_loss: 131.0533 - val_accuracy: 0.0588\n",
      "Epoch 6432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2664 - accuracy: 0.0156 - val_loss: 136.4717 - val_accuracy: 0.0588\n",
      "Epoch 6433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6909 - accuracy: 0.0156 - val_loss: 136.5438 - val_accuracy: 0.0588\n",
      "Epoch 6434/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7695 - accuracy: 0.0000e+00 - val_loss: 132.0491 - val_accuracy: 0.0588\n",
      "Epoch 6435/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.4853 - accuracy: 0.0156 - val_loss: 125.5450 - val_accuracy: 0.0588\n",
      "Epoch 6436/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.8134 - accuracy: 0.0000e+00 - val_loss: 120.4710 - val_accuracy: 0.0000e+00\n",
      "Epoch 6437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3754 - accuracy: 0.0156 - val_loss: 118.1305 - val_accuracy: 0.0588\n",
      "Epoch 6438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4367 - accuracy: 0.0000e+00 - val_loss: 117.9733 - val_accuracy: 0.0000e+00\n",
      "Epoch 6439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2509 - accuracy: 0.0000e+00 - val_loss: 126.3151 - val_accuracy: 0.0000e+00\n",
      "Epoch 6440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6503 - accuracy: 0.0156 - val_loss: 136.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 6441/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.9891 - accuracy: 0.0000e+00 - val_loss: 137.0962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4147 - accuracy: 0.0000e+00 - val_loss: 134.0193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6967 - accuracy: 0.0000e+00 - val_loss: 127.8109 - val_accuracy: 0.0000e+00\n",
      "Epoch 6444/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 28.4973 - accuracy: 0.0000e+00 - val_loss: 123.3439 - val_accuracy: 0.0000e+00\n",
      "Epoch 6445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0725 - accuracy: 0.0156 - val_loss: 122.4096 - val_accuracy: 0.0000e+00\n",
      "Epoch 6446/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.3354 - accuracy: 0.0000e+00 - val_loss: 123.8870 - val_accuracy: 0.0000e+00\n",
      "Epoch 6447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7687 - accuracy: 0.0000e+00 - val_loss: 129.5914 - val_accuracy: 0.0000e+00\n",
      "Epoch 6448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0781 - accuracy: 0.0156 - val_loss: 134.6084 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4306 - accuracy: 0.0156 - val_loss: 132.1494 - val_accuracy: 0.0000e+00\n",
      "Epoch 6450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3074 - accuracy: 0.0000e+00 - val_loss: 139.4897 - val_accuracy: 0.0000e+00\n",
      "Epoch 6451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9073 - accuracy: 0.0000e+00 - val_loss: 138.8446 - val_accuracy: 0.0000e+00\n",
      "Epoch 6452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3122 - accuracy: 0.0156 - val_loss: 136.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 6453/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3219 - accuracy: 0.0156 - val_loss: 134.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 6454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9417 - accuracy: 0.0312 - val_loss: 133.3149 - val_accuracy: 0.0000e+00\n",
      "Epoch 6455/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1602 - accuracy: 0.0000e+00 - val_loss: 139.2307 - val_accuracy: 0.0000e+00\n",
      "Epoch 6456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3594 - accuracy: 0.0156 - val_loss: 143.6522 - val_accuracy: 0.0000e+00\n",
      "Epoch 6457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1984 - accuracy: 0.0000e+00 - val_loss: 142.2979 - val_accuracy: 0.0000e+00\n",
      "Epoch 6458/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5634 - accuracy: 0.0000e+00 - val_loss: 134.8245 - val_accuracy: 0.0000e+00\n",
      "Epoch 6459/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 20.5655 - accuracy: 0.0000e+00 - val_loss: 133.1835 - val_accuracy: 0.0000e+00\n",
      "Epoch 6460/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.4430 - accuracy: 0.0000e+00 - val_loss: 134.2225 - val_accuracy: 0.0000e+00\n",
      "Epoch 6461/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8710 - accuracy: 0.0000e+00 - val_loss: 134.5457 - val_accuracy: 0.0000e+00\n",
      "Epoch 6462/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.7288 - accuracy: 0.0000e+00 - val_loss: 139.0667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4387 - accuracy: 0.0156 - val_loss: 143.3215 - val_accuracy: 0.0000e+00\n",
      "Epoch 6464/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.9229 - accuracy: 0.0156 - val_loss: 139.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 6465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9937 - accuracy: 0.0156 - val_loss: 130.8538 - val_accuracy: 0.0000e+00\n",
      "Epoch 6466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1725 - accuracy: 0.0156 - val_loss: 126.9425 - val_accuracy: 0.0000e+00\n",
      "Epoch 6467/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3491 - accuracy: 0.0469 - val_loss: 129.4053 - val_accuracy: 0.0000e+00\n",
      "Epoch 6468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6647 - accuracy: 0.0156 - val_loss: 133.0852 - val_accuracy: 0.0000e+00\n",
      "Epoch 6469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3235 - accuracy: 0.0312 - val_loss: 141.8056 - val_accuracy: 0.0588\n",
      "Epoch 6470/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 27.9689 - accuracy: 0.0000e+00 - val_loss: 145.8983 - val_accuracy: 0.0000e+00\n",
      "Epoch 6471/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.8109 - accuracy: 0.0000e+00 - val_loss: 141.0129 - val_accuracy: 0.0588\n",
      "Epoch 6472/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8557 - accuracy: 0.0000e+00 - val_loss: 127.0311 - val_accuracy: 0.0588\n",
      "Epoch 6473/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7062 - accuracy: 0.0000e+00 - val_loss: 113.6875 - val_accuracy: 0.0588\n",
      "Epoch 6474/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 19.5784 - accuracy: 0.0156 - val_loss: 116.1086 - val_accuracy: 0.0588\n",
      "Epoch 6475/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6546 - accuracy: 0.0156 - val_loss: 126.6429 - val_accuracy: 0.0588\n",
      "Epoch 6476/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.2203 - accuracy: 0.0156 - val_loss: 128.1016 - val_accuracy: 0.0588\n",
      "Epoch 6477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2186 - accuracy: 0.0000e+00 - val_loss: 124.5188 - val_accuracy: 0.0588\n",
      "Epoch 6478/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7882 - accuracy: 0.0156 - val_loss: 128.0824 - val_accuracy: 0.0588\n",
      "Epoch 6479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0429 - accuracy: 0.0312 - val_loss: 131.4419 - val_accuracy: 0.0588\n",
      "Epoch 6480/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.4595 - accuracy: 0.0156 - val_loss: 130.5482 - val_accuracy: 0.0000e+00\n",
      "Epoch 6481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2030 - accuracy: 0.0000e+00 - val_loss: 137.9704 - val_accuracy: 0.0000e+00\n",
      "Epoch 6482/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 17.9913 - accuracy: 0.0312 - val_loss: 138.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 6483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0348 - accuracy: 0.0000e+00 - val_loss: 145.2126 - val_accuracy: 0.0000e+00\n",
      "Epoch 6484/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9967 - accuracy: 0.0000e+00 - val_loss: 147.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 6485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3187 - accuracy: 0.0000e+00 - val_loss: 147.5664 - val_accuracy: 0.0000e+00\n",
      "Epoch 6486/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.5588 - accuracy: 0.0000e+00 - val_loss: 149.1830 - val_accuracy: 0.0000e+00\n",
      "Epoch 6487/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 34.5062 - accuracy: 0.0000e+00 - val_loss: 145.1346 - val_accuracy: 0.0588\n",
      "Epoch 6488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7954 - accuracy: 0.0000e+00 - val_loss: 138.1271 - val_accuracy: 0.1176\n",
      "Epoch 6489/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4290 - accuracy: 0.0156 - val_loss: 128.5827 - val_accuracy: 0.0588\n",
      "Epoch 6490/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 20.2938 - accuracy: 0.0156 - val_loss: 120.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 6491/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 45.8426 - accuracy: 0.0156 - val_loss: 120.2976 - val_accuracy: 0.0588\n",
      "Epoch 6492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1802 - accuracy: 0.0000e+00 - val_loss: 119.0464 - val_accuracy: 0.0588\n",
      "Epoch 6493/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 30.7036 - accuracy: 0.0000e+00 - val_loss: 119.1038 - val_accuracy: 0.0000e+00\n",
      "Epoch 6494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5985 - accuracy: 0.0000e+00 - val_loss: 128.1271 - val_accuracy: 0.0000e+00\n",
      "Epoch 6495/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8378 - accuracy: 0.0000e+00 - val_loss: 128.9803 - val_accuracy: 0.0000e+00\n",
      "Epoch 6496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4039 - accuracy: 0.0156 - val_loss: 127.6621 - val_accuracy: 0.0000e+00\n",
      "Epoch 6497/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5940 - accuracy: 0.0469 - val_loss: 123.0695 - val_accuracy: 0.0000e+00\n",
      "Epoch 6498/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2688 - accuracy: 0.0156 - val_loss: 129.3790 - val_accuracy: 0.0000e+00\n",
      "Epoch 6499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6111 - accuracy: 0.0156 - val_loss: 132.7848 - val_accuracy: 0.0000e+00\n",
      "Epoch 6500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7571 - accuracy: 0.0156 - val_loss: 136.6911 - val_accuracy: 0.0588\n",
      "Epoch 6501/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9192 - accuracy: 0.0000e+00 - val_loss: 137.8642 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6502/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1031 - accuracy: 0.0156 - val_loss: 139.6928 - val_accuracy: 0.0588\n",
      "Epoch 6503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5810 - accuracy: 0.0000e+00 - val_loss: 139.9901 - val_accuracy: 0.0000e+00\n",
      "Epoch 6504/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2965 - accuracy: 0.0000e+00 - val_loss: 135.0807 - val_accuracy: 0.0588\n",
      "Epoch 6505/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.3920 - accuracy: 0.0156 - val_loss: 133.1392 - val_accuracy: 0.0588\n",
      "Epoch 6506/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9158 - accuracy: 0.0156 - val_loss: 130.4741 - val_accuracy: 0.0588\n",
      "Epoch 6507/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.5755 - accuracy: 0.0312 - val_loss: 131.0679 - val_accuracy: 0.0000e+00\n",
      "Epoch 6508/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 33.6647 - accuracy: 0.0156 - val_loss: 127.8510 - val_accuracy: 0.0000e+00\n",
      "Epoch 6509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7276 - accuracy: 0.0156 - val_loss: 126.6484 - val_accuracy: 0.0000e+00\n",
      "Epoch 6510/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 24.8918 - accuracy: 0.0000e+00 - val_loss: 124.3824 - val_accuracy: 0.0000e+00\n",
      "Epoch 6511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1458 - accuracy: 0.0156 - val_loss: 122.6761 - val_accuracy: 0.0000e+00\n",
      "Epoch 6512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4359 - accuracy: 0.0000e+00 - val_loss: 120.2693 - val_accuracy: 0.0000e+00\n",
      "Epoch 6513/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.0501 - accuracy: 0.0000e+00 - val_loss: 124.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 6514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7635 - accuracy: 0.0000e+00 - val_loss: 135.7040 - val_accuracy: 0.0000e+00\n",
      "Epoch 6515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0834 - accuracy: 0.0000e+00 - val_loss: 146.7657 - val_accuracy: 0.0000e+00\n",
      "Epoch 6516/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4583 - accuracy: 0.0312 - val_loss: 148.7324 - val_accuracy: 0.0588\n",
      "Epoch 6517/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0190 - accuracy: 0.0156 - val_loss: 147.0313 - val_accuracy: 0.0588\n",
      "Epoch 6518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9434 - accuracy: 0.0156 - val_loss: 137.2259 - val_accuracy: 0.0588\n",
      "Epoch 6519/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.8857 - accuracy: 0.0156 - val_loss: 125.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 6520/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4623 - accuracy: 0.0000e+00 - val_loss: 118.9338 - val_accuracy: 0.0000e+00\n",
      "Epoch 6521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7817 - accuracy: 0.0000e+00 - val_loss: 116.8208 - val_accuracy: 0.0588\n",
      "Epoch 6522/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.9977 - accuracy: 0.0000e+00 - val_loss: 121.2039 - val_accuracy: 0.0588\n",
      "Epoch 6523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2816 - accuracy: 0.0156 - val_loss: 127.4878 - val_accuracy: 0.0588\n",
      "Epoch 6524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.2090 - accuracy: 0.0000e+00 - val_loss: 126.1330 - val_accuracy: 0.0000e+00\n",
      "Epoch 6525/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2930 - accuracy: 0.0000e+00 - val_loss: 128.9589 - val_accuracy: 0.0000e+00\n",
      "Epoch 6526/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0161 - accuracy: 0.0312 - val_loss: 133.2445 - val_accuracy: 0.0000e+00\n",
      "Epoch 6527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5260 - accuracy: 0.0000e+00 - val_loss: 128.9661 - val_accuracy: 0.0588\n",
      "Epoch 6528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0178 - accuracy: 0.0000e+00 - val_loss: 128.4819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6529/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8522 - accuracy: 0.0000e+00 - val_loss: 133.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 6530/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 22.9082 - accuracy: 0.0000e+00 - val_loss: 134.1805 - val_accuracy: 0.0588\n",
      "Epoch 6531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5466 - accuracy: 0.0156 - val_loss: 130.3922 - val_accuracy: 0.0588\n",
      "Epoch 6532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4051 - accuracy: 0.0156 - val_loss: 129.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 6533/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.6054 - accuracy: 0.0156 - val_loss: 130.3489 - val_accuracy: 0.0000e+00\n",
      "Epoch 6534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7043 - accuracy: 0.0156 - val_loss: 129.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 6535/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.1340 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 26.8182 - accuracy: 0.0000e+00 - val_loss: 122.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 6536/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.0194 - accuracy: 0.0312 - val_loss: 117.4810 - val_accuracy: 0.0000e+00\n",
      "Epoch 6537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8744 - accuracy: 0.0156 - val_loss: 119.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 6538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2318 - accuracy: 0.0000e+00 - val_loss: 119.0809 - val_accuracy: 0.0000e+00\n",
      "Epoch 6539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1347 - accuracy: 0.0156 - val_loss: 113.4674 - val_accuracy: 0.0588\n",
      "Epoch 6540/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 32.0994 - accuracy: 0.0156 - val_loss: 113.5701 - val_accuracy: 0.0588\n",
      "Epoch 6541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9184 - accuracy: 0.0156 - val_loss: 117.2731 - val_accuracy: 0.0588\n",
      "Epoch 6542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2871 - accuracy: 0.0000e+00 - val_loss: 117.2167 - val_accuracy: 0.0588\n",
      "Epoch 6543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4223 - accuracy: 0.0156 - val_loss: 120.9397 - val_accuracy: 0.0000e+00\n",
      "Epoch 6544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.3016 - accuracy: 0.0000e+00 - val_loss: 122.2645 - val_accuracy: 0.0000e+00\n",
      "Epoch 6545/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6769 - accuracy: 0.0000e+00 - val_loss: 122.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 6546/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9434 - accuracy: 0.0000e+00 - val_loss: 119.5913 - val_accuracy: 0.0588\n",
      "Epoch 6547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1644 - accuracy: 0.0000e+00 - val_loss: 117.6911 - val_accuracy: 0.0000e+00\n",
      "Epoch 6548/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.4746 - accuracy: 0.0312 - val_loss: 116.2925 - val_accuracy: 0.0000e+00\n",
      "Epoch 6549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6017 - accuracy: 0.0156 - val_loss: 117.5210 - val_accuracy: 0.0588\n",
      "Epoch 6550/10000\n",
      "64/64 [==============================] - 0s 173us/step - loss: 23.1931 - accuracy: 0.0312 - val_loss: 124.7562 - val_accuracy: 0.0000e+00\n",
      "Epoch 6551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8428 - accuracy: 0.0312 - val_loss: 129.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 6552/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 24.6077 - accuracy: 0.0000e+00 - val_loss: 133.1546 - val_accuracy: 0.0000e+00\n",
      "Epoch 6553/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 31.6085 - accuracy: 0.0000e+00 - val_loss: 132.0770 - val_accuracy: 0.0000e+00\n",
      "Epoch 6554/10000\n",
      "64/64 [==============================] - 0s 161us/step - loss: 21.9029 - accuracy: 0.0000e+00 - val_loss: 132.1920 - val_accuracy: 0.0588\n",
      "Epoch 6555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2329 - accuracy: 0.0000e+00 - val_loss: 132.3058 - val_accuracy: 0.0588\n",
      "Epoch 6556/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.8224 - accuracy: 0.0000e+00 - val_loss: 133.5569 - val_accuracy: 0.0588\n",
      "Epoch 6557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0733 - accuracy: 0.0000e+00 - val_loss: 129.5921 - val_accuracy: 0.0588\n",
      "Epoch 6558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8123 - accuracy: 0.0156 - val_loss: 130.6219 - val_accuracy: 0.0000e+00\n",
      "Epoch 6559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5834 - accuracy: 0.0156 - val_loss: 135.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 6560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7598 - accuracy: 0.0156 - val_loss: 141.1475 - val_accuracy: 0.0000e+00\n",
      "Epoch 6561/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.8203 - accuracy: 0.0000e+00 - val_loss: 147.0078 - val_accuracy: 0.0588\n",
      "Epoch 6562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6987 - accuracy: 0.0000e+00 - val_loss: 139.2061 - val_accuracy: 0.0588\n",
      "Epoch 6563/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 33.3127 - accuracy: 0.0000e+00 - val_loss: 123.2994 - val_accuracy: 0.0588\n",
      "Epoch 6564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8230 - accuracy: 0.0000e+00 - val_loss: 116.8312 - val_accuracy: 0.0588\n",
      "Epoch 6565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4313 - accuracy: 0.0000e+00 - val_loss: 121.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 6566/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.3486 - accuracy: 0.0156 - val_loss: 127.8089 - val_accuracy: 0.0000e+00\n",
      "Epoch 6567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4977 - accuracy: 0.0156 - val_loss: 135.7772 - val_accuracy: 0.0000e+00\n",
      "Epoch 6568/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8823 - accuracy: 0.0156 - val_loss: 134.8552 - val_accuracy: 0.0000e+00\n",
      "Epoch 6569/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8740 - accuracy: 0.0156 - val_loss: 132.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 6570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3402 - accuracy: 0.0000e+00 - val_loss: 129.8340 - val_accuracy: 0.0000e+00\n",
      "Epoch 6571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7965 - accuracy: 0.0000e+00 - val_loss: 124.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6572/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 36.4897 - accuracy: 0.0156 - val_loss: 122.9994 - val_accuracy: 0.0588\n",
      "Epoch 6573/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 44.0248 - accuracy: 0.0156 - val_loss: 127.8273 - val_accuracy: 0.0000e+00\n",
      "Epoch 6574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6856 - accuracy: 0.0156 - val_loss: 137.4110 - val_accuracy: 0.0588\n",
      "Epoch 6575/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9736 - accuracy: 0.0000e+00 - val_loss: 138.8326 - val_accuracy: 0.0588\n",
      "Epoch 6576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4428 - accuracy: 0.0156 - val_loss: 131.4526 - val_accuracy: 0.0000e+00\n",
      "Epoch 6577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6051 - accuracy: 0.0000e+00 - val_loss: 125.9714 - val_accuracy: 0.0588\n",
      "Epoch 6578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4205 - accuracy: 0.0000e+00 - val_loss: 121.8622 - val_accuracy: 0.0000e+00\n",
      "Epoch 6579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7586 - accuracy: 0.0000e+00 - val_loss: 122.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 6580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.8082 - accuracy: 0.0000e+00 - val_loss: 125.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 6581/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6710 - accuracy: 0.0000e+00 - val_loss: 125.1487 - val_accuracy: 0.0000e+00\n",
      "Epoch 6582/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 26.8448 - accuracy: 0.0156 - val_loss: 127.9754 - val_accuracy: 0.0588\n",
      "Epoch 6583/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4702 - accuracy: 0.0000e+00 - val_loss: 127.6210 - val_accuracy: 0.0000e+00\n",
      "Epoch 6584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2621 - accuracy: 0.0156 - val_loss: 123.2244 - val_accuracy: 0.0000e+00\n",
      "Epoch 6585/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6120 - accuracy: 0.0156 - val_loss: 118.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 6586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7208 - accuracy: 0.0312 - val_loss: 114.9260 - val_accuracy: 0.0000e+00\n",
      "Epoch 6587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9623 - accuracy: 0.0156 - val_loss: 121.0103 - val_accuracy: 0.0000e+00\n",
      "Epoch 6588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8752 - accuracy: 0.0312 - val_loss: 124.5103 - val_accuracy: 0.0000e+00\n",
      "Epoch 6589/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0322 - accuracy: 0.0000e+00 - val_loss: 122.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 6590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0874 - accuracy: 0.0156 - val_loss: 117.7999 - val_accuracy: 0.0000e+00\n",
      "Epoch 6591/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.6780 - accuracy: 0.0000e+00 - val_loss: 112.3929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5726 - accuracy: 0.0000e+00 - val_loss: 113.1252 - val_accuracy: 0.0000e+00\n",
      "Epoch 6593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2822 - accuracy: 0.0000e+00 - val_loss: 116.9706 - val_accuracy: 0.0588\n",
      "Epoch 6594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5829 - accuracy: 0.0000e+00 - val_loss: 120.6997 - val_accuracy: 0.0588\n",
      "Epoch 6595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4160 - accuracy: 0.0469 - val_loss: 121.1543 - val_accuracy: 0.0588\n",
      "Epoch 6596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3195 - accuracy: 0.0156 - val_loss: 115.1089 - val_accuracy: 0.0588\n",
      "Epoch 6597/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1452 - accuracy: 0.0000e+00 - val_loss: 118.9383 - val_accuracy: 0.0588\n",
      "Epoch 6598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4602 - accuracy: 0.0000e+00 - val_loss: 121.1099 - val_accuracy: 0.0588\n",
      "Epoch 6599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6684 - accuracy: 0.0000e+00 - val_loss: 117.1917 - val_accuracy: 0.0588\n",
      "Epoch 6600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4250 - accuracy: 0.0000e+00 - val_loss: 113.6731 - val_accuracy: 0.0588\n",
      "Epoch 6601/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 32.5682 - accuracy: 0.0000e+00 - val_loss: 115.8059 - val_accuracy: 0.0588\n",
      "Epoch 6602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2502 - accuracy: 0.0312 - val_loss: 124.2008 - val_accuracy: 0.0000e+00\n",
      "Epoch 6603/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2655 - accuracy: 0.0156 - val_loss: 130.3427 - val_accuracy: 0.0000e+00\n",
      "Epoch 6604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4185 - accuracy: 0.0156 - val_loss: 132.8700 - val_accuracy: 0.0000e+00\n",
      "Epoch 6605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2200 - accuracy: 0.0000e+00 - val_loss: 128.7734 - val_accuracy: 0.0000e+00\n",
      "Epoch 6606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1712 - accuracy: 0.0156 - val_loss: 125.0731 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7714 - accuracy: 0.0156 - val_loss: 125.8056 - val_accuracy: 0.0588\n",
      "Epoch 6608/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9200 - accuracy: 0.0000e+00 - val_loss: 125.9731 - val_accuracy: 0.0588\n",
      "Epoch 6609/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1087 - accuracy: 0.0156 - val_loss: 128.1243 - val_accuracy: 0.0000e+00\n",
      "Epoch 6610/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 15.2859 - accuracy: 0.0156 - val_loss: 126.3004 - val_accuracy: 0.0000e+00\n",
      "Epoch 6611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2510 - accuracy: 0.0156 - val_loss: 127.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 6612/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5140 - accuracy: 0.0000e+00 - val_loss: 130.8047 - val_accuracy: 0.0000e+00\n",
      "Epoch 6613/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 20.8281 - accuracy: 0.0000e+00 - val_loss: 131.5772 - val_accuracy: 0.0000e+00\n",
      "Epoch 6614/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3852 - accuracy: 0.0312 - val_loss: 132.0168 - val_accuracy: 0.0000e+00\n",
      "Epoch 6615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2328 - accuracy: 0.0156 - val_loss: 134.2973 - val_accuracy: 0.0000e+00\n",
      "Epoch 6616/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.7084 - accuracy: 0.0156 - val_loss: 128.0591 - val_accuracy: 0.0000e+00\n",
      "Epoch 6617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1184 - accuracy: 0.0000e+00 - val_loss: 126.3304 - val_accuracy: 0.0000e+00\n",
      "Epoch 6618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7221 - accuracy: 0.0000e+00 - val_loss: 127.3751 - val_accuracy: 0.0000e+00\n",
      "Epoch 6619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1631 - accuracy: 0.0156 - val_loss: 130.6362 - val_accuracy: 0.0000e+00\n",
      "Epoch 6620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4238 - accuracy: 0.0156 - val_loss: 134.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7695 - accuracy: 0.0000e+00 - val_loss: 129.0871 - val_accuracy: 0.0000e+00\n",
      "Epoch 6622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4471 - accuracy: 0.0000e+00 - val_loss: 129.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6951 - accuracy: 0.0000e+00 - val_loss: 126.6739 - val_accuracy: 0.0000e+00\n",
      "Epoch 6624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8078 - accuracy: 0.0000e+00 - val_loss: 128.8719 - val_accuracy: 0.0588\n",
      "Epoch 6625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5343 - accuracy: 0.0312 - val_loss: 126.4917 - val_accuracy: 0.0588\n",
      "Epoch 6626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1461 - accuracy: 0.0000e+00 - val_loss: 120.4086 - val_accuracy: 0.0588\n",
      "Epoch 6627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0096 - accuracy: 0.0000e+00 - val_loss: 113.6787 - val_accuracy: 0.0588\n",
      "Epoch 6628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0539 - accuracy: 0.0000e+00 - val_loss: 115.4687 - val_accuracy: 0.0000e+00\n",
      "Epoch 6629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3626 - accuracy: 0.0156 - val_loss: 120.9289 - val_accuracy: 0.0000e+00\n",
      "Epoch 6630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3751 - accuracy: 0.0000e+00 - val_loss: 123.2689 - val_accuracy: 0.0000e+00\n",
      "Epoch 6631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3761 - accuracy: 0.0000e+00 - val_loss: 118.8638 - val_accuracy: 0.0000e+00\n",
      "Epoch 6632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7866 - accuracy: 0.0156 - val_loss: 116.6496 - val_accuracy: 0.0000e+00\n",
      "Epoch 6633/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4507 - accuracy: 0.0312 - val_loss: 123.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 6634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0319 - accuracy: 0.0156 - val_loss: 128.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 6635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3586 - accuracy: 0.0156 - val_loss: 127.8731 - val_accuracy: 0.0588\n",
      "Epoch 6636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4549 - accuracy: 0.0000e+00 - val_loss: 128.1302 - val_accuracy: 0.0588\n",
      "Epoch 6637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1457 - accuracy: 0.0156 - val_loss: 127.7830 - val_accuracy: 0.0588\n",
      "Epoch 6638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0782 - accuracy: 0.0312 - val_loss: 129.3582 - val_accuracy: 0.0588\n",
      "Epoch 6639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2757 - accuracy: 0.0000e+00 - val_loss: 128.0610 - val_accuracy: 0.0588\n",
      "Epoch 6640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0689 - accuracy: 0.0000e+00 - val_loss: 125.2982 - val_accuracy: 0.0000e+00\n",
      "Epoch 6641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2485 - accuracy: 0.0000e+00 - val_loss: 121.5588 - val_accuracy: 0.0000e+00\n",
      "Epoch 6642/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 31.8505 - accuracy: 0.0156 - val_loss: 117.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 6643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9864 - accuracy: 0.0156 - val_loss: 111.8265 - val_accuracy: 0.0000e+00\n",
      "Epoch 6644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2992 - accuracy: 0.0000e+00 - val_loss: 113.2594 - val_accuracy: 0.0000e+00\n",
      "Epoch 6645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0038 - accuracy: 0.0156 - val_loss: 116.1943 - val_accuracy: 0.0000e+00\n",
      "Epoch 6646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1434 - accuracy: 0.0000e+00 - val_loss: 119.0469 - val_accuracy: 0.0000e+00\n",
      "Epoch 6647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6606 - accuracy: 0.0000e+00 - val_loss: 126.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 6648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4921 - accuracy: 0.0156 - val_loss: 125.5515 - val_accuracy: 0.0000e+00\n",
      "Epoch 6649/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.9941 - accuracy: 0.0000e+00 - val_loss: 125.0569 - val_accuracy: 0.0000e+00\n",
      "Epoch 6650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2520 - accuracy: 0.0000e+00 - val_loss: 122.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 6651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3981 - accuracy: 0.0156 - val_loss: 119.4612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2071 - accuracy: 0.0000e+00 - val_loss: 124.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 6653/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 27.4252 - accuracy: 0.0000e+00 - val_loss: 135.2811 - val_accuracy: 0.0000e+00\n",
      "Epoch 6654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.7358 - accuracy: 0.0000e+00 - val_loss: 147.1614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6655/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.8846 - accuracy: 0.0156 - val_loss: 146.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 6656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7804 - accuracy: 0.0000e+00 - val_loss: 140.4502 - val_accuracy: 0.0000e+00\n",
      "Epoch 6657/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 29.8474 - accuracy: 0.0156 - val_loss: 127.5343 - val_accuracy: 0.0000e+00\n",
      "Epoch 6658/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 41.3669 - accuracy: 0.0000e+00 - val_loss: 118.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 6659/10000\n",
      "64/64 [==============================] - 0s 122us/step - loss: 28.3901 - accuracy: 0.0000e+00 - val_loss: 115.5412 - val_accuracy: 0.0588\n",
      "Epoch 6660/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.1650 - accuracy: 0.0000e+00 - val_loss: 129.4802 - val_accuracy: 0.0588\n",
      "Epoch 6661/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5924 - accuracy: 0.0000e+00 - val_loss: 140.8028 - val_accuracy: 0.0588\n",
      "Epoch 6662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1324 - accuracy: 0.0312 - val_loss: 140.0893 - val_accuracy: 0.0588\n",
      "Epoch 6663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1071 - accuracy: 0.0000e+00 - val_loss: 135.3899 - val_accuracy: 0.0000e+00\n",
      "Epoch 6664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0825 - accuracy: 0.0156 - val_loss: 130.5478 - val_accuracy: 0.0588\n",
      "Epoch 6665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2825 - accuracy: 0.0312 - val_loss: 130.5226 - val_accuracy: 0.0588\n",
      "Epoch 6666/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8705 - accuracy: 0.0000e+00 - val_loss: 128.0607 - val_accuracy: 0.0588\n",
      "Epoch 6667/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 27.2617 - accuracy: 0.0312 - val_loss: 126.1591 - val_accuracy: 0.0000e+00\n",
      "Epoch 6668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9467 - accuracy: 0.0000e+00 - val_loss: 126.8737 - val_accuracy: 0.0588\n",
      "Epoch 6669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8206 - accuracy: 0.0000e+00 - val_loss: 131.8976 - val_accuracy: 0.0588\n",
      "Epoch 6670/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 35.6016 - accuracy: 0.0000e+00 - val_loss: 129.4979 - val_accuracy: 0.0000e+00\n",
      "Epoch 6671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6416 - accuracy: 0.0000e+00 - val_loss: 115.2986 - val_accuracy: 0.0000e+00\n",
      "Epoch 6672/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6360 - accuracy: 0.0156 - val_loss: 114.0157 - val_accuracy: 0.0588\n",
      "Epoch 6673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0205 - accuracy: 0.0000e+00 - val_loss: 119.1805 - val_accuracy: 0.0000e+00\n",
      "Epoch 6674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4340 - accuracy: 0.0469 - val_loss: 124.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 6675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4115 - accuracy: 0.0156 - val_loss: 125.4284 - val_accuracy: 0.0000e+00\n",
      "Epoch 6676/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.4232 - accuracy: 0.0000e+00 - val_loss: 125.0738 - val_accuracy: 0.0000e+00\n",
      "Epoch 6677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2271 - accuracy: 0.0312 - val_loss: 126.3478 - val_accuracy: 0.0000e+00\n",
      "Epoch 6678/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.1316 - accuracy: 0.0000e+00 - val_loss: 128.4898 - val_accuracy: 0.0000e+00\n",
      "Epoch 6679/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6326 - accuracy: 0.0000e+00 - val_loss: 133.2060 - val_accuracy: 0.0588\n",
      "Epoch 6680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0897 - accuracy: 0.0000e+00 - val_loss: 129.4544 - val_accuracy: 0.0588\n",
      "Epoch 6681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8924 - accuracy: 0.0312 - val_loss: 115.3609 - val_accuracy: 0.0588\n",
      "Epoch 6682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0860 - accuracy: 0.0312 - val_loss: 107.9240 - val_accuracy: 0.0588\n",
      "Epoch 6683/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.5142 - accuracy: 0.0000e+00 - val_loss: 111.3752 - val_accuracy: 0.0588\n",
      "Epoch 6684/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 31.8394 - accuracy: 0.0156 - val_loss: 121.2688 - val_accuracy: 0.0000e+00\n",
      "Epoch 6685/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 30.0651 - accuracy: 0.0312 - val_loss: 136.2424 - val_accuracy: 0.0000e+00\n",
      "Epoch 6686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3391 - accuracy: 0.0000e+00 - val_loss: 141.5050 - val_accuracy: 0.0000e+00\n",
      "Epoch 6687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8302 - accuracy: 0.0000e+00 - val_loss: 138.5422 - val_accuracy: 0.0588\n",
      "Epoch 6688/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3284 - accuracy: 0.0000e+00 - val_loss: 130.3685 - val_accuracy: 0.0588\n",
      "Epoch 6689/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3446 - accuracy: 0.0156 - val_loss: 125.8992 - val_accuracy: 0.0588\n",
      "Epoch 6690/10000\n",
      "64/64 [==============================] - 0s 199us/step - loss: 29.5910 - accuracy: 0.0312 - val_loss: 143.4420 - val_accuracy: 0.0000e+00\n",
      "Epoch 6691/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 28.8228 - accuracy: 0.0000e+00 - val_loss: 157.1952 - val_accuracy: 0.0000e+00\n",
      "Epoch 6692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1754 - accuracy: 0.0156 - val_loss: 146.0092 - val_accuracy: 0.0588\n",
      "Epoch 6693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6832 - accuracy: 0.0000e+00 - val_loss: 133.5065 - val_accuracy: 0.0588\n",
      "Epoch 6694/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.8134 - accuracy: 0.0000e+00 - val_loss: 133.1422 - val_accuracy: 0.0000e+00\n",
      "Epoch 6695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8381 - accuracy: 0.0000e+00 - val_loss: 131.4193 - val_accuracy: 0.0000e+00\n",
      "Epoch 6696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7149 - accuracy: 0.0000e+00 - val_loss: 128.8582 - val_accuracy: 0.0000e+00\n",
      "Epoch 6697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3235 - accuracy: 0.0156 - val_loss: 126.4400 - val_accuracy: 0.0588\n",
      "Epoch 6698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8303 - accuracy: 0.0000e+00 - val_loss: 119.7225 - val_accuracy: 0.0588\n",
      "Epoch 6699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2259 - accuracy: 0.0156 - val_loss: 121.4745 - val_accuracy: 0.0588\n",
      "Epoch 6700/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6170 - accuracy: 0.0156 - val_loss: 128.1539 - val_accuracy: 0.0588\n",
      "Epoch 6701/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9274 - accuracy: 0.0156 - val_loss: 128.6881 - val_accuracy: 0.0588\n",
      "Epoch 6702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9856 - accuracy: 0.0312 - val_loss: 128.9020 - val_accuracy: 0.0588\n",
      "Epoch 6703/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.0412 - accuracy: 0.0156 - val_loss: 124.9985 - val_accuracy: 0.0588\n",
      "Epoch 6704/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.4984 - accuracy: 0.0000e+00 - val_loss: 119.8799 - val_accuracy: 0.1176\n",
      "Epoch 6705/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5281 - accuracy: 0.0000e+00 - val_loss: 121.5036 - val_accuracy: 0.0588\n",
      "Epoch 6706/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 24.6508 - accuracy: 0.0000e+00 - val_loss: 128.4031 - val_accuracy: 0.0588\n",
      "Epoch 6707/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1861 - accuracy: 0.0000e+00 - val_loss: 129.7457 - val_accuracy: 0.0588\n",
      "Epoch 6708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1595 - accuracy: 0.0000e+00 - val_loss: 127.6443 - val_accuracy: 0.0588\n",
      "Epoch 6709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6199 - accuracy: 0.0156 - val_loss: 127.5342 - val_accuracy: 0.0588\n",
      "Epoch 6710/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8500 - accuracy: 0.0000e+00 - val_loss: 130.8031 - val_accuracy: 0.0588\n",
      "Epoch 6711/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.6278 - accuracy: 0.0156 - val_loss: 130.8918 - val_accuracy: 0.0588\n",
      "Epoch 6712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 104us/step - loss: 26.3799 - accuracy: 0.0312 - val_loss: 129.4120 - val_accuracy: 0.0588\n",
      "Epoch 6713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4553 - accuracy: 0.0000e+00 - val_loss: 127.0516 - val_accuracy: 0.0588\n",
      "Epoch 6714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0034 - accuracy: 0.0000e+00 - val_loss: 118.8956 - val_accuracy: 0.0588\n",
      "Epoch 6715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7060 - accuracy: 0.0000e+00 - val_loss: 112.7055 - val_accuracy: 0.0588\n",
      "Epoch 6716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.7538 - accuracy: 0.0000e+00 - val_loss: 117.0490 - val_accuracy: 0.0588\n",
      "Epoch 6717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7013 - accuracy: 0.0156 - val_loss: 123.6628 - val_accuracy: 0.0588\n",
      "Epoch 6718/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 24.6450 - accuracy: 0.0156 - val_loss: 126.0763 - val_accuracy: 0.0588\n",
      "Epoch 6719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8888 - accuracy: 0.0000e+00 - val_loss: 126.1827 - val_accuracy: 0.1176\n",
      "Epoch 6720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1276 - accuracy: 0.0156 - val_loss: 121.4478 - val_accuracy: 0.1176\n",
      "Epoch 6721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8759 - accuracy: 0.0000e+00 - val_loss: 116.9760 - val_accuracy: 0.1176\n",
      "Epoch 6722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6754 - accuracy: 0.0000e+00 - val_loss: 121.3678 - val_accuracy: 0.0588\n",
      "Epoch 6723/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.8510 - accuracy: 0.0000e+00 - val_loss: 122.8974 - val_accuracy: 0.0588\n",
      "Epoch 6724/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 28.8660 - accuracy: 0.0000e+00 - val_loss: 127.3021 - val_accuracy: 0.0588\n",
      "Epoch 6725/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 20.5140 - accuracy: 0.0156 - val_loss: 124.7450 - val_accuracy: 0.0588\n",
      "Epoch 6726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5461 - accuracy: 0.0000e+00 - val_loss: 124.3557 - val_accuracy: 0.0588\n",
      "Epoch 6727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.4525 - accuracy: 0.0000e+00 - val_loss: 117.6771 - val_accuracy: 0.0588\n",
      "Epoch 6728/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 26.5692 - accuracy: 0.0156 - val_loss: 107.1137 - val_accuracy: 0.1176\n",
      "Epoch 6729/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.6909 - accuracy: 0.0469 - val_loss: 106.1540 - val_accuracy: 0.1176\n",
      "Epoch 6730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5361 - accuracy: 0.0000e+00 - val_loss: 104.2915 - val_accuracy: 0.0588\n",
      "Epoch 6731/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 35.3734 - accuracy: 0.0156 - val_loss: 111.3962 - val_accuracy: 0.0000e+00\n",
      "Epoch 6732/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.1723 - accuracy: 0.0000e+00 - val_loss: 120.4429 - val_accuracy: 0.0000e+00\n",
      "Epoch 6733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3305 - accuracy: 0.0312 - val_loss: 127.3303 - val_accuracy: 0.0000e+00\n",
      "Epoch 6734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2085 - accuracy: 0.0000e+00 - val_loss: 126.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 6735/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 34.3443 - accuracy: 0.0000e+00 - val_loss: 127.9442 - val_accuracy: 0.0000e+00\n",
      "Epoch 6736/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6355 - accuracy: 0.0156 - val_loss: 131.3452 - val_accuracy: 0.0000e+00\n",
      "Epoch 6737/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6099 - accuracy: 0.0156 - val_loss: 134.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 6738/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 34.6363 - accuracy: 0.0469 - val_loss: 136.1379 - val_accuracy: 0.0000e+00\n",
      "Epoch 6739/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9609 - accuracy: 0.0156 - val_loss: 135.7630 - val_accuracy: 0.0588\n",
      "Epoch 6740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1431 - accuracy: 0.0000e+00 - val_loss: 133.6134 - val_accuracy: 0.0588\n",
      "Epoch 6741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0968 - accuracy: 0.0000e+00 - val_loss: 128.3624 - val_accuracy: 0.0588\n",
      "Epoch 6742/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.4453 - accuracy: 0.0156 - val_loss: 125.8208 - val_accuracy: 0.0588\n",
      "Epoch 6743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5172 - accuracy: 0.0000e+00 - val_loss: 131.4504 - val_accuracy: 0.0588\n",
      "Epoch 6744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0381 - accuracy: 0.0000e+00 - val_loss: 133.0186 - val_accuracy: 0.0588\n",
      "Epoch 6745/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8260 - accuracy: 0.0000e+00 - val_loss: 129.4592 - val_accuracy: 0.0000e+00\n",
      "Epoch 6746/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 32.8097 - accuracy: 0.0156 - val_loss: 129.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 6747/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 21.0258 - accuracy: 0.0000e+00 - val_loss: 128.8006 - val_accuracy: 0.0000e+00\n",
      "Epoch 6748/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.9684 - accuracy: 0.0000e+00 - val_loss: 126.8819 - val_accuracy: 0.0000e+00\n",
      "Epoch 6749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1314 - accuracy: 0.0000e+00 - val_loss: 125.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 6750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.2179 - accuracy: 0.0156 - val_loss: 125.4423 - val_accuracy: 0.0000e+00\n",
      "Epoch 6751/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4247 - accuracy: 0.0000e+00 - val_loss: 131.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 6752/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1806 - accuracy: 0.0000e+00 - val_loss: 129.9889 - val_accuracy: 0.0000e+00\n",
      "Epoch 6753/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4875 - accuracy: 0.0000e+00 - val_loss: 128.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 6754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1578 - accuracy: 0.0469 - val_loss: 119.6655 - val_accuracy: 0.0000e+00\n",
      "Epoch 6755/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 33.3350 - accuracy: 0.0000e+00 - val_loss: 117.7457 - val_accuracy: 0.0588\n",
      "Epoch 6756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7569 - accuracy: 0.0000e+00 - val_loss: 120.9258 - val_accuracy: 0.0588\n",
      "Epoch 6757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7854 - accuracy: 0.0312 - val_loss: 124.9777 - val_accuracy: 0.0588\n",
      "Epoch 6758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8725 - accuracy: 0.0312 - val_loss: 129.8688 - val_accuracy: 0.0588\n",
      "Epoch 6759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7358 - accuracy: 0.0156 - val_loss: 135.8167 - val_accuracy: 0.0588\n",
      "Epoch 6760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7271 - accuracy: 0.0156 - val_loss: 128.2707 - val_accuracy: 0.0588\n",
      "Epoch 6761/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1586 - accuracy: 0.0000e+00 - val_loss: 124.4343 - val_accuracy: 0.0588\n",
      "Epoch 6762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8549 - accuracy: 0.0000e+00 - val_loss: 123.3091 - val_accuracy: 0.0588\n",
      "Epoch 6763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2953 - accuracy: 0.0000e+00 - val_loss: 124.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 6764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8144 - accuracy: 0.0000e+00 - val_loss: 123.0918 - val_accuracy: 0.0588\n",
      "Epoch 6765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6518 - accuracy: 0.0312 - val_loss: 121.0219 - val_accuracy: 0.0000e+00\n",
      "Epoch 6766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7482 - accuracy: 0.0156 - val_loss: 126.5418 - val_accuracy: 0.0000e+00\n",
      "Epoch 6767/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 24.0250 - accuracy: 0.0000e+00 - val_loss: 130.9056 - val_accuracy: 0.0000e+00\n",
      "Epoch 6768/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 21.3610 - accuracy: 0.0000e+00 - val_loss: 136.2808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6769/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 22.6005 - accuracy: 0.0000e+00 - val_loss: 131.0399 - val_accuracy: 0.0588\n",
      "Epoch 6770/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 18.8021 - accuracy: 0.0000e+00 - val_loss: 122.7709 - val_accuracy: 0.0588\n",
      "Epoch 6771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5276 - accuracy: 0.0000e+00 - val_loss: 113.3179 - val_accuracy: 0.0000e+00\n",
      "Epoch 6772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0978 - accuracy: 0.0156 - val_loss: 118.3007 - val_accuracy: 0.0000e+00\n",
      "Epoch 6773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3752 - accuracy: 0.0000e+00 - val_loss: 123.0184 - val_accuracy: 0.0588\n",
      "Epoch 6774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3355 - accuracy: 0.0000e+00 - val_loss: 122.8118 - val_accuracy: 0.0588\n",
      "Epoch 6775/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8452 - accuracy: 0.0156 - val_loss: 126.6162 - val_accuracy: 0.1176\n",
      "Epoch 6776/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 18.6823 - accuracy: 0.0000e+00 - val_loss: 126.8628 - val_accuracy: 0.0588\n",
      "Epoch 6777/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7590 - accuracy: 0.0000e+00 - val_loss: 126.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 6778/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6412 - accuracy: 0.0000e+00 - val_loss: 127.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 6779/10000\n",
      "64/64 [==============================] - 0s 164us/step - loss: 27.6512 - accuracy: 0.0000e+00 - val_loss: 130.4193 - val_accuracy: 0.0588\n",
      "Epoch 6780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3104 - accuracy: 0.0000e+00 - val_loss: 133.4450 - val_accuracy: 0.0000e+00\n",
      "Epoch 6781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1653 - accuracy: 0.0312 - val_loss: 128.3084 - val_accuracy: 0.0000e+00\n",
      "Epoch 6782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0756 - accuracy: 0.0156 - val_loss: 118.8369 - val_accuracy: 0.0588\n",
      "Epoch 6783/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0880 - accuracy: 0.0156 - val_loss: 112.2206 - val_accuracy: 0.0000e+00\n",
      "Epoch 6784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.9629 - accuracy: 0.0000e+00 - val_loss: 117.5032 - val_accuracy: 0.0000e+00\n",
      "Epoch 6785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6724 - accuracy: 0.0312 - val_loss: 123.1961 - val_accuracy: 0.0588\n",
      "Epoch 6786/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 36.4996 - accuracy: 0.0000e+00 - val_loss: 126.2488 - val_accuracy: 0.0588\n",
      "Epoch 6787/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 43.3797 - accuracy: 0.0000e+00 - val_loss: 121.2172 - val_accuracy: 0.0588\n",
      "Epoch 6788/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 16.2383 - accuracy: 0.0000e+00 - val_loss: 112.3806 - val_accuracy: 0.0588\n",
      "Epoch 6789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1510 - accuracy: 0.0156 - val_loss: 106.6964 - val_accuracy: 0.0588\n",
      "Epoch 6790/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7864 - accuracy: 0.0000e+00 - val_loss: 111.2325 - val_accuracy: 0.0000e+00\n",
      "Epoch 6791/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.2513 - accuracy: 0.0156 - val_loss: 124.4020 - val_accuracy: 0.0000e+00\n",
      "Epoch 6792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1571 - accuracy: 0.0156 - val_loss: 138.8755 - val_accuracy: 0.0588\n",
      "Epoch 6793/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7285 - accuracy: 0.0156 - val_loss: 139.9808 - val_accuracy: 0.0588\n",
      "Epoch 6794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0702 - accuracy: 0.0469 - val_loss: 138.9275 - val_accuracy: 0.0588\n",
      "Epoch 6795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7716 - accuracy: 0.0156 - val_loss: 133.6324 - val_accuracy: 0.0588\n",
      "Epoch 6796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0417 - accuracy: 0.0000e+00 - val_loss: 127.6972 - val_accuracy: 0.0588\n",
      "Epoch 6797/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9786 - accuracy: 0.0000e+00 - val_loss: 126.1755 - val_accuracy: 0.0000e+00\n",
      "Epoch 6798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9616 - accuracy: 0.0000e+00 - val_loss: 125.1357 - val_accuracy: 0.0000e+00\n",
      "Epoch 6799/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 28.5707 - accuracy: 0.0000e+00 - val_loss: 126.8023 - val_accuracy: 0.0000e+00\n",
      "Epoch 6800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6316 - accuracy: 0.0000e+00 - val_loss: 131.2432 - val_accuracy: 0.0000e+00\n",
      "Epoch 6801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0205 - accuracy: 0.0156 - val_loss: 136.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 6802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8018 - accuracy: 0.0000e+00 - val_loss: 138.5770 - val_accuracy: 0.0588\n",
      "Epoch 6803/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6427 - accuracy: 0.0156 - val_loss: 136.4146 - val_accuracy: 0.1176\n",
      "Epoch 6804/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7108 - accuracy: 0.0156 - val_loss: 133.4857 - val_accuracy: 0.0000e+00\n",
      "Epoch 6805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3279 - accuracy: 0.0000e+00 - val_loss: 133.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 6806/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7825 - accuracy: 0.0000e+00 - val_loss: 132.5641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7803 - accuracy: 0.0156 - val_loss: 136.6145 - val_accuracy: 0.1176\n",
      "Epoch 6808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8307 - accuracy: 0.0000e+00 - val_loss: 141.4711 - val_accuracy: 0.0588\n",
      "Epoch 6809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3789 - accuracy: 0.0000e+00 - val_loss: 143.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 6810/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7222 - accuracy: 0.0156 - val_loss: 144.4638 - val_accuracy: 0.0000e+00\n",
      "Epoch 6811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8903 - accuracy: 0.0156 - val_loss: 141.4827 - val_accuracy: 0.0000e+00\n",
      "Epoch 6812/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 36.7584 - accuracy: 0.0156 - val_loss: 133.6260 - val_accuracy: 0.0588\n",
      "Epoch 6813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6667 - accuracy: 0.0156 - val_loss: 126.0223 - val_accuracy: 0.0588\n",
      "Epoch 6814/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6694 - accuracy: 0.0156 - val_loss: 122.0970 - val_accuracy: 0.0000e+00\n",
      "Epoch 6815/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 25.2613 - accuracy: 0.0312 - val_loss: 118.9361 - val_accuracy: 0.0000e+00\n",
      "Epoch 6816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7001 - accuracy: 0.0000e+00 - val_loss: 117.5023 - val_accuracy: 0.0588\n",
      "Epoch 6817/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4969 - accuracy: 0.0000e+00 - val_loss: 113.9259 - val_accuracy: 0.0588\n",
      "Epoch 6818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 32.5564 - accuracy: 0.0000e+00 - val_loss: 110.4482 - val_accuracy: 0.0588\n",
      "Epoch 6819/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.3732 - accuracy: 0.0312 - val_loss: 114.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 6820/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 30.8904 - accuracy: 0.0000e+00 - val_loss: 122.4036 - val_accuracy: 0.0588\n",
      "Epoch 6821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5643 - accuracy: 0.0000e+00 - val_loss: 134.1804 - val_accuracy: 0.0588\n",
      "Epoch 6822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7899 - accuracy: 0.0000e+00 - val_loss: 130.4634 - val_accuracy: 0.0000e+00\n",
      "Epoch 6823/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.7357 - accuracy: 0.0156 - val_loss: 121.0730 - val_accuracy: 0.0000e+00\n",
      "Epoch 6824/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0410 - accuracy: 0.0000e+00 - val_loss: 117.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 6825/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.3735 - accuracy: 0.0000e+00 - val_loss: 116.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 6826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1836 - accuracy: 0.0000e+00 - val_loss: 122.2145 - val_accuracy: 0.0588\n",
      "Epoch 6827/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.6757 - accuracy: 0.0312 - val_loss: 127.2941 - val_accuracy: 0.0588\n",
      "Epoch 6828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5778 - accuracy: 0.0156 - val_loss: 130.0657 - val_accuracy: 0.0588\n",
      "Epoch 6829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9480 - accuracy: 0.0000e+00 - val_loss: 127.1331 - val_accuracy: 0.0588\n",
      "Epoch 6830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6157 - accuracy: 0.0000e+00 - val_loss: 122.4831 - val_accuracy: 0.0000e+00\n",
      "Epoch 6831/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 25.6230 - accuracy: 0.0000e+00 - val_loss: 119.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8494 - accuracy: 0.0156 - val_loss: 115.6996 - val_accuracy: 0.0588\n",
      "Epoch 6833/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3492 - accuracy: 0.0000e+00 - val_loss: 116.3995 - val_accuracy: 0.0588\n",
      "Epoch 6834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8259 - accuracy: 0.0000e+00 - val_loss: 120.9999 - val_accuracy: 0.0588\n",
      "Epoch 6835/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7266 - accuracy: 0.0000e+00 - val_loss: 123.5747 - val_accuracy: 0.0588\n",
      "Epoch 6836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 53.0840 - accuracy: 0.0000e+00 - val_loss: 120.1527 - val_accuracy: 0.0000e+00\n",
      "Epoch 6837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5726 - accuracy: 0.0000e+00 - val_loss: 121.9618 - val_accuracy: 0.0000e+00\n",
      "Epoch 6838/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2560 - accuracy: 0.0312 - val_loss: 128.6506 - val_accuracy: 0.0000e+00\n",
      "Epoch 6839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1494 - accuracy: 0.0156 - val_loss: 135.1795 - val_accuracy: 0.0000e+00\n",
      "Epoch 6840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7655 - accuracy: 0.0625 - val_loss: 147.5371 - val_accuracy: 0.0588\n",
      "Epoch 6841/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.4979 - accuracy: 0.0000e+00 - val_loss: 145.5546 - val_accuracy: 0.0588\n",
      "Epoch 6842/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.8276 - accuracy: 0.0000e+00 - val_loss: 128.1020 - val_accuracy: 0.1176\n",
      "Epoch 6843/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7072 - accuracy: 0.0156 - val_loss: 121.8577 - val_accuracy: 0.0000e+00\n",
      "Epoch 6844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7450 - accuracy: 0.0156 - val_loss: 121.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 6845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1230 - accuracy: 0.0000e+00 - val_loss: 128.1859 - val_accuracy: 0.0000e+00\n",
      "Epoch 6846/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9301 - accuracy: 0.0312 - val_loss: 135.5128 - val_accuracy: 0.0000e+00\n",
      "Epoch 6847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6733 - accuracy: 0.0000e+00 - val_loss: 136.1950 - val_accuracy: 0.0000e+00\n",
      "Epoch 6848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0551 - accuracy: 0.0156 - val_loss: 128.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 6849/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4496 - accuracy: 0.0312 - val_loss: 123.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 6850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.2227 - accuracy: 0.0000e+00 - val_loss: 114.0676 - val_accuracy: 0.0588\n",
      "Epoch 6851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.6163 - accuracy: 0.0156 - val_loss: 112.3974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6852/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3496 - accuracy: 0.0000e+00 - val_loss: 116.4173 - val_accuracy: 0.0588\n",
      "Epoch 6853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5967 - accuracy: 0.0000e+00 - val_loss: 130.1024 - val_accuracy: 0.0588\n",
      "Epoch 6854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7521 - accuracy: 0.0000e+00 - val_loss: 140.9796 - val_accuracy: 0.0588\n",
      "Epoch 6855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1569 - accuracy: 0.0156 - val_loss: 141.7514 - val_accuracy: 0.0000e+00\n",
      "Epoch 6856/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.7372 - accuracy: 0.0000e+00 - val_loss: 137.4416 - val_accuracy: 0.0000e+00\n",
      "Epoch 6857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8761 - accuracy: 0.0156 - val_loss: 132.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.9654 - accuracy: 0.0000e+00 - val_loss: 128.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 6859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6927 - accuracy: 0.0156 - val_loss: 124.9834 - val_accuracy: 0.0000e+00\n",
      "Epoch 6860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0891 - accuracy: 0.0156 - val_loss: 125.0628 - val_accuracy: 0.0000e+00\n",
      "Epoch 6861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2268 - accuracy: 0.0000e+00 - val_loss: 126.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 6862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2229 - accuracy: 0.0000e+00 - val_loss: 129.7276 - val_accuracy: 0.0000e+00\n",
      "Epoch 6863/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 20.5303 - accuracy: 0.0000e+00 - val_loss: 138.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 6864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1188 - accuracy: 0.0000e+00 - val_loss: 145.5293 - val_accuracy: 0.0000e+00\n",
      "Epoch 6865/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.0220 - accuracy: 0.0000e+00 - val_loss: 142.4010 - val_accuracy: 0.0000e+00\n",
      "Epoch 6866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7487 - accuracy: 0.0312 - val_loss: 132.4399 - val_accuracy: 0.0000e+00\n",
      "Epoch 6867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9426 - accuracy: 0.0156 - val_loss: 124.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 6868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1668 - accuracy: 0.0000e+00 - val_loss: 127.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 6869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4774 - accuracy: 0.0156 - val_loss: 134.6920 - val_accuracy: 0.0000e+00\n",
      "Epoch 6870/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 10.2175 - accuracy: 0.0000e+00 - val_loss: 136.8701 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7140 - accuracy: 0.0156 - val_loss: 134.7614 - val_accuracy: 0.0000e+00\n",
      "Epoch 6872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4925 - accuracy: 0.0156 - val_loss: 124.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 6873/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 25.8759 - accuracy: 0.0000e+00 - val_loss: 119.2240 - val_accuracy: 0.0000e+00\n",
      "Epoch 6874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3392 - accuracy: 0.0000e+00 - val_loss: 121.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 6875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1369 - accuracy: 0.0156 - val_loss: 128.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 6876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0358 - accuracy: 0.0000e+00 - val_loss: 140.3839 - val_accuracy: 0.0000e+00\n",
      "Epoch 6877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1787 - accuracy: 0.0000e+00 - val_loss: 144.6080 - val_accuracy: 0.0588\n",
      "Epoch 6878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0710 - accuracy: 0.0156 - val_loss: 142.0568 - val_accuracy: 0.0588\n",
      "Epoch 6879/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.3251 - accuracy: 0.0156 - val_loss: 133.1828 - val_accuracy: 0.1176\n",
      "Epoch 6880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7626 - accuracy: 0.0156 - val_loss: 125.6065 - val_accuracy: 0.1176\n",
      "Epoch 6881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7465 - accuracy: 0.0000e+00 - val_loss: 121.9081 - val_accuracy: 0.1176\n",
      "Epoch 6882/10000\n",
      "64/64 [==============================] - 0s 162us/step - loss: 24.3912 - accuracy: 0.0000e+00 - val_loss: 121.4704 - val_accuracy: 0.0588\n",
      "Epoch 6883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0612 - accuracy: 0.0000e+00 - val_loss: 127.6182 - val_accuracy: 0.0588\n",
      "Epoch 6884/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.5869 - accuracy: 0.0000e+00 - val_loss: 132.5367 - val_accuracy: 0.0588\n",
      "Epoch 6885/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 28.7386 - accuracy: 0.0156 - val_loss: 131.2726 - val_accuracy: 0.0000e+00\n",
      "Epoch 6886/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 22.4256 - accuracy: 0.0156 - val_loss: 125.6612 - val_accuracy: 0.0000e+00\n",
      "Epoch 6887/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 27.2255 - accuracy: 0.0156 - val_loss: 120.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 6888/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 28.2840 - accuracy: 0.0156 - val_loss: 120.4715 - val_accuracy: 0.0000e+00\n",
      "Epoch 6889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7766 - accuracy: 0.0156 - val_loss: 130.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 6890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5931 - accuracy: 0.0000e+00 - val_loss: 133.1892 - val_accuracy: 0.0000e+00\n",
      "Epoch 6891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3867 - accuracy: 0.0000e+00 - val_loss: 132.0433 - val_accuracy: 0.0588\n",
      "Epoch 6892/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8011 - accuracy: 0.0156 - val_loss: 134.4425 - val_accuracy: 0.0588\n",
      "Epoch 6893/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 28.5797 - accuracy: 0.0156 - val_loss: 136.5959 - val_accuracy: 0.0000e+00\n",
      "Epoch 6894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9886 - accuracy: 0.0312 - val_loss: 135.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 6895/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 20.7101 - accuracy: 0.0156 - val_loss: 133.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 6896/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2087 - accuracy: 0.0000e+00 - val_loss: 132.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 6897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1884 - accuracy: 0.0312 - val_loss: 138.2581 - val_accuracy: 0.0000e+00\n",
      "Epoch 6898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4527 - accuracy: 0.0000e+00 - val_loss: 139.9613 - val_accuracy: 0.0588\n",
      "Epoch 6899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6630 - accuracy: 0.0156 - val_loss: 137.9805 - val_accuracy: 0.0588\n",
      "Epoch 6900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4633 - accuracy: 0.0000e+00 - val_loss: 133.1068 - val_accuracy: 0.0588\n",
      "Epoch 6901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0063 - accuracy: 0.0156 - val_loss: 127.4675 - val_accuracy: 0.0588\n",
      "Epoch 6902/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.0662 - accuracy: 0.0000e+00 - val_loss: 129.2436 - val_accuracy: 0.0588\n",
      "Epoch 6903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6855 - accuracy: 0.0156 - val_loss: 129.3474 - val_accuracy: 0.0588\n",
      "Epoch 6904/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.4139 - accuracy: 0.0000e+00 - val_loss: 130.6934 - val_accuracy: 0.0588\n",
      "Epoch 6905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9624 - accuracy: 0.0312 - val_loss: 131.9380 - val_accuracy: 0.0588\n",
      "Epoch 6906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.3759 - accuracy: 0.0000e+00 - val_loss: 130.2829 - val_accuracy: 0.0588\n",
      "Epoch 6907/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0528 - accuracy: 0.0156 - val_loss: 121.1936 - val_accuracy: 0.0588\n",
      "Epoch 6908/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4321 - accuracy: 0.0312 - val_loss: 119.3551 - val_accuracy: 0.0588\n",
      "Epoch 6909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4346 - accuracy: 0.0000e+00 - val_loss: 120.2491 - val_accuracy: 0.0588\n",
      "Epoch 6910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2963 - accuracy: 0.0156 - val_loss: 130.1434 - val_accuracy: 0.0588\n",
      "Epoch 6911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4344 - accuracy: 0.0156 - val_loss: 140.3197 - val_accuracy: 0.0000e+00\n",
      "Epoch 6912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6405 - accuracy: 0.0000e+00 - val_loss: 150.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 6913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6011 - accuracy: 0.0156 - val_loss: 155.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 6914/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4796 - accuracy: 0.0000e+00 - val_loss: 153.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 6915/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.3627 - accuracy: 0.0000e+00 - val_loss: 147.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 6916/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 27.3297 - accuracy: 0.0156 - val_loss: 138.8760 - val_accuracy: 0.0000e+00\n",
      "Epoch 6917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5314 - accuracy: 0.0000e+00 - val_loss: 134.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 6918/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 23.1204 - accuracy: 0.0156 - val_loss: 132.3668 - val_accuracy: 0.0000e+00\n",
      "Epoch 6919/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.9046 - accuracy: 0.0000e+00 - val_loss: 131.5808 - val_accuracy: 0.0000e+00\n",
      "Epoch 6920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7076 - accuracy: 0.0156 - val_loss: 133.2002 - val_accuracy: 0.0000e+00\n",
      "Epoch 6921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3529 - accuracy: 0.0156 - val_loss: 133.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 6922/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 17.8920 - accuracy: 0.0156 - val_loss: 133.1607 - val_accuracy: 0.0000e+00\n",
      "Epoch 6923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9474 - accuracy: 0.0000e+00 - val_loss: 130.3487 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8377 - accuracy: 0.0156 - val_loss: 130.6620 - val_accuracy: 0.0588\n",
      "Epoch 6925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4368 - accuracy: 0.0000e+00 - val_loss: 137.6691 - val_accuracy: 0.0000e+00\n",
      "Epoch 6926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8405 - accuracy: 0.0000e+00 - val_loss: 150.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 6927/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 33.5474 - accuracy: 0.0156 - val_loss: 151.9947 - val_accuracy: 0.0000e+00\n",
      "Epoch 6928/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7373 - accuracy: 0.0156 - val_loss: 139.3641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7028 - accuracy: 0.0000e+00 - val_loss: 117.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 6930/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 26.8723 - accuracy: 0.0156 - val_loss: 107.4974 - val_accuracy: 0.0000e+00\n",
      "Epoch 6931/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6043 - accuracy: 0.0156 - val_loss: 107.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 6932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9791 - accuracy: 0.0156 - val_loss: 111.8542 - val_accuracy: 0.0000e+00\n",
      "Epoch 6933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6656 - accuracy: 0.0000e+00 - val_loss: 122.5295 - val_accuracy: 0.0000e+00\n",
      "Epoch 6934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6794 - accuracy: 0.0000e+00 - val_loss: 133.5874 - val_accuracy: 0.0000e+00\n",
      "Epoch 6935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1739 - accuracy: 0.0000e+00 - val_loss: 137.2426 - val_accuracy: 0.0000e+00\n",
      "Epoch 6936/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6126 - accuracy: 0.0312 - val_loss: 132.6998 - val_accuracy: 0.0588\n",
      "Epoch 6937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9975 - accuracy: 0.0000e+00 - val_loss: 126.2447 - val_accuracy: 0.0588\n",
      "Epoch 6938/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 28.9358 - accuracy: 0.0156 - val_loss: 124.9667 - val_accuracy: 0.0000e+00\n",
      "Epoch 6939/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.1082 - accuracy: 0.0156 - val_loss: 126.0795 - val_accuracy: 0.0588\n",
      "Epoch 6940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9135 - accuracy: 0.0000e+00 - val_loss: 131.0326 - val_accuracy: 0.0588\n",
      "Epoch 6941/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 19.0239 - accuracy: 0.0312 - val_loss: 135.6707 - val_accuracy: 0.0588\n",
      "Epoch 6942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5884 - accuracy: 0.0156 - val_loss: 140.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 6943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8408 - accuracy: 0.0156 - val_loss: 141.4574 - val_accuracy: 0.0000e+00\n",
      "Epoch 6944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2092 - accuracy: 0.0156 - val_loss: 141.7713 - val_accuracy: 0.0000e+00\n",
      "Epoch 6945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7167 - accuracy: 0.0000e+00 - val_loss: 142.7762 - val_accuracy: 0.0000e+00\n",
      "Epoch 6946/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.1778 - accuracy: 0.0000e+00 - val_loss: 145.5298 - val_accuracy: 0.0000e+00\n",
      "Epoch 6947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6726 - accuracy: 0.0000e+00 - val_loss: 146.2000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9555 - accuracy: 0.0156 - val_loss: 141.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 6949/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 36.8482 - accuracy: 0.0312 - val_loss: 134.3972 - val_accuracy: 0.0000e+00\n",
      "Epoch 6950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6504 - accuracy: 0.0000e+00 - val_loss: 125.0719 - val_accuracy: 0.0000e+00\n",
      "Epoch 6951/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 19.1638 - accuracy: 0.0000e+00 - val_loss: 117.7387 - val_accuracy: 0.0000e+00\n",
      "Epoch 6952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0569 - accuracy: 0.0469 - val_loss: 120.4791 - val_accuracy: 0.0000e+00\n",
      "Epoch 6953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5158 - accuracy: 0.0000e+00 - val_loss: 126.7804 - val_accuracy: 0.0000e+00\n",
      "Epoch 6954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2633 - accuracy: 0.0000e+00 - val_loss: 124.8641 - val_accuracy: 0.0000e+00\n",
      "Epoch 6955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8047 - accuracy: 0.0000e+00 - val_loss: 136.4296 - val_accuracy: 0.0000e+00\n",
      "Epoch 6956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4050 - accuracy: 0.0000e+00 - val_loss: 146.1744 - val_accuracy: 0.0588\n",
      "Epoch 6957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6023 - accuracy: 0.0000e+00 - val_loss: 155.4180 - val_accuracy: 0.0588\n",
      "Epoch 6958/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.8723 - accuracy: 0.0156 - val_loss: 157.4693 - val_accuracy: 0.0588\n",
      "Epoch 6959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9395 - accuracy: 0.0000e+00 - val_loss: 143.4741 - val_accuracy: 0.0588\n",
      "Epoch 6960/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 35.7841 - accuracy: 0.0000e+00 - val_loss: 122.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 6961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1619 - accuracy: 0.0000e+00 - val_loss: 105.4274 - val_accuracy: 0.0000e+00\n",
      "Epoch 6962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5786 - accuracy: 0.0156 - val_loss: 103.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 6963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1234 - accuracy: 0.0156 - val_loss: 106.7836 - val_accuracy: 0.0000e+00\n",
      "Epoch 6964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2784 - accuracy: 0.0156 - val_loss: 117.2184 - val_accuracy: 0.0000e+00\n",
      "Epoch 6965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4522 - accuracy: 0.0156 - val_loss: 126.9653 - val_accuracy: 0.0000e+00\n",
      "Epoch 6966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4809 - accuracy: 0.0000e+00 - val_loss: 127.8856 - val_accuracy: 0.0000e+00\n",
      "Epoch 6967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6074 - accuracy: 0.0000e+00 - val_loss: 129.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 6968/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1748 - accuracy: 0.0000e+00 - val_loss: 133.4357 - val_accuracy: 0.0000e+00\n",
      "Epoch 6969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1995 - accuracy: 0.0156 - val_loss: 133.8064 - val_accuracy: 0.0000e+00\n",
      "Epoch 6970/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 33.1622 - accuracy: 0.0156 - val_loss: 136.9608 - val_accuracy: 0.0588\n",
      "Epoch 6971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8432 - accuracy: 0.0000e+00 - val_loss: 140.7182 - val_accuracy: 0.0588\n",
      "Epoch 6972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1868 - accuracy: 0.0000e+00 - val_loss: 142.4135 - val_accuracy: 0.0588\n",
      "Epoch 6973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3342 - accuracy: 0.0000e+00 - val_loss: 144.2523 - val_accuracy: 0.0588\n",
      "Epoch 6974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6951 - accuracy: 0.0156 - val_loss: 144.6121 - val_accuracy: 0.0588\n",
      "Epoch 6975/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.2923 - accuracy: 0.0000e+00 - val_loss: 138.4971 - val_accuracy: 0.0588\n",
      "Epoch 6976/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5896 - accuracy: 0.0312 - val_loss: 129.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 6977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.0752 - accuracy: 0.0000e+00 - val_loss: 127.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 6978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0134 - accuracy: 0.0000e+00 - val_loss: 130.4078 - val_accuracy: 0.0000e+00\n",
      "Epoch 6979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8529 - accuracy: 0.0156 - val_loss: 137.7863 - val_accuracy: 0.0000e+00\n",
      "Epoch 6980/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 30.6840 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 24.6438 - accuracy: 0.0156 - val_loss: 140.4713 - val_accuracy: 0.0000e+00\n",
      "Epoch 6981/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 21.1244 - accuracy: 0.0156 - val_loss: 142.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 6982/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6500 - accuracy: 0.0000e+00 - val_loss: 147.0331 - val_accuracy: 0.0000e+00\n",
      "Epoch 6983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4305 - accuracy: 0.0000e+00 - val_loss: 151.4922 - val_accuracy: 0.0000e+00\n",
      "Epoch 6984/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.1629 - accuracy: 0.0000e+00 - val_loss: 152.5880 - val_accuracy: 0.0000e+00\n",
      "Epoch 6985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9213 - accuracy: 0.0312 - val_loss: 152.5718 - val_accuracy: 0.0588\n",
      "Epoch 6986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7272 - accuracy: 0.0000e+00 - val_loss: 147.0879 - val_accuracy: 0.0588\n",
      "Epoch 6987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9597 - accuracy: 0.0000e+00 - val_loss: 138.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 6988/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9068 - accuracy: 0.0000e+00 - val_loss: 137.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 6989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6654 - accuracy: 0.0000e+00 - val_loss: 141.0963 - val_accuracy: 0.0588\n",
      "Epoch 6990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0181 - accuracy: 0.0156 - val_loss: 147.1517 - val_accuracy: 0.0588\n",
      "Epoch 6991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6666 - accuracy: 0.0000e+00 - val_loss: 149.0218 - val_accuracy: 0.0588\n",
      "Epoch 6992/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7963 - accuracy: 0.0156 - val_loss: 143.6116 - val_accuracy: 0.0588\n",
      "Epoch 6993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4764 - accuracy: 0.0000e+00 - val_loss: 128.1806 - val_accuracy: 0.0588\n",
      "Epoch 6994/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 23.6141 - accuracy: 0.0156 - val_loss: 112.3800 - val_accuracy: 0.0588\n",
      "Epoch 6995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6754 - accuracy: 0.0000e+00 - val_loss: 107.5126 - val_accuracy: 0.0588\n",
      "Epoch 6996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0204 - accuracy: 0.0156 - val_loss: 112.1348 - val_accuracy: 0.0588\n",
      "Epoch 6997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4374 - accuracy: 0.0156 - val_loss: 121.4963 - val_accuracy: 0.0588\n",
      "Epoch 6998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8118 - accuracy: 0.0000e+00 - val_loss: 123.5408 - val_accuracy: 0.0588\n",
      "Epoch 6999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0426 - accuracy: 0.0156 - val_loss: 114.2537 - val_accuracy: 0.0000e+00\n",
      "Epoch 7000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0154 - accuracy: 0.0312 - val_loss: 110.6338 - val_accuracy: 0.0000e+00\n",
      "Epoch 7001/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 43.7843 - accuracy: 0.0000e+00 - val_loss: 118.6778 - val_accuracy: 0.0000e+00\n",
      "Epoch 7002/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9244 - accuracy: 0.0000e+00 - val_loss: 133.9828 - val_accuracy: 0.0000e+00\n",
      "Epoch 7003/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 21.9372 - accuracy: 0.0000e+00 - val_loss: 144.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 7004/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.2274 - accuracy: 0.0000e+00 - val_loss: 148.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 7005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0689 - accuracy: 0.0156 - val_loss: 141.8805 - val_accuracy: 0.0000e+00\n",
      "Epoch 7006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1015 - accuracy: 0.0000e+00 - val_loss: 138.6532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7007/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3603 - accuracy: 0.0312 - val_loss: 134.3670 - val_accuracy: 0.0000e+00\n",
      "Epoch 7008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1759 - accuracy: 0.0156 - val_loss: 133.8073 - val_accuracy: 0.0000e+00\n",
      "Epoch 7009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3332 - accuracy: 0.0156 - val_loss: 133.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 7010/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5085 - accuracy: 0.0000e+00 - val_loss: 136.7293 - val_accuracy: 0.0588\n",
      "Epoch 7011/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.1763 - accuracy: 0.0000e+00 - val_loss: 131.6222 - val_accuracy: 0.0588\n",
      "Epoch 7012/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1461 - accuracy: 0.0156 - val_loss: 128.3195 - val_accuracy: 0.0000e+00\n",
      "Epoch 7013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8707 - accuracy: 0.0312 - val_loss: 130.0231 - val_accuracy: 0.0000e+00\n",
      "Epoch 7014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1378 - accuracy: 0.0000e+00 - val_loss: 132.7790 - val_accuracy: 0.0000e+00\n",
      "Epoch 7015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7936 - accuracy: 0.0000e+00 - val_loss: 139.0125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7016/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4352 - accuracy: 0.0000e+00 - val_loss: 139.5382 - val_accuracy: 0.0588\n",
      "Epoch 7017/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.0200 - accuracy: 0.0000e+00 - val_loss: 129.8808 - val_accuracy: 0.0588\n",
      "Epoch 7018/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 26.8836 - accuracy: 0.0156 - val_loss: 127.5108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7019/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0106 - accuracy: 0.0000e+00 - val_loss: 130.6519 - val_accuracy: 0.0000e+00\n",
      "Epoch 7020/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2683 - accuracy: 0.0000e+00 - val_loss: 131.4902 - val_accuracy: 0.0000e+00\n",
      "Epoch 7021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0559 - accuracy: 0.0000e+00 - val_loss: 128.8751 - val_accuracy: 0.0000e+00\n",
      "Epoch 7022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2359 - accuracy: 0.0000e+00 - val_loss: 124.4171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7023/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.5343 - accuracy: 0.0156 - val_loss: 126.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 7024/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 27.4078 - accuracy: 0.0156 - val_loss: 133.3108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7025/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 30.5346 - accuracy: 0.0000e+00 - val_loss: 140.3680 - val_accuracy: 0.0000e+00\n",
      "Epoch 7026/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6845 - accuracy: 0.0156 - val_loss: 138.4516 - val_accuracy: 0.0000e+00\n",
      "Epoch 7027/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2884 - accuracy: 0.0156 - val_loss: 137.6468 - val_accuracy: 0.0000e+00\n",
      "Epoch 7028/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 23.8081 - accuracy: 0.0000e+00 - val_loss: 137.4562 - val_accuracy: 0.0000e+00\n",
      "Epoch 7029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2551 - accuracy: 0.0000e+00 - val_loss: 134.2129 - val_accuracy: 0.0000e+00\n",
      "Epoch 7030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8954 - accuracy: 0.0000e+00 - val_loss: 133.8545 - val_accuracy: 0.0588\n",
      "Epoch 7031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8500 - accuracy: 0.0000e+00 - val_loss: 131.7464 - val_accuracy: 0.0588\n",
      "Epoch 7032/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 30.8674 - accuracy: 0.0156 - val_loss: 134.8424 - val_accuracy: 0.0588\n",
      "Epoch 7033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3293 - accuracy: 0.0000e+00 - val_loss: 143.4429 - val_accuracy: 0.0588\n",
      "Epoch 7034/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7447 - accuracy: 0.0156 - val_loss: 141.2941 - val_accuracy: 0.0000e+00\n",
      "Epoch 7035/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9196 - accuracy: 0.0156 - val_loss: 131.5401 - val_accuracy: 0.0000e+00\n",
      "Epoch 7036/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1497 - accuracy: 0.0000e+00 - val_loss: 126.6689 - val_accuracy: 0.0000e+00\n",
      "Epoch 7037/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7469 - accuracy: 0.0000e+00 - val_loss: 126.6454 - val_accuracy: 0.0588\n",
      "Epoch 7038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8627 - accuracy: 0.0156 - val_loss: 130.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 7039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4924 - accuracy: 0.0156 - val_loss: 139.6600 - val_accuracy: 0.0000e+00\n",
      "Epoch 7040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1468 - accuracy: 0.0312 - val_loss: 148.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 7041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3606 - accuracy: 0.0156 - val_loss: 146.0113 - val_accuracy: 0.0000e+00\n",
      "Epoch 7042/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.1771 - accuracy: 0.0000e+00 - val_loss: 133.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7043/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3315 - accuracy: 0.0000e+00 - val_loss: 123.9942 - val_accuracy: 0.0000e+00\n",
      "Epoch 7044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.0102 - accuracy: 0.0156 - val_loss: 120.9395 - val_accuracy: 0.0588\n",
      "Epoch 7045/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7412 - accuracy: 0.0156 - val_loss: 127.0591 - val_accuracy: 0.0588\n",
      "Epoch 7046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5226 - accuracy: 0.0000e+00 - val_loss: 121.5781 - val_accuracy: 0.1176\n",
      "Epoch 7047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.1627 - accuracy: 0.0156 - val_loss: 122.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 7048/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.3190 - accuracy: 0.0000e+00 - val_loss: 125.2653 - val_accuracy: 0.0000e+00\n",
      "Epoch 7049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6105 - accuracy: 0.0312 - val_loss: 130.5535 - val_accuracy: 0.0588\n",
      "Epoch 7050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3784 - accuracy: 0.0000e+00 - val_loss: 139.8421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4009 - accuracy: 0.0156 - val_loss: 142.2379 - val_accuracy: 0.0000e+00\n",
      "Epoch 7052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3415 - accuracy: 0.0000e+00 - val_loss: 138.3294 - val_accuracy: 0.0000e+00\n",
      "Epoch 7053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4425 - accuracy: 0.0000e+00 - val_loss: 128.6040 - val_accuracy: 0.0000e+00\n",
      "Epoch 7054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4097 - accuracy: 0.0000e+00 - val_loss: 120.7907 - val_accuracy: 0.0000e+00\n",
      "Epoch 7055/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0252 - accuracy: 0.0156 - val_loss: 118.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7056/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.3614 - accuracy: 0.0000e+00 - val_loss: 122.9809 - val_accuracy: 0.0000e+00\n",
      "Epoch 7057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0956 - accuracy: 0.0000e+00 - val_loss: 126.6931 - val_accuracy: 0.0000e+00\n",
      "Epoch 7058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0923 - accuracy: 0.0312 - val_loss: 123.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 7059/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 41.4791 - accuracy: 0.0000e+00 - val_loss: 122.4006 - val_accuracy: 0.0000e+00\n",
      "Epoch 7060/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 16.8441 - accuracy: 0.0156 - val_loss: 122.4374 - val_accuracy: 0.0000e+00\n",
      "Epoch 7061/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3688 - accuracy: 0.0000e+00 - val_loss: 118.5163 - val_accuracy: 0.0588\n",
      "Epoch 7062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9180 - accuracy: 0.0000e+00 - val_loss: 107.8544 - val_accuracy: 0.0588\n",
      "Epoch 7063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8104 - accuracy: 0.0469 - val_loss: 101.0556 - val_accuracy: 0.0000e+00\n",
      "Epoch 7064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1365 - accuracy: 0.0312 - val_loss: 101.6649 - val_accuracy: 0.0000e+00\n",
      "Epoch 7065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6444 - accuracy: 0.0312 - val_loss: 110.9013 - val_accuracy: 0.0000e+00\n",
      "Epoch 7066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0000 - accuracy: 0.0156 - val_loss: 126.4215 - val_accuracy: 0.0588\n",
      "Epoch 7067/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.6818 - accuracy: 0.0000e+00 - val_loss: 136.5104 - val_accuracy: 0.0000e+00\n",
      "Epoch 7068/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8349 - accuracy: 0.0000e+00 - val_loss: 136.0282 - val_accuracy: 0.0000e+00\n",
      "Epoch 7069/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 23.8893 - accuracy: 0.0156 - val_loss: 135.2706 - val_accuracy: 0.0000e+00\n",
      "Epoch 7070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4299 - accuracy: 0.0000e+00 - val_loss: 136.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 7071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7027 - accuracy: 0.0156 - val_loss: 131.7307 - val_accuracy: 0.0000e+00\n",
      "Epoch 7072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2802 - accuracy: 0.0156 - val_loss: 119.2783 - val_accuracy: 0.0000e+00\n",
      "Epoch 7073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3176 - accuracy: 0.0000e+00 - val_loss: 110.1296 - val_accuracy: 0.0000e+00\n",
      "Epoch 7074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5490 - accuracy: 0.0469 - val_loss: 109.6613 - val_accuracy: 0.0588\n",
      "Epoch 7075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4648 - accuracy: 0.0000e+00 - val_loss: 109.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2820 - accuracy: 0.0000e+00 - val_loss: 107.8727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7077/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 18.7439 - accuracy: 0.0469 - val_loss: 108.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 7078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5179 - accuracy: 0.0000e+00 - val_loss: 118.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 7079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0967 - accuracy: 0.0312 - val_loss: 125.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 7080/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 32.7824 - accuracy: 0.0156 - val_loss: 132.0148 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7736 - accuracy: 0.0156 - val_loss: 138.9626 - val_accuracy: 0.0000e+00\n",
      "Epoch 7082/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5826 - accuracy: 0.0156 - val_loss: 137.6414 - val_accuracy: 0.0000e+00\n",
      "Epoch 7083/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1112 - accuracy: 0.0156 - val_loss: 129.0916 - val_accuracy: 0.0000e+00\n",
      "Epoch 7084/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 30.9199 - accuracy: 0.0156 - val_loss: 135.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 7085/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1807 - accuracy: 0.0000e+00 - val_loss: 143.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 7086/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.3565 - accuracy: 0.0156 - val_loss: 147.7343 - val_accuracy: 0.0000e+00\n",
      "Epoch 7087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1839 - accuracy: 0.0000e+00 - val_loss: 144.5490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8980 - accuracy: 0.0000e+00 - val_loss: 141.4415 - val_accuracy: 0.0000e+00\n",
      "Epoch 7089/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4056 - accuracy: 0.0156 - val_loss: 133.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 7090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7711 - accuracy: 0.0000e+00 - val_loss: 127.4983 - val_accuracy: 0.0588\n",
      "Epoch 7091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5970 - accuracy: 0.0312 - val_loss: 122.5370 - val_accuracy: 0.0588\n",
      "Epoch 7092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7929 - accuracy: 0.0156 - val_loss: 126.7513 - val_accuracy: 0.0588\n",
      "Epoch 7093/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7481 - accuracy: 0.0000e+00 - val_loss: 131.1269 - val_accuracy: 0.0000e+00\n",
      "Epoch 7094/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.1767 - accuracy: 0.0000e+00 - val_loss: 121.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 7095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6444 - accuracy: 0.0312 - val_loss: 122.9211 - val_accuracy: 0.1176\n",
      "Epoch 7096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4699 - accuracy: 0.0469 - val_loss: 129.9479 - val_accuracy: 0.1176\n",
      "Epoch 7097/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1629 - accuracy: 0.0156 - val_loss: 141.7874 - val_accuracy: 0.0000e+00\n",
      "Epoch 7098/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8486 - accuracy: 0.0000e+00 - val_loss: 155.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 7099/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1690 - accuracy: 0.0469 - val_loss: 159.4257 - val_accuracy: 0.0000e+00\n",
      "Epoch 7100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.0356 - accuracy: 0.0000e+00 - val_loss: 155.6718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7101/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6343 - accuracy: 0.0312 - val_loss: 143.2758 - val_accuracy: 0.0000e+00\n",
      "Epoch 7102/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.0267 - accuracy: 0.0469 - val_loss: 135.6760 - val_accuracy: 0.0000e+00\n",
      "Epoch 7103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6994 - accuracy: 0.0000e+00 - val_loss: 128.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 7104/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8212 - accuracy: 0.0000e+00 - val_loss: 132.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7105/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.5133 - accuracy: 0.0156 - val_loss: 144.1268 - val_accuracy: 0.0588\n",
      "Epoch 7106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0176 - accuracy: 0.0156 - val_loss: 151.0748 - val_accuracy: 0.0588\n",
      "Epoch 7107/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.4468 - accuracy: 0.0156 - val_loss: 147.6131 - val_accuracy: 0.0588\n",
      "Epoch 7108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5826 - accuracy: 0.0312 - val_loss: 131.8407 - val_accuracy: 0.0588\n",
      "Epoch 7109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4711 - accuracy: 0.0000e+00 - val_loss: 130.4822 - val_accuracy: 0.0588\n",
      "Epoch 7110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8227 - accuracy: 0.0156 - val_loss: 125.7587 - val_accuracy: 0.0588\n",
      "Epoch 7111/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 19.0150 - accuracy: 0.0000e+00 - val_loss: 121.0865 - val_accuracy: 0.0588\n",
      "Epoch 7112/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3492 - accuracy: 0.0000e+00 - val_loss: 119.9115 - val_accuracy: 0.0588\n",
      "Epoch 7113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3946 - accuracy: 0.0000e+00 - val_loss: 121.2152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7114/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7507 - accuracy: 0.0312 - val_loss: 129.6226 - val_accuracy: 0.0000e+00\n",
      "Epoch 7115/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0903 - accuracy: 0.0000e+00 - val_loss: 135.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.5333 - accuracy: 0.0000e+00 - val_loss: 141.0991 - val_accuracy: 0.0588\n",
      "Epoch 7117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2731 - accuracy: 0.0156 - val_loss: 139.2424 - val_accuracy: 0.0588\n",
      "Epoch 7118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5785 - accuracy: 0.0156 - val_loss: 138.0395 - val_accuracy: 0.0588\n",
      "Epoch 7119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0481 - accuracy: 0.0156 - val_loss: 135.6763 - val_accuracy: 0.0000e+00\n",
      "Epoch 7120/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9101 - accuracy: 0.0156 - val_loss: 132.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 7121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5798 - accuracy: 0.0000e+00 - val_loss: 133.3966 - val_accuracy: 0.0000e+00\n",
      "Epoch 7122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7795 - accuracy: 0.0156 - val_loss: 136.3060 - val_accuracy: 0.0588\n",
      "Epoch 7123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7624 - accuracy: 0.0156 - val_loss: 138.5974 - val_accuracy: 0.0000e+00\n",
      "Epoch 7124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1563 - accuracy: 0.0000e+00 - val_loss: 136.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 7125/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.8549 - accuracy: 0.0156 - val_loss: 123.1217 - val_accuracy: 0.0588\n",
      "Epoch 7126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0659 - accuracy: 0.0156 - val_loss: 114.0211 - val_accuracy: 0.0588\n",
      "Epoch 7127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1980 - accuracy: 0.0156 - val_loss: 118.5300 - val_accuracy: 0.0588\n",
      "Epoch 7128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7051 - accuracy: 0.0000e+00 - val_loss: 126.9884 - val_accuracy: 0.0588\n",
      "Epoch 7129/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.5847 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 17.6533 - accuracy: 0.0000e+00 - val_loss: 136.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7130/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4153 - accuracy: 0.0000e+00 - val_loss: 143.5379 - val_accuracy: 0.0000e+00\n",
      "Epoch 7131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8610 - accuracy: 0.0000e+00 - val_loss: 143.0763 - val_accuracy: 0.0588\n",
      "Epoch 7132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1340 - accuracy: 0.0000e+00 - val_loss: 135.4794 - val_accuracy: 0.0588\n",
      "Epoch 7133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4687 - accuracy: 0.0000e+00 - val_loss: 130.1869 - val_accuracy: 0.0000e+00\n",
      "Epoch 7134/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4308 - accuracy: 0.0156 - val_loss: 127.8669 - val_accuracy: 0.1176\n",
      "Epoch 7135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1873 - accuracy: 0.0312 - val_loss: 127.3675 - val_accuracy: 0.0588\n",
      "Epoch 7136/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5868 - accuracy: 0.0000e+00 - val_loss: 140.0546 - val_accuracy: 0.0588\n",
      "Epoch 7137/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7901 - accuracy: 0.0000e+00 - val_loss: 141.2690 - val_accuracy: 0.0588\n",
      "Epoch 7138/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4688 - accuracy: 0.0000e+00 - val_loss: 131.3631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7139/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 17.4699 - accuracy: 0.0312 - val_loss: 125.4957 - val_accuracy: 0.0000e+00\n",
      "Epoch 7140/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.6172 - accuracy: 0.0000e+00 - val_loss: 124.7851 - val_accuracy: 0.0000e+00\n",
      "Epoch 7141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9681 - accuracy: 0.0000e+00 - val_loss: 133.8646 - val_accuracy: 0.0000e+00\n",
      "Epoch 7142/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2937 - accuracy: 0.0000e+00 - val_loss: 143.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 7143/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8596 - accuracy: 0.0000e+00 - val_loss: 149.3797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7144/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8971 - accuracy: 0.0000e+00 - val_loss: 147.5606 - val_accuracy: 0.0588\n",
      "Epoch 7145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.3767 - accuracy: 0.0000e+00 - val_loss: 143.0667 - val_accuracy: 0.0588\n",
      "Epoch 7146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3349 - accuracy: 0.0000e+00 - val_loss: 136.4156 - val_accuracy: 0.0000e+00\n",
      "Epoch 7147/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6724 - accuracy: 0.0000e+00 - val_loss: 129.8761 - val_accuracy: 0.0000e+00\n",
      "Epoch 7148/10000\n",
      "64/64 [==============================] - 0s 73us/step - loss: 27.2980 - accuracy: 0.0000e+00 - val_loss: 133.7831 - val_accuracy: 0.0000e+00\n",
      "Epoch 7149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5933 - accuracy: 0.0000e+00 - val_loss: 131.2681 - val_accuracy: 0.0000e+00\n",
      "Epoch 7150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9547 - accuracy: 0.0000e+00 - val_loss: 130.6307 - val_accuracy: 0.0588\n",
      "Epoch 7151/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4538 - accuracy: 0.0156 - val_loss: 132.1705 - val_accuracy: 0.0000e+00\n",
      "Epoch 7152/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3695 - accuracy: 0.0000e+00 - val_loss: 129.8589 - val_accuracy: 0.0000e+00\n",
      "Epoch 7153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8233 - accuracy: 0.0312 - val_loss: 125.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 7154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9118 - accuracy: 0.0000e+00 - val_loss: 127.6420 - val_accuracy: 0.0000e+00\n",
      "Epoch 7155/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6000 - accuracy: 0.0000e+00 - val_loss: 124.3861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7156/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8947 - accuracy: 0.0156 - val_loss: 124.8382 - val_accuracy: 0.0000e+00\n",
      "Epoch 7157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.7060 - accuracy: 0.0000e+00 - val_loss: 131.2974 - val_accuracy: 0.0000e+00\n",
      "Epoch 7158/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9551 - accuracy: 0.0000e+00 - val_loss: 135.2494 - val_accuracy: 0.0588\n",
      "Epoch 7159/10000\n",
      "64/64 [==============================] - 0s 67us/step - loss: 43.2104 - accuracy: 0.0156 - val_loss: 133.8125 - val_accuracy: 0.0588\n",
      "Epoch 7160/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.3246 - accuracy: 0.0000e+00 - val_loss: 133.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 7161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3171 - accuracy: 0.0000e+00 - val_loss: 129.5791 - val_accuracy: 0.0000e+00\n",
      "Epoch 7162/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.6463 - accuracy: 0.0000e+00 - val_loss: 119.5785 - val_accuracy: 0.0000e+00\n",
      "Epoch 7163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0526 - accuracy: 0.0000e+00 - val_loss: 114.1839 - val_accuracy: 0.0000e+00\n",
      "Epoch 7164/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0854 - accuracy: 0.0156 - val_loss: 115.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7165/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8409 - accuracy: 0.0156 - val_loss: 120.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 7166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7159 - accuracy: 0.0156 - val_loss: 129.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 7167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6059 - accuracy: 0.0156 - val_loss: 127.9082 - val_accuracy: 0.0588\n",
      "Epoch 7168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2603 - accuracy: 0.0156 - val_loss: 128.9594 - val_accuracy: 0.0588\n",
      "Epoch 7169/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 25.4067 - accuracy: 0.0156 - val_loss: 129.9905 - val_accuracy: 0.0000e+00\n",
      "Epoch 7170/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5437 - accuracy: 0.0156 - val_loss: 137.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7171/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 31.9049 - accuracy: 0.0156 - val_loss: 145.5733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7172/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 22.7749 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 23.0006 - accuracy: 0.0000e+00 - val_loss: 151.3168 - val_accuracy: 0.0000e+00\n",
      "Epoch 7173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1493 - accuracy: 0.0312 - val_loss: 151.1639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7174/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2222 - accuracy: 0.0000e+00 - val_loss: 144.8846 - val_accuracy: 0.0588\n",
      "Epoch 7175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4616 - accuracy: 0.0000e+00 - val_loss: 140.7117 - val_accuracy: 0.0588\n",
      "Epoch 7176/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0537 - accuracy: 0.0156 - val_loss: 145.9990 - val_accuracy: 0.0588\n",
      "Epoch 7177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4858 - accuracy: 0.0000e+00 - val_loss: 136.2711 - val_accuracy: 0.0000e+00\n",
      "Epoch 7178/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 18.8990 - accuracy: 0.0000e+00 - val_loss: 127.5149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7179/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.6992 - accuracy: 0.0000e+00 - val_loss: 120.5182 - val_accuracy: 0.0588\n",
      "Epoch 7180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9714 - accuracy: 0.0156 - val_loss: 119.4416 - val_accuracy: 0.0588\n",
      "Epoch 7181/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 27.6889 - accuracy: 0.0000e+00 - val_loss: 124.5152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1207 - accuracy: 0.0312 - val_loss: 130.9902 - val_accuracy: 0.0000e+00\n",
      "Epoch 7183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8901 - accuracy: 0.0156 - val_loss: 131.1918 - val_accuracy: 0.0000e+00\n",
      "Epoch 7184/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6208 - accuracy: 0.0156 - val_loss: 129.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 7185/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 24.2812 - accuracy: 0.0156 - val_loss: 130.2046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7513 - accuracy: 0.0156 - val_loss: 131.4249 - val_accuracy: 0.0000e+00\n",
      "Epoch 7187/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 34.6112 - accuracy: 0.0000e+00 - val_loss: 136.7606 - val_accuracy: 0.0588\n",
      "Epoch 7188/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0253 - accuracy: 0.0156 - val_loss: 139.6613 - val_accuracy: 0.0588\n",
      "Epoch 7189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9697 - accuracy: 0.0312 - val_loss: 139.0854 - val_accuracy: 0.0588\n",
      "Epoch 7190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1560 - accuracy: 0.0156 - val_loss: 140.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 7191/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1521 - accuracy: 0.0000e+00 - val_loss: 137.1880 - val_accuracy: 0.0588\n",
      "Epoch 7192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3706 - accuracy: 0.0000e+00 - val_loss: 130.0461 - val_accuracy: 0.0588\n",
      "Epoch 7193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0833 - accuracy: 0.0156 - val_loss: 119.3224 - val_accuracy: 0.0588\n",
      "Epoch 7194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8911 - accuracy: 0.0000e+00 - val_loss: 118.6168 - val_accuracy: 0.1176\n",
      "Epoch 7195/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8393 - accuracy: 0.0000e+00 - val_loss: 125.0472 - val_accuracy: 0.0588\n",
      "Epoch 7196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.2146 - accuracy: 0.0156 - val_loss: 130.0506 - val_accuracy: 0.0000e+00\n",
      "Epoch 7197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4800 - accuracy: 0.0156 - val_loss: 129.4402 - val_accuracy: 0.0000e+00\n",
      "Epoch 7198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1980 - accuracy: 0.0156 - val_loss: 124.2949 - val_accuracy: 0.0588\n",
      "Epoch 7199/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3754 - accuracy: 0.0000e+00 - val_loss: 123.2600 - val_accuracy: 0.0000e+00\n",
      "Epoch 7200/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.9215 - accuracy: 0.0000e+00 - val_loss: 128.0391 - val_accuracy: 0.0588\n",
      "Epoch 7201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6321 - accuracy: 0.0000e+00 - val_loss: 133.5995 - val_accuracy: 0.0000e+00\n",
      "Epoch 7202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0964 - accuracy: 0.0000e+00 - val_loss: 136.0539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2915 - accuracy: 0.0156 - val_loss: 136.9010 - val_accuracy: 0.0000e+00\n",
      "Epoch 7204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7487 - accuracy: 0.0312 - val_loss: 135.7467 - val_accuracy: 0.0000e+00\n",
      "Epoch 7205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7768 - accuracy: 0.0000e+00 - val_loss: 136.7590 - val_accuracy: 0.0000e+00\n",
      "Epoch 7206/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3908 - accuracy: 0.0000e+00 - val_loss: 146.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 7207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7211 - accuracy: 0.0312 - val_loss: 150.2925 - val_accuracy: 0.0000e+00\n",
      "Epoch 7208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1904 - accuracy: 0.0000e+00 - val_loss: 146.0081 - val_accuracy: 0.0000e+00\n",
      "Epoch 7209/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6986 - accuracy: 0.0312 - val_loss: 136.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 7210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8128 - accuracy: 0.0000e+00 - val_loss: 131.7979 - val_accuracy: 0.0000e+00\n",
      "Epoch 7211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0531 - accuracy: 0.0000e+00 - val_loss: 132.4532 - val_accuracy: 0.0588\n",
      "Epoch 7212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6438 - accuracy: 0.0000e+00 - val_loss: 136.7315 - val_accuracy: 0.0588\n",
      "Epoch 7213/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 22.1221 - accuracy: 0.0156 - val_loss: 136.6610 - val_accuracy: 0.0588\n",
      "Epoch 7214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3793 - accuracy: 0.0156 - val_loss: 132.4345 - val_accuracy: 0.0588\n",
      "Epoch 7215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3293 - accuracy: 0.0156 - val_loss: 129.2243 - val_accuracy: 0.0588\n",
      "Epoch 7216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4476 - accuracy: 0.0312 - val_loss: 121.5911 - val_accuracy: 0.0588\n",
      "Epoch 7217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6263 - accuracy: 0.0000e+00 - val_loss: 108.4667 - val_accuracy: 0.0588\n",
      "Epoch 7218/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.7654 - accuracy: 0.0000e+00 - val_loss: 104.9272 - val_accuracy: 0.0588\n",
      "Epoch 7219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1775 - accuracy: 0.0000e+00 - val_loss: 115.6585 - val_accuracy: 0.0588\n",
      "Epoch 7220/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9509 - accuracy: 0.0000e+00 - val_loss: 136.1793 - val_accuracy: 0.0000e+00\n",
      "Epoch 7221/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 23.5489 - accuracy: 0.0469 - val_loss: 149.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1791 - accuracy: 0.0000e+00 - val_loss: 151.8485 - val_accuracy: 0.0588\n",
      "Epoch 7223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8416 - accuracy: 0.0000e+00 - val_loss: 142.9645 - val_accuracy: 0.0000e+00\n",
      "Epoch 7224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0360 - accuracy: 0.0000e+00 - val_loss: 130.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2681 - accuracy: 0.0000e+00 - val_loss: 120.2254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2935 - accuracy: 0.0000e+00 - val_loss: 122.5185 - val_accuracy: 0.0000e+00\n",
      "Epoch 7227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7469 - accuracy: 0.0000e+00 - val_loss: 135.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 7228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0297 - accuracy: 0.0000e+00 - val_loss: 140.6861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2543 - accuracy: 0.0000e+00 - val_loss: 143.9450 - val_accuracy: 0.0000e+00\n",
      "Epoch 7230/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0937 - accuracy: 0.0156 - val_loss: 142.2921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8044 - accuracy: 0.0312 - val_loss: 137.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 7232/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4811 - accuracy: 0.0312 - val_loss: 130.3044 - val_accuracy: 0.0000e+00\n",
      "Epoch 7233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9485 - accuracy: 0.0156 - val_loss: 125.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 7234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.0345 - accuracy: 0.0000e+00 - val_loss: 130.2015 - val_accuracy: 0.0000e+00\n",
      "Epoch 7235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8812 - accuracy: 0.0000e+00 - val_loss: 138.4534 - val_accuracy: 0.0000e+00\n",
      "Epoch 7236/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5744 - accuracy: 0.0156 - val_loss: 137.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 7237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0860 - accuracy: 0.0000e+00 - val_loss: 136.2314 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6457 - accuracy: 0.0156 - val_loss: 133.8310 - val_accuracy: 0.0000e+00\n",
      "Epoch 7239/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3312 - accuracy: 0.0000e+00 - val_loss: 136.5045 - val_accuracy: 0.0588\n",
      "Epoch 7240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6870 - accuracy: 0.0000e+00 - val_loss: 138.3139 - val_accuracy: 0.0000e+00\n",
      "Epoch 7241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0185 - accuracy: 0.0000e+00 - val_loss: 139.7702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2086 - accuracy: 0.0312 - val_loss: 133.3127 - val_accuracy: 0.0000e+00\n",
      "Epoch 7243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0622 - accuracy: 0.0156 - val_loss: 138.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 7244/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4237 - accuracy: 0.0000e+00 - val_loss: 142.0585 - val_accuracy: 0.0588\n",
      "Epoch 7245/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.1954 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 28.9025 - accuracy: 0.0000e+00 - val_loss: 137.2698 - val_accuracy: 0.0588\n",
      "Epoch 7246/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5505 - accuracy: 0.0000e+00 - val_loss: 128.3779 - val_accuracy: 0.0588\n",
      "Epoch 7247/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1915 - accuracy: 0.0156 - val_loss: 129.0472 - val_accuracy: 0.0000e+00\n",
      "Epoch 7248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2085 - accuracy: 0.0000e+00 - val_loss: 134.2251 - val_accuracy: 0.0000e+00\n",
      "Epoch 7249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9626 - accuracy: 0.0000e+00 - val_loss: 137.2714 - val_accuracy: 0.0000e+00\n",
      "Epoch 7250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5499 - accuracy: 0.0000e+00 - val_loss: 135.9400 - val_accuracy: 0.0000e+00\n",
      "Epoch 7251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.1283 - accuracy: 0.0312 - val_loss: 136.3293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7468 - accuracy: 0.0000e+00 - val_loss: 142.4744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7253/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 18.5672 - accuracy: 0.0000e+00 - val_loss: 146.4363 - val_accuracy: 0.0000e+00\n",
      "Epoch 7254/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3532 - accuracy: 0.0000e+00 - val_loss: 143.9399 - val_accuracy: 0.0000e+00\n",
      "Epoch 7255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0588 - accuracy: 0.0000e+00 - val_loss: 142.3102 - val_accuracy: 0.0000e+00\n",
      "Epoch 7256/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7692 - accuracy: 0.0000e+00 - val_loss: 139.8853 - val_accuracy: 0.0000e+00\n",
      "Epoch 7257/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7315 - accuracy: 0.0156 - val_loss: 133.8673 - val_accuracy: 0.0000e+00\n",
      "Epoch 7258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2809 - accuracy: 0.0000e+00 - val_loss: 131.6684 - val_accuracy: 0.0000e+00\n",
      "Epoch 7259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4915 - accuracy: 0.0156 - val_loss: 133.6771 - val_accuracy: 0.0000e+00\n",
      "Epoch 7260/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.9863 - accuracy: 0.0000e+00 - val_loss: 134.3921 - val_accuracy: 0.0000e+00\n",
      "Epoch 7261/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5293 - accuracy: 0.0000e+00 - val_loss: 130.7229 - val_accuracy: 0.0000e+00\n",
      "Epoch 7262/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8793 - accuracy: 0.0156 - val_loss: 126.6469 - val_accuracy: 0.0000e+00\n",
      "Epoch 7263/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9236 - accuracy: 0.0000e+00 - val_loss: 126.6803 - val_accuracy: 0.0588\n",
      "Epoch 7264/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 23.6787 - accuracy: 0.0156 - val_loss: 131.3265 - val_accuracy: 0.0588\n",
      "Epoch 7265/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5131 - accuracy: 0.0156 - val_loss: 140.1561 - val_accuracy: 0.0000e+00\n",
      "Epoch 7266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0883 - accuracy: 0.0156 - val_loss: 146.0586 - val_accuracy: 0.0000e+00\n",
      "Epoch 7267/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 33.3037 - accuracy: 0.0156 - val_loss: 143.2090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7268/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5383 - accuracy: 0.0000e+00 - val_loss: 138.9810 - val_accuracy: 0.0588\n",
      "Epoch 7269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4621 - accuracy: 0.0000e+00 - val_loss: 131.1890 - val_accuracy: 0.0000e+00\n",
      "Epoch 7270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2347 - accuracy: 0.0312 - val_loss: 127.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5626 - accuracy: 0.0000e+00 - val_loss: 129.8506 - val_accuracy: 0.0000e+00\n",
      "Epoch 7272/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5644 - accuracy: 0.0156 - val_loss: 133.6824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3381 - accuracy: 0.0312 - val_loss: 134.3486 - val_accuracy: 0.0000e+00\n",
      "Epoch 7274/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.5796 - accuracy: 0.0156 - val_loss: 131.5331 - val_accuracy: 0.0000e+00\n",
      "Epoch 7275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2084 - accuracy: 0.0000e+00 - val_loss: 122.6774 - val_accuracy: 0.0000e+00\n",
      "Epoch 7276/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7918 - accuracy: 0.0000e+00 - val_loss: 114.5536 - val_accuracy: 0.0000e+00\n",
      "Epoch 7277/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 28.9625 - accuracy: 0.0156 - val_loss: 117.5191 - val_accuracy: 0.0000e+00\n",
      "Epoch 7278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3161 - accuracy: 0.0000e+00 - val_loss: 130.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 7279/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1689 - accuracy: 0.0156 - val_loss: 141.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 7280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0221 - accuracy: 0.0156 - val_loss: 144.8559 - val_accuracy: 0.0000e+00\n",
      "Epoch 7281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3376 - accuracy: 0.0000e+00 - val_loss: 137.0188 - val_accuracy: 0.0588\n",
      "Epoch 7282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1056 - accuracy: 0.0156 - val_loss: 125.2098 - val_accuracy: 0.0588\n",
      "Epoch 7283/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.1281 - accuracy: 0.0000e+00 - val_loss: 122.4118 - val_accuracy: 0.0588\n",
      "Epoch 7284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7691 - accuracy: 0.0000e+00 - val_loss: 122.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.2261 - accuracy: 0.0156 - val_loss: 123.9698 - val_accuracy: 0.0000e+00\n",
      "Epoch 7286/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.5447 - accuracy: 0.0156 - val_loss: 134.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 7287/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5988 - accuracy: 0.0156 - val_loss: 138.7954 - val_accuracy: 0.0000e+00\n",
      "Epoch 7288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7577 - accuracy: 0.0000e+00 - val_loss: 141.6220 - val_accuracy: 0.0000e+00\n",
      "Epoch 7289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8921 - accuracy: 0.0000e+00 - val_loss: 141.0968 - val_accuracy: 0.0000e+00\n",
      "Epoch 7290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1389 - accuracy: 0.0156 - val_loss: 140.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 7291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4486 - accuracy: 0.0156 - val_loss: 140.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 7292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2243 - accuracy: 0.0312 - val_loss: 141.4888 - val_accuracy: 0.0000e+00\n",
      "Epoch 7293/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.0159 - accuracy: 0.031 - 0s 125us/step - loss: 18.3628 - accuracy: 0.0156 - val_loss: 142.2381 - val_accuracy: 0.0000e+00\n",
      "Epoch 7294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9091 - accuracy: 0.0000e+00 - val_loss: 139.6358 - val_accuracy: 0.0588\n",
      "Epoch 7295/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 18.5073 - accuracy: 0.0000e+00 - val_loss: 131.9465 - val_accuracy: 0.0000e+00\n",
      "Epoch 7296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6269 - accuracy: 0.0000e+00 - val_loss: 125.4319 - val_accuracy: 0.0588\n",
      "Epoch 7297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5829 - accuracy: 0.0000e+00 - val_loss: 122.6451 - val_accuracy: 0.0588\n",
      "Epoch 7298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9921 - accuracy: 0.0000e+00 - val_loss: 119.8073 - val_accuracy: 0.0588\n",
      "Epoch 7299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2209 - accuracy: 0.0000e+00 - val_loss: 122.0223 - val_accuracy: 0.0000e+00\n",
      "Epoch 7300/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.8268 - accuracy: 0.0156 - val_loss: 125.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 7301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2081 - accuracy: 0.0156 - val_loss: 126.3170 - val_accuracy: 0.0000e+00\n",
      "Epoch 7302/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4088 - accuracy: 0.0156 - val_loss: 128.8638 - val_accuracy: 0.0000e+00\n",
      "Epoch 7303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9236 - accuracy: 0.0000e+00 - val_loss: 129.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0792 - accuracy: 0.0000e+00 - val_loss: 130.3702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7305/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1312 - accuracy: 0.0156 - val_loss: 138.3245 - val_accuracy: 0.0588\n",
      "Epoch 7306/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1997 - accuracy: 0.0000e+00 - val_loss: 142.8558 - val_accuracy: 0.0000e+00\n",
      "Epoch 7307/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 27.2078 - accuracy: 0.0156 - val_loss: 140.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 7308/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.8288 - accuracy: 0.0000e+00 - val_loss: 131.4856 - val_accuracy: 0.0000e+00\n",
      "Epoch 7309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2454 - accuracy: 0.0156 - val_loss: 126.3762 - val_accuracy: 0.0000e+00\n",
      "Epoch 7310/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7823 - accuracy: 0.0000e+00 - val_loss: 124.5108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7311/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2010 - accuracy: 0.0156 - val_loss: 124.5830 - val_accuracy: 0.0000e+00\n",
      "Epoch 7312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8197 - accuracy: 0.0000e+00 - val_loss: 129.4607 - val_accuracy: 0.0000e+00\n",
      "Epoch 7313/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6854 - accuracy: 0.0469 - val_loss: 126.6558 - val_accuracy: 0.0588\n",
      "Epoch 7314/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.7063 - accuracy: 0.0000e+00 - val_loss: 123.7247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7315/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2844 - accuracy: 0.0469 - val_loss: 124.3811 - val_accuracy: 0.0588\n",
      "Epoch 7316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6367 - accuracy: 0.0000e+00 - val_loss: 131.7975 - val_accuracy: 0.0000e+00\n",
      "Epoch 7317/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0614 - accuracy: 0.0000e+00 - val_loss: 140.4254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7318/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.3439 - accuracy: 0.0000e+0 - 0s 39us/step - loss: 22.5448 - accuracy: 0.0000e+00 - val_loss: 144.8674 - val_accuracy: 0.0000e+00\n",
      "Epoch 7319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8752 - accuracy: 0.0000e+00 - val_loss: 145.1374 - val_accuracy: 0.0588\n",
      "Epoch 7320/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8147 - accuracy: 0.0156 - val_loss: 138.5046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7321/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 28.2966 - accuracy: 0.0000e+00 - val_loss: 129.1983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7322/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3280 - accuracy: 0.0000e+00 - val_loss: 128.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 7323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6228 - accuracy: 0.0312 - val_loss: 133.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 7324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2002 - accuracy: 0.0156 - val_loss: 136.2022 - val_accuracy: 0.0000e+00\n",
      "Epoch 7325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6929 - accuracy: 0.0000e+00 - val_loss: 132.3744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7326/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.3530 - accuracy: 0.0156 - val_loss: 127.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 7327/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8058 - accuracy: 0.0156 - val_loss: 130.1424 - val_accuracy: 0.0588\n",
      "Epoch 7328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.8338 - accuracy: 0.0000e+00 - val_loss: 132.1267 - val_accuracy: 0.0588\n",
      "Epoch 7329/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 30.2457 - accuracy: 0.0156 - val_loss: 129.9348 - val_accuracy: 0.0000e+00\n",
      "Epoch 7330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0350 - accuracy: 0.0000e+00 - val_loss: 128.3092 - val_accuracy: 0.0000e+00\n",
      "Epoch 7331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3062 - accuracy: 0.0000e+00 - val_loss: 128.1768 - val_accuracy: 0.0000e+00\n",
      "Epoch 7332/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4233 - accuracy: 0.0312 - val_loss: 122.6817 - val_accuracy: 0.1176\n",
      "Epoch 7333/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 14.0393 - accuracy: 0.0469 - val_loss: 117.3306 - val_accuracy: 0.1176\n",
      "Epoch 7334/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2301 - accuracy: 0.0000e+00 - val_loss: 116.4525 - val_accuracy: 0.0588\n",
      "Epoch 7335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3337 - accuracy: 0.0000e+00 - val_loss: 126.0365 - val_accuracy: 0.0588\n",
      "Epoch 7336/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.4884 - accuracy: 0.0000e+00 - val_loss: 130.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 7337/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2002 - accuracy: 0.0000e+00 - val_loss: 126.3651 - val_accuracy: 0.0000e+00\n",
      "Epoch 7338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4590 - accuracy: 0.0156 - val_loss: 121.8370 - val_accuracy: 0.0000e+00\n",
      "Epoch 7339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9349 - accuracy: 0.0000e+00 - val_loss: 119.7704 - val_accuracy: 0.0000e+00\n",
      "Epoch 7340/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2328 - accuracy: 0.0156 - val_loss: 127.2060 - val_accuracy: 0.0000e+00\n",
      "Epoch 7341/10000\n",
      "64/64 [==============================] - 0s 220us/step - loss: 22.1937 - accuracy: 0.0000e+00 - val_loss: 129.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 7342/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 23.5934 - accuracy: 0.0000e+00 - val_loss: 123.2279 - val_accuracy: 0.0000e+00\n",
      "Epoch 7343/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7404 - accuracy: 0.0156 - val_loss: 116.7734 - val_accuracy: 0.0588\n",
      "Epoch 7344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4013 - accuracy: 0.0000e+00 - val_loss: 122.8673 - val_accuracy: 0.0588\n",
      "Epoch 7345/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4569 - accuracy: 0.0156 - val_loss: 130.7116 - val_accuracy: 0.0588\n",
      "Epoch 7346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4149 - accuracy: 0.0000e+00 - val_loss: 134.3315 - val_accuracy: 0.0588\n",
      "Epoch 7347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9403 - accuracy: 0.0156 - val_loss: 131.8832 - val_accuracy: 0.0000e+00\n",
      "Epoch 7348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8040 - accuracy: 0.0000e+00 - val_loss: 126.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 7349/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9981 - accuracy: 0.0156 - val_loss: 122.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 7350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3769 - accuracy: 0.0000e+00 - val_loss: 128.5266 - val_accuracy: 0.0000e+00\n",
      "Epoch 7351/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 36.7076 - accuracy: 0.0000e+00 - val_loss: 137.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 7352/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 24.7051 - accuracy: 0.0000e+00 - val_loss: 143.3935 - val_accuracy: 0.0588\n",
      "Epoch 7353/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.2504 - accuracy: 0.0156 - val_loss: 145.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 7354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0877 - accuracy: 0.0000e+00 - val_loss: 140.7150 - val_accuracy: 0.0000e+00\n",
      "Epoch 7355/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.8920 - accuracy: 0.0156 - val_loss: 132.1567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7727 - accuracy: 0.0312 - val_loss: 123.7662 - val_accuracy: 0.0000e+00\n",
      "Epoch 7357/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9462 - accuracy: 0.0156 - val_loss: 121.7076 - val_accuracy: 0.0000e+00\n",
      "Epoch 7358/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2505 - accuracy: 0.0000e+00 - val_loss: 122.8617 - val_accuracy: 0.0000e+00\n",
      "Epoch 7359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3751 - accuracy: 0.0156 - val_loss: 126.2473 - val_accuracy: 0.0000e+00\n",
      "Epoch 7360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5638 - accuracy: 0.0000e+00 - val_loss: 132.6357 - val_accuracy: 0.0588\n",
      "Epoch 7361/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0707 - accuracy: 0.0156 - val_loss: 137.7129 - val_accuracy: 0.0588\n",
      "Epoch 7362/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 23.8340 - accuracy: 0.0000e+00 - val_loss: 139.9539 - val_accuracy: 0.0588\n",
      "Epoch 7363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6022 - accuracy: 0.0000e+00 - val_loss: 132.0808 - val_accuracy: 0.0588\n",
      "Epoch 7364/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.4649 - accuracy: 0.0000e+00 - val_loss: 120.6018 - val_accuracy: 0.0588\n",
      "Epoch 7365/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0900 - accuracy: 0.0156 - val_loss: 113.8996 - val_accuracy: 0.0588\n",
      "Epoch 7366/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7258 - accuracy: 0.0000e+00 - val_loss: 124.2350 - val_accuracy: 0.0588\n",
      "Epoch 7367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5727 - accuracy: 0.0156 - val_loss: 140.1811 - val_accuracy: 0.0588\n",
      "Epoch 7368/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4792 - accuracy: 0.0156 - val_loss: 146.9068 - val_accuracy: 0.0588\n",
      "Epoch 7369/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7355 - accuracy: 0.0312 - val_loss: 147.4946 - val_accuracy: 0.1176\n",
      "Epoch 7370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9719 - accuracy: 0.0000e+00 - val_loss: 143.1221 - val_accuracy: 0.0588\n",
      "Epoch 7371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7272 - accuracy: 0.0156 - val_loss: 138.3929 - val_accuracy: 0.1176\n",
      "Epoch 7372/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1839 - accuracy: 0.0156 - val_loss: 131.0270 - val_accuracy: 0.0588\n",
      "Epoch 7373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6714 - accuracy: 0.0156 - val_loss: 127.9178 - val_accuracy: 0.0588\n",
      "Epoch 7374/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 24.1616 - accuracy: 0.0000e+00 - val_loss: 134.7498 - val_accuracy: 0.0588\n",
      "Epoch 7375/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4687 - accuracy: 0.0000e+00 - val_loss: 141.3537 - val_accuracy: 0.0588\n",
      "Epoch 7376/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9153 - accuracy: 0.0156 - val_loss: 144.9472 - val_accuracy: 0.0588\n",
      "Epoch 7377/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3986 - accuracy: 0.0000e+00 - val_loss: 143.7198 - val_accuracy: 0.0588\n",
      "Epoch 7378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8392 - accuracy: 0.0000e+00 - val_loss: 140.4272 - val_accuracy: 0.0588\n",
      "Epoch 7379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6051 - accuracy: 0.0000e+00 - val_loss: 135.2568 - val_accuracy: 0.0588\n",
      "Epoch 7380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1057 - accuracy: 0.0156 - val_loss: 130.2038 - val_accuracy: 0.0000e+00\n",
      "Epoch 7381/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1302 - accuracy: 0.0000e+00 - val_loss: 123.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7382/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5521 - accuracy: 0.0000e+00 - val_loss: 123.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3044 - accuracy: 0.0156 - val_loss: 124.3664 - val_accuracy: 0.0000e+00\n",
      "Epoch 7384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7944 - accuracy: 0.0312 - val_loss: 127.2949 - val_accuracy: 0.0000e+00\n",
      "Epoch 7385/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 20.4914 - accuracy: 0.0312 - val_loss: 130.3388 - val_accuracy: 0.0000e+00\n",
      "Epoch 7386/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9729 - accuracy: 0.0000e+00 - val_loss: 132.7600 - val_accuracy: 0.0588\n",
      "Epoch 7387/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.6872 - accuracy: 0.0156 - val_loss: 139.6659 - val_accuracy: 0.0588\n",
      "Epoch 7388/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1331 - accuracy: 0.0000e+00 - val_loss: 146.3619 - val_accuracy: 0.0588\n",
      "Epoch 7389/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9085 - accuracy: 0.0000e+00 - val_loss: 147.7374 - val_accuracy: 0.0588\n",
      "Epoch 7390/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4277 - accuracy: 0.0156 - val_loss: 144.4924 - val_accuracy: 0.0000e+00\n",
      "Epoch 7391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8775 - accuracy: 0.0000e+00 - val_loss: 139.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 7392/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0719 - accuracy: 0.0156 - val_loss: 138.9012 - val_accuracy: 0.0588\n",
      "Epoch 7393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7010 - accuracy: 0.0156 - val_loss: 137.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 7394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8284 - accuracy: 0.0000e+00 - val_loss: 136.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 7395/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 19.3868 - accuracy: 0.0156 - val_loss: 137.4305 - val_accuracy: 0.0588\n",
      "Epoch 7396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5534 - accuracy: 0.0000e+00 - val_loss: 131.5473 - val_accuracy: 0.0588\n",
      "Epoch 7397/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 17.4015 - accuracy: 0.0156 - val_loss: 127.7285 - val_accuracy: 0.0588\n",
      "Epoch 7398/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2493 - accuracy: 0.0156 - val_loss: 125.0948 - val_accuracy: 0.0000e+00\n",
      "Epoch 7399/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7548 - accuracy: 0.0156 - val_loss: 127.3341 - val_accuracy: 0.0000e+00\n",
      "Epoch 7400/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2992 - accuracy: 0.0156 - val_loss: 129.5748 - val_accuracy: 0.0000e+00\n",
      "Epoch 7401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2069 - accuracy: 0.0156 - val_loss: 126.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 7402/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.5948 - accuracy: 0.0156 - val_loss: 129.1599 - val_accuracy: 0.0588\n",
      "Epoch 7403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4343 - accuracy: 0.0156 - val_loss: 125.5627 - val_accuracy: 0.0000e+00\n",
      "Epoch 7404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3999 - accuracy: 0.0156 - val_loss: 126.0998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.0525 - accuracy: 0.0469 - val_loss: 131.0509 - val_accuracy: 0.0588\n",
      "Epoch 7406/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 18.8642 - accuracy: 0.0156 - val_loss: 132.4939 - val_accuracy: 0.0588\n",
      "Epoch 7407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4496 - accuracy: 0.0156 - val_loss: 135.8622 - val_accuracy: 0.0000e+00\n",
      "Epoch 7408/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.8022 - accuracy: 0.0000e+00 - val_loss: 139.9848 - val_accuracy: 0.0000e+00\n",
      "Epoch 7409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2206 - accuracy: 0.0000e+00 - val_loss: 138.0463 - val_accuracy: 0.0000e+00\n",
      "Epoch 7410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2273 - accuracy: 0.0000e+00 - val_loss: 136.8024 - val_accuracy: 0.0588\n",
      "Epoch 7411/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5888 - accuracy: 0.0156 - val_loss: 139.4359 - val_accuracy: 0.0588\n",
      "Epoch 7412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7017 - accuracy: 0.0156 - val_loss: 141.6357 - val_accuracy: 0.0588\n",
      "Epoch 7413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8008 - accuracy: 0.0000e+00 - val_loss: 144.4881 - val_accuracy: 0.0000e+00\n",
      "Epoch 7414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6140 - accuracy: 0.0312 - val_loss: 143.7868 - val_accuracy: 0.0000e+00\n",
      "Epoch 7415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0996 - accuracy: 0.0000e+00 - val_loss: 138.1125 - val_accuracy: 0.0588\n",
      "Epoch 7416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5955 - accuracy: 0.0469 - val_loss: 138.9357 - val_accuracy: 0.0588\n",
      "Epoch 7417/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5078 - accuracy: 0.0156 - val_loss: 141.4992 - val_accuracy: 0.0588\n",
      "Epoch 7418/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 20.8541 - accuracy: 0.0156 - val_loss: 140.3371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7419/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.6697 - accuracy: 0.0000e+00 - val_loss: 135.1352 - val_accuracy: 0.0000e+00\n",
      "Epoch 7420/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2284 - accuracy: 0.0156 - val_loss: 134.1636 - val_accuracy: 0.0000e+00\n",
      "Epoch 7421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4107 - accuracy: 0.0000e+00 - val_loss: 135.9014 - val_accuracy: 0.0000e+00\n",
      "Epoch 7422/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3976 - accuracy: 0.0156 - val_loss: 137.0108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7423/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.1706 - accuracy: 0.0000e+00 - val_loss: 139.7251 - val_accuracy: 0.0000e+00\n",
      "Epoch 7424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9726 - accuracy: 0.0000e+00 - val_loss: 141.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 7425/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9744 - accuracy: 0.0469 - val_loss: 141.8119 - val_accuracy: 0.0000e+00\n",
      "Epoch 7426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7036 - accuracy: 0.0156 - val_loss: 135.6266 - val_accuracy: 0.0588\n",
      "Epoch 7427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0697 - accuracy: 0.0000e+00 - val_loss: 124.4140 - val_accuracy: 0.0588\n",
      "Epoch 7428/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8502 - accuracy: 0.0000e+00 - val_loss: 121.0051 - val_accuracy: 0.0588\n",
      "Epoch 7429/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9186 - accuracy: 0.0156 - val_loss: 120.2671 - val_accuracy: 0.0000e+00\n",
      "Epoch 7430/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 32.1980 - accuracy: 0.0000e+00 - val_loss: 121.0876 - val_accuracy: 0.0000e+00\n",
      "Epoch 7431/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5263 - accuracy: 0.0312 - val_loss: 123.3114 - val_accuracy: 0.0588\n",
      "Epoch 7432/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0123 - accuracy: 0.0000e+00 - val_loss: 123.6576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7433/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.3461 - accuracy: 0.0312 - val_loss: 125.6850 - val_accuracy: 0.0588\n",
      "Epoch 7434/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 21.3900 - accuracy: 0.0000e+00 - val_loss: 123.9100 - val_accuracy: 0.0000e+00\n",
      "Epoch 7435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4228 - accuracy: 0.0000e+00 - val_loss: 129.9516 - val_accuracy: 0.0588\n",
      "Epoch 7436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1631 - accuracy: 0.0000e+00 - val_loss: 138.7932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7437/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3118 - accuracy: 0.0156 - val_loss: 140.0785 - val_accuracy: 0.0588\n",
      "Epoch 7438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1318 - accuracy: 0.0156 - val_loss: 134.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 7439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3727 - accuracy: 0.0000e+00 - val_loss: 128.7371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7440/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9256 - accuracy: 0.0000e+00 - val_loss: 121.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 7441/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.5688 - accuracy: 0.0156 - val_loss: 122.2857 - val_accuracy: 0.0000e+00\n",
      "Epoch 7442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9508 - accuracy: 0.0156 - val_loss: 127.3889 - val_accuracy: 0.0000e+00\n",
      "Epoch 7443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0359 - accuracy: 0.0000e+00 - val_loss: 135.7779 - val_accuracy: 0.0000e+00\n",
      "Epoch 7444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2568 - accuracy: 0.0469 - val_loss: 146.2771 - val_accuracy: 0.0000e+00\n",
      "Epoch 7445/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9670 - accuracy: 0.0156 - val_loss: 151.5379 - val_accuracy: 0.0588\n",
      "Epoch 7446/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2932 - accuracy: 0.0000e+00 - val_loss: 152.4220 - val_accuracy: 0.0588\n",
      "Epoch 7447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3582 - accuracy: 0.0312 - val_loss: 138.6395 - val_accuracy: 0.0000e+00\n",
      "Epoch 7448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 22.7600 - accuracy: 0.0156 - val_loss: 131.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2821 - accuracy: 0.0156 - val_loss: 127.2710 - val_accuracy: 0.0000e+00\n",
      "Epoch 7450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8173 - accuracy: 0.0000e+00 - val_loss: 128.9753 - val_accuracy: 0.0000e+00\n",
      "Epoch 7451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3771 - accuracy: 0.0156 - val_loss: 133.4016 - val_accuracy: 0.0000e+00\n",
      "Epoch 7452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8491 - accuracy: 0.0156 - val_loss: 134.5292 - val_accuracy: 0.0000e+00\n",
      "Epoch 7453/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9423 - accuracy: 0.0156 - val_loss: 142.0368 - val_accuracy: 0.0000e+00\n",
      "Epoch 7454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1780 - accuracy: 0.0156 - val_loss: 143.9655 - val_accuracy: 0.0588\n",
      "Epoch 7455/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0025 - accuracy: 0.0156 - val_loss: 135.2306 - val_accuracy: 0.0588\n",
      "Epoch 7456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.9862 - accuracy: 0.0312 - val_loss: 132.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 7457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2999 - accuracy: 0.0000e+00 - val_loss: 132.9360 - val_accuracy: 0.0000e+00\n",
      "Epoch 7458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5513 - accuracy: 0.0000e+00 - val_loss: 131.3288 - val_accuracy: 0.0000e+00\n",
      "Epoch 7459/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3113 - accuracy: 0.0156 - val_loss: 126.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 7460/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7617 - accuracy: 0.0000e+00 - val_loss: 121.5731 - val_accuracy: 0.0588\n",
      "Epoch 7461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9977 - accuracy: 0.0156 - val_loss: 119.2215 - val_accuracy: 0.0588\n",
      "Epoch 7462/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.7364 - accuracy: 0.0000e+00 - val_loss: 118.8170 - val_accuracy: 0.0588\n",
      "Epoch 7463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0859 - accuracy: 0.0000e+00 - val_loss: 120.2907 - val_accuracy: 0.0588\n",
      "Epoch 7464/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2023 - accuracy: 0.0000e+00 - val_loss: 130.8267 - val_accuracy: 0.0000e+00\n",
      "Epoch 7465/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 23.6895 - accuracy: 0.0156 - val_loss: 134.2722 - val_accuracy: 0.0000e+00\n",
      "Epoch 7466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2109 - accuracy: 0.0156 - val_loss: 133.7945 - val_accuracy: 0.0588\n",
      "Epoch 7467/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2618 - accuracy: 0.0156 - val_loss: 137.1467 - val_accuracy: 0.0000e+00\n",
      "Epoch 7468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.1246 - accuracy: 0.0000e+00 - val_loss: 141.0655 - val_accuracy: 0.0588\n",
      "Epoch 7469/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9197 - accuracy: 0.0156 - val_loss: 143.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 7470/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.8255 - accuracy: 0.0156 - val_loss: 143.2437 - val_accuracy: 0.0000e+00\n",
      "Epoch 7471/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 22.3755 - accuracy: 0.0000e+00 - val_loss: 142.1898 - val_accuracy: 0.0000e+00\n",
      "Epoch 7472/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 30.0500 - accuracy: 0.0000e+00 - val_loss: 142.0347 - val_accuracy: 0.0588\n",
      "Epoch 7473/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0850 - accuracy: 0.0000e+00 - val_loss: 142.3245 - val_accuracy: 0.0000e+00\n",
      "Epoch 7474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4598 - accuracy: 0.0000e+00 - val_loss: 137.3372 - val_accuracy: 0.0000e+00\n",
      "Epoch 7475/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 17.8666 - accuracy: 0.0000e+00 - val_loss: 129.4731 - val_accuracy: 0.0000e+00\n",
      "Epoch 7476/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 24.5973 - accuracy: 0.0156 - val_loss: 121.2979 - val_accuracy: 0.0588\n",
      "Epoch 7477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3974 - accuracy: 0.0000e+00 - val_loss: 115.8476 - val_accuracy: 0.0588\n",
      "Epoch 7478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4656 - accuracy: 0.0000e+00 - val_loss: 112.9741 - val_accuracy: 0.0588\n",
      "Epoch 7479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9250 - accuracy: 0.0312 - val_loss: 118.0633 - val_accuracy: 0.0588\n",
      "Epoch 7480/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0875 - accuracy: 0.0312 - val_loss: 125.2163 - val_accuracy: 0.0000e+00\n",
      "Epoch 7481/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4402 - accuracy: 0.0156 - val_loss: 132.4387 - val_accuracy: 0.0000e+00\n",
      "Epoch 7482/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 24.6656 - accuracy: 0.0312 - val_loss: 136.3848 - val_accuracy: 0.0000e+00\n",
      "Epoch 7483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2606 - accuracy: 0.0000e+00 - val_loss: 139.3978 - val_accuracy: 0.0588\n",
      "Epoch 7484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0231 - accuracy: 0.0156 - val_loss: 135.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 7485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1410 - accuracy: 0.0156 - val_loss: 132.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 7486/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.8666 - accuracy: 0.0156 - val_loss: 136.3458 - val_accuracy: 0.0000e+00\n",
      "Epoch 7487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8188 - accuracy: 0.0000e+00 - val_loss: 138.3247 - val_accuracy: 0.0000e+00\n",
      "Epoch 7488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6895 - accuracy: 0.0156 - val_loss: 141.2996 - val_accuracy: 0.0000e+00\n",
      "Epoch 7489/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0906 - accuracy: 0.0156 - val_loss: 137.9507 - val_accuracy: 0.0000e+00\n",
      "Epoch 7490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2645 - accuracy: 0.0156 - val_loss: 128.9896 - val_accuracy: 0.0000e+00\n",
      "Epoch 7491/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 17.5792 - accuracy: 0.0156 - val_loss: 123.3142 - val_accuracy: 0.0588\n",
      "Epoch 7492/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.1250 - accuracy: 0.0156 - val_loss: 123.8241 - val_accuracy: 0.0588\n",
      "Epoch 7493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6459 - accuracy: 0.0000e+00 - val_loss: 136.8460 - val_accuracy: 0.0588\n",
      "Epoch 7494/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2747 - accuracy: 0.0000e+00 - val_loss: 143.4293 - val_accuracy: 0.0588\n",
      "Epoch 7495/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.6044 - accuracy: 0.0156 - val_loss: 131.0000 - val_accuracy: 0.0588\n",
      "Epoch 7496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2551 - accuracy: 0.0000e+00 - val_loss: 125.6139 - val_accuracy: 0.0588\n",
      "Epoch 7497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1911 - accuracy: 0.0156 - val_loss: 126.0631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7498/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0015 - accuracy: 0.0156 - val_loss: 126.1476 - val_accuracy: 0.0000e+00\n",
      "Epoch 7499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.8104 - accuracy: 0.0000e+00 - val_loss: 131.5110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.9167 - accuracy: 0.0156 - val_loss: 141.9301 - val_accuracy: 0.0000e+00\n",
      "Epoch 7501/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 28.5917 - accuracy: 0.0312 - val_loss: 149.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7502/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.1664 - accuracy: 0.0000e+00 - val_loss: 149.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 7503/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3097 - accuracy: 0.0156 - val_loss: 141.2351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0285 - accuracy: 0.0000e+00 - val_loss: 137.0741 - val_accuracy: 0.0000e+00\n",
      "Epoch 7505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8335 - accuracy: 0.0156 - val_loss: 138.1173 - val_accuracy: 0.0000e+00\n",
      "Epoch 7506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.8606 - accuracy: 0.0469 - val_loss: 144.6811 - val_accuracy: 0.0588\n",
      "Epoch 7507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4905 - accuracy: 0.0312 - val_loss: 147.1034 - val_accuracy: 0.0588\n",
      "Epoch 7508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5241 - accuracy: 0.0469 - val_loss: 144.2018 - val_accuracy: 0.0588\n",
      "Epoch 7509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4147 - accuracy: 0.0000e+00 - val_loss: 143.1407 - val_accuracy: 0.0588\n",
      "Epoch 7510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1017 - accuracy: 0.0000e+00 - val_loss: 144.7118 - val_accuracy: 0.0588\n",
      "Epoch 7511/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 17.9094 - accuracy: 0.0000e+00 - val_loss: 144.6680 - val_accuracy: 0.0588\n",
      "Epoch 7512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1498 - accuracy: 0.0156 - val_loss: 147.1527 - val_accuracy: 0.0588\n",
      "Epoch 7513/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5285 - accuracy: 0.0312 - val_loss: 148.6960 - val_accuracy: 0.0588\n",
      "Epoch 7514/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7244 - accuracy: 0.0312 - val_loss: 145.0225 - val_accuracy: 0.0588\n",
      "Epoch 7515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6101 - accuracy: 0.0000e+00 - val_loss: 135.0649 - val_accuracy: 0.0000e+00\n",
      "Epoch 7516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.2088 - accuracy: 0.0156 - val_loss: 127.5392 - val_accuracy: 0.0000e+00\n",
      "Epoch 7517/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1302 - accuracy: 0.0312 - val_loss: 124.4194 - val_accuracy: 0.0588\n",
      "Epoch 7518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6926 - accuracy: 0.0156 - val_loss: 120.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 7519/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 35.5816 - accuracy: 0.0000e+00 - val_loss: 121.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7520/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.8399 - accuracy: 0.0156 - val_loss: 120.6289 - val_accuracy: 0.0000e+00\n",
      "Epoch 7521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2655 - accuracy: 0.0156 - val_loss: 123.8171 - val_accuracy: 0.0000e+00\n",
      "Epoch 7522/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 22.5844 - accuracy: 0.0156 - val_loss: 129.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7523/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.8937 - accuracy: 0.0156 - val_loss: 140.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7524/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 24.9597 - accuracy: 0.0156 - val_loss: 149.1796 - val_accuracy: 0.0000e+00\n",
      "Epoch 7525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6404 - accuracy: 0.0156 - val_loss: 148.3275 - val_accuracy: 0.0588\n",
      "Epoch 7526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2723 - accuracy: 0.0156 - val_loss: 136.4298 - val_accuracy: 0.1176\n",
      "Epoch 7527/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.2731 - accuracy: 0.0000e+00 - val_loss: 130.5034 - val_accuracy: 0.0588\n",
      "Epoch 7528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4457 - accuracy: 0.0156 - val_loss: 129.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 7529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2891 - accuracy: 0.0312 - val_loss: 129.2940 - val_accuracy: 0.0000e+00\n",
      "Epoch 7530/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 45.0529 - accuracy: 0.0000e+00 - val_loss: 129.9885 - val_accuracy: 0.0588\n",
      "Epoch 7531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7648 - accuracy: 0.0000e+00 - val_loss: 127.3174 - val_accuracy: 0.0588\n",
      "Epoch 7532/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0302 - accuracy: 0.0312 - val_loss: 122.2676 - val_accuracy: 0.0588\n",
      "Epoch 7533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6022 - accuracy: 0.0000e+00 - val_loss: 118.7342 - val_accuracy: 0.0588\n",
      "Epoch 7534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4218 - accuracy: 0.0000e+00 - val_loss: 123.9433 - val_accuracy: 0.0588\n",
      "Epoch 7535/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8402 - accuracy: 0.0156 - val_loss: 134.1165 - val_accuracy: 0.0000e+00\n",
      "Epoch 7536/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4863 - accuracy: 0.0312 - val_loss: 139.7335 - val_accuracy: 0.0000e+00\n",
      "Epoch 7537/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0610 - accuracy: 0.0312 - val_loss: 141.6832 - val_accuracy: 0.0000e+00\n",
      "Epoch 7538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1194 - accuracy: 0.0000e+00 - val_loss: 137.3623 - val_accuracy: 0.0000e+00\n",
      "Epoch 7539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1525 - accuracy: 0.0312 - val_loss: 134.4301 - val_accuracy: 0.0000e+00\n",
      "Epoch 7540/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1271 - accuracy: 0.0156 - val_loss: 131.9419 - val_accuracy: 0.0588\n",
      "Epoch 7541/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.8511 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 19.3900 - accuracy: 0.0000e+00 - val_loss: 129.5257 - val_accuracy: 0.1176\n",
      "Epoch 7542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0052 - accuracy: 0.0000e+00 - val_loss: 127.5619 - val_accuracy: 0.1176\n",
      "Epoch 7543/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 14.4653 - accuracy: 0.0000e+00 - val_loss: 129.8257 - val_accuracy: 0.0588\n",
      "Epoch 7544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3439 - accuracy: 0.0312 - val_loss: 132.4097 - val_accuracy: 0.0000e+00\n",
      "Epoch 7545/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0653 - accuracy: 0.0156 - val_loss: 136.3554 - val_accuracy: 0.0000e+00\n",
      "Epoch 7546/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2222 - accuracy: 0.0156 - val_loss: 136.7317 - val_accuracy: 0.0588\n",
      "Epoch 7547/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5510 - accuracy: 0.0469 - val_loss: 123.8940 - val_accuracy: 0.0588\n",
      "Epoch 7548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9628 - accuracy: 0.0000e+00 - val_loss: 120.3576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5202 - accuracy: 0.0156 - val_loss: 120.7338 - val_accuracy: 0.0000e+00\n",
      "Epoch 7550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.4604 - accuracy: 0.0000e+00 - val_loss: 127.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 7551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6875 - accuracy: 0.0156 - val_loss: 142.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 7552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7784 - accuracy: 0.0469 - val_loss: 147.3374 - val_accuracy: 0.0588\n",
      "Epoch 7553/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.2777 - accuracy: 0.0156 - val_loss: 146.6376 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7554/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 27.4067 - accuracy: 0.0000e+00 - val_loss: 141.4049 - val_accuracy: 0.0000e+00\n",
      "Epoch 7555/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4540 - accuracy: 0.0000e+00 - val_loss: 137.7241 - val_accuracy: 0.0000e+00\n",
      "Epoch 7556/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0892 - accuracy: 0.0000e+00 - val_loss: 127.7966 - val_accuracy: 0.0588\n",
      "Epoch 7557/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0619 - accuracy: 0.0312 - val_loss: 123.3729 - val_accuracy: 0.0588\n",
      "Epoch 7558/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0359 - accuracy: 0.0156 - val_loss: 128.1567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7559/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6347 - accuracy: 0.0000e+00 - val_loss: 127.0387 - val_accuracy: 0.0588\n",
      "Epoch 7560/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3987 - accuracy: 0.0312 - val_loss: 121.5226 - val_accuracy: 0.0588\n",
      "Epoch 7561/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 28.0245 - accuracy: 0.0312 - val_loss: 118.8465 - val_accuracy: 0.0000e+00\n",
      "Epoch 7562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0886 - accuracy: 0.0312 - val_loss: 121.2532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1381 - accuracy: 0.0156 - val_loss: 125.7154 - val_accuracy: 0.0000e+00\n",
      "Epoch 7564/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.3293 - accuracy: 0.0000e+00 - val_loss: 131.6722 - val_accuracy: 0.0588\n",
      "Epoch 7565/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 23.8187 - accuracy: 0.0000e+00 - val_loss: 132.7325 - val_accuracy: 0.0588\n",
      "Epoch 7566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6484 - accuracy: 0.0000e+00 - val_loss: 132.0180 - val_accuracy: 0.0588\n",
      "Epoch 7567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7010 - accuracy: 0.0000e+00 - val_loss: 130.6007 - val_accuracy: 0.0588\n",
      "Epoch 7568/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 18.8113 - accuracy: 0.0000e+00 - val_loss: 132.2492 - val_accuracy: 0.0588\n",
      "Epoch 7569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3292 - accuracy: 0.0000e+00 - val_loss: 129.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 7570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5394 - accuracy: 0.0000e+00 - val_loss: 122.6100 - val_accuracy: 0.0000e+00\n",
      "Epoch 7571/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2555 - accuracy: 0.0000e+00 - val_loss: 116.5378 - val_accuracy: 0.0000e+00\n",
      "Epoch 7572/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9539 - accuracy: 0.0156 - val_loss: 116.9500 - val_accuracy: 0.0588\n",
      "Epoch 7573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0531 - accuracy: 0.0156 - val_loss: 124.9346 - val_accuracy: 0.0588\n",
      "Epoch 7574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6149 - accuracy: 0.0000e+00 - val_loss: 127.5537 - val_accuracy: 0.0588\n",
      "Epoch 7575/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 18.4759 - accuracy: 0.0000e+00 - val_loss: 123.4854 - val_accuracy: 0.1176\n",
      "Epoch 7576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2712 - accuracy: 0.0156 - val_loss: 123.9950 - val_accuracy: 0.0588\n",
      "Epoch 7577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4599 - accuracy: 0.0000e+00 - val_loss: 120.7340 - val_accuracy: 0.1176\n",
      "Epoch 7578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7466 - accuracy: 0.0156 - val_loss: 121.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 7579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4110 - accuracy: 0.0156 - val_loss: 125.1624 - val_accuracy: 0.0000e+00\n",
      "Epoch 7580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8249 - accuracy: 0.0156 - val_loss: 130.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 7581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4170 - accuracy: 0.0156 - val_loss: 139.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 7582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7443 - accuracy: 0.0000e+00 - val_loss: 144.3280 - val_accuracy: 0.0000e+00\n",
      "Epoch 7583/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 24.2451 - accuracy: 0.0156 - val_loss: 147.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7584/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7194 - accuracy: 0.0000e+00 - val_loss: 146.5226 - val_accuracy: 0.0000e+00\n",
      "Epoch 7585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7899 - accuracy: 0.0000e+00 - val_loss: 136.5057 - val_accuracy: 0.0588\n",
      "Epoch 7586/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 20.1952 - accuracy: 0.0000e+00 - val_loss: 123.8135 - val_accuracy: 0.0588\n",
      "Epoch 7587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2523 - accuracy: 0.0000e+00 - val_loss: 124.6369 - val_accuracy: 0.0588\n",
      "Epoch 7588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7159 - accuracy: 0.0000e+00 - val_loss: 132.6094 - val_accuracy: 0.0588\n",
      "Epoch 7589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5133 - accuracy: 0.0156 - val_loss: 134.4375 - val_accuracy: 0.0588\n",
      "Epoch 7590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9525 - accuracy: 0.0312 - val_loss: 136.0773 - val_accuracy: 0.0000e+00\n",
      "Epoch 7591/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9406 - accuracy: 0.0156 - val_loss: 135.6709 - val_accuracy: 0.0000e+00\n",
      "Epoch 7592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.1268 - accuracy: 0.0156 - val_loss: 129.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 7593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5723 - accuracy: 0.0156 - val_loss: 126.0417 - val_accuracy: 0.0000e+00\n",
      "Epoch 7594/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9628 - accuracy: 0.0156 - val_loss: 129.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 7595/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7801 - accuracy: 0.0000e+00 - val_loss: 134.2578 - val_accuracy: 0.0000e+00\n",
      "Epoch 7596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8393 - accuracy: 0.0156 - val_loss: 139.4679 - val_accuracy: 0.0000e+00\n",
      "Epoch 7597/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 12.5627 - accuracy: 0.0156 - val_loss: 136.0885 - val_accuracy: 0.0588\n",
      "Epoch 7598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.1042 - accuracy: 0.0156 - val_loss: 136.2254 - val_accuracy: 0.0000e+00\n",
      "Epoch 7599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5616 - accuracy: 0.0156 - val_loss: 141.0146 - val_accuracy: 0.0000e+00\n",
      "Epoch 7600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0632 - accuracy: 0.0156 - val_loss: 143.8143 - val_accuracy: 0.0000e+00\n",
      "Epoch 7601/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9201 - accuracy: 0.0312 - val_loss: 143.5151 - val_accuracy: 0.0000e+00\n",
      "Epoch 7602/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7996 - accuracy: 0.0000e+00 - val_loss: 137.2654 - val_accuracy: 0.0588\n",
      "Epoch 7603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0672 - accuracy: 0.0312 - val_loss: 132.0300 - val_accuracy: 0.0588\n",
      "Epoch 7604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5196 - accuracy: 0.0156 - val_loss: 133.6721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7605/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0939 - accuracy: 0.0156 - val_loss: 131.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 7606/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 31.2527 - accuracy: 0.0000e+00 - val_loss: 127.5874 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7607/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1650 - accuracy: 0.0000e+00 - val_loss: 135.2606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9654 - accuracy: 0.0156 - val_loss: 138.2066 - val_accuracy: 0.0588\n",
      "Epoch 7609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1140 - accuracy: 0.0312 - val_loss: 132.8301 - val_accuracy: 0.0588\n",
      "Epoch 7610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0388 - accuracy: 0.0000e+00 - val_loss: 132.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 7611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8087 - accuracy: 0.0000e+00 - val_loss: 133.6935 - val_accuracy: 0.0000e+00\n",
      "Epoch 7612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6811 - accuracy: 0.0156 - val_loss: 135.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 7613/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.3960 - accuracy: 0.0156 - val_loss: 138.6674 - val_accuracy: 0.0588\n",
      "Epoch 7614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4215 - accuracy: 0.0000e+00 - val_loss: 137.5787 - val_accuracy: 0.0588\n",
      "Epoch 7615/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.6516 - accuracy: 0.0000e+00 - val_loss: 128.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 7616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0320 - accuracy: 0.0156 - val_loss: 120.6946 - val_accuracy: 0.0000e+00\n",
      "Epoch 7617/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6685 - accuracy: 0.0000e+00 - val_loss: 121.0244 - val_accuracy: 0.0588\n",
      "Epoch 7618/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 19.4414 - accuracy: 0.0156 - val_loss: 130.3279 - val_accuracy: 0.0588\n",
      "Epoch 7619/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 35.6733 - accuracy: 0.0000e+00 - val_loss: 129.4777 - val_accuracy: 0.0000e+00\n",
      "Epoch 7620/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 34.1384 - accuracy: 0.0000e+00 - val_loss: 133.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7621/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.9667 - accuracy: 0.0156 - val_loss: 132.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 7622/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1206 - accuracy: 0.0000e+00 - val_loss: 130.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 7623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1128 - accuracy: 0.0156 - val_loss: 127.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 7624/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.1652 - accuracy: 0.0000e+00 - val_loss: 125.9560 - val_accuracy: 0.0000e+00\n",
      "Epoch 7625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0225 - accuracy: 0.0156 - val_loss: 131.3125 - val_accuracy: 0.0000e+00\n",
      "Epoch 7626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1644 - accuracy: 0.0000e+00 - val_loss: 139.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 7627/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8930 - accuracy: 0.0312 - val_loss: 142.8732 - val_accuracy: 0.0000e+00\n",
      "Epoch 7628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8244 - accuracy: 0.0156 - val_loss: 147.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7629/10000\n",
      "64/64 [==============================] - 0s 105us/step - loss: 21.1812 - accuracy: 0.0000e+00 - val_loss: 144.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7630/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5951 - accuracy: 0.0156 - val_loss: 138.7742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7631/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2570 - accuracy: 0.0000e+00 - val_loss: 135.6471 - val_accuracy: 0.0000e+00\n",
      "Epoch 7632/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 27.9247 - accuracy: 0.0000e+00 - val_loss: 133.3420 - val_accuracy: 0.0000e+00\n",
      "Epoch 7633/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9772 - accuracy: 0.0312 - val_loss: 135.5998 - val_accuracy: 0.0000e+00\n",
      "Epoch 7634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4594 - accuracy: 0.0156 - val_loss: 142.2677 - val_accuracy: 0.0000e+00\n",
      "Epoch 7635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.1656 - accuracy: 0.0312 - val_loss: 144.8197 - val_accuracy: 0.0000e+00\n",
      "Epoch 7636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7089 - accuracy: 0.0000e+00 - val_loss: 140.4934 - val_accuracy: 0.0588\n",
      "Epoch 7637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9702 - accuracy: 0.0156 - val_loss: 136.3060 - val_accuracy: 0.0000e+00\n",
      "Epoch 7638/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2827 - accuracy: 0.0000e+00 - val_loss: 130.8298 - val_accuracy: 0.0000e+00\n",
      "Epoch 7639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9273 - accuracy: 0.0156 - val_loss: 122.4983 - val_accuracy: 0.0000e+00\n",
      "Epoch 7640/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 22.2903 - accuracy: 0.0000e+00 - val_loss: 118.3062 - val_accuracy: 0.0000e+00\n",
      "Epoch 7641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8874 - accuracy: 0.0000e+00 - val_loss: 122.3667 - val_accuracy: 0.0000e+00\n",
      "Epoch 7642/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 39.3263 - accuracy: 0.0156 - val_loss: 129.4873 - val_accuracy: 0.0000e+00\n",
      "Epoch 7643/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 14.7791 - accuracy: 0.0156 - val_loss: 134.5099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7644/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 22.3463 - accuracy: 0.0000e+00 - val_loss: 132.9721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7645/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7429 - accuracy: 0.0000e+00 - val_loss: 128.6324 - val_accuracy: 0.0000e+00\n",
      "Epoch 7646/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.2074 - accuracy: 0.0156 - val_loss: 124.9250 - val_accuracy: 0.0000e+00\n",
      "Epoch 7647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4056 - accuracy: 0.0000e+00 - val_loss: 128.4062 - val_accuracy: 0.0000e+00\n",
      "Epoch 7648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4406 - accuracy: 0.0156 - val_loss: 135.1781 - val_accuracy: 0.0000e+00\n",
      "Epoch 7649/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.9122 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 20.9459 - accuracy: 0.0000e+00 - val_loss: 135.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 7650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2655 - accuracy: 0.0000e+00 - val_loss: 138.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7651/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 20.7113 - accuracy: 0.0000e+00 - val_loss: 138.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 7652/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 28.1805 - accuracy: 0.0000e+00 - val_loss: 138.8080 - val_accuracy: 0.0000e+00\n",
      "Epoch 7653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0624 - accuracy: 0.0312 - val_loss: 134.7524 - val_accuracy: 0.0000e+00\n",
      "Epoch 7654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8743 - accuracy: 0.0000e+00 - val_loss: 126.2639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7655/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3819 - accuracy: 0.0312 - val_loss: 122.2580 - val_accuracy: 0.0588\n",
      "Epoch 7656/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7725 - accuracy: 0.0156 - val_loss: 125.6757 - val_accuracy: 0.0000e+00\n",
      "Epoch 7657/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6008 - accuracy: 0.0156 - val_loss: 128.2975 - val_accuracy: 0.0000e+00\n",
      "Epoch 7658/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6073 - accuracy: 0.0000e+00 - val_loss: 134.2833 - val_accuracy: 0.0000e+00\n",
      "Epoch 7659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3246 - accuracy: 0.0000e+00 - val_loss: 138.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 7660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2381 - accuracy: 0.0000e+00 - val_loss: 138.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 7661/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3349 - accuracy: 0.0156 - val_loss: 133.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 7662/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9916 - accuracy: 0.0156 - val_loss: 131.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 7663/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 31.6826 - accuracy: 0.0000e+00 - val_loss: 132.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 7664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5310 - accuracy: 0.0000e+00 - val_loss: 126.4278 - val_accuracy: 0.0000e+00\n",
      "Epoch 7665/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3706 - accuracy: 0.0156 - val_loss: 120.5752 - val_accuracy: 0.0000e+00\n",
      "Epoch 7666/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 14.9137 - accuracy: 0.0156 - val_loss: 116.5810 - val_accuracy: 0.0588\n",
      "Epoch 7667/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7518 - accuracy: 0.0156 - val_loss: 123.7784 - val_accuracy: 0.0000e+00\n",
      "Epoch 7668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9353 - accuracy: 0.0312 - val_loss: 127.2518 - val_accuracy: 0.0000e+00\n",
      "Epoch 7669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3731 - accuracy: 0.0000e+00 - val_loss: 130.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 7670/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7816 - accuracy: 0.0312 - val_loss: 129.5264 - val_accuracy: 0.0588\n",
      "Epoch 7671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0780 - accuracy: 0.0469 - val_loss: 129.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 7672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8352 - accuracy: 0.0000e+00 - val_loss: 125.7224 - val_accuracy: 0.0000e+00\n",
      "Epoch 7673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7271 - accuracy: 0.0000e+00 - val_loss: 124.7987 - val_accuracy: 0.0000e+00\n",
      "Epoch 7674/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 34.8053 - accuracy: 0.0312 - val_loss: 124.3568 - val_accuracy: 0.0000e+00\n",
      "Epoch 7675/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.0528 - accuracy: 0.0156 - val_loss: 137.9252 - val_accuracy: 0.0000e+00\n",
      "Epoch 7676/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 20.9167 - accuracy: 0.0469 - val_loss: 144.9504 - val_accuracy: 0.0000e+00\n",
      "Epoch 7677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3655 - accuracy: 0.0000e+00 - val_loss: 142.5754 - val_accuracy: 0.0000e+00\n",
      "Epoch 7678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7989 - accuracy: 0.0312 - val_loss: 137.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 7679/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8731 - accuracy: 0.0312 - val_loss: 127.6807 - val_accuracy: 0.0000e+00\n",
      "Epoch 7680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3776 - accuracy: 0.0000e+00 - val_loss: 122.1751 - val_accuracy: 0.0000e+00\n",
      "Epoch 7681/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3155 - accuracy: 0.0156 - val_loss: 127.1604 - val_accuracy: 0.0000e+00\n",
      "Epoch 7682/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7821 - accuracy: 0.0000e+00 - val_loss: 141.3743 - val_accuracy: 0.0000e+00\n",
      "Epoch 7683/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8615 - accuracy: 0.0000e+00 - val_loss: 149.6787 - val_accuracy: 0.0588\n",
      "Epoch 7684/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8599 - accuracy: 0.0156 - val_loss: 144.0583 - val_accuracy: 0.0000e+00\n",
      "Epoch 7685/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 18.0180 - accuracy: 0.0156 - val_loss: 137.0912 - val_accuracy: 0.0000e+00\n",
      "Epoch 7686/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 21.3886 - accuracy: 0.0156 - val_loss: 130.6049 - val_accuracy: 0.0588\n",
      "Epoch 7687/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.0511 - accuracy: 0.0000e+00 - val_loss: 136.9610 - val_accuracy: 0.0000e+00\n",
      "Epoch 7688/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0159 - accuracy: 0.0000e+00 - val_loss: 147.4497 - val_accuracy: 0.0000e+00\n",
      "Epoch 7689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8498 - accuracy: 0.0000e+00 - val_loss: 146.2481 - val_accuracy: 0.0000e+00\n",
      "Epoch 7690/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0084 - accuracy: 0.0156 - val_loss: 133.2592 - val_accuracy: 0.0000e+00\n",
      "Epoch 7691/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9593 - accuracy: 0.0000e+00 - val_loss: 125.1299 - val_accuracy: 0.0000e+00\n",
      "Epoch 7692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.9741 - accuracy: 0.0000e+00 - val_loss: 125.2701 - val_accuracy: 0.0000e+00\n",
      "Epoch 7693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9817 - accuracy: 0.0156 - val_loss: 126.4532 - val_accuracy: 0.0000e+00\n",
      "Epoch 7694/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9879 - accuracy: 0.0000e+00 - val_loss: 131.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 7695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8689 - accuracy: 0.0156 - val_loss: 137.2183 - val_accuracy: 0.0588\n",
      "Epoch 7696/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0673 - accuracy: 0.0000e+00 - val_loss: 136.1819 - val_accuracy: 0.0588\n",
      "Epoch 7697/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 16.0599 - accuracy: 0.0000e+00 - val_loss: 132.0769 - val_accuracy: 0.0588\n",
      "Epoch 7698/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.2801 - accuracy: 0.0312 - val_loss: 127.4968 - val_accuracy: 0.0588\n",
      "Epoch 7699/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6339 - accuracy: 0.0312 - val_loss: 122.1803 - val_accuracy: 0.0588\n",
      "Epoch 7700/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.6411 - accuracy: 0.0156 - val_loss: 119.0727 - val_accuracy: 0.0588\n",
      "Epoch 7701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9799 - accuracy: 0.0000e+00 - val_loss: 117.2563 - val_accuracy: 0.0588\n",
      "Epoch 7702/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 30.8880 - accuracy: 0.0000e+00 - val_loss: 115.3174 - val_accuracy: 0.0588\n",
      "Epoch 7703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0315 - accuracy: 0.0312 - val_loss: 115.5506 - val_accuracy: 0.0588\n",
      "Epoch 7704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7626 - accuracy: 0.0000e+00 - val_loss: 119.8397 - val_accuracy: 0.0588\n",
      "Epoch 7705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0395 - accuracy: 0.0156 - val_loss: 126.9718 - val_accuracy: 0.0588\n",
      "Epoch 7706/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.6597 - accuracy: 0.0000e+00 - val_loss: 129.8381 - val_accuracy: 0.1176\n",
      "Epoch 7707/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 27.8680 - accuracy: 0.0156 - val_loss: 131.1337 - val_accuracy: 0.0588\n",
      "Epoch 7708/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0020 - accuracy: 0.0000e+00 - val_loss: 132.7085 - val_accuracy: 0.0000e+00\n",
      "Epoch 7709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9860 - accuracy: 0.0156 - val_loss: 132.4122 - val_accuracy: 0.0000e+00\n",
      "Epoch 7710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9982 - accuracy: 0.0000e+00 - val_loss: 130.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 7711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9971 - accuracy: 0.0312 - val_loss: 128.6378 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5876 - accuracy: 0.0000e+00 - val_loss: 131.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 7713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2393 - accuracy: 0.0000e+00 - val_loss: 125.0551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7714/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2670 - accuracy: 0.0000e+00 - val_loss: 121.1875 - val_accuracy: 0.0588\n",
      "Epoch 7715/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 16.4822 - accuracy: 0.0000e+00 - val_loss: 122.9784 - val_accuracy: 0.0000e+00\n",
      "Epoch 7716/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.4524 - accuracy: 0.0312 - val_loss: 127.5237 - val_accuracy: 0.0000e+00\n",
      "Epoch 7717/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7701 - accuracy: 0.0156 - val_loss: 136.2149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7718/10000\n",
      "64/64 [==============================] - 0s 47us/step - loss: 24.2804 - accuracy: 0.0156 - val_loss: 142.4788 - val_accuracy: 0.0000e+00\n",
      "Epoch 7719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.1149 - accuracy: 0.0156 - val_loss: 142.8681 - val_accuracy: 0.0000e+00\n",
      "Epoch 7720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6459 - accuracy: 0.0156 - val_loss: 143.4025 - val_accuracy: 0.0000e+00\n",
      "Epoch 7721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1138 - accuracy: 0.0000e+00 - val_loss: 140.5051 - val_accuracy: 0.0588\n",
      "Epoch 7722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2695 - accuracy: 0.0156 - val_loss: 132.9763 - val_accuracy: 0.0588\n",
      "Epoch 7723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1470 - accuracy: 0.0000e+00 - val_loss: 124.3406 - val_accuracy: 0.0000e+00\n",
      "Epoch 7724/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 25.8622 - accuracy: 0.0000e+00 - val_loss: 118.9552 - val_accuracy: 0.1176\n",
      "Epoch 7725/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7718 - accuracy: 0.0156 - val_loss: 120.0736 - val_accuracy: 0.1176\n",
      "Epoch 7726/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7513 - accuracy: 0.0156 - val_loss: 119.5877 - val_accuracy: 0.1176\n",
      "Epoch 7727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1754 - accuracy: 0.0000e+00 - val_loss: 119.1161 - val_accuracy: 0.1176\n",
      "Epoch 7728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4403 - accuracy: 0.0156 - val_loss: 117.9242 - val_accuracy: 0.0588\n",
      "Epoch 7729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8816 - accuracy: 0.0156 - val_loss: 120.8505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7730/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0120 - accuracy: 0.0000e+00 - val_loss: 125.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 7731/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3855 - accuracy: 0.0000e+00 - val_loss: 126.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 7732/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.5707 - accuracy: 0.0156 - val_loss: 130.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7733/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 24.1055 - accuracy: 0.0000e+00 - val_loss: 130.0468 - val_accuracy: 0.0588\n",
      "Epoch 7734/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4281 - accuracy: 0.0000e+00 - val_loss: 129.1826 - val_accuracy: 0.0588\n",
      "Epoch 7735/10000\n",
      "64/64 [==============================] - 0s 75us/step - loss: 30.2872 - accuracy: 0.0000e+00 - val_loss: 128.3141 - val_accuracy: 0.0000e+00\n",
      "Epoch 7736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.2572 - accuracy: 0.0000e+00 - val_loss: 132.9339 - val_accuracy: 0.0000e+00\n",
      "Epoch 7737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8007 - accuracy: 0.0000e+00 - val_loss: 131.9854 - val_accuracy: 0.0588\n",
      "Epoch 7738/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 39.8109 - accuracy: 0.0000e+00 - val_loss: 126.6087 - val_accuracy: 0.1176\n",
      "Epoch 7739/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5971 - accuracy: 0.0000e+00 - val_loss: 124.8099 - val_accuracy: 0.0588\n",
      "Epoch 7740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9760 - accuracy: 0.0000e+00 - val_loss: 122.4703 - val_accuracy: 0.0588\n",
      "Epoch 7741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6742 - accuracy: 0.0156 - val_loss: 120.4758 - val_accuracy: 0.0588\n",
      "Epoch 7742/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 21.0229 - accuracy: 0.0000e+00 - val_loss: 131.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 7743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8565 - accuracy: 0.0000e+00 - val_loss: 139.8576 - val_accuracy: 0.0000e+00\n",
      "Epoch 7744/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8850 - accuracy: 0.0000e+00 - val_loss: 142.5606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7745/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.5682 - accuracy: 0.0000e+00 - val_loss: 131.5194 - val_accuracy: 0.0000e+00\n",
      "Epoch 7746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2419 - accuracy: 0.0000e+00 - val_loss: 130.7866 - val_accuracy: 0.0588\n",
      "Epoch 7747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4010 - accuracy: 0.0000e+00 - val_loss: 135.3981 - val_accuracy: 0.0000e+00\n",
      "Epoch 7748/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.9024 - accuracy: 0.0000e+00 - val_loss: 141.3742 - val_accuracy: 0.0000e+00\n",
      "Epoch 7749/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6372 - accuracy: 0.0000e+00 - val_loss: 140.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5629 - accuracy: 0.0156 - val_loss: 136.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 7751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5116 - accuracy: 0.0000e+00 - val_loss: 137.7450 - val_accuracy: 0.1176\n",
      "Epoch 7752/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6610 - accuracy: 0.0156 - val_loss: 138.4792 - val_accuracy: 0.1176\n",
      "Epoch 7753/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3309 - accuracy: 0.0156 - val_loss: 137.7879 - val_accuracy: 0.0000e+00\n",
      "Epoch 7754/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2504 - accuracy: 0.0000e+00 - val_loss: 130.6298 - val_accuracy: 0.0000e+00\n",
      "Epoch 7755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5711 - accuracy: 0.0000e+00 - val_loss: 123.0930 - val_accuracy: 0.0000e+00\n",
      "Epoch 7756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8711 - accuracy: 0.0000e+00 - val_loss: 121.3451 - val_accuracy: 0.0000e+00\n",
      "Epoch 7757/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.6189 - accuracy: 0.0000e+00 - val_loss: 126.3297 - val_accuracy: 0.0000e+00\n",
      "Epoch 7758/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0731 - accuracy: 0.0156 - val_loss: 134.2978 - val_accuracy: 0.0000e+00\n",
      "Epoch 7759/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1491 - accuracy: 0.0000e+00 - val_loss: 132.8777 - val_accuracy: 0.0000e+00\n",
      "Epoch 7760/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 27.1110 - accuracy: 0.0312 - val_loss: 126.9730 - val_accuracy: 0.0588\n",
      "Epoch 7761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1878 - accuracy: 0.0156 - val_loss: 120.4391 - val_accuracy: 0.0588\n",
      "Epoch 7762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4059 - accuracy: 0.0000e+00 - val_loss: 118.1645 - val_accuracy: 0.0000e+00\n",
      "Epoch 7763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9113 - accuracy: 0.0000e+00 - val_loss: 124.1122 - val_accuracy: 0.0000e+00\n",
      "Epoch 7764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 10.4137 - accuracy: 0.0156 - val_loss: 127.0435 - val_accuracy: 0.0000e+00\n",
      "Epoch 7765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4341 - accuracy: 0.0000e+00 - val_loss: 122.7606 - val_accuracy: 0.0000e+00\n",
      "Epoch 7766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9723 - accuracy: 0.0156 - val_loss: 118.2956 - val_accuracy: 0.0588\n",
      "Epoch 7767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8446 - accuracy: 0.0156 - val_loss: 120.6988 - val_accuracy: 0.0000e+00\n",
      "Epoch 7768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6833 - accuracy: 0.0000e+00 - val_loss: 135.9572 - val_accuracy: 0.0000e+00\n",
      "Epoch 7769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8394 - accuracy: 0.0000e+00 - val_loss: 146.4430 - val_accuracy: 0.0588\n",
      "Epoch 7770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2714 - accuracy: 0.0156 - val_loss: 145.5447 - val_accuracy: 0.0000e+00\n",
      "Epoch 7771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9336 - accuracy: 0.0000e+00 - val_loss: 140.4351 - val_accuracy: 0.0000e+00\n",
      "Epoch 7772/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.2533 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 25.8703 - accuracy: 0.0000e+00 - val_loss: 137.8840 - val_accuracy: 0.0000e+00\n",
      "Epoch 7773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9990 - accuracy: 0.0156 - val_loss: 145.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 7774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9372 - accuracy: 0.0312 - val_loss: 150.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 7775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5300 - accuracy: 0.0000e+00 - val_loss: 148.0689 - val_accuracy: 0.0000e+00\n",
      "Epoch 7776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1814 - accuracy: 0.0156 - val_loss: 139.9393 - val_accuracy: 0.0000e+00\n",
      "Epoch 7777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8994 - accuracy: 0.0312 - val_loss: 131.1373 - val_accuracy: 0.0000e+00\n",
      "Epoch 7778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8786 - accuracy: 0.0469 - val_loss: 122.7259 - val_accuracy: 0.0000e+00\n",
      "Epoch 7779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3819 - accuracy: 0.0156 - val_loss: 119.7780 - val_accuracy: 0.1176\n",
      "Epoch 7780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0609 - accuracy: 0.0156 - val_loss: 122.3996 - val_accuracy: 0.0588\n",
      "Epoch 7781/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.1267 - accuracy: 0.0156 - val_loss: 126.8604 - val_accuracy: 0.0588\n",
      "Epoch 7782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1251 - accuracy: 0.0000e+00 - val_loss: 127.4227 - val_accuracy: 0.0588\n",
      "Epoch 7783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6901 - accuracy: 0.0312 - val_loss: 128.6490 - val_accuracy: 0.0588\n",
      "Epoch 7784/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5655 - accuracy: 0.0312 - val_loss: 131.6434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2574 - accuracy: 0.0156 - val_loss: 132.9343 - val_accuracy: 0.0000e+00\n",
      "Epoch 7786/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1020 - accuracy: 0.0000e+00 - val_loss: 125.5396 - val_accuracy: 0.0000e+00\n",
      "Epoch 7787/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9445 - accuracy: 0.0156 - val_loss: 126.5539 - val_accuracy: 0.0000e+00\n",
      "Epoch 7788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6596 - accuracy: 0.0312 - val_loss: 132.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 7789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3560 - accuracy: 0.0156 - val_loss: 136.7409 - val_accuracy: 0.0000e+00\n",
      "Epoch 7790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9230 - accuracy: 0.0156 - val_loss: 138.6192 - val_accuracy: 0.0588\n",
      "Epoch 7791/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5313 - accuracy: 0.0156 - val_loss: 137.7467 - val_accuracy: 0.0588\n",
      "Epoch 7792/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 23.5031 - accuracy: 0.0312 - val_loss: 139.0343 - val_accuracy: 0.0588\n",
      "Epoch 7793/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.7334 - accuracy: 0.0156 - val_loss: 137.9882 - val_accuracy: 0.0000e+00\n",
      "Epoch 7794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6504 - accuracy: 0.0156 - val_loss: 135.7554 - val_accuracy: 0.0000e+00\n",
      "Epoch 7795/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 32.3318 - accuracy: 0.0000e+00 - val_loss: 131.9727 - val_accuracy: 0.0000e+00\n",
      "Epoch 7796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0078 - accuracy: 0.0156 - val_loss: 129.8637 - val_accuracy: 0.0000e+00\n",
      "Epoch 7797/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2220 - accuracy: 0.0000e+00 - val_loss: 131.8597 - val_accuracy: 0.0000e+00\n",
      "Epoch 7798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6639 - accuracy: 0.0000e+00 - val_loss: 134.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 7799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9839 - accuracy: 0.0156 - val_loss: 131.1658 - val_accuracy: 0.0000e+00\n",
      "Epoch 7800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1028 - accuracy: 0.0000e+00 - val_loss: 127.9020 - val_accuracy: 0.0588\n",
      "Epoch 7801/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1583 - accuracy: 0.0000e+00 - val_loss: 124.0737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7802/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0109 - accuracy: 0.0000e+00 - val_loss: 122.5314 - val_accuracy: 0.0588\n",
      "Epoch 7803/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 14.0632 - accuracy: 0.0000e+00 - val_loss: 126.4432 - val_accuracy: 0.0588\n",
      "Epoch 7804/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3998 - accuracy: 0.0000e+00 - val_loss: 139.9797 - val_accuracy: 0.0000e+00\n",
      "Epoch 7805/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6230 - accuracy: 0.0156 - val_loss: 140.9879 - val_accuracy: 0.0588\n",
      "Epoch 7806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6163 - accuracy: 0.0000e+00 - val_loss: 135.2906 - val_accuracy: 0.0000e+00\n",
      "Epoch 7807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3493 - accuracy: 0.0000e+00 - val_loss: 129.3188 - val_accuracy: 0.0588\n",
      "Epoch 7808/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6603 - accuracy: 0.0156 - val_loss: 125.4929 - val_accuracy: 0.0000e+00\n",
      "Epoch 7809/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.7276 - accuracy: 0.0156 - val_loss: 126.1737 - val_accuracy: 0.0000e+00\n",
      "Epoch 7810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9649 - accuracy: 0.0000e+00 - val_loss: 132.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 7811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.7921 - accuracy: 0.0312 - val_loss: 138.1174 - val_accuracy: 0.0000e+00\n",
      "Epoch 7812/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2606 - accuracy: 0.0000e+00 - val_loss: 142.6918 - val_accuracy: 0.0000e+00\n",
      "Epoch 7813/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5678 - accuracy: 0.0000e+00 - val_loss: 145.5308 - val_accuracy: 0.0000e+00\n",
      "Epoch 7814/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 25.8649 - accuracy: 0.0000e+00 - val_loss: 139.6663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7815/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7723 - accuracy: 0.0000e+00 - val_loss: 127.7237 - val_accuracy: 0.0588\n",
      "Epoch 7816/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 62us/step - loss: 14.7230 - accuracy: 0.0000e+00 - val_loss: 116.9482 - val_accuracy: 0.0588\n",
      "Epoch 7817/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.6442 - accuracy: 0.0000e+00 - val_loss: 121.1736 - val_accuracy: 0.0588\n",
      "Epoch 7818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6319 - accuracy: 0.0156 - val_loss: 129.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 7819/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.6416 - accuracy: 0.0469 - val_loss: 138.8090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 41.0554 - accuracy: 0.0000e+00 - val_loss: 149.4746 - val_accuracy: 0.0000e+00\n",
      "Epoch 7821/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.2785 - accuracy: 0.0156 - val_loss: 155.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 7822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7586 - accuracy: 0.0000e+00 - val_loss: 153.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 7823/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.1716 - accuracy: 0.0156 - val_loss: 141.6837 - val_accuracy: 0.0000e+00\n",
      "Epoch 7824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2005 - accuracy: 0.0000e+00 - val_loss: 130.6474 - val_accuracy: 0.0000e+00\n",
      "Epoch 7825/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 29.1444 - accuracy: 0.0000e+00 - val_loss: 129.4655 - val_accuracy: 0.0000e+00\n",
      "Epoch 7826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2725 - accuracy: 0.0156 - val_loss: 136.7706 - val_accuracy: 0.0588\n",
      "Epoch 7827/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 16.6471 - accuracy: 0.0156 - val_loss: 141.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 7828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9119 - accuracy: 0.0000e+00 - val_loss: 137.1317 - val_accuracy: 0.0588\n",
      "Epoch 7829/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4995 - accuracy: 0.0156 - val_loss: 136.3486 - val_accuracy: 0.0588\n",
      "Epoch 7830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8855 - accuracy: 0.0156 - val_loss: 145.2835 - val_accuracy: 0.0588\n",
      "Epoch 7831/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8821 - accuracy: 0.0156 - val_loss: 145.4057 - val_accuracy: 0.0588\n",
      "Epoch 7832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2315 - accuracy: 0.0469 - val_loss: 143.7190 - val_accuracy: 0.0000e+00\n",
      "Epoch 7833/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4488 - accuracy: 0.0156 - val_loss: 134.1953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7404 - accuracy: 0.0312 - val_loss: 124.9603 - val_accuracy: 0.0000e+00\n",
      "Epoch 7835/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 26.0375 - accuracy: 0.0000e+00 - val_loss: 119.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 7836/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 19.8594 - accuracy: 0.0000e+00 - val_loss: 124.0797 - val_accuracy: 0.0588\n",
      "Epoch 7837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3321 - accuracy: 0.0000e+00 - val_loss: 140.2124 - val_accuracy: 0.0588\n",
      "Epoch 7838/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.0844 - accuracy: 0.0156 - val_loss: 151.6080 - val_accuracy: 0.0000e+00\n",
      "Epoch 7839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0691 - accuracy: 0.0000e+00 - val_loss: 145.2211 - val_accuracy: 0.0000e+00\n",
      "Epoch 7840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1784 - accuracy: 0.0000e+00 - val_loss: 132.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 7841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2253 - accuracy: 0.0000e+00 - val_loss: 117.4859 - val_accuracy: 0.0000e+00\n",
      "Epoch 7842/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.8502 - accuracy: 0.0000e+00 - val_loss: 123.2964 - val_accuracy: 0.0000e+00\n",
      "Epoch 7843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9373 - accuracy: 0.0000e+00 - val_loss: 134.6431 - val_accuracy: 0.0000e+00\n",
      "Epoch 7844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6731 - accuracy: 0.0156 - val_loss: 146.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 7845/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6539 - accuracy: 0.0000e+00 - val_loss: 148.8816 - val_accuracy: 0.0000e+00\n",
      "Epoch 7846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9614 - accuracy: 0.0156 - val_loss: 141.1213 - val_accuracy: 0.0588\n",
      "Epoch 7847/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 26.6013 - accuracy: 0.0000e+00 - val_loss: 133.0667 - val_accuracy: 0.0588\n",
      "Epoch 7848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5283 - accuracy: 0.0000e+00 - val_loss: 132.9769 - val_accuracy: 0.0000e+00\n",
      "Epoch 7849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2456 - accuracy: 0.0156 - val_loss: 131.5782 - val_accuracy: 0.0588\n",
      "Epoch 7850/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 35.9671 - accuracy: 0.0156 - val_loss: 141.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 7851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7381 - accuracy: 0.0000e+00 - val_loss: 148.4953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7852/10000\n",
      "64/64 [==============================] - 0s 175us/step - loss: 22.1787 - accuracy: 0.0000e+00 - val_loss: 147.3785 - val_accuracy: 0.0000e+00\n",
      "Epoch 7853/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 37.3082 - accuracy: 0.0000e+00 - val_loss: 139.6540 - val_accuracy: 0.0000e+00\n",
      "Epoch 7854/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 26.7191 - accuracy: 0.0156 - val_loss: 129.5358 - val_accuracy: 0.0000e+00\n",
      "Epoch 7855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3664 - accuracy: 0.0000e+00 - val_loss: 122.8626 - val_accuracy: 0.0000e+00\n",
      "Epoch 7856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2440 - accuracy: 0.0000e+00 - val_loss: 123.8987 - val_accuracy: 0.0000e+00\n",
      "Epoch 7857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3756 - accuracy: 0.0000e+00 - val_loss: 123.3765 - val_accuracy: 0.0000e+00\n",
      "Epoch 7858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1142 - accuracy: 0.0000e+00 - val_loss: 125.1538 - val_accuracy: 0.0000e+00\n",
      "Epoch 7859/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 31.9376 - accuracy: 0.0000e+00 - val_loss: 130.4371 - val_accuracy: 0.0000e+00\n",
      "Epoch 7860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5806 - accuracy: 0.0156 - val_loss: 134.7997 - val_accuracy: 0.0588\n",
      "Epoch 7861/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5301 - accuracy: 0.0156 - val_loss: 134.8031 - val_accuracy: 0.0588\n",
      "Epoch 7862/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5264 - accuracy: 0.0312 - val_loss: 131.2845 - val_accuracy: 0.0588\n",
      "Epoch 7863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0190 - accuracy: 0.0156 - val_loss: 127.8012 - val_accuracy: 0.0000e+00\n",
      "Epoch 7864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7110 - accuracy: 0.0000e+00 - val_loss: 125.0037 - val_accuracy: 0.0588\n",
      "Epoch 7865/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.6297 - accuracy: 0.0000e+00 - val_loss: 130.2318 - val_accuracy: 0.0588\n",
      "Epoch 7866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3974 - accuracy: 0.0312 - val_loss: 133.1580 - val_accuracy: 0.0588\n",
      "Epoch 7867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4167 - accuracy: 0.0156 - val_loss: 132.2073 - val_accuracy: 0.0588\n",
      "Epoch 7868/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4422 - accuracy: 0.0312 - val_loss: 126.8641 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7869/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8777 - accuracy: 0.0000e+00 - val_loss: 129.2098 - val_accuracy: 0.0000e+00\n",
      "Epoch 7870/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.9187 - accuracy: 0.0000e+0 - 0s 47us/step - loss: 17.6636 - accuracy: 0.0000e+00 - val_loss: 138.2540 - val_accuracy: 0.0000e+00\n",
      "Epoch 7871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1908 - accuracy: 0.0156 - val_loss: 145.3363 - val_accuracy: 0.0000e+00\n",
      "Epoch 7872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2884 - accuracy: 0.0000e+00 - val_loss: 145.4384 - val_accuracy: 0.0000e+00\n",
      "Epoch 7873/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 23.2122 - accuracy: 0.0000e+00 - val_loss: 146.1855 - val_accuracy: 0.0000e+00\n",
      "Epoch 7874/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8759 - accuracy: 0.0156 - val_loss: 144.2943 - val_accuracy: 0.0588\n",
      "Epoch 7875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3212 - accuracy: 0.0156 - val_loss: 137.9061 - val_accuracy: 0.0588\n",
      "Epoch 7876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5896 - accuracy: 0.0000e+00 - val_loss: 131.1099 - val_accuracy: 0.0000e+00\n",
      "Epoch 7877/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5586 - accuracy: 0.0312 - val_loss: 123.8585 - val_accuracy: 0.0000e+00\n",
      "Epoch 7878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7119 - accuracy: 0.0000e+00 - val_loss: 122.4527 - val_accuracy: 0.0000e+00\n",
      "Epoch 7879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.6825 - accuracy: 0.0000e+00 - val_loss: 130.2701 - val_accuracy: 0.0588\n",
      "Epoch 7880/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9336 - accuracy: 0.0156 - val_loss: 131.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 7881/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 18.6455 - accuracy: 0.0312 - val_loss: 126.1181 - val_accuracy: 0.0000e+00\n",
      "Epoch 7882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8660 - accuracy: 0.0000e+00 - val_loss: 125.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 7883/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 41.7641 - accuracy: 0.0000e+00 - val_loss: 125.8612 - val_accuracy: 0.0000e+00\n",
      "Epoch 7884/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 26.5544 - accuracy: 0.0000e+00 - val_loss: 123.0790 - val_accuracy: 0.0000e+00\n",
      "Epoch 7885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.4247 - accuracy: 0.0156 - val_loss: 125.7306 - val_accuracy: 0.0000e+00\n",
      "Epoch 7886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0152 - accuracy: 0.0312 - val_loss: 130.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 7887/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2843 - accuracy: 0.0156 - val_loss: 127.6582 - val_accuracy: 0.0000e+00\n",
      "Epoch 7888/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 20.1449 - accuracy: 0.0156 - val_loss: 123.6309 - val_accuracy: 0.0000e+00\n",
      "Epoch 7889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1924 - accuracy: 0.0312 - val_loss: 121.5861 - val_accuracy: 0.0000e+00\n",
      "Epoch 7890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.9393 - accuracy: 0.0000e+00 - val_loss: 120.4262 - val_accuracy: 0.0000e+00\n",
      "Epoch 7891/10000\n",
      "64/64 [==============================] - 0s 81us/step - loss: 27.6363 - accuracy: 0.0156 - val_loss: 130.4427 - val_accuracy: 0.0000e+00\n",
      "Epoch 7892/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5838 - accuracy: 0.0000e+00 - val_loss: 133.6662 - val_accuracy: 0.0000e+00\n",
      "Epoch 7893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0995 - accuracy: 0.0000e+00 - val_loss: 134.9293 - val_accuracy: 0.0000e+00\n",
      "Epoch 7894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0040 - accuracy: 0.0156 - val_loss: 135.5564 - val_accuracy: 0.0000e+00\n",
      "Epoch 7895/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.1121 - accuracy: 0.0156 - val_loss: 130.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 7896/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5684 - accuracy: 0.0156 - val_loss: 122.8519 - val_accuracy: 0.0000e+00\n",
      "Epoch 7897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.8934 - accuracy: 0.0156 - val_loss: 122.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 7898/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 11.0857 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 19.6675 - accuracy: 0.0000e+00 - val_loss: 123.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 7899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2418 - accuracy: 0.0156 - val_loss: 125.3663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7900/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.4357 - accuracy: 0.0000e+00 - val_loss: 131.6611 - val_accuracy: 0.0000e+00\n",
      "Epoch 7901/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4767 - accuracy: 0.0000e+00 - val_loss: 138.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 7902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3077 - accuracy: 0.0156 - val_loss: 140.2066 - val_accuracy: 0.0000e+00\n",
      "Epoch 7903/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2729 - accuracy: 0.0000e+00 - val_loss: 140.7663 - val_accuracy: 0.0000e+00\n",
      "Epoch 7904/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.2759 - accuracy: 0.0156 - val_loss: 139.7571 - val_accuracy: 0.0000e+00\n",
      "Epoch 7905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3674 - accuracy: 0.0000e+00 - val_loss: 137.8468 - val_accuracy: 0.0000e+00\n",
      "Epoch 7906/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.6941 - accuracy: 0.0000e+00 - val_loss: 134.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 7907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6091 - accuracy: 0.0000e+00 - val_loss: 128.3146 - val_accuracy: 0.0000e+00\n",
      "Epoch 7908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5353 - accuracy: 0.0000e+00 - val_loss: 127.5419 - val_accuracy: 0.0000e+00\n",
      "Epoch 7909/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7543 - accuracy: 0.0156 - val_loss: 129.8636 - val_accuracy: 0.0000e+00\n",
      "Epoch 7910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5818 - accuracy: 0.0000e+00 - val_loss: 130.8710 - val_accuracy: 0.0000e+00\n",
      "Epoch 7911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3453 - accuracy: 0.0156 - val_loss: 135.0121 - val_accuracy: 0.0000e+00\n",
      "Epoch 7912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.3690 - accuracy: 0.0312 - val_loss: 133.7392 - val_accuracy: 0.0000e+00\n",
      "Epoch 7913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2661 - accuracy: 0.0000e+00 - val_loss: 121.4089 - val_accuracy: 0.0000e+00\n",
      "Epoch 7914/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 28.3778 - accuracy: 0.0156 - val_loss: 112.6137 - val_accuracy: 0.0000e+00\n",
      "Epoch 7915/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5541 - accuracy: 0.0000e+00 - val_loss: 110.9593 - val_accuracy: 0.0000e+00\n",
      "Epoch 7916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9254 - accuracy: 0.0156 - val_loss: 115.5526 - val_accuracy: 0.0000e+00\n",
      "Epoch 7917/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 17.5554 - accuracy: 0.0156 - val_loss: 124.6043 - val_accuracy: 0.0000e+00\n",
      "Epoch 7918/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 28.9611 - accuracy: 0.0000e+00 - val_loss: 129.1724 - val_accuracy: 0.0000e+00\n",
      "Epoch 7919/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.2116 - accuracy: 0.0000e+00 - val_loss: 125.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 7920/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9042 - accuracy: 0.0000e+00 - val_loss: 120.6790 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9848 - accuracy: 0.0156 - val_loss: 121.1234 - val_accuracy: 0.0000e+00\n",
      "Epoch 7922/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0855 - accuracy: 0.0000e+00 - val_loss: 129.5055 - val_accuracy: 0.0000e+00\n",
      "Epoch 7923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6069 - accuracy: 0.0156 - val_loss: 130.0414 - val_accuracy: 0.0000e+00\n",
      "Epoch 7924/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 24.6348 - accuracy: 0.0156 - val_loss: 133.4024 - val_accuracy: 0.0000e+00\n",
      "Epoch 7925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4966 - accuracy: 0.0156 - val_loss: 143.2145 - val_accuracy: 0.0000e+00\n",
      "Epoch 7926/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.3087 - accuracy: 0.0000e+00 - val_loss: 146.3213 - val_accuracy: 0.0000e+00\n",
      "Epoch 7927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0063 - accuracy: 0.0156 - val_loss: 143.3119 - val_accuracy: 0.0000e+00\n",
      "Epoch 7928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0620 - accuracy: 0.0312 - val_loss: 139.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 7929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0742 - accuracy: 0.0000e+00 - val_loss: 142.5186 - val_accuracy: 0.0000e+00\n",
      "Epoch 7930/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 27.5427 - accuracy: 0.0000e+00 - val_loss: 145.7149 - val_accuracy: 0.0000e+00\n",
      "Epoch 7931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0595 - accuracy: 0.0156 - val_loss: 143.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 7932/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6592 - accuracy: 0.0000e+00 - val_loss: 141.7246 - val_accuracy: 0.0000e+00\n",
      "Epoch 7933/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 29.2823 - accuracy: 0.0156 - val_loss: 139.1419 - val_accuracy: 0.0000e+00\n",
      "Epoch 7934/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3175 - accuracy: 0.0156 - val_loss: 145.2850 - val_accuracy: 0.0000e+00\n",
      "Epoch 7935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.9924 - accuracy: 0.0156 - val_loss: 149.4287 - val_accuracy: 0.0588\n",
      "Epoch 7936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2557 - accuracy: 0.0156 - val_loss: 148.5125 - val_accuracy: 0.0588\n",
      "Epoch 7937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0945 - accuracy: 0.0156 - val_loss: 143.6211 - val_accuracy: 0.0000e+00\n",
      "Epoch 7938/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2191 - accuracy: 0.0000e+00 - val_loss: 137.8531 - val_accuracy: 0.0000e+00\n",
      "Epoch 7939/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 23.3478 - accuracy: 0.0000e+00 - val_loss: 133.1862 - val_accuracy: 0.0588\n",
      "Epoch 7940/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.1235 - accuracy: 0.0312 - val_loss: 137.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 7941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3454 - accuracy: 0.0312 - val_loss: 140.3490 - val_accuracy: 0.0000e+00\n",
      "Epoch 7942/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 21.4876 - accuracy: 0.0000e+00 - val_loss: 139.5555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7943/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 20.1493 - accuracy: 0.0156 - val_loss: 143.5884 - val_accuracy: 0.0000e+00\n",
      "Epoch 7944/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.4719 - accuracy: 0.0312 - val_loss: 149.6255 - val_accuracy: 0.0000e+00\n",
      "Epoch 7945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7740 - accuracy: 0.0000e+00 - val_loss: 152.6429 - val_accuracy: 0.0000e+00\n",
      "Epoch 7946/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6096 - accuracy: 0.0000e+00 - val_loss: 151.4270 - val_accuracy: 0.0000e+00\n",
      "Epoch 7947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4463 - accuracy: 0.0000e+00 - val_loss: 138.8718 - val_accuracy: 0.0000e+00\n",
      "Epoch 7948/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4197 - accuracy: 0.0000e+00 - val_loss: 125.4321 - val_accuracy: 0.0000e+00\n",
      "Epoch 7949/10000\n",
      "64/64 [==============================] - 0s 106us/step - loss: 33.8928 - accuracy: 0.0000e+00 - val_loss: 119.7625 - val_accuracy: 0.0000e+00\n",
      "Epoch 7950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6140 - accuracy: 0.0000e+00 - val_loss: 121.8573 - val_accuracy: 0.0000e+00\n",
      "Epoch 7951/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5195 - accuracy: 0.0000e+00 - val_loss: 128.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 7952/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 15.8632 - accuracy: 0.0312 - val_loss: 127.2609 - val_accuracy: 0.0000e+00\n",
      "Epoch 7953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7070 - accuracy: 0.0000e+00 - val_loss: 128.5621 - val_accuracy: 0.0588\n",
      "Epoch 7954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8138 - accuracy: 0.0156 - val_loss: 132.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 7955/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 26.3017 - accuracy: 0.0156 - val_loss: 135.1796 - val_accuracy: 0.0588\n",
      "Epoch 7956/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2604 - accuracy: 0.0156 - val_loss: 136.6535 - val_accuracy: 0.0000e+00\n",
      "Epoch 7957/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.8178 - accuracy: 0.0000e+00 - val_loss: 139.6733 - val_accuracy: 0.0000e+00\n",
      "Epoch 7958/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.7253 - accuracy: 0.0000e+00 - val_loss: 137.0479 - val_accuracy: 0.0000e+00\n",
      "Epoch 7959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3708 - accuracy: 0.0312 - val_loss: 133.1631 - val_accuracy: 0.0000e+00\n",
      "Epoch 7960/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 25.6451 - accuracy: 0.0000e+00 - val_loss: 130.0496 - val_accuracy: 0.0000e+00\n",
      "Epoch 7961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6625 - accuracy: 0.0156 - val_loss: 130.7780 - val_accuracy: 0.0000e+00\n",
      "Epoch 7962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8500 - accuracy: 0.0156 - val_loss: 133.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 7963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2334 - accuracy: 0.0312 - val_loss: 133.8849 - val_accuracy: 0.0000e+00\n",
      "Epoch 7964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6647 - accuracy: 0.0000e+00 - val_loss: 134.4525 - val_accuracy: 0.0000e+00\n",
      "Epoch 7965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5237 - accuracy: 0.0312 - val_loss: 130.7523 - val_accuracy: 0.0588\n",
      "Epoch 7966/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6289 - accuracy: 0.0156 - val_loss: 117.1153 - val_accuracy: 0.0000e+00\n",
      "Epoch 7967/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0307 - accuracy: 0.0000e+00 - val_loss: 114.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 7968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6566 - accuracy: 0.0000e+00 - val_loss: 121.7893 - val_accuracy: 0.0000e+00\n",
      "Epoch 7969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6848 - accuracy: 0.0312 - val_loss: 135.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 7970/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.0448 - accuracy: 0.0000e+00 - val_loss: 144.9384 - val_accuracy: 0.0588\n",
      "Epoch 7971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7111 - accuracy: 0.0000e+00 - val_loss: 129.1178 - val_accuracy: 0.0588\n",
      "Epoch 7972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2599 - accuracy: 0.0000e+00 - val_loss: 121.6451 - val_accuracy: 0.0000e+00\n",
      "Epoch 7973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4025 - accuracy: 0.0000e+00 - val_loss: 116.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 7974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3881 - accuracy: 0.0000e+00 - val_loss: 116.5235 - val_accuracy: 0.0588\n",
      "Epoch 7975/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2825 - accuracy: 0.0000e+00 - val_loss: 120.6908 - val_accuracy: 0.0000e+00\n",
      "Epoch 7976/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4769 - accuracy: 0.0000e+00 - val_loss: 127.1940 - val_accuracy: 0.0588\n",
      "Epoch 7977/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9245 - accuracy: 0.0000e+00 - val_loss: 135.1560 - val_accuracy: 0.0588\n",
      "Epoch 7978/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6436 - accuracy: 0.0156 - val_loss: 138.5932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7979/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 41.2198 - accuracy: 0.0000e+00 - val_loss: 141.0084 - val_accuracy: 0.0000e+00\n",
      "Epoch 7980/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4096 - accuracy: 0.0000e+00 - val_loss: 134.1758 - val_accuracy: 0.0588\n",
      "Epoch 7981/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0184 - accuracy: 0.0000e+00 - val_loss: 126.9815 - val_accuracy: 0.0000e+00\n",
      "Epoch 7982/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 23.1338 - accuracy: 0.0156 - val_loss: 125.1893 - val_accuracy: 0.0000e+00\n",
      "Epoch 7983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5580 - accuracy: 0.0156 - val_loss: 127.8200 - val_accuracy: 0.0588\n",
      "Epoch 7984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8595 - accuracy: 0.0000e+00 - val_loss: 136.0896 - val_accuracy: 0.0000e+00\n",
      "Epoch 7985/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.5717 - accuracy: 0.0000e+00 - val_loss: 136.5115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2117 - accuracy: 0.0000e+00 - val_loss: 134.3591 - val_accuracy: 0.0000e+00\n",
      "Epoch 7987/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3797 - accuracy: 0.0000e+00 - val_loss: 128.2178 - val_accuracy: 0.0000e+00\n",
      "Epoch 7988/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9875 - accuracy: 0.0156 - val_loss: 119.4300 - val_accuracy: 0.0000e+00\n",
      "Epoch 7989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6115 - accuracy: 0.0000e+00 - val_loss: 123.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 7990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5512 - accuracy: 0.0000e+00 - val_loss: 127.5932 - val_accuracy: 0.0000e+00\n",
      "Epoch 7991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5135 - accuracy: 0.0000e+00 - val_loss: 133.4442 - val_accuracy: 0.0000e+00\n",
      "Epoch 7992/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 38.9008 - accuracy: 0.0000e+00 - val_loss: 136.0573 - val_accuracy: 0.0000e+00\n",
      "Epoch 7993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3950 - accuracy: 0.0000e+00 - val_loss: 129.9590 - val_accuracy: 0.0000e+00\n",
      "Epoch 7994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1369 - accuracy: 0.0156 - val_loss: 125.0493 - val_accuracy: 0.0000e+00\n",
      "Epoch 7995/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 29.6700 - accuracy: 0.0000e+00 - val_loss: 124.2244 - val_accuracy: 0.0588\n",
      "Epoch 7996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1278 - accuracy: 0.0000e+00 - val_loss: 119.5724 - val_accuracy: 0.0588\n",
      "Epoch 7997/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.2560 - accuracy: 0.0000e+00 - val_loss: 126.2813 - val_accuracy: 0.0000e+00\n",
      "Epoch 7998/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3548 - accuracy: 0.0000e+00 - val_loss: 137.9567 - val_accuracy: 0.0000e+00\n",
      "Epoch 7999/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6356 - accuracy: 0.0469 - val_loss: 138.2327 - val_accuracy: 0.0588\n",
      "Epoch 8000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0155 - accuracy: 0.0000e+00 - val_loss: 133.6268 - val_accuracy: 0.0588\n",
      "Epoch 8001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3039 - accuracy: 0.0156 - val_loss: 131.1145 - val_accuracy: 0.0588\n",
      "Epoch 8002/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 19.2528 - accuracy: 0.0156 - val_loss: 126.8932 - val_accuracy: 0.0588\n",
      "Epoch 8003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2566 - accuracy: 0.0156 - val_loss: 124.0796 - val_accuracy: 0.0588\n",
      "Epoch 8004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2649 - accuracy: 0.0000e+00 - val_loss: 121.6044 - val_accuracy: 0.0000e+00\n",
      "Epoch 8005/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9717 - accuracy: 0.0000e+00 - val_loss: 122.2165 - val_accuracy: 0.0000e+00\n",
      "Epoch 8006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4025 - accuracy: 0.0000e+00 - val_loss: 130.0540 - val_accuracy: 0.0588\n",
      "Epoch 8007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5779 - accuracy: 0.0000e+00 - val_loss: 144.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 8008/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6076 - accuracy: 0.0156 - val_loss: 152.0922 - val_accuracy: 0.0000e+00\n",
      "Epoch 8009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9467 - accuracy: 0.0156 - val_loss: 148.6371 - val_accuracy: 0.0000e+00\n",
      "Epoch 8010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6331 - accuracy: 0.0156 - val_loss: 141.2101 - val_accuracy: 0.0000e+00\n",
      "Epoch 8011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4589 - accuracy: 0.0156 - val_loss: 136.4166 - val_accuracy: 0.0588\n",
      "Epoch 8012/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6959 - accuracy: 0.0156 - val_loss: 132.4970 - val_accuracy: 0.0000e+00\n",
      "Epoch 8013/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 16.5308 - accuracy: 0.0000e+00 - val_loss: 132.1164 - val_accuracy: 0.0000e+00\n",
      "Epoch 8014/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2675 - accuracy: 0.0000e+00 - val_loss: 126.6745 - val_accuracy: 0.0000e+00\n",
      "Epoch 8015/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0218 - accuracy: 0.0312 - val_loss: 115.3909 - val_accuracy: 0.0000e+00\n",
      "Epoch 8016/10000\n",
      "64/64 [==============================] - 0s 61us/step - loss: 15.7750 - accuracy: 0.0000e+00 - val_loss: 112.3229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8017/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9049 - accuracy: 0.0156 - val_loss: 115.9977 - val_accuracy: 0.0000e+00\n",
      "Epoch 8018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6306 - accuracy: 0.0156 - val_loss: 122.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 8019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2676 - accuracy: 0.0312 - val_loss: 133.2619 - val_accuracy: 0.0000e+00\n",
      "Epoch 8020/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.9915 - accuracy: 0.0000e+00 - val_loss: 142.7721 - val_accuracy: 0.0000e+00\n",
      "Epoch 8021/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8366 - accuracy: 0.0000e+00 - val_loss: 145.3417 - val_accuracy: 0.0000e+00\n",
      "Epoch 8022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4814 - accuracy: 0.0156 - val_loss: 141.3204 - val_accuracy: 0.0588\n",
      "Epoch 8023/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 17.0274 - accuracy: 0.0156 - val_loss: 134.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6201 - accuracy: 0.0156 - val_loss: 129.5192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8025/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 30.2305 - accuracy: 0.0000e+00 - val_loss: 129.7186 - val_accuracy: 0.0588\n",
      "Epoch 8026/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 15.0709 - accuracy: 0.0312 - val_loss: 134.9476 - val_accuracy: 0.0588\n",
      "Epoch 8027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6820 - accuracy: 0.0000e+00 - val_loss: 141.2839 - val_accuracy: 0.0588\n",
      "Epoch 8028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6089 - accuracy: 0.0312 - val_loss: 144.3545 - val_accuracy: 0.0588\n",
      "Epoch 8029/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7776 - accuracy: 0.0156 - val_loss: 143.7567 - val_accuracy: 0.0000e+00\n",
      "Epoch 8030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1970 - accuracy: 0.0000e+00 - val_loss: 132.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 8031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.8316 - accuracy: 0.0156 - val_loss: 129.7616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8032/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.0570 - accuracy: 0.0156 - val_loss: 135.9605 - val_accuracy: 0.0000e+00\n",
      "Epoch 8033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5699 - accuracy: 0.0000e+00 - val_loss: 142.5357 - val_accuracy: 0.0000e+00\n",
      "Epoch 8034/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.5493 - accuracy: 0.0156 - val_loss: 148.0538 - val_accuracy: 0.0000e+00\n",
      "Epoch 8035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8692 - accuracy: 0.0156 - val_loss: 147.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 8036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5413 - accuracy: 0.0156 - val_loss: 142.4178 - val_accuracy: 0.0000e+00\n",
      "Epoch 8037/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.0215 - accuracy: 0.0000e+00 - val_loss: 134.6181 - val_accuracy: 0.0588\n",
      "Epoch 8038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1872 - accuracy: 0.0000e+00 - val_loss: 128.8249 - val_accuracy: 0.0588\n",
      "Epoch 8039/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9664 - accuracy: 0.0312 - val_loss: 127.8803 - val_accuracy: 0.0588\n",
      "Epoch 8040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3359 - accuracy: 0.0000e+00 - val_loss: 129.0348 - val_accuracy: 0.0588\n",
      "Epoch 8041/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6170 - accuracy: 0.0156 - val_loss: 132.1544 - val_accuracy: 0.0588\n",
      "Epoch 8042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2825 - accuracy: 0.0000e+00 - val_loss: 138.9065 - val_accuracy: 0.1176\n",
      "Epoch 8043/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 22.4236 - accuracy: 0.0156 - val_loss: 139.0911 - val_accuracy: 0.0588\n",
      "Epoch 8044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5712 - accuracy: 0.0156 - val_loss: 135.9112 - val_accuracy: 0.0588\n",
      "Epoch 8045/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1260 - accuracy: 0.0156 - val_loss: 135.1454 - val_accuracy: 0.0588\n",
      "Epoch 8046/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.8646 - accuracy: 0.0000e+00 - val_loss: 135.4805 - val_accuracy: 0.0588\n",
      "Epoch 8047/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.1198 - accuracy: 0.0000e+00 - val_loss: 127.8204 - val_accuracy: 0.0588\n",
      "Epoch 8048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3872 - accuracy: 0.0000e+00 - val_loss: 119.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 8049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9054 - accuracy: 0.0000e+00 - val_loss: 112.7897 - val_accuracy: 0.0588\n",
      "Epoch 8050/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.9534 - accuracy: 0.0156 - val_loss: 114.6679 - val_accuracy: 0.0000e+00\n",
      "Epoch 8051/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4050 - accuracy: 0.0156 - val_loss: 118.8818 - val_accuracy: 0.0000e+00\n",
      "Epoch 8052/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1200 - accuracy: 0.0312 - val_loss: 128.0298 - val_accuracy: 0.0000e+00\n",
      "Epoch 8053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4835 - accuracy: 0.0156 - val_loss: 140.4115 - val_accuracy: 0.0000e+00\n",
      "Epoch 8054/10000\n",
      "64/64 [==============================] - 0s 71us/step - loss: 20.4623 - accuracy: 0.0000e+00 - val_loss: 147.2569 - val_accuracy: 0.0588\n",
      "Epoch 8055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2261 - accuracy: 0.0000e+00 - val_loss: 141.5887 - val_accuracy: 0.0588\n",
      "Epoch 8056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3378 - accuracy: 0.0000e+00 - val_loss: 133.4997 - val_accuracy: 0.0588\n",
      "Epoch 8057/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5349 - accuracy: 0.0156 - val_loss: 128.1055 - val_accuracy: 0.0588\n",
      "Epoch 8058/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5146 - accuracy: 0.0156 - val_loss: 128.8963 - val_accuracy: 0.1176\n",
      "Epoch 8059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8432 - accuracy: 0.0156 - val_loss: 132.4471 - val_accuracy: 0.0588\n",
      "Epoch 8060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1832 - accuracy: 0.0000e+00 - val_loss: 138.2439 - val_accuracy: 0.0588\n",
      "Epoch 8061/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8554 - accuracy: 0.0156 - val_loss: 137.7037 - val_accuracy: 0.0588\n",
      "Epoch 8062/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3400 - accuracy: 0.0156 - val_loss: 125.8591 - val_accuracy: 0.0588\n",
      "Epoch 8063/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.8819 - accuracy: 0.0000e+00 - val_loss: 115.4102 - val_accuracy: 0.0000e+00\n",
      "Epoch 8064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2821 - accuracy: 0.0000e+00 - val_loss: 110.3170 - val_accuracy: 0.0000e+00\n",
      "Epoch 8065/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0662 - accuracy: 0.0156 - val_loss: 115.5511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8066/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 24.4718 - accuracy: 0.0156 - val_loss: 128.3402 - val_accuracy: 0.0588\n",
      "Epoch 8067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8592 - accuracy: 0.0000e+00 - val_loss: 133.4659 - val_accuracy: 0.0588\n",
      "Epoch 8068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8543 - accuracy: 0.0156 - val_loss: 134.6457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9464 - accuracy: 0.0156 - val_loss: 133.7102 - val_accuracy: 0.0000e+00\n",
      "Epoch 8070/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.6257 - accuracy: 0.0000e+00 - val_loss: 132.7801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1168 - accuracy: 0.0000e+00 - val_loss: 131.9641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1902 - accuracy: 0.0156 - val_loss: 125.6257 - val_accuracy: 0.0000e+00\n",
      "Epoch 8073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4148 - accuracy: 0.0156 - val_loss: 117.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8074/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1938 - accuracy: 0.0469 - val_loss: 113.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 8075/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 19.9247 - accuracy: 0.0469 - val_loss: 113.6546 - val_accuracy: 0.0000e+00\n",
      "Epoch 8076/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 35.8761 - accuracy: 0.0000e+00 - val_loss: 112.0616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8077/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6712 - accuracy: 0.0000e+00 - val_loss: 113.3612 - val_accuracy: 0.0000e+00\n",
      "Epoch 8078/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2660 - accuracy: 0.0156 - val_loss: 121.8580 - val_accuracy: 0.0000e+00\n",
      "Epoch 8079/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.1176 - accuracy: 0.0312 - val_loss: 134.1421 - val_accuracy: 0.0000e+00\n",
      "Epoch 8080/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9921 - accuracy: 0.0000e+00 - val_loss: 135.5902 - val_accuracy: 0.0000e+00\n",
      "Epoch 8081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2061 - accuracy: 0.0000e+00 - val_loss: 138.7575 - val_accuracy: 0.0000e+00\n",
      "Epoch 8082/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4503 - accuracy: 0.0000e+00 - val_loss: 137.2109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3864 - accuracy: 0.0156 - val_loss: 143.0452 - val_accuracy: 0.0000e+00\n",
      "Epoch 8084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6019 - accuracy: 0.0000e+00 - val_loss: 153.5452 - val_accuracy: 0.0000e+00\n",
      "Epoch 8085/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.9528 - accuracy: 0.0156 - val_loss: 156.6583 - val_accuracy: 0.0000e+00\n",
      "Epoch 8086/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.1287 - accuracy: 0.0312 - val_loss: 156.9809 - val_accuracy: 0.0000e+00\n",
      "Epoch 8087/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 17.9052 - accuracy: 0.0000e+00 - val_loss: 149.8464 - val_accuracy: 0.0588\n",
      "Epoch 8088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1810 - accuracy: 0.0000e+00 - val_loss: 137.5305 - val_accuracy: 0.0000e+00\n",
      "Epoch 8089/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 33.0358 - accuracy: 0.0156 - val_loss: 130.6081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2257 - accuracy: 0.0000e+00 - val_loss: 120.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9958 - accuracy: 0.0156 - val_loss: 117.5621 - val_accuracy: 0.0000e+00\n",
      "Epoch 8092/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 43.7739 - accuracy: 0.0000e+00 - val_loss: 119.6204 - val_accuracy: 0.0588\n",
      "Epoch 8093/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 32.4608 - accuracy: 0.0000e+00 - val_loss: 125.9292 - val_accuracy: 0.0000e+00\n",
      "Epoch 8094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8995 - accuracy: 0.0000e+00 - val_loss: 136.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.9022 - accuracy: 0.0156 - val_loss: 143.3573 - val_accuracy: 0.0000e+00\n",
      "Epoch 8096/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5842 - accuracy: 0.0312 - val_loss: 140.0010 - val_accuracy: 0.0000e+00\n",
      "Epoch 8097/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9179 - accuracy: 0.0000e+00 - val_loss: 128.0086 - val_accuracy: 0.0000e+00\n",
      "Epoch 8098/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 29.6694 - accuracy: 0.0000e+00 - val_loss: 118.2167 - val_accuracy: 0.0000e+00\n",
      "Epoch 8099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4445 - accuracy: 0.0000e+00 - val_loss: 116.5341 - val_accuracy: 0.0000e+00\n",
      "Epoch 8100/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.0514 - accuracy: 0.0156 - val_loss: 133.3281 - val_accuracy: 0.0000e+00\n",
      "Epoch 8101/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.6922 - accuracy: 0.0156 - val_loss: 141.7556 - val_accuracy: 0.0000e+00\n",
      "Epoch 8102/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 37.7757 - accuracy: 0.0000e+00 - val_loss: 132.3711 - val_accuracy: 0.0000e+00\n",
      "Epoch 8103/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3835 - accuracy: 0.0156 - val_loss: 125.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 8104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 40.0129 - accuracy: 0.0000e+00 - val_loss: 128.3712 - val_accuracy: 0.0000e+00\n",
      "Epoch 8105/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4821 - accuracy: 0.0156 - val_loss: 130.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 8106/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.9274 - accuracy: 0.0156 - val_loss: 129.0671 - val_accuracy: 0.0000e+00\n",
      "Epoch 8107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.7041 - accuracy: 0.0000e+00 - val_loss: 130.4229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8108/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1612 - accuracy: 0.0000e+00 - val_loss: 131.7025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8024 - accuracy: 0.0156 - val_loss: 129.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 8110/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 26.6001 - accuracy: 0.0000e+00 - val_loss: 129.1040 - val_accuracy: 0.0000e+00\n",
      "Epoch 8111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0075 - accuracy: 0.0156 - val_loss: 127.2849 - val_accuracy: 0.0000e+00\n",
      "Epoch 8112/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.6074 - accuracy: 0.0156 - val_loss: 126.9700 - val_accuracy: 0.0000e+00\n",
      "Epoch 8113/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 34.0065 - accuracy: 0.0000e+00 - val_loss: 128.0032 - val_accuracy: 0.0000e+00\n",
      "Epoch 8114/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4654 - accuracy: 0.0000e+00 - val_loss: 130.4035 - val_accuracy: 0.0000e+00\n",
      "Epoch 8115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8244 - accuracy: 0.0000e+00 - val_loss: 128.8226 - val_accuracy: 0.0000e+00\n",
      "Epoch 8116/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.6650 - accuracy: 0.0000e+00 - val_loss: 125.0702 - val_accuracy: 0.0588\n",
      "Epoch 8117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8587 - accuracy: 0.0156 - val_loss: 128.0864 - val_accuracy: 0.0588\n",
      "Epoch 8118/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7404 - accuracy: 0.0000e+00 - val_loss: 133.2192 - val_accuracy: 0.0588\n",
      "Epoch 8119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4299 - accuracy: 0.0156 - val_loss: 139.6636 - val_accuracy: 0.0588\n",
      "Epoch 8120/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9166 - accuracy: 0.0000e+00 - val_loss: 146.0097 - val_accuracy: 0.0000e+00\n",
      "Epoch 8121/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 34.1030 - accuracy: 0.0469 - val_loss: 145.0739 - val_accuracy: 0.0000e+00\n",
      "Epoch 8122/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.5043 - accuracy: 0.0000e+00 - val_loss: 148.7904 - val_accuracy: 0.0000e+00\n",
      "Epoch 8123/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 28.3621 - accuracy: 0.0156 - val_loss: 144.6589 - val_accuracy: 0.0000e+00\n",
      "Epoch 8124/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0171 - accuracy: 0.0000e+00 - val_loss: 135.5973 - val_accuracy: 0.0000e+00\n",
      "Epoch 8125/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.9796 - accuracy: 0.0000e+00 - val_loss: 122.7051 - val_accuracy: 0.0000e+00\n",
      "Epoch 8126/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8308 - accuracy: 0.0156 - val_loss: 112.6558 - val_accuracy: 0.0000e+00\n",
      "Epoch 8127/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2183 - accuracy: 0.0312 - val_loss: 115.7056 - val_accuracy: 0.0000e+00\n",
      "Epoch 8128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2346 - accuracy: 0.0312 - val_loss: 121.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 8129/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2567 - accuracy: 0.0000e+00 - val_loss: 126.8963 - val_accuracy: 0.0000e+00\n",
      "Epoch 8130/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 16.5914 - accuracy: 0.0156 - val_loss: 127.0653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3391 - accuracy: 0.0000e+00 - val_loss: 125.3202 - val_accuracy: 0.0000e+00\n",
      "Epoch 8132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3222 - accuracy: 0.0312 - val_loss: 122.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8133/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1376 - accuracy: 0.0000e+00 - val_loss: 114.5310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8134/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 32.5811 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 31.3810 - accuracy: 0.0000e+00 - val_loss: 113.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 8135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0440 - accuracy: 0.0000e+00 - val_loss: 122.4095 - val_accuracy: 0.0000e+00\n",
      "Epoch 8136/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8822 - accuracy: 0.0156 - val_loss: 128.6882 - val_accuracy: 0.0000e+00\n",
      "Epoch 8137/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1995 - accuracy: 0.0000e+00 - val_loss: 130.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8138/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 29.3170 - accuracy: 0.0000e+00 - val_loss: 138.9952 - val_accuracy: 0.0000e+00\n",
      "Epoch 8139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1245 - accuracy: 0.0312 - val_loss: 145.2332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8140/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.2663 - accuracy: 0.0312 - val_loss: 148.5895 - val_accuracy: 0.0000e+00\n",
      "Epoch 8141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2523 - accuracy: 0.0000e+00 - val_loss: 146.1699 - val_accuracy: 0.0000e+00\n",
      "Epoch 8142/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.1854 - accuracy: 0.0156 - val_loss: 143.0028 - val_accuracy: 0.0000e+00\n",
      "Epoch 8143/10000\n",
      "64/64 [==============================] - 0s 72us/step - loss: 20.9614 - accuracy: 0.0000e+00 - val_loss: 139.2657 - val_accuracy: 0.0000e+00\n",
      "Epoch 8144/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0579 - accuracy: 0.0469 - val_loss: 134.2094 - val_accuracy: 0.0000e+00\n",
      "Epoch 8145/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5503 - accuracy: 0.0000e+00 - val_loss: 128.2942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8146/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6682 - accuracy: 0.0156 - val_loss: 127.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8147/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.2501 - accuracy: 0.0000e+00 - val_loss: 131.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 8148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0621 - accuracy: 0.0156 - val_loss: 141.1464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3135 - accuracy: 0.0000e+00 - val_loss: 146.5615 - val_accuracy: 0.0000e+00\n",
      "Epoch 8150/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 21.2350 - accuracy: 0.0312 - val_loss: 147.3136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8151/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4585 - accuracy: 0.0000e+00 - val_loss: 142.5892 - val_accuracy: 0.0000e+00\n",
      "Epoch 8152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4586 - accuracy: 0.0312 - val_loss: 138.0342 - val_accuracy: 0.0000e+00\n",
      "Epoch 8153/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2776 - accuracy: 0.0156 - val_loss: 133.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 8154/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7714 - accuracy: 0.0000e+00 - val_loss: 129.2362 - val_accuracy: 0.0000e+00\n",
      "Epoch 8155/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 21.3771 - accuracy: 0.0156 - val_loss: 127.3148 - val_accuracy: 0.0000e+00\n",
      "Epoch 8156/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4775 - accuracy: 0.0312 - val_loss: 122.2185 - val_accuracy: 0.0000e+00\n",
      "Epoch 8157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1460 - accuracy: 0.0000e+00 - val_loss: 116.7362 - val_accuracy: 0.0000e+00\n",
      "Epoch 8158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1934 - accuracy: 0.0000e+00 - val_loss: 116.9937 - val_accuracy: 0.0000e+00\n",
      "Epoch 8159/10000\n",
      "64/64 [==============================] - 0s 69us/step - loss: 26.7247 - accuracy: 0.0000e+00 - val_loss: 120.4613 - val_accuracy: 0.0000e+00\n",
      "Epoch 8160/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9625 - accuracy: 0.0469 - val_loss: 120.2041 - val_accuracy: 0.0000e+00\n",
      "Epoch 8161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7981 - accuracy: 0.0000e+00 - val_loss: 119.4923 - val_accuracy: 0.0000e+00\n",
      "Epoch 8162/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 14.4193 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 22.4592 - accuracy: 0.0156 - val_loss: 118.8463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8163/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1966 - accuracy: 0.0000e+00 - val_loss: 118.7155 - val_accuracy: 0.0000e+00\n",
      "Epoch 8164/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.8243 - accuracy: 0.0000e+00 - val_loss: 123.7038 - val_accuracy: 0.0000e+00\n",
      "Epoch 8165/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 29.4367 - accuracy: 0.0000e+00 - val_loss: 131.5560 - val_accuracy: 0.0000e+00\n",
      "Epoch 8166/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2220 - accuracy: 0.0000e+00 - val_loss: 129.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 8167/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3466 - accuracy: 0.0156 - val_loss: 131.4439 - val_accuracy: 0.0000e+00\n",
      "Epoch 8168/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 45.5465 - accuracy: 0.0156 - val_loss: 136.9961 - val_accuracy: 0.0000e+00\n",
      "Epoch 8169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5682 - accuracy: 0.0000e+00 - val_loss: 145.3962 - val_accuracy: 0.0000e+00\n",
      "Epoch 8170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0393 - accuracy: 0.0156 - val_loss: 151.7108 - val_accuracy: 0.0000e+00\n",
      "Epoch 8171/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.3103 - accuracy: 0.0156 - val_loss: 155.7130 - val_accuracy: 0.0000e+00\n",
      "Epoch 8172/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7719 - accuracy: 0.0156 - val_loss: 145.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7389 - accuracy: 0.0000e+00 - val_loss: 127.3682 - val_accuracy: 0.0000e+00\n",
      "Epoch 8174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3068 - accuracy: 0.0156 - val_loss: 111.4310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8175/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.5490 - accuracy: 0.0156 - val_loss: 119.3935 - val_accuracy: 0.0588\n",
      "Epoch 8176/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 23.0669 - accuracy: 0.0000e+00 - val_loss: 137.5108 - val_accuracy: 0.0588\n",
      "Epoch 8177/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 32.1166 - accuracy: 0.0156 - val_loss: 137.2981 - val_accuracy: 0.0000e+00\n",
      "Epoch 8178/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1459 - accuracy: 0.0000e+00 - val_loss: 134.3807 - val_accuracy: 0.0000e+00\n",
      "Epoch 8179/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 24.3933 - accuracy: 0.0000e+00 - val_loss: 131.7127 - val_accuracy: 0.0000e+00\n",
      "Epoch 8180/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7578 - accuracy: 0.0312 - val_loss: 129.7287 - val_accuracy: 0.0000e+00\n",
      "Epoch 8181/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.9035 - accuracy: 0.0000e+00 - val_loss: 126.1540 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9610 - accuracy: 0.0469 - val_loss: 120.2696 - val_accuracy: 0.0588\n",
      "Epoch 8183/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0305 - accuracy: 0.0000e+00 - val_loss: 120.1808 - val_accuracy: 0.0588\n",
      "Epoch 8184/10000\n",
      "64/64 [==============================] - 0s 97us/step - loss: 34.6301 - accuracy: 0.0156 - val_loss: 126.8793 - val_accuracy: 0.0588\n",
      "Epoch 8185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5348 - accuracy: 0.0000e+00 - val_loss: 140.4358 - val_accuracy: 0.0588\n",
      "Epoch 8186/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6207 - accuracy: 0.0000e+00 - val_loss: 141.4872 - val_accuracy: 0.0588\n",
      "Epoch 8187/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 19.6996 - accuracy: 0.0156 - val_loss: 133.2211 - val_accuracy: 0.0588\n",
      "Epoch 8188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.4164 - accuracy: 0.0000e+00 - val_loss: 132.6646 - val_accuracy: 0.0588\n",
      "Epoch 8189/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 26.6073 - accuracy: 0.0156 - val_loss: 132.4088 - val_accuracy: 0.0000e+00\n",
      "Epoch 8190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3125 - accuracy: 0.0156 - val_loss: 139.2701 - val_accuracy: 0.0588\n",
      "Epoch 8191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7049 - accuracy: 0.0156 - val_loss: 144.4622 - val_accuracy: 0.0000e+00\n",
      "Epoch 8192/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3525 - accuracy: 0.0156 - val_loss: 145.7583 - val_accuracy: 0.0000e+00\n",
      "Epoch 8193/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4370 - accuracy: 0.0156 - val_loss: 144.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 8194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1110 - accuracy: 0.0000e+00 - val_loss: 140.3083 - val_accuracy: 0.0000e+00\n",
      "Epoch 8195/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.5604 - accuracy: 0.0156 - val_loss: 131.3586 - val_accuracy: 0.0000e+00\n",
      "Epoch 8196/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.8901 - accuracy: 0.0000e+00 - val_loss: 125.6533 - val_accuracy: 0.0000e+00\n",
      "Epoch 8197/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9816 - accuracy: 0.0156 - val_loss: 123.6492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5055 - accuracy: 0.0156 - val_loss: 124.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8199/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8987 - accuracy: 0.0000e+00 - val_loss: 125.9386 - val_accuracy: 0.0000e+00\n",
      "Epoch 8200/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 23.8512 - accuracy: 0.0156 - val_loss: 131.3233 - val_accuracy: 0.0000e+00\n",
      "Epoch 8201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1372 - accuracy: 0.0000e+00 - val_loss: 127.6597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7260 - accuracy: 0.0000e+00 - val_loss: 122.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 8203/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.8674 - accuracy: 0.0156 - val_loss: 121.8596 - val_accuracy: 0.0000e+00\n",
      "Epoch 8204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4810 - accuracy: 0.0156 - val_loss: 122.2261 - val_accuracy: 0.0000e+00\n",
      "Epoch 8205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.3005 - accuracy: 0.0000e+00 - val_loss: 120.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 8206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0792 - accuracy: 0.0000e+00 - val_loss: 119.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 8207/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3254 - accuracy: 0.0156 - val_loss: 116.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8208/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5172 - accuracy: 0.0156 - val_loss: 122.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 8209/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1240 - accuracy: 0.0000e+00 - val_loss: 128.5661 - val_accuracy: 0.0588\n",
      "Epoch 8210/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 25.0301 - accuracy: 0.0156 - val_loss: 131.4492 - val_accuracy: 0.1176\n",
      "Epoch 8211/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.5249 - accuracy: 0.0000e+00 - val_loss: 134.3666 - val_accuracy: 0.1176\n",
      "Epoch 8212/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1417 - accuracy: 0.0312 - val_loss: 135.5399 - val_accuracy: 0.0000e+00\n",
      "Epoch 8213/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.6156 - accuracy: 0.0156 - val_loss: 135.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 8214/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8050 - accuracy: 0.0312 - val_loss: 137.0676 - val_accuracy: 0.0000e+00\n",
      "Epoch 8215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4925 - accuracy: 0.0312 - val_loss: 131.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 8216/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2657 - accuracy: 0.0000e+00 - val_loss: 125.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 8217/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.7592 - accuracy: 0.0156 - val_loss: 123.1965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8218/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7799 - accuracy: 0.0000e+00 - val_loss: 127.5458 - val_accuracy: 0.0588\n",
      "Epoch 8219/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8780 - accuracy: 0.0000e+00 - val_loss: 132.2310 - val_accuracy: 0.0588\n",
      "Epoch 8220/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6326 - accuracy: 0.0000e+00 - val_loss: 131.0131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8221/10000\n",
      "64/64 [==============================] - 0s 197us/step - loss: 29.6969 - accuracy: 0.0000e+00 - val_loss: 133.8585 - val_accuracy: 0.0000e+00\n",
      "Epoch 8222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4698 - accuracy: 0.0156 - val_loss: 135.2684 - val_accuracy: 0.0000e+00\n",
      "Epoch 8223/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 33.6620 - accuracy: 0.0000e+00 - val_loss: 128.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8224/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8417 - accuracy: 0.0156 - val_loss: 125.0305 - val_accuracy: 0.0588\n",
      "Epoch 8225/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 37.5433 - accuracy: 0.0156 - val_loss: 129.7547 - val_accuracy: 0.0588\n",
      "Epoch 8226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4845 - accuracy: 0.0156 - val_loss: 133.5921 - val_accuracy: 0.0588\n",
      "Epoch 8227/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7830 - accuracy: 0.0000e+00 - val_loss: 134.0925 - val_accuracy: 0.0588\n",
      "Epoch 8228/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3389 - accuracy: 0.0156 - val_loss: 137.7783 - val_accuracy: 0.0000e+00\n",
      "Epoch 8229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7903 - accuracy: 0.0312 - val_loss: 135.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 8230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1952 - accuracy: 0.0000e+00 - val_loss: 138.4277 - val_accuracy: 0.0588\n",
      "Epoch 8231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9602 - accuracy: 0.0156 - val_loss: 144.6999 - val_accuracy: 0.0588\n",
      "Epoch 8232/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 18.0993 - accuracy: 0.0000e+00 - val_loss: 147.4980 - val_accuracy: 0.0588\n",
      "Epoch 8233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3794 - accuracy: 0.0312 - val_loss: 136.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 8234/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.8554 - accuracy: 0.0156 - val_loss: 128.8441 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7214 - accuracy: 0.0000e+00 - val_loss: 124.2985 - val_accuracy: 0.0000e+00\n",
      "Epoch 8236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5659 - accuracy: 0.0000e+00 - val_loss: 127.6398 - val_accuracy: 0.0000e+00\n",
      "Epoch 8237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.8588 - accuracy: 0.0000e+00 - val_loss: 125.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5131 - accuracy: 0.0156 - val_loss: 127.8751 - val_accuracy: 0.0588\n",
      "Epoch 8239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0026 - accuracy: 0.0156 - val_loss: 137.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 8240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7607 - accuracy: 0.0312 - val_loss: 137.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 8241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4629 - accuracy: 0.0156 - val_loss: 131.0446 - val_accuracy: 0.0000e+00\n",
      "Epoch 8242/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 24.4651 - accuracy: 0.0000e+00 - val_loss: 123.4775 - val_accuracy: 0.0000e+00\n",
      "Epoch 8243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5321 - accuracy: 0.0000e+00 - val_loss: 119.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 8244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.9078 - accuracy: 0.0156 - val_loss: 117.7677 - val_accuracy: 0.0000e+00\n",
      "Epoch 8245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5950 - accuracy: 0.0000e+00 - val_loss: 119.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 8246/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9959 - accuracy: 0.0156 - val_loss: 125.5255 - val_accuracy: 0.0000e+00\n",
      "Epoch 8247/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4714 - accuracy: 0.0156 - val_loss: 128.4313 - val_accuracy: 0.0000e+00\n",
      "Epoch 8248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9404 - accuracy: 0.0000e+00 - val_loss: 127.6388 - val_accuracy: 0.0000e+00\n",
      "Epoch 8249/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5784 - accuracy: 0.0000e+00 - val_loss: 132.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 8250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2602 - accuracy: 0.0156 - val_loss: 133.8422 - val_accuracy: 0.0588\n",
      "Epoch 8251/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.6554 - accuracy: 0.0000e+00 - val_loss: 137.1711 - val_accuracy: 0.0588\n",
      "Epoch 8252/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.5756 - accuracy: 0.0156 - val_loss: 143.6627 - val_accuracy: 0.0588\n",
      "Epoch 8253/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.2509 - accuracy: 0.0000e+00 - val_loss: 148.6903 - val_accuracy: 0.0000e+00\n",
      "Epoch 8254/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0194 - accuracy: 0.0312 - val_loss: 142.7686 - val_accuracy: 0.0000e+00\n",
      "Epoch 8255/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 22.3884 - accuracy: 0.0156 - val_loss: 135.6438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0118 - accuracy: 0.0000e+00 - val_loss: 130.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8257/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2180 - accuracy: 0.0156 - val_loss: 124.9416 - val_accuracy: 0.0000e+00\n",
      "Epoch 8258/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 23.1661 - accuracy: 0.0156 - val_loss: 122.9641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1803 - accuracy: 0.0000e+00 - val_loss: 124.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 8260/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.0901 - accuracy: 0.0312 - val_loss: 122.5712 - val_accuracy: 0.0588\n",
      "Epoch 8261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9005 - accuracy: 0.0000e+00 - val_loss: 120.9287 - val_accuracy: 0.0588\n",
      "Epoch 8262/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.5849 - accuracy: 0.0156 - val_loss: 123.2206 - val_accuracy: 0.0588\n",
      "Epoch 8263/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 30.9678 - accuracy: 0.0000e+00 - val_loss: 125.3510 - val_accuracy: 0.0000e+00\n",
      "Epoch 8264/10000\n",
      "64/64 [==============================] - 0s 76us/step - loss: 43.5665 - accuracy: 0.0000e+00 - val_loss: 129.0246 - val_accuracy: 0.0000e+00\n",
      "Epoch 8265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8203 - accuracy: 0.0156 - val_loss: 138.1008 - val_accuracy: 0.0000e+00\n",
      "Epoch 8266/10000\n",
      "64/64 [==============================] - 0s 91us/step - loss: 22.7728 - accuracy: 0.0000e+00 - val_loss: 131.5202 - val_accuracy: 0.0000e+00\n",
      "Epoch 8267/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5017 - accuracy: 0.0000e+00 - val_loss: 124.7472 - val_accuracy: 0.0000e+00\n",
      "Epoch 8268/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 38.4310 - accuracy: 0.0000e+00 - val_loss: 122.2801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1251 - accuracy: 0.0156 - val_loss: 123.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8270/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4135 - accuracy: 0.0469 - val_loss: 129.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 8271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6181 - accuracy: 0.0156 - val_loss: 137.2623 - val_accuracy: 0.0000e+00\n",
      "Epoch 8272/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 24.4044 - accuracy: 0.0156 - val_loss: 147.3434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8145 - accuracy: 0.0000e+00 - val_loss: 148.5281 - val_accuracy: 0.0000e+00\n",
      "Epoch 8274/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1011 - accuracy: 0.0000e+00 - val_loss: 145.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 8275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3916 - accuracy: 0.0156 - val_loss: 138.4772 - val_accuracy: 0.0000e+00\n",
      "Epoch 8276/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 21.2132 - accuracy: 0.0156 - val_loss: 135.0938 - val_accuracy: 0.0000e+00\n",
      "Epoch 8277/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3044 - accuracy: 0.0000e+00 - val_loss: 136.9909 - val_accuracy: 0.0000e+00\n",
      "Epoch 8278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6731 - accuracy: 0.0156 - val_loss: 138.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8279/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9345 - accuracy: 0.0000e+00 - val_loss: 134.0334 - val_accuracy: 0.0588\n",
      "Epoch 8280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6743 - accuracy: 0.0156 - val_loss: 127.0599 - val_accuracy: 0.1176\n",
      "Epoch 8281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1193 - accuracy: 0.0156 - val_loss: 120.0609 - val_accuracy: 0.1176\n",
      "Epoch 8282/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6396 - accuracy: 0.0000e+00 - val_loss: 113.4569 - val_accuracy: 0.0588\n",
      "Epoch 8283/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4193 - accuracy: 0.0312 - val_loss: 112.3563 - val_accuracy: 0.0000e+00\n",
      "Epoch 8284/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 50.4844 - accuracy: 0.0000e+00 - val_loss: 126.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8285/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7803 - accuracy: 0.0156 - val_loss: 132.4483 - val_accuracy: 0.0588\n",
      "Epoch 8286/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 31.8278 - accuracy: 0.0000e+00 - val_loss: 133.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 8287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.8661 - accuracy: 0.0312 - val_loss: 133.6591 - val_accuracy: 0.0000e+00\n",
      "Epoch 8288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7688 - accuracy: 0.0000e+00 - val_loss: 134.7951 - val_accuracy: 0.0000e+00\n",
      "Epoch 8289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6783 - accuracy: 0.0000e+00 - val_loss: 135.9989 - val_accuracy: 0.0000e+00\n",
      "Epoch 8290/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6971 - accuracy: 0.0156 - val_loss: 135.6490 - val_accuracy: 0.0000e+00\n",
      "Epoch 8291/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2434 - accuracy: 0.0000e+00 - val_loss: 133.8580 - val_accuracy: 0.0000e+00\n",
      "Epoch 8292/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7556 - accuracy: 0.0156 - val_loss: 129.6349 - val_accuracy: 0.0000e+00\n",
      "Epoch 8293/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2855 - accuracy: 0.0156 - val_loss: 125.9734 - val_accuracy: 0.0000e+00\n",
      "Epoch 8294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7445 - accuracy: 0.0156 - val_loss: 123.6308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8295/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6982 - accuracy: 0.0000e+00 - val_loss: 124.8835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8296/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4276 - accuracy: 0.0156 - val_loss: 131.2554 - val_accuracy: 0.0588\n",
      "Epoch 8297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6185 - accuracy: 0.0156 - val_loss: 137.0592 - val_accuracy: 0.0588\n",
      "Epoch 8298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0278 - accuracy: 0.0312 - val_loss: 137.4549 - val_accuracy: 0.0000e+00\n",
      "Epoch 8299/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.9591 - accuracy: 0.0000e+00 - val_loss: 134.8768 - val_accuracy: 0.0000e+00\n",
      "Epoch 8300/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 30.1112 - accuracy: 0.0156 - val_loss: 132.0814 - val_accuracy: 0.0000e+00\n",
      "Epoch 8301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5739 - accuracy: 0.0156 - val_loss: 125.3261 - val_accuracy: 0.0000e+00\n",
      "Epoch 8302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8068 - accuracy: 0.0156 - val_loss: 123.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 8303/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.7167 - accuracy: 0.0000e+00 - val_loss: 129.6683 - val_accuracy: 0.0000e+00\n",
      "Epoch 8304/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7949 - accuracy: 0.0000e+00 - val_loss: 134.0136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8305/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 31.6003 - accuracy: 0.0156 - val_loss: 134.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 8306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9751 - accuracy: 0.0000e+00 - val_loss: 141.4308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6467 - accuracy: 0.0000e+00 - val_loss: 144.2601 - val_accuracy: 0.0588\n",
      "Epoch 8308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6690 - accuracy: 0.0000e+00 - val_loss: 146.9203 - val_accuracy: 0.0588\n",
      "Epoch 8309/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.6967 - accuracy: 0.0156 - val_loss: 144.6562 - val_accuracy: 0.0588\n",
      "Epoch 8310/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.9691 - accuracy: 0.0000e+00 - val_loss: 140.1926 - val_accuracy: 0.0588\n",
      "Epoch 8311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5001 - accuracy: 0.0000e+00 - val_loss: 133.9948 - val_accuracy: 0.0588\n",
      "Epoch 8312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2872 - accuracy: 0.0156 - val_loss: 134.9868 - val_accuracy: 0.0588\n",
      "Epoch 8313/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0970 - accuracy: 0.0312 - val_loss: 140.9217 - val_accuracy: 0.0588\n",
      "Epoch 8314/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 21.9085 - accuracy: 0.0000e+00 - val_loss: 148.0471 - val_accuracy: 0.0588\n",
      "Epoch 8315/10000\n",
      "64/64 [==============================] - 0s 120us/step - loss: 25.3732 - accuracy: 0.0000e+00 - val_loss: 151.0943 - val_accuracy: 0.0588\n",
      "Epoch 8316/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.6518 - accuracy: 0.0156 - val_loss: 152.6766 - val_accuracy: 0.0588\n",
      "Epoch 8317/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 35.2358 - accuracy: 0.0156 - val_loss: 147.1584 - val_accuracy: 0.0588\n",
      "Epoch 8318/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0082 - accuracy: 0.0000e+00 - val_loss: 142.3229 - val_accuracy: 0.0000e+00\n",
      "Epoch 8319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0225 - accuracy: 0.0156 - val_loss: 131.7352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8320/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4200 - accuracy: 0.0156 - val_loss: 131.3104 - val_accuracy: 0.0000e+00\n",
      "Epoch 8321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7067 - accuracy: 0.0000e+00 - val_loss: 133.9470 - val_accuracy: 0.0000e+00\n",
      "Epoch 8322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7013 - accuracy: 0.0000e+00 - val_loss: 136.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8323/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5182 - accuracy: 0.0000e+00 - val_loss: 135.2443 - val_accuracy: 0.0000e+00\n",
      "Epoch 8324/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5022 - accuracy: 0.0000e+00 - val_loss: 130.3238 - val_accuracy: 0.0000e+00\n",
      "Epoch 8325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9556 - accuracy: 0.0000e+00 - val_loss: 125.4251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8326/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1288 - accuracy: 0.0312 - val_loss: 123.4407 - val_accuracy: 0.0000e+00\n",
      "Epoch 8327/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 30.0061 - accuracy: 0.0156 - val_loss: 125.1369 - val_accuracy: 0.0000e+00\n",
      "Epoch 8328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.4079 - accuracy: 0.0000e+00 - val_loss: 127.2494 - val_accuracy: 0.0588\n",
      "Epoch 8329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1768 - accuracy: 0.0000e+00 - val_loss: 132.4237 - val_accuracy: 0.0000e+00\n",
      "Epoch 8330/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4580 - accuracy: 0.0000e+00 - val_loss: 132.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 8331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.0953 - accuracy: 0.0156 - val_loss: 129.6478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8332/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1382 - accuracy: 0.0312 - val_loss: 118.2100 - val_accuracy: 0.0000e+00\n",
      "Epoch 8333/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6969 - accuracy: 0.0156 - val_loss: 116.3074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8334/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6876 - accuracy: 0.0156 - val_loss: 115.3918 - val_accuracy: 0.0588\n",
      "Epoch 8335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.7305 - accuracy: 0.0312 - val_loss: 119.3998 - val_accuracy: 0.0588\n",
      "Epoch 8336/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1400 - accuracy: 0.0000e+00 - val_loss: 120.7653 - val_accuracy: 0.0000e+00\n",
      "Epoch 8337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5378 - accuracy: 0.0156 - val_loss: 125.2213 - val_accuracy: 0.0000e+00\n",
      "Epoch 8338/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 25.5045 - accuracy: 0.0000e+00 - val_loss: 126.8967 - val_accuracy: 0.0000e+00\n",
      "Epoch 8339/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.5016 - accuracy: 0.0156 - val_loss: 134.4140 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8340/10000\n",
      "64/64 [==============================] - 0s 88us/step - loss: 29.2488 - accuracy: 0.0156 - val_loss: 134.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 8341/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5142 - accuracy: 0.0000e+00 - val_loss: 134.5444 - val_accuracy: 0.0588\n",
      "Epoch 8342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9201 - accuracy: 0.0156 - val_loss: 136.4936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9346 - accuracy: 0.0000e+00 - val_loss: 136.6522 - val_accuracy: 0.0588\n",
      "Epoch 8344/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1007 - accuracy: 0.0156 - val_loss: 133.5279 - val_accuracy: 0.1176\n",
      "Epoch 8345/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 25.3550 - accuracy: 0.0000e+00 - val_loss: 130.0521 - val_accuracy: 0.1176\n",
      "Epoch 8346/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2870 - accuracy: 0.0312 - val_loss: 125.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 8347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0669 - accuracy: 0.0156 - val_loss: 128.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8348/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5126 - accuracy: 0.0156 - val_loss: 127.2108 - val_accuracy: 0.0000e+00\n",
      "Epoch 8349/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7101 - accuracy: 0.0000e+00 - val_loss: 128.3931 - val_accuracy: 0.0000e+00\n",
      "Epoch 8350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8682 - accuracy: 0.0156 - val_loss: 135.0911 - val_accuracy: 0.0000e+00\n",
      "Epoch 8351/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 29.7596 - accuracy: 0.031 - 0s 62us/step - loss: 23.6664 - accuracy: 0.0156 - val_loss: 141.8448 - val_accuracy: 0.0000e+00\n",
      "Epoch 8352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5298 - accuracy: 0.0156 - val_loss: 138.8520 - val_accuracy: 0.0588\n",
      "Epoch 8353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4754 - accuracy: 0.0000e+00 - val_loss: 129.4762 - val_accuracy: 0.0588\n",
      "Epoch 8354/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5853 - accuracy: 0.0156 - val_loss: 122.1749 - val_accuracy: 0.0588\n",
      "Epoch 8355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.9036 - accuracy: 0.0312 - val_loss: 123.4582 - val_accuracy: 0.0588\n",
      "Epoch 8356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6016 - accuracy: 0.0156 - val_loss: 135.1317 - val_accuracy: 0.0000e+00\n",
      "Epoch 8357/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.9336 - accuracy: 0.0312 - val_loss: 132.4841 - val_accuracy: 0.0000e+00\n",
      "Epoch 8358/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9600 - accuracy: 0.0156 - val_loss: 122.2609 - val_accuracy: 0.0588\n",
      "Epoch 8359/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4377 - accuracy: 0.0156 - val_loss: 113.9007 - val_accuracy: 0.0588\n",
      "Epoch 8360/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.7265 - accuracy: 0.0156 - val_loss: 105.8390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8361/10000\n",
      "64/64 [==============================] - 0s 119us/step - loss: 26.8772 - accuracy: 0.0000e+00 - val_loss: 104.0629 - val_accuracy: 0.0588\n",
      "Epoch 8362/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.1373 - accuracy: 0.0156 - val_loss: 104.0481 - val_accuracy: 0.0588\n",
      "Epoch 8363/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.7790 - accuracy: 0.0312 - val_loss: 100.7368 - val_accuracy: 0.0000e+00\n",
      "Epoch 8364/10000\n",
      "64/64 [==============================] - 0s 132us/step - loss: 24.1145 - accuracy: 0.0156 - val_loss: 99.9373 - val_accuracy: 0.0000e+00\n",
      "Epoch 8365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5976 - accuracy: 0.0156 - val_loss: 103.1873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8366/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1254 - accuracy: 0.0000e+00 - val_loss: 109.7180 - val_accuracy: 0.0000e+00\n",
      "Epoch 8367/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7353 - accuracy: 0.0312 - val_loss: 120.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 8368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0386 - accuracy: 0.0000e+00 - val_loss: 129.2394 - val_accuracy: 0.0000e+00\n",
      "Epoch 8369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9684 - accuracy: 0.0000e+00 - val_loss: 134.6049 - val_accuracy: 0.0000e+00\n",
      "Epoch 8370/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 32.7949 - accuracy: 0.0000e+00 - val_loss: 135.1669 - val_accuracy: 0.0000e+00\n",
      "Epoch 8371/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4037 - accuracy: 0.0000e+00 - val_loss: 129.0761 - val_accuracy: 0.0588\n",
      "Epoch 8372/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7210 - accuracy: 0.0156 - val_loss: 114.5990 - val_accuracy: 0.0588\n",
      "Epoch 8373/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 30.0909 - accuracy: 0.0156 - val_loss: 103.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 8374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3763 - accuracy: 0.0312 - val_loss: 111.0512 - val_accuracy: 0.0588\n",
      "Epoch 8375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2699 - accuracy: 0.0156 - val_loss: 126.1273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8376/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.6932 - accuracy: 0.0000e+00 - val_loss: 132.2475 - val_accuracy: 0.0000e+00\n",
      "Epoch 8377/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1507 - accuracy: 0.0000e+00 - val_loss: 129.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 8378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.4214 - accuracy: 0.0000e+00 - val_loss: 123.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 8379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5811 - accuracy: 0.0000e+00 - val_loss: 117.6255 - val_accuracy: 0.0588\n",
      "Epoch 8380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9070 - accuracy: 0.0000e+00 - val_loss: 115.6555 - val_accuracy: 0.0588\n",
      "Epoch 8381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2439 - accuracy: 0.0000e+00 - val_loss: 116.9468 - val_accuracy: 0.0588\n",
      "Epoch 8382/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 24.3449 - accuracy: 0.0000e+00 - val_loss: 126.7488 - val_accuracy: 0.0588\n",
      "Epoch 8383/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0531 - accuracy: 0.0000e+00 - val_loss: 135.1676 - val_accuracy: 0.0588\n",
      "Epoch 8384/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2228 - accuracy: 0.0156 - val_loss: 136.2586 - val_accuracy: 0.0588\n",
      "Epoch 8385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1944 - accuracy: 0.0000e+00 - val_loss: 135.7839 - val_accuracy: 0.0588\n",
      "Epoch 8386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5537 - accuracy: 0.0156 - val_loss: 141.2764 - val_accuracy: 0.0588\n",
      "Epoch 8387/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9399 - accuracy: 0.0312 - val_loss: 138.6645 - val_accuracy: 0.0000e+00\n",
      "Epoch 8388/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9322 - accuracy: 0.0156 - val_loss: 134.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8389/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 19.3936 - accuracy: 0.0000e+00 - val_loss: 128.8813 - val_accuracy: 0.0000e+00\n",
      "Epoch 8390/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0613 - accuracy: 0.0156 - val_loss: 127.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5215 - accuracy: 0.0156 - val_loss: 129.5474 - val_accuracy: 0.0000e+00\n",
      "Epoch 8392/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 15.5082 - accuracy: 0.0156 - val_loss: 134.8898 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8393/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 28.4920 - accuracy: 0.0000e+00 - val_loss: 135.5686 - val_accuracy: 0.0000e+00\n",
      "Epoch 8394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8325 - accuracy: 0.0000e+00 - val_loss: 135.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8395/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3399 - accuracy: 0.0000e+00 - val_loss: 135.4798 - val_accuracy: 0.0000e+00\n",
      "Epoch 8396/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 11.1325 - accuracy: 0.0156 - val_loss: 133.1414 - val_accuracy: 0.0000e+00\n",
      "Epoch 8397/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.4296 - accuracy: 0.0156 - val_loss: 130.4121 - val_accuracy: 0.0000e+00\n",
      "Epoch 8398/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 34.9553 - accuracy: 0.0156 - val_loss: 129.8371 - val_accuracy: 0.0000e+00\n",
      "Epoch 8399/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 29.4201 - accuracy: 0.0000e+00 - val_loss: 130.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 8400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6787 - accuracy: 0.0156 - val_loss: 130.5138 - val_accuracy: 0.0000e+00\n",
      "Epoch 8401/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.3637 - accuracy: 0.0156 - val_loss: 126.6936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8402/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 19.7300 - accuracy: 0.0000e+00 - val_loss: 122.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 8403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4142 - accuracy: 0.0000e+00 - val_loss: 123.7275 - val_accuracy: 0.0000e+00\n",
      "Epoch 8404/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3108 - accuracy: 0.0000e+00 - val_loss: 122.9437 - val_accuracy: 0.0000e+00\n",
      "Epoch 8405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3578 - accuracy: 0.0000e+00 - val_loss: 120.5109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3250 - accuracy: 0.0000e+00 - val_loss: 119.9821 - val_accuracy: 0.0000e+00\n",
      "Epoch 8407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0880 - accuracy: 0.0000e+00 - val_loss: 124.5423 - val_accuracy: 0.0000e+00\n",
      "Epoch 8408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5883 - accuracy: 0.0000e+00 - val_loss: 122.5565 - val_accuracy: 0.0000e+00\n",
      "Epoch 8409/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4939 - accuracy: 0.0312 - val_loss: 120.4609 - val_accuracy: 0.0588\n",
      "Epoch 8410/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8182 - accuracy: 0.0156 - val_loss: 123.0713 - val_accuracy: 0.0588\n",
      "Epoch 8411/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 18.8442 - accuracy: 0.0156 - val_loss: 126.0203 - val_accuracy: 0.0000e+00\n",
      "Epoch 8412/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.4662 - accuracy: 0.0156 - val_loss: 133.0777 - val_accuracy: 0.0588\n",
      "Epoch 8413/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1833 - accuracy: 0.0000e+00 - val_loss: 144.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 8414/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 28.3571 - accuracy: 0.0000e+00 - val_loss: 147.6112 - val_accuracy: 0.0588\n",
      "Epoch 8415/10000\n",
      "64/64 [==============================] - 0s 477us/step - loss: 29.1587 - accuracy: 0.0312 - val_loss: 151.0843 - val_accuracy: 0.0588\n",
      "Epoch 8416/10000\n",
      "64/64 [==============================] - 0s 375us/step - loss: 24.8909 - accuracy: 0.0000e+00 - val_loss: 151.2998 - val_accuracy: 0.0588\n",
      "Epoch 8417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.9319 - accuracy: 0.0156 - val_loss: 145.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 8418/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.5081 - accuracy: 0.0312 - val_loss: 133.7799 - val_accuracy: 0.0000e+00\n",
      "Epoch 8419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.5444 - accuracy: 0.0156 - val_loss: 130.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 8420/10000\n",
      "64/64 [==============================] - 0s 170us/step - loss: 29.3943 - accuracy: 0.0156 - val_loss: 128.6964 - val_accuracy: 0.0000e+00\n",
      "Epoch 8421/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4690 - accuracy: 0.0156 - val_loss: 125.4088 - val_accuracy: 0.0588\n",
      "Epoch 8422/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 28.4507 - accuracy: 0.0000e+00 - val_loss: 123.6058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5356 - accuracy: 0.0156 - val_loss: 121.4250 - val_accuracy: 0.0000e+00\n",
      "Epoch 8424/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2147 - accuracy: 0.0312 - val_loss: 121.5346 - val_accuracy: 0.0588\n",
      "Epoch 8425/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 19.9044 - accuracy: 0.0000e+00 - val_loss: 126.2662 - val_accuracy: 0.0000e+00\n",
      "Epoch 8426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2278 - accuracy: 0.0000e+00 - val_loss: 138.6629 - val_accuracy: 0.0000e+00\n",
      "Epoch 8427/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 18.2719 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 32.7255 - accuracy: 0.0000e+00 - val_loss: 145.6378 - val_accuracy: 0.0000e+00\n",
      "Epoch 8428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3827 - accuracy: 0.0000e+00 - val_loss: 144.1520 - val_accuracy: 0.0000e+00\n",
      "Epoch 8429/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7019 - accuracy: 0.0312 - val_loss: 134.8864 - val_accuracy: 0.0000e+00\n",
      "Epoch 8430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8186 - accuracy: 0.0156 - val_loss: 120.9584 - val_accuracy: 0.0000e+00\n",
      "Epoch 8431/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 21.3320 - accuracy: 0.0000e+00 - val_loss: 111.1309 - val_accuracy: 0.0000e+00\n",
      "Epoch 8432/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0292 - accuracy: 0.0000e+00 - val_loss: 114.6748 - val_accuracy: 0.0000e+00\n",
      "Epoch 8433/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.8669 - accuracy: 0.0156 - val_loss: 129.9834 - val_accuracy: 0.0588\n",
      "Epoch 8434/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1976 - accuracy: 0.0156 - val_loss: 139.1856 - val_accuracy: 0.0588\n",
      "Epoch 8435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8647 - accuracy: 0.0156 - val_loss: 138.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 8436/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.2747 - accuracy: 0.0156 - val_loss: 132.0652 - val_accuracy: 0.0000e+00\n",
      "Epoch 8437/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6119 - accuracy: 0.0156 - val_loss: 133.3292 - val_accuracy: 0.0000e+00\n",
      "Epoch 8438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.8025 - accuracy: 0.0625 - val_loss: 138.7827 - val_accuracy: 0.0000e+00\n",
      "Epoch 8439/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5117 - accuracy: 0.0156 - val_loss: 143.6418 - val_accuracy: 0.0000e+00\n",
      "Epoch 8440/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 37.0701 - accuracy: 0.0000e+00 - val_loss: 143.3964 - val_accuracy: 0.0000e+00\n",
      "Epoch 8441/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 21.2535 - accuracy: 0.0156 - val_loss: 145.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 8442/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 36.1746 - accuracy: 0.0000e+00 - val_loss: 136.4511 - val_accuracy: 0.0000e+00\n",
      "Epoch 8443/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0294 - accuracy: 0.0000e+00 - val_loss: 128.8541 - val_accuracy: 0.0000e+00\n",
      "Epoch 8444/10000\n",
      "64/64 [==============================] - 0s 70us/step - loss: 20.5040 - accuracy: 0.0156 - val_loss: 128.8535 - val_accuracy: 0.0588\n",
      "Epoch 8445/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0630 - accuracy: 0.0000e+00 - val_loss: 137.0651 - val_accuracy: 0.0000e+00\n",
      "Epoch 8446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3201 - accuracy: 0.0000e+00 - val_loss: 136.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 8447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.9132 - accuracy: 0.0000e+00 - val_loss: 132.3843 - val_accuracy: 0.0000e+00\n",
      "Epoch 8448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9212 - accuracy: 0.0000e+00 - val_loss: 130.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 8449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7097 - accuracy: 0.0000e+00 - val_loss: 136.6994 - val_accuracy: 0.0588\n",
      "Epoch 8450/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8011 - accuracy: 0.0312 - val_loss: 146.6873 - val_accuracy: 0.1176\n",
      "Epoch 8451/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.1988 - accuracy: 0.0156 - val_loss: 154.0943 - val_accuracy: 0.0000e+00\n",
      "Epoch 8452/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9207 - accuracy: 0.0312 - val_loss: 156.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8453/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 26.3451 - accuracy: 0.0000e+00 - val_loss: 157.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 8454/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0646 - accuracy: 0.0000e+00 - val_loss: 155.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 8455/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9113 - accuracy: 0.0000e+00 - val_loss: 148.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 8456/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5311 - accuracy: 0.0312 - val_loss: 139.4989 - val_accuracy: 0.0000e+00\n",
      "Epoch 8457/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.3059 - accuracy: 0.0000e+00 - val_loss: 132.2153 - val_accuracy: 0.0588\n",
      "Epoch 8458/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3367 - accuracy: 0.0156 - val_loss: 129.9041 - val_accuracy: 0.0588\n",
      "Epoch 8459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5002 - accuracy: 0.0156 - val_loss: 134.0925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1648 - accuracy: 0.0000e+00 - val_loss: 140.4518 - val_accuracy: 0.0000e+00\n",
      "Epoch 8461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0229 - accuracy: 0.0156 - val_loss: 139.4382 - val_accuracy: 0.0588\n",
      "Epoch 8462/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.3943 - accuracy: 0.0000e+00 - val_loss: 129.8354 - val_accuracy: 0.0588\n",
      "Epoch 8463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0338 - accuracy: 0.0000e+00 - val_loss: 120.7807 - val_accuracy: 0.0000e+00\n",
      "Epoch 8464/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2547 - accuracy: 0.0312 - val_loss: 120.8325 - val_accuracy: 0.0000e+00\n",
      "Epoch 8465/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7877 - accuracy: 0.0000e+00 - val_loss: 125.8036 - val_accuracy: 0.0588\n",
      "Epoch 8466/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7804 - accuracy: 0.0156 - val_loss: 132.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 8467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7928 - accuracy: 0.0312 - val_loss: 139.6425 - val_accuracy: 0.0000e+00\n",
      "Epoch 8468/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7166 - accuracy: 0.0156 - val_loss: 149.5081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8469/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.3596 - accuracy: 0.0156 - val_loss: 149.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 8470/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.6005 - accuracy: 0.0156 - val_loss: 142.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0013 - accuracy: 0.0469 - val_loss: 136.3541 - val_accuracy: 0.0000e+00\n",
      "Epoch 8472/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 27.0797 - accuracy: 0.0156 - val_loss: 133.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 8473/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.2199 - accuracy: 0.0000e+00 - val_loss: 126.8838 - val_accuracy: 0.0000e+00\n",
      "Epoch 8474/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.8801 - accuracy: 0.0156 - val_loss: 120.3996 - val_accuracy: 0.0000e+00\n",
      "Epoch 8475/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 15.8593 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 25.5756 - accuracy: 0.0156 - val_loss: 117.0903 - val_accuracy: 0.0588\n",
      "Epoch 8476/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.7639 - accuracy: 0.0000e+00 - val_loss: 123.6816 - val_accuracy: 0.0588\n",
      "Epoch 8477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3391 - accuracy: 0.0000e+00 - val_loss: 140.1676 - val_accuracy: 0.0000e+00\n",
      "Epoch 8478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0778 - accuracy: 0.0000e+00 - val_loss: 149.6568 - val_accuracy: 0.0000e+00\n",
      "Epoch 8479/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.5313 - accuracy: 0.0000e+00 - val_loss: 143.1395 - val_accuracy: 0.0000e+00\n",
      "Epoch 8480/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 25.0434 - accuracy: 0.0156 - val_loss: 134.2882 - val_accuracy: 0.0000e+00\n",
      "Epoch 8481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3631 - accuracy: 0.0156 - val_loss: 133.1675 - val_accuracy: 0.0000e+00\n",
      "Epoch 8482/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.5871 - accuracy: 0.0156 - val_loss: 140.7979 - val_accuracy: 0.0588\n",
      "Epoch 8483/10000\n",
      "64/64 [==============================] - 0s 212us/step - loss: 30.7372 - accuracy: 0.0000e+00 - val_loss: 144.6910 - val_accuracy: 0.0000e+00\n",
      "Epoch 8484/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.2193 - accuracy: 0.0000e+00 - val_loss: 141.3229 - val_accuracy: 0.0588\n",
      "Epoch 8485/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 34.7517 - accuracy: 0.0000e+00 - val_loss: 135.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 8486/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.8446 - accuracy: 0.0000e+00 - val_loss: 131.9332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.7538 - accuracy: 0.0000e+00 - val_loss: 128.9895 - val_accuracy: 0.0000e+00\n",
      "Epoch 8488/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6073 - accuracy: 0.0000e+00 - val_loss: 122.7222 - val_accuracy: 0.0000e+00\n",
      "Epoch 8489/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.5617 - accuracy: 0.0000e+00 - val_loss: 122.0771 - val_accuracy: 0.0000e+00\n",
      "Epoch 8490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1819 - accuracy: 0.0000e+00 - val_loss: 131.2930 - val_accuracy: 0.0000e+00\n",
      "Epoch 8491/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4535 - accuracy: 0.0000e+00 - val_loss: 140.6105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9185 - accuracy: 0.0156 - val_loss: 139.9179 - val_accuracy: 0.0588\n",
      "Epoch 8493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6077 - accuracy: 0.0156 - val_loss: 130.4273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8494/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 42.5558 - accuracy: 0.0156 - val_loss: 129.5628 - val_accuracy: 0.0588\n",
      "Epoch 8495/10000\n",
      "64/64 [==============================] - 0s 201us/step - loss: 21.9112 - accuracy: 0.0156 - val_loss: 131.5475 - val_accuracy: 0.0000e+00\n",
      "Epoch 8496/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 28.1128 - accuracy: 0.0000e+00 - val_loss: 132.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8497/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/step - loss: 27.9848 - accuracy: 0.0156 - val_loss: 133.8027 - val_accuracy: 0.0588\n",
      "Epoch 8498/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.7265 - accuracy: 0.0156 - val_loss: 134.6494 - val_accuracy: 0.0588\n",
      "Epoch 8499/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.3004 - accuracy: 0.0000e+00 - val_loss: 130.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 8500/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8469 - accuracy: 0.0156 - val_loss: 119.2444 - val_accuracy: 0.0000e+00\n",
      "Epoch 8501/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5198 - accuracy: 0.0000e+00 - val_loss: 111.1256 - val_accuracy: 0.0000e+00\n",
      "Epoch 8502/10000\n",
      "64/64 [==============================] - 0s 198us/step - loss: 35.8221 - accuracy: 0.0156 - val_loss: 112.1955 - val_accuracy: 0.0000e+00\n",
      "Epoch 8503/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 13.5095 - accuracy: 0.0156 - val_loss: 119.9064 - val_accuracy: 0.0000e+00\n",
      "Epoch 8504/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 25.4848 - accuracy: 0.0156 - val_loss: 124.7833 - val_accuracy: 0.0000e+00\n",
      "Epoch 8505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4764 - accuracy: 0.0000e+00 - val_loss: 118.6273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1837 - accuracy: 0.0156 - val_loss: 110.7650 - val_accuracy: 0.0000e+00\n",
      "Epoch 8507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.0731 - accuracy: 0.0000e+00 - val_loss: 112.8332 - val_accuracy: 0.0000e+00\n",
      "Epoch 8508/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4652 - accuracy: 0.0156 - val_loss: 120.2784 - val_accuracy: 0.0000e+00\n",
      "Epoch 8509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.3390 - accuracy: 0.0000e+00 - val_loss: 122.2912 - val_accuracy: 0.0000e+00\n",
      "Epoch 8510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.9229 - accuracy: 0.0156 - val_loss: 119.9673 - val_accuracy: 0.0000e+00\n",
      "Epoch 8511/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 23.9400 - accuracy: 0.0000e+00 - val_loss: 125.0230 - val_accuracy: 0.0588\n",
      "Epoch 8512/10000\n",
      "64/64 [==============================] - 0s 171us/step - loss: 20.0503 - accuracy: 0.0000e+00 - val_loss: 130.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8513/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.1240 - accuracy: 0.0000e+00 - val_loss: 133.1808 - val_accuracy: 0.0588\n",
      "Epoch 8514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5053 - accuracy: 0.0000e+00 - val_loss: 133.8731 - val_accuracy: 0.0000e+00\n",
      "Epoch 8515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.1516 - accuracy: 0.0000e+00 - val_loss: 131.2835 - val_accuracy: 0.0000e+00\n",
      "Epoch 8516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0984 - accuracy: 0.0000e+00 - val_loss: 135.4060 - val_accuracy: 0.0000e+00\n",
      "Epoch 8517/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 37.9252 - accuracy: 0.0000e+00 - val_loss: 149.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 8518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4558 - accuracy: 0.0000e+00 - val_loss: 159.5164 - val_accuracy: 0.0000e+00\n",
      "Epoch 8519/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 28.9109 - accuracy: 0.0000e+00 - val_loss: 157.6199 - val_accuracy: 0.0000e+00\n",
      "Epoch 8520/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 32.1227 - accuracy: 0.0156 - val_loss: 147.0440 - val_accuracy: 0.0000e+00\n",
      "Epoch 8521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9141 - accuracy: 0.0000e+00 - val_loss: 136.1498 - val_accuracy: 0.0588\n",
      "Epoch 8522/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 36.2503 - accuracy: 0.0625 - val_loss: 133.2535 - val_accuracy: 0.0588\n",
      "Epoch 8523/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 20.7698 - accuracy: 0.0000e+00 - val_loss: 133.1210 - val_accuracy: 0.0588\n",
      "Epoch 8524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 38.5059 - accuracy: 0.0156 - val_loss: 137.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 8525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0933 - accuracy: 0.0000e+00 - val_loss: 145.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8526/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4508 - accuracy: 0.0312 - val_loss: 146.9997 - val_accuracy: 0.0000e+00\n",
      "Epoch 8527/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 24.9419 - accuracy: 0.0000e+00 - val_loss: 142.2446 - val_accuracy: 0.0000e+00\n",
      "Epoch 8528/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.1746 - accuracy: 0.0312 - val_loss: 132.0279 - val_accuracy: 0.0000e+00\n",
      "Epoch 8529/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2733 - accuracy: 0.0000e+00 - val_loss: 120.7941 - val_accuracy: 0.0000e+00\n",
      "Epoch 8530/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 21.6585 - accuracy: 0.0156 - val_loss: 113.2213 - val_accuracy: 0.0588\n",
      "Epoch 8531/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.2492 - accuracy: 0.0156 - val_loss: 123.7102 - val_accuracy: 0.0588\n",
      "Epoch 8532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3383 - accuracy: 0.0312 - val_loss: 142.5366 - val_accuracy: 0.0000e+00\n",
      "Epoch 8533/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.9447 - accuracy: 0.0000e+00 - val_loss: 153.6822 - val_accuracy: 0.0000e+00\n",
      "Epoch 8534/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3889 - accuracy: 0.0000e+00 - val_loss: 156.3328 - val_accuracy: 0.0588\n",
      "Epoch 8535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4775 - accuracy: 0.0000e+00 - val_loss: 151.2122 - val_accuracy: 0.0000e+00\n",
      "Epoch 8536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3236 - accuracy: 0.0000e+00 - val_loss: 141.5297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8492 - accuracy: 0.0156 - val_loss: 126.0437 - val_accuracy: 0.0588\n",
      "Epoch 8538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4241 - accuracy: 0.0312 - val_loss: 119.7297 - val_accuracy: 0.0588\n",
      "Epoch 8539/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.3790 - accuracy: 0.0156 - val_loss: 119.1422 - val_accuracy: 0.0000e+00\n",
      "Epoch 8540/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.7079 - accuracy: 0.0312 - val_loss: 135.7156 - val_accuracy: 0.0000e+00\n",
      "Epoch 8541/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1655 - accuracy: 0.0000e+00 - val_loss: 147.3009 - val_accuracy: 0.0000e+00\n",
      "Epoch 8542/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.1838 - accuracy: 0.0156 - val_loss: 150.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.5283 - accuracy: 0.0000e+00 - val_loss: 145.3720 - val_accuracy: 0.0000e+00\n",
      "Epoch 8544/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7143 - accuracy: 0.0156 - val_loss: 143.1974 - val_accuracy: 0.0000e+00\n",
      "Epoch 8545/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.8520 - accuracy: 0.0000e+00 - val_loss: 137.2387 - val_accuracy: 0.0000e+00\n",
      "Epoch 8546/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 24.2876 - accuracy: 0.0156 - val_loss: 134.9426 - val_accuracy: 0.0000e+00\n",
      "Epoch 8547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5209 - accuracy: 0.0312 - val_loss: 135.2168 - val_accuracy: 0.0000e+00\n",
      "Epoch 8548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0385 - accuracy: 0.0000e+00 - val_loss: 141.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 8549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3353 - accuracy: 0.0000e+00 - val_loss: 138.4386 - val_accuracy: 0.0000e+00\n",
      "Epoch 8550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7517 - accuracy: 0.0000e+00 - val_loss: 134.6033 - val_accuracy: 0.0588\n",
      "Epoch 8551/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 22.3305 - accuracy: 0.0156 - val_loss: 130.0751 - val_accuracy: 0.0588\n",
      "Epoch 8552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.6799 - accuracy: 0.0000e+00 - val_loss: 129.6581 - val_accuracy: 0.0000e+00\n",
      "Epoch 8553/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 21.5306 - accuracy: 0.0312 - val_loss: 134.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 8554/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9107 - accuracy: 0.0156 - val_loss: 134.0562 - val_accuracy: 0.0000e+00\n",
      "Epoch 8555/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 24.8108 - accuracy: 0.0000e+00 - val_loss: 134.9852 - val_accuracy: 0.0000e+00\n",
      "Epoch 8556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6109 - accuracy: 0.0000e+00 - val_loss: 135.9120 - val_accuracy: 0.0588\n",
      "Epoch 8557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6391 - accuracy: 0.0156 - val_loss: 137.8425 - val_accuracy: 0.0588\n",
      "Epoch 8558/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.6362 - accuracy: 0.0156 - val_loss: 139.2053 - val_accuracy: 0.0588\n",
      "Epoch 8559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0105 - accuracy: 0.0000e+00 - val_loss: 142.0268 - val_accuracy: 0.0000e+00\n",
      "Epoch 8560/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9594 - accuracy: 0.0000e+00 - val_loss: 139.4691 - val_accuracy: 0.0000e+00\n",
      "Epoch 8561/10000\n",
      "64/64 [==============================] - 0s 156us/step - loss: 30.5507 - accuracy: 0.0156 - val_loss: 142.0816 - val_accuracy: 0.0000e+00\n",
      "Epoch 8562/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5382 - accuracy: 0.0000e+00 - val_loss: 145.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 8563/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2582 - accuracy: 0.0156 - val_loss: 144.4389 - val_accuracy: 0.0000e+00\n",
      "Epoch 8564/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9143 - accuracy: 0.0000e+00 - val_loss: 141.6327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8565/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.0602 - accuracy: 0.0312 - val_loss: 131.5022 - val_accuracy: 0.0000e+00\n",
      "Epoch 8566/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1485 - accuracy: 0.0312 - val_loss: 127.4189 - val_accuracy: 0.0000e+00\n",
      "Epoch 8567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3263 - accuracy: 0.0000e+00 - val_loss: 125.6748 - val_accuracy: 0.0588\n",
      "Epoch 8568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5909 - accuracy: 0.0156 - val_loss: 132.5171 - val_accuracy: 0.0588\n",
      "Epoch 8569/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0851 - accuracy: 0.0000e+00 - val_loss: 135.0329 - val_accuracy: 0.0588\n",
      "Epoch 8570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0804 - accuracy: 0.0000e+00 - val_loss: 133.6737 - val_accuracy: 0.0588\n",
      "Epoch 8571/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.7967 - accuracy: 0.0156 - val_loss: 127.1555 - val_accuracy: 0.0588\n",
      "Epoch 8572/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 23.6265 - accuracy: 0.0000e+00 - val_loss: 117.4742 - val_accuracy: 0.1176\n",
      "Epoch 8573/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2119 - accuracy: 0.0469 - val_loss: 112.6777 - val_accuracy: 0.1176\n",
      "Epoch 8574/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7263 - accuracy: 0.0000e+00 - val_loss: 124.0824 - val_accuracy: 0.0588\n",
      "Epoch 8575/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 28.1138 - accuracy: 0.0156 - val_loss: 145.9511 - val_accuracy: 0.0588\n",
      "Epoch 8576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5675 - accuracy: 0.0156 - val_loss: 153.3263 - val_accuracy: 0.0588\n",
      "Epoch 8577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8956 - accuracy: 0.0000e+00 - val_loss: 157.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 8578/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7959 - accuracy: 0.0312 - val_loss: 149.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6709 - accuracy: 0.0156 - val_loss: 141.3620 - val_accuracy: 0.0000e+00\n",
      "Epoch 8580/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0022 - accuracy: 0.0469 - val_loss: 134.4942 - val_accuracy: 0.0000e+00\n",
      "Epoch 8581/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9043 - accuracy: 0.0156 - val_loss: 136.9785 - val_accuracy: 0.0000e+00\n",
      "Epoch 8582/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7646 - accuracy: 0.0156 - val_loss: 139.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 8583/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 20.4849 - accuracy: 0.0156 - val_loss: 144.9263 - val_accuracy: 0.0000e+00\n",
      "Epoch 8584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3296 - accuracy: 0.0312 - val_loss: 148.7828 - val_accuracy: 0.0000e+00\n",
      "Epoch 8585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.3367 - accuracy: 0.0000e+00 - val_loss: 154.2119 - val_accuracy: 0.0000e+00\n",
      "Epoch 8586/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 44.5461 - accuracy: 0.0156 - val_loss: 152.6131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5467 - accuracy: 0.0000e+00 - val_loss: 148.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 8588/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.1005 - accuracy: 0.0312 - val_loss: 138.9019 - val_accuracy: 0.0000e+00\n",
      "Epoch 8589/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 18.0842 - accuracy: 0.0156 - val_loss: 129.6367 - val_accuracy: 0.0000e+00\n",
      "Epoch 8590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7777 - accuracy: 0.0469 - val_loss: 126.2960 - val_accuracy: 0.0000e+00\n",
      "Epoch 8591/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 22.6644 - accuracy: 0.0156 - val_loss: 127.3098 - val_accuracy: 0.0000e+00\n",
      "Epoch 8592/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2018 - accuracy: 0.0000e+00 - val_loss: 132.5517 - val_accuracy: 0.0000e+00\n",
      "Epoch 8593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2163 - accuracy: 0.0000e+00 - val_loss: 130.1732 - val_accuracy: 0.0000e+00\n",
      "Epoch 8594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.5298 - accuracy: 0.0000e+00 - val_loss: 126.3528 - val_accuracy: 0.0588\n",
      "Epoch 8595/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6290 - accuracy: 0.0000e+00 - val_loss: 123.1542 - val_accuracy: 0.1176\n",
      "Epoch 8596/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9694 - accuracy: 0.0000e+00 - val_loss: 128.8551 - val_accuracy: 0.0588\n",
      "Epoch 8597/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 33.9293 - accuracy: 0.0156 - val_loss: 136.1162 - val_accuracy: 0.0588\n",
      "Epoch 8598/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0231 - accuracy: 0.0000e+00 - val_loss: 141.6163 - val_accuracy: 0.0000e+00\n",
      "Epoch 8599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7327 - accuracy: 0.0000e+00 - val_loss: 139.4685 - val_accuracy: 0.0000e+00\n",
      "Epoch 8600/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5669 - accuracy: 0.0000e+00 - val_loss: 138.1409 - val_accuracy: 0.0000e+00\n",
      "Epoch 8601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4362 - accuracy: 0.0000e+00 - val_loss: 136.1606 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8602/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.8675 - accuracy: 0.0469 - val_loss: 130.1568 - val_accuracy: 0.0588\n",
      "Epoch 8603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4166 - accuracy: 0.0156 - val_loss: 123.2701 - val_accuracy: 0.0588\n",
      "Epoch 8604/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 15.1304 - accuracy: 0.0000e+00 - val_loss: 117.8004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6851 - accuracy: 0.0156 - val_loss: 122.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 8606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.5843 - accuracy: 0.0312 - val_loss: 125.6028 - val_accuracy: 0.0588\n",
      "Epoch 8607/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 23.2577 - accuracy: 0.0000e+00 - val_loss: 129.1986 - val_accuracy: 0.0588\n",
      "Epoch 8608/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2340 - accuracy: 0.0156 - val_loss: 131.0905 - val_accuracy: 0.0000e+00\n",
      "Epoch 8609/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3732 - accuracy: 0.0000e+00 - val_loss: 130.2159 - val_accuracy: 0.0588\n",
      "Epoch 8610/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 30.2065 - accuracy: 0.0000e+00 - val_loss: 130.7097 - val_accuracy: 0.0588\n",
      "Epoch 8611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6297 - accuracy: 0.0156 - val_loss: 133.7406 - val_accuracy: 0.0588\n",
      "Epoch 8612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4038 - accuracy: 0.0000e+00 - val_loss: 140.7644 - val_accuracy: 0.0000e+00\n",
      "Epoch 8613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8115 - accuracy: 0.0000e+00 - val_loss: 145.1700 - val_accuracy: 0.0000e+00\n",
      "Epoch 8614/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7487 - accuracy: 0.0000e+00 - val_loss: 146.7434 - val_accuracy: 0.0000e+00\n",
      "Epoch 8615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0094 - accuracy: 0.0312 - val_loss: 140.6861 - val_accuracy: 0.0588\n",
      "Epoch 8616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5011 - accuracy: 0.0000e+00 - val_loss: 129.2950 - val_accuracy: 0.0588\n",
      "Epoch 8617/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3687 - accuracy: 0.0000e+00 - val_loss: 125.4460 - val_accuracy: 0.0000e+00\n",
      "Epoch 8618/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8835 - accuracy: 0.0156 - val_loss: 124.7813 - val_accuracy: 0.0588\n",
      "Epoch 8619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5883 - accuracy: 0.0469 - val_loss: 130.2189 - val_accuracy: 0.0588\n",
      "Epoch 8620/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9243 - accuracy: 0.0156 - val_loss: 141.5087 - val_accuracy: 0.0000e+00\n",
      "Epoch 8621/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 18.9248 - accuracy: 0.0156 - val_loss: 151.1914 - val_accuracy: 0.0588\n",
      "Epoch 8622/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.1422 - accuracy: 0.0156 - val_loss: 159.5931 - val_accuracy: 0.0588\n",
      "Epoch 8623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6433 - accuracy: 0.0156 - val_loss: 158.1790 - val_accuracy: 0.0588\n",
      "Epoch 8624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6735 - accuracy: 0.0000e+00 - val_loss: 149.2209 - val_accuracy: 0.0588\n",
      "Epoch 8625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0868 - accuracy: 0.0156 - val_loss: 139.6569 - val_accuracy: 0.0588\n",
      "Epoch 8626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2166 - accuracy: 0.0000e+00 - val_loss: 131.6922 - val_accuracy: 0.0588\n",
      "Epoch 8627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3237 - accuracy: 0.0000e+00 - val_loss: 136.1004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8628/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6667 - accuracy: 0.0312 - val_loss: 136.4665 - val_accuracy: 0.0000e+00\n",
      "Epoch 8629/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.6837 - accuracy: 0.0312 - val_loss: 136.2506 - val_accuracy: 0.0000e+00\n",
      "Epoch 8630/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1688 - accuracy: 0.0000e+00 - val_loss: 134.8158 - val_accuracy: 0.0588\n",
      "Epoch 8631/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 31.2545 - accuracy: 0.0156 - val_loss: 134.4783 - val_accuracy: 0.0588\n",
      "Epoch 8632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8738 - accuracy: 0.0156 - val_loss: 138.3328 - val_accuracy: 0.0588\n",
      "Epoch 8633/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 37.0401 - accuracy: 0.0156 - val_loss: 145.4804 - val_accuracy: 0.1176\n",
      "Epoch 8634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6928 - accuracy: 0.0000e+00 - val_loss: 152.8580 - val_accuracy: 0.0588\n",
      "Epoch 8635/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0432 - accuracy: 0.0312 - val_loss: 149.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 8636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7488 - accuracy: 0.0000e+00 - val_loss: 131.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 8637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8295 - accuracy: 0.0000e+00 - val_loss: 117.3058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0023 - accuracy: 0.0000e+00 - val_loss: 111.4004 - val_accuracy: 0.0000e+00\n",
      "Epoch 8639/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.9967 - accuracy: 0.0156 - val_loss: 111.7924 - val_accuracy: 0.0000e+00\n",
      "Epoch 8640/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1824 - accuracy: 0.0000e+00 - val_loss: 114.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 8641/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3838 - accuracy: 0.0312 - val_loss: 125.3463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8642/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 20.9028 - accuracy: 0.0000e+00 - val_loss: 135.0550 - val_accuracy: 0.0000e+00\n",
      "Epoch 8643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.6100 - accuracy: 0.0000e+00 - val_loss: 140.0495 - val_accuracy: 0.0588\n",
      "Epoch 8644/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.3248 - accuracy: 0.0000e+00 - val_loss: 147.4998 - val_accuracy: 0.0588\n",
      "Epoch 8645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9249 - accuracy: 0.0156 - val_loss: 156.1166 - val_accuracy: 0.0588\n",
      "Epoch 8646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7105 - accuracy: 0.0000e+00 - val_loss: 161.2301 - val_accuracy: 0.0588\n",
      "Epoch 8647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9787 - accuracy: 0.0156 - val_loss: 158.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 8648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1163 - accuracy: 0.0156 - val_loss: 152.8078 - val_accuracy: 0.0588\n",
      "Epoch 8649/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7517 - accuracy: 0.0000e+00 - val_loss: 146.8436 - val_accuracy: 0.0000e+00\n",
      "Epoch 8650/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0530 - accuracy: 0.0156 - val_loss: 140.7492 - val_accuracy: 0.0000e+00\n",
      "Epoch 8651/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.5535 - accuracy: 0.0156 - val_loss: 142.1551 - val_accuracy: 0.0000e+00\n",
      "Epoch 8652/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3361 - accuracy: 0.0156 - val_loss: 147.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2609 - accuracy: 0.0312 - val_loss: 147.7338 - val_accuracy: 0.0000e+00\n",
      "Epoch 8654/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0699 - accuracy: 0.0156 - val_loss: 143.6727 - val_accuracy: 0.0000e+00\n",
      "Epoch 8655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 18.1576 - accuracy: 0.0000e+00 - val_loss: 140.4397 - val_accuracy: 0.0000e+00\n",
      "Epoch 8656/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.4912 - accuracy: 0.0000e+00 - val_loss: 140.0789 - val_accuracy: 0.0000e+00\n",
      "Epoch 8657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0449 - accuracy: 0.0000e+00 - val_loss: 142.3987 - val_accuracy: 0.0000e+00\n",
      "Epoch 8658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8320 - accuracy: 0.0312 - val_loss: 144.3802 - val_accuracy: 0.0000e+00\n",
      "Epoch 8659/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.6855 - accuracy: 0.0000e+00 - val_loss: 147.6747 - val_accuracy: 0.0000e+00\n",
      "Epoch 8660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4117 - accuracy: 0.0156 - val_loss: 143.7433 - val_accuracy: 0.0000e+00\n",
      "Epoch 8661/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9907 - accuracy: 0.0000e+00 - val_loss: 141.6425 - val_accuracy: 0.0000e+00\n",
      "Epoch 8662/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 21.9947 - accuracy: 0.0156 - val_loss: 137.4382 - val_accuracy: 0.0000e+00\n",
      "Epoch 8663/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7097 - accuracy: 0.0156 - val_loss: 132.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 8664/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 41.3849 - accuracy: 0.031 - 0s 62us/step - loss: 34.9425 - accuracy: 0.0156 - val_loss: 128.2574 - val_accuracy: 0.0588\n",
      "Epoch 8665/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 23.6356 - accuracy: 0.0000e+00 - val_loss: 125.5525 - val_accuracy: 0.0588\n",
      "Epoch 8666/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9084 - accuracy: 0.0000e+00 - val_loss: 123.9304 - val_accuracy: 0.0588\n",
      "Epoch 8667/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0426 - accuracy: 0.0000e+00 - val_loss: 131.5529 - val_accuracy: 0.0000e+00\n",
      "Epoch 8668/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7855 - accuracy: 0.0156 - val_loss: 137.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 8669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6226 - accuracy: 0.0000e+00 - val_loss: 142.0574 - val_accuracy: 0.0000e+00\n",
      "Epoch 8670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7087 - accuracy: 0.0000e+00 - val_loss: 150.8423 - val_accuracy: 0.0588\n",
      "Epoch 8671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7268 - accuracy: 0.0000e+00 - val_loss: 154.4152 - val_accuracy: 0.0588\n",
      "Epoch 8672/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.7322 - accuracy: 0.0000e+00 - val_loss: 147.9850 - val_accuracy: 0.0588\n",
      "Epoch 8673/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2087 - accuracy: 0.0000e+00 - val_loss: 143.0109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5168 - accuracy: 0.0156 - val_loss: 139.2256 - val_accuracy: 0.0000e+00\n",
      "Epoch 8675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8423 - accuracy: 0.0156 - val_loss: 133.2484 - val_accuracy: 0.0588\n",
      "Epoch 8676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5178 - accuracy: 0.0312 - val_loss: 125.9989 - val_accuracy: 0.0588\n",
      "Epoch 8677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8534 - accuracy: 0.0156 - val_loss: 121.7419 - val_accuracy: 0.0588\n",
      "Epoch 8678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2869 - accuracy: 0.0000e+00 - val_loss: 124.5009 - val_accuracy: 0.0588\n",
      "Epoch 8679/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.6718 - accuracy: 0.0156 - val_loss: 130.9110 - val_accuracy: 0.0588\n",
      "Epoch 8680/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8939 - accuracy: 0.0312 - val_loss: 133.7025 - val_accuracy: 0.0588\n",
      "Epoch 8681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3199 - accuracy: 0.0000e+00 - val_loss: 132.7806 - val_accuracy: 0.0588\n",
      "Epoch 8682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4542 - accuracy: 0.0312 - val_loss: 129.8474 - val_accuracy: 0.1176\n",
      "Epoch 8683/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 27.4500 - accuracy: 0.0156 - val_loss: 132.0428 - val_accuracy: 0.1176\n",
      "Epoch 8684/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.6050 - accuracy: 0.0156 - val_loss: 139.5507 - val_accuracy: 0.0588\n",
      "Epoch 8685/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.5318 - accuracy: 0.0000e+00 - val_loss: 151.6051 - val_accuracy: 0.0588\n",
      "Epoch 8686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4382 - accuracy: 0.0156 - val_loss: 154.4968 - val_accuracy: 0.0000e+00\n",
      "Epoch 8687/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1659 - accuracy: 0.0000e+00 - val_loss: 148.7027 - val_accuracy: 0.0000e+00\n",
      "Epoch 8688/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 18.2183 - accuracy: 0.0156 - val_loss: 142.0968 - val_accuracy: 0.0000e+00\n",
      "Epoch 8689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2997 - accuracy: 0.0156 - val_loss: 130.9926 - val_accuracy: 0.0000e+00\n",
      "Epoch 8690/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7299 - accuracy: 0.0312 - val_loss: 133.6916 - val_accuracy: 0.0588\n",
      "Epoch 8691/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 19.7056 - accuracy: 0.0156 - val_loss: 144.8931 - val_accuracy: 0.0588\n",
      "Epoch 8692/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6802 - accuracy: 0.0312 - val_loss: 151.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 8693/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.7124 - accuracy: 0.0000e+00 - val_loss: 152.1036 - val_accuracy: 0.0000e+00\n",
      "Epoch 8694/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.3375 - accuracy: 0.0312 - val_loss: 146.4838 - val_accuracy: 0.0000e+00\n",
      "Epoch 8695/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2832 - accuracy: 0.0312 - val_loss: 143.8212 - val_accuracy: 0.0000e+00\n",
      "Epoch 8696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1593 - accuracy: 0.0156 - val_loss: 143.2845 - val_accuracy: 0.0000e+00\n",
      "Epoch 8697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9134 - accuracy: 0.0156 - val_loss: 147.3367 - val_accuracy: 0.0000e+00\n",
      "Epoch 8698/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4845 - accuracy: 0.0000e+00 - val_loss: 149.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 8699/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.3116 - accuracy: 0.0000e+00 - val_loss: 150.6127 - val_accuracy: 0.0000e+00\n",
      "Epoch 8700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8897 - accuracy: 0.0312 - val_loss: 147.2859 - val_accuracy: 0.0000e+00\n",
      "Epoch 8701/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 19.5614 - accuracy: 0.0000e+00 - val_loss: 141.8439 - val_accuracy: 0.0000e+00\n",
      "Epoch 8702/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6718 - accuracy: 0.0000e+00 - val_loss: 133.8483 - val_accuracy: 0.0000e+00\n",
      "Epoch 8703/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0782 - accuracy: 0.0312 - val_loss: 126.8066 - val_accuracy: 0.0000e+00\n",
      "Epoch 8704/10000\n",
      "64/64 [==============================] - 0s 57us/step - loss: 18.9748 - accuracy: 0.0000e+00 - val_loss: 124.5309 - val_accuracy: 0.0000e+00\n",
      "Epoch 8705/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.5145 - accuracy: 0.0000e+00 - val_loss: 124.4489 - val_accuracy: 0.0000e+00\n",
      "Epoch 8706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5904 - accuracy: 0.0156 - val_loss: 132.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8707/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 18.7033 - accuracy: 0.0000e+00 - val_loss: 137.7858 - val_accuracy: 0.0000e+00\n",
      "Epoch 8708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 30.2397 - accuracy: 0.0000e+00 - val_loss: 141.4269 - val_accuracy: 0.0000e+00\n",
      "Epoch 8709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7407 - accuracy: 0.0000e+00 - val_loss: 144.0267 - val_accuracy: 0.0000e+00\n",
      "Epoch 8710/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.4842 - accuracy: 0.0156 - val_loss: 145.4236 - val_accuracy: 0.0000e+00\n",
      "Epoch 8711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6136 - accuracy: 0.0156 - val_loss: 142.3328 - val_accuracy: 0.0000e+00\n",
      "Epoch 8712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9705 - accuracy: 0.0000e+00 - val_loss: 134.8318 - val_accuracy: 0.0000e+00\n",
      "Epoch 8713/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7093 - accuracy: 0.0156 - val_loss: 127.3597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8714/10000\n",
      "64/64 [==============================] - 0s 66us/step - loss: 30.9959 - accuracy: 0.0156 - val_loss: 127.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 8715/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9139 - accuracy: 0.0156 - val_loss: 128.6513 - val_accuracy: 0.0588\n",
      "Epoch 8716/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2934 - accuracy: 0.0000e+00 - val_loss: 133.8286 - val_accuracy: 0.0588\n",
      "Epoch 8717/10000\n",
      "64/64 [==============================] - 0s 108us/step - loss: 23.9649 - accuracy: 0.0000e+00 - val_loss: 142.7163 - val_accuracy: 0.0000e+00\n",
      "Epoch 8718/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4841 - accuracy: 0.0000e+00 - val_loss: 138.1459 - val_accuracy: 0.0000e+00\n",
      "Epoch 8719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2117 - accuracy: 0.0000e+00 - val_loss: 134.6334 - val_accuracy: 0.0000e+00\n",
      "Epoch 8720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1229 - accuracy: 0.0000e+00 - val_loss: 132.2957 - val_accuracy: 0.0588\n",
      "Epoch 8721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.9954 - accuracy: 0.0000e+00 - val_loss: 137.2720 - val_accuracy: 0.0588\n",
      "Epoch 8722/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5510 - accuracy: 0.0312 - val_loss: 142.9331 - val_accuracy: 0.0000e+00\n",
      "Epoch 8723/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.2153 - accuracy: 0.0156 - val_loss: 146.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 8724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2125 - accuracy: 0.0312 - val_loss: 149.6530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8725/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 18.3872 - accuracy: 0.0000e+00 - val_loss: 147.7244 - val_accuracy: 0.0000e+00\n",
      "Epoch 8726/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6861 - accuracy: 0.0156 - val_loss: 141.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 8727/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1581 - accuracy: 0.0156 - val_loss: 137.3744 - val_accuracy: 0.0000e+00\n",
      "Epoch 8728/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2329 - accuracy: 0.0312 - val_loss: 128.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0677 - accuracy: 0.0000e+00 - val_loss: 126.9409 - val_accuracy: 0.0000e+00\n",
      "Epoch 8730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2314 - accuracy: 0.0000e+00 - val_loss: 132.1817 - val_accuracy: 0.0000e+00\n",
      "Epoch 8731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0104 - accuracy: 0.0000e+00 - val_loss: 133.5973 - val_accuracy: 0.0000e+00\n",
      "Epoch 8732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5146 - accuracy: 0.0000e+00 - val_loss: 133.5753 - val_accuracy: 0.0000e+00\n",
      "Epoch 8733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6409 - accuracy: 0.0000e+00 - val_loss: 138.4457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6884 - accuracy: 0.0156 - val_loss: 139.8478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8735/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3743 - accuracy: 0.0000e+00 - val_loss: 135.6380 - val_accuracy: 0.0588\n",
      "Epoch 8736/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1409 - accuracy: 0.0000e+00 - val_loss: 134.2275 - val_accuracy: 0.0588\n",
      "Epoch 8737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5427 - accuracy: 0.0156 - val_loss: 138.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 8738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1001 - accuracy: 0.0000e+00 - val_loss: 143.7125 - val_accuracy: 0.0000e+00\n",
      "Epoch 8739/10000\n",
      "64/64 [==============================] - 0s 51us/step - loss: 20.7250 - accuracy: 0.0000e+00 - val_loss: 143.4759 - val_accuracy: 0.0000e+00\n",
      "Epoch 8740/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8280 - accuracy: 0.0156 - val_loss: 136.6241 - val_accuracy: 0.0000e+00\n",
      "Epoch 8741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1614 - accuracy: 0.0000e+00 - val_loss: 133.3780 - val_accuracy: 0.0000e+00\n",
      "Epoch 8742/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.2214 - accuracy: 0.0156 - val_loss: 135.1714 - val_accuracy: 0.0000e+00\n",
      "Epoch 8743/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5908 - accuracy: 0.0156 - val_loss: 140.7955 - val_accuracy: 0.0000e+00\n",
      "Epoch 8744/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 24.6073 - accuracy: 0.0000e+00 - val_loss: 143.5998 - val_accuracy: 0.0588\n",
      "Epoch 8745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0244 - accuracy: 0.0000e+00 - val_loss: 145.6035 - val_accuracy: 0.0588\n",
      "Epoch 8746/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 23.4606 - accuracy: 0.0000e+00 - val_loss: 145.4701 - val_accuracy: 0.0000e+00\n",
      "Epoch 8747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0436 - accuracy: 0.0156 - val_loss: 139.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 8748/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5448 - accuracy: 0.0156 - val_loss: 134.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 8749/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6056 - accuracy: 0.0000e+00 - val_loss: 135.1402 - val_accuracy: 0.0000e+00\n",
      "Epoch 8750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9742 - accuracy: 0.0156 - val_loss: 132.8553 - val_accuracy: 0.0000e+00\n",
      "Epoch 8751/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.1211 - accuracy: 0.0312 - val_loss: 130.9894 - val_accuracy: 0.0000e+00\n",
      "Epoch 8752/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 29.4775 - accuracy: 0.0156 - val_loss: 129.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 8753/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3827 - accuracy: 0.0000e+00 - val_loss: 125.6117 - val_accuracy: 0.0000e+00\n",
      "Epoch 8754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7983 - accuracy: 0.0312 - val_loss: 124.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 8755/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.1073 - accuracy: 0.0000e+00 - val_loss: 123.4336 - val_accuracy: 0.0000e+00\n",
      "Epoch 8756/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0856 - accuracy: 0.0156 - val_loss: 123.7493 - val_accuracy: 0.0000e+00\n",
      "Epoch 8757/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5011 - accuracy: 0.0000e+00 - val_loss: 121.9461 - val_accuracy: 0.0000e+00\n",
      "Epoch 8758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.4223 - accuracy: 0.0000e+00 - val_loss: 114.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 8759/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 14.7593 - accuracy: 0.0000e+00 - val_loss: 108.4144 - val_accuracy: 0.0000e+00\n",
      "Epoch 8760/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4709 - accuracy: 0.0000e+00 - val_loss: 114.2739 - val_accuracy: 0.0000e+00\n",
      "Epoch 8761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8954 - accuracy: 0.0000e+00 - val_loss: 129.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 8762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4476 - accuracy: 0.0156 - val_loss: 140.1415 - val_accuracy: 0.0000e+00\n",
      "Epoch 8763/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8612 - accuracy: 0.0312 - val_loss: 147.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 8764/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1012 - accuracy: 0.0156 - val_loss: 150.9262 - val_accuracy: 0.0000e+00\n",
      "Epoch 8765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3370 - accuracy: 0.0156 - val_loss: 151.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 8766/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9940 - accuracy: 0.0000e+00 - val_loss: 152.2395 - val_accuracy: 0.0588\n",
      "Epoch 8767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0791 - accuracy: 0.0156 - val_loss: 150.1289 - val_accuracy: 0.0000e+00\n",
      "Epoch 8768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2437 - accuracy: 0.0000e+00 - val_loss: 146.5699 - val_accuracy: 0.0000e+00\n",
      "Epoch 8769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1730 - accuracy: 0.0156 - val_loss: 137.8723 - val_accuracy: 0.0000e+00\n",
      "Epoch 8770/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3285 - accuracy: 0.0000e+00 - val_loss: 137.4495 - val_accuracy: 0.0000e+00\n",
      "Epoch 8771/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4944 - accuracy: 0.0156 - val_loss: 139.9362 - val_accuracy: 0.0588\n",
      "Epoch 8772/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1061 - accuracy: 0.0000e+00 - val_loss: 140.2988 - val_accuracy: 0.0588\n",
      "Epoch 8773/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2021 - accuracy: 0.0156 - val_loss: 144.2534 - val_accuracy: 0.0588\n",
      "Epoch 8774/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.2173 - accuracy: 0.0000e+00 - val_loss: 142.6398 - val_accuracy: 0.0588\n",
      "Epoch 8775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8955 - accuracy: 0.0000e+00 - val_loss: 134.8418 - val_accuracy: 0.0588\n",
      "Epoch 8776/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.1993 - accuracy: 0.0000e+00 - val_loss: 127.3033 - val_accuracy: 0.0588\n",
      "Epoch 8777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8370 - accuracy: 0.0000e+00 - val_loss: 126.4538 - val_accuracy: 0.0588\n",
      "Epoch 8778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0826 - accuracy: 0.0000e+00 - val_loss: 134.6451 - val_accuracy: 0.0588\n",
      "Epoch 8779/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2655 - accuracy: 0.0156 - val_loss: 138.9734 - val_accuracy: 0.0588\n",
      "Epoch 8780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6437 - accuracy: 0.0156 - val_loss: 143.6518 - val_accuracy: 0.0000e+00\n",
      "Epoch 8781/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7397 - accuracy: 0.0000e+00 - val_loss: 143.1327 - val_accuracy: 0.0000e+00\n",
      "Epoch 8782/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2513 - accuracy: 0.0156 - val_loss: 140.6074 - val_accuracy: 0.0000e+00\n",
      "Epoch 8783/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 15.4646 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 15.8493 - accuracy: 0.0000e+00 - val_loss: 135.5559 - val_accuracy: 0.0588\n",
      "Epoch 8784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5907 - accuracy: 0.0312 - val_loss: 131.7301 - val_accuracy: 0.0588\n",
      "Epoch 8785/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0046 - accuracy: 0.0156 - val_loss: 131.2042 - val_accuracy: 0.0000e+00\n",
      "Epoch 8786/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.8430 - accuracy: 0.0000e+00 - val_loss: 128.5295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8787/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6289 - accuracy: 0.0312 - val_loss: 130.2364 - val_accuracy: 0.0000e+00\n",
      "Epoch 8788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1169 - accuracy: 0.0156 - val_loss: 129.2793 - val_accuracy: 0.0000e+00\n",
      "Epoch 8789/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9688 - accuracy: 0.0000e+00 - val_loss: 128.4458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8790/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.4332 - accuracy: 0.0000e+00 - val_loss: 124.3208 - val_accuracy: 0.0588\n",
      "Epoch 8791/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6948 - accuracy: 0.0000e+00 - val_loss: 129.3971 - val_accuracy: 0.0000e+00\n",
      "Epoch 8792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1448 - accuracy: 0.0156 - val_loss: 137.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 8793/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 19.4860 - accuracy: 0.0000e+00 - val_loss: 142.9716 - val_accuracy: 0.0000e+00\n",
      "Epoch 8794/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9871 - accuracy: 0.0312 - val_loss: 143.4658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8795/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1219 - accuracy: 0.0000e+00 - val_loss: 150.7048 - val_accuracy: 0.0588\n",
      "Epoch 8796/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 14.4373 - accuracy: 0.0156 - val_loss: 150.1403 - val_accuracy: 0.0000e+00\n",
      "Epoch 8797/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8456 - accuracy: 0.0312 - val_loss: 148.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 8798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2902 - accuracy: 0.0469 - val_loss: 147.6505 - val_accuracy: 0.0588\n",
      "Epoch 8799/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5728 - accuracy: 0.0156 - val_loss: 146.4530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7045 - accuracy: 0.0000e+00 - val_loss: 146.9356 - val_accuracy: 0.0000e+00\n",
      "Epoch 8801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3208 - accuracy: 0.0000e+00 - val_loss: 152.8539 - val_accuracy: 0.0588\n",
      "Epoch 8802/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1414 - accuracy: 0.0156 - val_loss: 150.1497 - val_accuracy: 0.0000e+00\n",
      "Epoch 8803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.0799 - accuracy: 0.0156 - val_loss: 144.2081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8804/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 26.3688 - accuracy: 0.0000e+0 - 0s 62us/step - loss: 22.1512 - accuracy: 0.0000e+00 - val_loss: 137.0855 - val_accuracy: 0.0000e+00\n",
      "Epoch 8805/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4476 - accuracy: 0.0156 - val_loss: 131.6957 - val_accuracy: 0.0000e+00\n",
      "Epoch 8806/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6627 - accuracy: 0.0000e+00 - val_loss: 122.9221 - val_accuracy: 0.0588\n",
      "Epoch 8807/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8526 - accuracy: 0.0312 - val_loss: 120.6670 - val_accuracy: 0.0588\n",
      "Epoch 8808/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.1585 - accuracy: 0.0000e+00 - val_loss: 123.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 8809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4143 - accuracy: 0.0312 - val_loss: 124.0674 - val_accuracy: 0.0000e+00\n",
      "Epoch 8810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7240 - accuracy: 0.0469 - val_loss: 128.6539 - val_accuracy: 0.0000e+00\n",
      "Epoch 8811/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.3341 - accuracy: 0.0469 - val_loss: 138.5213 - val_accuracy: 0.0000e+00\n",
      "Epoch 8812/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 22.0315 - accuracy: 0.0312 - val_loss: 149.2039 - val_accuracy: 0.0000e+00\n",
      "Epoch 8813/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 20.4366 - accuracy: 0.0312 - val_loss: 144.3914 - val_accuracy: 0.0000e+00\n",
      "Epoch 8814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2889 - accuracy: 0.0312 - val_loss: 133.5616 - val_accuracy: 0.0000e+00\n",
      "Epoch 8815/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4395 - accuracy: 0.0156 - val_loss: 126.6192 - val_accuracy: 0.0000e+00\n",
      "Epoch 8816/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5573 - accuracy: 0.0312 - val_loss: 121.3169 - val_accuracy: 0.0588\n",
      "Epoch 8817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7619 - accuracy: 0.0156 - val_loss: 127.8314 - val_accuracy: 0.0588\n",
      "Epoch 8818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4448 - accuracy: 0.0156 - val_loss: 141.4577 - val_accuracy: 0.0000e+00\n",
      "Epoch 8819/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8507 - accuracy: 0.0156 - val_loss: 145.2637 - val_accuracy: 0.0000e+00\n",
      "Epoch 8820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8933 - accuracy: 0.0000e+00 - val_loss: 131.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 8821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7300 - accuracy: 0.0000e+00 - val_loss: 127.9308 - val_accuracy: 0.0000e+00\n",
      "Epoch 8822/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7168 - accuracy: 0.0000e+00 - val_loss: 127.0522 - val_accuracy: 0.0000e+00\n",
      "Epoch 8823/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8517 - accuracy: 0.0000e+00 - val_loss: 130.3436 - val_accuracy: 0.0000e+00\n",
      "Epoch 8824/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5187 - accuracy: 0.0000e+00 - val_loss: 129.9962 - val_accuracy: 0.0000e+00\n",
      "Epoch 8825/10000\n",
      "64/64 [==============================] - 0s 152us/step - loss: 24.2059 - accuracy: 0.0000e+00 - val_loss: 134.7543 - val_accuracy: 0.0000e+00\n",
      "Epoch 8826/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.9926 - accuracy: 0.0156 - val_loss: 132.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 8827/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2290 - accuracy: 0.0312 - val_loss: 134.0011 - val_accuracy: 0.0588\n",
      "Epoch 8828/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9447 - accuracy: 0.0000e+00 - val_loss: 139.9222 - val_accuracy: 0.0588\n",
      "Epoch 8829/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.1819 - accuracy: 0.0312 - val_loss: 146.7084 - val_accuracy: 0.0588\n",
      "Epoch 8830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7033 - accuracy: 0.0000e+00 - val_loss: 148.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 8831/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.2357 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 15.9500 - accuracy: 0.0000e+00 - val_loss: 152.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 8832/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2837 - accuracy: 0.0000e+00 - val_loss: 149.7266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8833/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 21.6450 - accuracy: 0.0000e+00 - val_loss: 139.8057 - val_accuracy: 0.0000e+00\n",
      "Epoch 8834/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 22.3431 - accuracy: 0.0156 - val_loss: 131.3194 - val_accuracy: 0.0588\n",
      "Epoch 8835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6860 - accuracy: 0.0000e+00 - val_loss: 127.7590 - val_accuracy: 0.1176\n",
      "Epoch 8836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5044 - accuracy: 0.0000e+00 - val_loss: 127.4060 - val_accuracy: 0.0588\n",
      "Epoch 8837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.2797 - accuracy: 0.0156 - val_loss: 129.2534 - val_accuracy: 0.0000e+00\n",
      "Epoch 8838/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9858 - accuracy: 0.0000e+00 - val_loss: 135.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 8839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2110 - accuracy: 0.0000e+00 - val_loss: 135.0910 - val_accuracy: 0.0588\n",
      "Epoch 8840/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.0553 - accuracy: 0.0000e+00 - val_loss: 128.8745 - val_accuracy: 0.0000e+00\n",
      "Epoch 8841/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8099 - accuracy: 0.0000e+00 - val_loss: 121.7043 - val_accuracy: 0.0000e+00\n",
      "Epoch 8842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6030 - accuracy: 0.0156 - val_loss: 118.2613 - val_accuracy: 0.0000e+00\n",
      "Epoch 8843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4409 - accuracy: 0.0312 - val_loss: 121.9478 - val_accuracy: 0.0000e+00\n",
      "Epoch 8844/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0272 - accuracy: 0.0000e+00 - val_loss: 129.3598 - val_accuracy: 0.0000e+00\n",
      "Epoch 8845/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 14.6913 - accuracy: 0.0000e+00 - val_loss: 130.0272 - val_accuracy: 0.0000e+00\n",
      "Epoch 8846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9187 - accuracy: 0.0156 - val_loss: 128.3500 - val_accuracy: 0.0000e+00\n",
      "Epoch 8847/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 29.7741 - accuracy: 0.0156 - val_loss: 129.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 8848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6523 - accuracy: 0.0000e+00 - val_loss: 130.4498 - val_accuracy: 0.0588\n",
      "Epoch 8849/10000\n",
      "64/64 [==============================] - 0s 173us/step - loss: 18.0407 - accuracy: 0.0312 - val_loss: 134.2806 - val_accuracy: 0.0000e+00\n",
      "Epoch 8850/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 18.9879 - accuracy: 0.0000e+00 - val_loss: 137.3128 - val_accuracy: 0.0000e+00\n",
      "Epoch 8851/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.5896 - accuracy: 0.0156 - val_loss: 130.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 8852/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2857 - accuracy: 0.0156 - val_loss: 125.6912 - val_accuracy: 0.0000e+00\n",
      "Epoch 8853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8206 - accuracy: 0.0156 - val_loss: 123.6627 - val_accuracy: 0.0000e+00\n",
      "Epoch 8854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5848 - accuracy: 0.0000e+00 - val_loss: 128.2538 - val_accuracy: 0.0588\n",
      "Epoch 8855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4376 - accuracy: 0.0000e+00 - val_loss: 135.0170 - val_accuracy: 0.0588\n",
      "Epoch 8856/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7623 - accuracy: 0.0156 - val_loss: 137.5561 - val_accuracy: 0.0588\n",
      "Epoch 8857/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5357 - accuracy: 0.0156 - val_loss: 142.2644 - val_accuracy: 0.0000e+00\n",
      "Epoch 8858/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 13.8121 - accuracy: 0.0000e+0 - 0s 63us/step - loss: 18.0569 - accuracy: 0.0000e+00 - val_loss: 146.6063 - val_accuracy: 0.0000e+00\n",
      "Epoch 8859/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.1379 - accuracy: 0.0156 - val_loss: 152.2328 - val_accuracy: 0.0000e+00\n",
      "Epoch 8860/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0567 - accuracy: 0.0000e+00 - val_loss: 151.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 8861/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 25.3644 - accuracy: 0.0000e+00 - val_loss: 141.3697 - val_accuracy: 0.0000e+00\n",
      "Epoch 8862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.8251 - accuracy: 0.0000e+00 - val_loss: 131.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 8863/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 20.3887 - accuracy: 0.0000e+00 - val_loss: 126.6339 - val_accuracy: 0.0000e+00\n",
      "Epoch 8864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8255 - accuracy: 0.0312 - val_loss: 128.1420 - val_accuracy: 0.0000e+00\n",
      "Epoch 8865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1267 - accuracy: 0.0000e+00 - val_loss: 133.1286 - val_accuracy: 0.0000e+00\n",
      "Epoch 8866/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.5766 - accuracy: 0.0000e+00 - val_loss: 144.0611 - val_accuracy: 0.0588\n",
      "Epoch 8867/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5726 - accuracy: 0.0000e+00 - val_loss: 154.7536 - val_accuracy: 0.0000e+00\n",
      "Epoch 8868/10000\n",
      "64/64 [==============================] - 0s 194us/step - loss: 20.9742 - accuracy: 0.0000e+00 - val_loss: 153.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 8869/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9639 - accuracy: 0.0000e+00 - val_loss: 144.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 8870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3708 - accuracy: 0.0312 - val_loss: 135.7619 - val_accuracy: 0.0588\n",
      "Epoch 8871/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4321 - accuracy: 0.0156 - val_loss: 130.2551 - val_accuracy: 0.0588\n",
      "Epoch 8872/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.6723 - accuracy: 0.0156 - val_loss: 134.3390 - val_accuracy: 0.0000e+00\n",
      "Epoch 8873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4789 - accuracy: 0.0156 - val_loss: 138.0200 - val_accuracy: 0.0000e+00\n",
      "Epoch 8874/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.7967 - accuracy: 0.0312 - val_loss: 144.4636 - val_accuracy: 0.0000e+00\n",
      "Epoch 8875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2510 - accuracy: 0.0156 - val_loss: 152.1429 - val_accuracy: 0.0588\n",
      "Epoch 8876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2104 - accuracy: 0.0312 - val_loss: 154.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 8877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4076 - accuracy: 0.0625 - val_loss: 150.1157 - val_accuracy: 0.0000e+00\n",
      "Epoch 8878/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 18.6508 - accuracy: 0.0000e+00 - val_loss: 143.1058 - val_accuracy: 0.0000e+00\n",
      "Epoch 8879/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.9552 - accuracy: 0.0000e+00 - val_loss: 136.8464 - val_accuracy: 0.0000e+00\n",
      "Epoch 8880/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7646 - accuracy: 0.0000e+00 - val_loss: 136.5346 - val_accuracy: 0.0000e+00\n",
      "Epoch 8881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0606 - accuracy: 0.0156 - val_loss: 136.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 8882/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9116 - accuracy: 0.0000e+00 - val_loss: 140.6062 - val_accuracy: 0.0000e+00\n",
      "Epoch 8883/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.4877 - accuracy: 0.0000e+00 - val_loss: 130.6305 - val_accuracy: 0.0000e+00\n",
      "Epoch 8884/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4675 - accuracy: 0.0000e+00 - val_loss: 130.9667 - val_accuracy: 0.0588\n",
      "Epoch 8885/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7898 - accuracy: 0.0156 - val_loss: 131.9460 - val_accuracy: 0.0588\n",
      "Epoch 8886/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4329 - accuracy: 0.0000e+00 - val_loss: 144.1266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8887/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 27.3875 - accuracy: 0.0312 - val_loss: 152.5936 - val_accuracy: 0.0000e+00\n",
      "Epoch 8888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3275 - accuracy: 0.0000e+00 - val_loss: 153.2636 - val_accuracy: 0.0000e+00\n",
      "Epoch 8889/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.4645 - accuracy: 0.0156 - val_loss: 151.3916 - val_accuracy: 0.0000e+00\n",
      "Epoch 8890/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2829 - accuracy: 0.0000e+00 - val_loss: 142.1028 - val_accuracy: 0.0588\n",
      "Epoch 8891/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3299 - accuracy: 0.0156 - val_loss: 132.1608 - val_accuracy: 0.0000e+00\n",
      "Epoch 8892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1552 - accuracy: 0.0312 - val_loss: 132.0688 - val_accuracy: 0.0000e+00\n",
      "Epoch 8893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9308 - accuracy: 0.0156 - val_loss: 138.4925 - val_accuracy: 0.0000e+00\n",
      "Epoch 8894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4805 - accuracy: 0.0312 - val_loss: 142.2469 - val_accuracy: 0.0000e+00\n",
      "Epoch 8895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7445 - accuracy: 0.0000e+00 - val_loss: 143.2694 - val_accuracy: 0.0000e+00\n",
      "Epoch 8896/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.7024 - accuracy: 0.0312 - val_loss: 141.7299 - val_accuracy: 0.0000e+00\n",
      "Epoch 8897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2616 - accuracy: 0.0156 - val_loss: 137.8324 - val_accuracy: 0.0000e+00\n",
      "Epoch 8898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0217 - accuracy: 0.0156 - val_loss: 135.3669 - val_accuracy: 0.0000e+00\n",
      "Epoch 8899/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3970 - accuracy: 0.0000e+00 - val_loss: 135.9978 - val_accuracy: 0.0000e+00\n",
      "Epoch 8900/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4955 - accuracy: 0.0156 - val_loss: 141.2438 - val_accuracy: 0.0000e+00\n",
      "Epoch 8901/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.3322 - accuracy: 0.0156 - val_loss: 140.1265 - val_accuracy: 0.0000e+00\n",
      "Epoch 8902/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1424 - accuracy: 0.0000e+00 - val_loss: 138.0597 - val_accuracy: 0.0000e+00\n",
      "Epoch 8903/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7282 - accuracy: 0.0000e+00 - val_loss: 131.5370 - val_accuracy: 0.0000e+00\n",
      "Epoch 8904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1647 - accuracy: 0.0000e+00 - val_loss: 125.0018 - val_accuracy: 0.0000e+00\n",
      "Epoch 8905/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0969 - accuracy: 0.0000e+00 - val_loss: 121.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 8906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4179 - accuracy: 0.0156 - val_loss: 126.2774 - val_accuracy: 0.0000e+00\n",
      "Epoch 8907/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8817 - accuracy: 0.0156 - val_loss: 124.4195 - val_accuracy: 0.0000e+00\n",
      "Epoch 8908/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.2997 - accuracy: 0.0000e+00 - val_loss: 122.2124 - val_accuracy: 0.0588\n",
      "Epoch 8909/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.9133 - accuracy: 0.0156 - val_loss: 135.1053 - val_accuracy: 0.0588\n",
      "Epoch 8910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2096 - accuracy: 0.0000e+00 - val_loss: 146.7531 - val_accuracy: 0.0588\n",
      "Epoch 8911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5717 - accuracy: 0.0312 - val_loss: 147.1231 - val_accuracy: 0.0588\n",
      "Epoch 8912/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8292 - accuracy: 0.0156 - val_loss: 141.5193 - val_accuracy: 0.0588\n",
      "Epoch 8913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4189 - accuracy: 0.0312 - val_loss: 132.0590 - val_accuracy: 0.0588\n",
      "Epoch 8914/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.0142 - accuracy: 0.0312 - val_loss: 130.6873 - val_accuracy: 0.0000e+00\n",
      "Epoch 8915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.3170 - accuracy: 0.0000e+00 - val_loss: 141.4066 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3963 - accuracy: 0.0156 - val_loss: 147.8392 - val_accuracy: 0.0000e+00\n",
      "Epoch 8917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2927 - accuracy: 0.0156 - val_loss: 148.0003 - val_accuracy: 0.0000e+00\n",
      "Epoch 8918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7820 - accuracy: 0.0000e+00 - val_loss: 140.5433 - val_accuracy: 0.0588\n",
      "Epoch 8919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6207 - accuracy: 0.0000e+00 - val_loss: 133.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 8920/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1840 - accuracy: 0.0156 - val_loss: 125.3458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7093 - accuracy: 0.0156 - val_loss: 124.2429 - val_accuracy: 0.0000e+00\n",
      "Epoch 8922/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0568 - accuracy: 0.0000e+00 - val_loss: 127.9586 - val_accuracy: 0.0000e+00\n",
      "Epoch 8923/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4182 - accuracy: 0.0000e+00 - val_loss: 133.3159 - val_accuracy: 0.0000e+00\n",
      "Epoch 8924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6655 - accuracy: 0.0156 - val_loss: 134.0544 - val_accuracy: 0.0000e+00\n",
      "Epoch 8925/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0788 - accuracy: 0.0000e+00 - val_loss: 133.4406 - val_accuracy: 0.0000e+00\n",
      "Epoch 8926/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8707 - accuracy: 0.0156 - val_loss: 127.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 8927/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2133 - accuracy: 0.0156 - val_loss: 121.5307 - val_accuracy: 0.0000e+00\n",
      "Epoch 8928/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.0166 - accuracy: 0.0312 - val_loss: 124.9939 - val_accuracy: 0.0000e+00\n",
      "Epoch 8929/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.8764 - accuracy: 0.0156 - val_loss: 136.7416 - val_accuracy: 0.0000e+00\n",
      "Epoch 8930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2696 - accuracy: 0.0156 - val_loss: 138.3273 - val_accuracy: 0.0000e+00\n",
      "Epoch 8931/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5208 - accuracy: 0.0000e+00 - val_loss: 139.5177 - val_accuracy: 0.0000e+00\n",
      "Epoch 8932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.9736 - accuracy: 0.0156 - val_loss: 145.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 8933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8369 - accuracy: 0.0000e+00 - val_loss: 141.5670 - val_accuracy: 0.0588\n",
      "Epoch 8934/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9325 - accuracy: 0.0156 - val_loss: 136.4327 - val_accuracy: 0.1176\n",
      "Epoch 8935/10000\n",
      "64/64 [==============================] - 0s 172us/step - loss: 14.0982 - accuracy: 0.0156 - val_loss: 130.7528 - val_accuracy: 0.0000e+00\n",
      "Epoch 8936/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2098 - accuracy: 0.0000e+00 - val_loss: 133.4066 - val_accuracy: 0.0588\n",
      "Epoch 8937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9925 - accuracy: 0.0312 - val_loss: 140.1797 - val_accuracy: 0.0000e+00\n",
      "Epoch 8938/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 34.1861 - accuracy: 0.0156 - val_loss: 146.2654 - val_accuracy: 0.0000e+00\n",
      "Epoch 8939/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.5373 - accuracy: 0.0156 - val_loss: 149.0652 - val_accuracy: 0.0588\n",
      "Epoch 8940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0602 - accuracy: 0.0156 - val_loss: 146.8297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8941/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3713 - accuracy: 0.0000e+00 - val_loss: 142.2659 - val_accuracy: 0.0000e+00\n",
      "Epoch 8942/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.9367 - accuracy: 0.0469 - val_loss: 140.6054 - val_accuracy: 0.0000e+00\n",
      "Epoch 8943/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 24.2033 - accuracy: 0.0000e+00 - val_loss: 140.0783 - val_accuracy: 0.0000e+00\n",
      "Epoch 8944/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 17.9846 - accuracy: 0.0156 - val_loss: 141.9552 - val_accuracy: 0.0000e+00\n",
      "Epoch 8945/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8777 - accuracy: 0.0000e+00 - val_loss: 142.1947 - val_accuracy: 0.0000e+00\n",
      "Epoch 8946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2123 - accuracy: 0.0000e+00 - val_loss: 141.4333 - val_accuracy: 0.0000e+00\n",
      "Epoch 8947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0184 - accuracy: 0.0000e+00 - val_loss: 140.7250 - val_accuracy: 0.0000e+00\n",
      "Epoch 8948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5554 - accuracy: 0.0000e+00 - val_loss: 140.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 8949/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.0597 - accuracy: 0.0000e+00 - val_loss: 140.7585 - val_accuracy: 0.0000e+00\n",
      "Epoch 8950/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.3370 - accuracy: 0.0156 - val_loss: 142.3457 - val_accuracy: 0.0000e+00\n",
      "Epoch 8951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7497 - accuracy: 0.0469 - val_loss: 142.8139 - val_accuracy: 0.0000e+00\n",
      "Epoch 8952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9317 - accuracy: 0.0156 - val_loss: 141.6998 - val_accuracy: 0.0588\n",
      "Epoch 8953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9560 - accuracy: 0.0000e+00 - val_loss: 142.4237 - val_accuracy: 0.0588\n",
      "Epoch 8954/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2277 - accuracy: 0.0156 - val_loss: 143.8878 - val_accuracy: 0.0588\n",
      "Epoch 8955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7790 - accuracy: 0.0156 - val_loss: 147.9512 - val_accuracy: 0.0588\n",
      "Epoch 8956/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 13.2005 - accuracy: 0.0156 - val_loss: 148.8628 - val_accuracy: 0.0588\n",
      "Epoch 8957/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 24.1836 - accuracy: 0.0156 - val_loss: 144.6646 - val_accuracy: 0.0588\n",
      "Epoch 8958/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5944 - accuracy: 0.0000e+00 - val_loss: 138.2923 - val_accuracy: 0.0000e+00\n",
      "Epoch 8959/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.0487 - accuracy: 0.0156 - val_loss: 137.5530 - val_accuracy: 0.0000e+00\n",
      "Epoch 8960/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 24.9088 - accuracy: 0.0156 - val_loss: 135.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 8961/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.0677 - accuracy: 0.0156 - val_loss: 133.8566 - val_accuracy: 0.0000e+00\n",
      "Epoch 8962/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.5256 - accuracy: 0.0156 - val_loss: 132.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 8963/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.6067 - accuracy: 0.0625 - val_loss: 133.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 8964/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.1865 - accuracy: 0.0000e+00 - val_loss: 136.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 8965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0546 - accuracy: 0.0000e+00 - val_loss: 134.7499 - val_accuracy: 0.0000e+00\n",
      "Epoch 8966/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.7897 - accuracy: 0.0000e+00 - val_loss: 132.3030 - val_accuracy: 0.0000e+00\n",
      "Epoch 8967/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.4402 - accuracy: 0.0000e+00 - val_loss: 130.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 8968/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.3876 - accuracy: 0.0000e+00 - val_loss: 127.9341 - val_accuracy: 0.0000e+00\n",
      "Epoch 8969/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6264 - accuracy: 0.0000e+00 - val_loss: 131.0553 - val_accuracy: 0.0000e+00\n",
      "Epoch 8970/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.9527 - accuracy: 0.0156 - val_loss: 129.8499 - val_accuracy: 0.0000e+00\n",
      "Epoch 8971/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 19.5209 - accuracy: 0.0156 - val_loss: 130.3101 - val_accuracy: 0.0000e+00\n",
      "Epoch 8972/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8949 - accuracy: 0.0156 - val_loss: 130.2718 - val_accuracy: 0.0000e+00\n",
      "Epoch 8973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6964 - accuracy: 0.0000e+00 - val_loss: 129.9048 - val_accuracy: 0.0000e+00\n",
      "Epoch 8974/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0620 - accuracy: 0.0000e+00 - val_loss: 124.0451 - val_accuracy: 0.0000e+00\n",
      "Epoch 8975/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.6295 - accuracy: 0.0156 - val_loss: 118.7846 - val_accuracy: 0.0000e+00\n",
      "Epoch 8976/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.3306 - accuracy: 0.0000e+00 - val_loss: 118.2905 - val_accuracy: 0.0000e+00\n",
      "Epoch 8977/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7306 - accuracy: 0.0156 - val_loss: 120.3235 - val_accuracy: 0.0588\n",
      "Epoch 8978/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 25.2782 - accuracy: 0.0156 - val_loss: 130.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 8979/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 34.4717 - accuracy: 0.0156 - val_loss: 127.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 8980/10000\n",
      "64/64 [==============================] - 0s 188us/step - loss: 17.9339 - accuracy: 0.0000e+00 - val_loss: 121.3886 - val_accuracy: 0.0000e+00\n",
      "Epoch 8981/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 17.3842 - accuracy: 0.0000e+00 - val_loss: 120.9884 - val_accuracy: 0.0588\n",
      "Epoch 8982/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 28.7609 - accuracy: 0.0000e+00 - val_loss: 122.3643 - val_accuracy: 0.0000e+00\n",
      "Epoch 8983/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 21.5189 - accuracy: 0.0469 - val_loss: 126.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 8984/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 30.6548 - accuracy: 0.0156 - val_loss: 127.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 8985/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.7010 - accuracy: 0.0000e+00 - val_loss: 122.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 8986/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 26.5777 - accuracy: 0.0156 - val_loss: 118.9792 - val_accuracy: 0.0000e+00\n",
      "Epoch 8987/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.4758 - accuracy: 0.0000e+00 - val_loss: 111.4183 - val_accuracy: 0.0000e+00\n",
      "Epoch 8988/10000\n",
      "64/64 [==============================] - 0s 203us/step - loss: 23.6619 - accuracy: 0.0000e+00 - val_loss: 101.4862 - val_accuracy: 0.0000e+00\n",
      "Epoch 8989/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 18.3265 - accuracy: 0.0156 - val_loss: 94.5458 - val_accuracy: 0.0000e+00\n",
      "Epoch 8990/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.3493 - accuracy: 0.0312 - val_loss: 95.4963 - val_accuracy: 0.0000e+00\n",
      "Epoch 8991/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9844 - accuracy: 0.0000e+00 - val_loss: 112.8972 - val_accuracy: 0.0000e+00\n",
      "Epoch 8992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0206 - accuracy: 0.0156 - val_loss: 126.7837 - val_accuracy: 0.0000e+00\n",
      "Epoch 8993/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 24.0627 - accuracy: 0.0312 - val_loss: 127.9537 - val_accuracy: 0.0000e+00\n",
      "Epoch 8994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5796 - accuracy: 0.0156 - val_loss: 129.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 8995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2339 - accuracy: 0.0156 - val_loss: 133.5199 - val_accuracy: 0.0000e+00\n",
      "Epoch 8996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3927 - accuracy: 0.0000e+00 - val_loss: 130.8203 - val_accuracy: 0.0000e+00\n",
      "Epoch 8997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1095 - accuracy: 0.0312 - val_loss: 126.7006 - val_accuracy: 0.0000e+00\n",
      "Epoch 8998/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0965 - accuracy: 0.0625 - val_loss: 124.6653 - val_accuracy: 0.0588\n",
      "Epoch 8999/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 28.1769 - accuracy: 0.0156 - val_loss: 123.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1892 - accuracy: 0.0000e+00 - val_loss: 123.4982 - val_accuracy: 0.0000e+00\n",
      "Epoch 9001/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5693 - accuracy: 0.0000e+00 - val_loss: 128.3625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9002/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.0579 - accuracy: 0.0000e+00 - val_loss: 133.2250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9003/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5617 - accuracy: 0.0000e+00 - val_loss: 137.7401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9004/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6348 - accuracy: 0.0312 - val_loss: 142.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9005/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3505 - accuracy: 0.0000e+00 - val_loss: 140.2296 - val_accuracy: 0.0000e+00\n",
      "Epoch 9006/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0033 - accuracy: 0.0156 - val_loss: 136.9540 - val_accuracy: 0.0000e+00\n",
      "Epoch 9007/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4103 - accuracy: 0.0000e+00 - val_loss: 139.4661 - val_accuracy: 0.0588\n",
      "Epoch 9008/10000\n",
      "64/64 [==============================] - 0s 180us/step - loss: 30.3362 - accuracy: 0.0000e+00 - val_loss: 142.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 9009/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2796 - accuracy: 0.0156 - val_loss: 143.2668 - val_accuracy: 0.0000e+00\n",
      "Epoch 9010/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1502 - accuracy: 0.0000e+00 - val_loss: 143.9660 - val_accuracy: 0.0000e+00\n",
      "Epoch 9011/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9642 - accuracy: 0.0000e+00 - val_loss: 141.3200 - val_accuracy: 0.0588\n",
      "Epoch 9012/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 24.0164 - accuracy: 0.0000e+00 - val_loss: 140.3463 - val_accuracy: 0.0588\n",
      "Epoch 9013/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3833 - accuracy: 0.0156 - val_loss: 135.7683 - val_accuracy: 0.0588\n",
      "Epoch 9014/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 14.3271 - accuracy: 0.0156 - val_loss: 132.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 9015/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 17.0966 - accuracy: 0.0000e+00 - val_loss: 130.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 9016/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.7380 - accuracy: 0.0000e+00 - val_loss: 129.3887 - val_accuracy: 0.0000e+00\n",
      "Epoch 9017/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 19.9014 - accuracy: 0.0156 - val_loss: 124.5891 - val_accuracy: 0.0000e+00\n",
      "Epoch 9018/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7285 - accuracy: 0.0156 - val_loss: 119.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 9019/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6837 - accuracy: 0.0156 - val_loss: 116.1132 - val_accuracy: 0.0000e+00\n",
      "Epoch 9020/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 25.9831 - accuracy: 0.0312 - val_loss: 119.0554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9021/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.8489 - accuracy: 0.0000e+00 - val_loss: 121.7586 - val_accuracy: 0.0000e+00\n",
      "Epoch 9022/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8347 - accuracy: 0.0312 - val_loss: 129.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 9023/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 24.4531 - accuracy: 0.062 - 0s 63us/step - loss: 18.6684 - accuracy: 0.0312 - val_loss: 133.8648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9024/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3616 - accuracy: 0.0000e+00 - val_loss: 137.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9025/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7385 - accuracy: 0.0469 - val_loss: 133.9392 - val_accuracy: 0.0000e+00\n",
      "Epoch 9026/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8045 - accuracy: 0.0156 - val_loss: 131.5984 - val_accuracy: 0.0000e+00\n",
      "Epoch 9027/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1884 - accuracy: 0.0156 - val_loss: 135.7577 - val_accuracy: 0.0000e+00\n",
      "Epoch 9028/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3074 - accuracy: 0.0156 - val_loss: 142.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9029/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9325 - accuracy: 0.0156 - val_loss: 150.2265 - val_accuracy: 0.0588\n",
      "Epoch 9030/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1468 - accuracy: 0.0156 - val_loss: 152.5682 - val_accuracy: 0.0588\n",
      "Epoch 9031/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3751 - accuracy: 0.0000e+00 - val_loss: 147.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9032/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.0839 - accuracy: 0.0156 - val_loss: 140.0635 - val_accuracy: 0.0000e+00\n",
      "Epoch 9033/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4561 - accuracy: 0.0156 - val_loss: 134.5242 - val_accuracy: 0.0000e+00\n",
      "Epoch 9034/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 25.3349 - accuracy: 0.0000e+00 - val_loss: 135.0799 - val_accuracy: 0.0000e+00\n",
      "Epoch 9035/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1845 - accuracy: 0.0312 - val_loss: 134.3582 - val_accuracy: 0.0000e+00\n",
      "Epoch 9036/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9644 - accuracy: 0.0156 - val_loss: 134.6169 - val_accuracy: 0.0588\n",
      "Epoch 9037/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.0445 - accuracy: 0.0156 - val_loss: 133.5201 - val_accuracy: 0.0588\n",
      "Epoch 9038/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1755 - accuracy: 0.0156 - val_loss: 135.3144 - val_accuracy: 0.0588\n",
      "Epoch 9039/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.9708 - accuracy: 0.0156 - val_loss: 139.7181 - val_accuracy: 0.0588\n",
      "Epoch 9040/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.8985 - accuracy: 0.0312 - val_loss: 145.9954 - val_accuracy: 0.0588\n",
      "Epoch 9041/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.2676 - accuracy: 0.0000e+00 - val_loss: 152.2329 - val_accuracy: 0.0000e+00\n",
      "Epoch 9042/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7518 - accuracy: 0.0000e+00 - val_loss: 155.7883 - val_accuracy: 0.0000e+00\n",
      "Epoch 9043/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 18.9156 - accuracy: 0.0000e+00 - val_loss: 149.9744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9044/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8512 - accuracy: 0.0000e+00 - val_loss: 140.4306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9045/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.1515 - accuracy: 0.0000e+00 - val_loss: 134.5240 - val_accuracy: 0.0000e+00\n",
      "Epoch 9046/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9668 - accuracy: 0.0000e+00 - val_loss: 129.0334 - val_accuracy: 0.0000e+00\n",
      "Epoch 9047/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7917 - accuracy: 0.0156 - val_loss: 125.2162 - val_accuracy: 0.0000e+00\n",
      "Epoch 9048/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9530 - accuracy: 0.0156 - val_loss: 125.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 9049/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3506 - accuracy: 0.0312 - val_loss: 122.2158 - val_accuracy: 0.0000e+00\n",
      "Epoch 9050/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.1353 - accuracy: 0.0000e+00 - val_loss: 118.2874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9051/10000\n",
      "64/64 [==============================] - 0s 140us/step - loss: 21.8791 - accuracy: 0.0000e+00 - val_loss: 113.1031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9052/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.5944 - accuracy: 0.0156 - val_loss: 109.2611 - val_accuracy: 0.0000e+00\n",
      "Epoch 9053/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4874 - accuracy: 0.0156 - val_loss: 112.8452 - val_accuracy: 0.0000e+00\n",
      "Epoch 9054/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9814 - accuracy: 0.0312 - val_loss: 123.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 9055/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3479 - accuracy: 0.0312 - val_loss: 134.7316 - val_accuracy: 0.0000e+00\n",
      "Epoch 9056/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1587 - accuracy: 0.0000e+00 - val_loss: 141.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 9057/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1521 - accuracy: 0.0000e+00 - val_loss: 142.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 9058/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 20.0974 - accuracy: 0.0000e+00 - val_loss: 137.7370 - val_accuracy: 0.0588\n",
      "Epoch 9059/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5347 - accuracy: 0.0000e+00 - val_loss: 129.6512 - val_accuracy: 0.0000e+00\n",
      "Epoch 9060/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0491 - accuracy: 0.0000e+00 - val_loss: 120.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 9061/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 15.6772 - accuracy: 0.0469 - val_loss: 115.8161 - val_accuracy: 0.0588\n",
      "Epoch 9062/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.8669 - accuracy: 0.0312 - val_loss: 114.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9063/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2332 - accuracy: 0.0000e+00 - val_loss: 118.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9064/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2783 - accuracy: 0.0000e+00 - val_loss: 121.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 9065/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 12.9512 - accuracy: 0.0312 - val_loss: 125.1168 - val_accuracy: 0.0000e+00\n",
      "Epoch 9066/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1266 - accuracy: 0.0156 - val_loss: 127.4702 - val_accuracy: 0.0000e+00\n",
      "Epoch 9067/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6401 - accuracy: 0.0000e+00 - val_loss: 131.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 9068/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4298 - accuracy: 0.0156 - val_loss: 134.6613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9069/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9062 - accuracy: 0.0312 - val_loss: 133.3884 - val_accuracy: 0.0000e+00\n",
      "Epoch 9070/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5058 - accuracy: 0.0000e+00 - val_loss: 130.9458 - val_accuracy: 0.0000e+00\n",
      "Epoch 9071/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8501 - accuracy: 0.0000e+00 - val_loss: 126.7440 - val_accuracy: 0.0000e+00\n",
      "Epoch 9072/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9209 - accuracy: 0.0000e+00 - val_loss: 122.9018 - val_accuracy: 0.0000e+00\n",
      "Epoch 9073/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7246 - accuracy: 0.0156 - val_loss: 119.3527 - val_accuracy: 0.0000e+00\n",
      "Epoch 9074/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7760 - accuracy: 0.0000e+00 - val_loss: 119.5246 - val_accuracy: 0.0000e+00\n",
      "Epoch 9075/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0778 - accuracy: 0.0156 - val_loss: 117.7117 - val_accuracy: 0.0000e+00\n",
      "Epoch 9076/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8017 - accuracy: 0.0000e+00 - val_loss: 119.9610 - val_accuracy: 0.0000e+00\n",
      "Epoch 9077/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.9683 - accuracy: 0.0312 - val_loss: 123.8727 - val_accuracy: 0.0000e+00\n",
      "Epoch 9078/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3442 - accuracy: 0.0156 - val_loss: 122.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9079/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5844 - accuracy: 0.0312 - val_loss: 118.5163 - val_accuracy: 0.0000e+00\n",
      "Epoch 9080/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 42.7807 - accuracy: 0.0156 - val_loss: 123.3116 - val_accuracy: 0.0000e+00\n",
      "Epoch 9081/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5575 - accuracy: 0.0156 - val_loss: 134.6869 - val_accuracy: 0.0588\n",
      "Epoch 9082/10000\n",
      "64/64 [==============================] - 0s 158us/step - loss: 20.6194 - accuracy: 0.0156 - val_loss: 145.6139 - val_accuracy: 0.0588\n",
      "Epoch 9083/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0932 - accuracy: 0.0156 - val_loss: 149.5190 - val_accuracy: 0.0588\n",
      "Epoch 9084/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5277 - accuracy: 0.0312 - val_loss: 150.7205 - val_accuracy: 0.0588\n",
      "Epoch 9085/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.7659 - accuracy: 0.0156 - val_loss: 151.9962 - val_accuracy: 0.0588\n",
      "Epoch 9086/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1633 - accuracy: 0.0312 - val_loss: 149.0513 - val_accuracy: 0.0000e+00\n",
      "Epoch 9087/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2934 - accuracy: 0.0000e+00 - val_loss: 137.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9088/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2497 - accuracy: 0.0156 - val_loss: 129.0469 - val_accuracy: 0.0588\n",
      "Epoch 9089/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.2633 - accuracy: 0.0000e+00 - val_loss: 130.1326 - val_accuracy: 0.0588\n",
      "Epoch 9090/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0686 - accuracy: 0.0000e+00 - val_loss: 134.3942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9091/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8629 - accuracy: 0.0156 - val_loss: 134.1754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9092/10000\n",
      "64/64 [==============================] - 0s 165us/step - loss: 18.3699 - accuracy: 0.0000e+00 - val_loss: 129.5869 - val_accuracy: 0.0588\n",
      "Epoch 9093/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 16.4292 - accuracy: 0.0000e+00 - val_loss: 125.0244 - val_accuracy: 0.0588\n",
      "Epoch 9094/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3378 - accuracy: 0.0312 - val_loss: 123.0909 - val_accuracy: 0.0000e+00\n",
      "Epoch 9095/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.8432 - accuracy: 0.0156 - val_loss: 124.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 9096/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 20.0608 - accuracy: 0.0156 - val_loss: 136.5533 - val_accuracy: 0.0000e+00\n",
      "Epoch 9097/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 12.5297 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 18.8978 - accuracy: 0.0156 - val_loss: 146.7597 - val_accuracy: 0.0000e+00\n",
      "Epoch 9098/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.5897 - accuracy: 0.0000e+00 - val_loss: 153.6670 - val_accuracy: 0.0000e+00\n",
      "Epoch 9099/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6926 - accuracy: 0.0000e+00 - val_loss: 148.2803 - val_accuracy: 0.0000e+00\n",
      "Epoch 9100/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0580 - accuracy: 0.0156 - val_loss: 136.2826 - val_accuracy: 0.0000e+00\n",
      "Epoch 9101/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.0137 - accuracy: 0.0156 - val_loss: 130.3414 - val_accuracy: 0.0000e+00\n",
      "Epoch 9102/10000\n",
      "64/64 [==============================] - 0s 154us/step - loss: 16.0262 - accuracy: 0.0312 - val_loss: 126.6494 - val_accuracy: 0.0000e+00\n",
      "Epoch 9103/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4908 - accuracy: 0.0000e+00 - val_loss: 131.2306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9104/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9734 - accuracy: 0.0000e+00 - val_loss: 140.2571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9105/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4809 - accuracy: 0.0000e+00 - val_loss: 149.3498 - val_accuracy: 0.0000e+00\n",
      "Epoch 9106/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9863 - accuracy: 0.0000e+00 - val_loss: 152.8192 - val_accuracy: 0.0000e+00\n",
      "Epoch 9107/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7456 - accuracy: 0.0156 - val_loss: 148.3455 - val_accuracy: 0.0000e+00\n",
      "Epoch 9108/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.3034 - accuracy: 0.0156 - val_loss: 138.9714 - val_accuracy: 0.0000e+00\n",
      "Epoch 9109/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3013 - accuracy: 0.0000e+00 - val_loss: 130.1015 - val_accuracy: 0.0000e+00\n",
      "Epoch 9110/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2398 - accuracy: 0.0156 - val_loss: 119.6441 - val_accuracy: 0.0588\n",
      "Epoch 9111/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8428 - accuracy: 0.0000e+00 - val_loss: 120.7127 - val_accuracy: 0.0588\n",
      "Epoch 9112/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6085 - accuracy: 0.0156 - val_loss: 134.5656 - val_accuracy: 0.0588\n",
      "Epoch 9113/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.9952 - accuracy: 0.0156 - val_loss: 148.2208 - val_accuracy: 0.0000e+00\n",
      "Epoch 9114/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 23.6682 - accuracy: 0.0156 - val_loss: 157.9991 - val_accuracy: 0.0000e+00\n",
      "Epoch 9115/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1108 - accuracy: 0.0156 - val_loss: 155.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 9116/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9859 - accuracy: 0.0000e+00 - val_loss: 145.1334 - val_accuracy: 0.0000e+00\n",
      "Epoch 9117/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6658 - accuracy: 0.0312 - val_loss: 130.2137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9118/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8892 - accuracy: 0.0000e+00 - val_loss: 122.5900 - val_accuracy: 0.0000e+00\n",
      "Epoch 9119/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3818 - accuracy: 0.0000e+00 - val_loss: 124.4621 - val_accuracy: 0.0000e+00\n",
      "Epoch 9120/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0891 - accuracy: 0.0156 - val_loss: 128.5236 - val_accuracy: 0.0588\n",
      "Epoch 9121/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0110 - accuracy: 0.0156 - val_loss: 131.2062 - val_accuracy: 0.0588\n",
      "Epoch 9122/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 24.6775 - accuracy: 0.0156 - val_loss: 132.9313 - val_accuracy: 0.0588\n",
      "Epoch 9123/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8594 - accuracy: 0.0156 - val_loss: 133.8504 - val_accuracy: 0.0588\n",
      "Epoch 9124/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 33.4386 - accuracy: 0.0156 - val_loss: 129.1343 - val_accuracy: 0.0000e+00\n",
      "Epoch 9125/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 14.4002 - accuracy: 0.0000e+00 - val_loss: 125.3571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9126/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4334 - accuracy: 0.0312 - val_loss: 131.5337 - val_accuracy: 0.0000e+00\n",
      "Epoch 9127/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 12.9735 - accuracy: 0.0000e+00 - val_loss: 136.6682 - val_accuracy: 0.0000e+00\n",
      "Epoch 9128/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1460 - accuracy: 0.0000e+00 - val_loss: 146.4434 - val_accuracy: 0.0000e+00\n",
      "Epoch 9129/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4290 - accuracy: 0.0156 - val_loss: 154.4544 - val_accuracy: 0.0000e+00\n",
      "Epoch 9130/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.8479 - accuracy: 0.0156 - val_loss: 150.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 9131/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3230 - accuracy: 0.0156 - val_loss: 144.4698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9132/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1351 - accuracy: 0.0000e+00 - val_loss: 130.7664 - val_accuracy: 0.0000e+00\n",
      "Epoch 9133/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 21.1832 - accuracy: 0.0000e+00 - val_loss: 126.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9134/10000\n",
      "64/64 [==============================] - 0s 184us/step - loss: 25.9946 - accuracy: 0.0469 - val_loss: 126.7924 - val_accuracy: 0.1176\n",
      "Epoch 9135/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3589 - accuracy: 0.0000e+00 - val_loss: 135.9055 - val_accuracy: 0.0588\n",
      "Epoch 9136/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4183 - accuracy: 0.0156 - val_loss: 141.8177 - val_accuracy: 0.0588\n",
      "Epoch 9137/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.8786 - accuracy: 0.0156 - val_loss: 146.6216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9138/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7636 - accuracy: 0.0156 - val_loss: 149.4637 - val_accuracy: 0.0000e+00\n",
      "Epoch 9139/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3411 - accuracy: 0.0312 - val_loss: 144.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9140/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3231 - accuracy: 0.0312 - val_loss: 138.3936 - val_accuracy: 0.0588\n",
      "Epoch 9141/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.8814 - accuracy: 0.0156 - val_loss: 133.4486 - val_accuracy: 0.0000e+00\n",
      "Epoch 9142/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 17.8955 - accuracy: 0.0000e+00 - val_loss: 127.9374 - val_accuracy: 0.0000e+00\n",
      "Epoch 9143/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7067 - accuracy: 0.0156 - val_loss: 126.7599 - val_accuracy: 0.0000e+00\n",
      "Epoch 9144/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 27.1850 - accuracy: 0.0000e+00 - val_loss: 129.3273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9145/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0602 - accuracy: 0.0000e+00 - val_loss: 132.4883 - val_accuracy: 0.0000e+00\n",
      "Epoch 9146/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.0793 - accuracy: 0.0469 - val_loss: 133.8698 - val_accuracy: 0.0000e+00\n",
      "Epoch 9147/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 25.7463 - accuracy: 0.0156 - val_loss: 132.5675 - val_accuracy: 0.0000e+00\n",
      "Epoch 9148/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7931 - accuracy: 0.0000e+00 - val_loss: 126.8211 - val_accuracy: 0.0000e+00\n",
      "Epoch 9149/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9821 - accuracy: 0.0156 - val_loss: 124.5993 - val_accuracy: 0.0000e+00\n",
      "Epoch 9150/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2737 - accuracy: 0.0000e+00 - val_loss: 124.3398 - val_accuracy: 0.0000e+00\n",
      "Epoch 9151/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.2914 - accuracy: 0.0156 - val_loss: 128.0143 - val_accuracy: 0.0588\n",
      "Epoch 9152/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0717 - accuracy: 0.0000e+00 - val_loss: 133.6858 - val_accuracy: 0.0588\n",
      "Epoch 9153/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.6253 - accuracy: 0.0000e+00 - val_loss: 142.4562 - val_accuracy: 0.0588\n",
      "Epoch 9154/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.0641 - accuracy: 0.0156 - val_loss: 141.1298 - val_accuracy: 0.0588\n",
      "Epoch 9155/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 22.3120 - accuracy: 0.0312 - val_loss: 141.0293 - val_accuracy: 0.0588\n",
      "Epoch 9156/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9985 - accuracy: 0.0156 - val_loss: 139.3384 - val_accuracy: 0.0588\n",
      "Epoch 9157/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3281 - accuracy: 0.0000e+00 - val_loss: 140.0095 - val_accuracy: 0.0588\n",
      "Epoch 9158/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3373 - accuracy: 0.0156 - val_loss: 138.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 9159/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5527 - accuracy: 0.0156 - val_loss: 130.6087 - val_accuracy: 0.0000e+00\n",
      "Epoch 9160/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8649 - accuracy: 0.0156 - val_loss: 126.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9161/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3651 - accuracy: 0.0000e+00 - val_loss: 127.6725 - val_accuracy: 0.0588\n",
      "Epoch 9162/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5077 - accuracy: 0.0156 - val_loss: 127.1030 - val_accuracy: 0.1176\n",
      "Epoch 9163/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8297 - accuracy: 0.0000e+00 - val_loss: 129.7136 - val_accuracy: 0.1176\n",
      "Epoch 9164/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 42.0253 - accuracy: 0.0000e+00 - val_loss: 130.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 9165/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 14.7069 - accuracy: 0.0000e+00 - val_loss: 130.1131 - val_accuracy: 0.0000e+00\n",
      "Epoch 9166/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 20.2370 - accuracy: 0.0000e+00 - val_loss: 128.1350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9167/10000\n",
      "64/64 [==============================] - 0s 74us/step - loss: 26.5539 - accuracy: 0.0156 - val_loss: 124.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 9168/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9507 - accuracy: 0.0000e+00 - val_loss: 126.3337 - val_accuracy: 0.0000e+00\n",
      "Epoch 9169/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7139 - accuracy: 0.0000e+00 - val_loss: 128.2610 - val_accuracy: 0.0000e+00\n",
      "Epoch 9170/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7940 - accuracy: 0.0156 - val_loss: 134.7429 - val_accuracy: 0.0000e+00\n",
      "Epoch 9171/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4653 - accuracy: 0.0000e+00 - val_loss: 136.9218 - val_accuracy: 0.0000e+00\n",
      "Epoch 9172/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8848 - accuracy: 0.0469 - val_loss: 130.5272 - val_accuracy: 0.0000e+00\n",
      "Epoch 9173/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8457 - accuracy: 0.0000e+00 - val_loss: 126.6491 - val_accuracy: 0.0000e+00\n",
      "Epoch 9174/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.1757 - accuracy: 0.0156 - val_loss: 120.4876 - val_accuracy: 0.0588\n",
      "Epoch 9175/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 31.1509 - accuracy: 0.0156 - val_loss: 125.8832 - val_accuracy: 0.0588\n",
      "Epoch 9176/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 21.9804 - accuracy: 0.0000e+00 - val_loss: 141.5550 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9177/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1682 - accuracy: 0.0469 - val_loss: 151.5954 - val_accuracy: 0.0588\n",
      "Epoch 9178/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.4260 - accuracy: 0.0156 - val_loss: 144.1967 - val_accuracy: 0.0000e+00\n",
      "Epoch 9179/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0349 - accuracy: 0.0000e+00 - val_loss: 137.3925 - val_accuracy: 0.0000e+00\n",
      "Epoch 9180/10000\n",
      "64/64 [==============================] - 0s 77us/step - loss: 16.6327 - accuracy: 0.0312 - val_loss: 131.7899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9181/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5044 - accuracy: 0.0156 - val_loss: 127.2671 - val_accuracy: 0.0000e+00\n",
      "Epoch 9182/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6849 - accuracy: 0.0000e+00 - val_loss: 124.3121 - val_accuracy: 0.0588\n",
      "Epoch 9183/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.9499 - accuracy: 0.0156 - val_loss: 123.2624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9184/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 24.5223 - accuracy: 0.0000e+00 - val_loss: 127.1378 - val_accuracy: 0.0588\n",
      "Epoch 9185/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.1005 - accuracy: 0.0156 - val_loss: 133.1418 - val_accuracy: 0.0000e+00\n",
      "Epoch 9186/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 26.7530 - accuracy: 0.0156 - val_loss: 133.9252 - val_accuracy: 0.0000e+00\n",
      "Epoch 9187/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4530 - accuracy: 0.0156 - val_loss: 135.3145 - val_accuracy: 0.0000e+00\n",
      "Epoch 9188/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0676 - accuracy: 0.0156 - val_loss: 146.4123 - val_accuracy: 0.0000e+00\n",
      "Epoch 9189/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8362 - accuracy: 0.0156 - val_loss: 149.2666 - val_accuracy: 0.0000e+00\n",
      "Epoch 9190/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4324 - accuracy: 0.0000e+00 - val_loss: 147.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9191/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0610 - accuracy: 0.0000e+00 - val_loss: 145.7527 - val_accuracy: 0.0000e+00\n",
      "Epoch 9192/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4840 - accuracy: 0.0156 - val_loss: 142.5187 - val_accuracy: 0.0588\n",
      "Epoch 9193/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 17.9893 - accuracy: 0.0000e+00 - val_loss: 139.2512 - val_accuracy: 0.0000e+00\n",
      "Epoch 9194/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6297 - accuracy: 0.0312 - val_loss: 137.8415 - val_accuracy: 0.0000e+00\n",
      "Epoch 9195/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 12.9513 - accuracy: 0.0000e+00 - val_loss: 132.9748 - val_accuracy: 0.0000e+00\n",
      "Epoch 9196/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.9118 - accuracy: 0.0000e+00 - val_loss: 131.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 9197/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3398 - accuracy: 0.0312 - val_loss: 133.3943 - val_accuracy: 0.0000e+00\n",
      "Epoch 9198/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9515 - accuracy: 0.0312 - val_loss: 137.1790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9199/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 18.0855 - accuracy: 0.0156 - val_loss: 140.7933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9200/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9242 - accuracy: 0.0312 - val_loss: 134.6614 - val_accuracy: 0.0000e+00\n",
      "Epoch 9201/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6915 - accuracy: 0.0312 - val_loss: 129.1204 - val_accuracy: 0.0000e+00\n",
      "Epoch 9202/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4953 - accuracy: 0.0156 - val_loss: 131.4931 - val_accuracy: 0.0000e+00\n",
      "Epoch 9203/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 30.4476 - accuracy: 0.0156 - val_loss: 135.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 9204/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3328 - accuracy: 0.0000e+00 - val_loss: 137.3426 - val_accuracy: 0.0000e+00\n",
      "Epoch 9205/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1680 - accuracy: 0.0000e+00 - val_loss: 137.1648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9206/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1798 - accuracy: 0.0312 - val_loss: 134.2344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9207/10000\n",
      "64/64 [==============================] - 0s 129us/step - loss: 15.9435 - accuracy: 0.0469 - val_loss: 134.7041 - val_accuracy: 0.0588\n",
      "Epoch 9208/10000\n",
      "64/64 [==============================] - 0s 101us/step - loss: 23.5633 - accuracy: 0.0156 - val_loss: 144.3926 - val_accuracy: 0.0588\n",
      "Epoch 9209/10000\n",
      "64/64 [==============================] - 0s 166us/step - loss: 19.9002 - accuracy: 0.0000e+00 - val_loss: 149.3098 - val_accuracy: 0.0588\n",
      "Epoch 9210/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6231 - accuracy: 0.0156 - val_loss: 155.0867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9211/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2310 - accuracy: 0.0312 - val_loss: 155.9866 - val_accuracy: 0.0588\n",
      "Epoch 9212/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 14.4216 - accuracy: 0.0000e+00 - val_loss: 151.3376 - val_accuracy: 0.0588\n",
      "Epoch 9213/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6087 - accuracy: 0.0000e+00 - val_loss: 143.7478 - val_accuracy: 0.0588\n",
      "Epoch 9214/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5390 - accuracy: 0.0000e+00 - val_loss: 132.1662 - val_accuracy: 0.0588\n",
      "Epoch 9215/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9869 - accuracy: 0.0312 - val_loss: 127.6480 - val_accuracy: 0.0588\n",
      "Epoch 9216/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7862 - accuracy: 0.0000e+00 - val_loss: 124.1202 - val_accuracy: 0.0588\n",
      "Epoch 9217/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.6047 - accuracy: 0.0156 - val_loss: 123.0459 - val_accuracy: 0.0588\n",
      "Epoch 9218/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 19.8817 - accuracy: 0.0000e+00 - val_loss: 129.0116 - val_accuracy: 0.0588\n",
      "Epoch 9219/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4076 - accuracy: 0.0156 - val_loss: 139.8060 - val_accuracy: 0.0000e+00\n",
      "Epoch 9220/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 27.7329 - accuracy: 0.0000e+00 - val_loss: 147.7473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9221/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.4378 - accuracy: 0.0000e+00 - val_loss: 145.6846 - val_accuracy: 0.0000e+00\n",
      "Epoch 9222/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0617 - accuracy: 0.0312 - val_loss: 140.0475 - val_accuracy: 0.0000e+00\n",
      "Epoch 9223/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3511 - accuracy: 0.0000e+00 - val_loss: 137.7987 - val_accuracy: 0.0588\n",
      "Epoch 9224/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.0390 - accuracy: 0.0156 - val_loss: 131.2242 - val_accuracy: 0.0588\n",
      "Epoch 9225/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4772 - accuracy: 0.0156 - val_loss: 127.2546 - val_accuracy: 0.0000e+00\n",
      "Epoch 9226/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2982 - accuracy: 0.0000e+00 - val_loss: 127.7402 - val_accuracy: 0.0000e+00\n",
      "Epoch 9227/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.6526 - accuracy: 0.0000e+00 - val_loss: 133.0119 - val_accuracy: 0.0000e+00\n",
      "Epoch 9228/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 25.2141 - accuracy: 0.0312 - val_loss: 144.2707 - val_accuracy: 0.0000e+00\n",
      "Epoch 9229/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3099 - accuracy: 0.0000e+00 - val_loss: 150.6537 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9230/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5929 - accuracy: 0.0000e+00 - val_loss: 145.1221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9231/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6695 - accuracy: 0.0156 - val_loss: 134.7723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9232/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9261 - accuracy: 0.0156 - val_loss: 125.7071 - val_accuracy: 0.0000e+00\n",
      "Epoch 9233/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2886 - accuracy: 0.0469 - val_loss: 126.8928 - val_accuracy: 0.0000e+00\n",
      "Epoch 9234/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5485 - accuracy: 0.0000e+00 - val_loss: 129.2593 - val_accuracy: 0.0000e+00\n",
      "Epoch 9235/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1997 - accuracy: 0.0312 - val_loss: 135.4061 - val_accuracy: 0.0000e+00\n",
      "Epoch 9236/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5230 - accuracy: 0.0156 - val_loss: 139.8877 - val_accuracy: 0.0588\n",
      "Epoch 9237/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2994 - accuracy: 0.0156 - val_loss: 140.5093 - val_accuracy: 0.0588\n",
      "Epoch 9238/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9849 - accuracy: 0.0000e+00 - val_loss: 134.3092 - val_accuracy: 0.0588\n",
      "Epoch 9239/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4609 - accuracy: 0.0000e+00 - val_loss: 134.7108 - val_accuracy: 0.0588\n",
      "Epoch 9240/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7448 - accuracy: 0.0000e+00 - val_loss: 139.9256 - val_accuracy: 0.0588\n",
      "Epoch 9241/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6835 - accuracy: 0.0312 - val_loss: 141.8622 - val_accuracy: 0.0588\n",
      "Epoch 9242/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6253 - accuracy: 0.0156 - val_loss: 136.4855 - val_accuracy: 0.0000e+00\n",
      "Epoch 9243/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3987 - accuracy: 0.0156 - val_loss: 132.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9244/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5877 - accuracy: 0.0000e+00 - val_loss: 128.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 9245/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8461 - accuracy: 0.0000e+00 - val_loss: 127.1425 - val_accuracy: 0.0000e+00\n",
      "Epoch 9246/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.5694 - accuracy: 0.0000e+00 - val_loss: 130.6687 - val_accuracy: 0.0000e+00\n",
      "Epoch 9247/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.2539 - accuracy: 0.0156 - val_loss: 131.0806 - val_accuracy: 0.0000e+00\n",
      "Epoch 9248/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8560 - accuracy: 0.0312 - val_loss: 131.6948 - val_accuracy: 0.0000e+00\n",
      "Epoch 9249/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 22.8497 - accuracy: 0.0156 - val_loss: 133.7538 - val_accuracy: 0.0000e+00\n",
      "Epoch 9250/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8280 - accuracy: 0.0000e+00 - val_loss: 133.8980 - val_accuracy: 0.0000e+00\n",
      "Epoch 9251/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5564 - accuracy: 0.0000e+00 - val_loss: 133.0392 - val_accuracy: 0.0588\n",
      "Epoch 9252/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4896 - accuracy: 0.0156 - val_loss: 130.3898 - val_accuracy: 0.0000e+00\n",
      "Epoch 9253/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0719 - accuracy: 0.0156 - val_loss: 134.7856 - val_accuracy: 0.0000e+00\n",
      "Epoch 9254/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.5588 - accuracy: 0.0156 - val_loss: 143.8594 - val_accuracy: 0.0000e+00\n",
      "Epoch 9255/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4412 - accuracy: 0.0156 - val_loss: 145.8658 - val_accuracy: 0.0000e+00\n",
      "Epoch 9256/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4431 - accuracy: 0.0156 - val_loss: 146.2359 - val_accuracy: 0.0000e+00\n",
      "Epoch 9257/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 15.6547 - accuracy: 0.0156 - val_loss: 146.1877 - val_accuracy: 0.0000e+00\n",
      "Epoch 9258/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7768 - accuracy: 0.0156 - val_loss: 149.5764 - val_accuracy: 0.0000e+00\n",
      "Epoch 9259/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1616 - accuracy: 0.0156 - val_loss: 146.4200 - val_accuracy: 0.0000e+00\n",
      "Epoch 9260/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.1279 - accuracy: 0.0156 - val_loss: 142.1179 - val_accuracy: 0.0588\n",
      "Epoch 9261/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5415 - accuracy: 0.0000e+00 - val_loss: 133.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 9262/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 21.5273 - accuracy: 0.0156 - val_loss: 130.1397 - val_accuracy: 0.0000e+00\n",
      "Epoch 9263/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2368 - accuracy: 0.0156 - val_loss: 136.3976 - val_accuracy: 0.0000e+00\n",
      "Epoch 9264/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.4945 - accuracy: 0.0000e+00 - val_loss: 134.5125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9265/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4166 - accuracy: 0.0000e+00 - val_loss: 136.1490 - val_accuracy: 0.0000e+00\n",
      "Epoch 9266/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.1722 - accuracy: 0.0156 - val_loss: 136.8867 - val_accuracy: 0.0000e+00\n",
      "Epoch 9267/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.0369 - accuracy: 0.0000e+00 - val_loss: 141.3219 - val_accuracy: 0.0000e+00\n",
      "Epoch 9268/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.1164 - accuracy: 0.0156 - val_loss: 138.9825 - val_accuracy: 0.0000e+00\n",
      "Epoch 9269/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.8552 - accuracy: 0.0000e+00 - val_loss: 133.9910 - val_accuracy: 0.0000e+00\n",
      "Epoch 9270/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7188 - accuracy: 0.0000e+00 - val_loss: 133.2607 - val_accuracy: 0.0000e+00\n",
      "Epoch 9271/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4849 - accuracy: 0.0156 - val_loss: 137.6694 - val_accuracy: 0.0000e+00\n",
      "Epoch 9272/10000\n",
      "64/64 [==============================] - 0s 60us/step - loss: 21.3812 - accuracy: 0.0000e+00 - val_loss: 139.5682 - val_accuracy: 0.0588\n",
      "Epoch 9273/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5357 - accuracy: 0.0156 - val_loss: 141.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9274/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 27.5842 - accuracy: 0.0000e+00 - val_loss: 140.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9275/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.6857 - accuracy: 0.0156 - val_loss: 133.0458 - val_accuracy: 0.0588\n",
      "Epoch 9276/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.9960 - accuracy: 0.0156 - val_loss: 124.5813 - val_accuracy: 0.0588\n",
      "Epoch 9277/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 20.1041 - accuracy: 0.0156 - val_loss: 116.2811 - val_accuracy: 0.0000e+00\n",
      "Epoch 9278/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0002 - accuracy: 0.0156 - val_loss: 117.6907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9279/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.9804 - accuracy: 0.0000e+00 - val_loss: 121.8470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9280/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4982 - accuracy: 0.0156 - val_loss: 133.1554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9281/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8442 - accuracy: 0.0156 - val_loss: 137.0273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9282/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0729 - accuracy: 0.0156 - val_loss: 137.7648 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9283/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 26.4669 - accuracy: 0.0156 - val_loss: 140.9382 - val_accuracy: 0.0588\n",
      "Epoch 9284/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.0557 - accuracy: 0.0156 - val_loss: 141.1246 - val_accuracy: 0.0000e+00\n",
      "Epoch 9285/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 13.8390 - accuracy: 0.0156 - val_loss: 135.4907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9286/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9117 - accuracy: 0.0312 - val_loss: 132.1251 - val_accuracy: 0.0000e+00\n",
      "Epoch 9287/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9844 - accuracy: 0.0156 - val_loss: 137.3001 - val_accuracy: 0.0000e+00\n",
      "Epoch 9288/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6971 - accuracy: 0.0000e+00 - val_loss: 145.7377 - val_accuracy: 0.0000e+00\n",
      "Epoch 9289/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.6290 - accuracy: 0.0156 - val_loss: 146.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 9290/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8432 - accuracy: 0.0156 - val_loss: 147.5135 - val_accuracy: 0.0000e+00\n",
      "Epoch 9291/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8914 - accuracy: 0.0000e+00 - val_loss: 145.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9292/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.4170 - accuracy: 0.0000e+00 - val_loss: 132.7137 - val_accuracy: 0.0588\n",
      "Epoch 9293/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 14.6661 - accuracy: 0.0000e+00 - val_loss: 122.4933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9294/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.9409 - accuracy: 0.0000e+00 - val_loss: 118.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 9295/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 17.5498 - accuracy: 0.0156 - val_loss: 122.5600 - val_accuracy: 0.0000e+00\n",
      "Epoch 9296/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.4773 - accuracy: 0.0156 - val_loss: 132.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 9297/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3158 - accuracy: 0.0000e+00 - val_loss: 134.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 9298/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.1557 - accuracy: 0.0156 - val_loss: 128.3683 - val_accuracy: 0.0000e+00\n",
      "Epoch 9299/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7550 - accuracy: 0.0156 - val_loss: 128.1306 - val_accuracy: 0.0000e+00\n",
      "Epoch 9300/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5214 - accuracy: 0.0156 - val_loss: 127.7178 - val_accuracy: 0.0000e+00\n",
      "Epoch 9301/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.3678 - accuracy: 0.0000e+00 - val_loss: 125.9696 - val_accuracy: 0.0000e+00\n",
      "Epoch 9302/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2214 - accuracy: 0.0156 - val_loss: 122.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 9303/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.3036 - accuracy: 0.0000e+00 - val_loss: 118.5898 - val_accuracy: 0.0000e+00\n",
      "Epoch 9304/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2848 - accuracy: 0.0000e+00 - val_loss: 127.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 9305/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.2162 - accuracy: 0.0312 - val_loss: 128.6580 - val_accuracy: 0.0000e+00\n",
      "Epoch 9306/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2564 - accuracy: 0.0156 - val_loss: 131.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 9307/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1243 - accuracy: 0.0312 - val_loss: 143.6978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9308/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1769 - accuracy: 0.0000e+00 - val_loss: 148.9375 - val_accuracy: 0.0000e+00\n",
      "Epoch 9309/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.7089 - accuracy: 0.0000e+00 - val_loss: 146.0805 - val_accuracy: 0.0000e+00\n",
      "Epoch 9310/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4909 - accuracy: 0.0000e+00 - val_loss: 140.5234 - val_accuracy: 0.0588\n",
      "Epoch 9311/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.7386 - accuracy: 0.0000e+00 - val_loss: 131.1979 - val_accuracy: 0.0588\n",
      "Epoch 9312/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2037 - accuracy: 0.0156 - val_loss: 122.9029 - val_accuracy: 0.0000e+00\n",
      "Epoch 9313/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0990 - accuracy: 0.0312 - val_loss: 125.4957 - val_accuracy: 0.0000e+00\n",
      "Epoch 9314/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5873 - accuracy: 0.0000e+00 - val_loss: 130.4785 - val_accuracy: 0.0588\n",
      "Epoch 9315/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 16.8633 - accuracy: 0.0156 - val_loss: 131.9774 - val_accuracy: 0.0000e+00\n",
      "Epoch 9316/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0986 - accuracy: 0.0156 - val_loss: 132.5880 - val_accuracy: 0.0000e+00\n",
      "Epoch 9317/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.7248 - accuracy: 0.0312 - val_loss: 128.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9318/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.1816 - accuracy: 0.0000e+00 - val_loss: 130.5328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9319/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0095 - accuracy: 0.0312 - val_loss: 134.2207 - val_accuracy: 0.0000e+00\n",
      "Epoch 9320/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.1502 - accuracy: 0.0156 - val_loss: 136.3559 - val_accuracy: 0.0000e+00\n",
      "Epoch 9321/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7689 - accuracy: 0.0000e+00 - val_loss: 138.8687 - val_accuracy: 0.0588\n",
      "Epoch 9322/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.9209 - accuracy: 0.0000e+00 - val_loss: 140.5061 - val_accuracy: 0.0588\n",
      "Epoch 9323/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.5677 - accuracy: 0.0156 - val_loss: 133.5380 - val_accuracy: 0.0588\n",
      "Epoch 9324/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.5481 - accuracy: 0.0000e+00 - val_loss: 127.2532 - val_accuracy: 0.0588\n",
      "Epoch 9325/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7306 - accuracy: 0.0312 - val_loss: 122.8853 - val_accuracy: 0.0588\n",
      "Epoch 9326/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 22.2307 - accuracy: 0.0000e+00 - val_loss: 121.6036 - val_accuracy: 0.1176\n",
      "Epoch 9327/10000\n",
      "64/64 [==============================] - 0s 118us/step - loss: 25.2439 - accuracy: 0.0000e+00 - val_loss: 120.5629 - val_accuracy: 0.0588\n",
      "Epoch 9328/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.2529 - accuracy: 0.0000e+00 - val_loss: 121.5964 - val_accuracy: 0.0000e+00\n",
      "Epoch 9329/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5329 - accuracy: 0.0156 - val_loss: 125.3728 - val_accuracy: 0.0588\n",
      "Epoch 9330/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 18.7231 - accuracy: 0.0000e+00 - val_loss: 127.6390 - val_accuracy: 0.0588\n",
      "Epoch 9331/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.3904 - accuracy: 0.0000e+00 - val_loss: 135.9435 - val_accuracy: 0.0000e+00\n",
      "Epoch 9332/10000\n",
      "64/64 [==============================] - 0s 233us/step - loss: 27.7643 - accuracy: 0.0000e+00 - val_loss: 138.2907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9333/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 23.8034 - accuracy: 0.0156 - val_loss: 139.7840 - val_accuracy: 0.0588\n",
      "Epoch 9334/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3650 - accuracy: 0.0000e+00 - val_loss: 139.9325 - val_accuracy: 0.0588\n",
      "Epoch 9335/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3023 - accuracy: 0.0156 - val_loss: 137.6187 - val_accuracy: 0.0588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9336/10000\n",
      "64/64 [==============================] - 0s 133us/step - loss: 22.5096 - accuracy: 0.0000e+00 - val_loss: 137.7491 - val_accuracy: 0.0000e+00\n",
      "Epoch 9337/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 37.0367 - accuracy: 0.0000e+00 - val_loss: 132.6666 - val_accuracy: 0.0000e+00\n",
      "Epoch 9338/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4101 - accuracy: 0.0156 - val_loss: 130.3137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9339/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9300 - accuracy: 0.0156 - val_loss: 131.1769 - val_accuracy: 0.0000e+00\n",
      "Epoch 9340/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8174 - accuracy: 0.0156 - val_loss: 140.7480 - val_accuracy: 0.0588\n",
      "Epoch 9341/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4987 - accuracy: 0.0000e+00 - val_loss: 149.3003 - val_accuracy: 0.0000e+00\n",
      "Epoch 9342/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3550 - accuracy: 0.0156 - val_loss: 157.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 9343/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3311 - accuracy: 0.0312 - val_loss: 155.5928 - val_accuracy: 0.0000e+00\n",
      "Epoch 9344/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.8287 - accuracy: 0.0469 - val_loss: 153.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 9345/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.4024 - accuracy: 0.0156 - val_loss: 148.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 9346/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6133 - accuracy: 0.0312 - val_loss: 148.1778 - val_accuracy: 0.0588\n",
      "Epoch 9347/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1211 - accuracy: 0.0156 - val_loss: 147.2075 - val_accuracy: 0.0588\n",
      "Epoch 9348/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 16.4060 - accuracy: 0.0000e+00 - val_loss: 142.8625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9349/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8895 - accuracy: 0.0000e+00 - val_loss: 135.4067 - val_accuracy: 0.0000e+00\n",
      "Epoch 9350/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.0260 - accuracy: 0.0469 - val_loss: 130.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 9351/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 21.9426 - accuracy: 0.0156 - val_loss: 130.4905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9352/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0145 - accuracy: 0.0000e+00 - val_loss: 131.4935 - val_accuracy: 0.0000e+00\n",
      "Epoch 9353/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3313 - accuracy: 0.0312 - val_loss: 131.4951 - val_accuracy: 0.0588\n",
      "Epoch 9354/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.1274 - accuracy: 0.0000e+00 - val_loss: 128.3429 - val_accuracy: 0.0588\n",
      "Epoch 9355/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0287 - accuracy: 0.0156 - val_loss: 130.8170 - val_accuracy: 0.0588\n",
      "Epoch 9356/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.0188 - accuracy: 0.0156 - val_loss: 136.9536 - val_accuracy: 0.0000e+00\n",
      "Epoch 9357/10000\n",
      "64/64 [==============================] - 0s 159us/step - loss: 20.0650 - accuracy: 0.0000e+00 - val_loss: 141.0828 - val_accuracy: 0.0588\n",
      "Epoch 9358/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 13.9443 - accuracy: 0.0156 - val_loss: 153.4769 - val_accuracy: 0.0588\n",
      "Epoch 9359/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 35.0992 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 23.9378 - accuracy: 0.0000e+00 - val_loss: 159.9492 - val_accuracy: 0.0588\n",
      "Epoch 9360/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0730 - accuracy: 0.0156 - val_loss: 163.8134 - val_accuracy: 0.0588\n",
      "Epoch 9361/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 32.3728 - accuracy: 0.0312 - val_loss: 161.5114 - val_accuracy: 0.0588\n",
      "Epoch 9362/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3394 - accuracy: 0.0469 - val_loss: 151.7744 - val_accuracy: 0.0588\n",
      "Epoch 9363/10000\n",
      "64/64 [==============================] - ETA: 0s - loss: 17.2960 - accuracy: 0.0000e+0 - 0s 125us/step - loss: 17.0336 - accuracy: 0.0000e+00 - val_loss: 140.6897 - val_accuracy: 0.0588\n",
      "Epoch 9364/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.8954 - accuracy: 0.0156 - val_loss: 129.8827 - val_accuracy: 0.0000e+00\n",
      "Epoch 9365/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6937 - accuracy: 0.0000e+00 - val_loss: 124.2651 - val_accuracy: 0.0000e+00\n",
      "Epoch 9366/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.7129 - accuracy: 0.0312 - val_loss: 119.5273 - val_accuracy: 0.0000e+00\n",
      "Epoch 9367/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 21.5105 - accuracy: 0.0000e+00 - val_loss: 123.3154 - val_accuracy: 0.0000e+00\n",
      "Epoch 9368/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6598 - accuracy: 0.0156 - val_loss: 131.0537 - val_accuracy: 0.0000e+00\n",
      "Epoch 9369/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 12.3053 - accuracy: 0.0156 - val_loss: 139.8755 - val_accuracy: 0.0000e+00\n",
      "Epoch 9370/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1474 - accuracy: 0.0156 - val_loss: 142.0046 - val_accuracy: 0.0000e+00\n",
      "Epoch 9371/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.2360 - accuracy: 0.0000e+00 - val_loss: 139.2971 - val_accuracy: 0.0588\n",
      "Epoch 9372/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.7868 - accuracy: 0.0156 - val_loss: 137.1468 - val_accuracy: 0.0588\n",
      "Epoch 9373/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3837 - accuracy: 0.0000e+00 - val_loss: 139.9532 - val_accuracy: 0.0588\n",
      "Epoch 9374/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 36.4467 - accuracy: 0.0312 - val_loss: 137.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 9375/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3074 - accuracy: 0.0000e+00 - val_loss: 139.6114 - val_accuracy: 0.0588\n",
      "Epoch 9376/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 15.6816 - accuracy: 0.0000e+00 - val_loss: 137.7716 - val_accuracy: 0.0000e+00\n",
      "Epoch 9377/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 23.1563 - accuracy: 0.0156 - val_loss: 131.5168 - val_accuracy: 0.0588\n",
      "Epoch 9378/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.4397 - accuracy: 0.0156 - val_loss: 123.7218 - val_accuracy: 0.0588\n",
      "Epoch 9379/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3422 - accuracy: 0.0000e+00 - val_loss: 114.4220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9380/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0297 - accuracy: 0.0000e+00 - val_loss: 116.1890 - val_accuracy: 0.0588\n",
      "Epoch 9381/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2273 - accuracy: 0.0000e+00 - val_loss: 122.8354 - val_accuracy: 0.0000e+00\n",
      "Epoch 9382/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 21.9947 - accuracy: 0.0312 - val_loss: 127.4600 - val_accuracy: 0.0000e+00\n",
      "Epoch 9383/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 21.9994 - accuracy: 0.0000e+00 - val_loss: 131.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 9384/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.2972 - accuracy: 0.0156 - val_loss: 135.8981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9385/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7622 - accuracy: 0.0000e+00 - val_loss: 130.0345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9386/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2152 - accuracy: 0.0312 - val_loss: 126.1588 - val_accuracy: 0.0000e+00\n",
      "Epoch 9387/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.0687 - accuracy: 0.0156 - val_loss: 123.2048 - val_accuracy: 0.0000e+00\n",
      "Epoch 9388/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 15.0774 - accuracy: 0.0156 - val_loss: 125.3425 - val_accuracy: 0.0000e+00\n",
      "Epoch 9389/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5156 - accuracy: 0.0312 - val_loss: 125.0485 - val_accuracy: 0.0000e+00\n",
      "Epoch 9390/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 23.0308 - accuracy: 0.0000e+00 - val_loss: 123.7718 - val_accuracy: 0.0000e+00\n",
      "Epoch 9391/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8328 - accuracy: 0.0000e+00 - val_loss: 126.4999 - val_accuracy: 0.0588\n",
      "Epoch 9392/10000\n",
      "64/64 [==============================] - 0s 131us/step - loss: 16.6992 - accuracy: 0.0156 - val_loss: 135.3754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9393/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8679 - accuracy: 0.0156 - val_loss: 147.3156 - val_accuracy: 0.0588\n",
      "Epoch 9394/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8059 - accuracy: 0.0156 - val_loss: 151.3445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9395/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.3152 - accuracy: 0.0000e+00 - val_loss: 140.9558 - val_accuracy: 0.0000e+00\n",
      "Epoch 9396/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9172 - accuracy: 0.0312 - val_loss: 130.1905 - val_accuracy: 0.0000e+00\n",
      "Epoch 9397/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5762 - accuracy: 0.0156 - val_loss: 127.3525 - val_accuracy: 0.0588\n",
      "Epoch 9398/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 15.9456 - accuracy: 0.0312 - val_loss: 126.8088 - val_accuracy: 0.0000e+00\n",
      "Epoch 9399/10000\n",
      "64/64 [==============================] - 0s 92us/step - loss: 23.7574 - accuracy: 0.0000e+00 - val_loss: 134.5636 - val_accuracy: 0.0000e+00\n",
      "Epoch 9400/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0877 - accuracy: 0.0000e+00 - val_loss: 146.5981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9401/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7165 - accuracy: 0.0000e+00 - val_loss: 154.5640 - val_accuracy: 0.0588\n",
      "Epoch 9402/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1146 - accuracy: 0.0156 - val_loss: 154.2675 - val_accuracy: 0.0000e+00\n",
      "Epoch 9403/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9901 - accuracy: 0.0312 - val_loss: 146.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9404/10000\n",
      "64/64 [==============================] - 0s 135us/step - loss: 21.2143 - accuracy: 0.0000e+00 - val_loss: 132.9746 - val_accuracy: 0.0000e+00\n",
      "Epoch 9405/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3410 - accuracy: 0.0000e+00 - val_loss: 121.4505 - val_accuracy: 0.0000e+00\n",
      "Epoch 9406/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6460 - accuracy: 0.0312 - val_loss: 119.4339 - val_accuracy: 0.0000e+00\n",
      "Epoch 9407/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2022 - accuracy: 0.0000e+00 - val_loss: 127.5330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9408/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9804 - accuracy: 0.0000e+00 - val_loss: 135.7816 - val_accuracy: 0.0000e+00\n",
      "Epoch 9409/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.6419 - accuracy: 0.0312 - val_loss: 139.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 9410/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 29.7215 - accuracy: 0.0156 - val_loss: 140.4626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9411/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.0198 - accuracy: 0.0156 - val_loss: 138.0744 - val_accuracy: 0.0000e+00\n",
      "Epoch 9412/10000\n",
      "64/64 [==============================] - 0s 138us/step - loss: 9.6533 - accuracy: 0.0156 - val_loss: 132.0821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9413/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 22.6010 - accuracy: 0.0156 - val_loss: 126.4468 - val_accuracy: 0.0000e+00\n",
      "Epoch 9414/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8646 - accuracy: 0.0312 - val_loss: 123.1452 - val_accuracy: 0.0588\n",
      "Epoch 9415/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7029 - accuracy: 0.0000e+00 - val_loss: 125.5091 - val_accuracy: 0.0000e+00\n",
      "Epoch 9416/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8068 - accuracy: 0.0156 - val_loss: 124.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 9417/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7689 - accuracy: 0.0000e+00 - val_loss: 122.8942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9418/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1728 - accuracy: 0.0000e+00 - val_loss: 121.8331 - val_accuracy: 0.0000e+00\n",
      "Epoch 9419/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.0318 - accuracy: 0.0156 - val_loss: 130.4657 - val_accuracy: 0.0000e+00\n",
      "Epoch 9420/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7703 - accuracy: 0.0000e+00 - val_loss: 136.4258 - val_accuracy: 0.0000e+00\n",
      "Epoch 9421/10000\n",
      "64/64 [==============================] - 0s 94us/step - loss: 18.2746 - accuracy: 0.0312 - val_loss: 137.3190 - val_accuracy: 0.0000e+00\n",
      "Epoch 9422/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.0922 - accuracy: 0.0000e+00 - val_loss: 136.8799 - val_accuracy: 0.0000e+00\n",
      "Epoch 9423/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.3054 - accuracy: 0.0469 - val_loss: 135.3462 - val_accuracy: 0.0000e+00\n",
      "Epoch 9424/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 23.4953 - accuracy: 0.0000e+00 - val_loss: 135.9810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9425/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 38.0700 - accuracy: 0.0000e+00 - val_loss: 136.5094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9426/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3777 - accuracy: 0.0312 - val_loss: 137.7842 - val_accuracy: 0.0000e+00\n",
      "Epoch 9427/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2486 - accuracy: 0.0000e+00 - val_loss: 140.5335 - val_accuracy: 0.0000e+00\n",
      "Epoch 9428/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.2902 - accuracy: 0.0000e+00 - val_loss: 140.5871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9429/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 19.6532 - accuracy: 0.0000e+00 - val_loss: 138.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 9430/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7853 - accuracy: 0.0312 - val_loss: 133.9632 - val_accuracy: 0.0000e+00\n",
      "Epoch 9431/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.6777 - accuracy: 0.0625 - val_loss: 137.4742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9432/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 22.8746 - accuracy: 0.0156 - val_loss: 141.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 9433/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3528 - accuracy: 0.0312 - val_loss: 142.2772 - val_accuracy: 0.0000e+00\n",
      "Epoch 9434/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 22.8482 - accuracy: 0.0156 - val_loss: 144.9271 - val_accuracy: 0.0000e+00\n",
      "Epoch 9435/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.6097 - accuracy: 0.0156 - val_loss: 146.9514 - val_accuracy: 0.0000e+00\n",
      "Epoch 9436/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2103 - accuracy: 0.0156 - val_loss: 147.0387 - val_accuracy: 0.0000e+00\n",
      "Epoch 9437/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1616 - accuracy: 0.0000e+00 - val_loss: 147.5978 - val_accuracy: 0.0000e+00\n",
      "Epoch 9438/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8523 - accuracy: 0.0156 - val_loss: 145.0462 - val_accuracy: 0.0000e+00\n",
      "Epoch 9439/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4907 - accuracy: 0.0156 - val_loss: 137.5169 - val_accuracy: 0.0000e+00\n",
      "Epoch 9440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 16.8635 - accuracy: 0.0000e+00 - val_loss: 133.3889 - val_accuracy: 0.0000e+00\n",
      "Epoch 9441/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.4686 - accuracy: 0.0000e+00 - val_loss: 130.4378 - val_accuracy: 0.0000e+00\n",
      "Epoch 9442/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4807 - accuracy: 0.0156 - val_loss: 135.5933 - val_accuracy: 0.0000e+00\n",
      "Epoch 9443/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 18.3356 - accuracy: 0.0156 - val_loss: 140.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 9444/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.9929 - accuracy: 0.0000e+00 - val_loss: 140.3377 - val_accuracy: 0.0000e+00\n",
      "Epoch 9445/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.3042 - accuracy: 0.0000e+00 - val_loss: 138.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 9446/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3018 - accuracy: 0.0312 - val_loss: 133.4695 - val_accuracy: 0.0588\n",
      "Epoch 9447/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7344 - accuracy: 0.0000e+00 - val_loss: 127.3745 - val_accuracy: 0.0588\n",
      "Epoch 9448/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3065 - accuracy: 0.0469 - val_loss: 120.5393 - val_accuracy: 0.0588\n",
      "Epoch 9449/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5625 - accuracy: 0.0156 - val_loss: 125.5748 - val_accuracy: 0.0588\n",
      "Epoch 9450/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7201 - accuracy: 0.0156 - val_loss: 133.7931 - val_accuracy: 0.0000e+00\n",
      "Epoch 9451/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7005 - accuracy: 0.0000e+00 - val_loss: 135.2346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9452/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 14.7913 - accuracy: 0.0000e+00 - val_loss: 130.6634 - val_accuracy: 0.0000e+00\n",
      "Epoch 9453/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 17.7862 - accuracy: 0.0156 - val_loss: 128.5539 - val_accuracy: 0.0000e+00\n",
      "Epoch 9454/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4494 - accuracy: 0.0156 - val_loss: 126.5886 - val_accuracy: 0.0000e+00\n",
      "Epoch 9455/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 28.5622 - accuracy: 0.0156 - val_loss: 126.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 9456/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.5061 - accuracy: 0.0000e+00 - val_loss: 135.4645 - val_accuracy: 0.0000e+00\n",
      "Epoch 9457/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4091 - accuracy: 0.0312 - val_loss: 149.1889 - val_accuracy: 0.0588\n",
      "Epoch 9458/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 16.0781 - accuracy: 0.0469 - val_loss: 158.1911 - val_accuracy: 0.0588\n",
      "Epoch 9459/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0278 - accuracy: 0.0000e+00 - val_loss: 159.6813 - val_accuracy: 0.0000e+00\n",
      "Epoch 9460/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2484 - accuracy: 0.0000e+00 - val_loss: 154.7843 - val_accuracy: 0.0000e+00\n",
      "Epoch 9461/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3486 - accuracy: 0.0312 - val_loss: 147.1745 - val_accuracy: 0.0000e+00\n",
      "Epoch 9462/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0717 - accuracy: 0.0000e+00 - val_loss: 149.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 9463/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5827 - accuracy: 0.0312 - val_loss: 152.6942 - val_accuracy: 0.0000e+00\n",
      "Epoch 9464/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 26.6131 - accuracy: 0.0000e+00 - val_loss: 152.7184 - val_accuracy: 0.0000e+00\n",
      "Epoch 9465/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2820 - accuracy: 0.0000e+00 - val_loss: 149.0857 - val_accuracy: 0.0588\n",
      "Epoch 9466/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 22.7049 - accuracy: 0.0000e+00 - val_loss: 146.8370 - val_accuracy: 0.0588\n",
      "Epoch 9467/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4760 - accuracy: 0.0000e+00 - val_loss: 142.2498 - val_accuracy: 0.0000e+00\n",
      "Epoch 9468/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7115 - accuracy: 0.0156 - val_loss: 137.3424 - val_accuracy: 0.0588\n",
      "Epoch 9469/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 26.2676 - accuracy: 0.0000e+00 - val_loss: 137.2892 - val_accuracy: 0.0588\n",
      "Epoch 9470/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0132 - accuracy: 0.0156 - val_loss: 138.1625 - val_accuracy: 0.0000e+00\n",
      "Epoch 9471/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7258 - accuracy: 0.0000e+00 - val_loss: 135.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 9472/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1905 - accuracy: 0.0156 - val_loss: 130.6607 - val_accuracy: 0.0000e+00\n",
      "Epoch 9473/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.4749 - accuracy: 0.0156 - val_loss: 125.7033 - val_accuracy: 0.0000e+00\n",
      "Epoch 9474/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1087 - accuracy: 0.0156 - val_loss: 123.0724 - val_accuracy: 0.0000e+00\n",
      "Epoch 9475/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3429 - accuracy: 0.0156 - val_loss: 121.3980 - val_accuracy: 0.0000e+00\n",
      "Epoch 9476/10000\n",
      "64/64 [==============================] - 0s 124us/step - loss: 18.0451 - accuracy: 0.0156 - val_loss: 125.4302 - val_accuracy: 0.1176\n",
      "Epoch 9477/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9323 - accuracy: 0.0312 - val_loss: 135.3080 - val_accuracy: 0.0000e+00\n",
      "Epoch 9478/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5920 - accuracy: 0.0156 - val_loss: 141.7705 - val_accuracy: 0.0000e+00\n",
      "Epoch 9479/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6693 - accuracy: 0.0156 - val_loss: 143.6064 - val_accuracy: 0.0000e+00\n",
      "Epoch 9480/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 20.4002 - accuracy: 0.0156 - val_loss: 139.1672 - val_accuracy: 0.0000e+00\n",
      "Epoch 9481/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6724 - accuracy: 0.0000e+00 - val_loss: 135.4747 - val_accuracy: 0.0000e+00\n",
      "Epoch 9482/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2758 - accuracy: 0.0000e+00 - val_loss: 133.4862 - val_accuracy: 0.0588\n",
      "Epoch 9483/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2894 - accuracy: 0.0000e+00 - val_loss: 131.3665 - val_accuracy: 0.0588\n",
      "Epoch 9484/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.6264 - accuracy: 0.0000e+00 - val_loss: 132.5137 - val_accuracy: 0.0000e+00\n",
      "Epoch 9485/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9014 - accuracy: 0.0000e+00 - val_loss: 130.2893 - val_accuracy: 0.0000e+00\n",
      "Epoch 9486/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 21.3754 - accuracy: 0.0000e+00 - val_loss: 123.4266 - val_accuracy: 0.0000e+00\n",
      "Epoch 9487/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6568 - accuracy: 0.0156 - val_loss: 122.0494 - val_accuracy: 0.0000e+00\n",
      "Epoch 9488/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 43.4133 - accuracy: 0.0156 - val_loss: 138.7981 - val_accuracy: 0.0000e+00\n",
      "Epoch 9489/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7353 - accuracy: 0.0000e+00 - val_loss: 152.5535 - val_accuracy: 0.0588\n",
      "Epoch 9490/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2581 - accuracy: 0.0000e+00 - val_loss: 156.3584 - val_accuracy: 0.0000e+00\n",
      "Epoch 9491/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7499 - accuracy: 0.0000e+00 - val_loss: 143.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 9492/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.4358 - accuracy: 0.0156 - val_loss: 129.2463 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9493/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2718 - accuracy: 0.0156 - val_loss: 116.3912 - val_accuracy: 0.0588\n",
      "Epoch 9494/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2589 - accuracy: 0.0000e+00 - val_loss: 110.8985 - val_accuracy: 0.0588\n",
      "Epoch 9495/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6970 - accuracy: 0.0156 - val_loss: 114.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9496/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.7797 - accuracy: 0.0000e+00 - val_loss: 120.7313 - val_accuracy: 0.0588\n",
      "Epoch 9497/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7725 - accuracy: 0.0000e+00 - val_loss: 127.0014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9498/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 28.9039 - accuracy: 0.0156 - val_loss: 133.6115 - val_accuracy: 0.0000e+00\n",
      "Epoch 9499/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6696 - accuracy: 0.0156 - val_loss: 131.5528 - val_accuracy: 0.0000e+00\n",
      "Epoch 9500/10000\n",
      "64/64 [==============================] - 0s 84us/step - loss: 22.4007 - accuracy: 0.0000e+00 - val_loss: 127.8988 - val_accuracy: 0.0588\n",
      "Epoch 9501/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7867 - accuracy: 0.0000e+00 - val_loss: 129.7372 - val_accuracy: 0.0000e+00\n",
      "Epoch 9502/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.6406 - accuracy: 0.0312 - val_loss: 135.0619 - val_accuracy: 0.0000e+00\n",
      "Epoch 9503/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.6508 - accuracy: 0.0156 - val_loss: 142.7416 - val_accuracy: 0.0588\n",
      "Epoch 9504/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3412 - accuracy: 0.0000e+00 - val_loss: 147.3536 - val_accuracy: 0.0000e+00\n",
      "Epoch 9505/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2266 - accuracy: 0.0000e+00 - val_loss: 148.3519 - val_accuracy: 0.0588\n",
      "Epoch 9506/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.3063 - accuracy: 0.0312 - val_loss: 142.2272 - val_accuracy: 0.0000e+00\n",
      "Epoch 9507/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8626 - accuracy: 0.0000e+00 - val_loss: 133.3988 - val_accuracy: 0.0000e+00\n",
      "Epoch 9508/10000\n",
      "64/64 [==============================] - 0s 143us/step - loss: 21.9391 - accuracy: 0.0000e+00 - val_loss: 129.8163 - val_accuracy: 0.0000e+00\n",
      "Epoch 9509/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.4616 - accuracy: 0.0156 - val_loss: 130.6750 - val_accuracy: 0.0000e+00\n",
      "Epoch 9510/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2892 - accuracy: 0.0000e+00 - val_loss: 129.1019 - val_accuracy: 0.0000e+00\n",
      "Epoch 9511/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 19.1778 - accuracy: 0.0156 - val_loss: 129.5300 - val_accuracy: 0.0588\n",
      "Epoch 9512/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2730 - accuracy: 0.0312 - val_loss: 131.4408 - val_accuracy: 0.0588\n",
      "Epoch 9513/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.3327 - accuracy: 0.0000e+00 - val_loss: 137.0064 - val_accuracy: 0.0588\n",
      "Epoch 9514/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2967 - accuracy: 0.0000e+00 - val_loss: 138.9029 - val_accuracy: 0.0588\n",
      "Epoch 9515/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.6597 - accuracy: 0.0156 - val_loss: 136.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 9516/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6897 - accuracy: 0.0000e+00 - val_loss: 132.0880 - val_accuracy: 0.0000e+00\n",
      "Epoch 9517/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8454 - accuracy: 0.0000e+00 - val_loss: 131.8742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9518/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.5088 - accuracy: 0.0000e+00 - val_loss: 130.1310 - val_accuracy: 0.0000e+00\n",
      "Epoch 9519/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6760 - accuracy: 0.0000e+00 - val_loss: 125.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 9520/10000\n",
      "64/64 [==============================] - 0s 39us/step - loss: 21.3464 - accuracy: 0.0156 - val_loss: 121.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9521/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9787 - accuracy: 0.0312 - val_loss: 124.1401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9522/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 13.7618 - accuracy: 0.0156 - val_loss: 134.2997 - val_accuracy: 0.0000e+00\n",
      "Epoch 9523/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.4234 - accuracy: 0.0156 - val_loss: 149.6742 - val_accuracy: 0.0000e+00\n",
      "Epoch 9524/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7666 - accuracy: 0.0156 - val_loss: 156.0423 - val_accuracy: 0.0000e+00\n",
      "Epoch 9525/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 36.4585 - accuracy: 0.0156 - val_loss: 155.7731 - val_accuracy: 0.0000e+00\n",
      "Epoch 9526/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 34.9478 - accuracy: 0.0156 - val_loss: 153.9345 - val_accuracy: 0.0000e+00\n",
      "Epoch 9527/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.0338 - accuracy: 0.0000e+00 - val_loss: 146.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9528/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.9139 - accuracy: 0.0000e+00 - val_loss: 133.9011 - val_accuracy: 0.0588\n",
      "Epoch 9529/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.6671 - accuracy: 0.0156 - val_loss: 131.2085 - val_accuracy: 0.0588\n",
      "Epoch 9530/10000\n",
      "64/64 [==============================] - 0s 80us/step - loss: 19.1761 - accuracy: 0.0312 - val_loss: 135.8431 - val_accuracy: 0.0000e+00\n",
      "Epoch 9531/10000\n",
      "64/64 [==============================] - 0s 114us/step - loss: 18.3526 - accuracy: 0.0156 - val_loss: 137.4380 - val_accuracy: 0.0000e+00\n",
      "Epoch 9532/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.0078 - accuracy: 0.0000e+00 - val_loss: 139.2318 - val_accuracy: 0.0000e+00\n",
      "Epoch 9533/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3722 - accuracy: 0.0156 - val_loss: 140.9812 - val_accuracy: 0.0000e+00\n",
      "Epoch 9534/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.1562 - accuracy: 0.0000e+00 - val_loss: 142.6502 - val_accuracy: 0.0000e+00\n",
      "Epoch 9535/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0500 - accuracy: 0.0000e+00 - val_loss: 146.3104 - val_accuracy: 0.0000e+00\n",
      "Epoch 9536/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1636 - accuracy: 0.0000e+00 - val_loss: 149.3633 - val_accuracy: 0.0000e+00\n",
      "Epoch 9537/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7290 - accuracy: 0.0000e+00 - val_loss: 152.0723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9538/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6532 - accuracy: 0.0000e+00 - val_loss: 146.9951 - val_accuracy: 0.0000e+00\n",
      "Epoch 9539/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5881 - accuracy: 0.0000e+00 - val_loss: 148.4937 - val_accuracy: 0.0000e+00\n",
      "Epoch 9540/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 16.0123 - accuracy: 0.0156 - val_loss: 152.5758 - val_accuracy: 0.0000e+00\n",
      "Epoch 9541/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 23.5204 - accuracy: 0.0000e+00 - val_loss: 153.4950 - val_accuracy: 0.0000e+00\n",
      "Epoch 9542/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7447 - accuracy: 0.0000e+00 - val_loss: 149.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 9543/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6566 - accuracy: 0.0000e+00 - val_loss: 147.4500 - val_accuracy: 0.0000e+00\n",
      "Epoch 9544/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.3152 - accuracy: 0.0000e+00 - val_loss: 141.1362 - val_accuracy: 0.0000e+00\n",
      "Epoch 9545/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.2559 - accuracy: 0.0000e+00 - val_loss: 135.8235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9546/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 15.9037 - accuracy: 0.0000e+00 - val_loss: 132.1097 - val_accuracy: 0.0588\n",
      "Epoch 9547/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9970 - accuracy: 0.0000e+00 - val_loss: 132.6790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9548/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9162 - accuracy: 0.0312 - val_loss: 130.5340 - val_accuracy: 0.0000e+00\n",
      "Epoch 9549/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8587 - accuracy: 0.0156 - val_loss: 129.7221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9550/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8984 - accuracy: 0.0000e+00 - val_loss: 131.9940 - val_accuracy: 0.0000e+00\n",
      "Epoch 9551/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3144 - accuracy: 0.0312 - val_loss: 134.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 9552/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5007 - accuracy: 0.0312 - val_loss: 138.9328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9553/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8644 - accuracy: 0.0000e+00 - val_loss: 147.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9554/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 24.6905 - accuracy: 0.0312 - val_loss: 151.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9555/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.7712 - accuracy: 0.0000e+00 - val_loss: 149.1529 - val_accuracy: 0.0000e+00\n",
      "Epoch 9556/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9321 - accuracy: 0.0000e+00 - val_loss: 141.9575 - val_accuracy: 0.0000e+00\n",
      "Epoch 9557/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3005 - accuracy: 0.0312 - val_loss: 138.7481 - val_accuracy: 0.0000e+00\n",
      "Epoch 9558/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 31.7253 - accuracy: 0.0156 - val_loss: 144.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9559/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8256 - accuracy: 0.0000e+00 - val_loss: 152.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 9560/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 19.6770 - accuracy: 0.0000e+00 - val_loss: 155.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9561/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7074 - accuracy: 0.0156 - val_loss: 150.5550 - val_accuracy: 0.0000e+00\n",
      "Epoch 9562/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.9723 - accuracy: 0.0156 - val_loss: 136.6975 - val_accuracy: 0.0588\n",
      "Epoch 9563/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4877 - accuracy: 0.0625 - val_loss: 122.9612 - val_accuracy: 0.0588\n",
      "Epoch 9564/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 21.8946 - accuracy: 0.0156 - val_loss: 113.5810 - val_accuracy: 0.0000e+00\n",
      "Epoch 9565/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.6170 - accuracy: 0.0156 - val_loss: 111.2441 - val_accuracy: 0.0000e+00\n",
      "Epoch 9566/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 24.0944 - accuracy: 0.0156 - val_loss: 117.1437 - val_accuracy: 0.0000e+00\n",
      "Epoch 9567/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.8545 - accuracy: 0.0156 - val_loss: 121.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 9568/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1221 - accuracy: 0.0000e+00 - val_loss: 116.9240 - val_accuracy: 0.0000e+00\n",
      "Epoch 9569/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 26.9518 - accuracy: 0.0000e+00 - val_loss: 121.7171 - val_accuracy: 0.0588\n",
      "Epoch 9570/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8263 - accuracy: 0.0156 - val_loss: 129.7309 - val_accuracy: 0.0000e+00\n",
      "Epoch 9571/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3203 - accuracy: 0.0000e+00 - val_loss: 138.1782 - val_accuracy: 0.0000e+00\n",
      "Epoch 9572/10000\n",
      "64/64 [==============================] - 0s 144us/step - loss: 19.5814 - accuracy: 0.0000e+00 - val_loss: 148.2417 - val_accuracy: 0.0000e+00\n",
      "Epoch 9573/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.2748 - accuracy: 0.0156 - val_loss: 151.1748 - val_accuracy: 0.0000e+00\n",
      "Epoch 9574/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2159 - accuracy: 0.0000e+00 - val_loss: 153.2411 - val_accuracy: 0.0000e+00\n",
      "Epoch 9575/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 34.8425 - accuracy: 0.0156 - val_loss: 151.0099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9576/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.7267 - accuracy: 0.0000e+00 - val_loss: 140.8886 - val_accuracy: 0.0000e+00\n",
      "Epoch 9577/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.6857 - accuracy: 0.0000e+00 - val_loss: 123.5456 - val_accuracy: 0.0000e+00\n",
      "Epoch 9578/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.7130 - accuracy: 0.0156 - val_loss: 113.8012 - val_accuracy: 0.0000e+00\n",
      "Epoch 9579/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.2546 - accuracy: 0.0156 - val_loss: 115.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9580/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.8775 - accuracy: 0.0000e+00 - val_loss: 117.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9581/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 15.2289 - accuracy: 0.0156 - val_loss: 117.0606 - val_accuracy: 0.0000e+00\n",
      "Epoch 9582/10000\n",
      "64/64 [==============================] - 0s 95us/step - loss: 23.5066 - accuracy: 0.0156 - val_loss: 114.7731 - val_accuracy: 0.0000e+00\n",
      "Epoch 9583/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 34.5634 - accuracy: 0.0156 - val_loss: 114.6118 - val_accuracy: 0.0000e+00\n",
      "Epoch 9584/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0638 - accuracy: 0.0312 - val_loss: 127.8053 - val_accuracy: 0.0000e+00\n",
      "Epoch 9585/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.7439 - accuracy: 0.0156 - val_loss: 135.9445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9586/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.8260 - accuracy: 0.0000e+00 - val_loss: 145.4580 - val_accuracy: 0.0000e+00\n",
      "Epoch 9587/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0336 - accuracy: 0.0000e+00 - val_loss: 144.8216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9588/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2820 - accuracy: 0.0000e+00 - val_loss: 140.2228 - val_accuracy: 0.0000e+00\n",
      "Epoch 9589/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5298 - accuracy: 0.0156 - val_loss: 137.2800 - val_accuracy: 0.0000e+00\n",
      "Epoch 9590/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8461 - accuracy: 0.0156 - val_loss: 132.5208 - val_accuracy: 0.0000e+00\n",
      "Epoch 9591/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3019 - accuracy: 0.0469 - val_loss: 129.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 9592/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 27.0007 - accuracy: 0.0156 - val_loss: 136.0620 - val_accuracy: 0.0000e+00\n",
      "Epoch 9593/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0619 - accuracy: 0.0000e+00 - val_loss: 144.0520 - val_accuracy: 0.0000e+00\n",
      "Epoch 9594/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7199 - accuracy: 0.0000e+00 - val_loss: 147.4186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9595/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.8043 - accuracy: 0.0000e+00 - val_loss: 142.0474 - val_accuracy: 0.0000e+00\n",
      "Epoch 9596/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8713 - accuracy: 0.0156 - val_loss: 128.2984 - val_accuracy: 0.0000e+00\n",
      "Epoch 9597/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 138us/step - loss: 13.0742 - accuracy: 0.0156 - val_loss: 121.5031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9598/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.6758 - accuracy: 0.0312 - val_loss: 121.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 9599/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9288 - accuracy: 0.0312 - val_loss: 132.3999 - val_accuracy: 0.0000e+00\n",
      "Epoch 9600/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 18.8370 - accuracy: 0.0000e+00 - val_loss: 139.8072 - val_accuracy: 0.0000e+00\n",
      "Epoch 9601/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5790 - accuracy: 0.0156 - val_loss: 139.5142 - val_accuracy: 0.0588\n",
      "Epoch 9602/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.6186 - accuracy: 0.0156 - val_loss: 136.5188 - val_accuracy: 0.0588\n",
      "Epoch 9603/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.0275 - accuracy: 0.0312 - val_loss: 129.6261 - val_accuracy: 0.0000e+00\n",
      "Epoch 9604/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3730 - accuracy: 0.0156 - val_loss: 128.7367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9605/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5070 - accuracy: 0.0000e+00 - val_loss: 131.8147 - val_accuracy: 0.0000e+00\n",
      "Epoch 9606/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 28.5758 - accuracy: 0.0000e+00 - val_loss: 141.6922 - val_accuracy: 0.0000e+00\n",
      "Epoch 9607/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.9255 - accuracy: 0.0469 - val_loss: 143.6212 - val_accuracy: 0.0000e+00\n",
      "Epoch 9608/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.3474 - accuracy: 0.0312 - val_loss: 140.7235 - val_accuracy: 0.0000e+00\n",
      "Epoch 9609/10000\n",
      "64/64 [==============================] - 0s 90us/step - loss: 21.1425 - accuracy: 0.0000e+00 - val_loss: 137.4821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9610/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8142 - accuracy: 0.0000e+00 - val_loss: 138.0760 - val_accuracy: 0.0588\n",
      "Epoch 9611/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.7628 - accuracy: 0.0000e+00 - val_loss: 140.7047 - val_accuracy: 0.0000e+00\n",
      "Epoch 9612/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.7696 - accuracy: 0.0156 - val_loss: 142.6678 - val_accuracy: 0.0000e+00\n",
      "Epoch 9613/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2798 - accuracy: 0.0156 - val_loss: 143.6620 - val_accuracy: 0.0000e+00\n",
      "Epoch 9614/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3040 - accuracy: 0.0156 - val_loss: 135.5154 - val_accuracy: 0.0000e+00\n",
      "Epoch 9615/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4195 - accuracy: 0.0156 - val_loss: 126.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 9616/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5545 - accuracy: 0.0156 - val_loss: 121.9031 - val_accuracy: 0.0000e+00\n",
      "Epoch 9617/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5081 - accuracy: 0.0000e+00 - val_loss: 122.2594 - val_accuracy: 0.0000e+00\n",
      "Epoch 9618/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.9956 - accuracy: 0.0469 - val_loss: 126.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9619/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5616 - accuracy: 0.0312 - val_loss: 129.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9620/10000\n",
      "64/64 [==============================] - 0s 137us/step - loss: 23.9332 - accuracy: 0.0312 - val_loss: 134.4330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9621/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3451 - accuracy: 0.0000e+00 - val_loss: 137.5805 - val_accuracy: 0.0000e+00\n",
      "Epoch 9622/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 17.5234 - accuracy: 0.0156 - val_loss: 139.9554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9623/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.1663 - accuracy: 0.0469 - val_loss: 135.0697 - val_accuracy: 0.0000e+00\n",
      "Epoch 9624/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2881 - accuracy: 0.0000e+00 - val_loss: 130.4191 - val_accuracy: 0.0000e+00\n",
      "Epoch 9625/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5524 - accuracy: 0.0156 - val_loss: 129.9969 - val_accuracy: 0.0000e+00\n",
      "Epoch 9626/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.0116 - accuracy: 0.0156 - val_loss: 132.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 9627/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.3288 - accuracy: 0.0156 - val_loss: 136.3149 - val_accuracy: 0.0000e+00\n",
      "Epoch 9628/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.7623 - accuracy: 0.0000e+00 - val_loss: 140.3665 - val_accuracy: 0.0000e+00\n",
      "Epoch 9629/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6475 - accuracy: 0.0156 - val_loss: 145.9146 - val_accuracy: 0.0588\n",
      "Epoch 9630/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.4489 - accuracy: 0.0000e+00 - val_loss: 145.0930 - val_accuracy: 0.0588\n",
      "Epoch 9631/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7339 - accuracy: 0.0156 - val_loss: 139.2375 - val_accuracy: 0.0000e+00\n",
      "Epoch 9632/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0607 - accuracy: 0.0000e+00 - val_loss: 137.3117 - val_accuracy: 0.0000e+00\n",
      "Epoch 9633/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.5461 - accuracy: 0.0312 - val_loss: 140.2111 - val_accuracy: 0.0000e+00\n",
      "Epoch 9634/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4738 - accuracy: 0.0156 - val_loss: 141.9952 - val_accuracy: 0.0000e+00\n",
      "Epoch 9635/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 39.4474 - accuracy: 0.0000e+00 - val_loss: 140.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 9636/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6460 - accuracy: 0.0000e+00 - val_loss: 134.6365 - val_accuracy: 0.0588\n",
      "Epoch 9637/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.9493 - accuracy: 0.0312 - val_loss: 138.7185 - val_accuracy: 0.0000e+00\n",
      "Epoch 9638/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9025 - accuracy: 0.0156 - val_loss: 140.4022 - val_accuracy: 0.0000e+00\n",
      "Epoch 9639/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2751 - accuracy: 0.0156 - val_loss: 141.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 9640/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.2451 - accuracy: 0.0000e+00 - val_loss: 141.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 9641/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7740 - accuracy: 0.0000e+00 - val_loss: 142.1684 - val_accuracy: 0.0000e+00\n",
      "Epoch 9642/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3405 - accuracy: 0.0000e+00 - val_loss: 146.2049 - val_accuracy: 0.0000e+00\n",
      "Epoch 9643/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.5372 - accuracy: 0.0000e+00 - val_loss: 149.3615 - val_accuracy: 0.0000e+00\n",
      "Epoch 9644/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.3600 - accuracy: 0.0000e+00 - val_loss: 151.3454 - val_accuracy: 0.0588\n",
      "Epoch 9645/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.6208 - accuracy: 0.0000e+00 - val_loss: 148.7870 - val_accuracy: 0.0588\n",
      "Epoch 9646/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6997 - accuracy: 0.0312 - val_loss: 137.8399 - val_accuracy: 0.0000e+00\n",
      "Epoch 9647/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.6328 - accuracy: 0.0000e+00 - val_loss: 128.9281 - val_accuracy: 0.0000e+00\n",
      "Epoch 9648/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.7658 - accuracy: 0.0000e+00 - val_loss: 128.2541 - val_accuracy: 0.0000e+00\n",
      "Epoch 9649/10000\n",
      "64/64 [==============================] - 0s 500us/step - loss: 22.2431 - accuracy: 0.0156 - val_loss: 131.7681 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9650/10000\n",
      "64/64 [==============================] - 0s 437us/step - loss: 18.3781 - accuracy: 0.0156 - val_loss: 142.5066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9651/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2184 - accuracy: 0.0000e+00 - val_loss: 148.1580 - val_accuracy: 0.0588\n",
      "Epoch 9652/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.5934 - accuracy: 0.0156 - val_loss: 144.1215 - val_accuracy: 0.0588\n",
      "Epoch 9653/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.3485 - accuracy: 0.0000e+00 - val_loss: 143.0822 - val_accuracy: 0.0000e+00\n",
      "Epoch 9654/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.9469 - accuracy: 0.0000e+00 - val_loss: 141.1400 - val_accuracy: 0.0000e+00\n",
      "Epoch 9655/10000\n",
      "64/64 [==============================] - 0s 196us/step - loss: 20.8715 - accuracy: 0.0156 - val_loss: 141.0754 - val_accuracy: 0.0000e+00\n",
      "Epoch 9656/10000\n",
      "64/64 [==============================] - 0s 79us/step - loss: 12.7063 - accuracy: 0.0312 - val_loss: 142.5567 - val_accuracy: 0.0000e+00\n",
      "Epoch 9657/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.2150 - accuracy: 0.0000e+00 - val_loss: 142.5790 - val_accuracy: 0.0000e+00\n",
      "Epoch 9658/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0658 - accuracy: 0.0156 - val_loss: 141.2871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9659/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6056 - accuracy: 0.0156 - val_loss: 143.8917 - val_accuracy: 0.0000e+00\n",
      "Epoch 9660/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.6400 - accuracy: 0.0000e+00 - val_loss: 152.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 9661/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 16.6307 - accuracy: 0.0156 - val_loss: 152.2770 - val_accuracy: 0.0000e+00\n",
      "Epoch 9662/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 31.2009 - accuracy: 0.0312 - val_loss: 144.6503 - val_accuracy: 0.0000e+00\n",
      "Epoch 9663/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 18.8838 - accuracy: 0.0000e+00 - val_loss: 136.4949 - val_accuracy: 0.0000e+00\n",
      "Epoch 9664/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.8392 - accuracy: 0.0156 - val_loss: 133.6360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9665/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9445 - accuracy: 0.0156 - val_loss: 138.3361 - val_accuracy: 0.0000e+00\n",
      "Epoch 9666/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 23.0397 - accuracy: 0.0156 - val_loss: 150.2174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9667/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 11.9288 - accuracy: 0.0000e+00 - val_loss: 152.7059 - val_accuracy: 0.0000e+00\n",
      "Epoch 9668/10000\n",
      "64/64 [==============================] - 0s 148us/step - loss: 15.0433 - accuracy: 0.0156 - val_loss: 150.2316 - val_accuracy: 0.0000e+00\n",
      "Epoch 9669/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.6672 - accuracy: 0.0000e+00 - val_loss: 147.4448 - val_accuracy: 0.0000e+00\n",
      "Epoch 9670/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.8997 - accuracy: 0.0156 - val_loss: 144.8831 - val_accuracy: 0.0000e+00\n",
      "Epoch 9671/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.8011 - accuracy: 0.0156 - val_loss: 143.9780 - val_accuracy: 0.0000e+00\n",
      "Epoch 9672/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2516 - accuracy: 0.0156 - val_loss: 141.8350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9673/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.4006 - accuracy: 0.0000e+00 - val_loss: 136.5747 - val_accuracy: 0.0000e+00\n",
      "Epoch 9674/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.3955 - accuracy: 0.0000e+00 - val_loss: 128.9431 - val_accuracy: 0.0000e+00\n",
      "Epoch 9675/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.3822 - accuracy: 0.0156 - val_loss: 123.8230 - val_accuracy: 0.0000e+00\n",
      "Epoch 9676/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5445 - accuracy: 0.0156 - val_loss: 121.0915 - val_accuracy: 0.0000e+00\n",
      "Epoch 9677/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.7936 - accuracy: 0.0156 - val_loss: 122.0554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9678/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2756 - accuracy: 0.0000e+00 - val_loss: 126.5868 - val_accuracy: 0.0000e+00\n",
      "Epoch 9679/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.5181 - accuracy: 0.0156 - val_loss: 132.3695 - val_accuracy: 0.0000e+00\n",
      "Epoch 9680/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.4693 - accuracy: 0.0000e+00 - val_loss: 133.2804 - val_accuracy: 0.0000e+00\n",
      "Epoch 9681/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.2150 - accuracy: 0.0312 - val_loss: 134.6925 - val_accuracy: 0.0588\n",
      "Epoch 9682/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.1108 - accuracy: 0.0000e+00 - val_loss: 132.3401 - val_accuracy: 0.0000e+00\n",
      "Epoch 9683/10000\n",
      "64/64 [==============================] - 0s 103us/step - loss: 15.9856 - accuracy: 0.0000e+00 - val_loss: 126.3709 - val_accuracy: 0.0000e+00\n",
      "Epoch 9684/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.3519 - accuracy: 0.0156 - val_loss: 122.2169 - val_accuracy: 0.0000e+00\n",
      "Epoch 9685/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 13.1301 - accuracy: 0.0000e+00 - val_loss: 117.6631 - val_accuracy: 0.0000e+00\n",
      "Epoch 9686/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4877 - accuracy: 0.0312 - val_loss: 121.1241 - val_accuracy: 0.0000e+00\n",
      "Epoch 9687/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 35.6399 - accuracy: 0.0000e+00 - val_loss: 130.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 9688/10000\n",
      "64/64 [==============================] - 0s 149us/step - loss: 20.6241 - accuracy: 0.0156 - val_loss: 143.8158 - val_accuracy: 0.0000e+00\n",
      "Epoch 9689/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8647 - accuracy: 0.0156 - val_loss: 145.8802 - val_accuracy: 0.0000e+00\n",
      "Epoch 9690/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6140 - accuracy: 0.0312 - val_loss: 141.1215 - val_accuracy: 0.0000e+00\n",
      "Epoch 9691/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.5033 - accuracy: 0.0156 - val_loss: 127.0950 - val_accuracy: 0.0000e+00\n",
      "Epoch 9692/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 19.8250 - accuracy: 0.0156 - val_loss: 115.4260 - val_accuracy: 0.0000e+00\n",
      "Epoch 9693/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.1409 - accuracy: 0.0000e+00 - val_loss: 121.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 9694/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.4123 - accuracy: 0.0000e+00 - val_loss: 136.0654 - val_accuracy: 0.0000e+00\n",
      "Epoch 9695/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 14.0940 - accuracy: 0.0156 - val_loss: 145.9960 - val_accuracy: 0.0000e+00\n",
      "Epoch 9696/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2360 - accuracy: 0.0156 - val_loss: 142.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9697/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.5166 - accuracy: 0.0156 - val_loss: 131.4042 - val_accuracy: 0.0000e+00\n",
      "Epoch 9698/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.1915 - accuracy: 0.0469 - val_loss: 128.7970 - val_accuracy: 0.0000e+00\n",
      "Epoch 9699/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 26.0266 - accuracy: 0.0000e+00 - val_loss: 138.8201 - val_accuracy: 0.0588\n",
      "Epoch 9700/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.4714 - accuracy: 0.0000e+00 - val_loss: 147.8474 - val_accuracy: 0.0588\n",
      "Epoch 9701/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3434 - accuracy: 0.0312 - val_loss: 152.8841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9702/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.2210 - accuracy: 0.0000e+00 - val_loss: 154.7635 - val_accuracy: 0.0000e+00\n",
      "Epoch 9703/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.1815 - accuracy: 0.0000e+00 - val_loss: 148.8105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9704/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.0750 - accuracy: 0.0312 - val_loss: 147.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 9705/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2921 - accuracy: 0.0000e+00 - val_loss: 142.5445 - val_accuracy: 0.0000e+00\n",
      "Epoch 9706/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7425 - accuracy: 0.0156 - val_loss: 141.7613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9707/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2352 - accuracy: 0.0156 - val_loss: 142.6311 - val_accuracy: 0.0000e+00\n",
      "Epoch 9708/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.4580 - accuracy: 0.0156 - val_loss: 138.2709 - val_accuracy: 0.0000e+00\n",
      "Epoch 9709/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9332 - accuracy: 0.0156 - val_loss: 133.2899 - val_accuracy: 0.0000e+00\n",
      "Epoch 9710/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5134 - accuracy: 0.0156 - val_loss: 130.5070 - val_accuracy: 0.0000e+00\n",
      "Epoch 9711/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.4467 - accuracy: 0.0156 - val_loss: 131.0331 - val_accuracy: 0.0588\n",
      "Epoch 9712/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0413 - accuracy: 0.0000e+00 - val_loss: 131.3262 - val_accuracy: 0.0588\n",
      "Epoch 9713/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6306 - accuracy: 0.0156 - val_loss: 136.9874 - val_accuracy: 0.0000e+00\n",
      "Epoch 9714/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 35.6265 - accuracy: 0.0000e+00 - val_loss: 136.3996 - val_accuracy: 0.0588\n",
      "Epoch 9715/10000\n",
      "64/64 [==============================] - 0s 82us/step - loss: 27.8397 - accuracy: 0.0156 - val_loss: 131.1520 - val_accuracy: 0.0588\n",
      "Epoch 9716/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 19.5523 - accuracy: 0.0000e+00 - val_loss: 125.9970 - val_accuracy: 0.0588\n",
      "Epoch 9717/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3287 - accuracy: 0.0312 - val_loss: 122.0187 - val_accuracy: 0.0588\n",
      "Epoch 9718/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 21.3565 - accuracy: 0.0000e+00 - val_loss: 120.8518 - val_accuracy: 0.0588\n",
      "Epoch 9719/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2208 - accuracy: 0.0156 - val_loss: 122.9248 - val_accuracy: 0.0000e+00\n",
      "Epoch 9720/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.7707 - accuracy: 0.0000e+00 - val_loss: 129.2215 - val_accuracy: 0.0000e+00\n",
      "Epoch 9721/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0736 - accuracy: 0.0469 - val_loss: 138.2783 - val_accuracy: 0.0000e+00\n",
      "Epoch 9722/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.1067 - accuracy: 0.0000e+00 - val_loss: 143.1433 - val_accuracy: 0.0000e+00\n",
      "Epoch 9723/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.5284 - accuracy: 0.0312 - val_loss: 140.7862 - val_accuracy: 0.0000e+00\n",
      "Epoch 9724/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5651 - accuracy: 0.0156 - val_loss: 134.4388 - val_accuracy: 0.0000e+00\n",
      "Epoch 9725/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 13.3886 - accuracy: 0.0000e+00 - val_loss: 128.5947 - val_accuracy: 0.0000e+00\n",
      "Epoch 9726/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.6885 - accuracy: 0.0156 - val_loss: 131.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 9727/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 25.2282 - accuracy: 0.0156 - val_loss: 143.5344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9728/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0165 - accuracy: 0.0156 - val_loss: 154.8995 - val_accuracy: 0.0000e+00\n",
      "Epoch 9729/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5825 - accuracy: 0.0000e+00 - val_loss: 159.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 9730/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.1521 - accuracy: 0.0156 - val_loss: 155.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 9731/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.3507 - accuracy: 0.0000e+00 - val_loss: 146.9643 - val_accuracy: 0.0000e+00\n",
      "Epoch 9732/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.6017 - accuracy: 0.0156 - val_loss: 142.2554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9733/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.5762 - accuracy: 0.0156 - val_loss: 142.1250 - val_accuracy: 0.0000e+00\n",
      "Epoch 9734/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.8523 - accuracy: 0.0156 - val_loss: 138.5165 - val_accuracy: 0.0000e+00\n",
      "Epoch 9735/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9875 - accuracy: 0.0156 - val_loss: 129.4872 - val_accuracy: 0.0588\n",
      "Epoch 9736/10000\n",
      "64/64 [==============================] - 0s 150us/step - loss: 19.2322 - accuracy: 0.0312 - val_loss: 126.1917 - val_accuracy: 0.0588\n",
      "Epoch 9737/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.6551 - accuracy: 0.0156 - val_loss: 130.8052 - val_accuracy: 0.0588\n",
      "Epoch 9738/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2896 - accuracy: 0.0156 - val_loss: 136.0577 - val_accuracy: 0.0588\n",
      "Epoch 9739/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 16.2396 - accuracy: 0.0156 - val_loss: 136.9598 - val_accuracy: 0.0588\n",
      "Epoch 9740/10000\n",
      "64/64 [==============================] - 0s 123us/step - loss: 12.7105 - accuracy: 0.0156 - val_loss: 141.0604 - val_accuracy: 0.0588\n",
      "Epoch 9741/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2622 - accuracy: 0.0156 - val_loss: 140.5823 - val_accuracy: 0.0588\n",
      "Epoch 9742/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 19.3747 - accuracy: 0.0156 - val_loss: 138.4856 - val_accuracy: 0.0588\n",
      "Epoch 9743/10000\n",
      "64/64 [==============================] - 0s 151us/step - loss: 23.8729 - accuracy: 0.0156 - val_loss: 132.8997 - val_accuracy: 0.0588\n",
      "Epoch 9744/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.6813 - accuracy: 0.0312 - val_loss: 127.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9745/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2201 - accuracy: 0.0156 - val_loss: 114.7105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9746/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5964 - accuracy: 0.0000e+00 - val_loss: 106.6159 - val_accuracy: 0.0000e+00\n",
      "Epoch 9747/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0348 - accuracy: 0.0000e+00 - val_loss: 108.2062 - val_accuracy: 0.0000e+00\n",
      "Epoch 9748/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.2951 - accuracy: 0.0312 - val_loss: 109.5078 - val_accuracy: 0.0000e+00\n",
      "Epoch 9749/10000\n",
      "64/64 [==============================] - 0s 96us/step - loss: 20.4518 - accuracy: 0.0156 - val_loss: 112.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 9750/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.7600 - accuracy: 0.0000e+00 - val_loss: 114.1155 - val_accuracy: 0.0000e+00\n",
      "Epoch 9751/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 40.7644 - accuracy: 0.0000e+00 - val_loss: 119.6841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9752/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.1006 - accuracy: 0.0156 - val_loss: 130.6314 - val_accuracy: 0.0000e+00\n",
      "Epoch 9753/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7530 - accuracy: 0.0156 - val_loss: 141.1164 - val_accuracy: 0.0000e+00\n",
      "Epoch 9754/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9197 - accuracy: 0.0000e+00 - val_loss: 142.9347 - val_accuracy: 0.0588\n",
      "Epoch 9755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 146us/step - loss: 25.4191 - accuracy: 0.0156 - val_loss: 144.0330 - val_accuracy: 0.0588\n",
      "Epoch 9756/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 20.7748 - accuracy: 0.0000e+00 - val_loss: 147.8074 - val_accuracy: 0.0000e+00\n",
      "Epoch 9757/10000\n",
      "64/64 [==============================] - 0s 139us/step - loss: 12.1885 - accuracy: 0.0000e+00 - val_loss: 151.3453 - val_accuracy: 0.0000e+00\n",
      "Epoch 9758/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1946 - accuracy: 0.0312 - val_loss: 148.7174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9759/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.8838 - accuracy: 0.0156 - val_loss: 142.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 9760/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 36.0210 - accuracy: 0.0312 - val_loss: 144.5968 - val_accuracy: 0.0588\n",
      "Epoch 9761/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.4783 - accuracy: 0.0156 - val_loss: 146.6937 - val_accuracy: 0.0000e+00\n",
      "Epoch 9762/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.2981 - accuracy: 0.0156 - val_loss: 139.4444 - val_accuracy: 0.0588\n",
      "Epoch 9763/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.8252 - accuracy: 0.0000e+00 - val_loss: 132.5113 - val_accuracy: 0.0000e+00\n",
      "Epoch 9764/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.8942 - accuracy: 0.0000e+00 - val_loss: 130.5430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9765/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0345 - accuracy: 0.0156 - val_loss: 133.3089 - val_accuracy: 0.0000e+00\n",
      "Epoch 9766/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 34.4321 - accuracy: 0.0156 - val_loss: 140.2267 - val_accuracy: 0.0000e+00\n",
      "Epoch 9767/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.2799 - accuracy: 0.0000e+00 - val_loss: 143.9220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9768/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.1345 - accuracy: 0.0156 - val_loss: 141.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 9769/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.4129 - accuracy: 0.0156 - val_loss: 142.3872 - val_accuracy: 0.0000e+00\n",
      "Epoch 9770/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 31.4136 - accuracy: 0.0156 - val_loss: 143.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 9771/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3914 - accuracy: 0.0156 - val_loss: 139.1939 - val_accuracy: 0.0000e+00\n",
      "Epoch 9772/10000\n",
      "64/64 [==============================] - 0s 142us/step - loss: 26.0125 - accuracy: 0.0156 - val_loss: 130.4519 - val_accuracy: 0.0000e+00\n",
      "Epoch 9773/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.5652 - accuracy: 0.0000e+00 - val_loss: 128.3191 - val_accuracy: 0.0588\n",
      "Epoch 9774/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.9943 - accuracy: 0.0312 - val_loss: 133.5650 - val_accuracy: 0.0000e+00\n",
      "Epoch 9775/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.3976 - accuracy: 0.0156 - val_loss: 135.4029 - val_accuracy: 0.0000e+00\n",
      "Epoch 9776/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3497 - accuracy: 0.0000e+00 - val_loss: 135.5746 - val_accuracy: 0.0000e+00\n",
      "Epoch 9777/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9721 - accuracy: 0.0156 - val_loss: 140.0043 - val_accuracy: 0.0000e+00\n",
      "Epoch 9778/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.5376 - accuracy: 0.0312 - val_loss: 140.6359 - val_accuracy: 0.0000e+00\n",
      "Epoch 9779/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3276 - accuracy: 0.0156 - val_loss: 142.9469 - val_accuracy: 0.0588\n",
      "Epoch 9780/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.2765 - accuracy: 0.0312 - val_loss: 140.9481 - val_accuracy: 0.0000e+00\n",
      "Epoch 9781/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 18.1214 - accuracy: 0.0000e+00 - val_loss: 136.8664 - val_accuracy: 0.0000e+00\n",
      "Epoch 9782/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 18.1388 - accuracy: 0.0156 - val_loss: 129.2142 - val_accuracy: 0.0588\n",
      "Epoch 9783/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5156 - accuracy: 0.0156 - val_loss: 129.8000 - val_accuracy: 0.0588\n",
      "Epoch 9784/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.5142 - accuracy: 0.0000e+00 - val_loss: 128.9942 - val_accuracy: 0.0588\n",
      "Epoch 9785/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 27.3642 - accuracy: 0.0156 - val_loss: 137.7126 - val_accuracy: 0.0000e+00\n",
      "Epoch 9786/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.0383 - accuracy: 0.0000e+00 - val_loss: 138.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 9787/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 26.4812 - accuracy: 0.0312 - val_loss: 138.9723 - val_accuracy: 0.0000e+00\n",
      "Epoch 9788/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.3973 - accuracy: 0.0000e+00 - val_loss: 140.8858 - val_accuracy: 0.0000e+00\n",
      "Epoch 9789/10000\n",
      "64/64 [==============================] - 0s 146us/step - loss: 18.3977 - accuracy: 0.0000e+00 - val_loss: 143.7853 - val_accuracy: 0.0000e+00\n",
      "Epoch 9790/10000\n",
      "64/64 [==============================] - 0s 117us/step - loss: 22.7707 - accuracy: 0.0156 - val_loss: 143.7171 - val_accuracy: 0.0000e+00\n",
      "Epoch 9791/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0416 - accuracy: 0.0625 - val_loss: 138.7841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9792/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.6097 - accuracy: 0.0000e+00 - val_loss: 134.2821 - val_accuracy: 0.0000e+00\n",
      "Epoch 9793/10000\n",
      "64/64 [==============================] - 0s 116us/step - loss: 26.9096 - accuracy: 0.0000e+00 - val_loss: 131.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 9794/10000\n",
      "64/64 [==============================] - 0s 147us/step - loss: 21.6334 - accuracy: 0.0156 - val_loss: 133.9877 - val_accuracy: 0.0000e+00\n",
      "Epoch 9795/10000\n",
      "64/64 [==============================] - 0s 126us/step - loss: 25.6606 - accuracy: 0.0000e+00 - val_loss: 136.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 9796/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2363 - accuracy: 0.0156 - val_loss: 131.6152 - val_accuracy: 0.0000e+00\n",
      "Epoch 9797/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 17.1662 - accuracy: 0.0156 - val_loss: 120.3871 - val_accuracy: 0.0000e+00\n",
      "Epoch 9798/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.9689 - accuracy: 0.0000e+00 - val_loss: 115.0418 - val_accuracy: 0.0000e+00\n",
      "Epoch 9799/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0221 - accuracy: 0.0156 - val_loss: 119.1348 - val_accuracy: 0.0000e+00\n",
      "Epoch 9800/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.6919 - accuracy: 0.0156 - val_loss: 126.2330 - val_accuracy: 0.0000e+00\n",
      "Epoch 9801/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.5802 - accuracy: 0.0000e+00 - val_loss: 130.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 9802/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 15.8178 - accuracy: 0.0156 - val_loss: 133.8249 - val_accuracy: 0.0000e+00\n",
      "Epoch 9803/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8571 - accuracy: 0.0312 - val_loss: 135.2689 - val_accuracy: 0.0588\n",
      "Epoch 9804/10000\n",
      "64/64 [==============================] - 0s 104us/step - loss: 17.8366 - accuracy: 0.0156 - val_loss: 140.3282 - val_accuracy: 0.0000e+00\n",
      "Epoch 9805/10000\n",
      "64/64 [==============================] - 0s 155us/step - loss: 26.1940 - accuracy: 0.0000e+00 - val_loss: 140.6710 - val_accuracy: 0.0000e+00\n",
      "Epoch 9806/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 27.1492 - accuracy: 0.0312 - val_loss: 136.7094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9807/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8840 - accuracy: 0.0312 - val_loss: 136.4389 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9808/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.8019 - accuracy: 0.0156 - val_loss: 134.3683 - val_accuracy: 0.0588\n",
      "Epoch 9809/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0171 - accuracy: 0.0469 - val_loss: 135.9400 - val_accuracy: 0.0588\n",
      "Epoch 9810/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5297 - accuracy: 0.0156 - val_loss: 142.9810 - val_accuracy: 0.0588\n",
      "Epoch 9811/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.3681 - accuracy: 0.0000e+00 - val_loss: 148.3360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9812/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.2550 - accuracy: 0.0156 - val_loss: 150.5835 - val_accuracy: 0.0588\n",
      "Epoch 9813/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 14.7702 - accuracy: 0.0312 - val_loss: 155.8535 - val_accuracy: 0.0588\n",
      "Epoch 9814/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5540 - accuracy: 0.0156 - val_loss: 154.3902 - val_accuracy: 0.0000e+00\n",
      "Epoch 9815/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.3417 - accuracy: 0.0000e+00 - val_loss: 147.3181 - val_accuracy: 0.0000e+00\n",
      "Epoch 9816/10000\n",
      "64/64 [==============================] - 0s 121us/step - loss: 25.4319 - accuracy: 0.0000e+00 - val_loss: 134.2848 - val_accuracy: 0.0588\n",
      "Epoch 9817/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.5004 - accuracy: 0.0156 - val_loss: 126.2099 - val_accuracy: 0.0588\n",
      "Epoch 9818/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9409 - accuracy: 0.0469 - val_loss: 116.9361 - val_accuracy: 0.0588\n",
      "Epoch 9819/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.8694 - accuracy: 0.0000e+00 - val_loss: 114.7518 - val_accuracy: 0.0000e+00\n",
      "Epoch 9820/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4985 - accuracy: 0.0156 - val_loss: 117.0017 - val_accuracy: 0.0000e+00\n",
      "Epoch 9821/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2681 - accuracy: 0.0000e+00 - val_loss: 123.1346 - val_accuracy: 0.0000e+00\n",
      "Epoch 9822/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 12.6758 - accuracy: 0.0156 - val_loss: 130.8564 - val_accuracy: 0.0000e+00\n",
      "Epoch 9823/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0121 - accuracy: 0.0156 - val_loss: 131.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 9824/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.7783 - accuracy: 0.0156 - val_loss: 133.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 9825/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7341 - accuracy: 0.0156 - val_loss: 131.6222 - val_accuracy: 0.0000e+00\n",
      "Epoch 9826/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7697 - accuracy: 0.0000e+00 - val_loss: 132.4298 - val_accuracy: 0.0000e+00\n",
      "Epoch 9827/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 32.2829 - accuracy: 0.0000e+00 - val_loss: 143.4703 - val_accuracy: 0.0000e+00\n",
      "Epoch 9828/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0121 - accuracy: 0.0156 - val_loss: 147.5552 - val_accuracy: 0.0000e+00\n",
      "Epoch 9829/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.8841 - accuracy: 0.0156 - val_loss: 149.3094 - val_accuracy: 0.0000e+00\n",
      "Epoch 9830/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0945 - accuracy: 0.0000e+00 - val_loss: 148.0216 - val_accuracy: 0.0000e+00\n",
      "Epoch 9831/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7508 - accuracy: 0.0156 - val_loss: 144.5554 - val_accuracy: 0.0000e+00\n",
      "Epoch 9832/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.5929 - accuracy: 0.0000e+00 - val_loss: 143.9288 - val_accuracy: 0.0588\n",
      "Epoch 9833/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.0692 - accuracy: 0.0156 - val_loss: 140.9749 - val_accuracy: 0.0000e+00\n",
      "Epoch 9834/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0479 - accuracy: 0.0000e+00 - val_loss: 142.5473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9835/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.7787 - accuracy: 0.0156 - val_loss: 149.8914 - val_accuracy: 0.0000e+00\n",
      "Epoch 9836/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.6600 - accuracy: 0.0312 - val_loss: 155.9477 - val_accuracy: 0.0000e+00\n",
      "Epoch 9837/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0483 - accuracy: 0.0000e+00 - val_loss: 158.3677 - val_accuracy: 0.0000e+00\n",
      "Epoch 9838/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 18.7951 - accuracy: 0.0156 - val_loss: 148.7723 - val_accuracy: 0.0588\n",
      "Epoch 9839/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.6540 - accuracy: 0.0312 - val_loss: 130.4104 - val_accuracy: 0.0588\n",
      "Epoch 9840/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4118 - accuracy: 0.0000e+00 - val_loss: 119.8856 - val_accuracy: 0.0588\n",
      "Epoch 9841/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.0032 - accuracy: 0.0000e+00 - val_loss: 116.3536 - val_accuracy: 0.0588\n",
      "Epoch 9842/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0724 - accuracy: 0.0000e+00 - val_loss: 121.2258 - val_accuracy: 0.0588\n",
      "Epoch 9843/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6853 - accuracy: 0.0156 - val_loss: 124.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 9844/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.5005 - accuracy: 0.0000e+00 - val_loss: 127.4295 - val_accuracy: 0.0000e+00\n",
      "Epoch 9845/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.4078 - accuracy: 0.0156 - val_loss: 128.8052 - val_accuracy: 0.0000e+00\n",
      "Epoch 9846/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7386 - accuracy: 0.0312 - val_loss: 130.4753 - val_accuracy: 0.0000e+00\n",
      "Epoch 9847/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6525 - accuracy: 0.0312 - val_loss: 133.2626 - val_accuracy: 0.0000e+00\n",
      "Epoch 9848/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.2516 - accuracy: 0.0000e+00 - val_loss: 136.2220 - val_accuracy: 0.0000e+00\n",
      "Epoch 9849/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.5584 - accuracy: 0.0156 - val_loss: 140.1355 - val_accuracy: 0.0000e+00\n",
      "Epoch 9850/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.1224 - accuracy: 0.0156 - val_loss: 138.0167 - val_accuracy: 0.0000e+00\n",
      "Epoch 9851/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7589 - accuracy: 0.0156 - val_loss: 137.1912 - val_accuracy: 0.0000e+00\n",
      "Epoch 9852/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.4931 - accuracy: 0.0156 - val_loss: 136.6196 - val_accuracy: 0.0000e+00\n",
      "Epoch 9853/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.8562 - accuracy: 0.0312 - val_loss: 134.5401 - val_accuracy: 0.0588\n",
      "Epoch 9854/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.9951 - accuracy: 0.0312 - val_loss: 137.4819 - val_accuracy: 0.0588\n",
      "Epoch 9855/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.5575 - accuracy: 0.0156 - val_loss: 139.9357 - val_accuracy: 0.0588\n",
      "Epoch 9856/10000\n",
      "64/64 [==============================] - 0s 65us/step - loss: 19.7628 - accuracy: 0.0000e+00 - val_loss: 138.9469 - val_accuracy: 0.0588\n",
      "Epoch 9857/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8903 - accuracy: 0.0156 - val_loss: 136.4161 - val_accuracy: 0.0588\n",
      "Epoch 9858/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5661 - accuracy: 0.0156 - val_loss: 128.9901 - val_accuracy: 0.0588\n",
      "Epoch 9859/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8383 - accuracy: 0.0156 - val_loss: 121.7066 - val_accuracy: 0.0588\n",
      "Epoch 9860/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 33.2846 - accuracy: 0.0000e+00 - val_loss: 123.0885 - val_accuracy: 0.0000e+00\n",
      "Epoch 9861/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 125us/step - loss: 20.5489 - accuracy: 0.0156 - val_loss: 126.2734 - val_accuracy: 0.0000e+00\n",
      "Epoch 9862/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 12.5741 - accuracy: 0.0000e+00 - val_loss: 134.6010 - val_accuracy: 0.0000e+00\n",
      "Epoch 9863/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.3115 - accuracy: 0.0156 - val_loss: 137.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 9864/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1069 - accuracy: 0.0312 - val_loss: 134.4099 - val_accuracy: 0.0000e+00\n",
      "Epoch 9865/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0676 - accuracy: 0.0000e+00 - val_loss: 131.8132 - val_accuracy: 0.0000e+00\n",
      "Epoch 9866/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.2168 - accuracy: 0.0312 - val_loss: 129.2646 - val_accuracy: 0.0000e+00\n",
      "Epoch 9867/10000\n",
      "64/64 [==============================] - 0s 83us/step - loss: 17.7584 - accuracy: 0.0000e+00 - val_loss: 122.2605 - val_accuracy: 0.0000e+00\n",
      "Epoch 9868/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 13.8331 - accuracy: 0.0312 - val_loss: 119.9726 - val_accuracy: 0.0000e+00\n",
      "Epoch 9869/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 24.3767 - accuracy: 0.0156 - val_loss: 126.4391 - val_accuracy: 0.0000e+00\n",
      "Epoch 9870/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 32.0840 - accuracy: 0.0000e+00 - val_loss: 130.1925 - val_accuracy: 0.0000e+00\n",
      "Epoch 9871/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.0388 - accuracy: 0.0000e+00 - val_loss: 137.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 9872/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9835 - accuracy: 0.0156 - val_loss: 138.1366 - val_accuracy: 0.0000e+00\n",
      "Epoch 9873/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.0819 - accuracy: 0.0000e+00 - val_loss: 138.3174 - val_accuracy: 0.0000e+00\n",
      "Epoch 9874/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.3286 - accuracy: 0.0000e+00 - val_loss: 137.4057 - val_accuracy: 0.0000e+00\n",
      "Epoch 9875/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.2267 - accuracy: 0.0000e+00 - val_loss: 132.9675 - val_accuracy: 0.0588\n",
      "Epoch 9876/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6101 - accuracy: 0.0312 - val_loss: 128.0565 - val_accuracy: 0.0588\n",
      "Epoch 9877/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.9025 - accuracy: 0.0000e+00 - val_loss: 123.6505 - val_accuracy: 0.0000e+00\n",
      "Epoch 9878/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.6745 - accuracy: 0.0000e+00 - val_loss: 121.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 9879/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.6294 - accuracy: 0.0469 - val_loss: 118.0145 - val_accuracy: 0.0588\n",
      "Epoch 9880/10000\n",
      "64/64 [==============================] - 0s 141us/step - loss: 11.6311 - accuracy: 0.0469 - val_loss: 119.2055 - val_accuracy: 0.0588\n",
      "Epoch 9881/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.5938 - accuracy: 0.0156 - val_loss: 128.1972 - val_accuracy: 0.0588\n",
      "Epoch 9882/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.5170 - accuracy: 0.0312 - val_loss: 137.2189 - val_accuracy: 0.0000e+00\n",
      "Epoch 9883/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 20.0622 - accuracy: 0.0000e+00 - val_loss: 142.8014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9884/10000\n",
      "64/64 [==============================] - 0s 136us/step - loss: 18.7405 - accuracy: 0.0312 - val_loss: 147.1757 - val_accuracy: 0.0588\n",
      "Epoch 9885/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.3695 - accuracy: 0.0156 - val_loss: 149.0917 - val_accuracy: 0.0000e+00\n",
      "Epoch 9886/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.4821 - accuracy: 0.0312 - val_loss: 143.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 9887/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.7226 - accuracy: 0.0156 - val_loss: 137.0237 - val_accuracy: 0.0000e+00\n",
      "Epoch 9888/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2852 - accuracy: 0.0156 - val_loss: 132.9687 - val_accuracy: 0.0000e+00\n",
      "Epoch 9889/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.9024 - accuracy: 0.0000e+00 - val_loss: 132.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 9890/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 13.0202 - accuracy: 0.0156 - val_loss: 136.5415 - val_accuracy: 0.0588\n",
      "Epoch 9891/10000\n",
      "64/64 [==============================] - 0s 127us/step - loss: 19.9693 - accuracy: 0.0156 - val_loss: 141.7458 - val_accuracy: 0.0000e+00\n",
      "Epoch 9892/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9216 - accuracy: 0.0156 - val_loss: 143.1027 - val_accuracy: 0.0000e+00\n",
      "Epoch 9893/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.0354 - accuracy: 0.0156 - val_loss: 140.8451 - val_accuracy: 0.0000e+00\n",
      "Epoch 9894/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4093 - accuracy: 0.0156 - val_loss: 140.2601 - val_accuracy: 0.0000e+00\n",
      "Epoch 9895/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.2776 - accuracy: 0.0312 - val_loss: 136.0489 - val_accuracy: 0.0000e+00\n",
      "Epoch 9896/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.0587 - accuracy: 0.0000e+00 - val_loss: 135.8307 - val_accuracy: 0.0000e+00\n",
      "Epoch 9897/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.7326 - accuracy: 0.0156 - val_loss: 136.1470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9898/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.3747 - accuracy: 0.0312 - val_loss: 133.9438 - val_accuracy: 0.0000e+00\n",
      "Epoch 9899/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3149 - accuracy: 0.0000e+00 - val_loss: 130.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 9900/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 21.8423 - accuracy: 0.0156 - val_loss: 129.6997 - val_accuracy: 0.0000e+00\n",
      "Epoch 9901/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.8991 - accuracy: 0.0000e+00 - val_loss: 130.5184 - val_accuracy: 0.0000e+00\n",
      "Epoch 9902/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 23.3263 - accuracy: 0.0469 - val_loss: 132.6555 - val_accuracy: 0.0000e+00\n",
      "Epoch 9903/10000\n",
      "64/64 [==============================] - 0s 110us/step - loss: 23.3696 - accuracy: 0.0000e+00 - val_loss: 138.7850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9904/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.2420 - accuracy: 0.0156 - val_loss: 144.5835 - val_accuracy: 0.0000e+00\n",
      "Epoch 9905/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.9009 - accuracy: 0.0000e+00 - val_loss: 141.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 9906/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.0441 - accuracy: 0.0156 - val_loss: 139.3526 - val_accuracy: 0.0000e+00\n",
      "Epoch 9907/10000\n",
      "64/64 [==============================] - 0s 145us/step - loss: 17.7673 - accuracy: 0.0000e+00 - val_loss: 135.8730 - val_accuracy: 0.0000e+00\n",
      "Epoch 9908/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 19.1774 - accuracy: 0.0000e+00 - val_loss: 127.1653 - val_accuracy: 0.0000e+00\n",
      "Epoch 9909/10000\n",
      "64/64 [==============================] - 0s 78us/step - loss: 28.2023 - accuracy: 0.0000e+00 - val_loss: 134.7958 - val_accuracy: 0.0588\n",
      "Epoch 9910/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9527 - accuracy: 0.0156 - val_loss: 142.7298 - val_accuracy: 0.0000e+00\n",
      "Epoch 9911/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4083 - accuracy: 0.0000e+00 - val_loss: 145.3673 - val_accuracy: 0.0000e+00\n",
      "Epoch 9912/10000\n",
      "64/64 [==============================] - 0s 153us/step - loss: 19.7469 - accuracy: 0.0000e+00 - val_loss: 136.3688 - val_accuracy: 0.0000e+00\n",
      "Epoch 9913/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1333 - accuracy: 0.0156 - val_loss: 127.5220 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9914/10000\n",
      "64/64 [==============================] - 0s 85us/step - loss: 21.5244 - accuracy: 0.0156 - val_loss: 118.4850 - val_accuracy: 0.0000e+00\n",
      "Epoch 9915/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7651 - accuracy: 0.0000e+00 - val_loss: 118.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 9916/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.3594 - accuracy: 0.0156 - val_loss: 122.6014 - val_accuracy: 0.0000e+00\n",
      "Epoch 9917/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8850 - accuracy: 0.0000e+00 - val_loss: 131.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 9918/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.8709 - accuracy: 0.0156 - val_loss: 145.3707 - val_accuracy: 0.0000e+00\n",
      "Epoch 9919/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2574 - accuracy: 0.0000e+00 - val_loss: 157.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 9920/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.0027 - accuracy: 0.0000e+00 - val_loss: 161.4779 - val_accuracy: 0.0000e+00\n",
      "Epoch 9921/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 17.8416 - accuracy: 0.0000e+00 - val_loss: 161.3845 - val_accuracy: 0.0588\n",
      "Epoch 9922/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.7491 - accuracy: 0.0000e+00 - val_loss: 158.4932 - val_accuracy: 0.0588\n",
      "Epoch 9923/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 23.5067 - accuracy: 0.0156 - val_loss: 150.7121 - val_accuracy: 0.0588\n",
      "Epoch 9924/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5500 - accuracy: 0.0156 - val_loss: 142.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 9925/10000\n",
      "64/64 [==============================] - 0s 100us/step - loss: 16.4700 - accuracy: 0.0156 - val_loss: 137.0087 - val_accuracy: 0.0000e+00\n",
      "Epoch 9926/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 25.3697 - accuracy: 0.0312 - val_loss: 140.4536 - val_accuracy: 0.0588\n",
      "Epoch 9927/10000\n",
      "64/64 [==============================] - 0s 174us/step - loss: 18.5994 - accuracy: 0.0156 - val_loss: 150.6473 - val_accuracy: 0.0000e+00\n",
      "Epoch 9928/10000\n",
      "64/64 [==============================] - 0s 130us/step - loss: 34.8550 - accuracy: 0.0000e+00 - val_loss: 145.9624 - val_accuracy: 0.0000e+00\n",
      "Epoch 9929/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 25.7432 - accuracy: 0.0000e+00 - val_loss: 134.8129 - val_accuracy: 0.0000e+00\n",
      "Epoch 9930/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.5265 - accuracy: 0.0312 - val_loss: 138.7344 - val_accuracy: 0.0000e+00\n",
      "Epoch 9931/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.2614 - accuracy: 0.0156 - val_loss: 140.5470 - val_accuracy: 0.0000e+00\n",
      "Epoch 9932/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.4695 - accuracy: 0.0312 - val_loss: 137.1681 - val_accuracy: 0.0588\n",
      "Epoch 9933/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.5590 - accuracy: 0.0312 - val_loss: 133.5997 - val_accuracy: 0.0588\n",
      "Epoch 9934/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 15.8961 - accuracy: 0.0000e+00 - val_loss: 133.8285 - val_accuracy: 0.0000e+00\n",
      "Epoch 9935/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.3694 - accuracy: 0.0000e+00 - val_loss: 129.2549 - val_accuracy: 0.0000e+00\n",
      "Epoch 9936/10000\n",
      "64/64 [==============================] - 0s 102us/step - loss: 20.6409 - accuracy: 0.0000e+00 - val_loss: 126.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 9937/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.4960 - accuracy: 0.0156 - val_loss: 124.9287 - val_accuracy: 0.0000e+00\n",
      "Epoch 9938/10000\n",
      "64/64 [==============================] - 0s 87us/step - loss: 13.9020 - accuracy: 0.0312 - val_loss: 127.3492 - val_accuracy: 0.0000e+00\n",
      "Epoch 9939/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.2015 - accuracy: 0.0156 - val_loss: 133.3389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9940/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.2568 - accuracy: 0.0000e+00 - val_loss: 137.6930 - val_accuracy: 0.0000e+00\n",
      "Epoch 9941/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 26.0052 - accuracy: 0.0000e+00 - val_loss: 141.1715 - val_accuracy: 0.0000e+00\n",
      "Epoch 9942/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 33.1345 - accuracy: 0.0000e+00 - val_loss: 143.1230 - val_accuracy: 0.0000e+00\n",
      "Epoch 9943/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.7143 - accuracy: 0.0156 - val_loss: 142.5836 - val_accuracy: 0.0000e+00\n",
      "Epoch 9944/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0583 - accuracy: 0.0156 - val_loss: 140.3309 - val_accuracy: 0.0000e+00\n",
      "Epoch 9945/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 20.8896 - accuracy: 0.0312 - val_loss: 138.8116 - val_accuracy: 0.0588\n",
      "Epoch 9946/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0064 - accuracy: 0.0312 - val_loss: 135.3931 - val_accuracy: 0.0588\n",
      "Epoch 9947/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.7425 - accuracy: 0.0000e+00 - val_loss: 134.7969 - val_accuracy: 0.0588\n",
      "Epoch 9948/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.5458 - accuracy: 0.0000e+00 - val_loss: 138.7638 - val_accuracy: 0.0588\n",
      "Epoch 9949/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.0550 - accuracy: 0.0000e+00 - val_loss: 147.5381 - val_accuracy: 0.0588\n",
      "Epoch 9950/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.8965 - accuracy: 0.0000e+00 - val_loss: 157.7421 - val_accuracy: 0.0000e+00\n",
      "Epoch 9951/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.9413 - accuracy: 0.0156 - val_loss: 159.2860 - val_accuracy: 0.0000e+00\n",
      "Epoch 9952/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.9299 - accuracy: 0.0156 - val_loss: 153.1389 - val_accuracy: 0.0000e+00\n",
      "Epoch 9953/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.6821 - accuracy: 0.0000e+00 - val_loss: 147.0964 - val_accuracy: 0.0000e+00\n",
      "Epoch 9954/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 14.9601 - accuracy: 0.0469 - val_loss: 140.0186 - val_accuracy: 0.0000e+00\n",
      "Epoch 9955/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.5633 - accuracy: 0.0000e+00 - val_loss: 140.3648 - val_accuracy: 0.0000e+00\n",
      "Epoch 9956/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.2776 - accuracy: 0.0156 - val_loss: 146.4523 - val_accuracy: 0.0000e+00\n",
      "Epoch 9957/10000\n",
      "64/64 [==============================] - 0s 195us/step - loss: 16.2912 - accuracy: 0.0156 - val_loss: 150.1909 - val_accuracy: 0.0000e+00\n",
      "Epoch 9958/10000\n",
      "64/64 [==============================] - 0s 187us/step - loss: 20.5315 - accuracy: 0.0156 - val_loss: 151.0567 - val_accuracy: 0.0000e+00\n",
      "Epoch 9959/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.8898 - accuracy: 0.0000e+00 - val_loss: 144.9995 - val_accuracy: 0.0000e+00\n",
      "Epoch 9960/10000\n",
      "64/64 [==============================] - 0s 86us/step - loss: 19.4253 - accuracy: 0.0156 - val_loss: 138.2679 - val_accuracy: 0.0000e+00\n",
      "Epoch 9961/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.1945 - accuracy: 0.0156 - val_loss: 134.1398 - val_accuracy: 0.0000e+00\n",
      "Epoch 9962/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 21.4369 - accuracy: 0.0000e+00 - val_loss: 132.9970 - val_accuracy: 0.0000e+00\n",
      "Epoch 9963/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.6507 - accuracy: 0.0469 - val_loss: 129.4328 - val_accuracy: 0.0000e+00\n",
      "Epoch 9964/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 11.1365 - accuracy: 0.0156 - val_loss: 127.9631 - val_accuracy: 0.0000e+00\n",
      "Epoch 9965/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.1047 - accuracy: 0.0156 - val_loss: 133.4317 - val_accuracy: 0.0588\n",
      "Epoch 9966/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 24.2456 - accuracy: 0.0000e+00 - val_loss: 145.9754 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9967/10000\n",
      "64/64 [==============================] - 0s 93us/step - loss: 18.2778 - accuracy: 0.0156 - val_loss: 156.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 9968/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.8304 - accuracy: 0.0000e+00 - val_loss: 165.8756 - val_accuracy: 0.0000e+00\n",
      "Epoch 9969/10000\n",
      "64/64 [==============================] - 0s 128us/step - loss: 26.9529 - accuracy: 0.0156 - val_loss: 165.0133 - val_accuracy: 0.0000e+00\n",
      "Epoch 9970/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.1319 - accuracy: 0.0000e+00 - val_loss: 155.1613 - val_accuracy: 0.0000e+00\n",
      "Epoch 9971/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 13.5019 - accuracy: 0.0156 - val_loss: 140.1994 - val_accuracy: 0.0000e+00\n",
      "Epoch 9972/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 23.0858 - accuracy: 0.0000e+00 - val_loss: 137.1344 - val_accuracy: 0.0588\n",
      "Epoch 9973/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.9209 - accuracy: 0.0000e+00 - val_loss: 142.1771 - val_accuracy: 0.0000e+00\n",
      "Epoch 9974/10000\n",
      "64/64 [==============================] - 0s 134us/step - loss: 13.9946 - accuracy: 0.0156 - val_loss: 145.4255 - val_accuracy: 0.0000e+00\n",
      "Epoch 9975/10000\n",
      "64/64 [==============================] - 0s 157us/step - loss: 15.8515 - accuracy: 0.0156 - val_loss: 149.1477 - val_accuracy: 0.0000e+00\n",
      "Epoch 9976/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 17.8100 - accuracy: 0.0000e+00 - val_loss: 156.3189 - val_accuracy: 0.0588\n",
      "Epoch 9977/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.2784 - accuracy: 0.0000e+00 - val_loss: 159.5592 - val_accuracy: 0.0000e+00\n",
      "Epoch 9978/10000\n",
      "64/64 [==============================] - 0s 98us/step - loss: 15.4704 - accuracy: 0.0000e+00 - val_loss: 147.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 9979/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 18.0433 - accuracy: 0.0156 - val_loss: 139.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 9980/10000\n",
      "64/64 [==============================] - 0s 63us/step - loss: 17.7576 - accuracy: 0.0312 - val_loss: 123.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 9981/10000\n",
      "64/64 [==============================] - 0s 89us/step - loss: 18.6951 - accuracy: 0.0156 - val_loss: 130.4451 - val_accuracy: 0.0000e+00\n",
      "Epoch 9982/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 18.9880 - accuracy: 0.0000e+00 - val_loss: 138.0385 - val_accuracy: 0.0588\n",
      "Epoch 9983/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 20.9351 - accuracy: 0.0156 - val_loss: 136.0934 - val_accuracy: 0.0000e+00\n",
      "Epoch 9984/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 14.1129 - accuracy: 0.0156 - val_loss: 135.0263 - val_accuracy: 0.0000e+00\n",
      "Epoch 9985/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 28.2055 - accuracy: 0.0000e+00 - val_loss: 132.7384 - val_accuracy: 0.0000e+00\n",
      "Epoch 9986/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.1778 - accuracy: 0.0156 - val_loss: 131.2520 - val_accuracy: 0.0000e+00\n",
      "Epoch 9987/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 30.7390 - accuracy: 0.0000e+00 - val_loss: 130.1026 - val_accuracy: 0.0000e+00\n",
      "Epoch 9988/10000\n",
      "64/64 [==============================] - 0s 113us/step - loss: 15.5808 - accuracy: 0.0000e+00 - val_loss: 130.2360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9989/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 29.7069 - accuracy: 0.0156 - val_loss: 135.5590 - val_accuracy: 0.0588\n",
      "Epoch 9990/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 16.3631 - accuracy: 0.0000e+00 - val_loss: 135.1702 - val_accuracy: 0.1176\n",
      "Epoch 9991/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 29.0321 - accuracy: 0.0156 - val_loss: 131.2747 - val_accuracy: 0.1176\n",
      "Epoch 9992/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 19.4510 - accuracy: 0.0000e+00 - val_loss: 121.9860 - val_accuracy: 0.0000e+00\n",
      "Epoch 9993/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 16.1156 - accuracy: 0.0000e+00 - val_loss: 123.3522 - val_accuracy: 0.0000e+00\n",
      "Epoch 9994/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 22.6018 - accuracy: 0.0156 - val_loss: 128.0817 - val_accuracy: 0.0000e+00\n",
      "Epoch 9995/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 24.7382 - accuracy: 0.0156 - val_loss: 130.4597 - val_accuracy: 0.0000e+00\n",
      "Epoch 9996/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 15.7135 - accuracy: 0.0312 - val_loss: 132.3255 - val_accuracy: 0.0000e+00\n",
      "Epoch 9997/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 25.2128 - accuracy: 0.0000e+00 - val_loss: 132.1205 - val_accuracy: 0.0000e+00\n",
      "Epoch 9998/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 22.6554 - accuracy: 0.0156 - val_loss: 131.8360 - val_accuracy: 0.0000e+00\n",
      "Epoch 9999/10000\n",
      "64/64 [==============================] - 0s 62us/step - loss: 19.7084 - accuracy: 0.0156 - val_loss: 132.0891 - val_accuracy: 0.0000e+00\n",
      "Epoch 10000/10000\n",
      "64/64 [==============================] - 0s 125us/step - loss: 27.9720 - accuracy: 0.0469 - val_loss: 137.9646 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = model.fit(test_data_x, test_data_y, epochs=10000, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red')\n",
    "plt.plot(data_history['loss'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f56</th>\n",
       "      <th>f57</th>\n",
       "      <th>f58</th>\n",
       "      <th>f59</th>\n",
       "      <th>f60</th>\n",
       "      <th>f61</th>\n",
       "      <th>f62</th>\n",
       "      <th>f63</th>\n",
       "      <th>f64</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.028796</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.035953</td>\n",
       "      <td>0.044183</td>\n",
       "      <td>0.066405</td>\n",
       "      <td>0.121921</td>\n",
       "      <td>0.206038</td>\n",
       "      <td>0.288564</td>\n",
       "      <td>0.381148</td>\n",
       "      <td>0.503240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421101</td>\n",
       "      <td>0.581313</td>\n",
       "      <td>0.674222</td>\n",
       "      <td>0.707964</td>\n",
       "      <td>0.704825</td>\n",
       "      <td>0.634228</td>\n",
       "      <td>0.577624</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>677</td>\n",
       "      <td>0.065548</td>\n",
       "      <td>0.062322</td>\n",
       "      <td>0.060254</td>\n",
       "      <td>0.065530</td>\n",
       "      <td>0.092613</td>\n",
       "      <td>0.145811</td>\n",
       "      <td>0.205864</td>\n",
       "      <td>0.259082</td>\n",
       "      <td>0.328832</td>\n",
       "      <td>0.435089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334879</td>\n",
       "      <td>0.437199</td>\n",
       "      <td>0.497421</td>\n",
       "      <td>0.531572</td>\n",
       "      <td>0.544168</td>\n",
       "      <td>0.511745</td>\n",
       "      <td>0.573746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>364</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>0.043313</td>\n",
       "      <td>0.042787</td>\n",
       "      <td>0.050618</td>\n",
       "      <td>0.075615</td>\n",
       "      <td>0.120446</td>\n",
       "      <td>0.184025</td>\n",
       "      <td>0.261701</td>\n",
       "      <td>0.369852</td>\n",
       "      <td>0.525703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466931</td>\n",
       "      <td>0.615784</td>\n",
       "      <td>0.709372</td>\n",
       "      <td>0.753730</td>\n",
       "      <td>0.754293</td>\n",
       "      <td>0.637584</td>\n",
       "      <td>0.472356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>0.052033</td>\n",
       "      <td>0.054948</td>\n",
       "      <td>0.071690</td>\n",
       "      <td>0.122190</td>\n",
       "      <td>0.193307</td>\n",
       "      <td>0.259890</td>\n",
       "      <td>0.326314</td>\n",
       "      <td>0.414541</td>\n",
       "      <td>0.542426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479133</td>\n",
       "      <td>0.648237</td>\n",
       "      <td>0.751051</td>\n",
       "      <td>0.801043</td>\n",
       "      <td>0.817695</td>\n",
       "      <td>0.570470</td>\n",
       "      <td>0.591887</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.327869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>0.063436</td>\n",
       "      <td>0.060565</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>0.064028</td>\n",
       "      <td>0.093407</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.247979</td>\n",
       "      <td>0.311369</td>\n",
       "      <td>0.376568</td>\n",
       "      <td>0.480816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459529</td>\n",
       "      <td>0.553023</td>\n",
       "      <td>0.597067</td>\n",
       "      <td>0.612529</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.585570</td>\n",
       "      <td>0.669323</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f1        f2        f3        f4        f5        f6        f7  \\\n",
       "6    0.028796  0.031857  0.035953  0.044183  0.066405  0.121921  0.206038   \n",
       "677  0.065548  0.062322  0.060254  0.065530  0.092613  0.145811  0.205864   \n",
       "364  0.045745  0.043313  0.042787  0.050618  0.075615  0.120446  0.184025   \n",
       "255  0.051508  0.052033  0.054948  0.071690  0.122190  0.193307  0.259890   \n",
       "683  0.063436  0.060565  0.058813  0.064028  0.093407  0.162574  0.247979   \n",
       "\n",
       "           f8        f9       f10  ...       f56       f57       f58  \\\n",
       "6    0.288564  0.381148  0.503240  ...  0.421101  0.581313  0.674222   \n",
       "677  0.259082  0.328832  0.435089  ...  0.334879  0.437199  0.497421   \n",
       "364  0.261701  0.369852  0.525703  ...  0.466931  0.615784  0.709372   \n",
       "255  0.326314  0.414541  0.542426  ...  0.479133  0.648237  0.751051   \n",
       "683  0.311369  0.376568  0.480816  ...  0.459529  0.553023  0.597067   \n",
       "\n",
       "          f59       f60       f61       f62  f63  f64    target  \n",
       "6    0.707964  0.704825  0.634228  0.577624    0    1  0.347541  \n",
       "677  0.531572  0.544168  0.511745  0.573746    1    0  0.388197  \n",
       "364  0.753730  0.754293  0.637584  0.472356    0    1  0.344918  \n",
       "255  0.801043  0.817695  0.570470  0.591887    0    1  0.327869  \n",
       "683  0.612529  0.606061  0.585570  0.669323    1    0  0.411148  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canopy_dataframe = pd.read_excel('X.xlsx')\n",
    "canopy_dataframe = canopy_dataframe.reindex(np.random.permutation(canopy_dataframe.index))\n",
    "canopy_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows and columns in the data :  (805, 65)\n"
     ]
    }
   ],
   "source": [
    "print('Number of rows and columns in the data : ', canopy_dataframe.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = canopy_dataframe['target'].values\n",
    "x_train = canopy_dataframe[canopy_dataframe.columns[canopy_dataframe.columns!='target']].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563,)\n",
      "(563, 64)\n",
      "(242, 64)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 260       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 8,585\n",
      "Trainable params: 8,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "default_model = build_medium_regression_model(64)\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "default_model.compile('adam', loss='mse', metrics=['accuracy'])\n",
    "default_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 113 samples\n",
      "Epoch 1/10000\n",
      "450/450 [==============================] - 0s 642us/step - loss: 0.1905 - accuracy: 0.0000e+00 - val_loss: 0.0516 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0491 - accuracy: 0.0000e+00 - val_loss: 0.0196 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0336 - accuracy: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0255 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0218 - accuracy: 0.0000e+00 - val_loss: 0.0126 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0241 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0207 - accuracy: 0.0000e+00 - val_loss: 0.0112 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0181 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0171 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10000\n",
      "450/450 [==============================] - 0s 71us/step - loss: 0.0157 - accuracy: 0.0000e+00 - val_loss: 0.0101 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0162 - accuracy: 0.0000e+00 - val_loss: 0.0107 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0161 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/10000\n",
      "450/450 [==============================] - 0s 93us/step - loss: 0.0148 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0144 - accuracy: 0.0000e+00 - val_loss: 0.0135 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0153 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0127 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0136 - accuracy: 0.0000e+00 - val_loss: 0.0127 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0122 - accuracy: 0.0000e+00 - val_loss: 0.0106 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0130 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0096 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0117 - accuracy: 0.0000e+00 - val_loss: 0.0117 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0126 - accuracy: 0.0000e+00 - val_loss: 0.0078 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0119 - accuracy: 0.0000e+00 - val_loss: 0.0105 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0129 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0115 - accuracy: 0.0000e+00 - val_loss: 0.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0114 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0112 - accuracy: 0.0000e+00 - val_loss: 0.0069 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0075 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0108 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0098 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0111 - accuracy: 0.0000e+00 - val_loss: 0.0088 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0101 - accuracy: 0.0000e+00 - val_loss: 0.0104 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/10000\n",
      "450/450 [==============================] - 0s 53us/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0100 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/10000\n",
      "450/450 [==============================] - 0s 71us/step - loss: 0.0128 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0066 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0102 - accuracy: 0.0000e+00 - val_loss: 0.0074 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0085 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/10000\n",
      "450/450 [==============================] - 0s 84us/step - loss: 0.0090 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/10000\n",
      "450/450 [==============================] - 0s 64us/step - loss: 0.0094 - accuracy: 0.0000e+00 - val_loss: 0.0079 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0083 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/10000\n",
      "450/450 [==============================] - 0s 51us/step - loss: 0.0086 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/10000\n",
      "450/450 [==============================] - 0s 56us/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0076 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/10000\n",
      "450/450 [==============================] - 0s 60us/step - loss: 0.0097 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/10000\n",
      "450/450 [==============================] - 0s 58us/step - loss: 0.0084 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/10000\n",
      "450/450 [==============================] - 0s 62us/step - loss: 0.0087 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/10000\n",
      "450/450 [==============================] - 0s 91us/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/10000\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.0089 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/10000\n",
      "450/450 [==============================] - 0s 67us/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0062 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/10000\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0051 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/10000\n",
      "450/450 [==============================] - 0s 89us/step - loss: 0.0070 - accuracy: 0.0000e+00 - val_loss: 0.0048 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0081 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/10000\n",
      "450/450 [==============================] - 0s 76us/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0072 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/10000\n",
      "450/450 [==============================] - 0s 78us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0058 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0075 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/10000\n",
      "450/450 [==============================] - 0s 69us/step - loss: 0.0077 - accuracy: 0.0000e+00 - val_loss: 0.0072 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0064 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/10000\n",
      "450/450 [==============================] - 0s 73us/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0054 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/10000\n",
      "450/450 [==============================] - 0s 80us/step - loss: 0.0073 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\n",
      "Epoch 00067: early stopping\n"
     ]
    }
   ],
   "source": [
    "ES = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=20, mode=\"min\", verbose=1)\n",
    "history = default_model.fit(x_train, y_train, epochs=10000, validation_split = 0.2, callbacks = [ES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_history = history.history\n",
    "print(data_history.keys())\n",
    "plt.figure()\n",
    "plt.plot(data_history['val_loss'], color='red')\n",
    "plt.plot(data_history['loss'], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.T\n",
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "x_train = x_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = prn.CreateNN([32, 10, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0 \t\tError:  25.4806223918662 \tscale factor:  0.02\n",
      "Iteration:  1 \t\tError:  0.13294383152426648 \tscale factor:  0.007407407407407407\n",
      "Iteration:  2 \t\tError:  0.12767144260074254 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  3 \t\tError:  0.12408018035644208 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  4 \t\tError:  0.12293902009681015 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  5 \t\tError:  0.12180346807176798 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  6 \t\tError:  0.12059951225562018 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  7 \t\tError:  0.11937903852261858 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  8 \t\tError:  0.11826617387809281 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  9 \t\tError:  0.11733334914155179 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  10 \t\tError:  0.11657992729455262 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  11 \t\tError:  0.11597090958837045 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  12 \t\tError:  0.1154683835228018 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  13 \t\tError:  0.1150426266011995 \tscale factor:  0.0027434842249657062\n",
      "Iteration:  14 \t\tError:  0.11472753945816182 \tscale factor:  0.001016105268505817\n",
      "Iteration:  15 \t\tError:  0.11283943425146734 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  16 \t\tError:  0.1098880331944816 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  17 \t\tError:  0.10799964990700504 \tscale factor:  0.001016105268505817\n",
      "Iteration:  18 \t\tError:  0.10670817163820753 \tscale factor:  0.001016105268505817\n",
      "Iteration:  19 \t\tError:  0.1055299228484931 \tscale factor:  0.001016105268505817\n",
      "Iteration:  20 \t\tError:  0.10421029217173036 \tscale factor:  0.001016105268505817\n",
      "Iteration:  21 \t\tError:  0.10276304219374216 \tscale factor:  0.001016105268505817\n",
      "Iteration:  22 \t\tError:  0.10119388283918573 \tscale factor:  0.001016105268505817\n",
      "Iteration:  23 \t\tError:  0.09952177666967658 \tscale factor:  0.001016105268505817\n",
      "Iteration:  24 \t\tError:  0.09777596612240622 \tscale factor:  0.001016105268505817\n",
      "Iteration:  25 \t\tError:  0.09599202329221579 \tscale factor:  0.001016105268505817\n",
      "Iteration:  26 \t\tError:  0.09420714908610925 \tscale factor:  0.001016105268505817\n",
      "Iteration:  27 \t\tError:  0.09349214117551445 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  28 \t\tError:  0.08741713527439453 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  29 \t\tError:  0.08392092129476365 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  30 \t\tError:  0.0814196816195614 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  31 \t\tError:  0.08119703777677217 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  32 \t\tError:  0.07742708848139301 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  33 \t\tError:  0.0760962488041549 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  34 \t\tError:  0.07575053536815804 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  35 \t\tError:  0.07552114457431396 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  36 \t\tError:  0.07534479764442714 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  37 \t\tError:  0.07519928877944962 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  38 \t\tError:  0.07505549834834711 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  39 \t\tError:  0.07488754572419626 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  40 \t\tError:  0.0746786433041662 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  41 \t\tError:  0.07442224138247662 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  42 \t\tError:  0.07412115531925415 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  43 \t\tError:  0.073786662411297 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  44 \t\tError:  0.07343552510377521 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  45 \t\tError:  0.07308357702256886 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  46 \t\tError:  0.0727391430048602 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  47 \t\tError:  0.07240141993418639 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  48 \t\tError:  0.07180058392417828 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  49 \t\tError:  0.07086043112769577 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  50 \t\tError:  0.06988153550087198 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  51 \t\tError:  0.06966336517755108 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  52 \t\tError:  0.06842368034740051 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  53 \t\tError:  0.06775608044100236 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  54 \t\tError:  0.0677226086006471 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  55 \t\tError:  0.06600875091240364 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  56 \t\tError:  0.06564383017383169 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  57 \t\tError:  0.06521879818474474 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  58 \t\tError:  0.06478488137709788 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  59 \t\tError:  0.06437798320459988 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  60 \t\tError:  0.0639469399290861 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  61 \t\tError:  0.0635384846433919 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  62 \t\tError:  0.06315987820620787 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  63 \t\tError:  0.06288050334355239 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  64 \t\tError:  0.06287905784851316 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  65 \t\tError:  0.06217425116239683 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  66 \t\tError:  0.06192401988245038 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  67 \t\tError:  0.061845113728651355 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  68 \t\tError:  0.06124193751010584 \tscale factor:  0.001016105268505817\n",
      "Iteration:  69 \t\tError:  0.06104634596012106 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  70 \t\tError:  0.06086740070368087 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  71 \t\tError:  0.06041389917280958 \tscale factor:  0.001016105268505817\n",
      "Iteration:  72 \t\tError:  0.060218345450520606 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  73 \t\tError:  0.059986263608602514 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  74 \t\tError:  0.059626215386758934 \tscale factor:  0.001016105268505817\n",
      "Iteration:  75 \t\tError:  0.05943591452137713 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  76 \t\tError:  0.05917138310308272 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  77 \t\tError:  0.05888117271241339 \tscale factor:  0.001016105268505817\n",
      "Iteration:  78 \t\tError:  0.05869925772032837 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  79 \t\tError:  0.05841109997477 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  80 \t\tError:  0.058180251898138025 \tscale factor:  0.001016105268505817\n",
      "Iteration:  81 \t\tError:  0.05800882562150304 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  82 \t\tError:  0.05770008809632095 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  83 \t\tError:  0.057523792614353926 \tscale factor:  0.001016105268505817\n",
      "Iteration:  84 \t\tError:  0.057364087600864644 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  85 \t\tError:  0.05703705720360215 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  86 \t\tError:  0.05691102398368945 \tscale factor:  0.001016105268505817\n",
      "Iteration:  87 \t\tError:  0.056763321938660585 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  88 \t\tError:  0.05642426825499583 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  89 \t\tError:  0.05634024022489172 \tscale factor:  0.001016105268505817\n",
      "Iteration:  90 \t\tError:  0.05620385690458262 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  91 \t\tError:  0.05586504537045278 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  92 \t\tError:  0.05580888136948105 \tscale factor:  0.001016105268505817\n",
      "Iteration:  93 \t\tError:  0.05568243814303946 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  94 \t\tError:  0.05535809376727381 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  95 \t\tError:  0.05529429670387385 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  96 \t\tError:  0.055100805664034316 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  97 \t\tError:  0.054903672922301285 \tscale factor:  0.001016105268505817\n",
      "Iteration:  98 \t\tError:  0.05479789421067231 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  99 \t\tError:  0.054512124528546944 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  100 \t\tError:  0.054501105504996525 \tscale factor:  0.00037633528463178407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  101 \t\tError:  0.05428051609448088 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  102 \t\tError:  0.0540817801309882 \tscale factor:  0.001016105268505817\n",
      "Iteration:  103 \t\tError:  0.05398995417111241 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  104 \t\tError:  0.053717577427860916 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  105 \t\tError:  0.053640098675879655 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  106 \t\tError:  0.0533701868549085 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  107 \t\tError:  0.05328734430897948 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  108 \t\tError:  0.053030146735875014 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  109 \t\tError:  0.052976072913881816 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  110 \t\tError:  0.05279727422054804 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  111 \t\tError:  0.05247744932035972 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  112 \t\tError:  0.052358971947997435 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  113 \t\tError:  0.052200642489724884 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  114 \t\tError:  0.05194027328072506 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  115 \t\tError:  0.05157464960491345 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  116 \t\tError:  0.05140555499806197 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  117 \t\tError:  0.05110483536780355 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  118 \t\tError:  0.05059466062615564 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  119 \t\tError:  0.05037497853843018 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  120 \t\tError:  0.05013518620571414 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  121 \t\tError:  0.04987008352968256 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  122 \t\tError:  0.04945944563866814 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  123 \t\tError:  0.04939327061595338 \tscale factor:  0.00037633528463178407\n",
      "Iteration:  124 \t\tError:  0.04923781625482667 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  125 \t\tError:  0.04889301572482003 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  126 \t\tError:  0.048762115844158294 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  127 \t\tError:  0.04846375989270482 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  128 \t\tError:  0.04839619112056537 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  129 \t\tError:  0.0481306054424281 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  130 \t\tError:  0.04811779525476933 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  131 \t\tError:  0.04785104490467992 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  132 \t\tError:  0.047805689941328486 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  133 \t\tError:  0.04762676829912233 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  134 \t\tError:  0.04749913298763038 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  135 \t\tError:  0.0474335792044481 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  136 \t\tError:  0.04736073879582535 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  137 \t\tError:  0.04724165257950198 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  138 \t\tError:  0.04705626432022667 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  139 \t\tError:  0.047032731153225024 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  140 \t\tError:  0.04696171554318977 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  141 \t\tError:  0.0469063624155376 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  142 \t\tError:  0.046794106107783895 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  143 \t\tError:  0.04672970084426725 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  144 \t\tError:  0.04666275482857083 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  145 \t\tError:  0.04665516263440556 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  146 \t\tError:  0.04653846049430575 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  147 \t\tError:  0.04649641335311615 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  148 \t\tError:  0.04647364899012274 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  149 \t\tError:  0.04645264194803975 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  150 \t\tError:  0.046432734141010616 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  151 \t\tError:  0.04641386338652638 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  152 \t\tError:  0.04639602747199514 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  153 \t\tError:  0.04637926190539117 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  154 \t\tError:  0.046363636839244285 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  155 \t\tError:  0.046349254510767504 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  156 \t\tError:  0.04633624708843416 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  157 \t\tError:  0.04632477001578962 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  158 \t\tError:  0.04631498899571118 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  159 \t\tError:  0.04630705639003714 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  160 \t\tError:  0.04630107298177327 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  161 \t\tError:  0.046297030007233675 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  162 \t\tError:  0.046294727451370477 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  163 \t\tError:  0.046293669000414005 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  164 \t\tError:  0.046292937021777884 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  165 \t\tError:  0.046291063372469576 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  166 \t\tError:  0.0462859201202223 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  167 \t\tError:  0.04627469687788044 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  168 \t\tError:  0.046254033055197014 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  169 \t\tError:  0.04622041409600903 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  170 \t\tError:  0.04617101507303513 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  171 \t\tError:  0.04610521228177464 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  172 \t\tError:  0.04594867858100511 \tscale factor:  1.91198132719496e-05\n",
      "Iteration:  173 \t\tError:  0.04591739548998639 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  174 \t\tError:  0.04586165060998368 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  175 \t\tError:  0.04584325936675515 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  176 \t\tError:  0.04582447005317079 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  177 \t\tError:  0.04580755632823823 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  178 \t\tError:  0.04578990130393671 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  179 \t\tError:  0.045771229794064366 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  180 \t\tError:  0.04575115213448658 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  181 \t\tError:  0.04572913067373827 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  182 \t\tError:  0.04570454119572445 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  183 \t\tError:  0.04567680058129227 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  184 \t\tError:  0.045645525515548686 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  185 \t\tError:  0.04561067380982638 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  186 \t\tError:  0.045572622762012904 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  187 \t\tError:  0.04553215983132172 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  188 \t\tError:  0.04549038322349589 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  189 \t\tError:  0.045448520384084576 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  190 \t\tError:  0.04537053208552837 \tscale factor:  5.162349583426392e-05\n",
      "Iteration:  191 \t\tError:  0.045322191494351 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  192 \t\tError:  0.04527402999317199 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  193 \t\tError:  0.04523861863551921 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  194 \t\tError:  0.04520391700583741 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  195 \t\tError:  0.04516901817968125 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  196 \t\tError:  0.045133160279019174 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  197 \t\tError:  0.0450959703206264 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  198 \t\tError:  0.0450573427445045 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  199 \t\tError:  0.04501730402485285 \tscale factor:  0.0001393834387525126\n",
      "Iteration:  200 \t\tError:  0.04497591943255336 \tscale factor:  0.0001393834387525126\n",
      "Maximum number of iterations reached\n"
     ]
    }
   ],
   "source": [
    "net = prn.train_LM(x_train, y_train, net, verbose=True,\n",
    " dampfac = 0.02, dampconst = 2.70,\n",
    " k_max=200, E_stop=0.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prn.NNOut(x_train, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_train_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.114210</td>\n",
       "      <td>0.093109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.047459</td>\n",
       "      <td>0.035673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051703</td>\n",
       "      <td>0.044996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.030793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070224</td>\n",
       "      <td>0.066673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_train  y_train_pred\n",
       "0  0.114210      0.093109\n",
       "1  0.047459      0.035673\n",
       "2  0.051703      0.044996\n",
       "3  0.045144      0.030793\n",
       "4  0.070224      0.066673"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk = pd.DataFrame({'y_train': y_train.flatten(), 'y_train_pred': y.flatten()})\n",
    "acc_sc_chk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.6891513783874852 / 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score_1 = r2_score(acc_sc_chk.y_train, acc_sc_chk.y_train_pred)\n",
    "print('r2 score = ', r2_score_1, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = prn.NNOut(x_test, net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.019727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.016599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.037801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089130</td>\n",
       "      <td>0.065511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033569</td>\n",
       "      <td>0.008591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_test_pred\n",
       "0  0.018135     0.019727\n",
       "1  0.002701     0.016599\n",
       "2  0.002701     0.037801\n",
       "3  0.089130     0.065511\n",
       "4  0.033569     0.008591"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_sc_chk_2 = pd.DataFrame({'y_test': y_test.flatten(), 'y_test_pred': y_pred.flatten()})\n",
    "acc_sc_chk_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score =  0.3547752701549468 / 1.0\n"
     ]
    }
   ],
   "source": [
    " r2_score = r2_score(acc_sc_chk_2.y_test, acc_sc_chk_2.y_test_pred)\n",
    "print('r2 score = ', r2_score, '/ 1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[           id  CC160323  CC160328  CC160329  CC160331  CC160414  CC160419  \\\n",
      "0    0.000349  0.002941  0.005263  0.006426  0.006561  0.010057  0.010712   \n",
      "1    0.000697  0.001944  0.004398  0.005121  0.006285  0.010145  0.009603   \n",
      "2    0.001046  0.001727  0.003102  0.004388  0.004193  0.008887  0.009074   \n",
      "3    0.001394  0.001319  0.002720  0.004339  0.003934  0.007248  0.007119   \n",
      "4    0.001743  0.003098  0.005202  0.005608  0.006448  0.008060  0.007821   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.083313  0.000000  0.000000  0.000000  0.000000  0.001720  0.002330   \n",
      "239  0.083662  0.000000  0.000000  0.000000  0.000000  0.001812  0.002173   \n",
      "240  0.084010  0.000000  0.000000  0.000000  0.000000  0.001230  0.001899   \n",
      "241  0.084359  0.000000  0.000000  0.000000  0.000000  0.001490  0.002664   \n",
      "242  0.084707  0.000000  0.000000  0.000000  0.000001  0.001482  0.002940   \n",
      "\n",
      "     CC160421  CC160425  CC160504  CC160510  CC160512  CC160516  CC160523  \\\n",
      "0    0.011305  0.011080  0.008448  0.009489  0.012636  0.011800  0.010251   \n",
      "1    0.010816  0.009170  0.009070  0.007931  0.011137  0.008938  0.008315   \n",
      "2    0.010235  0.009133  0.007139  0.008947  0.012485  0.011081  0.008663   \n",
      "3    0.008914  0.008639  0.007002  0.008612  0.012974  0.011293  0.009483   \n",
      "4    0.009087  0.008080  0.008852  0.007366  0.010697  0.009211  0.007997   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.004043  0.005293  0.005727  0.011309  0.013580  0.018191  0.009292   \n",
      "239  0.004108  0.005331  0.004309  0.011551  0.013644  0.015621  0.014607   \n",
      "240  0.003310  0.004341  0.005157  0.009925  0.012135  0.011794  0.010537   \n",
      "241  0.004283  0.005703  0.005466  0.008806  0.010194  0.013427  0.012113   \n",
      "242  0.004285  0.005069  0.004730  0.010760  0.012306  0.014803  0.013732   \n",
      "\n",
      "     CC160524  CC160525  CC160609  CC160616  CC160622  \n",
      "0    0.011200  0.011306  0.009176  0.013678  0.008847  \n",
      "1    0.008664  0.010572  0.007429  0.010679  0.015020  \n",
      "2    0.010304  0.010882  0.009008  0.018495  0.023976  \n",
      "3    0.010331  0.009867  0.010559  0.017769  0.024659  \n",
      "4    0.008861  0.009668  0.006515  0.007789  0.011669  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.009236  0.008577  0.007939  0.008867  0.012720  \n",
      "239  0.014683  0.013160  0.012560  0.014917  0.012712  \n",
      "240  0.009572  0.006973  0.008734  0.009413  0.008558  \n",
      "241  0.012910  0.010324  0.010369  0.009800  0.009256  \n",
      "242  0.012615  0.012939  0.011703  0.011915  0.009943  \n",
      "\n",
      "[243 rows x 19 columns],            id  CV160323  CV160328  CV160329  CV160331  CV160414  CV160419  \\\n",
      "0    0.000456  0.000025  0.000241  0.000039 -0.000555  0.000303  0.000506   \n",
      "1    0.000911 -0.000007  0.000144 -0.000058 -0.000761  0.000123  0.000359   \n",
      "2    0.001367  0.000026  0.000162 -0.000018 -0.000698  0.000148  0.000367   \n",
      "3    0.001822  0.000020  0.000175 -0.000022 -0.000684  0.000160  0.000342   \n",
      "4    0.002278  0.000062  0.000197 -0.000005 -0.000691  0.000163  0.000318   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.108887  0.000011  0.000009 -0.000057 -0.000326 -0.000038  0.000033   \n",
      "239  0.109342  0.000023  0.000024 -0.000032 -0.000252 -0.000037  0.000048   \n",
      "240  0.109798  0.000020  0.000016 -0.000037 -0.000203 -0.000059  0.000038   \n",
      "241  0.110254  0.000017  0.000017 -0.000025 -0.000149 -0.000093  0.000054   \n",
      "242  0.110709  0.000072  0.000083  0.000051 -0.000041 -0.000103  0.000109   \n",
      "\n",
      "     CV160421  CV160425  CV160504  CV160510  CV160512  CV160516  CV160523  \\\n",
      "0    0.000528  0.000572  0.000589  0.000483  0.000570  0.000552  0.000549   \n",
      "1    0.000381  0.000426  0.000429  0.000391  0.000435  0.000420  0.000365   \n",
      "2    0.000371  0.000381  0.000445  0.000345  0.000424  0.000407  0.000360   \n",
      "3    0.000378  0.000391  0.000533  0.000390  0.000536  0.000454  0.000398   \n",
      "4    0.000331  0.000389  0.000434  0.000382  0.000463  0.000434  0.000392   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.000110  0.000096  0.000256  0.000240  0.000341  0.000265  0.000243   \n",
      "239  0.000122  0.000098  0.000288  0.000353  0.000542  0.000455  0.000537   \n",
      "240  0.000092  0.000061  0.000205  0.000308  0.000401  0.000306  0.000333   \n",
      "241  0.000102  0.000086  0.000232  0.000300  0.000344  0.000346  0.000387   \n",
      "242  0.000175  0.000124  0.000252  0.000369  0.000444  0.000436  0.000437   \n",
      "\n",
      "     CV160524  CV160525  CV160609  CV160616  CV160622  \n",
      "0    0.000591  0.000611  0.000564  0.000425  0.000464  \n",
      "1    0.000432  0.000391  0.000287  0.000283  0.000357  \n",
      "2    0.000403  0.000385  0.000255  0.000202  0.000382  \n",
      "3    0.000399  0.000406  0.000295  0.000267  0.000451  \n",
      "4    0.000412  0.000416  0.000286  0.000265  0.000326  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.000261  0.000289  0.000277  0.000185  0.000373  \n",
      "239  0.000580  0.000656  0.000488  0.000347  0.000510  \n",
      "240  0.000333  0.000385  0.000344  0.000242  0.000382  \n",
      "241  0.000416  0.000458  0.000381  0.000262  0.000355  \n",
      "242  0.000481  0.000500  0.000552  0.000337  0.000452  \n",
      "\n",
      "[243 rows x 19 columns],            id  CH160323  CH160328  CH160329  CH160331  CH160414  CH160419  \\\n",
      "0    0.000456  0.000062  0.000116  0.000099  0.000114  0.000220  0.000247   \n",
      "1    0.000912  0.000040  0.000073  0.000098  0.000088  0.000191  0.000206   \n",
      "2    0.001367  0.000042  0.000082  0.000075  0.000051  0.000192  0.000204   \n",
      "3    0.001823  0.000032  0.000078  0.000078  0.000053  0.000165  0.000171   \n",
      "4    0.002279  0.000036  0.000071  0.000088  0.000088  0.000156  0.000164   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.108935  0.000024  0.000024  0.000000  0.000000  0.000035  0.000053   \n",
      "239  0.109391  0.000025  0.000023  0.000024  0.000000  0.000037  0.000058   \n",
      "240  0.109847  0.000025  0.000024  0.000000  0.000000  0.000000  0.000046   \n",
      "241  0.110302  0.000025  0.000024  0.000000  0.000029  0.000028  0.000050   \n",
      "242  0.110758  0.000054  0.000052  0.000060  0.000035  0.000039  0.000065   \n",
      "\n",
      "     CH160421  CH160425  CH160504  CH160510  CH160512  CH160516  CH160523  \\\n",
      "0    0.000262  0.000266  0.000271  0.000251  0.000260  0.000233  0.000240   \n",
      "1    0.000225  0.000239  0.000256  0.000245  0.000247  0.000206  0.000255   \n",
      "2    0.000221  0.000222  0.000227  0.000239  0.000230  0.000209  0.000213   \n",
      "3    0.000200  0.000204  0.000246  0.000250  0.000215  0.000184  0.000200   \n",
      "4    0.000186  0.000187  0.000234  0.000208  0.000199  0.000151  0.000201   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "238  0.000076  0.000097  0.000163  0.000149  0.000141  0.000156  0.000203   \n",
      "239  0.000085  0.000113  0.000167  0.000214  0.000233  0.000272  0.000279   \n",
      "240  0.000056  0.000087  0.000158  0.000215  0.000214  0.000238  0.000246   \n",
      "241  0.000068  0.000102  0.000158  0.000211  0.000214  0.000254  0.000264   \n",
      "242  0.000089  0.000107  0.000156  0.000205  0.000207  0.000259  0.000254   \n",
      "\n",
      "     CH160524  CH160525  CH160609  CH160616  CH160622  \n",
      "0    0.000249  0.000258  0.000226  0.000175  0.000144  \n",
      "1    0.000202  0.000244  0.000250  0.000189  0.000113  \n",
      "2    0.000197  0.000216  0.000194  0.000169  0.000139  \n",
      "3    0.000171  0.000208  0.000170  0.000166  0.000140  \n",
      "4    0.000155  0.000197  0.000167  0.000129  0.000092  \n",
      "..        ...       ...       ...       ...       ...  \n",
      "238  0.000199  0.000190  0.000193  0.000190  0.000097  \n",
      "239  0.000291  0.000279  0.000201  0.000188  0.000124  \n",
      "240  0.000257  0.000246  0.000195  0.000174  0.000107  \n",
      "241  0.000274  0.000272  0.000222  0.000195  0.000097  \n",
      "242  0.000262  0.000266  0.000230  0.000188  0.000111  \n",
      "\n",
      "[243 rows x 19 columns],            id  ExG160317  ExG160323  ExG160328  ExG160329  ExG160331  \\\n",
      "0    0.000456   0.000084   0.000097   0.000122   0.000126   0.000114   \n",
      "1    0.000912   0.000053   0.000104   0.000130   0.000123   0.000115   \n",
      "2    0.001367   0.000093   0.000100   0.000112   0.000123   0.000110   \n",
      "3    0.001823   0.000082   0.000091   0.000092   0.000107   0.000104   \n",
      "4    0.002279   0.000075   0.000101   0.000139   0.000145   0.000123   \n",
      "..        ...        ...        ...        ...        ...        ...   \n",
      "238  0.108943   0.000000   0.000000   0.000000   0.000000   0.000062   \n",
      "239  0.109399   0.000000   0.000000   0.000000   0.000000   0.000061   \n",
      "240  0.109855   0.000000   0.000000   0.000000   0.000000   0.000068   \n",
      "241  0.110311   0.000000   0.000000   0.000000   0.000000   0.000073   \n",
      "242  0.110766   0.000000   0.000054   0.000000   0.000000   0.000479   \n",
      "\n",
      "     ExG160414  ExG160419  ExG160421  ExG160425  ExG160504  ExG160510  \\\n",
      "0     0.000133   0.000109   0.000108   0.000130   0.000122   0.000089   \n",
      "1     0.000132   0.000109   0.000109   0.000128   0.000136   0.000089   \n",
      "2     0.000134   0.000113   0.000110   0.000128   0.000128   0.000089   \n",
      "3     0.000105   0.000092   0.000092   0.000115   0.000133   0.000093   \n",
      "4     0.000129   0.000120   0.000110   0.000141   0.000146   0.000098   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "238   0.000076   0.000100   0.000099   0.000122   0.000119   0.000110   \n",
      "239   0.000068   0.000086   0.000086   0.000101   0.000106   0.000109   \n",
      "240   0.000067   0.000082   0.000089   0.000123   0.000128   0.000132   \n",
      "241   0.000066   0.000095   0.000086   0.000123   0.000122   0.000118   \n",
      "242   0.000059   0.000088   0.000080   0.000120   0.000117   0.000117   \n",
      "\n",
      "     ExG160512  ExG160516  ExG160523  ExG160524  ExG160525  ExG160609  \\\n",
      "0     0.000108   0.000090   0.000081   0.000083   0.000094   0.000091   \n",
      "1     0.000116   0.000104   0.000082   0.000091   0.000106   0.000086   \n",
      "2     0.000107   0.000097   0.000079   0.000089   0.000093   0.000083   \n",
      "3     0.000112   0.000099   0.000090   0.000093   0.000098   0.000098   \n",
      "4     0.000124   0.000104   0.000086   0.000102   0.000107   0.000083   \n",
      "..         ...        ...        ...        ...        ...        ...   \n",
      "238   0.000118   0.000110   0.000125   0.000124   0.000120   0.000102   \n",
      "239   0.000119   0.000118   0.000127   0.000127   0.000136   0.000141   \n",
      "240   0.000141   0.000134   0.000121   0.000128   0.000132   0.000123   \n",
      "241   0.000143   0.000124   0.000123   0.000124   0.000130   0.000110   \n",
      "242   0.000144   0.000135   0.000128   0.000115   0.000132   0.000141   \n",
      "\n",
      "     ExG160616  ExG160622  \n",
      "0     0.000084   0.000110  \n",
      "1     0.000079   0.000102  \n",
      "2     0.000085   0.000115  \n",
      "3     0.000072   0.000112  \n",
      "4     0.000073   0.000076  \n",
      "..         ...        ...  \n",
      "238   0.000083   0.000092  \n",
      "239   0.000117   0.000103  \n",
      "240   0.000092   0.000088  \n",
      "241   0.000089   0.000100  \n",
      "242   0.000110   0.000090  \n",
      "\n",
      "[243 rows x 20 columns]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for (i, parameter) in enumerate(parameters):\n",
    "    test[i] = test[i]/np.linalg.norm(test[i])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bd83531fa4bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in 4:\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
